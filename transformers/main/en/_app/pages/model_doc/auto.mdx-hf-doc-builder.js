import{S as oTa,i as rTa,s as tTa,e as a,k as l,w as F,t as o,M as aTa,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as nTa,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as u3t}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function sTa($){let g,v,u,f,p,d,h,xo,dd,Rf,bt,cd,md,Ax,Pf,Xe,He,fd,ns,Lx,ss,ls,yx,gd,is,xx,hd,Bf,Ja;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),xo=o(`, make sure its
`),dd=a("code"),Rf=o("model_type"),bt=o(" attribute is set to the same key you use when registering the config (here "),cd=a("code"),md=o('"new-model"'),Ax=o(")."),Pf=l(),Xe=a("p"),He=o("Likewise, if your "),fd=a("code"),ns=o("NewModel"),Lx=o(" is a subclass of "),ss=a("a"),ls=o("PreTrainedModel"),yx=o(`, make sure its
`),gd=a("code"),is=o("config_class"),xx=o(` attribute is set to the same class you use when registering the model (here
`),hd=a("code"),Bf=o("NewModelConfig"),Ja=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var BI=s(u);f=r(BI,"NewModelConfig"),BI.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var ud=s(d);h=r(ud,"~transformer.PretrainedConfig"),ud.forEach(t),xo=r(Ae,`, make sure its
`),dd=n(Ae,"CODE",{});var II=s(dd);Rf=r(II,"model_type"),II.forEach(t),bt=r(Ae," attribute is set to the same key you use when registering the config (here "),cd=n(Ae,"CODE",{});var NI=s(cd);md=r(NI,'"new-model"'),NI.forEach(t),Ax=r(Ae,")."),Ae.forEach(t),Pf=i(Je),Xe=n(Je,"P",{});var $o=s(Xe);He=r($o,"Likewise, if your "),fd=n($o,"CODE",{});var Ya=s(fd);ns=r(Ya,"NewModel"),Ya.forEach(t),Lx=r($o," is a subclass of "),ss=n($o,"A",{href:!0});var qI=s(ss);ls=r(qI,"PreTrainedModel"),qI.forEach(t),yx=r($o,`, make sure its
`),gd=n($o,"CODE",{});var If=s(gd);is=r(If,"config_class"),If.forEach(t),xx=r($o,` attribute is set to the same class you use when registering the model (here
`),hd=n($o,"CODE",{});var jI=s(hd);Bf=r(jI,"NewModelConfig"),jI.forEach(t),Ja=r($o,")."),$o.forEach(t),this.h()},h(){c(ss,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,xo),e(g,dd),e(dd,Rf),e(g,bt),e(g,cd),e(cd,md),e(g,Ax),b(Je,Pf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,fd),e(fd,ns),e(Xe,Lx),e(Xe,ss),e(ss,ls),e(Xe,yx),e(Xe,gd),e(gd,is),e(Xe,xx),e(Xe,hd),e(hd,Bf),e(Xe,Ja)},d(Je){Je&&t(g),Je&&t(Pf),Je&&t(Xe)}}}function lTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dTa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var xo=s(u);f=r(xo,"use_auth_token=True"),xo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function cTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mTa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var xo=s(u);f=r(xo,"use_auth_token=True"),xo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function fTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Ta($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ETa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ATa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $Ta($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function STa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ITa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KTa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Ma($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function EMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function AMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $Ma($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function SMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function IMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KMa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hEa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uEa($){let g,v,u,f,p,d,h,xo,dd,Rf,bt,cd,md,Ax,Pf,Xe,He,fd,ns,Lx,ss,ls,yx,gd,is,xx,hd,Bf,Ja,Je,Ae,BI,ud,II,NI,$o,Ya,qI,If,jI,aso,Coo,pd,Nf,eme,$x,nso,ome,sso,woo,ds,lso,rme,iso,dso,tme,cso,mso,Aoo,kx,Loo,DI,fso,yoo,qf,xoo,_d,jf,ame,Sx,gso,nme,hso,$oo,ko,Rx,uso,Px,pso,GI,_so,bso,vso,Bx,Fso,sme,Tso,Mso,Eso,Ir,Ix,Cso,lme,wso,Aso,bd,Lso,ime,yso,xso,dme,$so,kso,Sso,A,Df,cme,Rso,Pso,OI,Bso,Iso,Nso,Gf,mme,qso,jso,VI,Dso,Gso,Oso,Of,fme,Vso,Xso,XI,zso,Qso,Wso,Vf,gme,Uso,Hso,zI,Jso,Yso,Zso,Xf,hme,Kso,elo,QI,olo,rlo,tlo,zf,ume,alo,nlo,WI,slo,llo,ilo,Qf,pme,dlo,clo,UI,mlo,flo,glo,Wf,_me,hlo,ulo,HI,plo,_lo,blo,Uf,bme,vlo,Flo,JI,Tlo,Mlo,Elo,Hf,vme,Clo,wlo,YI,Alo,Llo,ylo,Jf,Fme,xlo,$lo,ZI,klo,Slo,Rlo,Yf,Tme,Plo,Blo,KI,Ilo,Nlo,qlo,Zf,Mme,jlo,Dlo,eN,Glo,Olo,Vlo,Kf,Eme,Xlo,zlo,oN,Qlo,Wlo,Ulo,eg,Cme,Hlo,Jlo,rN,Ylo,Zlo,Klo,og,wme,eio,oio,tN,rio,tio,aio,rg,Ame,nio,sio,aN,lio,iio,dio,tg,Lme,cio,mio,nN,fio,gio,hio,ag,yme,uio,pio,sN,_io,bio,vio,ng,xme,Fio,Tio,lN,Mio,Eio,Cio,sg,$me,wio,Aio,iN,Lio,yio,xio,lg,kme,$io,kio,dN,Sio,Rio,Pio,ig,Sme,Bio,Iio,cN,Nio,qio,jio,dg,Rme,Dio,Gio,mN,Oio,Vio,Xio,cg,Pme,zio,Qio,fN,Wio,Uio,Hio,mg,Bme,Jio,Yio,gN,Zio,Kio,edo,fg,Ime,odo,rdo,hN,tdo,ado,ndo,gg,Nme,sdo,ldo,uN,ido,ddo,cdo,hg,qme,mdo,fdo,pN,gdo,hdo,udo,ug,jme,pdo,_do,_N,bdo,vdo,Fdo,pg,Dme,Tdo,Mdo,bN,Edo,Cdo,wdo,_g,Gme,Ado,Ldo,vN,ydo,xdo,$do,bg,Ome,kdo,Sdo,FN,Rdo,Pdo,Bdo,vg,Vme,Ido,Ndo,TN,qdo,jdo,Ddo,Fg,Xme,Gdo,Odo,MN,Vdo,Xdo,zdo,Tg,zme,Qdo,Wdo,EN,Udo,Hdo,Jdo,Mg,Qme,Ydo,Zdo,CN,Kdo,eco,oco,Eg,Wme,rco,tco,wN,aco,nco,sco,Cg,Ume,lco,ico,AN,dco,cco,mco,wg,Hme,fco,gco,LN,hco,uco,pco,Ag,Jme,_co,bco,yN,vco,Fco,Tco,Lg,Yme,Mco,Eco,xN,Cco,wco,Aco,yg,Zme,Lco,yco,$N,xco,$co,kco,xg,Kme,Sco,Rco,kN,Pco,Bco,Ico,$g,efe,Nco,qco,SN,jco,Dco,Gco,kg,ofe,Oco,Vco,RN,Xco,zco,Qco,Sg,rfe,Wco,Uco,PN,Hco,Jco,Yco,Rg,tfe,Zco,Kco,BN,emo,omo,rmo,Pg,afe,tmo,amo,IN,nmo,smo,lmo,Bg,nfe,imo,dmo,NN,cmo,mmo,fmo,Ig,sfe,gmo,hmo,qN,umo,pmo,_mo,Ng,lfe,bmo,vmo,jN,Fmo,Tmo,Mmo,qg,ife,Emo,Cmo,DN,wmo,Amo,Lmo,jg,dfe,ymo,xmo,GN,$mo,kmo,Smo,Dg,cfe,Rmo,Pmo,ON,Bmo,Imo,Nmo,Gg,mfe,qmo,jmo,VN,Dmo,Gmo,Omo,Og,ffe,Vmo,Xmo,XN,zmo,Qmo,Wmo,Vg,gfe,Umo,Hmo,zN,Jmo,Ymo,Zmo,Xg,hfe,Kmo,efo,QN,ofo,rfo,tfo,zg,ufe,afo,nfo,WN,sfo,lfo,ifo,Qg,pfe,dfo,cfo,UN,mfo,ffo,gfo,Wg,_fe,hfo,ufo,HN,pfo,_fo,bfo,Ug,bfe,vfo,Ffo,JN,Tfo,Mfo,Efo,Hg,vfe,Cfo,wfo,YN,Afo,Lfo,yfo,Jg,Ffe,xfo,$fo,ZN,kfo,Sfo,Rfo,Yg,Tfe,Pfo,Bfo,KN,Ifo,Nfo,qfo,Zg,Mfe,jfo,Dfo,eq,Gfo,Ofo,Vfo,Kg,Efe,Xfo,zfo,oq,Qfo,Wfo,Ufo,eh,Cfe,Hfo,Jfo,rq,Yfo,Zfo,Kfo,oh,wfe,ego,ogo,tq,rgo,tgo,ago,rh,Afe,ngo,sgo,aq,lgo,igo,dgo,th,Lfe,cgo,mgo,nq,fgo,ggo,hgo,ah,yfe,ugo,pgo,sq,_go,bgo,vgo,nh,xfe,Fgo,Tgo,lq,Mgo,Ego,Cgo,sh,$fe,wgo,Ago,iq,Lgo,ygo,xgo,lh,kfe,$go,kgo,dq,Sgo,Rgo,Pgo,ih,Sfe,Bgo,Igo,cq,Ngo,qgo,jgo,dh,Rfe,Dgo,Ggo,mq,Ogo,Vgo,Xgo,ch,Pfe,zgo,Qgo,fq,Wgo,Ugo,Hgo,mh,Bfe,Jgo,Ygo,gq,Zgo,Kgo,eho,fh,Ife,oho,rho,hq,tho,aho,nho,gh,Nfe,sho,lho,uq,iho,dho,cho,hh,qfe,mho,fho,pq,gho,hho,uho,uh,jfe,pho,_ho,_q,bho,vho,Fho,ph,Dfe,Tho,Mho,bq,Eho,Cho,who,_h,Gfe,Aho,Lho,vq,yho,xho,$ho,bh,Ofe,kho,Sho,Fq,Rho,Pho,Bho,vh,Vfe,Iho,Nho,Tq,qho,jho,Dho,Fh,Xfe,Gho,Oho,Mq,Vho,Xho,zho,Th,zfe,Qho,Who,Eq,Uho,Hho,Jho,Mh,Qfe,Yho,Zho,Cq,Kho,euo,ouo,Eh,Wfe,ruo,tuo,wq,auo,nuo,suo,Ch,Ufe,luo,iuo,Aq,duo,cuo,muo,wh,Hfe,fuo,guo,Lq,huo,uuo,puo,Ah,Jfe,_uo,buo,yq,vuo,Fuo,Tuo,Lh,Yfe,Muo,Euo,xq,Cuo,wuo,Auo,yh,Zfe,Luo,yuo,$q,xuo,$uo,kuo,xh,Kfe,Suo,Ruo,kq,Puo,Buo,Iuo,$h,ege,Nuo,quo,Sq,juo,Duo,Guo,kh,oge,Ouo,Vuo,Rq,Xuo,zuo,Quo,Sh,rge,Wuo,Uuo,Pq,Huo,Juo,Yuo,Rh,tge,Zuo,Kuo,Bq,epo,opo,rpo,Ph,age,tpo,apo,Iq,npo,spo,lpo,Bh,nge,ipo,dpo,Nq,cpo,mpo,fpo,Ih,sge,gpo,hpo,qq,upo,ppo,_po,Nh,lge,bpo,vpo,jq,Fpo,Tpo,Mpo,qh,ige,Epo,Cpo,Dq,wpo,Apo,Lpo,jh,dge,ypo,xpo,Gq,$po,kpo,Spo,Dh,cge,Rpo,Ppo,Oq,Bpo,Ipo,Npo,Gh,mge,qpo,jpo,Vq,Dpo,Gpo,Opo,Oh,fge,Vpo,Xpo,Xq,zpo,Qpo,Wpo,Vh,gge,Upo,Hpo,zq,Jpo,Ypo,Zpo,Xh,hge,Kpo,e_o,Qq,o_o,r_o,t_o,zh,uge,a_o,n_o,Wq,s_o,l_o,i_o,Qh,pge,d_o,c_o,Uq,m_o,f_o,g_o,Wh,_ge,h_o,u_o,Hq,p_o,__o,b_o,Uh,bge,v_o,F_o,Jq,T_o,M_o,E_o,Hh,vge,C_o,w_o,Yq,A_o,L_o,y_o,Jh,Fge,x_o,$_o,Zq,k_o,S_o,R_o,Yh,Tge,P_o,B_o,Kq,I_o,N_o,q_o,Zh,Mge,j_o,D_o,ej,G_o,O_o,V_o,Kh,Ege,X_o,z_o,oj,Q_o,W_o,U_o,eu,Cge,H_o,J_o,rj,Y_o,Z_o,K_o,ou,wge,e1o,o1o,tj,r1o,t1o,a1o,ru,Age,n1o,s1o,aj,l1o,i1o,d1o,tu,Lge,c1o,m1o,nj,f1o,g1o,h1o,au,yge,u1o,p1o,sj,_1o,b1o,v1o,nu,xge,F1o,T1o,lj,M1o,E1o,C1o,su,$ge,w1o,A1o,ij,L1o,y1o,x1o,lu,kge,$1o,k1o,dj,S1o,R1o,P1o,iu,Sge,B1o,I1o,cj,N1o,q1o,j1o,du,Rge,D1o,G1o,mj,O1o,V1o,X1o,cu,Pge,z1o,Q1o,fj,W1o,U1o,H1o,mu,J1o,fu,Nx,Y1o,Bge,Z1o,koo,vd,gu,Ige,qx,K1o,Nge,e2o,Soo,So,jx,o2o,Dx,r2o,gj,t2o,a2o,n2o,Gx,s2o,qge,l2o,i2o,d2o,Nr,Ox,c2o,jge,m2o,f2o,Za,g2o,Dge,h2o,u2o,Gge,p2o,_2o,Oge,b2o,v2o,F2o,k,cs,Vge,T2o,M2o,hj,E2o,C2o,uj,w2o,A2o,L2o,ms,Xge,y2o,x2o,pj,$2o,k2o,_j,S2o,R2o,P2o,fs,zge,B2o,I2o,bj,N2o,q2o,vj,j2o,D2o,G2o,hu,Qge,O2o,V2o,Fj,X2o,z2o,Q2o,gs,Wge,W2o,U2o,Tj,H2o,J2o,Mj,Y2o,Z2o,K2o,uu,Uge,ebo,obo,Ej,rbo,tbo,abo,pu,Hge,nbo,sbo,Cj,lbo,ibo,dbo,_u,Jge,cbo,mbo,wj,fbo,gbo,hbo,hs,Yge,ubo,pbo,Aj,_bo,bbo,Lj,vbo,Fbo,Tbo,us,Zge,Mbo,Ebo,yj,Cbo,wbo,xj,Abo,Lbo,ybo,ps,Kge,xbo,$bo,$j,kbo,Sbo,kj,Rbo,Pbo,Bbo,bu,ehe,Ibo,Nbo,Sj,qbo,jbo,Dbo,vu,ohe,Gbo,Obo,Rj,Vbo,Xbo,zbo,Fu,rhe,Qbo,Wbo,Pj,Ubo,Hbo,Jbo,_s,the,Ybo,Zbo,Bj,Kbo,evo,Ij,ovo,rvo,tvo,Tu,ahe,avo,nvo,Nj,svo,lvo,ivo,bs,nhe,dvo,cvo,qj,mvo,fvo,jj,gvo,hvo,uvo,vs,she,pvo,_vo,Dj,bvo,vvo,Gj,Fvo,Tvo,Mvo,Fs,lhe,Evo,Cvo,Oj,wvo,Avo,Vj,Lvo,yvo,xvo,Ts,ihe,$vo,kvo,Xj,Svo,Rvo,zj,Pvo,Bvo,Ivo,Mu,dhe,Nvo,qvo,Qj,jvo,Dvo,Gvo,Ms,che,Ovo,Vvo,Wj,Xvo,zvo,Uj,Qvo,Wvo,Uvo,Es,mhe,Hvo,Jvo,Hj,Yvo,Zvo,Jj,Kvo,eFo,oFo,Cs,fhe,rFo,tFo,Yj,aFo,nFo,Zj,sFo,lFo,iFo,ws,ghe,dFo,cFo,Kj,mFo,fFo,eD,gFo,hFo,uFo,As,hhe,pFo,_Fo,oD,bFo,vFo,rD,FFo,TFo,MFo,Ls,uhe,EFo,CFo,tD,wFo,AFo,aD,LFo,yFo,xFo,ys,phe,$Fo,kFo,nD,SFo,RFo,sD,PFo,BFo,IFo,Eu,_he,NFo,qFo,lD,jFo,DFo,GFo,xs,bhe,OFo,VFo,iD,XFo,zFo,dD,QFo,WFo,UFo,Cu,vhe,HFo,JFo,cD,YFo,ZFo,KFo,$s,Fhe,eTo,oTo,mD,rTo,tTo,fD,aTo,nTo,sTo,ks,The,lTo,iTo,gD,dTo,cTo,hD,mTo,fTo,gTo,Ss,Mhe,hTo,uTo,uD,pTo,_To,pD,bTo,vTo,FTo,wu,Ehe,TTo,MTo,_D,ETo,CTo,wTo,Au,Che,ATo,LTo,bD,yTo,xTo,$To,Rs,whe,kTo,STo,vD,RTo,PTo,FD,BTo,ITo,NTo,Ps,Ahe,qTo,jTo,TD,DTo,GTo,MD,OTo,VTo,XTo,Bs,Lhe,zTo,QTo,ED,WTo,UTo,CD,HTo,JTo,YTo,Lu,yhe,ZTo,KTo,wD,eMo,oMo,rMo,Is,xhe,tMo,aMo,AD,nMo,sMo,LD,lMo,iMo,dMo,Ns,$he,cMo,mMo,yD,fMo,gMo,xD,hMo,uMo,pMo,qs,khe,_Mo,bMo,$D,vMo,FMo,kD,TMo,MMo,EMo,js,She,CMo,wMo,SD,AMo,LMo,RD,yMo,xMo,$Mo,Ds,Rhe,kMo,SMo,PD,RMo,PMo,BD,BMo,IMo,NMo,Gs,Phe,qMo,jMo,ID,DMo,GMo,ND,OMo,VMo,XMo,Os,Bhe,zMo,QMo,qD,WMo,UMo,jD,HMo,JMo,YMo,Vs,Ihe,ZMo,KMo,DD,eEo,oEo,GD,rEo,tEo,aEo,yu,Nhe,nEo,sEo,OD,lEo,iEo,dEo,Xs,qhe,cEo,mEo,VD,fEo,gEo,XD,hEo,uEo,pEo,xu,jhe,_Eo,bEo,zD,vEo,FEo,TEo,$u,Dhe,MEo,EEo,QD,CEo,wEo,AEo,zs,Ghe,LEo,yEo,WD,xEo,$Eo,UD,kEo,SEo,REo,Qs,Ohe,PEo,BEo,HD,IEo,NEo,JD,qEo,jEo,DEo,Ws,Vhe,GEo,OEo,YD,VEo,XEo,ZD,zEo,QEo,WEo,ku,Xhe,UEo,HEo,KD,JEo,YEo,ZEo,Us,zhe,KEo,e4o,eG,o4o,r4o,oG,t4o,a4o,n4o,Hs,Qhe,s4o,l4o,rG,i4o,d4o,tG,c4o,m4o,f4o,Js,Whe,g4o,h4o,aG,u4o,p4o,nG,_4o,b4o,v4o,Ys,Uhe,F4o,T4o,sG,M4o,E4o,lG,C4o,w4o,A4o,Zs,Hhe,L4o,y4o,iG,x4o,$4o,dG,k4o,S4o,R4o,Ks,Jhe,P4o,B4o,cG,I4o,N4o,mG,q4o,j4o,D4o,el,Yhe,G4o,O4o,fG,V4o,X4o,gG,z4o,Q4o,W4o,ol,Zhe,U4o,H4o,hG,J4o,Y4o,uG,Z4o,K4o,eCo,Su,Khe,oCo,rCo,pG,tCo,aCo,nCo,rl,eue,sCo,lCo,_G,iCo,dCo,bG,cCo,mCo,fCo,tl,oue,gCo,hCo,vG,uCo,pCo,FG,_Co,bCo,vCo,Ru,rue,FCo,TCo,TG,MCo,ECo,CCo,Pu,tue,wCo,ACo,MG,LCo,yCo,xCo,Bu,aue,$Co,kCo,EG,SCo,RCo,PCo,Iu,nue,BCo,ICo,CG,NCo,qCo,jCo,al,sue,DCo,GCo,wG,OCo,VCo,AG,XCo,zCo,QCo,Nu,lue,WCo,UCo,LG,HCo,JCo,YCo,nl,iue,ZCo,KCo,yG,e3o,o3o,xG,r3o,t3o,a3o,sl,due,n3o,s3o,$G,l3o,i3o,kG,d3o,c3o,m3o,ll,cue,f3o,g3o,SG,h3o,u3o,RG,p3o,_3o,b3o,il,mue,v3o,F3o,PG,T3o,M3o,BG,E3o,C3o,w3o,dl,fue,A3o,L3o,IG,y3o,x3o,NG,$3o,k3o,S3o,cl,gue,R3o,P3o,qG,B3o,I3o,jG,N3o,q3o,j3o,qu,hue,D3o,G3o,DG,O3o,V3o,X3o,ju,uue,z3o,Q3o,GG,W3o,U3o,H3o,ml,pue,J3o,Y3o,OG,Z3o,K3o,VG,e5o,o5o,r5o,fl,_ue,t5o,a5o,XG,n5o,s5o,zG,l5o,i5o,d5o,gl,bue,c5o,m5o,QG,f5o,g5o,WG,h5o,u5o,p5o,Du,vue,_5o,b5o,UG,v5o,F5o,T5o,Gu,Fue,M5o,E5o,HG,C5o,w5o,A5o,Ou,Tue,L5o,y5o,JG,x5o,$5o,k5o,hl,Mue,S5o,R5o,YG,P5o,B5o,ZG,I5o,N5o,q5o,ul,Eue,j5o,D5o,KG,G5o,O5o,eO,V5o,X5o,z5o,Vu,Cue,Q5o,W5o,oO,U5o,H5o,J5o,Xu,wue,Y5o,Z5o,rO,K5o,e0o,o0o,zu,Aue,r0o,t0o,tO,a0o,n0o,s0o,Qu,Lue,l0o,i0o,aO,d0o,c0o,m0o,pl,yue,f0o,g0o,nO,h0o,u0o,sO,p0o,_0o,b0o,_l,xue,v0o,F0o,lO,T0o,M0o,iO,E0o,C0o,w0o,Wu,$ue,A0o,L0o,dO,y0o,x0o,$0o,Uu,kue,k0o,S0o,cO,R0o,P0o,B0o,bl,Sue,I0o,N0o,mO,q0o,j0o,fO,D0o,G0o,O0o,vl,Rue,V0o,X0o,gO,z0o,Q0o,hO,W0o,U0o,H0o,Fl,Pue,J0o,Y0o,uO,Z0o,K0o,pO,ewo,owo,rwo,Tl,Bue,two,awo,_O,nwo,swo,bO,lwo,iwo,dwo,Hu,cwo,Ju,Vx,mwo,Iue,fwo,Roo,Fd,Yu,Nue,Xx,gwo,que,hwo,Poo,Ro,zx,uwo,Qx,pwo,vO,_wo,bwo,vwo,Wx,Fwo,jue,Two,Mwo,Ewo,Ye,Ux,Cwo,Due,wwo,Awo,Ka,Lwo,Gue,ywo,xwo,Oue,$wo,kwo,Vue,Swo,Rwo,Pwo,z,Zu,Xue,Bwo,Iwo,FO,Nwo,qwo,jwo,Ku,zue,Dwo,Gwo,TO,Owo,Vwo,Xwo,ep,Que,zwo,Qwo,MO,Wwo,Uwo,Hwo,op,Wue,Jwo,Ywo,EO,Zwo,Kwo,eAo,rp,Uue,oAo,rAo,CO,tAo,aAo,nAo,tp,Hue,sAo,lAo,wO,iAo,dAo,cAo,ap,Jue,mAo,fAo,AO,gAo,hAo,uAo,np,Yue,pAo,_Ao,LO,bAo,vAo,FAo,sp,Zue,TAo,MAo,yO,EAo,CAo,wAo,lp,Kue,AAo,LAo,xO,yAo,xAo,$Ao,ip,epe,kAo,SAo,$O,RAo,PAo,BAo,dp,ope,IAo,NAo,kO,qAo,jAo,DAo,cp,rpe,GAo,OAo,SO,VAo,XAo,zAo,mp,tpe,QAo,WAo,RO,UAo,HAo,JAo,fp,ape,YAo,ZAo,PO,KAo,e6o,o6o,gp,npe,r6o,t6o,BO,a6o,n6o,s6o,hp,spe,l6o,i6o,IO,d6o,c6o,m6o,up,lpe,f6o,g6o,NO,h6o,u6o,p6o,pp,ipe,_6o,b6o,qO,v6o,F6o,T6o,_p,dpe,M6o,E6o,jO,C6o,w6o,A6o,bp,cpe,L6o,y6o,DO,x6o,$6o,k6o,vp,mpe,S6o,R6o,GO,P6o,B6o,I6o,Fp,fpe,N6o,q6o,OO,j6o,D6o,G6o,Tp,gpe,O6o,V6o,VO,X6o,z6o,Q6o,Mp,hpe,W6o,U6o,XO,H6o,J6o,Y6o,Ep,upe,Z6o,K6o,zO,e7o,o7o,r7o,Cp,ppe,t7o,a7o,QO,n7o,s7o,l7o,wp,_pe,i7o,d7o,WO,c7o,m7o,f7o,Ap,bpe,g7o,h7o,UO,u7o,p7o,_7o,Lp,vpe,b7o,v7o,HO,F7o,T7o,M7o,yp,Fpe,E7o,C7o,JO,w7o,A7o,L7o,xp,Tpe,y7o,x7o,YO,$7o,k7o,S7o,$p,Mpe,R7o,P7o,ZO,B7o,I7o,N7o,kp,Epe,q7o,j7o,KO,D7o,G7o,O7o,Sp,Cpe,V7o,X7o,eV,z7o,Q7o,W7o,Rp,wpe,U7o,H7o,oV,J7o,Y7o,Z7o,Pp,Ape,K7o,eLo,rV,oLo,rLo,tLo,Bp,Lpe,aLo,nLo,tV,sLo,lLo,iLo,Ip,ype,dLo,cLo,aV,mLo,fLo,gLo,Np,xpe,hLo,uLo,nV,pLo,_Lo,bLo,qp,$pe,vLo,FLo,sV,TLo,MLo,ELo,jp,kpe,CLo,wLo,lV,ALo,LLo,yLo,Dp,Spe,xLo,$Lo,iV,kLo,SLo,RLo,Gp,PLo,Op,BLo,Vp,Hx,ILo,Rpe,NLo,Boo,Td,Xp,Ppe,Jx,qLo,Bpe,jLo,Ioo,Po,Yx,DLo,Zx,GLo,dV,OLo,VLo,XLo,Kx,zLo,Ipe,QLo,WLo,ULo,Ze,e$,HLo,Npe,JLo,YLo,Md,ZLo,qpe,KLo,e8o,jpe,o8o,r8o,t8o,se,zp,Dpe,a8o,n8o,cV,s8o,l8o,i8o,Qp,Gpe,d8o,c8o,mV,m8o,f8o,g8o,Wp,Ope,h8o,u8o,fV,p8o,_8o,b8o,Up,Vpe,v8o,F8o,gV,T8o,M8o,E8o,Hp,Xpe,C8o,w8o,hV,A8o,L8o,y8o,Jp,zpe,x8o,$8o,uV,k8o,S8o,R8o,Yp,Qpe,P8o,B8o,pV,I8o,N8o,q8o,Zp,Wpe,j8o,D8o,_V,G8o,O8o,V8o,Kp,Upe,X8o,z8o,bV,Q8o,W8o,U8o,e_,Hpe,H8o,J8o,vV,Y8o,Z8o,K8o,o_,Jpe,eyo,oyo,FV,ryo,tyo,ayo,r_,Ype,nyo,syo,TV,lyo,iyo,dyo,t_,Zpe,cyo,myo,MV,fyo,gyo,hyo,a_,Kpe,uyo,pyo,EV,_yo,byo,vyo,n_,e_e,Fyo,Tyo,CV,Myo,Eyo,Cyo,s_,o_e,wyo,Ayo,wV,Lyo,yyo,xyo,l_,r_e,$yo,kyo,AV,Syo,Ryo,Pyo,i_,t_e,Byo,Iyo,LV,Nyo,qyo,jyo,d_,a_e,Dyo,Gyo,yV,Oyo,Vyo,Xyo,c_,n_e,zyo,Qyo,xV,Wyo,Uyo,Hyo,m_,s_e,Jyo,Yyo,$V,Zyo,Kyo,e9o,f_,l_e,o9o,r9o,kV,t9o,a9o,n9o,g_,i_e,s9o,l9o,SV,i9o,d9o,c9o,h_,m9o,u_,f9o,p_,o$,g9o,d_e,h9o,Noo,Ed,__,c_e,r$,u9o,m_e,p9o,qoo,Bo,t$,_9o,Cd,b9o,RV,v9o,F9o,PV,T9o,M9o,E9o,a$,C9o,f_e,w9o,A9o,L9o,vt,n$,y9o,g_e,x9o,$9o,wd,k9o,h_e,S9o,R9o,BV,P9o,B9o,I9o,b_,N9o,Ke,s$,q9o,u_e,j9o,D9o,en,G9o,p_e,O9o,V9o,__e,X9o,z9o,b_e,Q9o,W9o,U9o,y,v_,v_e,H9o,J9o,IV,Y9o,Z9o,K9o,F_,F_e,exo,oxo,NV,rxo,txo,axo,T_,T_e,nxo,sxo,qV,lxo,ixo,dxo,M_,M_e,cxo,mxo,jV,fxo,gxo,hxo,E_,E_e,uxo,pxo,DV,_xo,bxo,vxo,C_,C_e,Fxo,Txo,GV,Mxo,Exo,Cxo,w_,w_e,wxo,Axo,OV,Lxo,yxo,xxo,A_,A_e,$xo,kxo,VV,Sxo,Rxo,Pxo,L_,L_e,Bxo,Ixo,XV,Nxo,qxo,jxo,y_,y_e,Dxo,Gxo,zV,Oxo,Vxo,Xxo,x_,x_e,zxo,Qxo,QV,Wxo,Uxo,Hxo,$_,$_e,Jxo,Yxo,WV,Zxo,Kxo,e$o,k_,k_e,o$o,r$o,UV,t$o,a$o,n$o,S_,S_e,s$o,l$o,HV,i$o,d$o,c$o,R_,R_e,m$o,f$o,JV,g$o,h$o,u$o,P_,P_e,p$o,_$o,YV,b$o,v$o,F$o,B_,B_e,T$o,M$o,ZV,E$o,C$o,w$o,I_,I_e,A$o,L$o,KV,y$o,x$o,$$o,N_,N_e,k$o,S$o,eX,R$o,P$o,B$o,q_,q_e,I$o,N$o,oX,q$o,j$o,D$o,j_,j_e,G$o,O$o,rX,V$o,X$o,z$o,D_,D_e,Q$o,W$o,tX,U$o,H$o,J$o,G_,G_e,Y$o,Z$o,aX,K$o,eko,oko,O_,O_e,rko,tko,nX,ako,nko,sko,V_,V_e,lko,iko,sX,dko,cko,mko,X_,X_e,fko,gko,lX,hko,uko,pko,z_,z_e,_ko,bko,iX,vko,Fko,Tko,Q_,Q_e,Mko,Eko,dX,Cko,wko,Ako,W_,W_e,Lko,yko,cX,xko,$ko,kko,U_,U_e,Sko,Rko,mX,Pko,Bko,Iko,H_,H_e,Nko,qko,fX,jko,Dko,Gko,J_,J_e,Oko,Vko,gX,Xko,zko,Qko,Y_,Y_e,Wko,Uko,hX,Hko,Jko,Yko,Z_,Z_e,Zko,Kko,uX,eSo,oSo,rSo,K_,K_e,tSo,aSo,pX,nSo,sSo,lSo,e1,e1e,iSo,dSo,_X,cSo,mSo,fSo,o1,o1e,gSo,hSo,bX,uSo,pSo,_So,r1,r1e,bSo,vSo,vX,FSo,TSo,MSo,t1,t1e,ESo,CSo,FX,wSo,ASo,LSo,Ml,a1e,ySo,xSo,TX,$So,kSo,MX,SSo,RSo,PSo,a1,n1e,BSo,ISo,EX,NSo,qSo,jSo,n1,s1e,DSo,GSo,CX,OSo,VSo,XSo,s1,l1e,zSo,QSo,wX,WSo,USo,HSo,l1,i1e,JSo,YSo,AX,ZSo,KSo,eRo,i1,d1e,oRo,rRo,LX,tRo,aRo,nRo,d1,c1e,sRo,lRo,yX,iRo,dRo,cRo,c1,m1e,mRo,fRo,xX,gRo,hRo,uRo,m1,f1e,pRo,_Ro,$X,bRo,vRo,FRo,f1,g1e,TRo,MRo,kX,ERo,CRo,wRo,g1,h1e,ARo,LRo,SX,yRo,xRo,$Ro,h1,u1e,kRo,SRo,RX,RRo,PRo,BRo,u1,p1e,IRo,NRo,PX,qRo,jRo,DRo,p1,_1e,GRo,ORo,BX,VRo,XRo,zRo,_1,b1e,QRo,WRo,IX,URo,HRo,JRo,b1,v1e,YRo,ZRo,NX,KRo,ePo,oPo,v1,F1e,rPo,tPo,qX,aPo,nPo,sPo,F1,T1e,lPo,iPo,jX,dPo,cPo,mPo,T1,M1e,fPo,gPo,DX,hPo,uPo,pPo,M1,E1e,_Po,bPo,GX,vPo,FPo,TPo,E1,C1e,MPo,EPo,OX,CPo,wPo,APo,C1,w1e,LPo,yPo,VX,xPo,$Po,kPo,w1,A1e,SPo,RPo,XX,PPo,BPo,IPo,A1,L1e,NPo,qPo,zX,jPo,DPo,GPo,L1,y1e,OPo,VPo,QX,XPo,zPo,QPo,y1,x1e,WPo,UPo,WX,HPo,JPo,YPo,x1,$1e,ZPo,KPo,UX,eBo,oBo,rBo,$1,k1e,tBo,aBo,HX,nBo,sBo,lBo,k1,S1e,iBo,dBo,JX,cBo,mBo,fBo,S1,R1e,gBo,hBo,YX,uBo,pBo,_Bo,R1,P1e,bBo,vBo,ZX,FBo,TBo,MBo,P1,B1e,EBo,CBo,KX,wBo,ABo,LBo,B1,I1e,yBo,xBo,ez,$Bo,kBo,SBo,I1,N1e,RBo,PBo,oz,BBo,IBo,NBo,N1,q1e,qBo,jBo,rz,DBo,GBo,OBo,q1,j1e,VBo,XBo,tz,zBo,QBo,WBo,j1,D1e,UBo,HBo,az,JBo,YBo,ZBo,D1,G1e,KBo,eIo,nz,oIo,rIo,tIo,G1,O1e,aIo,nIo,sz,sIo,lIo,iIo,O1,V1e,dIo,cIo,lz,mIo,fIo,gIo,V1,X1e,hIo,uIo,iz,pIo,_Io,bIo,X1,z1e,vIo,FIo,dz,TIo,MIo,EIo,z1,Q1e,CIo,wIo,cz,AIo,LIo,yIo,Q1,W1e,xIo,$Io,mz,kIo,SIo,RIo,W1,U1e,PIo,BIo,fz,IIo,NIo,qIo,U1,H1e,jIo,DIo,gz,GIo,OIo,VIo,H1,J1e,XIo,zIo,hz,QIo,WIo,UIo,J1,Y1e,HIo,JIo,uz,YIo,ZIo,KIo,Y1,Z1e,eNo,oNo,pz,rNo,tNo,aNo,Z1,K1e,nNo,sNo,_z,lNo,iNo,dNo,K1,e2e,cNo,mNo,bz,fNo,gNo,hNo,e2,o2e,uNo,pNo,vz,_No,bNo,vNo,o2,r2e,FNo,TNo,Fz,MNo,ENo,CNo,r2,t2e,wNo,ANo,Tz,LNo,yNo,xNo,t2,a2e,$No,kNo,Mz,SNo,RNo,PNo,a2,n2e,BNo,INo,Ez,NNo,qNo,jNo,n2,s2e,DNo,GNo,Cz,ONo,VNo,XNo,s2,l2e,zNo,QNo,wz,WNo,UNo,HNo,l2,i2e,JNo,YNo,Az,ZNo,KNo,eqo,i2,d2e,oqo,rqo,Lz,tqo,aqo,nqo,d2,c2e,sqo,lqo,yz,iqo,dqo,cqo,c2,m2e,mqo,fqo,xz,gqo,hqo,uqo,m2,f2e,pqo,_qo,$z,bqo,vqo,Fqo,f2,g2e,Tqo,Mqo,kz,Eqo,Cqo,wqo,g2,h2e,Aqo,Lqo,Sz,yqo,xqo,$qo,h2,u2e,kqo,Sqo,Rz,Rqo,Pqo,Bqo,u2,p2e,Iqo,Nqo,Pz,qqo,jqo,Dqo,p2,_2e,Gqo,Oqo,Bz,Vqo,Xqo,zqo,_2,b2e,Qqo,Wqo,Iz,Uqo,Hqo,Jqo,b2,v2e,Yqo,Zqo,Nz,Kqo,ejo,ojo,v2,F2e,rjo,tjo,qz,ajo,njo,sjo,F2,T2e,ljo,ijo,jz,djo,cjo,mjo,T2,M2e,fjo,gjo,Dz,hjo,ujo,pjo,M2,E2e,_jo,bjo,Gz,vjo,Fjo,Tjo,E2,C2e,Mjo,Ejo,Oz,Cjo,wjo,Ajo,C2,w2e,Ljo,yjo,Vz,xjo,$jo,kjo,w2,A2e,Sjo,Rjo,Xz,Pjo,Bjo,Ijo,A2,L2e,Njo,qjo,zz,jjo,Djo,Gjo,L2,y2e,Ojo,Vjo,Qz,Xjo,zjo,Qjo,y2,x2e,Wjo,Ujo,Wz,Hjo,Jjo,Yjo,x2,$2e,Zjo,Kjo,Uz,eDo,oDo,rDo,$2,k2e,tDo,aDo,Hz,nDo,sDo,lDo,k2,S2e,iDo,dDo,Jz,cDo,mDo,fDo,S2,R2e,gDo,hDo,Yz,uDo,pDo,_Do,R2,P2e,bDo,vDo,Zz,FDo,TDo,MDo,P2,B2e,EDo,CDo,Kz,wDo,ADo,LDo,B2,I2e,yDo,xDo,eQ,$Do,kDo,SDo,I2,N2e,RDo,PDo,oQ,BDo,IDo,NDo,N2,qDo,q2e,jDo,DDo,j2e,GDo,ODo,q2,joo,Ad,j2,D2e,l$,VDo,G2e,XDo,Doo,Io,i$,zDo,Ld,QDo,rQ,WDo,UDo,tQ,HDo,JDo,YDo,d$,ZDo,O2e,KDo,eGo,oGo,Ft,c$,rGo,V2e,tGo,aGo,yd,nGo,X2e,sGo,lGo,aQ,iGo,dGo,cGo,D2,mGo,eo,m$,fGo,z2e,gGo,hGo,on,uGo,Q2e,pGo,_Go,W2e,bGo,vGo,U2e,FGo,TGo,MGo,G,G2,H2e,EGo,CGo,nQ,wGo,AGo,LGo,O2,J2e,yGo,xGo,sQ,$Go,kGo,SGo,V2,Y2e,RGo,PGo,lQ,BGo,IGo,NGo,X2,Z2e,qGo,jGo,iQ,DGo,GGo,OGo,z2,K2e,VGo,XGo,dQ,zGo,QGo,WGo,Q2,ebe,UGo,HGo,cQ,JGo,YGo,ZGo,W2,obe,KGo,eOo,mQ,oOo,rOo,tOo,U2,rbe,aOo,nOo,fQ,sOo,lOo,iOo,H2,tbe,dOo,cOo,gQ,mOo,fOo,gOo,J2,abe,hOo,uOo,hQ,pOo,_Oo,bOo,Y2,nbe,vOo,FOo,uQ,TOo,MOo,EOo,Z2,sbe,COo,wOo,pQ,AOo,LOo,yOo,K2,lbe,xOo,$Oo,_Q,kOo,SOo,ROo,eb,ibe,POo,BOo,bQ,IOo,NOo,qOo,ob,dbe,jOo,DOo,vQ,GOo,OOo,VOo,rb,cbe,XOo,zOo,FQ,QOo,WOo,UOo,tb,mbe,HOo,JOo,TQ,YOo,ZOo,KOo,ab,fbe,eVo,oVo,MQ,rVo,tVo,aVo,nb,gbe,nVo,sVo,EQ,lVo,iVo,dVo,sb,hbe,cVo,mVo,CQ,fVo,gVo,hVo,lb,ube,uVo,pVo,wQ,_Vo,bVo,vVo,ib,pbe,FVo,TVo,AQ,MVo,EVo,CVo,db,_be,wVo,AVo,LQ,LVo,yVo,xVo,cb,bbe,$Vo,kVo,yQ,SVo,RVo,PVo,mb,vbe,BVo,IVo,xQ,NVo,qVo,jVo,fb,Fbe,DVo,GVo,$Q,OVo,VVo,XVo,gb,Tbe,zVo,QVo,kQ,WVo,UVo,HVo,hb,Mbe,JVo,YVo,SQ,ZVo,KVo,eXo,ub,Ebe,oXo,rXo,RQ,tXo,aXo,nXo,pb,Cbe,sXo,lXo,PQ,iXo,dXo,cXo,_b,wbe,mXo,fXo,BQ,gXo,hXo,uXo,bb,Abe,pXo,_Xo,IQ,bXo,vXo,FXo,vb,Lbe,TXo,MXo,NQ,EXo,CXo,wXo,Fb,ybe,AXo,LXo,qQ,yXo,xXo,$Xo,Tb,xbe,kXo,SXo,jQ,RXo,PXo,BXo,Mb,$be,IXo,NXo,DQ,qXo,jXo,DXo,Eb,kbe,GXo,OXo,GQ,VXo,XXo,zXo,Cb,Sbe,QXo,WXo,OQ,UXo,HXo,JXo,wb,Rbe,YXo,ZXo,VQ,KXo,ezo,ozo,Ab,Pbe,rzo,tzo,XQ,azo,nzo,szo,Lb,Bbe,lzo,izo,zQ,dzo,czo,mzo,yb,Ibe,fzo,gzo,QQ,hzo,uzo,pzo,xb,Nbe,_zo,bzo,WQ,vzo,Fzo,Tzo,$b,qbe,Mzo,Ezo,UQ,Czo,wzo,Azo,kb,jbe,Lzo,yzo,HQ,xzo,$zo,kzo,Sb,Dbe,Szo,Rzo,JQ,Pzo,Bzo,Izo,Rb,Gbe,Nzo,qzo,YQ,jzo,Dzo,Gzo,Pb,Obe,Ozo,Vzo,ZQ,Xzo,zzo,Qzo,Bb,Wzo,Vbe,Uzo,Hzo,Xbe,Jzo,Yzo,Ib,Goo,xd,Nb,zbe,f$,Zzo,Qbe,Kzo,Ooo,No,g$,eQo,$d,oQo,KQ,rQo,tQo,eW,aQo,nQo,sQo,h$,lQo,Wbe,iQo,dQo,cQo,Tt,u$,mQo,Ube,fQo,gQo,kd,hQo,Hbe,uQo,pQo,oW,_Qo,bQo,vQo,qb,FQo,oo,p$,TQo,Jbe,MQo,EQo,rn,CQo,Ybe,wQo,AQo,Zbe,LQo,yQo,Kbe,xQo,$Qo,kQo,Q,jb,eve,SQo,RQo,rW,PQo,BQo,IQo,Db,ove,NQo,qQo,tW,jQo,DQo,GQo,Gb,rve,OQo,VQo,aW,XQo,zQo,QQo,Ob,tve,WQo,UQo,nW,HQo,JQo,YQo,Vb,ave,ZQo,KQo,sW,eWo,oWo,rWo,Xb,nve,tWo,aWo,lW,nWo,sWo,lWo,zb,sve,iWo,dWo,iW,cWo,mWo,fWo,Qb,lve,gWo,hWo,dW,uWo,pWo,_Wo,Wb,ive,bWo,vWo,cW,FWo,TWo,MWo,Ub,dve,EWo,CWo,mW,wWo,AWo,LWo,Hb,cve,yWo,xWo,fW,$Wo,kWo,SWo,Jb,mve,RWo,PWo,gW,BWo,IWo,NWo,Yb,fve,qWo,jWo,hW,DWo,GWo,OWo,Zb,gve,VWo,XWo,uW,zWo,QWo,WWo,Kb,hve,UWo,HWo,pW,JWo,YWo,ZWo,ev,uve,KWo,eUo,_W,oUo,rUo,tUo,ov,pve,aUo,nUo,bW,sUo,lUo,iUo,rv,_ve,dUo,cUo,vW,mUo,fUo,gUo,tv,bve,hUo,uUo,FW,pUo,_Uo,bUo,av,vve,vUo,FUo,TW,TUo,MUo,EUo,nv,Fve,CUo,wUo,MW,AUo,LUo,yUo,sv,Tve,xUo,$Uo,EW,kUo,SUo,RUo,lv,Mve,PUo,BUo,CW,IUo,NUo,qUo,iv,Eve,jUo,DUo,wW,GUo,OUo,VUo,dv,Cve,XUo,zUo,AW,QUo,WUo,UUo,cv,wve,HUo,JUo,LW,YUo,ZUo,KUo,mv,Ave,eHo,oHo,yW,rHo,tHo,aHo,fv,Lve,nHo,sHo,xW,lHo,iHo,dHo,gv,yve,cHo,mHo,$W,fHo,gHo,hHo,hv,xve,uHo,pHo,kW,_Ho,bHo,vHo,uv,$ve,FHo,THo,SW,MHo,EHo,CHo,pv,kve,wHo,AHo,RW,LHo,yHo,xHo,_v,Sve,$Ho,kHo,PW,SHo,RHo,PHo,bv,Rve,BHo,IHo,BW,NHo,qHo,jHo,vv,Pve,DHo,GHo,IW,OHo,VHo,XHo,Fv,Bve,zHo,QHo,NW,WHo,UHo,HHo,Tv,Ive,JHo,YHo,qW,ZHo,KHo,eJo,Mv,Nve,oJo,rJo,jW,tJo,aJo,nJo,Ev,qve,sJo,lJo,DW,iJo,dJo,cJo,Cv,jve,mJo,fJo,GW,gJo,hJo,uJo,wv,Dve,pJo,_Jo,OW,bJo,vJo,FJo,Av,Gve,TJo,MJo,VW,EJo,CJo,wJo,Lv,AJo,Ove,LJo,yJo,Vve,xJo,$Jo,yv,Voo,Sd,xv,Xve,_$,kJo,zve,SJo,Xoo,qo,b$,RJo,Rd,PJo,XW,BJo,IJo,zW,NJo,qJo,jJo,v$,DJo,Qve,GJo,OJo,VJo,Mt,F$,XJo,Wve,zJo,QJo,Pd,WJo,Uve,UJo,HJo,QW,JJo,YJo,ZJo,$v,KJo,ro,T$,eYo,Hve,oYo,rYo,tn,tYo,Jve,aYo,nYo,Yve,sYo,lYo,Zve,iYo,dYo,cYo,J,kv,Kve,mYo,fYo,WW,gYo,hYo,uYo,Sv,eFe,pYo,_Yo,UW,bYo,vYo,FYo,Rv,oFe,TYo,MYo,HW,EYo,CYo,wYo,Pv,rFe,AYo,LYo,JW,yYo,xYo,$Yo,Bv,tFe,kYo,SYo,YW,RYo,PYo,BYo,Iv,aFe,IYo,NYo,ZW,qYo,jYo,DYo,Nv,nFe,GYo,OYo,KW,VYo,XYo,zYo,qv,sFe,QYo,WYo,eU,UYo,HYo,JYo,jv,lFe,YYo,ZYo,oU,KYo,eZo,oZo,Dv,iFe,rZo,tZo,rU,aZo,nZo,sZo,Gv,dFe,lZo,iZo,tU,dZo,cZo,mZo,Ov,cFe,fZo,gZo,aU,hZo,uZo,pZo,Vv,mFe,_Zo,bZo,nU,vZo,FZo,TZo,Xv,fFe,MZo,EZo,sU,CZo,wZo,AZo,zv,gFe,LZo,yZo,lU,xZo,$Zo,kZo,Qv,hFe,SZo,RZo,iU,PZo,BZo,IZo,Wv,uFe,NZo,qZo,dU,jZo,DZo,GZo,Uv,pFe,OZo,VZo,cU,XZo,zZo,QZo,Hv,_Fe,WZo,UZo,mU,HZo,JZo,YZo,Jv,bFe,ZZo,KZo,fU,eKo,oKo,rKo,Yv,vFe,tKo,aKo,gU,nKo,sKo,lKo,Zv,FFe,iKo,dKo,hU,cKo,mKo,fKo,Kv,TFe,gKo,hKo,uU,uKo,pKo,_Ko,eF,MFe,bKo,vKo,pU,FKo,TKo,MKo,oF,EFe,EKo,CKo,_U,wKo,AKo,LKo,rF,CFe,yKo,xKo,bU,$Ko,kKo,SKo,tF,wFe,RKo,PKo,vU,BKo,IKo,NKo,aF,AFe,qKo,jKo,FU,DKo,GKo,OKo,nF,LFe,VKo,XKo,TU,zKo,QKo,WKo,sF,yFe,UKo,HKo,MU,JKo,YKo,ZKo,lF,xFe,KKo,eer,EU,oer,rer,ter,iF,$Fe,aer,ner,CU,ser,ler,ier,dF,kFe,der,cer,wU,mer,fer,ger,cF,SFe,her,uer,AU,per,_er,ber,mF,RFe,ver,Fer,PFe,Ter,Mer,Eer,fF,BFe,Cer,wer,LU,Aer,Ler,yer,gF,IFe,xer,$er,yU,ker,Ser,Rer,hF,NFe,Per,Ber,xU,Ier,Ner,qer,uF,qFe,jer,Der,$U,Ger,Oer,Ver,pF,Xer,jFe,zer,Qer,DFe,Wer,Uer,_F,zoo,Bd,bF,GFe,M$,Her,OFe,Jer,Qoo,jo,E$,Yer,Id,Zer,kU,Ker,eor,SU,oor,ror,tor,C$,aor,VFe,nor,sor,lor,Et,w$,ior,XFe,dor,cor,Nd,mor,zFe,gor,hor,RU,uor,por,_or,vF,bor,to,A$,vor,QFe,For,Tor,an,Mor,WFe,Eor,Cor,UFe,wor,Aor,HFe,Lor,yor,xor,fe,FF,JFe,$or,kor,PU,Sor,Ror,Por,TF,YFe,Bor,Ior,BU,Nor,qor,jor,MF,ZFe,Dor,Gor,IU,Oor,Vor,Xor,EF,KFe,zor,Qor,NU,Wor,Uor,Hor,CF,eTe,Jor,Yor,qU,Zor,Kor,err,wF,oTe,orr,rrr,jU,trr,arr,nrr,AF,rTe,srr,lrr,DU,irr,drr,crr,LF,tTe,mrr,frr,GU,grr,hrr,urr,yF,aTe,prr,_rr,OU,brr,vrr,Frr,xF,nTe,Trr,Mrr,VU,Err,Crr,wrr,$F,sTe,Arr,Lrr,XU,yrr,xrr,$rr,kF,lTe,krr,Srr,zU,Rrr,Prr,Brr,SF,iTe,Irr,Nrr,QU,qrr,jrr,Drr,RF,dTe,Grr,Orr,WU,Vrr,Xrr,zrr,PF,cTe,Qrr,Wrr,UU,Urr,Hrr,Jrr,BF,mTe,Yrr,Zrr,HU,Krr,etr,otr,IF,fTe,rtr,ttr,JU,atr,ntr,str,NF,gTe,ltr,itr,YU,dtr,ctr,mtr,qF,hTe,ftr,gtr,ZU,htr,utr,ptr,jF,uTe,_tr,btr,KU,vtr,Ftr,Ttr,DF,Mtr,pTe,Etr,Ctr,_Te,wtr,Atr,GF,Woo,qd,OF,bTe,L$,Ltr,vTe,ytr,Uoo,Do,y$,xtr,jd,$tr,eH,ktr,Str,oH,Rtr,Ptr,Btr,x$,Itr,FTe,Ntr,qtr,jtr,Ct,$$,Dtr,TTe,Gtr,Otr,Dd,Vtr,MTe,Xtr,ztr,rH,Qtr,Wtr,Utr,VF,Htr,ao,k$,Jtr,ETe,Ytr,Ztr,nn,Ktr,CTe,ear,oar,wTe,rar,tar,ATe,aar,nar,sar,j,XF,LTe,lar,iar,tH,dar,car,mar,zF,yTe,far,gar,aH,har,uar,par,QF,xTe,_ar,bar,nH,Far,Tar,Mar,WF,$Te,Ear,Car,sH,war,Aar,Lar,UF,kTe,yar,xar,lH,$ar,kar,Sar,HF,STe,Rar,Par,iH,Bar,Iar,Nar,JF,RTe,qar,jar,dH,Dar,Gar,Oar,YF,PTe,Var,Xar,cH,zar,Qar,War,ZF,BTe,Uar,Har,mH,Jar,Yar,Zar,KF,ITe,Kar,enr,fH,onr,rnr,tnr,eT,NTe,anr,nnr,gH,snr,lnr,inr,oT,qTe,dnr,cnr,hH,mnr,fnr,gnr,rT,jTe,hnr,unr,uH,pnr,_nr,bnr,tT,DTe,vnr,Fnr,pH,Tnr,Mnr,Enr,aT,GTe,Cnr,wnr,_H,Anr,Lnr,ynr,nT,OTe,xnr,$nr,bH,knr,Snr,Rnr,sT,VTe,Pnr,Bnr,vH,Inr,Nnr,qnr,lT,XTe,jnr,Dnr,FH,Gnr,Onr,Vnr,iT,zTe,Xnr,znr,TH,Qnr,Wnr,Unr,dT,QTe,Hnr,Jnr,MH,Ynr,Znr,Knr,cT,WTe,esr,osr,EH,rsr,tsr,asr,mT,UTe,nsr,ssr,CH,lsr,isr,dsr,fT,HTe,csr,msr,wH,fsr,gsr,hsr,gT,JTe,usr,psr,AH,_sr,bsr,vsr,hT,YTe,Fsr,Tsr,LH,Msr,Esr,Csr,uT,ZTe,wsr,Asr,yH,Lsr,ysr,xsr,pT,KTe,$sr,ksr,xH,Ssr,Rsr,Psr,_T,eMe,Bsr,Isr,$H,Nsr,qsr,jsr,bT,oMe,Dsr,Gsr,kH,Osr,Vsr,Xsr,vT,rMe,zsr,Qsr,SH,Wsr,Usr,Hsr,FT,tMe,Jsr,Ysr,RH,Zsr,Ksr,elr,TT,aMe,olr,rlr,PH,tlr,alr,nlr,MT,nMe,slr,llr,BH,ilr,dlr,clr,ET,sMe,mlr,flr,IH,glr,hlr,ulr,CT,lMe,plr,_lr,NH,blr,vlr,Flr,wT,iMe,Tlr,Mlr,qH,Elr,Clr,wlr,AT,dMe,Alr,Llr,jH,ylr,xlr,$lr,LT,cMe,klr,Slr,DH,Rlr,Plr,Blr,yT,mMe,Ilr,Nlr,GH,qlr,jlr,Dlr,xT,fMe,Glr,Olr,OH,Vlr,Xlr,zlr,$T,gMe,Qlr,Wlr,VH,Ulr,Hlr,Jlr,kT,hMe,Ylr,Zlr,XH,Klr,eir,oir,ST,uMe,rir,tir,zH,air,nir,sir,RT,pMe,lir,iir,QH,dir,cir,mir,PT,_Me,fir,gir,WH,hir,uir,pir,BT,bMe,_ir,bir,UH,vir,Fir,Tir,IT,vMe,Mir,Eir,HH,Cir,wir,Air,NT,FMe,Lir,yir,JH,xir,$ir,kir,qT,TMe,Sir,Rir,YH,Pir,Bir,Iir,jT,MMe,Nir,qir,ZH,jir,Dir,Gir,DT,EMe,Oir,Vir,KH,Xir,zir,Qir,GT,CMe,Wir,Uir,eJ,Hir,Jir,Yir,OT,wMe,Zir,Kir,oJ,edr,odr,rdr,VT,AMe,tdr,adr,rJ,ndr,sdr,ldr,XT,LMe,idr,ddr,tJ,cdr,mdr,fdr,zT,gdr,yMe,hdr,udr,xMe,pdr,_dr,QT,Hoo,Gd,WT,$Me,S$,bdr,kMe,vdr,Joo,Go,R$,Fdr,Od,Tdr,aJ,Mdr,Edr,nJ,Cdr,wdr,Adr,P$,Ldr,SMe,ydr,xdr,$dr,wt,B$,kdr,RMe,Sdr,Rdr,Vd,Pdr,PMe,Bdr,Idr,sJ,Ndr,qdr,jdr,UT,Ddr,no,I$,Gdr,BMe,Odr,Vdr,sn,Xdr,IMe,zdr,Qdr,NMe,Wdr,Udr,qMe,Hdr,Jdr,Ydr,K,HT,jMe,Zdr,Kdr,lJ,ecr,ocr,rcr,JT,DMe,tcr,acr,iJ,ncr,scr,lcr,YT,GMe,icr,dcr,dJ,ccr,mcr,fcr,ZT,OMe,gcr,hcr,cJ,ucr,pcr,_cr,KT,VMe,bcr,vcr,mJ,Fcr,Tcr,Mcr,eM,XMe,Ecr,Ccr,fJ,wcr,Acr,Lcr,oM,zMe,ycr,xcr,gJ,$cr,kcr,Scr,rM,QMe,Rcr,Pcr,hJ,Bcr,Icr,Ncr,tM,WMe,qcr,jcr,uJ,Dcr,Gcr,Ocr,aM,UMe,Vcr,Xcr,pJ,zcr,Qcr,Wcr,nM,HMe,Ucr,Hcr,_J,Jcr,Ycr,Zcr,sM,JMe,Kcr,emr,bJ,omr,rmr,tmr,lM,YMe,amr,nmr,vJ,smr,lmr,imr,iM,ZMe,dmr,cmr,FJ,mmr,fmr,gmr,dM,KMe,hmr,umr,TJ,pmr,_mr,bmr,cM,eEe,vmr,Fmr,MJ,Tmr,Mmr,Emr,mM,oEe,Cmr,wmr,EJ,Amr,Lmr,ymr,fM,rEe,xmr,$mr,CJ,kmr,Smr,Rmr,gM,tEe,Pmr,Bmr,wJ,Imr,Nmr,qmr,hM,aEe,jmr,Dmr,AJ,Gmr,Omr,Vmr,uM,nEe,Xmr,zmr,LJ,Qmr,Wmr,Umr,pM,sEe,Hmr,Jmr,yJ,Ymr,Zmr,Kmr,_M,lEe,efr,ofr,xJ,rfr,tfr,afr,bM,iEe,nfr,sfr,$J,lfr,ifr,dfr,vM,dEe,cfr,mfr,kJ,ffr,gfr,hfr,FM,cEe,ufr,pfr,SJ,_fr,bfr,vfr,TM,mEe,Ffr,Tfr,RJ,Mfr,Efr,Cfr,MM,fEe,wfr,Afr,PJ,Lfr,yfr,xfr,EM,gEe,$fr,kfr,BJ,Sfr,Rfr,Pfr,CM,hEe,Bfr,Ifr,IJ,Nfr,qfr,jfr,wM,uEe,Dfr,Gfr,NJ,Ofr,Vfr,Xfr,AM,pEe,zfr,Qfr,qJ,Wfr,Ufr,Hfr,LM,Jfr,_Ee,Yfr,Zfr,bEe,Kfr,egr,yM,Yoo,Xd,xM,vEe,N$,ogr,FEe,rgr,Zoo,Oo,q$,tgr,zd,agr,jJ,ngr,sgr,DJ,lgr,igr,dgr,j$,cgr,TEe,mgr,fgr,ggr,At,D$,hgr,MEe,ugr,pgr,Qd,_gr,EEe,bgr,vgr,GJ,Fgr,Tgr,Mgr,$M,Egr,so,G$,Cgr,CEe,wgr,Agr,ln,Lgr,wEe,ygr,xgr,AEe,$gr,kgr,LEe,Sgr,Rgr,Pgr,Ue,kM,yEe,Bgr,Igr,OJ,Ngr,qgr,jgr,SM,xEe,Dgr,Ggr,VJ,Ogr,Vgr,Xgr,RM,$Ee,zgr,Qgr,XJ,Wgr,Ugr,Hgr,PM,kEe,Jgr,Ygr,zJ,Zgr,Kgr,ehr,BM,SEe,ohr,rhr,QJ,thr,ahr,nhr,IM,REe,shr,lhr,WJ,ihr,dhr,chr,NM,PEe,mhr,fhr,UJ,ghr,hhr,uhr,qM,phr,BEe,_hr,bhr,IEe,vhr,Fhr,jM,Koo,Wd,DM,NEe,O$,Thr,qEe,Mhr,ero,Vo,V$,Ehr,Ud,Chr,HJ,whr,Ahr,JJ,Lhr,yhr,xhr,X$,$hr,jEe,khr,Shr,Rhr,Lt,z$,Phr,DEe,Bhr,Ihr,Hd,Nhr,GEe,qhr,jhr,YJ,Dhr,Ghr,Ohr,GM,Vhr,lo,Q$,Xhr,OEe,zhr,Qhr,dn,Whr,VEe,Uhr,Hhr,XEe,Jhr,Yhr,zEe,Zhr,Khr,eur,H,OM,QEe,our,rur,ZJ,tur,aur,nur,VM,WEe,sur,lur,KJ,iur,dur,cur,XM,UEe,mur,fur,eY,gur,hur,uur,zM,HEe,pur,_ur,oY,bur,vur,Fur,QM,JEe,Tur,Mur,rY,Eur,Cur,wur,WM,YEe,Aur,Lur,tY,yur,xur,$ur,UM,ZEe,kur,Sur,aY,Rur,Pur,Bur,HM,KEe,Iur,Nur,nY,qur,jur,Dur,JM,e4e,Gur,Our,sY,Vur,Xur,zur,YM,o4e,Qur,Wur,lY,Uur,Hur,Jur,ZM,r4e,Yur,Zur,iY,Kur,epr,opr,KM,t4e,rpr,tpr,dY,apr,npr,spr,eE,a4e,lpr,ipr,cY,dpr,cpr,mpr,oE,n4e,fpr,gpr,mY,hpr,upr,ppr,rE,s4e,_pr,bpr,fY,vpr,Fpr,Tpr,tE,l4e,Mpr,Epr,gY,Cpr,wpr,Apr,aE,i4e,Lpr,ypr,hY,xpr,$pr,kpr,nE,d4e,Spr,Rpr,uY,Ppr,Bpr,Ipr,sE,c4e,Npr,qpr,pY,jpr,Dpr,Gpr,lE,m4e,Opr,Vpr,_Y,Xpr,zpr,Qpr,iE,f4e,Wpr,Upr,bY,Hpr,Jpr,Ypr,dE,g4e,Zpr,Kpr,vY,e_r,o_r,r_r,cE,h4e,t_r,a_r,FY,n_r,s_r,l_r,mE,u4e,i_r,d_r,TY,c_r,m_r,f_r,fE,p4e,g_r,h_r,MY,u_r,p_r,__r,gE,_4e,b_r,v_r,EY,F_r,T_r,M_r,hE,b4e,E_r,C_r,CY,w_r,A_r,L_r,uE,v4e,y_r,x_r,wY,$_r,k_r,S_r,pE,F4e,R_r,P_r,AY,B_r,I_r,N_r,_E,T4e,q_r,j_r,LY,D_r,G_r,O_r,bE,M4e,V_r,X_r,yY,z_r,Q_r,W_r,vE,E4e,U_r,H_r,xY,J_r,Y_r,Z_r,FE,C4e,K_r,e1r,$Y,o1r,r1r,t1r,TE,w4e,a1r,n1r,kY,s1r,l1r,i1r,ME,A4e,d1r,c1r,SY,m1r,f1r,g1r,EE,L4e,h1r,u1r,RY,p1r,_1r,b1r,CE,y4e,v1r,F1r,PY,T1r,M1r,E1r,wE,x4e,C1r,w1r,BY,A1r,L1r,y1r,AE,$4e,x1r,$1r,IY,k1r,S1r,R1r,LE,k4e,P1r,B1r,NY,I1r,N1r,q1r,yE,j1r,S4e,D1r,G1r,R4e,O1r,V1r,xE,oro,Jd,$E,P4e,W$,X1r,B4e,z1r,rro,Xo,U$,Q1r,Yd,W1r,qY,U1r,H1r,jY,J1r,Y1r,Z1r,H$,K1r,I4e,e2r,o2r,r2r,yt,J$,t2r,N4e,a2r,n2r,Zd,s2r,q4e,l2r,i2r,DY,d2r,c2r,m2r,kE,f2r,io,Y$,g2r,j4e,h2r,u2r,cn,p2r,D4e,_2r,b2r,G4e,v2r,F2r,O4e,T2r,M2r,E2r,O,SE,V4e,C2r,w2r,GY,A2r,L2r,y2r,RE,X4e,x2r,$2r,OY,k2r,S2r,R2r,PE,z4e,P2r,B2r,VY,I2r,N2r,q2r,BE,Q4e,j2r,D2r,XY,G2r,O2r,V2r,IE,W4e,X2r,z2r,zY,Q2r,W2r,U2r,NE,U4e,H2r,J2r,QY,Y2r,Z2r,K2r,qE,H4e,ebr,obr,WY,rbr,tbr,abr,jE,J4e,nbr,sbr,UY,lbr,ibr,dbr,DE,Y4e,cbr,mbr,HY,fbr,gbr,hbr,GE,Z4e,ubr,pbr,JY,_br,bbr,vbr,OE,K4e,Fbr,Tbr,YY,Mbr,Ebr,Cbr,VE,eCe,wbr,Abr,ZY,Lbr,ybr,xbr,XE,oCe,$br,kbr,KY,Sbr,Rbr,Pbr,zE,rCe,Bbr,Ibr,eZ,Nbr,qbr,jbr,QE,tCe,Dbr,Gbr,oZ,Obr,Vbr,Xbr,WE,aCe,zbr,Qbr,rZ,Wbr,Ubr,Hbr,UE,nCe,Jbr,Ybr,tZ,Zbr,Kbr,evr,HE,sCe,ovr,rvr,aZ,tvr,avr,nvr,JE,lCe,svr,lvr,nZ,ivr,dvr,cvr,YE,iCe,mvr,fvr,sZ,gvr,hvr,uvr,ZE,dCe,pvr,_vr,lZ,bvr,vvr,Fvr,KE,cCe,Tvr,Mvr,iZ,Evr,Cvr,wvr,e4,mCe,Avr,Lvr,dZ,yvr,xvr,$vr,o4,fCe,kvr,Svr,cZ,Rvr,Pvr,Bvr,r4,gCe,Ivr,Nvr,mZ,qvr,jvr,Dvr,t4,hCe,Gvr,Ovr,fZ,Vvr,Xvr,zvr,a4,uCe,Qvr,Wvr,gZ,Uvr,Hvr,Jvr,n4,pCe,Yvr,Zvr,hZ,Kvr,eFr,oFr,s4,_Ce,rFr,tFr,uZ,aFr,nFr,sFr,l4,bCe,lFr,iFr,pZ,dFr,cFr,mFr,i4,vCe,fFr,gFr,_Z,hFr,uFr,pFr,d4,FCe,_Fr,bFr,bZ,vFr,FFr,TFr,c4,TCe,MFr,EFr,vZ,CFr,wFr,AFr,m4,MCe,LFr,yFr,FZ,xFr,$Fr,kFr,f4,ECe,SFr,RFr,TZ,PFr,BFr,IFr,g4,CCe,NFr,qFr,MZ,jFr,DFr,GFr,h4,wCe,OFr,VFr,EZ,XFr,zFr,QFr,u4,ACe,WFr,UFr,CZ,HFr,JFr,YFr,p4,LCe,ZFr,KFr,wZ,eTr,oTr,rTr,_4,yCe,tTr,aTr,AZ,nTr,sTr,lTr,b4,xCe,iTr,dTr,LZ,cTr,mTr,fTr,v4,$Ce,gTr,hTr,yZ,uTr,pTr,_Tr,F4,kCe,bTr,vTr,xZ,FTr,TTr,MTr,T4,SCe,ETr,CTr,$Z,wTr,ATr,LTr,M4,RCe,yTr,xTr,kZ,$Tr,kTr,STr,E4,PCe,RTr,PTr,SZ,BTr,ITr,NTr,C4,BCe,qTr,jTr,RZ,DTr,GTr,OTr,w4,VTr,ICe,XTr,zTr,NCe,QTr,WTr,A4,tro,Kd,L4,qCe,Z$,UTr,jCe,HTr,aro,zo,K$,JTr,ec,YTr,PZ,ZTr,KTr,BZ,eMr,oMr,rMr,ek,tMr,DCe,aMr,nMr,sMr,xt,ok,lMr,GCe,iMr,dMr,oc,cMr,OCe,mMr,fMr,IZ,gMr,hMr,uMr,y4,pMr,co,rk,_Mr,VCe,bMr,vMr,mn,FMr,XCe,TMr,MMr,zCe,EMr,CMr,QCe,wMr,AMr,LMr,WCe,x4,UCe,yMr,xMr,NZ,$Mr,kMr,SMr,$4,RMr,HCe,PMr,BMr,JCe,IMr,NMr,k4,nro,rc,S4,YCe,tk,qMr,ZCe,jMr,sro,Qo,ak,DMr,tc,GMr,qZ,OMr,VMr,jZ,XMr,zMr,QMr,nk,WMr,KCe,UMr,HMr,JMr,$t,sk,YMr,e3e,ZMr,KMr,ac,eEr,o3e,oEr,rEr,DZ,tEr,aEr,nEr,R4,sEr,mo,lk,lEr,r3e,iEr,dEr,fn,cEr,t3e,mEr,fEr,a3e,gEr,hEr,n3e,uEr,pEr,_Er,nc,P4,s3e,bEr,vEr,GZ,FEr,TEr,MEr,B4,l3e,EEr,CEr,OZ,wEr,AEr,LEr,I4,i3e,yEr,xEr,VZ,$Er,kEr,SEr,N4,REr,d3e,PEr,BEr,c3e,IEr,NEr,q4,lro,sc,j4,m3e,ik,qEr,f3e,jEr,iro,Wo,dk,DEr,lc,GEr,XZ,OEr,VEr,zZ,XEr,zEr,QEr,ck,WEr,g3e,UEr,HEr,JEr,kt,mk,YEr,h3e,ZEr,KEr,ic,e4r,u3e,o4r,r4r,QZ,t4r,a4r,n4r,D4,s4r,fo,fk,l4r,p3e,i4r,d4r,gn,c4r,_3e,m4r,f4r,b3e,g4r,h4r,v3e,u4r,p4r,_4r,be,G4,F3e,b4r,v4r,WZ,F4r,T4r,M4r,O4,T3e,E4r,C4r,UZ,w4r,A4r,L4r,V4,M3e,y4r,x4r,HZ,$4r,k4r,S4r,X4,E3e,R4r,P4r,JZ,B4r,I4r,N4r,El,C3e,q4r,j4r,YZ,D4r,G4r,ZZ,O4r,V4r,X4r,z4,w3e,z4r,Q4r,KZ,W4r,U4r,H4r,Cl,A3e,J4r,Y4r,eK,Z4r,K4r,oK,eCr,oCr,rCr,Q4,L3e,tCr,aCr,rK,nCr,sCr,lCr,St,y3e,iCr,dCr,tK,cCr,mCr,aK,fCr,gCr,nK,hCr,uCr,pCr,W4,x3e,_Cr,bCr,sK,vCr,FCr,TCr,U4,$3e,MCr,ECr,lK,CCr,wCr,ACr,H4,k3e,LCr,yCr,iK,xCr,$Cr,kCr,J4,S3e,SCr,RCr,dK,PCr,BCr,ICr,Y4,R3e,NCr,qCr,cK,jCr,DCr,GCr,Z4,P3e,OCr,VCr,mK,XCr,zCr,QCr,K4,B3e,WCr,UCr,fK,HCr,JCr,YCr,eC,I3e,ZCr,KCr,gK,e3r,o3r,r3r,oC,N3e,t3r,a3r,hK,n3r,s3r,l3r,rC,i3r,q3e,d3r,c3r,j3e,m3r,f3r,tC,dro,dc,aC,D3e,gk,g3r,G3e,h3r,cro,Uo,hk,u3r,cc,p3r,uK,_3r,b3r,pK,v3r,F3r,T3r,uk,M3r,O3e,E3r,C3r,w3r,Rt,pk,A3r,V3e,L3r,y3r,mc,x3r,X3e,$3r,k3r,_K,S3r,R3r,P3r,nC,B3r,go,_k,I3r,z3e,N3r,q3r,hn,j3r,Q3e,D3r,G3r,W3e,O3r,V3r,U3e,X3r,z3r,Q3r,H3e,sC,J3e,W3r,U3r,bK,H3r,J3r,Y3r,lC,Z3r,Y3e,K3r,e5r,Z3e,o5r,r5r,iC,mro,fc,dC,K3e,bk,t5r,e5e,a5r,fro,Ho,vk,n5r,gc,s5r,vK,l5r,i5r,FK,d5r,c5r,m5r,Fk,f5r,o5e,g5r,h5r,u5r,Pt,Tk,p5r,r5e,_5r,b5r,hc,v5r,t5e,F5r,T5r,TK,M5r,E5r,C5r,cC,w5r,ho,Mk,A5r,a5e,L5r,y5r,un,x5r,n5e,$5r,k5r,s5e,S5r,R5r,l5e,P5r,B5r,I5r,i5e,mC,d5e,N5r,q5r,MK,j5r,D5r,G5r,fC,O5r,c5e,V5r,X5r,m5e,z5r,Q5r,gC,gro,uc,hC,f5e,Ek,W5r,g5e,U5r,hro,Jo,Ck,H5r,pc,J5r,EK,Y5r,Z5r,CK,K5r,e0r,o0r,wk,r0r,h5e,t0r,a0r,n0r,Bt,Ak,s0r,u5e,l0r,i0r,_c,d0r,p5e,c0r,m0r,wK,f0r,g0r,h0r,uC,u0r,uo,Lk,p0r,_5e,_0r,b0r,pn,v0r,b5e,F0r,T0r,v5e,M0r,E0r,F5e,C0r,w0r,A0r,T5e,pC,M5e,L0r,y0r,AK,x0r,$0r,k0r,_C,S0r,E5e,R0r,P0r,C5e,B0r,I0r,bC,uro,bc,vC,w5e,yk,N0r,A5e,q0r,pro,Yo,xk,j0r,vc,D0r,LK,G0r,O0r,yK,V0r,X0r,z0r,$k,Q0r,L5e,W0r,U0r,H0r,It,kk,J0r,y5e,Y0r,Z0r,Fc,K0r,x5e,ewr,owr,xK,rwr,twr,awr,FC,nwr,po,Sk,swr,$5e,lwr,iwr,_n,dwr,k5e,cwr,mwr,S5e,fwr,gwr,R5e,hwr,uwr,pwr,Be,TC,P5e,_wr,bwr,$K,vwr,Fwr,Twr,MC,B5e,Mwr,Ewr,kK,Cwr,wwr,Awr,EC,I5e,Lwr,ywr,SK,xwr,$wr,kwr,CC,N5e,Swr,Rwr,RK,Pwr,Bwr,Iwr,wC,q5e,Nwr,qwr,PK,jwr,Dwr,Gwr,AC,j5e,Owr,Vwr,BK,Xwr,zwr,Qwr,LC,D5e,Wwr,Uwr,IK,Hwr,Jwr,Ywr,yC,G5e,Zwr,Kwr,NK,eAr,oAr,rAr,xC,O5e,tAr,aAr,qK,nAr,sAr,lAr,$C,iAr,V5e,dAr,cAr,X5e,mAr,fAr,kC,_ro,Tc,SC,z5e,Rk,gAr,Q5e,hAr,bro,Zo,Pk,uAr,Mc,pAr,jK,_Ar,bAr,DK,vAr,FAr,TAr,Bk,MAr,W5e,EAr,CAr,wAr,Nt,Ik,AAr,U5e,LAr,yAr,Ec,xAr,H5e,$Ar,kAr,GK,SAr,RAr,PAr,RC,BAr,_o,Nk,IAr,J5e,NAr,qAr,bn,jAr,Y5e,DAr,GAr,Z5e,OAr,VAr,K5e,XAr,zAr,QAr,gt,PC,e0e,WAr,UAr,OK,HAr,JAr,YAr,BC,o0e,ZAr,KAr,VK,e6r,o6r,r6r,IC,r0e,t6r,a6r,XK,n6r,s6r,l6r,NC,t0e,i6r,d6r,zK,c6r,m6r,f6r,qC,a0e,g6r,h6r,QK,u6r,p6r,_6r,jC,b6r,n0e,v6r,F6r,s0e,T6r,M6r,DC,vro,Cc,GC,l0e,qk,E6r,i0e,C6r,Fro,Ko,jk,w6r,wc,A6r,WK,L6r,y6r,UK,x6r,$6r,k6r,Dk,S6r,d0e,R6r,P6r,B6r,qt,Gk,I6r,c0e,N6r,q6r,Ac,j6r,m0e,D6r,G6r,HK,O6r,V6r,X6r,OC,z6r,bo,Ok,Q6r,f0e,W6r,U6r,vn,H6r,g0e,J6r,Y6r,h0e,Z6r,K6r,u0e,e7r,o7r,r7r,Le,VC,p0e,t7r,a7r,JK,n7r,s7r,l7r,XC,_0e,i7r,d7r,YK,c7r,m7r,f7r,zC,b0e,g7r,h7r,ZK,u7r,p7r,_7r,QC,v0e,b7r,v7r,KK,F7r,T7r,M7r,WC,F0e,E7r,C7r,eee,w7r,A7r,L7r,UC,T0e,y7r,x7r,oee,$7r,k7r,S7r,HC,M0e,R7r,P7r,ree,B7r,I7r,N7r,JC,E0e,q7r,j7r,tee,D7r,G7r,O7r,YC,C0e,V7r,X7r,aee,z7r,Q7r,W7r,ZC,w0e,U7r,H7r,nee,J7r,Y7r,Z7r,KC,K7r,A0e,eLr,oLr,L0e,rLr,tLr,e3,Tro,Lc,o3,y0e,Vk,aLr,x0e,nLr,Mro,er,Xk,sLr,yc,lLr,see,iLr,dLr,lee,cLr,mLr,fLr,zk,gLr,$0e,hLr,uLr,pLr,jt,Qk,_Lr,k0e,bLr,vLr,xc,FLr,S0e,TLr,MLr,iee,ELr,CLr,wLr,r3,ALr,vo,Wk,LLr,R0e,yLr,xLr,Fn,$Lr,P0e,kLr,SLr,B0e,RLr,PLr,I0e,BLr,ILr,NLr,$c,t3,N0e,qLr,jLr,dee,DLr,GLr,OLr,a3,q0e,VLr,XLr,cee,zLr,QLr,WLr,n3,j0e,ULr,HLr,mee,JLr,YLr,ZLr,s3,KLr,D0e,e8r,o8r,G0e,r8r,t8r,l3,Ero,kc,i3,O0e,Uk,a8r,V0e,n8r,Cro,or,Hk,s8r,Sc,l8r,fee,i8r,d8r,gee,c8r,m8r,f8r,Jk,g8r,X0e,h8r,u8r,p8r,Dt,Yk,_8r,z0e,b8r,v8r,Rc,F8r,Q0e,T8r,M8r,hee,E8r,C8r,w8r,d3,A8r,Fo,Zk,L8r,W0e,y8r,x8r,Tn,$8r,U0e,k8r,S8r,H0e,R8r,P8r,J0e,B8r,I8r,N8r,ht,c3,Y0e,q8r,j8r,uee,D8r,G8r,O8r,m3,Z0e,V8r,X8r,pee,z8r,Q8r,W8r,f3,K0e,U8r,H8r,_ee,J8r,Y8r,Z8r,g3,ewe,K8r,eyr,bee,oyr,ryr,tyr,h3,owe,ayr,nyr,vee,syr,lyr,iyr,u3,dyr,rwe,cyr,myr,twe,fyr,gyr,p3,wro,Pc,_3,awe,Kk,hyr,nwe,uyr,Aro,rr,eS,pyr,Bc,_yr,Fee,byr,vyr,Tee,Fyr,Tyr,Myr,oS,Eyr,swe,Cyr,wyr,Ayr,Gt,rS,Lyr,lwe,yyr,xyr,Ic,$yr,iwe,kyr,Syr,Mee,Ryr,Pyr,Byr,b3,Iyr,To,tS,Nyr,dwe,qyr,jyr,Mn,Dyr,cwe,Gyr,Oyr,mwe,Vyr,Xyr,fwe,zyr,Qyr,Wyr,En,v3,gwe,Uyr,Hyr,Eee,Jyr,Yyr,Zyr,F3,hwe,Kyr,e9r,Cee,o9r,r9r,t9r,T3,uwe,a9r,n9r,wee,s9r,l9r,i9r,M3,pwe,d9r,c9r,Aee,m9r,f9r,g9r,E3,h9r,_we,u9r,p9r,bwe,_9r,b9r,C3,Lro,Nc,w3,vwe,aS,v9r,Fwe,F9r,yro,tr,nS,T9r,qc,M9r,Lee,E9r,C9r,yee,w9r,A9r,L9r,sS,y9r,Twe,x9r,$9r,k9r,Ot,lS,S9r,Mwe,R9r,P9r,jc,B9r,Ewe,I9r,N9r,xee,q9r,j9r,D9r,A3,G9r,Mo,iS,O9r,Cwe,V9r,X9r,Cn,z9r,wwe,Q9r,W9r,Awe,U9r,H9r,Lwe,J9r,Y9r,Z9r,wn,L3,ywe,K9r,exr,$ee,oxr,rxr,txr,y3,xwe,axr,nxr,kee,sxr,lxr,ixr,x3,$we,dxr,cxr,See,mxr,fxr,gxr,$3,kwe,hxr,uxr,Ree,pxr,_xr,bxr,k3,vxr,Swe,Fxr,Txr,Rwe,Mxr,Exr,S3,xro,Dc,R3,Pwe,dS,Cxr,Bwe,wxr,$ro,ar,cS,Axr,Gc,Lxr,Pee,yxr,xxr,Bee,$xr,kxr,Sxr,mS,Rxr,Iwe,Pxr,Bxr,Ixr,Vt,fS,Nxr,Nwe,qxr,jxr,Oc,Dxr,qwe,Gxr,Oxr,Iee,Vxr,Xxr,zxr,P3,Qxr,Eo,gS,Wxr,jwe,Uxr,Hxr,An,Jxr,Dwe,Yxr,Zxr,Gwe,Kxr,e$r,Owe,o$r,r$r,t$r,Vwe,B3,Xwe,a$r,n$r,Nee,s$r,l$r,i$r,I3,d$r,zwe,c$r,m$r,Qwe,f$r,g$r,N3,kro,Vc,q3,Wwe,hS,h$r,Uwe,u$r,Sro,nr,uS,p$r,Xc,_$r,qee,b$r,v$r,jee,F$r,T$r,M$r,pS,E$r,Hwe,C$r,w$r,A$r,Xt,_S,L$r,Jwe,y$r,x$r,zc,$$r,Ywe,k$r,S$r,Dee,R$r,P$r,B$r,j3,I$r,Co,bS,N$r,Zwe,q$r,j$r,Ln,D$r,Kwe,G$r,O$r,eAe,V$r,X$r,oAe,z$r,Q$r,W$r,ut,D3,rAe,U$r,H$r,Gee,J$r,Y$r,Z$r,G3,tAe,K$r,ekr,Oee,okr,rkr,tkr,O3,aAe,akr,nkr,Vee,skr,lkr,ikr,V3,nAe,dkr,ckr,Xee,mkr,fkr,gkr,X3,sAe,hkr,ukr,zee,pkr,_kr,bkr,z3,vkr,lAe,Fkr,Tkr,iAe,Mkr,Ekr,Q3,Rro,Qc,W3,dAe,vS,Ckr,cAe,wkr,Pro,sr,FS,Akr,Wc,Lkr,Qee,ykr,xkr,Wee,$kr,kkr,Skr,TS,Rkr,mAe,Pkr,Bkr,Ikr,zt,MS,Nkr,fAe,qkr,jkr,Uc,Dkr,gAe,Gkr,Okr,Uee,Vkr,Xkr,zkr,U3,Qkr,wo,ES,Wkr,hAe,Ukr,Hkr,yn,Jkr,uAe,Ykr,Zkr,pAe,Kkr,eSr,_Ae,oSr,rSr,tSr,bAe,H3,vAe,aSr,nSr,Hee,sSr,lSr,iSr,J3,dSr,FAe,cSr,mSr,TAe,fSr,gSr,Y3,Bro,Hc,Z3,MAe,CS,hSr,EAe,uSr,Iro,lr,wS,pSr,Jc,_Sr,Jee,bSr,vSr,Yee,FSr,TSr,MSr,AS,ESr,CAe,CSr,wSr,ASr,Qt,LS,LSr,wAe,ySr,xSr,Yc,$Sr,AAe,kSr,SSr,Zee,RSr,PSr,BSr,K3,ISr,Ao,yS,NSr,LAe,qSr,jSr,xn,DSr,yAe,GSr,OSr,xAe,VSr,XSr,$Ae,zSr,QSr,WSr,kAe,e5,SAe,USr,HSr,Kee,JSr,YSr,ZSr,o5,KSr,RAe,eRr,oRr,PAe,rRr,tRr,r5,Nro,Zc,t5,BAe,xS,aRr,IAe,nRr,qro,ir,$S,sRr,Kc,lRr,eoe,iRr,dRr,ooe,cRr,mRr,fRr,kS,gRr,NAe,hRr,uRr,pRr,Wt,SS,_Rr,qAe,bRr,vRr,em,FRr,jAe,TRr,MRr,roe,ERr,CRr,wRr,a5,ARr,qr,RS,LRr,DAe,yRr,xRr,$n,$Rr,GAe,kRr,SRr,OAe,RRr,PRr,VAe,BRr,IRr,NRr,P,n5,XAe,qRr,jRr,toe,DRr,GRr,ORr,s5,zAe,VRr,XRr,aoe,zRr,QRr,WRr,l5,QAe,URr,HRr,noe,JRr,YRr,ZRr,i5,WAe,KRr,ePr,soe,oPr,rPr,tPr,d5,UAe,aPr,nPr,loe,sPr,lPr,iPr,c5,HAe,dPr,cPr,ioe,mPr,fPr,gPr,m5,JAe,hPr,uPr,doe,pPr,_Pr,bPr,f5,YAe,vPr,FPr,coe,TPr,MPr,EPr,g5,ZAe,CPr,wPr,moe,APr,LPr,yPr,h5,KAe,xPr,$Pr,foe,kPr,SPr,RPr,u5,e6e,PPr,BPr,goe,IPr,NPr,qPr,p5,o6e,jPr,DPr,hoe,GPr,OPr,VPr,_5,r6e,XPr,zPr,uoe,QPr,WPr,UPr,b5,t6e,HPr,JPr,poe,YPr,ZPr,KPr,v5,a6e,eBr,oBr,_oe,rBr,tBr,aBr,F5,n6e,nBr,sBr,boe,lBr,iBr,dBr,T5,s6e,cBr,mBr,voe,fBr,gBr,hBr,M5,l6e,uBr,pBr,Foe,_Br,bBr,vBr,E5,i6e,FBr,TBr,Toe,MBr,EBr,CBr,wl,d6e,wBr,ABr,Moe,LBr,yBr,Eoe,xBr,$Br,kBr,C5,c6e,SBr,RBr,Coe,PBr,BBr,IBr,w5,m6e,NBr,qBr,woe,jBr,DBr,GBr,A5,f6e,OBr,VBr,Aoe,XBr,zBr,QBr,L5,g6e,WBr,UBr,Loe,HBr,JBr,YBr,y5,h6e,ZBr,KBr,yoe,eIr,oIr,rIr,x5,u6e,tIr,aIr,xoe,nIr,sIr,lIr,$5,p6e,iIr,dIr,$oe,cIr,mIr,fIr,k5,_6e,gIr,hIr,koe,uIr,pIr,_Ir,S5,b6e,bIr,vIr,Soe,FIr,TIr,MIr,R5,v6e,EIr,CIr,Roe,wIr,AIr,LIr,P5,F6e,yIr,xIr,Poe,$Ir,kIr,SIr,B5,T6e,RIr,PIr,Boe,BIr,IIr,NIr,I5,M6e,qIr,jIr,Ioe,DIr,GIr,OIr,N5,E6e,VIr,XIr,Noe,zIr,QIr,WIr,q5,C6e,UIr,HIr,qoe,JIr,YIr,ZIr,j5,w6e,KIr,eNr,joe,oNr,rNr,tNr,D5,A6e,aNr,nNr,Doe,sNr,lNr,iNr,G5,L6e,dNr,cNr,Goe,mNr,fNr,gNr,O5,y6e,hNr,uNr,Ooe,pNr,_Nr,bNr,V5,x6e,vNr,FNr,Voe,TNr,MNr,ENr,X5,$6e,CNr,wNr,Xoe,ANr,LNr,yNr,z5,k6e,xNr,$Nr,zoe,kNr,SNr,RNr,Q5,S6e,PNr,BNr,Qoe,INr,NNr,qNr,W5,R6e,jNr,DNr,Woe,GNr,ONr,VNr,U5,P6e,XNr,zNr,Uoe,QNr,WNr,UNr,H5,B6e,HNr,JNr,Hoe,YNr,ZNr,KNr,J5,I6e,eqr,oqr,Joe,rqr,tqr,aqr,Y5,N6e,nqr,sqr,Yoe,lqr,iqr,dqr,Z5,q6e,cqr,mqr,Zoe,fqr,gqr,hqr,K5,j6e,uqr,pqr,Koe,_qr,bqr,vqr,e0,D6e,Fqr,Tqr,ere,Mqr,Eqr,Cqr,o0,G6e,wqr,Aqr,ore,Lqr,yqr,xqr,r0,O6e,$qr,kqr,rre,Sqr,Rqr,Pqr,t0,V6e,Bqr,Iqr,tre,Nqr,qqr,jqr,a0,X6e,Dqr,Gqr,are,Oqr,Vqr,Xqr,n0,z6e,zqr,Qqr,nre,Wqr,Uqr,Hqr,s0,Q6e,Jqr,Yqr,sre,Zqr,Kqr,ejr,l0,jro,om,i0,W6e,PS,ojr,U6e,rjr,Dro,dr,BS,tjr,rm,ajr,lre,njr,sjr,ire,ljr,ijr,djr,IS,cjr,H6e,mjr,fjr,gjr,Ut,NS,hjr,J6e,ujr,pjr,tm,_jr,Y6e,bjr,vjr,dre,Fjr,Tjr,Mjr,d0,Ejr,jr,qS,Cjr,Z6e,wjr,Ajr,kn,Ljr,K6e,yjr,xjr,e7e,$jr,kjr,o7e,Sjr,Rjr,Pjr,le,c0,r7e,Bjr,Ijr,cre,Njr,qjr,jjr,m0,t7e,Djr,Gjr,mre,Ojr,Vjr,Xjr,f0,a7e,zjr,Qjr,fre,Wjr,Ujr,Hjr,g0,n7e,Jjr,Yjr,gre,Zjr,Kjr,eDr,h0,s7e,oDr,rDr,hre,tDr,aDr,nDr,u0,l7e,sDr,lDr,ure,iDr,dDr,cDr,p0,i7e,mDr,fDr,pre,gDr,hDr,uDr,_0,d7e,pDr,_Dr,_re,bDr,vDr,FDr,b0,c7e,TDr,MDr,bre,EDr,CDr,wDr,v0,m7e,ADr,LDr,vre,yDr,xDr,$Dr,F0,f7e,kDr,SDr,Fre,RDr,PDr,BDr,T0,g7e,IDr,NDr,Tre,qDr,jDr,DDr,M0,h7e,GDr,ODr,Mre,VDr,XDr,zDr,E0,u7e,QDr,WDr,Ere,UDr,HDr,JDr,C0,p7e,YDr,ZDr,Cre,KDr,eGr,oGr,w0,_7e,rGr,tGr,wre,aGr,nGr,sGr,A0,b7e,lGr,iGr,Are,dGr,cGr,mGr,L0,v7e,fGr,gGr,Lre,hGr,uGr,pGr,y0,F7e,_Gr,bGr,yre,vGr,FGr,TGr,x0,T7e,MGr,EGr,xre,CGr,wGr,AGr,$0,M7e,LGr,yGr,$re,xGr,$Gr,kGr,k0,E7e,SGr,RGr,kre,PGr,BGr,IGr,S0,C7e,NGr,qGr,Sre,jGr,DGr,GGr,R0,Gro,am,P0,w7e,jS,OGr,A7e,VGr,Oro,cr,DS,XGr,nm,zGr,Rre,QGr,WGr,Pre,UGr,HGr,JGr,GS,YGr,L7e,ZGr,KGr,eOr,Ht,OS,oOr,y7e,rOr,tOr,sm,aOr,x7e,nOr,sOr,Bre,lOr,iOr,dOr,B0,cOr,Dr,VS,mOr,$7e,fOr,gOr,Sn,hOr,k7e,uOr,pOr,S7e,_Or,bOr,R7e,vOr,FOr,TOr,Me,I0,P7e,MOr,EOr,Ire,COr,wOr,AOr,N0,B7e,LOr,yOr,Nre,xOr,$Or,kOr,q0,I7e,SOr,ROr,qre,POr,BOr,IOr,j0,N7e,NOr,qOr,jre,jOr,DOr,GOr,D0,q7e,OOr,VOr,Dre,XOr,zOr,QOr,G0,j7e,WOr,UOr,Gre,HOr,JOr,YOr,O0,D7e,ZOr,KOr,Ore,eVr,oVr,rVr,V0,G7e,tVr,aVr,Vre,nVr,sVr,lVr,X0,O7e,iVr,dVr,Xre,cVr,mVr,fVr,z0,V7e,gVr,hVr,zre,uVr,pVr,_Vr,Q0,X7e,bVr,vVr,Qre,FVr,TVr,MVr,W0,z7e,EVr,CVr,Wre,wVr,AVr,LVr,U0,Q7e,yVr,xVr,Ure,$Vr,kVr,SVr,H0,W7e,RVr,PVr,Hre,BVr,IVr,NVr,J0,Vro,lm,Y0,U7e,XS,qVr,H7e,jVr,Xro,mr,zS,DVr,im,GVr,Jre,OVr,VVr,Yre,XVr,zVr,QVr,QS,WVr,J7e,UVr,HVr,JVr,Jt,WS,YVr,Y7e,ZVr,KVr,dm,eXr,Z7e,oXr,rXr,Zre,tXr,aXr,nXr,Z0,sXr,Gr,US,lXr,K7e,iXr,dXr,Rn,cXr,eLe,mXr,fXr,oLe,gXr,hXr,rLe,uXr,pXr,_Xr,ye,K0,tLe,bXr,vXr,Kre,FXr,TXr,MXr,ew,aLe,EXr,CXr,ete,wXr,AXr,LXr,ow,nLe,yXr,xXr,ote,$Xr,kXr,SXr,Al,sLe,RXr,PXr,rte,BXr,IXr,tte,NXr,qXr,jXr,rw,lLe,DXr,GXr,ate,OXr,VXr,XXr,tw,iLe,zXr,QXr,nte,WXr,UXr,HXr,aw,dLe,JXr,YXr,ste,ZXr,KXr,ezr,nw,cLe,ozr,rzr,lte,tzr,azr,nzr,sw,mLe,szr,lzr,ite,izr,dzr,czr,lw,fLe,mzr,fzr,dte,gzr,hzr,uzr,iw,zro,cm,dw,gLe,HS,pzr,hLe,_zr,Qro,fr,JS,bzr,mm,vzr,cte,Fzr,Tzr,mte,Mzr,Ezr,Czr,YS,wzr,uLe,Azr,Lzr,yzr,Yt,ZS,xzr,pLe,$zr,kzr,fm,Szr,_Le,Rzr,Pzr,fte,Bzr,Izr,Nzr,cw,qzr,Or,KS,jzr,bLe,Dzr,Gzr,Pn,Ozr,vLe,Vzr,Xzr,FLe,zzr,Qzr,TLe,Wzr,Uzr,Hzr,gm,mw,MLe,Jzr,Yzr,gte,Zzr,Kzr,eQr,fw,ELe,oQr,rQr,hte,tQr,aQr,nQr,gw,CLe,sQr,lQr,ute,iQr,dQr,cQr,hw,Wro,hm,uw,wLe,eR,mQr,ALe,fQr,Uro,gr,oR,gQr,um,hQr,pte,uQr,pQr,_te,_Qr,bQr,vQr,rR,FQr,LLe,TQr,MQr,EQr,Zt,tR,CQr,yLe,wQr,AQr,pm,LQr,xLe,yQr,xQr,bte,$Qr,kQr,SQr,pw,RQr,Vr,aR,PQr,$Le,BQr,IQr,Bn,NQr,kLe,qQr,jQr,SLe,DQr,GQr,RLe,OQr,VQr,XQr,ge,_w,PLe,zQr,QQr,vte,WQr,UQr,HQr,bw,BLe,JQr,YQr,Fte,ZQr,KQr,eWr,vw,ILe,oWr,rWr,Tte,tWr,aWr,nWr,Fw,NLe,sWr,lWr,Mte,iWr,dWr,cWr,Tw,qLe,mWr,fWr,Ete,gWr,hWr,uWr,Mw,jLe,pWr,_Wr,Cte,bWr,vWr,FWr,Ew,DLe,TWr,MWr,wte,EWr,CWr,wWr,Cw,GLe,AWr,LWr,Ate,yWr,xWr,$Wr,ww,OLe,kWr,SWr,Lte,RWr,PWr,BWr,Aw,VLe,IWr,NWr,yte,qWr,jWr,DWr,Lw,XLe,GWr,OWr,xte,VWr,XWr,zWr,yw,zLe,QWr,WWr,$te,UWr,HWr,JWr,xw,QLe,YWr,ZWr,kte,KWr,eUr,oUr,$w,WLe,rUr,tUr,Ste,aUr,nUr,sUr,kw,ULe,lUr,iUr,Rte,dUr,cUr,mUr,Sw,HLe,fUr,gUr,Pte,hUr,uUr,pUr,Rw,JLe,_Ur,bUr,Bte,vUr,FUr,TUr,Pw,YLe,MUr,EUr,Ite,CUr,wUr,AUr,Bw,ZLe,LUr,yUr,Nte,xUr,$Ur,kUr,Iw,KLe,SUr,RUr,qte,PUr,BUr,IUr,Nw,Hro,_m,qw,e8e,nR,NUr,o8e,qUr,Jro,hr,sR,jUr,bm,DUr,jte,GUr,OUr,Dte,VUr,XUr,zUr,lR,QUr,r8e,WUr,UUr,HUr,Kt,iR,JUr,t8e,YUr,ZUr,vm,KUr,a8e,eHr,oHr,Gte,rHr,tHr,aHr,jw,nHr,Xr,dR,sHr,n8e,lHr,iHr,In,dHr,s8e,cHr,mHr,l8e,fHr,gHr,i8e,hHr,uHr,pHr,xe,Dw,d8e,_Hr,bHr,Ote,vHr,FHr,THr,Gw,c8e,MHr,EHr,Vte,CHr,wHr,AHr,Ow,m8e,LHr,yHr,Xte,xHr,$Hr,kHr,Vw,f8e,SHr,RHr,zte,PHr,BHr,IHr,Xw,g8e,NHr,qHr,Qte,jHr,DHr,GHr,zw,h8e,OHr,VHr,Wte,XHr,zHr,QHr,Qw,u8e,WHr,UHr,Ute,HHr,JHr,YHr,Ww,p8e,ZHr,KHr,Hte,eJr,oJr,rJr,Uw,_8e,tJr,aJr,Jte,nJr,sJr,lJr,Hw,b8e,iJr,dJr,Yte,cJr,mJr,fJr,Jw,Yro,Fm,Yw,v8e,cR,gJr,F8e,hJr,Zro,ur,mR,uJr,Tm,pJr,Zte,_Jr,bJr,Kte,vJr,FJr,TJr,fR,MJr,T8e,EJr,CJr,wJr,ea,gR,AJr,M8e,LJr,yJr,Mm,xJr,E8e,$Jr,kJr,eae,SJr,RJr,PJr,Zw,BJr,zr,hR,IJr,C8e,NJr,qJr,Nn,jJr,w8e,DJr,GJr,A8e,OJr,VJr,L8e,XJr,zJr,QJr,re,Kw,y8e,WJr,UJr,oae,HJr,JJr,YJr,eA,x8e,ZJr,KJr,rae,eYr,oYr,rYr,oA,$8e,tYr,aYr,tae,nYr,sYr,lYr,rA,k8e,iYr,dYr,aae,cYr,mYr,fYr,tA,S8e,gYr,hYr,nae,uYr,pYr,_Yr,aA,R8e,bYr,vYr,sae,FYr,TYr,MYr,nA,P8e,EYr,CYr,lae,wYr,AYr,LYr,sA,B8e,yYr,xYr,iae,$Yr,kYr,SYr,lA,I8e,RYr,PYr,dae,BYr,IYr,NYr,iA,N8e,qYr,jYr,cae,DYr,GYr,OYr,dA,q8e,VYr,XYr,mae,zYr,QYr,WYr,cA,j8e,UYr,HYr,fae,JYr,YYr,ZYr,mA,D8e,KYr,eZr,gae,oZr,rZr,tZr,fA,G8e,aZr,nZr,hae,sZr,lZr,iZr,gA,O8e,dZr,cZr,uae,mZr,fZr,gZr,hA,V8e,hZr,uZr,pae,pZr,_Zr,bZr,uA,X8e,vZr,FZr,_ae,TZr,MZr,EZr,pA,z8e,CZr,wZr,bae,AZr,LZr,yZr,_A,Q8e,xZr,$Zr,vae,kZr,SZr,RZr,bA,W8e,PZr,BZr,Fae,IZr,NZr,qZr,vA,U8e,jZr,DZr,Tae,GZr,OZr,VZr,FA,H8e,XZr,zZr,Mae,QZr,WZr,UZr,TA,J8e,HZr,JZr,Eae,YZr,ZZr,KZr,MA,Y8e,eKr,oKr,Cae,rKr,tKr,aKr,EA,Z8e,nKr,sKr,wae,lKr,iKr,dKr,CA,K8e,cKr,mKr,Aae,fKr,gKr,hKr,wA,eye,uKr,pKr,Lae,_Kr,bKr,vKr,AA,Kro,Em,LA,oye,uR,FKr,rye,TKr,eto,pr,pR,MKr,Cm,EKr,yae,CKr,wKr,xae,AKr,LKr,yKr,_R,xKr,tye,$Kr,kKr,SKr,oa,bR,RKr,aye,PKr,BKr,wm,IKr,nye,NKr,qKr,$ae,jKr,DKr,GKr,yA,OKr,Qr,vR,VKr,sye,XKr,zKr,qn,QKr,lye,WKr,UKr,iye,HKr,JKr,dye,YKr,ZKr,KKr,ve,xA,cye,eet,oet,kae,ret,tet,aet,$A,mye,net,set,Sae,iet,det,cet,kA,fye,met,fet,Rae,get,het,uet,SA,gye,pet,_et,Pae,bet,vet,Fet,RA,hye,Tet,Met,Bae,Eet,Cet,wet,PA,uye,Aet,Let,Iae,yet,xet,$et,BA,pye,ket,Set,Nae,Ret,Pet,Bet,IA,_ye,Iet,Net,qae,qet,jet,Det,NA,bye,Get,Oet,jae,Vet,Xet,zet,qA,vye,Qet,Wet,Dae,Uet,Het,Jet,jA,Fye,Yet,Zet,Gae,Ket,eot,oot,DA,Tye,rot,tot,Oae,aot,not,sot,GA,Mye,lot,iot,Vae,dot,cot,mot,OA,Eye,fot,got,Xae,hot,uot,pot,VA,Cye,_ot,bot,zae,vot,Fot,Tot,XA,wye,Mot,Eot,Qae,Cot,wot,Aot,zA,Aye,Lot,yot,Wae,xot,$ot,kot,QA,oto,Am,WA,Lye,FR,Sot,yye,Rot,rto,_r,TR,Pot,Lm,Bot,Uae,Iot,Not,Hae,qot,jot,Dot,MR,Got,xye,Oot,Vot,Xot,ra,ER,zot,$ye,Qot,Wot,ym,Uot,kye,Hot,Jot,Jae,Yot,Zot,Kot,UA,ert,Wr,CR,ort,Sye,rrt,trt,jn,art,Rye,nrt,srt,Pye,lrt,irt,Bye,drt,crt,mrt,wR,HA,Iye,frt,grt,Yae,hrt,urt,prt,JA,Nye,_rt,brt,Zae,vrt,Frt,Trt,YA,tto,xm,ZA,qye,AR,Mrt,jye,Ert,ato,br,LR,Crt,$m,wrt,Kae,Art,Lrt,ene,yrt,xrt,$rt,yR,krt,Dye,Srt,Rrt,Prt,ta,xR,Brt,Gye,Irt,Nrt,km,qrt,Oye,jrt,Drt,one,Grt,Ort,Vrt,KA,Xrt,Ur,$R,zrt,Vye,Qrt,Wrt,Dn,Urt,Xye,Hrt,Jrt,zye,Yrt,Zrt,Qye,Krt,ett,ott,Wye,e6,Uye,rtt,ttt,rne,att,ntt,stt,o6,nto,Sm,r6,Hye,kR,ltt,Jye,itt,sto,vr,SR,dtt,Rm,ctt,tne,mtt,ftt,ane,gtt,htt,utt,RR,ptt,Yye,_tt,btt,vtt,aa,PR,Ftt,Zye,Ttt,Mtt,Pm,Ett,Kye,Ctt,wtt,nne,Att,Ltt,ytt,t6,xtt,Hr,BR,$tt,e9e,ktt,Stt,Gn,Rtt,o9e,Ptt,Btt,r9e,Itt,Ntt,t9e,qtt,jtt,Dtt,a9e,a6,n9e,Gtt,Ott,sne,Vtt,Xtt,ztt,n6,lto,Bm,s6,s9e,IR,Qtt,l9e,Wtt,ito,Fr,NR,Utt,Im,Htt,lne,Jtt,Ytt,ine,Ztt,Ktt,eat,qR,oat,i9e,rat,tat,aat,na,jR,nat,d9e,sat,lat,Nm,iat,c9e,dat,cat,dne,mat,fat,gat,l6,hat,Jr,DR,uat,m9e,pat,_at,On,bat,f9e,vat,Fat,g9e,Tat,Mat,h9e,Eat,Cat,wat,ce,i6,u9e,Aat,Lat,cne,yat,xat,$at,d6,p9e,kat,Sat,mne,Rat,Pat,Bat,c6,_9e,Iat,Nat,fne,qat,jat,Dat,m6,b9e,Gat,Oat,gne,Vat,Xat,zat,f6,v9e,Qat,Wat,hne,Uat,Hat,Jat,g6,F9e,Yat,Zat,une,Kat,ent,ont,h6,T9e,rnt,tnt,pne,ant,nnt,snt,u6,M9e,lnt,int,_ne,dnt,cnt,mnt,p6,E9e,fnt,gnt,bne,hnt,unt,pnt,_6,C9e,_nt,bnt,vne,vnt,Fnt,Tnt,b6,w9e,Mnt,Ent,Fne,Cnt,wnt,Ant,v6,A9e,Lnt,ynt,Tne,xnt,$nt,knt,F6,L9e,Snt,Rnt,Mne,Pnt,Bnt,Int,T6,y9e,Nnt,qnt,Ene,jnt,Dnt,Gnt,M6,x9e,Ont,Vnt,Cne,Xnt,znt,Qnt,E6,$9e,Wnt,Unt,wne,Hnt,Jnt,Ynt,C6,k9e,Znt,Knt,Ane,est,ost,rst,w6,S9e,tst,ast,Lne,nst,sst,lst,A6,R9e,ist,dst,yne,cst,mst,fst,L6,P9e,gst,hst,xne,ust,pst,_st,y6,B9e,bst,vst,$ne,Fst,Tst,Mst,x6,dto,qm,$6,I9e,GR,Est,N9e,Cst,cto,Tr,OR,wst,jm,Ast,kne,Lst,yst,Sne,xst,$st,kst,VR,Sst,q9e,Rst,Pst,Bst,sa,XR,Ist,j9e,Nst,qst,Dm,jst,D9e,Dst,Gst,Rne,Ost,Vst,Xst,k6,zst,Yr,zR,Qst,G9e,Wst,Ust,Vn,Hst,O9e,Jst,Yst,V9e,Zst,Kst,X9e,elt,olt,rlt,me,S6,z9e,tlt,alt,Pne,nlt,slt,llt,R6,Q9e,ilt,dlt,Bne,clt,mlt,flt,P6,W9e,glt,hlt,Ine,ult,plt,_lt,B6,U9e,blt,vlt,Nne,Flt,Tlt,Mlt,I6,H9e,Elt,Clt,qne,wlt,Alt,Llt,N6,J9e,ylt,xlt,jne,$lt,klt,Slt,q6,Y9e,Rlt,Plt,Dne,Blt,Ilt,Nlt,j6,Z9e,qlt,jlt,Gne,Dlt,Glt,Olt,D6,K9e,Vlt,Xlt,One,zlt,Qlt,Wlt,G6,exe,Ult,Hlt,Vne,Jlt,Ylt,Zlt,O6,oxe,Klt,eit,Xne,oit,rit,tit,V6,rxe,ait,nit,zne,sit,lit,iit,X6,txe,dit,cit,Qne,mit,fit,git,z6,axe,hit,uit,Wne,pit,_it,bit,Q6,nxe,vit,Fit,Une,Tit,Mit,Eit,W6,sxe,Cit,wit,Hne,Ait,Lit,yit,U6,lxe,xit,$it,Jne,kit,Sit,Rit,H6,ixe,Pit,Bit,Yne,Iit,Nit,qit,J6,dxe,jit,Dit,Zne,Git,Oit,Vit,Y6,cxe,Xit,zit,Kne,Qit,Wit,Uit,Z6,mxe,Hit,Jit,ese,Yit,Zit,Kit,K6,mto,Gm,e7,fxe,QR,edt,gxe,odt,fto,Mr,WR,rdt,Om,tdt,ose,adt,ndt,rse,sdt,ldt,idt,UR,ddt,hxe,cdt,mdt,fdt,la,HR,gdt,uxe,hdt,udt,Vm,pdt,pxe,_dt,bdt,tse,vdt,Fdt,Tdt,o7,Mdt,Zr,JR,Edt,_xe,Cdt,wdt,Xn,Adt,bxe,Ldt,ydt,vxe,xdt,$dt,Fxe,kdt,Sdt,Rdt,Txe,r7,Mxe,Pdt,Bdt,ase,Idt,Ndt,qdt,t7,gto,Xm,a7,Exe,YR,jdt,Cxe,Ddt,hto,Er,ZR,Gdt,zm,Odt,nse,Vdt,Xdt,sse,zdt,Qdt,Wdt,KR,Udt,wxe,Hdt,Jdt,Ydt,ia,eP,Zdt,Axe,Kdt,ect,Qm,oct,Lxe,rct,tct,lse,act,nct,sct,n7,lct,Kr,oP,ict,yxe,dct,cct,zn,mct,xxe,fct,gct,$xe,hct,uct,kxe,pct,_ct,bct,rP,s7,Sxe,vct,Fct,ise,Tct,Mct,Ect,l7,Rxe,Cct,wct,dse,Act,Lct,yct,i7,uto,Wm,d7,Pxe,tP,xct,Bxe,$ct,pto,Cr,aP,kct,Um,Sct,cse,Rct,Pct,mse,Bct,Ict,Nct,nP,qct,Ixe,jct,Dct,Gct,da,sP,Oct,Nxe,Vct,Xct,Hm,zct,qxe,Qct,Wct,fse,Uct,Hct,Jct,c7,Yct,et,lP,Zct,jxe,Kct,emt,Qn,omt,Dxe,rmt,tmt,Gxe,amt,nmt,Oxe,smt,lmt,imt,te,m7,Vxe,dmt,cmt,gse,mmt,fmt,gmt,f7,Xxe,hmt,umt,hse,pmt,_mt,bmt,g7,zxe,vmt,Fmt,use,Tmt,Mmt,Emt,h7,Qxe,Cmt,wmt,pse,Amt,Lmt,ymt,u7,Wxe,xmt,$mt,_se,kmt,Smt,Rmt,p7,Uxe,Pmt,Bmt,bse,Imt,Nmt,qmt,_7,Hxe,jmt,Dmt,vse,Gmt,Omt,Vmt,b7,Jxe,Xmt,zmt,Fse,Qmt,Wmt,Umt,v7,Yxe,Hmt,Jmt,Tse,Ymt,Zmt,Kmt,F7,Zxe,eft,oft,Mse,rft,tft,aft,T7,Kxe,nft,sft,Ese,lft,ift,dft,M7,e$e,cft,mft,Cse,fft,gft,hft,E7,o$e,uft,pft,wse,_ft,bft,vft,C7,r$e,Fft,Tft,Ase,Mft,Eft,Cft,w7,t$e,wft,Aft,Lse,Lft,yft,xft,A7,a$e,$ft,kft,yse,Sft,Rft,Pft,L7,n$e,Bft,Ift,xse,Nft,qft,jft,y7,s$e,Dft,Gft,$se,Oft,Vft,Xft,x7,l$e,zft,Qft,kse,Wft,Uft,Hft,$7,i$e,Jft,Yft,Sse,Zft,Kft,egt,k7,d$e,ogt,rgt,Rse,tgt,agt,ngt,S7,c$e,sgt,lgt,Pse,igt,dgt,cgt,R7,m$e,mgt,fgt,Bse,ggt,hgt,ugt,P7,f$e,pgt,_gt,Ise,bgt,vgt,Fgt,B7,g$e,Tgt,Mgt,Nse,Egt,Cgt,wgt,I7,h$e,Agt,Lgt,qse,ygt,xgt,$gt,N7,u$e,kgt,Sgt,jse,Rgt,Pgt,Bgt,q7,_to,Jm,j7,p$e,iP,Igt,_$e,Ngt,bto,wr,dP,qgt,Ym,jgt,Dse,Dgt,Ggt,Gse,Ogt,Vgt,Xgt,cP,zgt,b$e,Qgt,Wgt,Ugt,ca,mP,Hgt,v$e,Jgt,Ygt,Zm,Zgt,F$e,Kgt,eht,Ose,oht,rht,tht,D7,aht,ot,fP,nht,T$e,sht,lht,Wn,iht,M$e,dht,cht,E$e,mht,fht,C$e,ght,hht,uht,$e,G7,w$e,pht,_ht,Vse,bht,vht,Fht,O7,A$e,Tht,Mht,Xse,Eht,Cht,wht,V7,L$e,Aht,Lht,zse,yht,xht,$ht,X7,y$e,kht,Sht,Qse,Rht,Pht,Bht,z7,x$e,Iht,Nht,Wse,qht,jht,Dht,Q7,$$e,Ght,Oht,Use,Vht,Xht,zht,W7,k$e,Qht,Wht,Hse,Uht,Hht,Jht,U7,S$e,Yht,Zht,Jse,Kht,eut,out,H7,R$e,rut,tut,Yse,aut,nut,sut,J7,P$e,lut,iut,Zse,dut,cut,mut,Y7,vto,Km,Z7,B$e,gP,fut,I$e,gut,Fto,Ar,hP,hut,ef,uut,Kse,put,_ut,ele,but,vut,Fut,uP,Tut,N$e,Mut,Eut,Cut,ma,pP,wut,q$e,Aut,Lut,of,yut,j$e,xut,$ut,ole,kut,Sut,Rut,K7,Put,rt,_P,But,D$e,Iut,Nut,Un,qut,G$e,jut,Dut,O$e,Gut,Out,V$e,Vut,Xut,zut,Ee,eL,X$e,Qut,Wut,rle,Uut,Hut,Jut,oL,z$e,Yut,Zut,tle,Kut,ept,opt,rL,Q$e,rpt,tpt,ale,apt,npt,spt,tL,W$e,lpt,ipt,nle,dpt,cpt,mpt,aL,U$e,fpt,gpt,sle,hpt,upt,ppt,nL,H$e,_pt,bpt,lle,vpt,Fpt,Tpt,sL,J$e,Mpt,Ept,ile,Cpt,wpt,Apt,lL,Y$e,Lpt,ypt,dle,xpt,$pt,kpt,iL,Z$e,Spt,Rpt,cle,Ppt,Bpt,Ipt,dL,K$e,Npt,qpt,mle,jpt,Dpt,Gpt,cL,eke,Opt,Vpt,fle,Xpt,zpt,Qpt,mL,oke,Wpt,Upt,gle,Hpt,Jpt,Ypt,fL,rke,Zpt,Kpt,hle,e_t,o_t,r_t,gL,Tto,rf,hL,tke,bP,t_t,ake,a_t,Mto,Lr,vP,n_t,tf,s_t,ule,l_t,i_t,ple,d_t,c_t,m_t,FP,f_t,nke,g_t,h_t,u_t,fa,TP,p_t,ske,__t,b_t,af,v_t,lke,F_t,T_t,_le,M_t,E_t,C_t,uL,w_t,tt,MP,A_t,ike,L_t,y_t,Hn,x_t,dke,$_t,k_t,cke,S_t,R_t,mke,P_t,B_t,I_t,ke,pL,fke,N_t,q_t,ble,j_t,D_t,G_t,_L,gke,O_t,V_t,vle,X_t,z_t,Q_t,bL,hke,W_t,U_t,Fle,H_t,J_t,Y_t,vL,uke,Z_t,K_t,Tle,e1t,o1t,r1t,FL,pke,t1t,a1t,Mle,n1t,s1t,l1t,TL,_ke,i1t,d1t,Ele,c1t,m1t,f1t,ML,bke,g1t,h1t,Cle,u1t,p1t,_1t,EL,vke,b1t,v1t,wle,F1t,T1t,M1t,CL,Fke,E1t,C1t,Ale,w1t,A1t,L1t,wL,Tke,y1t,x1t,Lle,$1t,k1t,S1t,AL,Eto,nf,LL,Mke,EP,R1t,Eke,P1t,Cto,yr,CP,B1t,sf,I1t,yle,N1t,q1t,xle,j1t,D1t,G1t,wP,O1t,Cke,V1t,X1t,z1t,ga,AP,Q1t,wke,W1t,U1t,lf,H1t,Ake,J1t,Y1t,$le,Z1t,K1t,e2t,yL,o2t,at,LP,r2t,Lke,t2t,a2t,Jn,n2t,yke,s2t,l2t,xke,i2t,d2t,$ke,c2t,m2t,f2t,Se,xL,kke,g2t,h2t,kle,u2t,p2t,_2t,$L,Ske,b2t,v2t,Sle,F2t,T2t,M2t,kL,Rke,E2t,C2t,Rle,w2t,A2t,L2t,SL,Pke,y2t,x2t,Ple,$2t,k2t,S2t,RL,Bke,R2t,P2t,Ble,B2t,I2t,N2t,PL,Ike,q2t,j2t,Ile,D2t,G2t,O2t,BL,Nke,V2t,X2t,Nle,z2t,Q2t,W2t,IL,qke,U2t,H2t,qle,J2t,Y2t,Z2t,NL,jke,K2t,ebt,jle,obt,rbt,tbt,qL,Dke,abt,nbt,Dle,sbt,lbt,ibt,jL,wto,df,DL,Gke,yP,dbt,Oke,cbt,Ato,xr,xP,mbt,cf,fbt,Gle,gbt,hbt,Ole,ubt,pbt,_bt,$P,bbt,Vke,vbt,Fbt,Tbt,ha,kP,Mbt,Xke,Ebt,Cbt,mf,wbt,zke,Abt,Lbt,Vle,ybt,xbt,$bt,GL,kbt,nt,SP,Sbt,Qke,Rbt,Pbt,Yn,Bbt,Wke,Ibt,Nbt,Uke,qbt,jbt,Hke,Dbt,Gbt,Obt,Re,OL,Jke,Vbt,Xbt,Xle,zbt,Qbt,Wbt,VL,Yke,Ubt,Hbt,zle,Jbt,Ybt,Zbt,XL,Zke,Kbt,evt,Qle,ovt,rvt,tvt,zL,Kke,avt,nvt,Wle,svt,lvt,ivt,QL,eSe,dvt,cvt,Ule,mvt,fvt,gvt,WL,oSe,hvt,uvt,Hle,pvt,_vt,bvt,UL,rSe,vvt,Fvt,Jle,Tvt,Mvt,Evt,HL,tSe,Cvt,wvt,Yle,Avt,Lvt,yvt,JL,aSe,xvt,$vt,Zle,kvt,Svt,Rvt,YL,nSe,Pvt,Bvt,Kle,Ivt,Nvt,qvt,ZL,Lto,ff,KL,sSe,RP,jvt,lSe,Dvt,yto,$r,PP,Gvt,gf,Ovt,eie,Vvt,Xvt,oie,zvt,Qvt,Wvt,BP,Uvt,iSe,Hvt,Jvt,Yvt,ua,IP,Zvt,dSe,Kvt,eFt,hf,oFt,cSe,rFt,tFt,rie,aFt,nFt,sFt,e8,lFt,st,NP,iFt,mSe,dFt,cFt,Zn,mFt,fSe,fFt,gFt,gSe,hFt,uFt,hSe,pFt,_Ft,bFt,Pe,o8,uSe,vFt,FFt,tie,TFt,MFt,EFt,r8,pSe,CFt,wFt,aie,AFt,LFt,yFt,t8,_Se,xFt,$Ft,nie,kFt,SFt,RFt,a8,bSe,PFt,BFt,sie,IFt,NFt,qFt,n8,vSe,jFt,DFt,lie,GFt,OFt,VFt,s8,FSe,XFt,zFt,iie,QFt,WFt,UFt,l8,TSe,HFt,JFt,die,YFt,ZFt,KFt,i8,MSe,eTt,oTt,cie,rTt,tTt,aTt,d8,ESe,nTt,sTt,mie,lTt,iTt,dTt,c8,CSe,cTt,mTt,fie,fTt,gTt,hTt,m8,xto,uf,f8,wSe,qP,uTt,ASe,pTt,$to,kr,jP,_Tt,pf,bTt,gie,vTt,FTt,hie,TTt,MTt,ETt,DP,CTt,LSe,wTt,ATt,LTt,pa,GP,yTt,ySe,xTt,$Tt,_f,kTt,xSe,STt,RTt,uie,PTt,BTt,ITt,g8,NTt,lt,OP,qTt,$Se,jTt,DTt,Kn,GTt,kSe,OTt,VTt,SSe,XTt,zTt,RSe,QTt,WTt,UTt,ze,h8,PSe,HTt,JTt,pie,YTt,ZTt,KTt,u8,BSe,eMt,oMt,_ie,rMt,tMt,aMt,p8,ISe,nMt,sMt,bie,lMt,iMt,dMt,_8,NSe,cMt,mMt,vie,fMt,gMt,hMt,b8,qSe,uMt,pMt,Fie,_Mt,bMt,vMt,v8,jSe,FMt,TMt,Tie,MMt,EMt,CMt,F8,DSe,wMt,AMt,Mie,LMt,yMt,xMt,T8,GSe,$Mt,kMt,Eie,SMt,RMt,PMt,M8,kto,bf,E8,OSe,VP,BMt,VSe,IMt,Sto,Sr,XP,NMt,vf,qMt,Cie,jMt,DMt,wie,GMt,OMt,VMt,zP,XMt,XSe,zMt,QMt,WMt,_a,QP,UMt,zSe,HMt,JMt,Ff,YMt,QSe,ZMt,KMt,Aie,eEt,oEt,rEt,C8,tEt,it,WP,aEt,WSe,nEt,sEt,es,lEt,USe,iEt,dEt,HSe,cEt,mEt,JSe,fEt,gEt,hEt,Qe,w8,YSe,uEt,pEt,Lie,_Et,bEt,vEt,A8,ZSe,FEt,TEt,yie,MEt,EEt,CEt,L8,KSe,wEt,AEt,xie,LEt,yEt,xEt,y8,eRe,$Et,kEt,$ie,SEt,REt,PEt,x8,oRe,BEt,IEt,kie,NEt,qEt,jEt,$8,rRe,DEt,GEt,Sie,OEt,VEt,XEt,k8,tRe,zEt,QEt,Rie,WEt,UEt,HEt,S8,aRe,JEt,YEt,Pie,ZEt,KEt,e4t,R8,Rto,Tf,P8,nRe,UP,o4t,sRe,r4t,Pto,Rr,HP,t4t,Mf,a4t,Bie,n4t,s4t,Iie,l4t,i4t,d4t,JP,c4t,lRe,m4t,f4t,g4t,ba,YP,h4t,iRe,u4t,p4t,Ef,_4t,dRe,b4t,v4t,Nie,F4t,T4t,M4t,B8,E4t,dt,ZP,C4t,cRe,w4t,A4t,os,L4t,mRe,y4t,x4t,fRe,$4t,k4t,gRe,S4t,R4t,P4t,hRe,I8,uRe,B4t,I4t,qie,N4t,q4t,j4t,N8,Bto,Cf,q8,pRe,KP,D4t,_Re,G4t,Ito,Pr,eB,O4t,wf,V4t,jie,X4t,z4t,Die,Q4t,W4t,U4t,oB,H4t,bRe,J4t,Y4t,Z4t,va,rB,K4t,vRe,eCt,oCt,Af,rCt,FRe,tCt,aCt,Gie,nCt,sCt,lCt,j8,iCt,ct,tB,dCt,TRe,cCt,mCt,rs,fCt,MRe,gCt,hCt,ERe,uCt,pCt,CRe,_Ct,bCt,vCt,aB,D8,wRe,FCt,TCt,Oie,MCt,ECt,CCt,G8,ARe,wCt,ACt,Vie,LCt,yCt,xCt,O8,Nto,Lf,V8,LRe,nB,$Ct,yRe,kCt,qto,Br,sB,SCt,yf,RCt,Xie,PCt,BCt,zie,ICt,NCt,qCt,lB,jCt,xRe,DCt,GCt,OCt,Fa,iB,VCt,$Re,XCt,zCt,xf,QCt,kRe,WCt,UCt,Qie,HCt,JCt,YCt,X8,ZCt,mt,dB,KCt,SRe,e3t,o3t,ts,r3t,RRe,t3t,a3t,PRe,n3t,s3t,BRe,l3t,i3t,d3t,IRe,z8,NRe,c3t,m3t,Wie,f3t,g3t,h3t,Q8,jto;return d=new oe({}),Ja=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),$x=new oe({}),kx=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),qf=new u3t({props:{warning:!0,$$slots:{default:[sTa]},$$scope:{ctx:$}}}),Sx=new oe({}),Rx=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L659"}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L682"}}),mu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[lTa]},$$scope:{ctx:$}}}),Nx=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L805"}}),qx=new oe({}),jx=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L428"}}),Ox=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L442"}}),Hu=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[iTa]},$$scope:{ctx:$}}}),Vx=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L643"}}),Xx=new oe({}),zx=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L203"}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L217"}}),Gp=new u3t({props:{$$slots:{default:[dTa]},$$scope:{ctx:$}}}),Op=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[cTa]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L344"}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),h_=new u3t({props:{$$slots:{default:[mTa]},$$scope:{ctx:$}}}),u_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[fTa]},$$scope:{ctx:$}}}),o$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),r$=new oe({}),t$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L874"}}),n$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[gTa]},$$scope:{ctx:$}}}),s$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q2=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[hTa]},$$scope:{ctx:$}}}),l$=new oe({}),i$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L881"}}),c$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D2=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[uTa]},$$scope:{ctx:$}}}),m$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ib=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[pTa]},$$scope:{ctx:$}}}),f$=new oe({}),g$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L896"}}),u$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),qb=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[_Ta]},$$scope:{ctx:$}}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[bTa]},$$scope:{ctx:$}}}),_$=new oe({}),b$=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L903"}}),F$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$v=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[vTa]},$$scope:{ctx:$}}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_F=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[FTa]},$$scope:{ctx:$}}}),M$=new oe({}),E$=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L910"}}),w$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[TTa]},$$scope:{ctx:$}}}),A$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),GF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[MTa]},$$scope:{ctx:$}}}),L$=new oe({}),y$=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L919"}}),$$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),VF=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[ETa]},$$scope:{ctx:$}}}),k$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[CTa]},$$scope:{ctx:$}}}),S$=new oe({}),R$=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L975"}}),B$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UT=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[wTa]},$$scope:{ctx:$}}}),I$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[ATa]},$$scope:{ctx:$}}}),N$=new oe({}),q$=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L982"}}),D$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$M=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[LTa]},$$scope:{ctx:$}}}),G$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jM=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[yTa]},$$scope:{ctx:$}}}),O$=new oe({}),V$=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L968"}}),z$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GM=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[xTa]},$$scope:{ctx:$}}}),Q$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[$Ta]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L928"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kE=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[kTa]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[STa]},$$scope:{ctx:$}}}),Z$=new oe({}),K$=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L935"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[RTa]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[PTa]},$$scope:{ctx:$}}}),tk=new oe({}),ak=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L957"}}),sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R4=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[BTa]},$$scope:{ctx:$}}}),lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q4=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[ITa]},$$scope:{ctx:$}}}),ik=new oe({}),dk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L991"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D4=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[NTa]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[qTa]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1039"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[jTa]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[DTa]},$$scope:{ctx:$}}}),bk=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1046"}}),Tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[GTa]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[OTa]},$$scope:{ctx:$}}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L946"}}),Ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[VTa]},$$scope:{ctx:$}}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[XTa]},$$scope:{ctx:$}}}),yk=new oe({}),xk=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1053"}}),kk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),FC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[zTa]},$$scope:{ctx:$}}}),Sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),kC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[QTa]},$$scope:{ctx:$}}}),Rk=new oe({}),Pk=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1076"}}),Ik=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),RC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[WTa]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),DC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[UTa]},$$scope:{ctx:$}}}),qk=new oe({}),jk=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1060"}}),Gk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),OC=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[HTa]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[JTa]},$$scope:{ctx:$}}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1067"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[YTa]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[ZTa]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1085"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[KTa]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[eMa]},$$scope:{ctx:$}}}),Kk=new oe({}),eS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1092"}}),rS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[oMa]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[rMa]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1023"}}),lS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[tMa]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[aMa]},$$scope:{ctx:$}}}),dS=new oe({}),cS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L998"}}),fS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[nMa]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[sMa]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1005"}}),_S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),j3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[lMa]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[iMa]},$$scope:{ctx:$}}}),vS=new oe({}),FS=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1014"}}),MS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),U3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[dMa]},$$scope:{ctx:$}}}),ES=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Y3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[cMa]},$$scope:{ctx:$}}}),CS=new oe({}),wS=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1030"}}),LS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K3=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[mMa]},$$scope:{ctx:$}}}),yS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[fMa]},$$scope:{ctx:$}}}),xS=new oe({}),$S=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L439"}}),SS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a5=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[gMa]},$$scope:{ctx:$}}}),RS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l0=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[hMa]},$$scope:{ctx:$}}}),PS=new oe({}),BS=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L446"}}),NS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[uMa]},$$scope:{ctx:$}}}),qS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[pMa]},$$scope:{ctx:$}}}),jS=new oe({}),DS=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L461"}}),OS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B0=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[_Ma]},$$scope:{ctx:$}}}),VS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J0=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[bMa]},$$scope:{ctx:$}}}),XS=new oe({}),zS=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L477"}}),WS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z0=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[vMa]},$$scope:{ctx:$}}}),US=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[FMa]},$$scope:{ctx:$}}}),HS=new oe({}),JS=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L486"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[TMa]},$$scope:{ctx:$}}}),KS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[MMa]},$$scope:{ctx:$}}}),eR=new oe({}),oR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L502"}}),tR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[EMa]},$$scope:{ctx:$}}}),aR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Nw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[CMa]},$$scope:{ctx:$}}}),nR=new oe({}),sR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L509"}}),iR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jw=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[wMa]},$$scope:{ctx:$}}}),dR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Jw=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[AMa]},$$scope:{ctx:$}}}),cR=new oe({}),mR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L518"}}),gR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Zw=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[LMa]},$$scope:{ctx:$}}}),hR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[yMa]},$$scope:{ctx:$}}}),uR=new oe({}),pR=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L565"}}),bR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[xMa]},$$scope:{ctx:$}}}),vR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[$Ma]},$$scope:{ctx:$}}}),FR=new oe({}),TR=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L572"}}),ER=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UA=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[kMa]},$$scope:{ctx:$}}}),CR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YA=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[SMa]},$$scope:{ctx:$}}}),AR=new oe({}),LR=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L545"}}),xR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),KA=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[RMa]},$$scope:{ctx:$}}}),$R=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[PMa]},$$scope:{ctx:$}}}),kR=new oe({}),SR=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L534"}}),PR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[BMa]},$$scope:{ctx:$}}}),BR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[IMa]},$$scope:{ctx:$}}}),IR=new oe({}),NR=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L556"}}),jR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[NMa]},$$scope:{ctx:$}}}),DR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[qMa]},$$scope:{ctx:$}}}),GR=new oe({}),OR=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L527"}}),XR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k6=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[jMa]},$$scope:{ctx:$}}}),zR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),K6=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[DMa]},$$scope:{ctx:$}}}),QR=new oe({}),WR=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L495"}}),HR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[GMa]},$$scope:{ctx:$}}}),JR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[OMa]},$$scope:{ctx:$}}}),YR=new oe({}),ZR=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L581"}}),eP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[VMa]},$$scope:{ctx:$}}}),oP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[XMa]},$$scope:{ctx:$}}}),tP=new oe({}),aP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),sP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),c7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[zMa]},$$scope:{ctx:$}}}),lP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q7=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[QMa]},$$scope:{ctx:$}}}),iP=new oe({}),dP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),mP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D7=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[WMa]},$$scope:{ctx:$}}}),fP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Y7=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[UMa]},$$scope:{ctx:$}}}),gP=new oe({}),hP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),pP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K7=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[HMa]},$$scope:{ctx:$}}}),_P=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[JMa]},$$scope:{ctx:$}}}),bP=new oe({}),vP=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),TP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[YMa]},$$scope:{ctx:$}}}),MP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[ZMa]},$$scope:{ctx:$}}}),EP=new oe({}),CP=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),AP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[KMa]},$$scope:{ctx:$}}}),LP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[eEa]},$$scope:{ctx:$}}}),yP=new oe({}),xP=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),kP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[oEa]},$$scope:{ctx:$}}}),SP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[rEa]},$$scope:{ctx:$}}}),RP=new oe({}),PP=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),IP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e8=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[tEa]},$$scope:{ctx:$}}}),NP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m8=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[aEa]},$$scope:{ctx:$}}}),qP=new oe({}),jP=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),GP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g8=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[nEa]},$$scope:{ctx:$}}}),OP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M8=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[sEa]},$$scope:{ctx:$}}}),VP=new oe({}),XP=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),QP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C8=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[lEa]},$$scope:{ctx:$}}}),WP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R8=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[iEa]},$$scope:{ctx:$}}}),UP=new oe({}),HP=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),YP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B8=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[dEa]},$$scope:{ctx:$}}}),ZP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),N8=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[cEa]},$$scope:{ctx:$}}}),KP=new oe({}),eB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),rB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),j8=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[mEa]},$$scope:{ctx:$}}}),tB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),O8=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[fEa]},$$scope:{ctx:$}}}),nB=new oe({}),sB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),iB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),X8=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[gEa]},$$scope:{ctx:$}}}),dB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q8=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[hEa]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),xo=a("span"),dd=o("Auto Classes"),Rf=l(),bt=a("p"),cd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),md=a("code"),Ax=o("from_pretrained()"),Pf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),fd=o("Instantiating one of "),ns=a("a"),Lx=o("AutoConfig"),ss=o(", "),ls=a("a"),yx=o("AutoModel"),gd=o(`, and
`),is=a("a"),xx=o("AutoTokenizer"),hd=o(" will directly create a class of the relevant architecture. For instance"),Bf=l(),F(Ja.$$.fragment),Je=l(),Ae=a("p"),BI=o("will create a model that is an instance of "),ud=a("a"),II=o("BertModel"),NI=o("."),$o=l(),Ya=a("p"),qI=o("There is one class of "),If=a("code"),jI=o("AutoModel"),aso=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Coo=l(),pd=a("h2"),Nf=a("a"),eme=a("span"),F($x.$$.fragment),nso=l(),ome=a("span"),sso=o("Extending the Auto Classes"),woo=l(),ds=a("p"),lso=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),rme=a("code"),iso=o("NewModel"),dso=o(", make sure you have a "),tme=a("code"),cso=o("NewModelConfig"),mso=o(` then you can add those to the auto
classes like this:`),Aoo=l(),F(kx.$$.fragment),Loo=l(),DI=a("p"),fso=o("You will then be able to use the auto classes like you would usually do!"),yoo=l(),F(qf.$$.fragment),xoo=l(),_d=a("h2"),jf=a("a"),ame=a("span"),F(Sx.$$.fragment),gso=l(),nme=a("span"),hso=o("AutoConfig"),$oo=l(),ko=a("div"),F(Rx.$$.fragment),uso=l(),Px=a("p"),pso=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),GI=a("a"),_so=o("from_pretrained()"),bso=o(" class method."),vso=l(),Bx=a("p"),Fso=o("This class cannot be instantiated directly using "),sme=a("code"),Tso=o("__init__()"),Mso=o(" (throws an error)."),Eso=l(),Ir=a("div"),F(Ix.$$.fragment),Cso=l(),lme=a("p"),wso=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Aso=l(),bd=a("p"),Lso=o("The configuration class to instantiate is selected based on the "),ime=a("code"),yso=o("model_type"),xso=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),dme=a("code"),$so=o("pretrained_model_name_or_path"),kso=o(":"),Sso=l(),A=a("ul"),Df=a("li"),cme=a("strong"),Rso=o("albert"),Pso=o(" \u2014 "),OI=a("a"),Bso=o("AlbertConfig"),Iso=o(" (ALBERT model)"),Nso=l(),Gf=a("li"),mme=a("strong"),qso=o("bart"),jso=o(" \u2014 "),VI=a("a"),Dso=o("BartConfig"),Gso=o(" (BART model)"),Oso=l(),Of=a("li"),fme=a("strong"),Vso=o("beit"),Xso=o(" \u2014 "),XI=a("a"),zso=o("BeitConfig"),Qso=o(" (BEiT model)"),Wso=l(),Vf=a("li"),gme=a("strong"),Uso=o("bert"),Hso=o(" \u2014 "),zI=a("a"),Jso=o("BertConfig"),Yso=o(" (BERT model)"),Zso=l(),Xf=a("li"),hme=a("strong"),Kso=o("bert-generation"),elo=o(" \u2014 "),QI=a("a"),olo=o("BertGenerationConfig"),rlo=o(" (Bert Generation model)"),tlo=l(),zf=a("li"),ume=a("strong"),alo=o("big_bird"),nlo=o(" \u2014 "),WI=a("a"),slo=o("BigBirdConfig"),llo=o(" (BigBird model)"),ilo=l(),Qf=a("li"),pme=a("strong"),dlo=o("bigbird_pegasus"),clo=o(" \u2014 "),UI=a("a"),mlo=o("BigBirdPegasusConfig"),flo=o(" (BigBird-Pegasus model)"),glo=l(),Wf=a("li"),_me=a("strong"),hlo=o("blenderbot"),ulo=o(" \u2014 "),HI=a("a"),plo=o("BlenderbotConfig"),_lo=o(" (Blenderbot model)"),blo=l(),Uf=a("li"),bme=a("strong"),vlo=o("blenderbot-small"),Flo=o(" \u2014 "),JI=a("a"),Tlo=o("BlenderbotSmallConfig"),Mlo=o(" (BlenderbotSmall model)"),Elo=l(),Hf=a("li"),vme=a("strong"),Clo=o("bloom"),wlo=o(" \u2014 "),YI=a("a"),Alo=o("BloomConfig"),Llo=o(" (BLOOM model)"),ylo=l(),Jf=a("li"),Fme=a("strong"),xlo=o("camembert"),$lo=o(" \u2014 "),ZI=a("a"),klo=o("CamembertConfig"),Slo=o(" (CamemBERT model)"),Rlo=l(),Yf=a("li"),Tme=a("strong"),Plo=o("canine"),Blo=o(" \u2014 "),KI=a("a"),Ilo=o("CanineConfig"),Nlo=o(" (CANINE model)"),qlo=l(),Zf=a("li"),Mme=a("strong"),jlo=o("clip"),Dlo=o(" \u2014 "),eN=a("a"),Glo=o("CLIPConfig"),Olo=o(" (CLIP model)"),Vlo=l(),Kf=a("li"),Eme=a("strong"),Xlo=o("codegen"),zlo=o(" \u2014 "),oN=a("a"),Qlo=o("CodeGenConfig"),Wlo=o(" (CodeGen model)"),Ulo=l(),eg=a("li"),Cme=a("strong"),Hlo=o("conditional_detr"),Jlo=o(" \u2014 "),rN=a("a"),Ylo=o("ConditionalDetrConfig"),Zlo=o(" (Conditional DETR model)"),Klo=l(),og=a("li"),wme=a("strong"),eio=o("convbert"),oio=o(" \u2014 "),tN=a("a"),rio=o("ConvBertConfig"),tio=o(" (ConvBERT model)"),aio=l(),rg=a("li"),Ame=a("strong"),nio=o("convnext"),sio=o(" \u2014 "),aN=a("a"),lio=o("ConvNextConfig"),iio=o(" (ConvNeXT model)"),dio=l(),tg=a("li"),Lme=a("strong"),cio=o("ctrl"),mio=o(" \u2014 "),nN=a("a"),fio=o("CTRLConfig"),gio=o(" (CTRL model)"),hio=l(),ag=a("li"),yme=a("strong"),uio=o("cvt"),pio=o(" \u2014 "),sN=a("a"),_io=o("CvtConfig"),bio=o(" (CvT model)"),vio=l(),ng=a("li"),xme=a("strong"),Fio=o("data2vec-audio"),Tio=o(" \u2014 "),lN=a("a"),Mio=o("Data2VecAudioConfig"),Eio=o(" (Data2VecAudio model)"),Cio=l(),sg=a("li"),$me=a("strong"),wio=o("data2vec-text"),Aio=o(" \u2014 "),iN=a("a"),Lio=o("Data2VecTextConfig"),yio=o(" (Data2VecText model)"),xio=l(),lg=a("li"),kme=a("strong"),$io=o("data2vec-vision"),kio=o(" \u2014 "),dN=a("a"),Sio=o("Data2VecVisionConfig"),Rio=o(" (Data2VecVision model)"),Pio=l(),ig=a("li"),Sme=a("strong"),Bio=o("deberta"),Iio=o(" \u2014 "),cN=a("a"),Nio=o("DebertaConfig"),qio=o(" (DeBERTa model)"),jio=l(),dg=a("li"),Rme=a("strong"),Dio=o("deberta-v2"),Gio=o(" \u2014 "),mN=a("a"),Oio=o("DebertaV2Config"),Vio=o(" (DeBERTa-v2 model)"),Xio=l(),cg=a("li"),Pme=a("strong"),zio=o("decision_transformer"),Qio=o(" \u2014 "),fN=a("a"),Wio=o("DecisionTransformerConfig"),Uio=o(" (Decision Transformer model)"),Hio=l(),mg=a("li"),Bme=a("strong"),Jio=o("deformable_detr"),Yio=o(" \u2014 "),gN=a("a"),Zio=o("DeformableDetrConfig"),Kio=o(" (Deformable DETR model)"),edo=l(),fg=a("li"),Ime=a("strong"),odo=o("deit"),rdo=o(" \u2014 "),hN=a("a"),tdo=o("DeiTConfig"),ado=o(" (DeiT model)"),ndo=l(),gg=a("li"),Nme=a("strong"),sdo=o("detr"),ldo=o(" \u2014 "),uN=a("a"),ido=o("DetrConfig"),ddo=o(" (DETR model)"),cdo=l(),hg=a("li"),qme=a("strong"),mdo=o("distilbert"),fdo=o(" \u2014 "),pN=a("a"),gdo=o("DistilBertConfig"),hdo=o(" (DistilBERT model)"),udo=l(),ug=a("li"),jme=a("strong"),pdo=o("donut-swin"),_do=o(" \u2014 "),_N=a("a"),bdo=o("DonutSwinConfig"),vdo=o(" (DonutSwin model)"),Fdo=l(),pg=a("li"),Dme=a("strong"),Tdo=o("dpr"),Mdo=o(" \u2014 "),bN=a("a"),Edo=o("DPRConfig"),Cdo=o(" (DPR model)"),wdo=l(),_g=a("li"),Gme=a("strong"),Ado=o("dpt"),Ldo=o(" \u2014 "),vN=a("a"),ydo=o("DPTConfig"),xdo=o(" (DPT model)"),$do=l(),bg=a("li"),Ome=a("strong"),kdo=o("electra"),Sdo=o(" \u2014 "),FN=a("a"),Rdo=o("ElectraConfig"),Pdo=o(" (ELECTRA model)"),Bdo=l(),vg=a("li"),Vme=a("strong"),Ido=o("encoder-decoder"),Ndo=o(" \u2014 "),TN=a("a"),qdo=o("EncoderDecoderConfig"),jdo=o(" (Encoder decoder model)"),Ddo=l(),Fg=a("li"),Xme=a("strong"),Gdo=o("ernie"),Odo=o(" \u2014 "),MN=a("a"),Vdo=o("ErnieConfig"),Xdo=o(" (ERNIE model)"),zdo=l(),Tg=a("li"),zme=a("strong"),Qdo=o("esm"),Wdo=o(" \u2014 "),EN=a("a"),Udo=o("EsmConfig"),Hdo=o(" (ESM model)"),Jdo=l(),Mg=a("li"),Qme=a("strong"),Ydo=o("flaubert"),Zdo=o(" \u2014 "),CN=a("a"),Kdo=o("FlaubertConfig"),eco=o(" (FlauBERT model)"),oco=l(),Eg=a("li"),Wme=a("strong"),rco=o("flava"),tco=o(" \u2014 "),wN=a("a"),aco=o("FlavaConfig"),nco=o(" (FLAVA model)"),sco=l(),Cg=a("li"),Ume=a("strong"),lco=o("fnet"),ico=o(" \u2014 "),AN=a("a"),dco=o("FNetConfig"),cco=o(" (FNet model)"),mco=l(),wg=a("li"),Hme=a("strong"),fco=o("fsmt"),gco=o(" \u2014 "),LN=a("a"),hco=o("FSMTConfig"),uco=o(" (FairSeq Machine-Translation model)"),pco=l(),Ag=a("li"),Jme=a("strong"),_co=o("funnel"),bco=o(" \u2014 "),yN=a("a"),vco=o("FunnelConfig"),Fco=o(" (Funnel Transformer model)"),Tco=l(),Lg=a("li"),Yme=a("strong"),Mco=o("glpn"),Eco=o(" \u2014 "),xN=a("a"),Cco=o("GLPNConfig"),wco=o(" (GLPN model)"),Aco=l(),yg=a("li"),Zme=a("strong"),Lco=o("gpt2"),yco=o(" \u2014 "),$N=a("a"),xco=o("GPT2Config"),$co=o(" (OpenAI GPT-2 model)"),kco=l(),xg=a("li"),Kme=a("strong"),Sco=o("gpt_neo"),Rco=o(" \u2014 "),kN=a("a"),Pco=o("GPTNeoConfig"),Bco=o(" (GPT Neo model)"),Ico=l(),$g=a("li"),efe=a("strong"),Nco=o("gpt_neox"),qco=o(" \u2014 "),SN=a("a"),jco=o("GPTNeoXConfig"),Dco=o(" (GPT NeoX model)"),Gco=l(),kg=a("li"),ofe=a("strong"),Oco=o("gpt_neox_japanese"),Vco=o(" \u2014 "),RN=a("a"),Xco=o("GPTNeoXJapaneseConfig"),zco=o(" (GPT NeoX Japanese model)"),Qco=l(),Sg=a("li"),rfe=a("strong"),Wco=o("gptj"),Uco=o(" \u2014 "),PN=a("a"),Hco=o("GPTJConfig"),Jco=o(" (GPT-J model)"),Yco=l(),Rg=a("li"),tfe=a("strong"),Zco=o("groupvit"),Kco=o(" \u2014 "),BN=a("a"),emo=o("GroupViTConfig"),omo=o(" (GroupViT model)"),rmo=l(),Pg=a("li"),afe=a("strong"),tmo=o("hubert"),amo=o(" \u2014 "),IN=a("a"),nmo=o("HubertConfig"),smo=o(" (Hubert model)"),lmo=l(),Bg=a("li"),nfe=a("strong"),imo=o("ibert"),dmo=o(" \u2014 "),NN=a("a"),cmo=o("IBertConfig"),mmo=o(" (I-BERT model)"),fmo=l(),Ig=a("li"),sfe=a("strong"),gmo=o("imagegpt"),hmo=o(" \u2014 "),qN=a("a"),umo=o("ImageGPTConfig"),pmo=o(" (ImageGPT model)"),_mo=l(),Ng=a("li"),lfe=a("strong"),bmo=o("layoutlm"),vmo=o(" \u2014 "),jN=a("a"),Fmo=o("LayoutLMConfig"),Tmo=o(" (LayoutLM model)"),Mmo=l(),qg=a("li"),ife=a("strong"),Emo=o("layoutlmv2"),Cmo=o(" \u2014 "),DN=a("a"),wmo=o("LayoutLMv2Config"),Amo=o(" (LayoutLMv2 model)"),Lmo=l(),jg=a("li"),dfe=a("strong"),ymo=o("layoutlmv3"),xmo=o(" \u2014 "),GN=a("a"),$mo=o("LayoutLMv3Config"),kmo=o(" (LayoutLMv3 model)"),Smo=l(),Dg=a("li"),cfe=a("strong"),Rmo=o("led"),Pmo=o(" \u2014 "),ON=a("a"),Bmo=o("LEDConfig"),Imo=o(" (LED model)"),Nmo=l(),Gg=a("li"),mfe=a("strong"),qmo=o("levit"),jmo=o(" \u2014 "),VN=a("a"),Dmo=o("LevitConfig"),Gmo=o(" (LeViT model)"),Omo=l(),Og=a("li"),ffe=a("strong"),Vmo=o("longformer"),Xmo=o(" \u2014 "),XN=a("a"),zmo=o("LongformerConfig"),Qmo=o(" (Longformer model)"),Wmo=l(),Vg=a("li"),gfe=a("strong"),Umo=o("longt5"),Hmo=o(" \u2014 "),zN=a("a"),Jmo=o("LongT5Config"),Ymo=o(" (LongT5 model)"),Zmo=l(),Xg=a("li"),hfe=a("strong"),Kmo=o("luke"),efo=o(" \u2014 "),QN=a("a"),ofo=o("LukeConfig"),rfo=o(" (LUKE model)"),tfo=l(),zg=a("li"),ufe=a("strong"),afo=o("lxmert"),nfo=o(" \u2014 "),WN=a("a"),sfo=o("LxmertConfig"),lfo=o(" (LXMERT model)"),ifo=l(),Qg=a("li"),pfe=a("strong"),dfo=o("m2m_100"),cfo=o(" \u2014 "),UN=a("a"),mfo=o("M2M100Config"),ffo=o(" (M2M100 model)"),gfo=l(),Wg=a("li"),_fe=a("strong"),hfo=o("marian"),ufo=o(" \u2014 "),HN=a("a"),pfo=o("MarianConfig"),_fo=o(" (Marian model)"),bfo=l(),Ug=a("li"),bfe=a("strong"),vfo=o("markuplm"),Ffo=o(" \u2014 "),JN=a("a"),Tfo=o("MarkupLMConfig"),Mfo=o(" (MarkupLM model)"),Efo=l(),Hg=a("li"),vfe=a("strong"),Cfo=o("maskformer"),wfo=o(" \u2014 "),YN=a("a"),Afo=o("MaskFormerConfig"),Lfo=o(" (MaskFormer model)"),yfo=l(),Jg=a("li"),Ffe=a("strong"),xfo=o("mbart"),$fo=o(" \u2014 "),ZN=a("a"),kfo=o("MBartConfig"),Sfo=o(" (mBART model)"),Rfo=l(),Yg=a("li"),Tfe=a("strong"),Pfo=o("mctct"),Bfo=o(" \u2014 "),KN=a("a"),Ifo=o("MCTCTConfig"),Nfo=o(" (M-CTC-T model)"),qfo=l(),Zg=a("li"),Mfe=a("strong"),jfo=o("megatron-bert"),Dfo=o(" \u2014 "),eq=a("a"),Gfo=o("MegatronBertConfig"),Ofo=o(" (Megatron-BERT model)"),Vfo=l(),Kg=a("li"),Efe=a("strong"),Xfo=o("mobilebert"),zfo=o(" \u2014 "),oq=a("a"),Qfo=o("MobileBertConfig"),Wfo=o(" (MobileBERT model)"),Ufo=l(),eh=a("li"),Cfe=a("strong"),Hfo=o("mobilevit"),Jfo=o(" \u2014 "),rq=a("a"),Yfo=o("MobileViTConfig"),Zfo=o(" (MobileViT model)"),Kfo=l(),oh=a("li"),wfe=a("strong"),ego=o("mpnet"),ogo=o(" \u2014 "),tq=a("a"),rgo=o("MPNetConfig"),tgo=o(" (MPNet model)"),ago=l(),rh=a("li"),Afe=a("strong"),ngo=o("mt5"),sgo=o(" \u2014 "),aq=a("a"),lgo=o("MT5Config"),igo=o(" (MT5 model)"),dgo=l(),th=a("li"),Lfe=a("strong"),cgo=o("mvp"),mgo=o(" \u2014 "),nq=a("a"),fgo=o("MvpConfig"),ggo=o(" (MVP model)"),hgo=l(),ah=a("li"),yfe=a("strong"),ugo=o("nezha"),pgo=o(" \u2014 "),sq=a("a"),_go=o("NezhaConfig"),bgo=o(" (Nezha model)"),vgo=l(),nh=a("li"),xfe=a("strong"),Fgo=o("nystromformer"),Tgo=o(" \u2014 "),lq=a("a"),Mgo=o("NystromformerConfig"),Ego=o(" (Nystr\xF6mformer model)"),Cgo=l(),sh=a("li"),$fe=a("strong"),wgo=o("openai-gpt"),Ago=o(" \u2014 "),iq=a("a"),Lgo=o("OpenAIGPTConfig"),ygo=o(" (OpenAI GPT model)"),xgo=l(),lh=a("li"),kfe=a("strong"),$go=o("opt"),kgo=o(" \u2014 "),dq=a("a"),Sgo=o("OPTConfig"),Rgo=o(" (OPT model)"),Pgo=l(),ih=a("li"),Sfe=a("strong"),Bgo=o("owlvit"),Igo=o(" \u2014 "),cq=a("a"),Ngo=o("OwlViTConfig"),qgo=o(" (OWL-ViT model)"),jgo=l(),dh=a("li"),Rfe=a("strong"),Dgo=o("pegasus"),Ggo=o(" \u2014 "),mq=a("a"),Ogo=o("PegasusConfig"),Vgo=o(" (Pegasus model)"),Xgo=l(),ch=a("li"),Pfe=a("strong"),zgo=o("pegasus_x"),Qgo=o(" \u2014 "),fq=a("a"),Wgo=o("PegasusXConfig"),Ugo=o(" (PEGASUS-X model)"),Hgo=l(),mh=a("li"),Bfe=a("strong"),Jgo=o("perceiver"),Ygo=o(" \u2014 "),gq=a("a"),Zgo=o("PerceiverConfig"),Kgo=o(" (Perceiver model)"),eho=l(),fh=a("li"),Ife=a("strong"),oho=o("plbart"),rho=o(" \u2014 "),hq=a("a"),tho=o("PLBartConfig"),aho=o(" (PLBart model)"),nho=l(),gh=a("li"),Nfe=a("strong"),sho=o("poolformer"),lho=o(" \u2014 "),uq=a("a"),iho=o("PoolFormerConfig"),dho=o(" (PoolFormer model)"),cho=l(),hh=a("li"),qfe=a("strong"),mho=o("prophetnet"),fho=o(" \u2014 "),pq=a("a"),gho=o("ProphetNetConfig"),hho=o(" (ProphetNet model)"),uho=l(),uh=a("li"),jfe=a("strong"),pho=o("qdqbert"),_ho=o(" \u2014 "),_q=a("a"),bho=o("QDQBertConfig"),vho=o(" (QDQBert model)"),Fho=l(),ph=a("li"),Dfe=a("strong"),Tho=o("rag"),Mho=o(" \u2014 "),bq=a("a"),Eho=o("RagConfig"),Cho=o(" (RAG model)"),who=l(),_h=a("li"),Gfe=a("strong"),Aho=o("realm"),Lho=o(" \u2014 "),vq=a("a"),yho=o("RealmConfig"),xho=o(" (REALM model)"),$ho=l(),bh=a("li"),Ofe=a("strong"),kho=o("reformer"),Sho=o(" \u2014 "),Fq=a("a"),Rho=o("ReformerConfig"),Pho=o(" (Reformer model)"),Bho=l(),vh=a("li"),Vfe=a("strong"),Iho=o("regnet"),Nho=o(" \u2014 "),Tq=a("a"),qho=o("RegNetConfig"),jho=o(" (RegNet model)"),Dho=l(),Fh=a("li"),Xfe=a("strong"),Gho=o("rembert"),Oho=o(" \u2014 "),Mq=a("a"),Vho=o("RemBertConfig"),Xho=o(" (RemBERT model)"),zho=l(),Th=a("li"),zfe=a("strong"),Qho=o("resnet"),Who=o(" \u2014 "),Eq=a("a"),Uho=o("ResNetConfig"),Hho=o(" (ResNet model)"),Jho=l(),Mh=a("li"),Qfe=a("strong"),Yho=o("retribert"),Zho=o(" \u2014 "),Cq=a("a"),Kho=o("RetriBertConfig"),euo=o(" (RetriBERT model)"),ouo=l(),Eh=a("li"),Wfe=a("strong"),ruo=o("roberta"),tuo=o(" \u2014 "),wq=a("a"),auo=o("RobertaConfig"),nuo=o(" (RoBERTa model)"),suo=l(),Ch=a("li"),Ufe=a("strong"),luo=o("roformer"),iuo=o(" \u2014 "),Aq=a("a"),duo=o("RoFormerConfig"),cuo=o(" (RoFormer model)"),muo=l(),wh=a("li"),Hfe=a("strong"),fuo=o("segformer"),guo=o(" \u2014 "),Lq=a("a"),huo=o("SegformerConfig"),uuo=o(" (SegFormer model)"),puo=l(),Ah=a("li"),Jfe=a("strong"),_uo=o("sew"),buo=o(" \u2014 "),yq=a("a"),vuo=o("SEWConfig"),Fuo=o(" (SEW model)"),Tuo=l(),Lh=a("li"),Yfe=a("strong"),Muo=o("sew-d"),Euo=o(" \u2014 "),xq=a("a"),Cuo=o("SEWDConfig"),wuo=o(" (SEW-D model)"),Auo=l(),yh=a("li"),Zfe=a("strong"),Luo=o("speech-encoder-decoder"),yuo=o(" \u2014 "),$q=a("a"),xuo=o("SpeechEncoderDecoderConfig"),$uo=o(" (Speech Encoder decoder model)"),kuo=l(),xh=a("li"),Kfe=a("strong"),Suo=o("speech_to_text"),Ruo=o(" \u2014 "),kq=a("a"),Puo=o("Speech2TextConfig"),Buo=o(" (Speech2Text model)"),Iuo=l(),$h=a("li"),ege=a("strong"),Nuo=o("speech_to_text_2"),quo=o(" \u2014 "),Sq=a("a"),juo=o("Speech2Text2Config"),Duo=o(" (Speech2Text2 model)"),Guo=l(),kh=a("li"),oge=a("strong"),Ouo=o("splinter"),Vuo=o(" \u2014 "),Rq=a("a"),Xuo=o("SplinterConfig"),zuo=o(" (Splinter model)"),Quo=l(),Sh=a("li"),rge=a("strong"),Wuo=o("squeezebert"),Uuo=o(" \u2014 "),Pq=a("a"),Huo=o("SqueezeBertConfig"),Juo=o(" (SqueezeBERT model)"),Yuo=l(),Rh=a("li"),tge=a("strong"),Zuo=o("swin"),Kuo=o(" \u2014 "),Bq=a("a"),epo=o("SwinConfig"),opo=o(" (Swin Transformer model)"),rpo=l(),Ph=a("li"),age=a("strong"),tpo=o("swinv2"),apo=o(" \u2014 "),Iq=a("a"),npo=o("Swinv2Config"),spo=o(" (Swin Transformer V2 model)"),lpo=l(),Bh=a("li"),nge=a("strong"),ipo=o("t5"),dpo=o(" \u2014 "),Nq=a("a"),cpo=o("T5Config"),mpo=o(" (T5 model)"),fpo=l(),Ih=a("li"),sge=a("strong"),gpo=o("tapas"),hpo=o(" \u2014 "),qq=a("a"),upo=o("TapasConfig"),ppo=o(" (TAPAS model)"),_po=l(),Nh=a("li"),lge=a("strong"),bpo=o("time_series_transformer"),vpo=o(" \u2014 "),jq=a("a"),Fpo=o("TimeSeriesTransformerConfig"),Tpo=o(" (Time Series Transformer model)"),Mpo=l(),qh=a("li"),ige=a("strong"),Epo=o("trajectory_transformer"),Cpo=o(" \u2014 "),Dq=a("a"),wpo=o("TrajectoryTransformerConfig"),Apo=o(" (Trajectory Transformer model)"),Lpo=l(),jh=a("li"),dge=a("strong"),ypo=o("transfo-xl"),xpo=o(" \u2014 "),Gq=a("a"),$po=o("TransfoXLConfig"),kpo=o(" (Transformer-XL model)"),Spo=l(),Dh=a("li"),cge=a("strong"),Rpo=o("trocr"),Ppo=o(" \u2014 "),Oq=a("a"),Bpo=o("TrOCRConfig"),Ipo=o(" (TrOCR model)"),Npo=l(),Gh=a("li"),mge=a("strong"),qpo=o("unispeech"),jpo=o(" \u2014 "),Vq=a("a"),Dpo=o("UniSpeechConfig"),Gpo=o(" (UniSpeech model)"),Opo=l(),Oh=a("li"),fge=a("strong"),Vpo=o("unispeech-sat"),Xpo=o(" \u2014 "),Xq=a("a"),zpo=o("UniSpeechSatConfig"),Qpo=o(" (UniSpeechSat model)"),Wpo=l(),Vh=a("li"),gge=a("strong"),Upo=o("van"),Hpo=o(" \u2014 "),zq=a("a"),Jpo=o("VanConfig"),Ypo=o(" (VAN model)"),Zpo=l(),Xh=a("li"),hge=a("strong"),Kpo=o("videomae"),e_o=o(" \u2014 "),Qq=a("a"),o_o=o("VideoMAEConfig"),r_o=o(" (VideoMAE model)"),t_o=l(),zh=a("li"),uge=a("strong"),a_o=o("vilt"),n_o=o(" \u2014 "),Wq=a("a"),s_o=o("ViltConfig"),l_o=o(" (ViLT model)"),i_o=l(),Qh=a("li"),pge=a("strong"),d_o=o("vision-encoder-decoder"),c_o=o(" \u2014 "),Uq=a("a"),m_o=o("VisionEncoderDecoderConfig"),f_o=o(" (Vision Encoder decoder model)"),g_o=l(),Wh=a("li"),_ge=a("strong"),h_o=o("vision-text-dual-encoder"),u_o=o(" \u2014 "),Hq=a("a"),p_o=o("VisionTextDualEncoderConfig"),__o=o(" (VisionTextDualEncoder model)"),b_o=l(),Uh=a("li"),bge=a("strong"),v_o=o("visual_bert"),F_o=o(" \u2014 "),Jq=a("a"),T_o=o("VisualBertConfig"),M_o=o(" (VisualBERT model)"),E_o=l(),Hh=a("li"),vge=a("strong"),C_o=o("vit"),w_o=o(" \u2014 "),Yq=a("a"),A_o=o("ViTConfig"),L_o=o(" (ViT model)"),y_o=l(),Jh=a("li"),Fge=a("strong"),x_o=o("vit_mae"),$_o=o(" \u2014 "),Zq=a("a"),k_o=o("ViTMAEConfig"),S_o=o(" (ViTMAE model)"),R_o=l(),Yh=a("li"),Tge=a("strong"),P_o=o("vit_msn"),B_o=o(" \u2014 "),Kq=a("a"),I_o=o("ViTMSNConfig"),N_o=o(" (ViTMSN model)"),q_o=l(),Zh=a("li"),Mge=a("strong"),j_o=o("wav2vec2"),D_o=o(" \u2014 "),ej=a("a"),G_o=o("Wav2Vec2Config"),O_o=o(" (Wav2Vec2 model)"),V_o=l(),Kh=a("li"),Ege=a("strong"),X_o=o("wav2vec2-conformer"),z_o=o(" \u2014 "),oj=a("a"),Q_o=o("Wav2Vec2ConformerConfig"),W_o=o(" (Wav2Vec2-Conformer model)"),U_o=l(),eu=a("li"),Cge=a("strong"),H_o=o("wavlm"),J_o=o(" \u2014 "),rj=a("a"),Y_o=o("WavLMConfig"),Z_o=o(" (WavLM model)"),K_o=l(),ou=a("li"),wge=a("strong"),e1o=o("whisper"),o1o=o(" \u2014 "),tj=a("a"),r1o=o("WhisperConfig"),t1o=o(" (Whisper model)"),a1o=l(),ru=a("li"),Age=a("strong"),n1o=o("xclip"),s1o=o(" \u2014 "),aj=a("a"),l1o=o("XCLIPConfig"),i1o=o(" (X-CLIP model)"),d1o=l(),tu=a("li"),Lge=a("strong"),c1o=o("xglm"),m1o=o(" \u2014 "),nj=a("a"),f1o=o("XGLMConfig"),g1o=o(" (XGLM model)"),h1o=l(),au=a("li"),yge=a("strong"),u1o=o("xlm"),p1o=o(" \u2014 "),sj=a("a"),_1o=o("XLMConfig"),b1o=o(" (XLM model)"),v1o=l(),nu=a("li"),xge=a("strong"),F1o=o("xlm-prophetnet"),T1o=o(" \u2014 "),lj=a("a"),M1o=o("XLMProphetNetConfig"),E1o=o(" (XLM-ProphetNet model)"),C1o=l(),su=a("li"),$ge=a("strong"),w1o=o("xlm-roberta"),A1o=o(" \u2014 "),ij=a("a"),L1o=o("XLMRobertaConfig"),y1o=o(" (XLM-RoBERTa model)"),x1o=l(),lu=a("li"),kge=a("strong"),$1o=o("xlm-roberta-xl"),k1o=o(" \u2014 "),dj=a("a"),S1o=o("XLMRobertaXLConfig"),R1o=o(" (XLM-RoBERTa-XL model)"),P1o=l(),iu=a("li"),Sge=a("strong"),B1o=o("xlnet"),I1o=o(" \u2014 "),cj=a("a"),N1o=o("XLNetConfig"),q1o=o(" (XLNet model)"),j1o=l(),du=a("li"),Rge=a("strong"),D1o=o("yolos"),G1o=o(" \u2014 "),mj=a("a"),O1o=o("YolosConfig"),V1o=o(" (YOLOS model)"),X1o=l(),cu=a("li"),Pge=a("strong"),z1o=o("yoso"),Q1o=o(" \u2014 "),fj=a("a"),W1o=o("YosoConfig"),U1o=o(" (YOSO model)"),H1o=l(),F(mu.$$.fragment),J1o=l(),fu=a("div"),F(Nx.$$.fragment),Y1o=l(),Bge=a("p"),Z1o=o("Register a new configuration for this class."),koo=l(),vd=a("h2"),gu=a("a"),Ige=a("span"),F(qx.$$.fragment),K1o=l(),Nge=a("span"),e2o=o("AutoTokenizer"),Soo=l(),So=a("div"),F(jx.$$.fragment),o2o=l(),Dx=a("p"),r2o=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),gj=a("a"),t2o=o("AutoTokenizer.from_pretrained()"),a2o=o(" class method."),n2o=l(),Gx=a("p"),s2o=o("This class cannot be instantiated directly using "),qge=a("code"),l2o=o("__init__()"),i2o=o(" (throws an error)."),d2o=l(),Nr=a("div"),F(Ox.$$.fragment),c2o=l(),jge=a("p"),m2o=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),f2o=l(),Za=a("p"),g2o=o("The tokenizer class to instantiate is selected based on the "),Dge=a("code"),h2o=o("model_type"),u2o=o(` property of the config object (either
passed as an argument or loaded from `),Gge=a("code"),p2o=o("pretrained_model_name_or_path"),_2o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oge=a("code"),b2o=o("pretrained_model_name_or_path"),v2o=o(":"),F2o=l(),k=a("ul"),cs=a("li"),Vge=a("strong"),T2o=o("albert"),M2o=o(" \u2014 "),hj=a("a"),E2o=o("AlbertTokenizer"),C2o=o(" or "),uj=a("a"),w2o=o("AlbertTokenizerFast"),A2o=o(" (ALBERT model)"),L2o=l(),ms=a("li"),Xge=a("strong"),y2o=o("bart"),x2o=o(" \u2014 "),pj=a("a"),$2o=o("BartTokenizer"),k2o=o(" or "),_j=a("a"),S2o=o("BartTokenizerFast"),R2o=o(" (BART model)"),P2o=l(),fs=a("li"),zge=a("strong"),B2o=o("barthez"),I2o=o(" \u2014 "),bj=a("a"),N2o=o("BarthezTokenizer"),q2o=o(" or "),vj=a("a"),j2o=o("BarthezTokenizerFast"),D2o=o(" (BARThez model)"),G2o=l(),hu=a("li"),Qge=a("strong"),O2o=o("bartpho"),V2o=o(" \u2014 "),Fj=a("a"),X2o=o("BartphoTokenizer"),z2o=o(" (BARTpho model)"),Q2o=l(),gs=a("li"),Wge=a("strong"),W2o=o("bert"),U2o=o(" \u2014 "),Tj=a("a"),H2o=o("BertTokenizer"),J2o=o(" or "),Mj=a("a"),Y2o=o("BertTokenizerFast"),Z2o=o(" (BERT model)"),K2o=l(),uu=a("li"),Uge=a("strong"),ebo=o("bert-generation"),obo=o(" \u2014 "),Ej=a("a"),rbo=o("BertGenerationTokenizer"),tbo=o(" (Bert Generation model)"),abo=l(),pu=a("li"),Hge=a("strong"),nbo=o("bert-japanese"),sbo=o(" \u2014 "),Cj=a("a"),lbo=o("BertJapaneseTokenizer"),ibo=o(" (BertJapanese model)"),dbo=l(),_u=a("li"),Jge=a("strong"),cbo=o("bertweet"),mbo=o(" \u2014 "),wj=a("a"),fbo=o("BertweetTokenizer"),gbo=o(" (BERTweet model)"),hbo=l(),hs=a("li"),Yge=a("strong"),ubo=o("big_bird"),pbo=o(" \u2014 "),Aj=a("a"),_bo=o("BigBirdTokenizer"),bbo=o(" or "),Lj=a("a"),vbo=o("BigBirdTokenizerFast"),Fbo=o(" (BigBird model)"),Tbo=l(),us=a("li"),Zge=a("strong"),Mbo=o("bigbird_pegasus"),Ebo=o(" \u2014 "),yj=a("a"),Cbo=o("PegasusTokenizer"),wbo=o(" or "),xj=a("a"),Abo=o("PegasusTokenizerFast"),Lbo=o(" (BigBird-Pegasus model)"),ybo=l(),ps=a("li"),Kge=a("strong"),xbo=o("blenderbot"),$bo=o(" \u2014 "),$j=a("a"),kbo=o("BlenderbotTokenizer"),Sbo=o(" or "),kj=a("a"),Rbo=o("BlenderbotTokenizerFast"),Pbo=o(" (Blenderbot model)"),Bbo=l(),bu=a("li"),ehe=a("strong"),Ibo=o("blenderbot-small"),Nbo=o(" \u2014 "),Sj=a("a"),qbo=o("BlenderbotSmallTokenizer"),jbo=o(" (BlenderbotSmall model)"),Dbo=l(),vu=a("li"),ohe=a("strong"),Gbo=o("bloom"),Obo=o(" \u2014 "),Rj=a("a"),Vbo=o("BloomTokenizerFast"),Xbo=o(" (BLOOM model)"),zbo=l(),Fu=a("li"),rhe=a("strong"),Qbo=o("byt5"),Wbo=o(" \u2014 "),Pj=a("a"),Ubo=o("ByT5Tokenizer"),Hbo=o(" (ByT5 model)"),Jbo=l(),_s=a("li"),the=a("strong"),Ybo=o("camembert"),Zbo=o(" \u2014 "),Bj=a("a"),Kbo=o("CamembertTokenizer"),evo=o(" or "),Ij=a("a"),ovo=o("CamembertTokenizerFast"),rvo=o(" (CamemBERT model)"),tvo=l(),Tu=a("li"),ahe=a("strong"),avo=o("canine"),nvo=o(" \u2014 "),Nj=a("a"),svo=o("CanineTokenizer"),lvo=o(" (CANINE model)"),ivo=l(),bs=a("li"),nhe=a("strong"),dvo=o("clip"),cvo=o(" \u2014 "),qj=a("a"),mvo=o("CLIPTokenizer"),fvo=o(" or "),jj=a("a"),gvo=o("CLIPTokenizerFast"),hvo=o(" (CLIP model)"),uvo=l(),vs=a("li"),she=a("strong"),pvo=o("codegen"),_vo=o(" \u2014 "),Dj=a("a"),bvo=o("CodeGenTokenizer"),vvo=o(" or "),Gj=a("a"),Fvo=o("CodeGenTokenizerFast"),Tvo=o(" (CodeGen model)"),Mvo=l(),Fs=a("li"),lhe=a("strong"),Evo=o("convbert"),Cvo=o(" \u2014 "),Oj=a("a"),wvo=o("ConvBertTokenizer"),Avo=o(" or "),Vj=a("a"),Lvo=o("ConvBertTokenizerFast"),yvo=o(" (ConvBERT model)"),xvo=l(),Ts=a("li"),ihe=a("strong"),$vo=o("cpm"),kvo=o(" \u2014 "),Xj=a("a"),Svo=o("CpmTokenizer"),Rvo=o(" or "),zj=a("a"),Pvo=o("CpmTokenizerFast"),Bvo=o(" (CPM model)"),Ivo=l(),Mu=a("li"),dhe=a("strong"),Nvo=o("ctrl"),qvo=o(" \u2014 "),Qj=a("a"),jvo=o("CTRLTokenizer"),Dvo=o(" (CTRL model)"),Gvo=l(),Ms=a("li"),che=a("strong"),Ovo=o("data2vec-text"),Vvo=o(" \u2014 "),Wj=a("a"),Xvo=o("RobertaTokenizer"),zvo=o(" or "),Uj=a("a"),Qvo=o("RobertaTokenizerFast"),Wvo=o(" (Data2VecText model)"),Uvo=l(),Es=a("li"),mhe=a("strong"),Hvo=o("deberta"),Jvo=o(" \u2014 "),Hj=a("a"),Yvo=o("DebertaTokenizer"),Zvo=o(" or "),Jj=a("a"),Kvo=o("DebertaTokenizerFast"),eFo=o(" (DeBERTa model)"),oFo=l(),Cs=a("li"),fhe=a("strong"),rFo=o("deberta-v2"),tFo=o(" \u2014 "),Yj=a("a"),aFo=o("DebertaV2Tokenizer"),nFo=o(" or "),Zj=a("a"),sFo=o("DebertaV2TokenizerFast"),lFo=o(" (DeBERTa-v2 model)"),iFo=l(),ws=a("li"),ghe=a("strong"),dFo=o("distilbert"),cFo=o(" \u2014 "),Kj=a("a"),mFo=o("DistilBertTokenizer"),fFo=o(" or "),eD=a("a"),gFo=o("DistilBertTokenizerFast"),hFo=o(" (DistilBERT model)"),uFo=l(),As=a("li"),hhe=a("strong"),pFo=o("dpr"),_Fo=o(" \u2014 "),oD=a("a"),bFo=o("DPRQuestionEncoderTokenizer"),vFo=o(" or "),rD=a("a"),FFo=o("DPRQuestionEncoderTokenizerFast"),TFo=o(" (DPR model)"),MFo=l(),Ls=a("li"),uhe=a("strong"),EFo=o("electra"),CFo=o(" \u2014 "),tD=a("a"),wFo=o("ElectraTokenizer"),AFo=o(" or "),aD=a("a"),LFo=o("ElectraTokenizerFast"),yFo=o(" (ELECTRA model)"),xFo=l(),ys=a("li"),phe=a("strong"),$Fo=o("ernie"),kFo=o(" \u2014 "),nD=a("a"),SFo=o("BertTokenizer"),RFo=o(" or "),sD=a("a"),PFo=o("BertTokenizerFast"),BFo=o(" (ERNIE model)"),IFo=l(),Eu=a("li"),_he=a("strong"),NFo=o("flaubert"),qFo=o(" \u2014 "),lD=a("a"),jFo=o("FlaubertTokenizer"),DFo=o(" (FlauBERT model)"),GFo=l(),xs=a("li"),bhe=a("strong"),OFo=o("fnet"),VFo=o(" \u2014 "),iD=a("a"),XFo=o("FNetTokenizer"),zFo=o(" or "),dD=a("a"),QFo=o("FNetTokenizerFast"),WFo=o(" (FNet model)"),UFo=l(),Cu=a("li"),vhe=a("strong"),HFo=o("fsmt"),JFo=o(" \u2014 "),cD=a("a"),YFo=o("FSMTTokenizer"),ZFo=o(" (FairSeq Machine-Translation model)"),KFo=l(),$s=a("li"),Fhe=a("strong"),eTo=o("funnel"),oTo=o(" \u2014 "),mD=a("a"),rTo=o("FunnelTokenizer"),tTo=o(" or "),fD=a("a"),aTo=o("FunnelTokenizerFast"),nTo=o(" (Funnel Transformer model)"),sTo=l(),ks=a("li"),The=a("strong"),lTo=o("gpt2"),iTo=o(" \u2014 "),gD=a("a"),dTo=o("GPT2Tokenizer"),cTo=o(" or "),hD=a("a"),mTo=o("GPT2TokenizerFast"),fTo=o(" (OpenAI GPT-2 model)"),gTo=l(),Ss=a("li"),Mhe=a("strong"),hTo=o("gpt_neo"),uTo=o(" \u2014 "),uD=a("a"),pTo=o("GPT2Tokenizer"),_To=o(" or "),pD=a("a"),bTo=o("GPT2TokenizerFast"),vTo=o(" (GPT Neo model)"),FTo=l(),wu=a("li"),Ehe=a("strong"),TTo=o("gpt_neox"),MTo=o(" \u2014 "),_D=a("a"),ETo=o("GPTNeoXTokenizerFast"),CTo=o(" (GPT NeoX model)"),wTo=l(),Au=a("li"),Che=a("strong"),ATo=o("gpt_neox_japanese"),LTo=o(" \u2014 "),bD=a("a"),yTo=o("GPTNeoXJapaneseTokenizer"),xTo=o(" (GPT NeoX Japanese model)"),$To=l(),Rs=a("li"),whe=a("strong"),kTo=o("gptj"),STo=o(" \u2014 "),vD=a("a"),RTo=o("GPT2Tokenizer"),PTo=o(" or "),FD=a("a"),BTo=o("GPT2TokenizerFast"),ITo=o(" (GPT-J model)"),NTo=l(),Ps=a("li"),Ahe=a("strong"),qTo=o("groupvit"),jTo=o(" \u2014 "),TD=a("a"),DTo=o("CLIPTokenizer"),GTo=o(" or "),MD=a("a"),OTo=o("CLIPTokenizerFast"),VTo=o(" (GroupViT model)"),XTo=l(),Bs=a("li"),Lhe=a("strong"),zTo=o("herbert"),QTo=o(" \u2014 "),ED=a("a"),WTo=o("HerbertTokenizer"),UTo=o(" or "),CD=a("a"),HTo=o("HerbertTokenizerFast"),JTo=o(" (HerBERT model)"),YTo=l(),Lu=a("li"),yhe=a("strong"),ZTo=o("hubert"),KTo=o(" \u2014 "),wD=a("a"),eMo=o("Wav2Vec2CTCTokenizer"),oMo=o(" (Hubert model)"),rMo=l(),Is=a("li"),xhe=a("strong"),tMo=o("ibert"),aMo=o(" \u2014 "),AD=a("a"),nMo=o("RobertaTokenizer"),sMo=o(" or "),LD=a("a"),lMo=o("RobertaTokenizerFast"),iMo=o(" (I-BERT model)"),dMo=l(),Ns=a("li"),$he=a("strong"),cMo=o("layoutlm"),mMo=o(" \u2014 "),yD=a("a"),fMo=o("LayoutLMTokenizer"),gMo=o(" or "),xD=a("a"),hMo=o("LayoutLMTokenizerFast"),uMo=o(" (LayoutLM model)"),pMo=l(),qs=a("li"),khe=a("strong"),_Mo=o("layoutlmv2"),bMo=o(" \u2014 "),$D=a("a"),vMo=o("LayoutLMv2Tokenizer"),FMo=o(" or "),kD=a("a"),TMo=o("LayoutLMv2TokenizerFast"),MMo=o(" (LayoutLMv2 model)"),EMo=l(),js=a("li"),She=a("strong"),CMo=o("layoutlmv3"),wMo=o(" \u2014 "),SD=a("a"),AMo=o("LayoutLMv3Tokenizer"),LMo=o(" or "),RD=a("a"),yMo=o("LayoutLMv3TokenizerFast"),xMo=o(" (LayoutLMv3 model)"),$Mo=l(),Ds=a("li"),Rhe=a("strong"),kMo=o("layoutxlm"),SMo=o(" \u2014 "),PD=a("a"),RMo=o("LayoutXLMTokenizer"),PMo=o(" or "),BD=a("a"),BMo=o("LayoutXLMTokenizerFast"),IMo=o(" (LayoutXLM model)"),NMo=l(),Gs=a("li"),Phe=a("strong"),qMo=o("led"),jMo=o(" \u2014 "),ID=a("a"),DMo=o("LEDTokenizer"),GMo=o(" or "),ND=a("a"),OMo=o("LEDTokenizerFast"),VMo=o(" (LED model)"),XMo=l(),Os=a("li"),Bhe=a("strong"),zMo=o("longformer"),QMo=o(" \u2014 "),qD=a("a"),WMo=o("LongformerTokenizer"),UMo=o(" or "),jD=a("a"),HMo=o("LongformerTokenizerFast"),JMo=o(" (Longformer model)"),YMo=l(),Vs=a("li"),Ihe=a("strong"),ZMo=o("longt5"),KMo=o(" \u2014 "),DD=a("a"),eEo=o("T5Tokenizer"),oEo=o(" or "),GD=a("a"),rEo=o("T5TokenizerFast"),tEo=o(" (LongT5 model)"),aEo=l(),yu=a("li"),Nhe=a("strong"),nEo=o("luke"),sEo=o(" \u2014 "),OD=a("a"),lEo=o("LukeTokenizer"),iEo=o(" (LUKE model)"),dEo=l(),Xs=a("li"),qhe=a("strong"),cEo=o("lxmert"),mEo=o(" \u2014 "),VD=a("a"),fEo=o("LxmertTokenizer"),gEo=o(" or "),XD=a("a"),hEo=o("LxmertTokenizerFast"),uEo=o(" (LXMERT model)"),pEo=l(),xu=a("li"),jhe=a("strong"),_Eo=o("m2m_100"),bEo=o(" \u2014 "),zD=a("a"),vEo=o("M2M100Tokenizer"),FEo=o(" (M2M100 model)"),TEo=l(),$u=a("li"),Dhe=a("strong"),MEo=o("marian"),EEo=o(" \u2014 "),QD=a("a"),CEo=o("MarianTokenizer"),wEo=o(" (Marian model)"),AEo=l(),zs=a("li"),Ghe=a("strong"),LEo=o("mbart"),yEo=o(" \u2014 "),WD=a("a"),xEo=o("MBartTokenizer"),$Eo=o(" or "),UD=a("a"),kEo=o("MBartTokenizerFast"),SEo=o(" (mBART model)"),REo=l(),Qs=a("li"),Ohe=a("strong"),PEo=o("mbart50"),BEo=o(" \u2014 "),HD=a("a"),IEo=o("MBart50Tokenizer"),NEo=o(" or "),JD=a("a"),qEo=o("MBart50TokenizerFast"),jEo=o(" (mBART-50 model)"),DEo=l(),Ws=a("li"),Vhe=a("strong"),GEo=o("megatron-bert"),OEo=o(" \u2014 "),YD=a("a"),VEo=o("BertTokenizer"),XEo=o(" or "),ZD=a("a"),zEo=o("BertTokenizerFast"),QEo=o(" (Megatron-BERT model)"),WEo=l(),ku=a("li"),Xhe=a("strong"),UEo=o("mluke"),HEo=o(" \u2014 "),KD=a("a"),JEo=o("MLukeTokenizer"),YEo=o(" (mLUKE model)"),ZEo=l(),Us=a("li"),zhe=a("strong"),KEo=o("mobilebert"),e4o=o(" \u2014 "),eG=a("a"),o4o=o("MobileBertTokenizer"),r4o=o(" or "),oG=a("a"),t4o=o("MobileBertTokenizerFast"),a4o=o(" (MobileBERT model)"),n4o=l(),Hs=a("li"),Qhe=a("strong"),s4o=o("mpnet"),l4o=o(" \u2014 "),rG=a("a"),i4o=o("MPNetTokenizer"),d4o=o(" or "),tG=a("a"),c4o=o("MPNetTokenizerFast"),m4o=o(" (MPNet model)"),f4o=l(),Js=a("li"),Whe=a("strong"),g4o=o("mt5"),h4o=o(" \u2014 "),aG=a("a"),u4o=o("MT5Tokenizer"),p4o=o(" or "),nG=a("a"),_4o=o("MT5TokenizerFast"),b4o=o(" (MT5 model)"),v4o=l(),Ys=a("li"),Uhe=a("strong"),F4o=o("mvp"),T4o=o(" \u2014 "),sG=a("a"),M4o=o("MvpTokenizer"),E4o=o(" or "),lG=a("a"),C4o=o("MvpTokenizerFast"),w4o=o(" (MVP model)"),A4o=l(),Zs=a("li"),Hhe=a("strong"),L4o=o("nezha"),y4o=o(" \u2014 "),iG=a("a"),x4o=o("BertTokenizer"),$4o=o(" or "),dG=a("a"),k4o=o("BertTokenizerFast"),S4o=o(" (Nezha model)"),R4o=l(),Ks=a("li"),Jhe=a("strong"),P4o=o("nllb"),B4o=o(" \u2014 "),cG=a("a"),I4o=o("NllbTokenizer"),N4o=o(" or "),mG=a("a"),q4o=o("NllbTokenizerFast"),j4o=o(" (NLLB model)"),D4o=l(),el=a("li"),Yhe=a("strong"),G4o=o("nystromformer"),O4o=o(" \u2014 "),fG=a("a"),V4o=o("AlbertTokenizer"),X4o=o(" or "),gG=a("a"),z4o=o("AlbertTokenizerFast"),Q4o=o(" (Nystr\xF6mformer model)"),W4o=l(),ol=a("li"),Zhe=a("strong"),U4o=o("openai-gpt"),H4o=o(" \u2014 "),hG=a("a"),J4o=o("OpenAIGPTTokenizer"),Y4o=o(" or "),uG=a("a"),Z4o=o("OpenAIGPTTokenizerFast"),K4o=o(" (OpenAI GPT model)"),eCo=l(),Su=a("li"),Khe=a("strong"),oCo=o("opt"),rCo=o(" \u2014 "),pG=a("a"),tCo=o("GPT2Tokenizer"),aCo=o(" (OPT model)"),nCo=l(),rl=a("li"),eue=a("strong"),sCo=o("owlvit"),lCo=o(" \u2014 "),_G=a("a"),iCo=o("CLIPTokenizer"),dCo=o(" or "),bG=a("a"),cCo=o("CLIPTokenizerFast"),mCo=o(" (OWL-ViT model)"),fCo=l(),tl=a("li"),oue=a("strong"),gCo=o("pegasus"),hCo=o(" \u2014 "),vG=a("a"),uCo=o("PegasusTokenizer"),pCo=o(" or "),FG=a("a"),_Co=o("PegasusTokenizerFast"),bCo=o(" (Pegasus model)"),vCo=l(),Ru=a("li"),rue=a("strong"),FCo=o("perceiver"),TCo=o(" \u2014 "),TG=a("a"),MCo=o("PerceiverTokenizer"),ECo=o(" (Perceiver model)"),CCo=l(),Pu=a("li"),tue=a("strong"),wCo=o("phobert"),ACo=o(" \u2014 "),MG=a("a"),LCo=o("PhobertTokenizer"),yCo=o(" (PhoBERT model)"),xCo=l(),Bu=a("li"),aue=a("strong"),$Co=o("plbart"),kCo=o(" \u2014 "),EG=a("a"),SCo=o("PLBartTokenizer"),RCo=o(" (PLBart model)"),PCo=l(),Iu=a("li"),nue=a("strong"),BCo=o("prophetnet"),ICo=o(" \u2014 "),CG=a("a"),NCo=o("ProphetNetTokenizer"),qCo=o(" (ProphetNet model)"),jCo=l(),al=a("li"),sue=a("strong"),DCo=o("qdqbert"),GCo=o(" \u2014 "),wG=a("a"),OCo=o("BertTokenizer"),VCo=o(" or "),AG=a("a"),XCo=o("BertTokenizerFast"),zCo=o(" (QDQBert model)"),QCo=l(),Nu=a("li"),lue=a("strong"),WCo=o("rag"),UCo=o(" \u2014 "),LG=a("a"),HCo=o("RagTokenizer"),JCo=o(" (RAG model)"),YCo=l(),nl=a("li"),iue=a("strong"),ZCo=o("realm"),KCo=o(" \u2014 "),yG=a("a"),e3o=o("RealmTokenizer"),o3o=o(" or "),xG=a("a"),r3o=o("RealmTokenizerFast"),t3o=o(" (REALM model)"),a3o=l(),sl=a("li"),due=a("strong"),n3o=o("reformer"),s3o=o(" \u2014 "),$G=a("a"),l3o=o("ReformerTokenizer"),i3o=o(" or "),kG=a("a"),d3o=o("ReformerTokenizerFast"),c3o=o(" (Reformer model)"),m3o=l(),ll=a("li"),cue=a("strong"),f3o=o("rembert"),g3o=o(" \u2014 "),SG=a("a"),h3o=o("RemBertTokenizer"),u3o=o(" or "),RG=a("a"),p3o=o("RemBertTokenizerFast"),_3o=o(" (RemBERT model)"),b3o=l(),il=a("li"),mue=a("strong"),v3o=o("retribert"),F3o=o(" \u2014 "),PG=a("a"),T3o=o("RetriBertTokenizer"),M3o=o(" or "),BG=a("a"),E3o=o("RetriBertTokenizerFast"),C3o=o(" (RetriBERT model)"),w3o=l(),dl=a("li"),fue=a("strong"),A3o=o("roberta"),L3o=o(" \u2014 "),IG=a("a"),y3o=o("RobertaTokenizer"),x3o=o(" or "),NG=a("a"),$3o=o("RobertaTokenizerFast"),k3o=o(" (RoBERTa model)"),S3o=l(),cl=a("li"),gue=a("strong"),R3o=o("roformer"),P3o=o(" \u2014 "),qG=a("a"),B3o=o("RoFormerTokenizer"),I3o=o(" or "),jG=a("a"),N3o=o("RoFormerTokenizerFast"),q3o=o(" (RoFormer model)"),j3o=l(),qu=a("li"),hue=a("strong"),D3o=o("speech_to_text"),G3o=o(" \u2014 "),DG=a("a"),O3o=o("Speech2TextTokenizer"),V3o=o(" (Speech2Text model)"),X3o=l(),ju=a("li"),uue=a("strong"),z3o=o("speech_to_text_2"),Q3o=o(" \u2014 "),GG=a("a"),W3o=o("Speech2Text2Tokenizer"),U3o=o(" (Speech2Text2 model)"),H3o=l(),ml=a("li"),pue=a("strong"),J3o=o("splinter"),Y3o=o(" \u2014 "),OG=a("a"),Z3o=o("SplinterTokenizer"),K3o=o(" or "),VG=a("a"),e5o=o("SplinterTokenizerFast"),o5o=o(" (Splinter model)"),r5o=l(),fl=a("li"),_ue=a("strong"),t5o=o("squeezebert"),a5o=o(" \u2014 "),XG=a("a"),n5o=o("SqueezeBertTokenizer"),s5o=o(" or "),zG=a("a"),l5o=o("SqueezeBertTokenizerFast"),i5o=o(" (SqueezeBERT model)"),d5o=l(),gl=a("li"),bue=a("strong"),c5o=o("t5"),m5o=o(" \u2014 "),QG=a("a"),f5o=o("T5Tokenizer"),g5o=o(" or "),WG=a("a"),h5o=o("T5TokenizerFast"),u5o=o(" (T5 model)"),p5o=l(),Du=a("li"),vue=a("strong"),_5o=o("tapas"),b5o=o(" \u2014 "),UG=a("a"),v5o=o("TapasTokenizer"),F5o=o(" (TAPAS model)"),T5o=l(),Gu=a("li"),Fue=a("strong"),M5o=o("tapex"),E5o=o(" \u2014 "),HG=a("a"),C5o=o("TapexTokenizer"),w5o=o(" (TAPEX model)"),A5o=l(),Ou=a("li"),Tue=a("strong"),L5o=o("transfo-xl"),y5o=o(" \u2014 "),JG=a("a"),x5o=o("TransfoXLTokenizer"),$5o=o(" (Transformer-XL model)"),k5o=l(),hl=a("li"),Mue=a("strong"),S5o=o("vilt"),R5o=o(" \u2014 "),YG=a("a"),P5o=o("BertTokenizer"),B5o=o(" or "),ZG=a("a"),I5o=o("BertTokenizerFast"),N5o=o(" (ViLT model)"),q5o=l(),ul=a("li"),Eue=a("strong"),j5o=o("visual_bert"),D5o=o(" \u2014 "),KG=a("a"),G5o=o("BertTokenizer"),O5o=o(" or "),eO=a("a"),V5o=o("BertTokenizerFast"),X5o=o(" (VisualBERT model)"),z5o=l(),Vu=a("li"),Cue=a("strong"),Q5o=o("wav2vec2"),W5o=o(" \u2014 "),oO=a("a"),U5o=o("Wav2Vec2CTCTokenizer"),H5o=o(" (Wav2Vec2 model)"),J5o=l(),Xu=a("li"),wue=a("strong"),Y5o=o("wav2vec2-conformer"),Z5o=o(" \u2014 "),rO=a("a"),K5o=o("Wav2Vec2CTCTokenizer"),e0o=o(" (Wav2Vec2-Conformer model)"),o0o=l(),zu=a("li"),Aue=a("strong"),r0o=o("wav2vec2_phoneme"),t0o=o(" \u2014 "),tO=a("a"),a0o=o("Wav2Vec2PhonemeCTCTokenizer"),n0o=o(" (Wav2Vec2Phoneme model)"),s0o=l(),Qu=a("li"),Lue=a("strong"),l0o=o("whisper"),i0o=o(" \u2014 "),aO=a("a"),d0o=o("WhisperTokenizer"),c0o=o(" (Whisper model)"),m0o=l(),pl=a("li"),yue=a("strong"),f0o=o("xclip"),g0o=o(" \u2014 "),nO=a("a"),h0o=o("CLIPTokenizer"),u0o=o(" or "),sO=a("a"),p0o=o("CLIPTokenizerFast"),_0o=o(" (X-CLIP model)"),b0o=l(),_l=a("li"),xue=a("strong"),v0o=o("xglm"),F0o=o(" \u2014 "),lO=a("a"),T0o=o("XGLMTokenizer"),M0o=o(" or "),iO=a("a"),E0o=o("XGLMTokenizerFast"),C0o=o(" (XGLM model)"),w0o=l(),Wu=a("li"),$ue=a("strong"),A0o=o("xlm"),L0o=o(" \u2014 "),dO=a("a"),y0o=o("XLMTokenizer"),x0o=o(" (XLM model)"),$0o=l(),Uu=a("li"),kue=a("strong"),k0o=o("xlm-prophetnet"),S0o=o(" \u2014 "),cO=a("a"),R0o=o("XLMProphetNetTokenizer"),P0o=o(" (XLM-ProphetNet model)"),B0o=l(),bl=a("li"),Sue=a("strong"),I0o=o("xlm-roberta"),N0o=o(" \u2014 "),mO=a("a"),q0o=o("XLMRobertaTokenizer"),j0o=o(" or "),fO=a("a"),D0o=o("XLMRobertaTokenizerFast"),G0o=o(" (XLM-RoBERTa model)"),O0o=l(),vl=a("li"),Rue=a("strong"),V0o=o("xlm-roberta-xl"),X0o=o(" \u2014 "),gO=a("a"),z0o=o("XLMRobertaTokenizer"),Q0o=o(" or "),hO=a("a"),W0o=o("XLMRobertaTokenizerFast"),U0o=o(" (XLM-RoBERTa-XL model)"),H0o=l(),Fl=a("li"),Pue=a("strong"),J0o=o("xlnet"),Y0o=o(" \u2014 "),uO=a("a"),Z0o=o("XLNetTokenizer"),K0o=o(" or "),pO=a("a"),ewo=o("XLNetTokenizerFast"),owo=o(" (XLNet model)"),rwo=l(),Tl=a("li"),Bue=a("strong"),two=o("yoso"),awo=o(" \u2014 "),_O=a("a"),nwo=o("AlbertTokenizer"),swo=o(" or "),bO=a("a"),lwo=o("AlbertTokenizerFast"),iwo=o(" (YOSO model)"),dwo=l(),F(Hu.$$.fragment),cwo=l(),Ju=a("div"),F(Vx.$$.fragment),mwo=l(),Iue=a("p"),fwo=o("Register a new tokenizer in this mapping."),Roo=l(),Fd=a("h2"),Yu=a("a"),Nue=a("span"),F(Xx.$$.fragment),gwo=l(),que=a("span"),hwo=o("AutoFeatureExtractor"),Poo=l(),Ro=a("div"),F(zx.$$.fragment),uwo=l(),Qx=a("p"),pwo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),vO=a("a"),_wo=o("AutoFeatureExtractor.from_pretrained()"),bwo=o(" class method."),vwo=l(),Wx=a("p"),Fwo=o("This class cannot be instantiated directly using "),jue=a("code"),Two=o("__init__()"),Mwo=o(" (throws an error)."),Ewo=l(),Ye=a("div"),F(Ux.$$.fragment),Cwo=l(),Due=a("p"),wwo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Awo=l(),Ka=a("p"),Lwo=o("The feature extractor class to instantiate is selected based on the "),Gue=a("code"),ywo=o("model_type"),xwo=o(` property of the config object
(either passed as an argument or loaded from `),Oue=a("code"),$wo=o("pretrained_model_name_or_path"),kwo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Vue=a("code"),Swo=o("pretrained_model_name_or_path"),Rwo=o(":"),Pwo=l(),z=a("ul"),Zu=a("li"),Xue=a("strong"),Bwo=o("beit"),Iwo=o(" \u2014 "),FO=a("a"),Nwo=o("BeitFeatureExtractor"),qwo=o(" (BEiT model)"),jwo=l(),Ku=a("li"),zue=a("strong"),Dwo=o("clip"),Gwo=o(" \u2014 "),TO=a("a"),Owo=o("CLIPFeatureExtractor"),Vwo=o(" (CLIP model)"),Xwo=l(),ep=a("li"),Que=a("strong"),zwo=o("conditional_detr"),Qwo=o(" \u2014 "),MO=a("a"),Wwo=o("ConditionalDetrFeatureExtractor"),Uwo=o(" (Conditional DETR model)"),Hwo=l(),op=a("li"),Wue=a("strong"),Jwo=o("convnext"),Ywo=o(" \u2014 "),EO=a("a"),Zwo=o("ConvNextFeatureExtractor"),Kwo=o(" (ConvNeXT model)"),eAo=l(),rp=a("li"),Uue=a("strong"),oAo=o("cvt"),rAo=o(" \u2014 "),CO=a("a"),tAo=o("ConvNextFeatureExtractor"),aAo=o(" (CvT model)"),nAo=l(),tp=a("li"),Hue=a("strong"),sAo=o("data2vec-audio"),lAo=o(" \u2014 "),wO=a("a"),iAo=o("Wav2Vec2FeatureExtractor"),dAo=o(" (Data2VecAudio model)"),cAo=l(),ap=a("li"),Jue=a("strong"),mAo=o("data2vec-vision"),fAo=o(" \u2014 "),AO=a("a"),gAo=o("BeitFeatureExtractor"),hAo=o(" (Data2VecVision model)"),uAo=l(),np=a("li"),Yue=a("strong"),pAo=o("deformable_detr"),_Ao=o(" \u2014 "),LO=a("a"),bAo=o("DeformableDetrFeatureExtractor"),vAo=o(" (Deformable DETR model)"),FAo=l(),sp=a("li"),Zue=a("strong"),TAo=o("deit"),MAo=o(" \u2014 "),yO=a("a"),EAo=o("DeiTFeatureExtractor"),CAo=o(" (DeiT model)"),wAo=l(),lp=a("li"),Kue=a("strong"),AAo=o("detr"),LAo=o(" \u2014 "),xO=a("a"),yAo=o("DetrFeatureExtractor"),xAo=o(" (DETR model)"),$Ao=l(),ip=a("li"),epe=a("strong"),kAo=o("donut"),SAo=o(" \u2014 "),$O=a("a"),RAo=o("DonutFeatureExtractor"),PAo=o(" (Donut model)"),BAo=l(),dp=a("li"),ope=a("strong"),IAo=o("dpt"),NAo=o(" \u2014 "),kO=a("a"),qAo=o("DPTFeatureExtractor"),jAo=o(" (DPT model)"),DAo=l(),cp=a("li"),rpe=a("strong"),GAo=o("flava"),OAo=o(" \u2014 "),SO=a("a"),VAo=o("FlavaFeatureExtractor"),XAo=o(" (FLAVA model)"),zAo=l(),mp=a("li"),tpe=a("strong"),QAo=o("glpn"),WAo=o(" \u2014 "),RO=a("a"),UAo=o("GLPNFeatureExtractor"),HAo=o(" (GLPN model)"),JAo=l(),fp=a("li"),ape=a("strong"),YAo=o("groupvit"),ZAo=o(" \u2014 "),PO=a("a"),KAo=o("CLIPFeatureExtractor"),e6o=o(" (GroupViT model)"),o6o=l(),gp=a("li"),npe=a("strong"),r6o=o("hubert"),t6o=o(" \u2014 "),BO=a("a"),a6o=o("Wav2Vec2FeatureExtractor"),n6o=o(" (Hubert model)"),s6o=l(),hp=a("li"),spe=a("strong"),l6o=o("imagegpt"),i6o=o(" \u2014 "),IO=a("a"),d6o=o("ImageGPTFeatureExtractor"),c6o=o(" (ImageGPT model)"),m6o=l(),up=a("li"),lpe=a("strong"),f6o=o("layoutlmv2"),g6o=o(" \u2014 "),NO=a("a"),h6o=o("LayoutLMv2FeatureExtractor"),u6o=o(" (LayoutLMv2 model)"),p6o=l(),pp=a("li"),ipe=a("strong"),_6o=o("layoutlmv3"),b6o=o(" \u2014 "),qO=a("a"),v6o=o("LayoutLMv3FeatureExtractor"),F6o=o(" (LayoutLMv3 model)"),T6o=l(),_p=a("li"),dpe=a("strong"),M6o=o("levit"),E6o=o(" \u2014 "),jO=a("a"),C6o=o("LevitFeatureExtractor"),w6o=o(" (LeViT model)"),A6o=l(),bp=a("li"),cpe=a("strong"),L6o=o("maskformer"),y6o=o(" \u2014 "),DO=a("a"),x6o=o("MaskFormerFeatureExtractor"),$6o=o(" (MaskFormer model)"),k6o=l(),vp=a("li"),mpe=a("strong"),S6o=o("mctct"),R6o=o(" \u2014 "),GO=a("a"),P6o=o("MCTCTFeatureExtractor"),B6o=o(" (M-CTC-T model)"),I6o=l(),Fp=a("li"),fpe=a("strong"),N6o=o("mobilevit"),q6o=o(" \u2014 "),OO=a("a"),j6o=o("MobileViTFeatureExtractor"),D6o=o(" (MobileViT model)"),G6o=l(),Tp=a("li"),gpe=a("strong"),O6o=o("owlvit"),V6o=o(" \u2014 "),VO=a("a"),X6o=o("OwlViTFeatureExtractor"),z6o=o(" (OWL-ViT model)"),Q6o=l(),Mp=a("li"),hpe=a("strong"),W6o=o("perceiver"),U6o=o(" \u2014 "),XO=a("a"),H6o=o("PerceiverFeatureExtractor"),J6o=o(" (Perceiver model)"),Y6o=l(),Ep=a("li"),upe=a("strong"),Z6o=o("poolformer"),K6o=o(" \u2014 "),zO=a("a"),e7o=o("PoolFormerFeatureExtractor"),o7o=o(" (PoolFormer model)"),r7o=l(),Cp=a("li"),ppe=a("strong"),t7o=o("regnet"),a7o=o(" \u2014 "),QO=a("a"),n7o=o("ConvNextFeatureExtractor"),s7o=o(" (RegNet model)"),l7o=l(),wp=a("li"),_pe=a("strong"),i7o=o("resnet"),d7o=o(" \u2014 "),WO=a("a"),c7o=o("ConvNextFeatureExtractor"),m7o=o(" (ResNet model)"),f7o=l(),Ap=a("li"),bpe=a("strong"),g7o=o("segformer"),h7o=o(" \u2014 "),UO=a("a"),u7o=o("SegformerFeatureExtractor"),p7o=o(" (SegFormer model)"),_7o=l(),Lp=a("li"),vpe=a("strong"),b7o=o("speech_to_text"),v7o=o(" \u2014 "),HO=a("a"),F7o=o("Speech2TextFeatureExtractor"),T7o=o(" (Speech2Text model)"),M7o=l(),yp=a("li"),Fpe=a("strong"),E7o=o("swin"),C7o=o(" \u2014 "),JO=a("a"),w7o=o("ViTFeatureExtractor"),A7o=o(" (Swin Transformer model)"),L7o=l(),xp=a("li"),Tpe=a("strong"),y7o=o("swinv2"),x7o=o(" \u2014 "),YO=a("a"),$7o=o("ViTFeatureExtractor"),k7o=o(" (Swin Transformer V2 model)"),S7o=l(),$p=a("li"),Mpe=a("strong"),R7o=o("van"),P7o=o(" \u2014 "),ZO=a("a"),B7o=o("ConvNextFeatureExtractor"),I7o=o(" (VAN model)"),N7o=l(),kp=a("li"),Epe=a("strong"),q7o=o("videomae"),j7o=o(" \u2014 "),KO=a("a"),D7o=o("VideoMAEFeatureExtractor"),G7o=o(" (VideoMAE model)"),O7o=l(),Sp=a("li"),Cpe=a("strong"),V7o=o("vilt"),X7o=o(" \u2014 "),eV=a("a"),z7o=o("ViltFeatureExtractor"),Q7o=o(" (ViLT model)"),W7o=l(),Rp=a("li"),wpe=a("strong"),U7o=o("vit"),H7o=o(" \u2014 "),oV=a("a"),J7o=o("ViTFeatureExtractor"),Y7o=o(" (ViT model)"),Z7o=l(),Pp=a("li"),Ape=a("strong"),K7o=o("vit_mae"),eLo=o(" \u2014 "),rV=a("a"),oLo=o("ViTFeatureExtractor"),rLo=o(" (ViTMAE model)"),tLo=l(),Bp=a("li"),Lpe=a("strong"),aLo=o("vit_msn"),nLo=o(" \u2014 "),tV=a("a"),sLo=o("ViTFeatureExtractor"),lLo=o(" (ViTMSN model)"),iLo=l(),Ip=a("li"),ype=a("strong"),dLo=o("wav2vec2"),cLo=o(" \u2014 "),aV=a("a"),mLo=o("Wav2Vec2FeatureExtractor"),fLo=o(" (Wav2Vec2 model)"),gLo=l(),Np=a("li"),xpe=a("strong"),hLo=o("wav2vec2-conformer"),uLo=o(" \u2014 "),nV=a("a"),pLo=o("Wav2Vec2FeatureExtractor"),_Lo=o(" (Wav2Vec2-Conformer model)"),bLo=l(),qp=a("li"),$pe=a("strong"),vLo=o("whisper"),FLo=o(" \u2014 "),sV=a("a"),TLo=o("WhisperFeatureExtractor"),MLo=o(" (Whisper model)"),ELo=l(),jp=a("li"),kpe=a("strong"),CLo=o("xclip"),wLo=o(" \u2014 "),lV=a("a"),ALo=o("CLIPFeatureExtractor"),LLo=o(" (X-CLIP model)"),yLo=l(),Dp=a("li"),Spe=a("strong"),xLo=o("yolos"),$Lo=o(" \u2014 "),iV=a("a"),kLo=o("YolosFeatureExtractor"),SLo=o(" (YOLOS model)"),RLo=l(),F(Gp.$$.fragment),PLo=l(),F(Op.$$.fragment),BLo=l(),Vp=a("div"),F(Hx.$$.fragment),ILo=l(),Rpe=a("p"),NLo=o("Register a new feature extractor for this class."),Boo=l(),Td=a("h2"),Xp=a("a"),Ppe=a("span"),F(Jx.$$.fragment),qLo=l(),Bpe=a("span"),jLo=o("AutoProcessor"),Ioo=l(),Po=a("div"),F(Yx.$$.fragment),DLo=l(),Zx=a("p"),GLo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),dV=a("a"),OLo=o("AutoProcessor.from_pretrained()"),VLo=o(" class method."),XLo=l(),Kx=a("p"),zLo=o("This class cannot be instantiated directly using "),Ipe=a("code"),QLo=o("__init__()"),WLo=o(" (throws an error)."),ULo=l(),Ze=a("div"),F(e$.$$.fragment),HLo=l(),Npe=a("p"),JLo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),YLo=l(),Md=a("p"),ZLo=o("The processor class to instantiate is selected based on the "),qpe=a("code"),KLo=o("model_type"),e8o=o(` property of the config object (either
passed as an argument or loaded from `),jpe=a("code"),o8o=o("pretrained_model_name_or_path"),r8o=o(" if possible):"),t8o=l(),se=a("ul"),zp=a("li"),Dpe=a("strong"),a8o=o("clip"),n8o=o(" \u2014 "),cV=a("a"),s8o=o("CLIPProcessor"),l8o=o(" (CLIP model)"),i8o=l(),Qp=a("li"),Gpe=a("strong"),d8o=o("donut"),c8o=o(" \u2014 "),mV=a("a"),m8o=o("DonutProcessor"),f8o=o(" (Donut model)"),g8o=l(),Wp=a("li"),Ope=a("strong"),h8o=o("flava"),u8o=o(" \u2014 "),fV=a("a"),p8o=o("FlavaProcessor"),_8o=o(" (FLAVA model)"),b8o=l(),Up=a("li"),Vpe=a("strong"),v8o=o("groupvit"),F8o=o(" \u2014 "),gV=a("a"),T8o=o("CLIPProcessor"),M8o=o(" (GroupViT model)"),E8o=l(),Hp=a("li"),Xpe=a("strong"),C8o=o("layoutlmv2"),w8o=o(" \u2014 "),hV=a("a"),A8o=o("LayoutLMv2Processor"),L8o=o(" (LayoutLMv2 model)"),y8o=l(),Jp=a("li"),zpe=a("strong"),x8o=o("layoutlmv3"),$8o=o(" \u2014 "),uV=a("a"),k8o=o("LayoutLMv3Processor"),S8o=o(" (LayoutLMv3 model)"),R8o=l(),Yp=a("li"),Qpe=a("strong"),P8o=o("layoutxlm"),B8o=o(" \u2014 "),pV=a("a"),I8o=o("LayoutXLMProcessor"),N8o=o(" (LayoutXLM model)"),q8o=l(),Zp=a("li"),Wpe=a("strong"),j8o=o("markuplm"),D8o=o(" \u2014 "),_V=a("a"),G8o=o("MarkupLMProcessor"),O8o=o(" (MarkupLM model)"),V8o=l(),Kp=a("li"),Upe=a("strong"),X8o=o("owlvit"),z8o=o(" \u2014 "),bV=a("a"),Q8o=o("OwlViTProcessor"),W8o=o(" (OWL-ViT model)"),U8o=l(),e_=a("li"),Hpe=a("strong"),H8o=o("sew"),J8o=o(" \u2014 "),vV=a("a"),Y8o=o("Wav2Vec2Processor"),Z8o=o(" (SEW model)"),K8o=l(),o_=a("li"),Jpe=a("strong"),eyo=o("sew-d"),oyo=o(" \u2014 "),FV=a("a"),ryo=o("Wav2Vec2Processor"),tyo=o(" (SEW-D model)"),ayo=l(),r_=a("li"),Ype=a("strong"),nyo=o("speech_to_text"),syo=o(" \u2014 "),TV=a("a"),lyo=o("Speech2TextProcessor"),iyo=o(" (Speech2Text model)"),dyo=l(),t_=a("li"),Zpe=a("strong"),cyo=o("speech_to_text_2"),myo=o(" \u2014 "),MV=a("a"),fyo=o("Speech2Text2Processor"),gyo=o(" (Speech2Text2 model)"),hyo=l(),a_=a("li"),Kpe=a("strong"),uyo=o("trocr"),pyo=o(" \u2014 "),EV=a("a"),_yo=o("TrOCRProcessor"),byo=o(" (TrOCR model)"),vyo=l(),n_=a("li"),e_e=a("strong"),Fyo=o("unispeech"),Tyo=o(" \u2014 "),CV=a("a"),Myo=o("Wav2Vec2Processor"),Eyo=o(" (UniSpeech model)"),Cyo=l(),s_=a("li"),o_e=a("strong"),wyo=o("unispeech-sat"),Ayo=o(" \u2014 "),wV=a("a"),Lyo=o("Wav2Vec2Processor"),yyo=o(" (UniSpeechSat model)"),xyo=l(),l_=a("li"),r_e=a("strong"),$yo=o("vilt"),kyo=o(" \u2014 "),AV=a("a"),Syo=o("ViltProcessor"),Ryo=o(" (ViLT model)"),Pyo=l(),i_=a("li"),t_e=a("strong"),Byo=o("vision-text-dual-encoder"),Iyo=o(" \u2014 "),LV=a("a"),Nyo=o("VisionTextDualEncoderProcessor"),qyo=o(" (VisionTextDualEncoder model)"),jyo=l(),d_=a("li"),a_e=a("strong"),Dyo=o("wav2vec2"),Gyo=o(" \u2014 "),yV=a("a"),Oyo=o("Wav2Vec2Processor"),Vyo=o(" (Wav2Vec2 model)"),Xyo=l(),c_=a("li"),n_e=a("strong"),zyo=o("wav2vec2-conformer"),Qyo=o(" \u2014 "),xV=a("a"),Wyo=o("Wav2Vec2Processor"),Uyo=o(" (Wav2Vec2-Conformer model)"),Hyo=l(),m_=a("li"),s_e=a("strong"),Jyo=o("wavlm"),Yyo=o(" \u2014 "),$V=a("a"),Zyo=o("Wav2Vec2Processor"),Kyo=o(" (WavLM model)"),e9o=l(),f_=a("li"),l_e=a("strong"),o9o=o("whisper"),r9o=o(" \u2014 "),kV=a("a"),t9o=o("WhisperProcessor"),a9o=o(" (Whisper model)"),n9o=l(),g_=a("li"),i_e=a("strong"),s9o=o("xclip"),l9o=o(" \u2014 "),SV=a("a"),i9o=o("CLIPProcessor"),d9o=o(" (X-CLIP model)"),c9o=l(),F(h_.$$.fragment),m9o=l(),F(u_.$$.fragment),f9o=l(),p_=a("div"),F(o$.$$.fragment),g9o=l(),d_e=a("p"),h9o=o("Register a new processor for this class."),Noo=l(),Ed=a("h2"),__=a("a"),c_e=a("span"),F(r$.$$.fragment),u9o=l(),m_e=a("span"),p9o=o("AutoModel"),qoo=l(),Bo=a("div"),F(t$.$$.fragment),_9o=l(),Cd=a("p"),b9o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RV=a("a"),v9o=o("from_pretrained()"),F9o=o(" class method or the "),PV=a("a"),T9o=o("from_config()"),M9o=o(` class
method.`),E9o=l(),a$=a("p"),C9o=o("This class cannot be instantiated directly using "),f_e=a("code"),w9o=o("__init__()"),A9o=o(" (throws an error)."),L9o=l(),vt=a("div"),F(n$.$$.fragment),y9o=l(),g_e=a("p"),x9o=o("Instantiates one of the base model classes of the library from a configuration."),$9o=l(),wd=a("p"),k9o=o(`Note:
Loading a model from its configuration file does `),h_e=a("strong"),S9o=o("not"),R9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=a("a"),P9o=o("from_pretrained()"),B9o=o(" to load the model weights."),I9o=l(),F(b_.$$.fragment),N9o=l(),Ke=a("div"),F(s$.$$.fragment),q9o=l(),u_e=a("p"),j9o=o("Instantiate one of the base model classes of the library from a pretrained model."),D9o=l(),en=a("p"),G9o=o("The model class to instantiate is selected based on the "),p_e=a("code"),O9o=o("model_type"),V9o=o(` property of the config object (either
passed as an argument or loaded from `),__e=a("code"),X9o=o("pretrained_model_name_or_path"),z9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=a("code"),Q9o=o("pretrained_model_name_or_path"),W9o=o(":"),U9o=l(),y=a("ul"),v_=a("li"),v_e=a("strong"),H9o=o("albert"),J9o=o(" \u2014 "),IV=a("a"),Y9o=o("AlbertModel"),Z9o=o(" (ALBERT model)"),K9o=l(),F_=a("li"),F_e=a("strong"),exo=o("bart"),oxo=o(" \u2014 "),NV=a("a"),rxo=o("BartModel"),txo=o(" (BART model)"),axo=l(),T_=a("li"),T_e=a("strong"),nxo=o("beit"),sxo=o(" \u2014 "),qV=a("a"),lxo=o("BeitModel"),ixo=o(" (BEiT model)"),dxo=l(),M_=a("li"),M_e=a("strong"),cxo=o("bert"),mxo=o(" \u2014 "),jV=a("a"),fxo=o("BertModel"),gxo=o(" (BERT model)"),hxo=l(),E_=a("li"),E_e=a("strong"),uxo=o("bert-generation"),pxo=o(" \u2014 "),DV=a("a"),_xo=o("BertGenerationEncoder"),bxo=o(" (Bert Generation model)"),vxo=l(),C_=a("li"),C_e=a("strong"),Fxo=o("big_bird"),Txo=o(" \u2014 "),GV=a("a"),Mxo=o("BigBirdModel"),Exo=o(" (BigBird model)"),Cxo=l(),w_=a("li"),w_e=a("strong"),wxo=o("bigbird_pegasus"),Axo=o(" \u2014 "),OV=a("a"),Lxo=o("BigBirdPegasusModel"),yxo=o(" (BigBird-Pegasus model)"),xxo=l(),A_=a("li"),A_e=a("strong"),$xo=o("blenderbot"),kxo=o(" \u2014 "),VV=a("a"),Sxo=o("BlenderbotModel"),Rxo=o(" (Blenderbot model)"),Pxo=l(),L_=a("li"),L_e=a("strong"),Bxo=o("blenderbot-small"),Ixo=o(" \u2014 "),XV=a("a"),Nxo=o("BlenderbotSmallModel"),qxo=o(" (BlenderbotSmall model)"),jxo=l(),y_=a("li"),y_e=a("strong"),Dxo=o("bloom"),Gxo=o(" \u2014 "),zV=a("a"),Oxo=o("BloomModel"),Vxo=o(" (BLOOM model)"),Xxo=l(),x_=a("li"),x_e=a("strong"),zxo=o("camembert"),Qxo=o(" \u2014 "),QV=a("a"),Wxo=o("CamembertModel"),Uxo=o(" (CamemBERT model)"),Hxo=l(),$_=a("li"),$_e=a("strong"),Jxo=o("canine"),Yxo=o(" \u2014 "),WV=a("a"),Zxo=o("CanineModel"),Kxo=o(" (CANINE model)"),e$o=l(),k_=a("li"),k_e=a("strong"),o$o=o("clip"),r$o=o(" \u2014 "),UV=a("a"),t$o=o("CLIPModel"),a$o=o(" (CLIP model)"),n$o=l(),S_=a("li"),S_e=a("strong"),s$o=o("codegen"),l$o=o(" \u2014 "),HV=a("a"),i$o=o("CodeGenModel"),d$o=o(" (CodeGen model)"),c$o=l(),R_=a("li"),R_e=a("strong"),m$o=o("conditional_detr"),f$o=o(" \u2014 "),JV=a("a"),g$o=o("ConditionalDetrModel"),h$o=o(" (Conditional DETR model)"),u$o=l(),P_=a("li"),P_e=a("strong"),p$o=o("convbert"),_$o=o(" \u2014 "),YV=a("a"),b$o=o("ConvBertModel"),v$o=o(" (ConvBERT model)"),F$o=l(),B_=a("li"),B_e=a("strong"),T$o=o("convnext"),M$o=o(" \u2014 "),ZV=a("a"),E$o=o("ConvNextModel"),C$o=o(" (ConvNeXT model)"),w$o=l(),I_=a("li"),I_e=a("strong"),A$o=o("ctrl"),L$o=o(" \u2014 "),KV=a("a"),y$o=o("CTRLModel"),x$o=o(" (CTRL model)"),$$o=l(),N_=a("li"),N_e=a("strong"),k$o=o("cvt"),S$o=o(" \u2014 "),eX=a("a"),R$o=o("CvtModel"),P$o=o(" (CvT model)"),B$o=l(),q_=a("li"),q_e=a("strong"),I$o=o("data2vec-audio"),N$o=o(" \u2014 "),oX=a("a"),q$o=o("Data2VecAudioModel"),j$o=o(" (Data2VecAudio model)"),D$o=l(),j_=a("li"),j_e=a("strong"),G$o=o("data2vec-text"),O$o=o(" \u2014 "),rX=a("a"),V$o=o("Data2VecTextModel"),X$o=o(" (Data2VecText model)"),z$o=l(),D_=a("li"),D_e=a("strong"),Q$o=o("data2vec-vision"),W$o=o(" \u2014 "),tX=a("a"),U$o=o("Data2VecVisionModel"),H$o=o(" (Data2VecVision model)"),J$o=l(),G_=a("li"),G_e=a("strong"),Y$o=o("deberta"),Z$o=o(" \u2014 "),aX=a("a"),K$o=o("DebertaModel"),eko=o(" (DeBERTa model)"),oko=l(),O_=a("li"),O_e=a("strong"),rko=o("deberta-v2"),tko=o(" \u2014 "),nX=a("a"),ako=o("DebertaV2Model"),nko=o(" (DeBERTa-v2 model)"),sko=l(),V_=a("li"),V_e=a("strong"),lko=o("decision_transformer"),iko=o(" \u2014 "),sX=a("a"),dko=o("DecisionTransformerModel"),cko=o(" (Decision Transformer model)"),mko=l(),X_=a("li"),X_e=a("strong"),fko=o("deformable_detr"),gko=o(" \u2014 "),lX=a("a"),hko=o("DeformableDetrModel"),uko=o(" (Deformable DETR model)"),pko=l(),z_=a("li"),z_e=a("strong"),_ko=o("deit"),bko=o(" \u2014 "),iX=a("a"),vko=o("DeiTModel"),Fko=o(" (DeiT model)"),Tko=l(),Q_=a("li"),Q_e=a("strong"),Mko=o("detr"),Eko=o(" \u2014 "),dX=a("a"),Cko=o("DetrModel"),wko=o(" (DETR model)"),Ako=l(),W_=a("li"),W_e=a("strong"),Lko=o("distilbert"),yko=o(" \u2014 "),cX=a("a"),xko=o("DistilBertModel"),$ko=o(" (DistilBERT model)"),kko=l(),U_=a("li"),U_e=a("strong"),Sko=o("donut-swin"),Rko=o(" \u2014 "),mX=a("a"),Pko=o("DonutSwinModel"),Bko=o(" (DonutSwin model)"),Iko=l(),H_=a("li"),H_e=a("strong"),Nko=o("dpr"),qko=o(" \u2014 "),fX=a("a"),jko=o("DPRQuestionEncoder"),Dko=o(" (DPR model)"),Gko=l(),J_=a("li"),J_e=a("strong"),Oko=o("dpt"),Vko=o(" \u2014 "),gX=a("a"),Xko=o("DPTModel"),zko=o(" (DPT model)"),Qko=l(),Y_=a("li"),Y_e=a("strong"),Wko=o("electra"),Uko=o(" \u2014 "),hX=a("a"),Hko=o("ElectraModel"),Jko=o(" (ELECTRA model)"),Yko=l(),Z_=a("li"),Z_e=a("strong"),Zko=o("ernie"),Kko=o(" \u2014 "),uX=a("a"),eSo=o("ErnieModel"),oSo=o(" (ERNIE model)"),rSo=l(),K_=a("li"),K_e=a("strong"),tSo=o("esm"),aSo=o(" \u2014 "),pX=a("a"),nSo=o("EsmModel"),sSo=o(" (ESM model)"),lSo=l(),e1=a("li"),e1e=a("strong"),iSo=o("flaubert"),dSo=o(" \u2014 "),_X=a("a"),cSo=o("FlaubertModel"),mSo=o(" (FlauBERT model)"),fSo=l(),o1=a("li"),o1e=a("strong"),gSo=o("flava"),hSo=o(" \u2014 "),bX=a("a"),uSo=o("FlavaModel"),pSo=o(" (FLAVA model)"),_So=l(),r1=a("li"),r1e=a("strong"),bSo=o("fnet"),vSo=o(" \u2014 "),vX=a("a"),FSo=o("FNetModel"),TSo=o(" (FNet model)"),MSo=l(),t1=a("li"),t1e=a("strong"),ESo=o("fsmt"),CSo=o(" \u2014 "),FX=a("a"),wSo=o("FSMTModel"),ASo=o(" (FairSeq Machine-Translation model)"),LSo=l(),Ml=a("li"),a1e=a("strong"),ySo=o("funnel"),xSo=o(" \u2014 "),TX=a("a"),$So=o("FunnelModel"),kSo=o(" or "),MX=a("a"),SSo=o("FunnelBaseModel"),RSo=o(" (Funnel Transformer model)"),PSo=l(),a1=a("li"),n1e=a("strong"),BSo=o("glpn"),ISo=o(" \u2014 "),EX=a("a"),NSo=o("GLPNModel"),qSo=o(" (GLPN model)"),jSo=l(),n1=a("li"),s1e=a("strong"),DSo=o("gpt2"),GSo=o(" \u2014 "),CX=a("a"),OSo=o("GPT2Model"),VSo=o(" (OpenAI GPT-2 model)"),XSo=l(),s1=a("li"),l1e=a("strong"),zSo=o("gpt_neo"),QSo=o(" \u2014 "),wX=a("a"),WSo=o("GPTNeoModel"),USo=o(" (GPT Neo model)"),HSo=l(),l1=a("li"),i1e=a("strong"),JSo=o("gpt_neox"),YSo=o(" \u2014 "),AX=a("a"),ZSo=o("GPTNeoXModel"),KSo=o(" (GPT NeoX model)"),eRo=l(),i1=a("li"),d1e=a("strong"),oRo=o("gpt_neox_japanese"),rRo=o(" \u2014 "),LX=a("a"),tRo=o("GPTNeoXJapaneseModel"),aRo=o(" (GPT NeoX Japanese model)"),nRo=l(),d1=a("li"),c1e=a("strong"),sRo=o("gptj"),lRo=o(" \u2014 "),yX=a("a"),iRo=o("GPTJModel"),dRo=o(" (GPT-J model)"),cRo=l(),c1=a("li"),m1e=a("strong"),mRo=o("groupvit"),fRo=o(" \u2014 "),xX=a("a"),gRo=o("GroupViTModel"),hRo=o(" (GroupViT model)"),uRo=l(),m1=a("li"),f1e=a("strong"),pRo=o("hubert"),_Ro=o(" \u2014 "),$X=a("a"),bRo=o("HubertModel"),vRo=o(" (Hubert model)"),FRo=l(),f1=a("li"),g1e=a("strong"),TRo=o("ibert"),MRo=o(" \u2014 "),kX=a("a"),ERo=o("IBertModel"),CRo=o(" (I-BERT model)"),wRo=l(),g1=a("li"),h1e=a("strong"),ARo=o("imagegpt"),LRo=o(" \u2014 "),SX=a("a"),yRo=o("ImageGPTModel"),xRo=o(" (ImageGPT model)"),$Ro=l(),h1=a("li"),u1e=a("strong"),kRo=o("layoutlm"),SRo=o(" \u2014 "),RX=a("a"),RRo=o("LayoutLMModel"),PRo=o(" (LayoutLM model)"),BRo=l(),u1=a("li"),p1e=a("strong"),IRo=o("layoutlmv2"),NRo=o(" \u2014 "),PX=a("a"),qRo=o("LayoutLMv2Model"),jRo=o(" (LayoutLMv2 model)"),DRo=l(),p1=a("li"),_1e=a("strong"),GRo=o("layoutlmv3"),ORo=o(" \u2014 "),BX=a("a"),VRo=o("LayoutLMv3Model"),XRo=o(" (LayoutLMv3 model)"),zRo=l(),_1=a("li"),b1e=a("strong"),QRo=o("led"),WRo=o(" \u2014 "),IX=a("a"),URo=o("LEDModel"),HRo=o(" (LED model)"),JRo=l(),b1=a("li"),v1e=a("strong"),YRo=o("levit"),ZRo=o(" \u2014 "),NX=a("a"),KRo=o("LevitModel"),ePo=o(" (LeViT model)"),oPo=l(),v1=a("li"),F1e=a("strong"),rPo=o("longformer"),tPo=o(" \u2014 "),qX=a("a"),aPo=o("LongformerModel"),nPo=o(" (Longformer model)"),sPo=l(),F1=a("li"),T1e=a("strong"),lPo=o("longt5"),iPo=o(" \u2014 "),jX=a("a"),dPo=o("LongT5Model"),cPo=o(" (LongT5 model)"),mPo=l(),T1=a("li"),M1e=a("strong"),fPo=o("luke"),gPo=o(" \u2014 "),DX=a("a"),hPo=o("LukeModel"),uPo=o(" (LUKE model)"),pPo=l(),M1=a("li"),E1e=a("strong"),_Po=o("lxmert"),bPo=o(" \u2014 "),GX=a("a"),vPo=o("LxmertModel"),FPo=o(" (LXMERT model)"),TPo=l(),E1=a("li"),C1e=a("strong"),MPo=o("m2m_100"),EPo=o(" \u2014 "),OX=a("a"),CPo=o("M2M100Model"),wPo=o(" (M2M100 model)"),APo=l(),C1=a("li"),w1e=a("strong"),LPo=o("marian"),yPo=o(" \u2014 "),VX=a("a"),xPo=o("MarianModel"),$Po=o(" (Marian model)"),kPo=l(),w1=a("li"),A1e=a("strong"),SPo=o("markuplm"),RPo=o(" \u2014 "),XX=a("a"),PPo=o("MarkupLMModel"),BPo=o(" (MarkupLM model)"),IPo=l(),A1=a("li"),L1e=a("strong"),NPo=o("maskformer"),qPo=o(" \u2014 "),zX=a("a"),jPo=o("MaskFormerModel"),DPo=o(" (MaskFormer model)"),GPo=l(),L1=a("li"),y1e=a("strong"),OPo=o("mbart"),VPo=o(" \u2014 "),QX=a("a"),XPo=o("MBartModel"),zPo=o(" (mBART model)"),QPo=l(),y1=a("li"),x1e=a("strong"),WPo=o("mctct"),UPo=o(" \u2014 "),WX=a("a"),HPo=o("MCTCTModel"),JPo=o(" (M-CTC-T model)"),YPo=l(),x1=a("li"),$1e=a("strong"),ZPo=o("megatron-bert"),KPo=o(" \u2014 "),UX=a("a"),eBo=o("MegatronBertModel"),oBo=o(" (Megatron-BERT model)"),rBo=l(),$1=a("li"),k1e=a("strong"),tBo=o("mobilebert"),aBo=o(" \u2014 "),HX=a("a"),nBo=o("MobileBertModel"),sBo=o(" (MobileBERT model)"),lBo=l(),k1=a("li"),S1e=a("strong"),iBo=o("mobilevit"),dBo=o(" \u2014 "),JX=a("a"),cBo=o("MobileViTModel"),mBo=o(" (MobileViT model)"),fBo=l(),S1=a("li"),R1e=a("strong"),gBo=o("mpnet"),hBo=o(" \u2014 "),YX=a("a"),uBo=o("MPNetModel"),pBo=o(" (MPNet model)"),_Bo=l(),R1=a("li"),P1e=a("strong"),bBo=o("mt5"),vBo=o(" \u2014 "),ZX=a("a"),FBo=o("MT5Model"),TBo=o(" (MT5 model)"),MBo=l(),P1=a("li"),B1e=a("strong"),EBo=o("mvp"),CBo=o(" \u2014 "),KX=a("a"),wBo=o("MvpModel"),ABo=o(" (MVP model)"),LBo=l(),B1=a("li"),I1e=a("strong"),yBo=o("nezha"),xBo=o(" \u2014 "),ez=a("a"),$Bo=o("NezhaModel"),kBo=o(" (Nezha model)"),SBo=l(),I1=a("li"),N1e=a("strong"),RBo=o("nllb"),PBo=o(" \u2014 "),oz=a("a"),BBo=o("M2M100Model"),IBo=o(" (NLLB model)"),NBo=l(),N1=a("li"),q1e=a("strong"),qBo=o("nystromformer"),jBo=o(" \u2014 "),rz=a("a"),DBo=o("NystromformerModel"),GBo=o(" (Nystr\xF6mformer model)"),OBo=l(),q1=a("li"),j1e=a("strong"),VBo=o("openai-gpt"),XBo=o(" \u2014 "),tz=a("a"),zBo=o("OpenAIGPTModel"),QBo=o(" (OpenAI GPT model)"),WBo=l(),j1=a("li"),D1e=a("strong"),UBo=o("opt"),HBo=o(" \u2014 "),az=a("a"),JBo=o("OPTModel"),YBo=o(" (OPT model)"),ZBo=l(),D1=a("li"),G1e=a("strong"),KBo=o("owlvit"),eIo=o(" \u2014 "),nz=a("a"),oIo=o("OwlViTModel"),rIo=o(" (OWL-ViT model)"),tIo=l(),G1=a("li"),O1e=a("strong"),aIo=o("pegasus"),nIo=o(" \u2014 "),sz=a("a"),sIo=o("PegasusModel"),lIo=o(" (Pegasus model)"),iIo=l(),O1=a("li"),V1e=a("strong"),dIo=o("pegasus_x"),cIo=o(" \u2014 "),lz=a("a"),mIo=o("PegasusXModel"),fIo=o(" (PEGASUS-X model)"),gIo=l(),V1=a("li"),X1e=a("strong"),hIo=o("perceiver"),uIo=o(" \u2014 "),iz=a("a"),pIo=o("PerceiverModel"),_Io=o(" (Perceiver model)"),bIo=l(),X1=a("li"),z1e=a("strong"),vIo=o("plbart"),FIo=o(" \u2014 "),dz=a("a"),TIo=o("PLBartModel"),MIo=o(" (PLBart model)"),EIo=l(),z1=a("li"),Q1e=a("strong"),CIo=o("poolformer"),wIo=o(" \u2014 "),cz=a("a"),AIo=o("PoolFormerModel"),LIo=o(" (PoolFormer model)"),yIo=l(),Q1=a("li"),W1e=a("strong"),xIo=o("prophetnet"),$Io=o(" \u2014 "),mz=a("a"),kIo=o("ProphetNetModel"),SIo=o(" (ProphetNet model)"),RIo=l(),W1=a("li"),U1e=a("strong"),PIo=o("qdqbert"),BIo=o(" \u2014 "),fz=a("a"),IIo=o("QDQBertModel"),NIo=o(" (QDQBert model)"),qIo=l(),U1=a("li"),H1e=a("strong"),jIo=o("reformer"),DIo=o(" \u2014 "),gz=a("a"),GIo=o("ReformerModel"),OIo=o(" (Reformer model)"),VIo=l(),H1=a("li"),J1e=a("strong"),XIo=o("regnet"),zIo=o(" \u2014 "),hz=a("a"),QIo=o("RegNetModel"),WIo=o(" (RegNet model)"),UIo=l(),J1=a("li"),Y1e=a("strong"),HIo=o("rembert"),JIo=o(" \u2014 "),uz=a("a"),YIo=o("RemBertModel"),ZIo=o(" (RemBERT model)"),KIo=l(),Y1=a("li"),Z1e=a("strong"),eNo=o("resnet"),oNo=o(" \u2014 "),pz=a("a"),rNo=o("ResNetModel"),tNo=o(" (ResNet model)"),aNo=l(),Z1=a("li"),K1e=a("strong"),nNo=o("retribert"),sNo=o(" \u2014 "),_z=a("a"),lNo=o("RetriBertModel"),iNo=o(" (RetriBERT model)"),dNo=l(),K1=a("li"),e2e=a("strong"),cNo=o("roberta"),mNo=o(" \u2014 "),bz=a("a"),fNo=o("RobertaModel"),gNo=o(" (RoBERTa model)"),hNo=l(),e2=a("li"),o2e=a("strong"),uNo=o("roformer"),pNo=o(" \u2014 "),vz=a("a"),_No=o("RoFormerModel"),bNo=o(" (RoFormer model)"),vNo=l(),o2=a("li"),r2e=a("strong"),FNo=o("segformer"),TNo=o(" \u2014 "),Fz=a("a"),MNo=o("SegformerModel"),ENo=o(" (SegFormer model)"),CNo=l(),r2=a("li"),t2e=a("strong"),wNo=o("sew"),ANo=o(" \u2014 "),Tz=a("a"),LNo=o("SEWModel"),yNo=o(" (SEW model)"),xNo=l(),t2=a("li"),a2e=a("strong"),$No=o("sew-d"),kNo=o(" \u2014 "),Mz=a("a"),SNo=o("SEWDModel"),RNo=o(" (SEW-D model)"),PNo=l(),a2=a("li"),n2e=a("strong"),BNo=o("speech_to_text"),INo=o(" \u2014 "),Ez=a("a"),NNo=o("Speech2TextModel"),qNo=o(" (Speech2Text model)"),jNo=l(),n2=a("li"),s2e=a("strong"),DNo=o("splinter"),GNo=o(" \u2014 "),Cz=a("a"),ONo=o("SplinterModel"),VNo=o(" (Splinter model)"),XNo=l(),s2=a("li"),l2e=a("strong"),zNo=o("squeezebert"),QNo=o(" \u2014 "),wz=a("a"),WNo=o("SqueezeBertModel"),UNo=o(" (SqueezeBERT model)"),HNo=l(),l2=a("li"),i2e=a("strong"),JNo=o("swin"),YNo=o(" \u2014 "),Az=a("a"),ZNo=o("SwinModel"),KNo=o(" (Swin Transformer model)"),eqo=l(),i2=a("li"),d2e=a("strong"),oqo=o("swinv2"),rqo=o(" \u2014 "),Lz=a("a"),tqo=o("Swinv2Model"),aqo=o(" (Swin Transformer V2 model)"),nqo=l(),d2=a("li"),c2e=a("strong"),sqo=o("t5"),lqo=o(" \u2014 "),yz=a("a"),iqo=o("T5Model"),dqo=o(" (T5 model)"),cqo=l(),c2=a("li"),m2e=a("strong"),mqo=o("tapas"),fqo=o(" \u2014 "),xz=a("a"),gqo=o("TapasModel"),hqo=o(" (TAPAS model)"),uqo=l(),m2=a("li"),f2e=a("strong"),pqo=o("time_series_transformer"),_qo=o(" \u2014 "),$z=a("a"),bqo=o("TimeSeriesTransformerModel"),vqo=o(" (Time Series Transformer model)"),Fqo=l(),f2=a("li"),g2e=a("strong"),Tqo=o("trajectory_transformer"),Mqo=o(" \u2014 "),kz=a("a"),Eqo=o("TrajectoryTransformerModel"),Cqo=o(" (Trajectory Transformer model)"),wqo=l(),g2=a("li"),h2e=a("strong"),Aqo=o("transfo-xl"),Lqo=o(" \u2014 "),Sz=a("a"),yqo=o("TransfoXLModel"),xqo=o(" (Transformer-XL model)"),$qo=l(),h2=a("li"),u2e=a("strong"),kqo=o("unispeech"),Sqo=o(" \u2014 "),Rz=a("a"),Rqo=o("UniSpeechModel"),Pqo=o(" (UniSpeech model)"),Bqo=l(),u2=a("li"),p2e=a("strong"),Iqo=o("unispeech-sat"),Nqo=o(" \u2014 "),Pz=a("a"),qqo=o("UniSpeechSatModel"),jqo=o(" (UniSpeechSat model)"),Dqo=l(),p2=a("li"),_2e=a("strong"),Gqo=o("van"),Oqo=o(" \u2014 "),Bz=a("a"),Vqo=o("VanModel"),Xqo=o(" (VAN model)"),zqo=l(),_2=a("li"),b2e=a("strong"),Qqo=o("videomae"),Wqo=o(" \u2014 "),Iz=a("a"),Uqo=o("VideoMAEModel"),Hqo=o(" (VideoMAE model)"),Jqo=l(),b2=a("li"),v2e=a("strong"),Yqo=o("vilt"),Zqo=o(" \u2014 "),Nz=a("a"),Kqo=o("ViltModel"),ejo=o(" (ViLT model)"),ojo=l(),v2=a("li"),F2e=a("strong"),rjo=o("vision-text-dual-encoder"),tjo=o(" \u2014 "),qz=a("a"),ajo=o("VisionTextDualEncoderModel"),njo=o(" (VisionTextDualEncoder model)"),sjo=l(),F2=a("li"),T2e=a("strong"),ljo=o("visual_bert"),ijo=o(" \u2014 "),jz=a("a"),djo=o("VisualBertModel"),cjo=o(" (VisualBERT model)"),mjo=l(),T2=a("li"),M2e=a("strong"),fjo=o("vit"),gjo=o(" \u2014 "),Dz=a("a"),hjo=o("ViTModel"),ujo=o(" (ViT model)"),pjo=l(),M2=a("li"),E2e=a("strong"),_jo=o("vit_mae"),bjo=o(" \u2014 "),Gz=a("a"),vjo=o("ViTMAEModel"),Fjo=o(" (ViTMAE model)"),Tjo=l(),E2=a("li"),C2e=a("strong"),Mjo=o("vit_msn"),Ejo=o(" \u2014 "),Oz=a("a"),Cjo=o("ViTMSNModel"),wjo=o(" (ViTMSN model)"),Ajo=l(),C2=a("li"),w2e=a("strong"),Ljo=o("wav2vec2"),yjo=o(" \u2014 "),Vz=a("a"),xjo=o("Wav2Vec2Model"),$jo=o(" (Wav2Vec2 model)"),kjo=l(),w2=a("li"),A2e=a("strong"),Sjo=o("wav2vec2-conformer"),Rjo=o(" \u2014 "),Xz=a("a"),Pjo=o("Wav2Vec2ConformerModel"),Bjo=o(" (Wav2Vec2-Conformer model)"),Ijo=l(),A2=a("li"),L2e=a("strong"),Njo=o("wavlm"),qjo=o(" \u2014 "),zz=a("a"),jjo=o("WavLMModel"),Djo=o(" (WavLM model)"),Gjo=l(),L2=a("li"),y2e=a("strong"),Ojo=o("whisper"),Vjo=o(" \u2014 "),Qz=a("a"),Xjo=o("WhisperModel"),zjo=o(" (Whisper model)"),Qjo=l(),y2=a("li"),x2e=a("strong"),Wjo=o("xclip"),Ujo=o(" \u2014 "),Wz=a("a"),Hjo=o("XCLIPModel"),Jjo=o(" (X-CLIP model)"),Yjo=l(),x2=a("li"),$2e=a("strong"),Zjo=o("xglm"),Kjo=o(" \u2014 "),Uz=a("a"),eDo=o("XGLMModel"),oDo=o(" (XGLM model)"),rDo=l(),$2=a("li"),k2e=a("strong"),tDo=o("xlm"),aDo=o(" \u2014 "),Hz=a("a"),nDo=o("XLMModel"),sDo=o(" (XLM model)"),lDo=l(),k2=a("li"),S2e=a("strong"),iDo=o("xlm-prophetnet"),dDo=o(" \u2014 "),Jz=a("a"),cDo=o("XLMProphetNetModel"),mDo=o(" (XLM-ProphetNet model)"),fDo=l(),S2=a("li"),R2e=a("strong"),gDo=o("xlm-roberta"),hDo=o(" \u2014 "),Yz=a("a"),uDo=o("XLMRobertaModel"),pDo=o(" (XLM-RoBERTa model)"),_Do=l(),R2=a("li"),P2e=a("strong"),bDo=o("xlm-roberta-xl"),vDo=o(" \u2014 "),Zz=a("a"),FDo=o("XLMRobertaXLModel"),TDo=o(" (XLM-RoBERTa-XL model)"),MDo=l(),P2=a("li"),B2e=a("strong"),EDo=o("xlnet"),CDo=o(" \u2014 "),Kz=a("a"),wDo=o("XLNetModel"),ADo=o(" (XLNet model)"),LDo=l(),B2=a("li"),I2e=a("strong"),yDo=o("yolos"),xDo=o(" \u2014 "),eQ=a("a"),$Do=o("YolosModel"),kDo=o(" (YOLOS model)"),SDo=l(),I2=a("li"),N2e=a("strong"),RDo=o("yoso"),PDo=o(" \u2014 "),oQ=a("a"),BDo=o("YosoModel"),IDo=o(" (YOSO model)"),NDo=l(),N2=a("p"),qDo=o("The model is set in evaluation mode by default using "),q2e=a("code"),jDo=o("model.eval()"),DDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j2e=a("code"),GDo=o("model.train()"),ODo=l(),F(q2.$$.fragment),joo=l(),Ad=a("h2"),j2=a("a"),D2e=a("span"),F(l$.$$.fragment),VDo=l(),G2e=a("span"),XDo=o("AutoModelForPreTraining"),Doo=l(),Io=a("div"),F(i$.$$.fragment),zDo=l(),Ld=a("p"),QDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rQ=a("a"),WDo=o("from_pretrained()"),UDo=o(" class method or the "),tQ=a("a"),HDo=o("from_config()"),JDo=o(` class
method.`),YDo=l(),d$=a("p"),ZDo=o("This class cannot be instantiated directly using "),O2e=a("code"),KDo=o("__init__()"),eGo=o(" (throws an error)."),oGo=l(),Ft=a("div"),F(c$.$$.fragment),rGo=l(),V2e=a("p"),tGo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),aGo=l(),yd=a("p"),nGo=o(`Note:
Loading a model from its configuration file does `),X2e=a("strong"),sGo=o("not"),lGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aQ=a("a"),iGo=o("from_pretrained()"),dGo=o(" to load the model weights."),cGo=l(),F(D2.$$.fragment),mGo=l(),eo=a("div"),F(m$.$$.fragment),fGo=l(),z2e=a("p"),gGo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),hGo=l(),on=a("p"),uGo=o("The model class to instantiate is selected based on the "),Q2e=a("code"),pGo=o("model_type"),_Go=o(` property of the config object (either
passed as an argument or loaded from `),W2e=a("code"),bGo=o("pretrained_model_name_or_path"),vGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=a("code"),FGo=o("pretrained_model_name_or_path"),TGo=o(":"),MGo=l(),G=a("ul"),G2=a("li"),H2e=a("strong"),EGo=o("albert"),CGo=o(" \u2014 "),nQ=a("a"),wGo=o("AlbertForPreTraining"),AGo=o(" (ALBERT model)"),LGo=l(),O2=a("li"),J2e=a("strong"),yGo=o("bart"),xGo=o(" \u2014 "),sQ=a("a"),$Go=o("BartForConditionalGeneration"),kGo=o(" (BART model)"),SGo=l(),V2=a("li"),Y2e=a("strong"),RGo=o("bert"),PGo=o(" \u2014 "),lQ=a("a"),BGo=o("BertForPreTraining"),IGo=o(" (BERT model)"),NGo=l(),X2=a("li"),Z2e=a("strong"),qGo=o("big_bird"),jGo=o(" \u2014 "),iQ=a("a"),DGo=o("BigBirdForPreTraining"),GGo=o(" (BigBird model)"),OGo=l(),z2=a("li"),K2e=a("strong"),VGo=o("bloom"),XGo=o(" \u2014 "),dQ=a("a"),zGo=o("BloomForCausalLM"),QGo=o(" (BLOOM model)"),WGo=l(),Q2=a("li"),ebe=a("strong"),UGo=o("camembert"),HGo=o(" \u2014 "),cQ=a("a"),JGo=o("CamembertForMaskedLM"),YGo=o(" (CamemBERT model)"),ZGo=l(),W2=a("li"),obe=a("strong"),KGo=o("ctrl"),eOo=o(" \u2014 "),mQ=a("a"),oOo=o("CTRLLMHeadModel"),rOo=o(" (CTRL model)"),tOo=l(),U2=a("li"),rbe=a("strong"),aOo=o("data2vec-text"),nOo=o(" \u2014 "),fQ=a("a"),sOo=o("Data2VecTextForMaskedLM"),lOo=o(" (Data2VecText model)"),iOo=l(),H2=a("li"),tbe=a("strong"),dOo=o("deberta"),cOo=o(" \u2014 "),gQ=a("a"),mOo=o("DebertaForMaskedLM"),fOo=o(" (DeBERTa model)"),gOo=l(),J2=a("li"),abe=a("strong"),hOo=o("deberta-v2"),uOo=o(" \u2014 "),hQ=a("a"),pOo=o("DebertaV2ForMaskedLM"),_Oo=o(" (DeBERTa-v2 model)"),bOo=l(),Y2=a("li"),nbe=a("strong"),vOo=o("distilbert"),FOo=o(" \u2014 "),uQ=a("a"),TOo=o("DistilBertForMaskedLM"),MOo=o(" (DistilBERT model)"),EOo=l(),Z2=a("li"),sbe=a("strong"),COo=o("electra"),wOo=o(" \u2014 "),pQ=a("a"),AOo=o("ElectraForPreTraining"),LOo=o(" (ELECTRA model)"),yOo=l(),K2=a("li"),lbe=a("strong"),xOo=o("ernie"),$Oo=o(" \u2014 "),_Q=a("a"),kOo=o("ErnieForPreTraining"),SOo=o(" (ERNIE model)"),ROo=l(),eb=a("li"),ibe=a("strong"),POo=o("flaubert"),BOo=o(" \u2014 "),bQ=a("a"),IOo=o("FlaubertWithLMHeadModel"),NOo=o(" (FlauBERT model)"),qOo=l(),ob=a("li"),dbe=a("strong"),jOo=o("flava"),DOo=o(" \u2014 "),vQ=a("a"),GOo=o("FlavaForPreTraining"),OOo=o(" (FLAVA model)"),VOo=l(),rb=a("li"),cbe=a("strong"),XOo=o("fnet"),zOo=o(" \u2014 "),FQ=a("a"),QOo=o("FNetForPreTraining"),WOo=o(" (FNet model)"),UOo=l(),tb=a("li"),mbe=a("strong"),HOo=o("fsmt"),JOo=o(" \u2014 "),TQ=a("a"),YOo=o("FSMTForConditionalGeneration"),ZOo=o(" (FairSeq Machine-Translation model)"),KOo=l(),ab=a("li"),fbe=a("strong"),eVo=o("funnel"),oVo=o(" \u2014 "),MQ=a("a"),rVo=o("FunnelForPreTraining"),tVo=o(" (Funnel Transformer model)"),aVo=l(),nb=a("li"),gbe=a("strong"),nVo=o("gpt2"),sVo=o(" \u2014 "),EQ=a("a"),lVo=o("GPT2LMHeadModel"),iVo=o(" (OpenAI GPT-2 model)"),dVo=l(),sb=a("li"),hbe=a("strong"),cVo=o("ibert"),mVo=o(" \u2014 "),CQ=a("a"),fVo=o("IBertForMaskedLM"),gVo=o(" (I-BERT model)"),hVo=l(),lb=a("li"),ube=a("strong"),uVo=o("layoutlm"),pVo=o(" \u2014 "),wQ=a("a"),_Vo=o("LayoutLMForMaskedLM"),bVo=o(" (LayoutLM model)"),vVo=l(),ib=a("li"),pbe=a("strong"),FVo=o("longformer"),TVo=o(" \u2014 "),AQ=a("a"),MVo=o("LongformerForMaskedLM"),EVo=o(" (Longformer model)"),CVo=l(),db=a("li"),_be=a("strong"),wVo=o("luke"),AVo=o(" \u2014 "),LQ=a("a"),LVo=o("LukeForMaskedLM"),yVo=o(" (LUKE model)"),xVo=l(),cb=a("li"),bbe=a("strong"),$Vo=o("lxmert"),kVo=o(" \u2014 "),yQ=a("a"),SVo=o("LxmertForPreTraining"),RVo=o(" (LXMERT model)"),PVo=l(),mb=a("li"),vbe=a("strong"),BVo=o("megatron-bert"),IVo=o(" \u2014 "),xQ=a("a"),NVo=o("MegatronBertForPreTraining"),qVo=o(" (Megatron-BERT model)"),jVo=l(),fb=a("li"),Fbe=a("strong"),DVo=o("mobilebert"),GVo=o(" \u2014 "),$Q=a("a"),OVo=o("MobileBertForPreTraining"),VVo=o(" (MobileBERT model)"),XVo=l(),gb=a("li"),Tbe=a("strong"),zVo=o("mpnet"),QVo=o(" \u2014 "),kQ=a("a"),WVo=o("MPNetForMaskedLM"),UVo=o(" (MPNet model)"),HVo=l(),hb=a("li"),Mbe=a("strong"),JVo=o("mvp"),YVo=o(" \u2014 "),SQ=a("a"),ZVo=o("MvpForConditionalGeneration"),KVo=o(" (MVP model)"),eXo=l(),ub=a("li"),Ebe=a("strong"),oXo=o("nezha"),rXo=o(" \u2014 "),RQ=a("a"),tXo=o("NezhaForPreTraining"),aXo=o(" (Nezha model)"),nXo=l(),pb=a("li"),Cbe=a("strong"),sXo=o("openai-gpt"),lXo=o(" \u2014 "),PQ=a("a"),iXo=o("OpenAIGPTLMHeadModel"),dXo=o(" (OpenAI GPT model)"),cXo=l(),_b=a("li"),wbe=a("strong"),mXo=o("retribert"),fXo=o(" \u2014 "),BQ=a("a"),gXo=o("RetriBertModel"),hXo=o(" (RetriBERT model)"),uXo=l(),bb=a("li"),Abe=a("strong"),pXo=o("roberta"),_Xo=o(" \u2014 "),IQ=a("a"),bXo=o("RobertaForMaskedLM"),vXo=o(" (RoBERTa model)"),FXo=l(),vb=a("li"),Lbe=a("strong"),TXo=o("splinter"),MXo=o(" \u2014 "),NQ=a("a"),EXo=o("SplinterForPreTraining"),CXo=o(" (Splinter model)"),wXo=l(),Fb=a("li"),ybe=a("strong"),AXo=o("squeezebert"),LXo=o(" \u2014 "),qQ=a("a"),yXo=o("SqueezeBertForMaskedLM"),xXo=o(" (SqueezeBERT model)"),$Xo=l(),Tb=a("li"),xbe=a("strong"),kXo=o("t5"),SXo=o(" \u2014 "),jQ=a("a"),RXo=o("T5ForConditionalGeneration"),PXo=o(" (T5 model)"),BXo=l(),Mb=a("li"),$be=a("strong"),IXo=o("tapas"),NXo=o(" \u2014 "),DQ=a("a"),qXo=o("TapasForMaskedLM"),jXo=o(" (TAPAS model)"),DXo=l(),Eb=a("li"),kbe=a("strong"),GXo=o("transfo-xl"),OXo=o(" \u2014 "),GQ=a("a"),VXo=o("TransfoXLLMHeadModel"),XXo=o(" (Transformer-XL model)"),zXo=l(),Cb=a("li"),Sbe=a("strong"),QXo=o("unispeech"),WXo=o(" \u2014 "),OQ=a("a"),UXo=o("UniSpeechForPreTraining"),HXo=o(" (UniSpeech model)"),JXo=l(),wb=a("li"),Rbe=a("strong"),YXo=o("unispeech-sat"),ZXo=o(" \u2014 "),VQ=a("a"),KXo=o("UniSpeechSatForPreTraining"),ezo=o(" (UniSpeechSat model)"),ozo=l(),Ab=a("li"),Pbe=a("strong"),rzo=o("videomae"),tzo=o(" \u2014 "),XQ=a("a"),azo=o("VideoMAEForPreTraining"),nzo=o(" (VideoMAE model)"),szo=l(),Lb=a("li"),Bbe=a("strong"),lzo=o("visual_bert"),izo=o(" \u2014 "),zQ=a("a"),dzo=o("VisualBertForPreTraining"),czo=o(" (VisualBERT model)"),mzo=l(),yb=a("li"),Ibe=a("strong"),fzo=o("vit_mae"),gzo=o(" \u2014 "),QQ=a("a"),hzo=o("ViTMAEForPreTraining"),uzo=o(" (ViTMAE model)"),pzo=l(),xb=a("li"),Nbe=a("strong"),_zo=o("wav2vec2"),bzo=o(" \u2014 "),WQ=a("a"),vzo=o("Wav2Vec2ForPreTraining"),Fzo=o(" (Wav2Vec2 model)"),Tzo=l(),$b=a("li"),qbe=a("strong"),Mzo=o("wav2vec2-conformer"),Ezo=o(" \u2014 "),UQ=a("a"),Czo=o("Wav2Vec2ConformerForPreTraining"),wzo=o(" (Wav2Vec2-Conformer model)"),Azo=l(),kb=a("li"),jbe=a("strong"),Lzo=o("xlm"),yzo=o(" \u2014 "),HQ=a("a"),xzo=o("XLMWithLMHeadModel"),$zo=o(" (XLM model)"),kzo=l(),Sb=a("li"),Dbe=a("strong"),Szo=o("xlm-roberta"),Rzo=o(" \u2014 "),JQ=a("a"),Pzo=o("XLMRobertaForMaskedLM"),Bzo=o(" (XLM-RoBERTa model)"),Izo=l(),Rb=a("li"),Gbe=a("strong"),Nzo=o("xlm-roberta-xl"),qzo=o(" \u2014 "),YQ=a("a"),jzo=o("XLMRobertaXLForMaskedLM"),Dzo=o(" (XLM-RoBERTa-XL model)"),Gzo=l(),Pb=a("li"),Obe=a("strong"),Ozo=o("xlnet"),Vzo=o(" \u2014 "),ZQ=a("a"),Xzo=o("XLNetLMHeadModel"),zzo=o(" (XLNet model)"),Qzo=l(),Bb=a("p"),Wzo=o("The model is set in evaluation mode by default using "),Vbe=a("code"),Uzo=o("model.eval()"),Hzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xbe=a("code"),Jzo=o("model.train()"),Yzo=l(),F(Ib.$$.fragment),Goo=l(),xd=a("h2"),Nb=a("a"),zbe=a("span"),F(f$.$$.fragment),Zzo=l(),Qbe=a("span"),Kzo=o("AutoModelForCausalLM"),Ooo=l(),No=a("div"),F(g$.$$.fragment),eQo=l(),$d=a("p"),oQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),KQ=a("a"),rQo=o("from_pretrained()"),tQo=o(" class method or the "),eW=a("a"),aQo=o("from_config()"),nQo=o(` class
method.`),sQo=l(),h$=a("p"),lQo=o("This class cannot be instantiated directly using "),Wbe=a("code"),iQo=o("__init__()"),dQo=o(" (throws an error)."),cQo=l(),Tt=a("div"),F(u$.$$.fragment),mQo=l(),Ube=a("p"),fQo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gQo=l(),kd=a("p"),hQo=o(`Note:
Loading a model from its configuration file does `),Hbe=a("strong"),uQo=o("not"),pQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=a("a"),_Qo=o("from_pretrained()"),bQo=o(" to load the model weights."),vQo=l(),F(qb.$$.fragment),FQo=l(),oo=a("div"),F(p$.$$.fragment),TQo=l(),Jbe=a("p"),MQo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),EQo=l(),rn=a("p"),CQo=o("The model class to instantiate is selected based on the "),Ybe=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),Zbe=a("code"),LQo=o("pretrained_model_name_or_path"),yQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kbe=a("code"),xQo=o("pretrained_model_name_or_path"),$Qo=o(":"),kQo=l(),Q=a("ul"),jb=a("li"),eve=a("strong"),SQo=o("bart"),RQo=o(" \u2014 "),rW=a("a"),PQo=o("BartForCausalLM"),BQo=o(" (BART model)"),IQo=l(),Db=a("li"),ove=a("strong"),NQo=o("bert"),qQo=o(" \u2014 "),tW=a("a"),jQo=o("BertLMHeadModel"),DQo=o(" (BERT model)"),GQo=l(),Gb=a("li"),rve=a("strong"),OQo=o("bert-generation"),VQo=o(" \u2014 "),aW=a("a"),XQo=o("BertGenerationDecoder"),zQo=o(" (Bert Generation model)"),QQo=l(),Ob=a("li"),tve=a("strong"),WQo=o("big_bird"),UQo=o(" \u2014 "),nW=a("a"),HQo=o("BigBirdForCausalLM"),JQo=o(" (BigBird model)"),YQo=l(),Vb=a("li"),ave=a("strong"),ZQo=o("bigbird_pegasus"),KQo=o(" \u2014 "),sW=a("a"),eWo=o("BigBirdPegasusForCausalLM"),oWo=o(" (BigBird-Pegasus model)"),rWo=l(),Xb=a("li"),nve=a("strong"),tWo=o("blenderbot"),aWo=o(" \u2014 "),lW=a("a"),nWo=o("BlenderbotForCausalLM"),sWo=o(" (Blenderbot model)"),lWo=l(),zb=a("li"),sve=a("strong"),iWo=o("blenderbot-small"),dWo=o(" \u2014 "),iW=a("a"),cWo=o("BlenderbotSmallForCausalLM"),mWo=o(" (BlenderbotSmall model)"),fWo=l(),Qb=a("li"),lve=a("strong"),gWo=o("bloom"),hWo=o(" \u2014 "),dW=a("a"),uWo=o("BloomForCausalLM"),pWo=o(" (BLOOM model)"),_Wo=l(),Wb=a("li"),ive=a("strong"),bWo=o("camembert"),vWo=o(" \u2014 "),cW=a("a"),FWo=o("CamembertForCausalLM"),TWo=o(" (CamemBERT model)"),MWo=l(),Ub=a("li"),dve=a("strong"),EWo=o("codegen"),CWo=o(" \u2014 "),mW=a("a"),wWo=o("CodeGenForCausalLM"),AWo=o(" (CodeGen model)"),LWo=l(),Hb=a("li"),cve=a("strong"),yWo=o("ctrl"),xWo=o(" \u2014 "),fW=a("a"),$Wo=o("CTRLLMHeadModel"),kWo=o(" (CTRL model)"),SWo=l(),Jb=a("li"),mve=a("strong"),RWo=o("data2vec-text"),PWo=o(" \u2014 "),gW=a("a"),BWo=o("Data2VecTextForCausalLM"),IWo=o(" (Data2VecText model)"),NWo=l(),Yb=a("li"),fve=a("strong"),qWo=o("electra"),jWo=o(" \u2014 "),hW=a("a"),DWo=o("ElectraForCausalLM"),GWo=o(" (ELECTRA model)"),OWo=l(),Zb=a("li"),gve=a("strong"),VWo=o("ernie"),XWo=o(" \u2014 "),uW=a("a"),zWo=o("ErnieForCausalLM"),QWo=o(" (ERNIE model)"),WWo=l(),Kb=a("li"),hve=a("strong"),UWo=o("gpt2"),HWo=o(" \u2014 "),pW=a("a"),JWo=o("GPT2LMHeadModel"),YWo=o(" (OpenAI GPT-2 model)"),ZWo=l(),ev=a("li"),uve=a("strong"),KWo=o("gpt_neo"),eUo=o(" \u2014 "),_W=a("a"),oUo=o("GPTNeoForCausalLM"),rUo=o(" (GPT Neo model)"),tUo=l(),ov=a("li"),pve=a("strong"),aUo=o("gpt_neox"),nUo=o(" \u2014 "),bW=a("a"),sUo=o("GPTNeoXForCausalLM"),lUo=o(" (GPT NeoX model)"),iUo=l(),rv=a("li"),_ve=a("strong"),dUo=o("gpt_neox_japanese"),cUo=o(" \u2014 "),vW=a("a"),mUo=o("GPTNeoXJapaneseForCausalLM"),fUo=o(" (GPT NeoX Japanese model)"),gUo=l(),tv=a("li"),bve=a("strong"),hUo=o("gptj"),uUo=o(" \u2014 "),FW=a("a"),pUo=o("GPTJForCausalLM"),_Uo=o(" (GPT-J model)"),bUo=l(),av=a("li"),vve=a("strong"),vUo=o("marian"),FUo=o(" \u2014 "),TW=a("a"),TUo=o("MarianForCausalLM"),MUo=o(" (Marian model)"),EUo=l(),nv=a("li"),Fve=a("strong"),CUo=o("mbart"),wUo=o(" \u2014 "),MW=a("a"),AUo=o("MBartForCausalLM"),LUo=o(" (mBART model)"),yUo=l(),sv=a("li"),Tve=a("strong"),xUo=o("megatron-bert"),$Uo=o(" \u2014 "),EW=a("a"),kUo=o("MegatronBertForCausalLM"),SUo=o(" (Megatron-BERT model)"),RUo=l(),lv=a("li"),Mve=a("strong"),PUo=o("mvp"),BUo=o(" \u2014 "),CW=a("a"),IUo=o("MvpForCausalLM"),NUo=o(" (MVP model)"),qUo=l(),iv=a("li"),Eve=a("strong"),jUo=o("openai-gpt"),DUo=o(" \u2014 "),wW=a("a"),GUo=o("OpenAIGPTLMHeadModel"),OUo=o(" (OpenAI GPT model)"),VUo=l(),dv=a("li"),Cve=a("strong"),XUo=o("opt"),zUo=o(" \u2014 "),AW=a("a"),QUo=o("OPTForCausalLM"),WUo=o(" (OPT model)"),UUo=l(),cv=a("li"),wve=a("strong"),HUo=o("pegasus"),JUo=o(" \u2014 "),LW=a("a"),YUo=o("PegasusForCausalLM"),ZUo=o(" (Pegasus model)"),KUo=l(),mv=a("li"),Ave=a("strong"),eHo=o("plbart"),oHo=o(" \u2014 "),yW=a("a"),rHo=o("PLBartForCausalLM"),tHo=o(" (PLBart model)"),aHo=l(),fv=a("li"),Lve=a("strong"),nHo=o("prophetnet"),sHo=o(" \u2014 "),xW=a("a"),lHo=o("ProphetNetForCausalLM"),iHo=o(" (ProphetNet model)"),dHo=l(),gv=a("li"),yve=a("strong"),cHo=o("qdqbert"),mHo=o(" \u2014 "),$W=a("a"),fHo=o("QDQBertLMHeadModel"),gHo=o(" (QDQBert model)"),hHo=l(),hv=a("li"),xve=a("strong"),uHo=o("reformer"),pHo=o(" \u2014 "),kW=a("a"),_Ho=o("ReformerModelWithLMHead"),bHo=o(" (Reformer model)"),vHo=l(),uv=a("li"),$ve=a("strong"),FHo=o("rembert"),THo=o(" \u2014 "),SW=a("a"),MHo=o("RemBertForCausalLM"),EHo=o(" (RemBERT model)"),CHo=l(),pv=a("li"),kve=a("strong"),wHo=o("roberta"),AHo=o(" \u2014 "),RW=a("a"),LHo=o("RobertaForCausalLM"),yHo=o(" (RoBERTa model)"),xHo=l(),_v=a("li"),Sve=a("strong"),$Ho=o("roformer"),kHo=o(" \u2014 "),PW=a("a"),SHo=o("RoFormerForCausalLM"),RHo=o(" (RoFormer model)"),PHo=l(),bv=a("li"),Rve=a("strong"),BHo=o("speech_to_text_2"),IHo=o(" \u2014 "),BW=a("a"),NHo=o("Speech2Text2ForCausalLM"),qHo=o(" (Speech2Text2 model)"),jHo=l(),vv=a("li"),Pve=a("strong"),DHo=o("transfo-xl"),GHo=o(" \u2014 "),IW=a("a"),OHo=o("TransfoXLLMHeadModel"),VHo=o(" (Transformer-XL model)"),XHo=l(),Fv=a("li"),Bve=a("strong"),zHo=o("trocr"),QHo=o(" \u2014 "),NW=a("a"),WHo=o("TrOCRForCausalLM"),UHo=o(" (TrOCR model)"),HHo=l(),Tv=a("li"),Ive=a("strong"),JHo=o("xglm"),YHo=o(" \u2014 "),qW=a("a"),ZHo=o("XGLMForCausalLM"),KHo=o(" (XGLM model)"),eJo=l(),Mv=a("li"),Nve=a("strong"),oJo=o("xlm"),rJo=o(" \u2014 "),jW=a("a"),tJo=o("XLMWithLMHeadModel"),aJo=o(" (XLM model)"),nJo=l(),Ev=a("li"),qve=a("strong"),sJo=o("xlm-prophetnet"),lJo=o(" \u2014 "),DW=a("a"),iJo=o("XLMProphetNetForCausalLM"),dJo=o(" (XLM-ProphetNet model)"),cJo=l(),Cv=a("li"),jve=a("strong"),mJo=o("xlm-roberta"),fJo=o(" \u2014 "),GW=a("a"),gJo=o("XLMRobertaForCausalLM"),hJo=o(" (XLM-RoBERTa model)"),uJo=l(),wv=a("li"),Dve=a("strong"),pJo=o("xlm-roberta-xl"),_Jo=o(" \u2014 "),OW=a("a"),bJo=o("XLMRobertaXLForCausalLM"),vJo=o(" (XLM-RoBERTa-XL model)"),FJo=l(),Av=a("li"),Gve=a("strong"),TJo=o("xlnet"),MJo=o(" \u2014 "),VW=a("a"),EJo=o("XLNetLMHeadModel"),CJo=o(" (XLNet model)"),wJo=l(),Lv=a("p"),AJo=o("The model is set in evaluation mode by default using "),Ove=a("code"),LJo=o("model.eval()"),yJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vve=a("code"),xJo=o("model.train()"),$Jo=l(),F(yv.$$.fragment),Voo=l(),Sd=a("h2"),xv=a("a"),Xve=a("span"),F(_$.$$.fragment),kJo=l(),zve=a("span"),SJo=o("AutoModelForMaskedLM"),Xoo=l(),qo=a("div"),F(b$.$$.fragment),RJo=l(),Rd=a("p"),PJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),XW=a("a"),BJo=o("from_pretrained()"),IJo=o(" class method or the "),zW=a("a"),NJo=o("from_config()"),qJo=o(` class
method.`),jJo=l(),v$=a("p"),DJo=o("This class cannot be instantiated directly using "),Qve=a("code"),GJo=o("__init__()"),OJo=o(" (throws an error)."),VJo=l(),Mt=a("div"),F(F$.$$.fragment),XJo=l(),Wve=a("p"),zJo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),QJo=l(),Pd=a("p"),WJo=o(`Note:
Loading a model from its configuration file does `),Uve=a("strong"),UJo=o("not"),HJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QW=a("a"),JJo=o("from_pretrained()"),YJo=o(" to load the model weights."),ZJo=l(),F($v.$$.fragment),KJo=l(),ro=a("div"),F(T$.$$.fragment),eYo=l(),Hve=a("p"),oYo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),rYo=l(),tn=a("p"),tYo=o("The model class to instantiate is selected based on the "),Jve=a("code"),aYo=o("model_type"),nYo=o(` property of the config object (either
passed as an argument or loaded from `),Yve=a("code"),sYo=o("pretrained_model_name_or_path"),lYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zve=a("code"),iYo=o("pretrained_model_name_or_path"),dYo=o(":"),cYo=l(),J=a("ul"),kv=a("li"),Kve=a("strong"),mYo=o("albert"),fYo=o(" \u2014 "),WW=a("a"),gYo=o("AlbertForMaskedLM"),hYo=o(" (ALBERT model)"),uYo=l(),Sv=a("li"),eFe=a("strong"),pYo=o("bart"),_Yo=o(" \u2014 "),UW=a("a"),bYo=o("BartForConditionalGeneration"),vYo=o(" (BART model)"),FYo=l(),Rv=a("li"),oFe=a("strong"),TYo=o("bert"),MYo=o(" \u2014 "),HW=a("a"),EYo=o("BertForMaskedLM"),CYo=o(" (BERT model)"),wYo=l(),Pv=a("li"),rFe=a("strong"),AYo=o("big_bird"),LYo=o(" \u2014 "),JW=a("a"),yYo=o("BigBirdForMaskedLM"),xYo=o(" (BigBird model)"),$Yo=l(),Bv=a("li"),tFe=a("strong"),kYo=o("camembert"),SYo=o(" \u2014 "),YW=a("a"),RYo=o("CamembertForMaskedLM"),PYo=o(" (CamemBERT model)"),BYo=l(),Iv=a("li"),aFe=a("strong"),IYo=o("convbert"),NYo=o(" \u2014 "),ZW=a("a"),qYo=o("ConvBertForMaskedLM"),jYo=o(" (ConvBERT model)"),DYo=l(),Nv=a("li"),nFe=a("strong"),GYo=o("data2vec-text"),OYo=o(" \u2014 "),KW=a("a"),VYo=o("Data2VecTextForMaskedLM"),XYo=o(" (Data2VecText model)"),zYo=l(),qv=a("li"),sFe=a("strong"),QYo=o("deberta"),WYo=o(" \u2014 "),eU=a("a"),UYo=o("DebertaForMaskedLM"),HYo=o(" (DeBERTa model)"),JYo=l(),jv=a("li"),lFe=a("strong"),YYo=o("deberta-v2"),ZYo=o(" \u2014 "),oU=a("a"),KYo=o("DebertaV2ForMaskedLM"),eZo=o(" (DeBERTa-v2 model)"),oZo=l(),Dv=a("li"),iFe=a("strong"),rZo=o("distilbert"),tZo=o(" \u2014 "),rU=a("a"),aZo=o("DistilBertForMaskedLM"),nZo=o(" (DistilBERT model)"),sZo=l(),Gv=a("li"),dFe=a("strong"),lZo=o("electra"),iZo=o(" \u2014 "),tU=a("a"),dZo=o("ElectraForMaskedLM"),cZo=o(" (ELECTRA model)"),mZo=l(),Ov=a("li"),cFe=a("strong"),fZo=o("ernie"),gZo=o(" \u2014 "),aU=a("a"),hZo=o("ErnieForMaskedLM"),uZo=o(" (ERNIE model)"),pZo=l(),Vv=a("li"),mFe=a("strong"),_Zo=o("flaubert"),bZo=o(" \u2014 "),nU=a("a"),vZo=o("FlaubertWithLMHeadModel"),FZo=o(" (FlauBERT model)"),TZo=l(),Xv=a("li"),fFe=a("strong"),MZo=o("fnet"),EZo=o(" \u2014 "),sU=a("a"),CZo=o("FNetForMaskedLM"),wZo=o(" (FNet model)"),AZo=l(),zv=a("li"),gFe=a("strong"),LZo=o("funnel"),yZo=o(" \u2014 "),lU=a("a"),xZo=o("FunnelForMaskedLM"),$Zo=o(" (Funnel Transformer model)"),kZo=l(),Qv=a("li"),hFe=a("strong"),SZo=o("ibert"),RZo=o(" \u2014 "),iU=a("a"),PZo=o("IBertForMaskedLM"),BZo=o(" (I-BERT model)"),IZo=l(),Wv=a("li"),uFe=a("strong"),NZo=o("layoutlm"),qZo=o(" \u2014 "),dU=a("a"),jZo=o("LayoutLMForMaskedLM"),DZo=o(" (LayoutLM model)"),GZo=l(),Uv=a("li"),pFe=a("strong"),OZo=o("longformer"),VZo=o(" \u2014 "),cU=a("a"),XZo=o("LongformerForMaskedLM"),zZo=o(" (Longformer model)"),QZo=l(),Hv=a("li"),_Fe=a("strong"),WZo=o("luke"),UZo=o(" \u2014 "),mU=a("a"),HZo=o("LukeForMaskedLM"),JZo=o(" (LUKE model)"),YZo=l(),Jv=a("li"),bFe=a("strong"),ZZo=o("mbart"),KZo=o(" \u2014 "),fU=a("a"),eKo=o("MBartForConditionalGeneration"),oKo=o(" (mBART model)"),rKo=l(),Yv=a("li"),vFe=a("strong"),tKo=o("megatron-bert"),aKo=o(" \u2014 "),gU=a("a"),nKo=o("MegatronBertForMaskedLM"),sKo=o(" (Megatron-BERT model)"),lKo=l(),Zv=a("li"),FFe=a("strong"),iKo=o("mobilebert"),dKo=o(" \u2014 "),hU=a("a"),cKo=o("MobileBertForMaskedLM"),mKo=o(" (MobileBERT model)"),fKo=l(),Kv=a("li"),TFe=a("strong"),gKo=o("mpnet"),hKo=o(" \u2014 "),uU=a("a"),uKo=o("MPNetForMaskedLM"),pKo=o(" (MPNet model)"),_Ko=l(),eF=a("li"),MFe=a("strong"),bKo=o("mvp"),vKo=o(" \u2014 "),pU=a("a"),FKo=o("MvpForConditionalGeneration"),TKo=o(" (MVP model)"),MKo=l(),oF=a("li"),EFe=a("strong"),EKo=o("nezha"),CKo=o(" \u2014 "),_U=a("a"),wKo=o("NezhaForMaskedLM"),AKo=o(" (Nezha model)"),LKo=l(),rF=a("li"),CFe=a("strong"),yKo=o("nystromformer"),xKo=o(" \u2014 "),bU=a("a"),$Ko=o("NystromformerForMaskedLM"),kKo=o(" (Nystr\xF6mformer model)"),SKo=l(),tF=a("li"),wFe=a("strong"),RKo=o("perceiver"),PKo=o(" \u2014 "),vU=a("a"),BKo=o("PerceiverForMaskedLM"),IKo=o(" (Perceiver model)"),NKo=l(),aF=a("li"),AFe=a("strong"),qKo=o("qdqbert"),jKo=o(" \u2014 "),FU=a("a"),DKo=o("QDQBertForMaskedLM"),GKo=o(" (QDQBert model)"),OKo=l(),nF=a("li"),LFe=a("strong"),VKo=o("reformer"),XKo=o(" \u2014 "),TU=a("a"),zKo=o("ReformerForMaskedLM"),QKo=o(" (Reformer model)"),WKo=l(),sF=a("li"),yFe=a("strong"),UKo=o("rembert"),HKo=o(" \u2014 "),MU=a("a"),JKo=o("RemBertForMaskedLM"),YKo=o(" (RemBERT model)"),ZKo=l(),lF=a("li"),xFe=a("strong"),KKo=o("roberta"),eer=o(" \u2014 "),EU=a("a"),oer=o("RobertaForMaskedLM"),rer=o(" (RoBERTa model)"),ter=l(),iF=a("li"),$Fe=a("strong"),aer=o("roformer"),ner=o(" \u2014 "),CU=a("a"),ser=o("RoFormerForMaskedLM"),ler=o(" (RoFormer model)"),ier=l(),dF=a("li"),kFe=a("strong"),der=o("squeezebert"),cer=o(" \u2014 "),wU=a("a"),mer=o("SqueezeBertForMaskedLM"),fer=o(" (SqueezeBERT model)"),ger=l(),cF=a("li"),SFe=a("strong"),her=o("tapas"),uer=o(" \u2014 "),AU=a("a"),per=o("TapasForMaskedLM"),_er=o(" (TAPAS model)"),ber=l(),mF=a("li"),RFe=a("strong"),ver=o("wav2vec2"),Fer=o(" \u2014 "),PFe=a("code"),Ter=o("Wav2Vec2ForMaskedLM"),Mer=o(" (Wav2Vec2 model)"),Eer=l(),fF=a("li"),BFe=a("strong"),Cer=o("xlm"),wer=o(" \u2014 "),LU=a("a"),Aer=o("XLMWithLMHeadModel"),Ler=o(" (XLM model)"),yer=l(),gF=a("li"),IFe=a("strong"),xer=o("xlm-roberta"),$er=o(" \u2014 "),yU=a("a"),ker=o("XLMRobertaForMaskedLM"),Ser=o(" (XLM-RoBERTa model)"),Rer=l(),hF=a("li"),NFe=a("strong"),Per=o("xlm-roberta-xl"),Ber=o(" \u2014 "),xU=a("a"),Ier=o("XLMRobertaXLForMaskedLM"),Ner=o(" (XLM-RoBERTa-XL model)"),qer=l(),uF=a("li"),qFe=a("strong"),jer=o("yoso"),Der=o(" \u2014 "),$U=a("a"),Ger=o("YosoForMaskedLM"),Oer=o(" (YOSO model)"),Ver=l(),pF=a("p"),Xer=o("The model is set in evaluation mode by default using "),jFe=a("code"),zer=o("model.eval()"),Qer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DFe=a("code"),Wer=o("model.train()"),Uer=l(),F(_F.$$.fragment),zoo=l(),Bd=a("h2"),bF=a("a"),GFe=a("span"),F(M$.$$.fragment),Her=l(),OFe=a("span"),Jer=o("AutoModelForSeq2SeqLM"),Qoo=l(),jo=a("div"),F(E$.$$.fragment),Yer=l(),Id=a("p"),Zer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kU=a("a"),Ker=o("from_pretrained()"),eor=o(" class method or the "),SU=a("a"),oor=o("from_config()"),ror=o(` class
method.`),tor=l(),C$=a("p"),aor=o("This class cannot be instantiated directly using "),VFe=a("code"),nor=o("__init__()"),sor=o(" (throws an error)."),lor=l(),Et=a("div"),F(w$.$$.fragment),ior=l(),XFe=a("p"),dor=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),cor=l(),Nd=a("p"),mor=o(`Note:
Loading a model from its configuration file does `),zFe=a("strong"),gor=o("not"),hor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=a("a"),uor=o("from_pretrained()"),por=o(" to load the model weights."),_or=l(),F(vF.$$.fragment),bor=l(),to=a("div"),F(A$.$$.fragment),vor=l(),QFe=a("p"),For=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Tor=l(),an=a("p"),Mor=o("The model class to instantiate is selected based on the "),WFe=a("code"),Eor=o("model_type"),Cor=o(` property of the config object (either
passed as an argument or loaded from `),UFe=a("code"),wor=o("pretrained_model_name_or_path"),Aor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HFe=a("code"),Lor=o("pretrained_model_name_or_path"),yor=o(":"),xor=l(),fe=a("ul"),FF=a("li"),JFe=a("strong"),$or=o("bart"),kor=o(" \u2014 "),PU=a("a"),Sor=o("BartForConditionalGeneration"),Ror=o(" (BART model)"),Por=l(),TF=a("li"),YFe=a("strong"),Bor=o("bigbird_pegasus"),Ior=o(" \u2014 "),BU=a("a"),Nor=o("BigBirdPegasusForConditionalGeneration"),qor=o(" (BigBird-Pegasus model)"),jor=l(),MF=a("li"),ZFe=a("strong"),Dor=o("blenderbot"),Gor=o(" \u2014 "),IU=a("a"),Oor=o("BlenderbotForConditionalGeneration"),Vor=o(" (Blenderbot model)"),Xor=l(),EF=a("li"),KFe=a("strong"),zor=o("blenderbot-small"),Qor=o(" \u2014 "),NU=a("a"),Wor=o("BlenderbotSmallForConditionalGeneration"),Uor=o(" (BlenderbotSmall model)"),Hor=l(),CF=a("li"),eTe=a("strong"),Jor=o("encoder-decoder"),Yor=o(" \u2014 "),qU=a("a"),Zor=o("EncoderDecoderModel"),Kor=o(" (Encoder decoder model)"),err=l(),wF=a("li"),oTe=a("strong"),orr=o("fsmt"),rrr=o(" \u2014 "),jU=a("a"),trr=o("FSMTForConditionalGeneration"),arr=o(" (FairSeq Machine-Translation model)"),nrr=l(),AF=a("li"),rTe=a("strong"),srr=o("led"),lrr=o(" \u2014 "),DU=a("a"),irr=o("LEDForConditionalGeneration"),drr=o(" (LED model)"),crr=l(),LF=a("li"),tTe=a("strong"),mrr=o("longt5"),frr=o(" \u2014 "),GU=a("a"),grr=o("LongT5ForConditionalGeneration"),hrr=o(" (LongT5 model)"),urr=l(),yF=a("li"),aTe=a("strong"),prr=o("m2m_100"),_rr=o(" \u2014 "),OU=a("a"),brr=o("M2M100ForConditionalGeneration"),vrr=o(" (M2M100 model)"),Frr=l(),xF=a("li"),nTe=a("strong"),Trr=o("marian"),Mrr=o(" \u2014 "),VU=a("a"),Err=o("MarianMTModel"),Crr=o(" (Marian model)"),wrr=l(),$F=a("li"),sTe=a("strong"),Arr=o("mbart"),Lrr=o(" \u2014 "),XU=a("a"),yrr=o("MBartForConditionalGeneration"),xrr=o(" (mBART model)"),$rr=l(),kF=a("li"),lTe=a("strong"),krr=o("mt5"),Srr=o(" \u2014 "),zU=a("a"),Rrr=o("MT5ForConditionalGeneration"),Prr=o(" (MT5 model)"),Brr=l(),SF=a("li"),iTe=a("strong"),Irr=o("mvp"),Nrr=o(" \u2014 "),QU=a("a"),qrr=o("MvpForConditionalGeneration"),jrr=o(" (MVP model)"),Drr=l(),RF=a("li"),dTe=a("strong"),Grr=o("nllb"),Orr=o(" \u2014 "),WU=a("a"),Vrr=o("M2M100ForConditionalGeneration"),Xrr=o(" (NLLB model)"),zrr=l(),PF=a("li"),cTe=a("strong"),Qrr=o("pegasus"),Wrr=o(" \u2014 "),UU=a("a"),Urr=o("PegasusForConditionalGeneration"),Hrr=o(" (Pegasus model)"),Jrr=l(),BF=a("li"),mTe=a("strong"),Yrr=o("pegasus_x"),Zrr=o(" \u2014 "),HU=a("a"),Krr=o("PegasusXForConditionalGeneration"),etr=o(" (PEGASUS-X model)"),otr=l(),IF=a("li"),fTe=a("strong"),rtr=o("plbart"),ttr=o(" \u2014 "),JU=a("a"),atr=o("PLBartForConditionalGeneration"),ntr=o(" (PLBart model)"),str=l(),NF=a("li"),gTe=a("strong"),ltr=o("prophetnet"),itr=o(" \u2014 "),YU=a("a"),dtr=o("ProphetNetForConditionalGeneration"),ctr=o(" (ProphetNet model)"),mtr=l(),qF=a("li"),hTe=a("strong"),ftr=o("t5"),gtr=o(" \u2014 "),ZU=a("a"),htr=o("T5ForConditionalGeneration"),utr=o(" (T5 model)"),ptr=l(),jF=a("li"),uTe=a("strong"),_tr=o("xlm-prophetnet"),btr=o(" \u2014 "),KU=a("a"),vtr=o("XLMProphetNetForConditionalGeneration"),Ftr=o(" (XLM-ProphetNet model)"),Ttr=l(),DF=a("p"),Mtr=o("The model is set in evaluation mode by default using "),pTe=a("code"),Etr=o("model.eval()"),Ctr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Te=a("code"),wtr=o("model.train()"),Atr=l(),F(GF.$$.fragment),Woo=l(),qd=a("h2"),OF=a("a"),bTe=a("span"),F(L$.$$.fragment),Ltr=l(),vTe=a("span"),ytr=o("AutoModelForSequenceClassification"),Uoo=l(),Do=a("div"),F(y$.$$.fragment),xtr=l(),jd=a("p"),$tr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),eH=a("a"),ktr=o("from_pretrained()"),Str=o(" class method or the "),oH=a("a"),Rtr=o("from_config()"),Ptr=o(` class
method.`),Btr=l(),x$=a("p"),Itr=o("This class cannot be instantiated directly using "),FTe=a("code"),Ntr=o("__init__()"),qtr=o(" (throws an error)."),jtr=l(),Ct=a("div"),F($$.$$.fragment),Dtr=l(),TTe=a("p"),Gtr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Otr=l(),Dd=a("p"),Vtr=o(`Note:
Loading a model from its configuration file does `),MTe=a("strong"),Xtr=o("not"),ztr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rH=a("a"),Qtr=o("from_pretrained()"),Wtr=o(" to load the model weights."),Utr=l(),F(VF.$$.fragment),Htr=l(),ao=a("div"),F(k$.$$.fragment),Jtr=l(),ETe=a("p"),Ytr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ztr=l(),nn=a("p"),Ktr=o("The model class to instantiate is selected based on the "),CTe=a("code"),ear=o("model_type"),oar=o(` property of the config object (either
passed as an argument or loaded from `),wTe=a("code"),rar=o("pretrained_model_name_or_path"),tar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ATe=a("code"),aar=o("pretrained_model_name_or_path"),nar=o(":"),sar=l(),j=a("ul"),XF=a("li"),LTe=a("strong"),lar=o("albert"),iar=o(" \u2014 "),tH=a("a"),dar=o("AlbertForSequenceClassification"),car=o(" (ALBERT model)"),mar=l(),zF=a("li"),yTe=a("strong"),far=o("bart"),gar=o(" \u2014 "),aH=a("a"),har=o("BartForSequenceClassification"),uar=o(" (BART model)"),par=l(),QF=a("li"),xTe=a("strong"),_ar=o("bert"),bar=o(" \u2014 "),nH=a("a"),Far=o("BertForSequenceClassification"),Tar=o(" (BERT model)"),Mar=l(),WF=a("li"),$Te=a("strong"),Ear=o("big_bird"),Car=o(" \u2014 "),sH=a("a"),war=o("BigBirdForSequenceClassification"),Aar=o(" (BigBird model)"),Lar=l(),UF=a("li"),kTe=a("strong"),yar=o("bigbird_pegasus"),xar=o(" \u2014 "),lH=a("a"),$ar=o("BigBirdPegasusForSequenceClassification"),kar=o(" (BigBird-Pegasus model)"),Sar=l(),HF=a("li"),STe=a("strong"),Rar=o("bloom"),Par=o(" \u2014 "),iH=a("a"),Bar=o("BloomForSequenceClassification"),Iar=o(" (BLOOM model)"),Nar=l(),JF=a("li"),RTe=a("strong"),qar=o("camembert"),jar=o(" \u2014 "),dH=a("a"),Dar=o("CamembertForSequenceClassification"),Gar=o(" (CamemBERT model)"),Oar=l(),YF=a("li"),PTe=a("strong"),Var=o("canine"),Xar=o(" \u2014 "),cH=a("a"),zar=o("CanineForSequenceClassification"),Qar=o(" (CANINE model)"),War=l(),ZF=a("li"),BTe=a("strong"),Uar=o("convbert"),Har=o(" \u2014 "),mH=a("a"),Jar=o("ConvBertForSequenceClassification"),Yar=o(" (ConvBERT model)"),Zar=l(),KF=a("li"),ITe=a("strong"),Kar=o("ctrl"),enr=o(" \u2014 "),fH=a("a"),onr=o("CTRLForSequenceClassification"),rnr=o(" (CTRL model)"),tnr=l(),eT=a("li"),NTe=a("strong"),anr=o("data2vec-text"),nnr=o(" \u2014 "),gH=a("a"),snr=o("Data2VecTextForSequenceClassification"),lnr=o(" (Data2VecText model)"),inr=l(),oT=a("li"),qTe=a("strong"),dnr=o("deberta"),cnr=o(" \u2014 "),hH=a("a"),mnr=o("DebertaForSequenceClassification"),fnr=o(" (DeBERTa model)"),gnr=l(),rT=a("li"),jTe=a("strong"),hnr=o("deberta-v2"),unr=o(" \u2014 "),uH=a("a"),pnr=o("DebertaV2ForSequenceClassification"),_nr=o(" (DeBERTa-v2 model)"),bnr=l(),tT=a("li"),DTe=a("strong"),vnr=o("distilbert"),Fnr=o(" \u2014 "),pH=a("a"),Tnr=o("DistilBertForSequenceClassification"),Mnr=o(" (DistilBERT model)"),Enr=l(),aT=a("li"),GTe=a("strong"),Cnr=o("electra"),wnr=o(" \u2014 "),_H=a("a"),Anr=o("ElectraForSequenceClassification"),Lnr=o(" (ELECTRA model)"),ynr=l(),nT=a("li"),OTe=a("strong"),xnr=o("ernie"),$nr=o(" \u2014 "),bH=a("a"),knr=o("ErnieForSequenceClassification"),Snr=o(" (ERNIE model)"),Rnr=l(),sT=a("li"),VTe=a("strong"),Pnr=o("esm"),Bnr=o(" \u2014 "),vH=a("a"),Inr=o("EsmForSequenceClassification"),Nnr=o(" (ESM model)"),qnr=l(),lT=a("li"),XTe=a("strong"),jnr=o("flaubert"),Dnr=o(" \u2014 "),FH=a("a"),Gnr=o("FlaubertForSequenceClassification"),Onr=o(" (FlauBERT model)"),Vnr=l(),iT=a("li"),zTe=a("strong"),Xnr=o("fnet"),znr=o(" \u2014 "),TH=a("a"),Qnr=o("FNetForSequenceClassification"),Wnr=o(" (FNet model)"),Unr=l(),dT=a("li"),QTe=a("strong"),Hnr=o("funnel"),Jnr=o(" \u2014 "),MH=a("a"),Ynr=o("FunnelForSequenceClassification"),Znr=o(" (Funnel Transformer model)"),Knr=l(),cT=a("li"),WTe=a("strong"),esr=o("gpt2"),osr=o(" \u2014 "),EH=a("a"),rsr=o("GPT2ForSequenceClassification"),tsr=o(" (OpenAI GPT-2 model)"),asr=l(),mT=a("li"),UTe=a("strong"),nsr=o("gpt_neo"),ssr=o(" \u2014 "),CH=a("a"),lsr=o("GPTNeoForSequenceClassification"),isr=o(" (GPT Neo model)"),dsr=l(),fT=a("li"),HTe=a("strong"),csr=o("gptj"),msr=o(" \u2014 "),wH=a("a"),fsr=o("GPTJForSequenceClassification"),gsr=o(" (GPT-J model)"),hsr=l(),gT=a("li"),JTe=a("strong"),usr=o("ibert"),psr=o(" \u2014 "),AH=a("a"),_sr=o("IBertForSequenceClassification"),bsr=o(" (I-BERT model)"),vsr=l(),hT=a("li"),YTe=a("strong"),Fsr=o("layoutlm"),Tsr=o(" \u2014 "),LH=a("a"),Msr=o("LayoutLMForSequenceClassification"),Esr=o(" (LayoutLM model)"),Csr=l(),uT=a("li"),ZTe=a("strong"),wsr=o("layoutlmv2"),Asr=o(" \u2014 "),yH=a("a"),Lsr=o("LayoutLMv2ForSequenceClassification"),ysr=o(" (LayoutLMv2 model)"),xsr=l(),pT=a("li"),KTe=a("strong"),$sr=o("layoutlmv3"),ksr=o(" \u2014 "),xH=a("a"),Ssr=o("LayoutLMv3ForSequenceClassification"),Rsr=o(" (LayoutLMv3 model)"),Psr=l(),_T=a("li"),eMe=a("strong"),Bsr=o("led"),Isr=o(" \u2014 "),$H=a("a"),Nsr=o("LEDForSequenceClassification"),qsr=o(" (LED model)"),jsr=l(),bT=a("li"),oMe=a("strong"),Dsr=o("longformer"),Gsr=o(" \u2014 "),kH=a("a"),Osr=o("LongformerForSequenceClassification"),Vsr=o(" (Longformer model)"),Xsr=l(),vT=a("li"),rMe=a("strong"),zsr=o("luke"),Qsr=o(" \u2014 "),SH=a("a"),Wsr=o("LukeForSequenceClassification"),Usr=o(" (LUKE model)"),Hsr=l(),FT=a("li"),tMe=a("strong"),Jsr=o("markuplm"),Ysr=o(" \u2014 "),RH=a("a"),Zsr=o("MarkupLMForSequenceClassification"),Ksr=o(" (MarkupLM model)"),elr=l(),TT=a("li"),aMe=a("strong"),olr=o("mbart"),rlr=o(" \u2014 "),PH=a("a"),tlr=o("MBartForSequenceClassification"),alr=o(" (mBART model)"),nlr=l(),MT=a("li"),nMe=a("strong"),slr=o("megatron-bert"),llr=o(" \u2014 "),BH=a("a"),ilr=o("MegatronBertForSequenceClassification"),dlr=o(" (Megatron-BERT model)"),clr=l(),ET=a("li"),sMe=a("strong"),mlr=o("mobilebert"),flr=o(" \u2014 "),IH=a("a"),glr=o("MobileBertForSequenceClassification"),hlr=o(" (MobileBERT model)"),ulr=l(),CT=a("li"),lMe=a("strong"),plr=o("mpnet"),_lr=o(" \u2014 "),NH=a("a"),blr=o("MPNetForSequenceClassification"),vlr=o(" (MPNet model)"),Flr=l(),wT=a("li"),iMe=a("strong"),Tlr=o("mvp"),Mlr=o(" \u2014 "),qH=a("a"),Elr=o("MvpForSequenceClassification"),Clr=o(" (MVP model)"),wlr=l(),AT=a("li"),dMe=a("strong"),Alr=o("nezha"),Llr=o(" \u2014 "),jH=a("a"),ylr=o("NezhaForSequenceClassification"),xlr=o(" (Nezha model)"),$lr=l(),LT=a("li"),cMe=a("strong"),klr=o("nystromformer"),Slr=o(" \u2014 "),DH=a("a"),Rlr=o("NystromformerForSequenceClassification"),Plr=o(" (Nystr\xF6mformer model)"),Blr=l(),yT=a("li"),mMe=a("strong"),Ilr=o("openai-gpt"),Nlr=o(" \u2014 "),GH=a("a"),qlr=o("OpenAIGPTForSequenceClassification"),jlr=o(" (OpenAI GPT model)"),Dlr=l(),xT=a("li"),fMe=a("strong"),Glr=o("opt"),Olr=o(" \u2014 "),OH=a("a"),Vlr=o("OPTForSequenceClassification"),Xlr=o(" (OPT model)"),zlr=l(),$T=a("li"),gMe=a("strong"),Qlr=o("perceiver"),Wlr=o(" \u2014 "),VH=a("a"),Ulr=o("PerceiverForSequenceClassification"),Hlr=o(" (Perceiver model)"),Jlr=l(),kT=a("li"),hMe=a("strong"),Ylr=o("plbart"),Zlr=o(" \u2014 "),XH=a("a"),Klr=o("PLBartForSequenceClassification"),eir=o(" (PLBart model)"),oir=l(),ST=a("li"),uMe=a("strong"),rir=o("qdqbert"),tir=o(" \u2014 "),zH=a("a"),air=o("QDQBertForSequenceClassification"),nir=o(" (QDQBert model)"),sir=l(),RT=a("li"),pMe=a("strong"),lir=o("reformer"),iir=o(" \u2014 "),QH=a("a"),dir=o("ReformerForSequenceClassification"),cir=o(" (Reformer model)"),mir=l(),PT=a("li"),_Me=a("strong"),fir=o("rembert"),gir=o(" \u2014 "),WH=a("a"),hir=o("RemBertForSequenceClassification"),uir=o(" (RemBERT model)"),pir=l(),BT=a("li"),bMe=a("strong"),_ir=o("roberta"),bir=o(" \u2014 "),UH=a("a"),vir=o("RobertaForSequenceClassification"),Fir=o(" (RoBERTa model)"),Tir=l(),IT=a("li"),vMe=a("strong"),Mir=o("roformer"),Eir=o(" \u2014 "),HH=a("a"),Cir=o("RoFormerForSequenceClassification"),wir=o(" (RoFormer model)"),Air=l(),NT=a("li"),FMe=a("strong"),Lir=o("squeezebert"),yir=o(" \u2014 "),JH=a("a"),xir=o("SqueezeBertForSequenceClassification"),$ir=o(" (SqueezeBERT model)"),kir=l(),qT=a("li"),TMe=a("strong"),Sir=o("tapas"),Rir=o(" \u2014 "),YH=a("a"),Pir=o("TapasForSequenceClassification"),Bir=o(" (TAPAS model)"),Iir=l(),jT=a("li"),MMe=a("strong"),Nir=o("transfo-xl"),qir=o(" \u2014 "),ZH=a("a"),jir=o("TransfoXLForSequenceClassification"),Dir=o(" (Transformer-XL model)"),Gir=l(),DT=a("li"),EMe=a("strong"),Oir=o("xlm"),Vir=o(" \u2014 "),KH=a("a"),Xir=o("XLMForSequenceClassification"),zir=o(" (XLM model)"),Qir=l(),GT=a("li"),CMe=a("strong"),Wir=o("xlm-roberta"),Uir=o(" \u2014 "),eJ=a("a"),Hir=o("XLMRobertaForSequenceClassification"),Jir=o(" (XLM-RoBERTa model)"),Yir=l(),OT=a("li"),wMe=a("strong"),Zir=o("xlm-roberta-xl"),Kir=o(" \u2014 "),oJ=a("a"),edr=o("XLMRobertaXLForSequenceClassification"),odr=o(" (XLM-RoBERTa-XL model)"),rdr=l(),VT=a("li"),AMe=a("strong"),tdr=o("xlnet"),adr=o(" \u2014 "),rJ=a("a"),ndr=o("XLNetForSequenceClassification"),sdr=o(" (XLNet model)"),ldr=l(),XT=a("li"),LMe=a("strong"),idr=o("yoso"),ddr=o(" \u2014 "),tJ=a("a"),cdr=o("YosoForSequenceClassification"),mdr=o(" (YOSO model)"),fdr=l(),zT=a("p"),gdr=o("The model is set in evaluation mode by default using "),yMe=a("code"),hdr=o("model.eval()"),udr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xMe=a("code"),pdr=o("model.train()"),_dr=l(),F(QT.$$.fragment),Hoo=l(),Gd=a("h2"),WT=a("a"),$Me=a("span"),F(S$.$$.fragment),bdr=l(),kMe=a("span"),vdr=o("AutoModelForMultipleChoice"),Joo=l(),Go=a("div"),F(R$.$$.fragment),Fdr=l(),Od=a("p"),Tdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),aJ=a("a"),Mdr=o("from_pretrained()"),Edr=o(" class method or the "),nJ=a("a"),Cdr=o("from_config()"),wdr=o(` class
method.`),Adr=l(),P$=a("p"),Ldr=o("This class cannot be instantiated directly using "),SMe=a("code"),ydr=o("__init__()"),xdr=o(" (throws an error)."),$dr=l(),wt=a("div"),F(B$.$$.fragment),kdr=l(),RMe=a("p"),Sdr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Rdr=l(),Vd=a("p"),Pdr=o(`Note:
Loading a model from its configuration file does `),PMe=a("strong"),Bdr=o("not"),Idr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sJ=a("a"),Ndr=o("from_pretrained()"),qdr=o(" to load the model weights."),jdr=l(),F(UT.$$.fragment),Ddr=l(),no=a("div"),F(I$.$$.fragment),Gdr=l(),BMe=a("p"),Odr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Vdr=l(),sn=a("p"),Xdr=o("The model class to instantiate is selected based on the "),IMe=a("code"),zdr=o("model_type"),Qdr=o(` property of the config object (either
passed as an argument or loaded from `),NMe=a("code"),Wdr=o("pretrained_model_name_or_path"),Udr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qMe=a("code"),Hdr=o("pretrained_model_name_or_path"),Jdr=o(":"),Ydr=l(),K=a("ul"),HT=a("li"),jMe=a("strong"),Zdr=o("albert"),Kdr=o(" \u2014 "),lJ=a("a"),ecr=o("AlbertForMultipleChoice"),ocr=o(" (ALBERT model)"),rcr=l(),JT=a("li"),DMe=a("strong"),tcr=o("bert"),acr=o(" \u2014 "),iJ=a("a"),ncr=o("BertForMultipleChoice"),scr=o(" (BERT model)"),lcr=l(),YT=a("li"),GMe=a("strong"),icr=o("big_bird"),dcr=o(" \u2014 "),dJ=a("a"),ccr=o("BigBirdForMultipleChoice"),mcr=o(" (BigBird model)"),fcr=l(),ZT=a("li"),OMe=a("strong"),gcr=o("camembert"),hcr=o(" \u2014 "),cJ=a("a"),ucr=o("CamembertForMultipleChoice"),pcr=o(" (CamemBERT model)"),_cr=l(),KT=a("li"),VMe=a("strong"),bcr=o("canine"),vcr=o(" \u2014 "),mJ=a("a"),Fcr=o("CanineForMultipleChoice"),Tcr=o(" (CANINE model)"),Mcr=l(),eM=a("li"),XMe=a("strong"),Ecr=o("convbert"),Ccr=o(" \u2014 "),fJ=a("a"),wcr=o("ConvBertForMultipleChoice"),Acr=o(" (ConvBERT model)"),Lcr=l(),oM=a("li"),zMe=a("strong"),ycr=o("data2vec-text"),xcr=o(" \u2014 "),gJ=a("a"),$cr=o("Data2VecTextForMultipleChoice"),kcr=o(" (Data2VecText model)"),Scr=l(),rM=a("li"),QMe=a("strong"),Rcr=o("deberta-v2"),Pcr=o(" \u2014 "),hJ=a("a"),Bcr=o("DebertaV2ForMultipleChoice"),Icr=o(" (DeBERTa-v2 model)"),Ncr=l(),tM=a("li"),WMe=a("strong"),qcr=o("distilbert"),jcr=o(" \u2014 "),uJ=a("a"),Dcr=o("DistilBertForMultipleChoice"),Gcr=o(" (DistilBERT model)"),Ocr=l(),aM=a("li"),UMe=a("strong"),Vcr=o("electra"),Xcr=o(" \u2014 "),pJ=a("a"),zcr=o("ElectraForMultipleChoice"),Qcr=o(" (ELECTRA model)"),Wcr=l(),nM=a("li"),HMe=a("strong"),Ucr=o("ernie"),Hcr=o(" \u2014 "),_J=a("a"),Jcr=o("ErnieForMultipleChoice"),Ycr=o(" (ERNIE model)"),Zcr=l(),sM=a("li"),JMe=a("strong"),Kcr=o("flaubert"),emr=o(" \u2014 "),bJ=a("a"),omr=o("FlaubertForMultipleChoice"),rmr=o(" (FlauBERT model)"),tmr=l(),lM=a("li"),YMe=a("strong"),amr=o("fnet"),nmr=o(" \u2014 "),vJ=a("a"),smr=o("FNetForMultipleChoice"),lmr=o(" (FNet model)"),imr=l(),iM=a("li"),ZMe=a("strong"),dmr=o("funnel"),cmr=o(" \u2014 "),FJ=a("a"),mmr=o("FunnelForMultipleChoice"),fmr=o(" (Funnel Transformer model)"),gmr=l(),dM=a("li"),KMe=a("strong"),hmr=o("ibert"),umr=o(" \u2014 "),TJ=a("a"),pmr=o("IBertForMultipleChoice"),_mr=o(" (I-BERT model)"),bmr=l(),cM=a("li"),eEe=a("strong"),vmr=o("longformer"),Fmr=o(" \u2014 "),MJ=a("a"),Tmr=o("LongformerForMultipleChoice"),Mmr=o(" (Longformer model)"),Emr=l(),mM=a("li"),oEe=a("strong"),Cmr=o("luke"),wmr=o(" \u2014 "),EJ=a("a"),Amr=o("LukeForMultipleChoice"),Lmr=o(" (LUKE model)"),ymr=l(),fM=a("li"),rEe=a("strong"),xmr=o("megatron-bert"),$mr=o(" \u2014 "),CJ=a("a"),kmr=o("MegatronBertForMultipleChoice"),Smr=o(" (Megatron-BERT model)"),Rmr=l(),gM=a("li"),tEe=a("strong"),Pmr=o("mobilebert"),Bmr=o(" \u2014 "),wJ=a("a"),Imr=o("MobileBertForMultipleChoice"),Nmr=o(" (MobileBERT model)"),qmr=l(),hM=a("li"),aEe=a("strong"),jmr=o("mpnet"),Dmr=o(" \u2014 "),AJ=a("a"),Gmr=o("MPNetForMultipleChoice"),Omr=o(" (MPNet model)"),Vmr=l(),uM=a("li"),nEe=a("strong"),Xmr=o("nezha"),zmr=o(" \u2014 "),LJ=a("a"),Qmr=o("NezhaForMultipleChoice"),Wmr=o(" (Nezha model)"),Umr=l(),pM=a("li"),sEe=a("strong"),Hmr=o("nystromformer"),Jmr=o(" \u2014 "),yJ=a("a"),Ymr=o("NystromformerForMultipleChoice"),Zmr=o(" (Nystr\xF6mformer model)"),Kmr=l(),_M=a("li"),lEe=a("strong"),efr=o("qdqbert"),ofr=o(" \u2014 "),xJ=a("a"),rfr=o("QDQBertForMultipleChoice"),tfr=o(" (QDQBert model)"),afr=l(),bM=a("li"),iEe=a("strong"),nfr=o("rembert"),sfr=o(" \u2014 "),$J=a("a"),lfr=o("RemBertForMultipleChoice"),ifr=o(" (RemBERT model)"),dfr=l(),vM=a("li"),dEe=a("strong"),cfr=o("roberta"),mfr=o(" \u2014 "),kJ=a("a"),ffr=o("RobertaForMultipleChoice"),gfr=o(" (RoBERTa model)"),hfr=l(),FM=a("li"),cEe=a("strong"),ufr=o("roformer"),pfr=o(" \u2014 "),SJ=a("a"),_fr=o("RoFormerForMultipleChoice"),bfr=o(" (RoFormer model)"),vfr=l(),TM=a("li"),mEe=a("strong"),Ffr=o("squeezebert"),Tfr=o(" \u2014 "),RJ=a("a"),Mfr=o("SqueezeBertForMultipleChoice"),Efr=o(" (SqueezeBERT model)"),Cfr=l(),MM=a("li"),fEe=a("strong"),wfr=o("xlm"),Afr=o(" \u2014 "),PJ=a("a"),Lfr=o("XLMForMultipleChoice"),yfr=o(" (XLM model)"),xfr=l(),EM=a("li"),gEe=a("strong"),$fr=o("xlm-roberta"),kfr=o(" \u2014 "),BJ=a("a"),Sfr=o("XLMRobertaForMultipleChoice"),Rfr=o(" (XLM-RoBERTa model)"),Pfr=l(),CM=a("li"),hEe=a("strong"),Bfr=o("xlm-roberta-xl"),Ifr=o(" \u2014 "),IJ=a("a"),Nfr=o("XLMRobertaXLForMultipleChoice"),qfr=o(" (XLM-RoBERTa-XL model)"),jfr=l(),wM=a("li"),uEe=a("strong"),Dfr=o("xlnet"),Gfr=o(" \u2014 "),NJ=a("a"),Ofr=o("XLNetForMultipleChoice"),Vfr=o(" (XLNet model)"),Xfr=l(),AM=a("li"),pEe=a("strong"),zfr=o("yoso"),Qfr=o(" \u2014 "),qJ=a("a"),Wfr=o("YosoForMultipleChoice"),Ufr=o(" (YOSO model)"),Hfr=l(),LM=a("p"),Jfr=o("The model is set in evaluation mode by default using "),_Ee=a("code"),Yfr=o("model.eval()"),Zfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bEe=a("code"),Kfr=o("model.train()"),egr=l(),F(yM.$$.fragment),Yoo=l(),Xd=a("h2"),xM=a("a"),vEe=a("span"),F(N$.$$.fragment),ogr=l(),FEe=a("span"),rgr=o("AutoModelForNextSentencePrediction"),Zoo=l(),Oo=a("div"),F(q$.$$.fragment),tgr=l(),zd=a("p"),agr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),jJ=a("a"),ngr=o("from_pretrained()"),sgr=o(" class method or the "),DJ=a("a"),lgr=o("from_config()"),igr=o(` class
method.`),dgr=l(),j$=a("p"),cgr=o("This class cannot be instantiated directly using "),TEe=a("code"),mgr=o("__init__()"),fgr=o(" (throws an error)."),ggr=l(),At=a("div"),F(D$.$$.fragment),hgr=l(),MEe=a("p"),ugr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),pgr=l(),Qd=a("p"),_gr=o(`Note:
Loading a model from its configuration file does `),EEe=a("strong"),bgr=o("not"),vgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GJ=a("a"),Fgr=o("from_pretrained()"),Tgr=o(" to load the model weights."),Mgr=l(),F($M.$$.fragment),Egr=l(),so=a("div"),F(G$.$$.fragment),Cgr=l(),CEe=a("p"),wgr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Agr=l(),ln=a("p"),Lgr=o("The model class to instantiate is selected based on the "),wEe=a("code"),ygr=o("model_type"),xgr=o(` property of the config object (either
passed as an argument or loaded from `),AEe=a("code"),$gr=o("pretrained_model_name_or_path"),kgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=a("code"),Sgr=o("pretrained_model_name_or_path"),Rgr=o(":"),Pgr=l(),Ue=a("ul"),kM=a("li"),yEe=a("strong"),Bgr=o("bert"),Igr=o(" \u2014 "),OJ=a("a"),Ngr=o("BertForNextSentencePrediction"),qgr=o(" (BERT model)"),jgr=l(),SM=a("li"),xEe=a("strong"),Dgr=o("ernie"),Ggr=o(" \u2014 "),VJ=a("a"),Ogr=o("ErnieForNextSentencePrediction"),Vgr=o(" (ERNIE model)"),Xgr=l(),RM=a("li"),$Ee=a("strong"),zgr=o("fnet"),Qgr=o(" \u2014 "),XJ=a("a"),Wgr=o("FNetForNextSentencePrediction"),Ugr=o(" (FNet model)"),Hgr=l(),PM=a("li"),kEe=a("strong"),Jgr=o("megatron-bert"),Ygr=o(" \u2014 "),zJ=a("a"),Zgr=o("MegatronBertForNextSentencePrediction"),Kgr=o(" (Megatron-BERT model)"),ehr=l(),BM=a("li"),SEe=a("strong"),ohr=o("mobilebert"),rhr=o(" \u2014 "),QJ=a("a"),thr=o("MobileBertForNextSentencePrediction"),ahr=o(" (MobileBERT model)"),nhr=l(),IM=a("li"),REe=a("strong"),shr=o("nezha"),lhr=o(" \u2014 "),WJ=a("a"),ihr=o("NezhaForNextSentencePrediction"),dhr=o(" (Nezha model)"),chr=l(),NM=a("li"),PEe=a("strong"),mhr=o("qdqbert"),fhr=o(" \u2014 "),UJ=a("a"),ghr=o("QDQBertForNextSentencePrediction"),hhr=o(" (QDQBert model)"),uhr=l(),qM=a("p"),phr=o("The model is set in evaluation mode by default using "),BEe=a("code"),_hr=o("model.eval()"),bhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),IEe=a("code"),vhr=o("model.train()"),Fhr=l(),F(jM.$$.fragment),Koo=l(),Wd=a("h2"),DM=a("a"),NEe=a("span"),F(O$.$$.fragment),Thr=l(),qEe=a("span"),Mhr=o("AutoModelForTokenClassification"),ero=l(),Vo=a("div"),F(V$.$$.fragment),Ehr=l(),Ud=a("p"),Chr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HJ=a("a"),whr=o("from_pretrained()"),Ahr=o(" class method or the "),JJ=a("a"),Lhr=o("from_config()"),yhr=o(` class
method.`),xhr=l(),X$=a("p"),$hr=o("This class cannot be instantiated directly using "),jEe=a("code"),khr=o("__init__()"),Shr=o(" (throws an error)."),Rhr=l(),Lt=a("div"),F(z$.$$.fragment),Phr=l(),DEe=a("p"),Bhr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Ihr=l(),Hd=a("p"),Nhr=o(`Note:
Loading a model from its configuration file does `),GEe=a("strong"),qhr=o("not"),jhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),Dhr=o("from_pretrained()"),Ghr=o(" to load the model weights."),Ohr=l(),F(GM.$$.fragment),Vhr=l(),lo=a("div"),F(Q$.$$.fragment),Xhr=l(),OEe=a("p"),zhr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Qhr=l(),dn=a("p"),Whr=o("The model class to instantiate is selected based on the "),VEe=a("code"),Uhr=o("model_type"),Hhr=o(` property of the config object (either
passed as an argument or loaded from `),XEe=a("code"),Jhr=o("pretrained_model_name_or_path"),Yhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zEe=a("code"),Zhr=o("pretrained_model_name_or_path"),Khr=o(":"),eur=l(),H=a("ul"),OM=a("li"),QEe=a("strong"),our=o("albert"),rur=o(" \u2014 "),ZJ=a("a"),tur=o("AlbertForTokenClassification"),aur=o(" (ALBERT model)"),nur=l(),VM=a("li"),WEe=a("strong"),sur=o("bert"),lur=o(" \u2014 "),KJ=a("a"),iur=o("BertForTokenClassification"),dur=o(" (BERT model)"),cur=l(),XM=a("li"),UEe=a("strong"),mur=o("big_bird"),fur=o(" \u2014 "),eY=a("a"),gur=o("BigBirdForTokenClassification"),hur=o(" (BigBird model)"),uur=l(),zM=a("li"),HEe=a("strong"),pur=o("bloom"),_ur=o(" \u2014 "),oY=a("a"),bur=o("BloomForTokenClassification"),vur=o(" (BLOOM model)"),Fur=l(),QM=a("li"),JEe=a("strong"),Tur=o("camembert"),Mur=o(" \u2014 "),rY=a("a"),Eur=o("CamembertForTokenClassification"),Cur=o(" (CamemBERT model)"),wur=l(),WM=a("li"),YEe=a("strong"),Aur=o("canine"),Lur=o(" \u2014 "),tY=a("a"),yur=o("CanineForTokenClassification"),xur=o(" (CANINE model)"),$ur=l(),UM=a("li"),ZEe=a("strong"),kur=o("convbert"),Sur=o(" \u2014 "),aY=a("a"),Rur=o("ConvBertForTokenClassification"),Pur=o(" (ConvBERT model)"),Bur=l(),HM=a("li"),KEe=a("strong"),Iur=o("data2vec-text"),Nur=o(" \u2014 "),nY=a("a"),qur=o("Data2VecTextForTokenClassification"),jur=o(" (Data2VecText model)"),Dur=l(),JM=a("li"),e4e=a("strong"),Gur=o("deberta"),Our=o(" \u2014 "),sY=a("a"),Vur=o("DebertaForTokenClassification"),Xur=o(" (DeBERTa model)"),zur=l(),YM=a("li"),o4e=a("strong"),Qur=o("deberta-v2"),Wur=o(" \u2014 "),lY=a("a"),Uur=o("DebertaV2ForTokenClassification"),Hur=o(" (DeBERTa-v2 model)"),Jur=l(),ZM=a("li"),r4e=a("strong"),Yur=o("distilbert"),Zur=o(" \u2014 "),iY=a("a"),Kur=o("DistilBertForTokenClassification"),epr=o(" (DistilBERT model)"),opr=l(),KM=a("li"),t4e=a("strong"),rpr=o("electra"),tpr=o(" \u2014 "),dY=a("a"),apr=o("ElectraForTokenClassification"),npr=o(" (ELECTRA model)"),spr=l(),eE=a("li"),a4e=a("strong"),lpr=o("ernie"),ipr=o(" \u2014 "),cY=a("a"),dpr=o("ErnieForTokenClassification"),cpr=o(" (ERNIE model)"),mpr=l(),oE=a("li"),n4e=a("strong"),fpr=o("esm"),gpr=o(" \u2014 "),mY=a("a"),hpr=o("EsmForTokenClassification"),upr=o(" (ESM model)"),ppr=l(),rE=a("li"),s4e=a("strong"),_pr=o("flaubert"),bpr=o(" \u2014 "),fY=a("a"),vpr=o("FlaubertForTokenClassification"),Fpr=o(" (FlauBERT model)"),Tpr=l(),tE=a("li"),l4e=a("strong"),Mpr=o("fnet"),Epr=o(" \u2014 "),gY=a("a"),Cpr=o("FNetForTokenClassification"),wpr=o(" (FNet model)"),Apr=l(),aE=a("li"),i4e=a("strong"),Lpr=o("funnel"),ypr=o(" \u2014 "),hY=a("a"),xpr=o("FunnelForTokenClassification"),$pr=o(" (Funnel Transformer model)"),kpr=l(),nE=a("li"),d4e=a("strong"),Spr=o("gpt2"),Rpr=o(" \u2014 "),uY=a("a"),Ppr=o("GPT2ForTokenClassification"),Bpr=o(" (OpenAI GPT-2 model)"),Ipr=l(),sE=a("li"),c4e=a("strong"),Npr=o("ibert"),qpr=o(" \u2014 "),pY=a("a"),jpr=o("IBertForTokenClassification"),Dpr=o(" (I-BERT model)"),Gpr=l(),lE=a("li"),m4e=a("strong"),Opr=o("layoutlm"),Vpr=o(" \u2014 "),_Y=a("a"),Xpr=o("LayoutLMForTokenClassification"),zpr=o(" (LayoutLM model)"),Qpr=l(),iE=a("li"),f4e=a("strong"),Wpr=o("layoutlmv2"),Upr=o(" \u2014 "),bY=a("a"),Hpr=o("LayoutLMv2ForTokenClassification"),Jpr=o(" (LayoutLMv2 model)"),Ypr=l(),dE=a("li"),g4e=a("strong"),Zpr=o("layoutlmv3"),Kpr=o(" \u2014 "),vY=a("a"),e_r=o("LayoutLMv3ForTokenClassification"),o_r=o(" (LayoutLMv3 model)"),r_r=l(),cE=a("li"),h4e=a("strong"),t_r=o("longformer"),a_r=o(" \u2014 "),FY=a("a"),n_r=o("LongformerForTokenClassification"),s_r=o(" (Longformer model)"),l_r=l(),mE=a("li"),u4e=a("strong"),i_r=o("luke"),d_r=o(" \u2014 "),TY=a("a"),c_r=o("LukeForTokenClassification"),m_r=o(" (LUKE model)"),f_r=l(),fE=a("li"),p4e=a("strong"),g_r=o("markuplm"),h_r=o(" \u2014 "),MY=a("a"),u_r=o("MarkupLMForTokenClassification"),p_r=o(" (MarkupLM model)"),__r=l(),gE=a("li"),_4e=a("strong"),b_r=o("megatron-bert"),v_r=o(" \u2014 "),EY=a("a"),F_r=o("MegatronBertForTokenClassification"),T_r=o(" (Megatron-BERT model)"),M_r=l(),hE=a("li"),b4e=a("strong"),E_r=o("mobilebert"),C_r=o(" \u2014 "),CY=a("a"),w_r=o("MobileBertForTokenClassification"),A_r=o(" (MobileBERT model)"),L_r=l(),uE=a("li"),v4e=a("strong"),y_r=o("mpnet"),x_r=o(" \u2014 "),wY=a("a"),$_r=o("MPNetForTokenClassification"),k_r=o(" (MPNet model)"),S_r=l(),pE=a("li"),F4e=a("strong"),R_r=o("nezha"),P_r=o(" \u2014 "),AY=a("a"),B_r=o("NezhaForTokenClassification"),I_r=o(" (Nezha model)"),N_r=l(),_E=a("li"),T4e=a("strong"),q_r=o("nystromformer"),j_r=o(" \u2014 "),LY=a("a"),D_r=o("NystromformerForTokenClassification"),G_r=o(" (Nystr\xF6mformer model)"),O_r=l(),bE=a("li"),M4e=a("strong"),V_r=o("qdqbert"),X_r=o(" \u2014 "),yY=a("a"),z_r=o("QDQBertForTokenClassification"),Q_r=o(" (QDQBert model)"),W_r=l(),vE=a("li"),E4e=a("strong"),U_r=o("rembert"),H_r=o(" \u2014 "),xY=a("a"),J_r=o("RemBertForTokenClassification"),Y_r=o(" (RemBERT model)"),Z_r=l(),FE=a("li"),C4e=a("strong"),K_r=o("roberta"),e1r=o(" \u2014 "),$Y=a("a"),o1r=o("RobertaForTokenClassification"),r1r=o(" (RoBERTa model)"),t1r=l(),TE=a("li"),w4e=a("strong"),a1r=o("roformer"),n1r=o(" \u2014 "),kY=a("a"),s1r=o("RoFormerForTokenClassification"),l1r=o(" (RoFormer model)"),i1r=l(),ME=a("li"),A4e=a("strong"),d1r=o("squeezebert"),c1r=o(" \u2014 "),SY=a("a"),m1r=o("SqueezeBertForTokenClassification"),f1r=o(" (SqueezeBERT model)"),g1r=l(),EE=a("li"),L4e=a("strong"),h1r=o("xlm"),u1r=o(" \u2014 "),RY=a("a"),p1r=o("XLMForTokenClassification"),_1r=o(" (XLM model)"),b1r=l(),CE=a("li"),y4e=a("strong"),v1r=o("xlm-roberta"),F1r=o(" \u2014 "),PY=a("a"),T1r=o("XLMRobertaForTokenClassification"),M1r=o(" (XLM-RoBERTa model)"),E1r=l(),wE=a("li"),x4e=a("strong"),C1r=o("xlm-roberta-xl"),w1r=o(" \u2014 "),BY=a("a"),A1r=o("XLMRobertaXLForTokenClassification"),L1r=o(" (XLM-RoBERTa-XL model)"),y1r=l(),AE=a("li"),$4e=a("strong"),x1r=o("xlnet"),$1r=o(" \u2014 "),IY=a("a"),k1r=o("XLNetForTokenClassification"),S1r=o(" (XLNet model)"),R1r=l(),LE=a("li"),k4e=a("strong"),P1r=o("yoso"),B1r=o(" \u2014 "),NY=a("a"),I1r=o("YosoForTokenClassification"),N1r=o(" (YOSO model)"),q1r=l(),yE=a("p"),j1r=o("The model is set in evaluation mode by default using "),S4e=a("code"),D1r=o("model.eval()"),G1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R4e=a("code"),O1r=o("model.train()"),V1r=l(),F(xE.$$.fragment),oro=l(),Jd=a("h2"),$E=a("a"),P4e=a("span"),F(W$.$$.fragment),X1r=l(),B4e=a("span"),z1r=o("AutoModelForQuestionAnswering"),rro=l(),Xo=a("div"),F(U$.$$.fragment),Q1r=l(),Yd=a("p"),W1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qY=a("a"),U1r=o("from_pretrained()"),H1r=o(" class method or the "),jY=a("a"),J1r=o("from_config()"),Y1r=o(` class
method.`),Z1r=l(),H$=a("p"),K1r=o("This class cannot be instantiated directly using "),I4e=a("code"),e2r=o("__init__()"),o2r=o(" (throws an error)."),r2r=l(),yt=a("div"),F(J$.$$.fragment),t2r=l(),N4e=a("p"),a2r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),n2r=l(),Zd=a("p"),s2r=o(`Note:
Loading a model from its configuration file does `),q4e=a("strong"),l2r=o("not"),i2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=a("a"),d2r=o("from_pretrained()"),c2r=o(" to load the model weights."),m2r=l(),F(kE.$$.fragment),f2r=l(),io=a("div"),F(Y$.$$.fragment),g2r=l(),j4e=a("p"),h2r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),u2r=l(),cn=a("p"),p2r=o("The model class to instantiate is selected based on the "),D4e=a("code"),_2r=o("model_type"),b2r=o(` property of the config object (either
passed as an argument or loaded from `),G4e=a("code"),v2r=o("pretrained_model_name_or_path"),F2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O4e=a("code"),T2r=o("pretrained_model_name_or_path"),M2r=o(":"),E2r=l(),O=a("ul"),SE=a("li"),V4e=a("strong"),C2r=o("albert"),w2r=o(" \u2014 "),GY=a("a"),A2r=o("AlbertForQuestionAnswering"),L2r=o(" (ALBERT model)"),y2r=l(),RE=a("li"),X4e=a("strong"),x2r=o("bart"),$2r=o(" \u2014 "),OY=a("a"),k2r=o("BartForQuestionAnswering"),S2r=o(" (BART model)"),R2r=l(),PE=a("li"),z4e=a("strong"),P2r=o("bert"),B2r=o(" \u2014 "),VY=a("a"),I2r=o("BertForQuestionAnswering"),N2r=o(" (BERT model)"),q2r=l(),BE=a("li"),Q4e=a("strong"),j2r=o("big_bird"),D2r=o(" \u2014 "),XY=a("a"),G2r=o("BigBirdForQuestionAnswering"),O2r=o(" (BigBird model)"),V2r=l(),IE=a("li"),W4e=a("strong"),X2r=o("bigbird_pegasus"),z2r=o(" \u2014 "),zY=a("a"),Q2r=o("BigBirdPegasusForQuestionAnswering"),W2r=o(" (BigBird-Pegasus model)"),U2r=l(),NE=a("li"),U4e=a("strong"),H2r=o("bloom"),J2r=o(" \u2014 "),QY=a("a"),Y2r=o("BloomForQuestionAnswering"),Z2r=o(" (BLOOM model)"),K2r=l(),qE=a("li"),H4e=a("strong"),ebr=o("camembert"),obr=o(" \u2014 "),WY=a("a"),rbr=o("CamembertForQuestionAnswering"),tbr=o(" (CamemBERT model)"),abr=l(),jE=a("li"),J4e=a("strong"),nbr=o("canine"),sbr=o(" \u2014 "),UY=a("a"),lbr=o("CanineForQuestionAnswering"),ibr=o(" (CANINE model)"),dbr=l(),DE=a("li"),Y4e=a("strong"),cbr=o("convbert"),mbr=o(" \u2014 "),HY=a("a"),fbr=o("ConvBertForQuestionAnswering"),gbr=o(" (ConvBERT model)"),hbr=l(),GE=a("li"),Z4e=a("strong"),ubr=o("data2vec-text"),pbr=o(" \u2014 "),JY=a("a"),_br=o("Data2VecTextForQuestionAnswering"),bbr=o(" (Data2VecText model)"),vbr=l(),OE=a("li"),K4e=a("strong"),Fbr=o("deberta"),Tbr=o(" \u2014 "),YY=a("a"),Mbr=o("DebertaForQuestionAnswering"),Ebr=o(" (DeBERTa model)"),Cbr=l(),VE=a("li"),eCe=a("strong"),wbr=o("deberta-v2"),Abr=o(" \u2014 "),ZY=a("a"),Lbr=o("DebertaV2ForQuestionAnswering"),ybr=o(" (DeBERTa-v2 model)"),xbr=l(),XE=a("li"),oCe=a("strong"),$br=o("distilbert"),kbr=o(" \u2014 "),KY=a("a"),Sbr=o("DistilBertForQuestionAnswering"),Rbr=o(" (DistilBERT model)"),Pbr=l(),zE=a("li"),rCe=a("strong"),Bbr=o("electra"),Ibr=o(" \u2014 "),eZ=a("a"),Nbr=o("ElectraForQuestionAnswering"),qbr=o(" (ELECTRA model)"),jbr=l(),QE=a("li"),tCe=a("strong"),Dbr=o("ernie"),Gbr=o(" \u2014 "),oZ=a("a"),Obr=o("ErnieForQuestionAnswering"),Vbr=o(" (ERNIE model)"),Xbr=l(),WE=a("li"),aCe=a("strong"),zbr=o("flaubert"),Qbr=o(" \u2014 "),rZ=a("a"),Wbr=o("FlaubertForQuestionAnsweringSimple"),Ubr=o(" (FlauBERT model)"),Hbr=l(),UE=a("li"),nCe=a("strong"),Jbr=o("fnet"),Ybr=o(" \u2014 "),tZ=a("a"),Zbr=o("FNetForQuestionAnswering"),Kbr=o(" (FNet model)"),evr=l(),HE=a("li"),sCe=a("strong"),ovr=o("funnel"),rvr=o(" \u2014 "),aZ=a("a"),tvr=o("FunnelForQuestionAnswering"),avr=o(" (Funnel Transformer model)"),nvr=l(),JE=a("li"),lCe=a("strong"),svr=o("gptj"),lvr=o(" \u2014 "),nZ=a("a"),ivr=o("GPTJForQuestionAnswering"),dvr=o(" (GPT-J model)"),cvr=l(),YE=a("li"),iCe=a("strong"),mvr=o("ibert"),fvr=o(" \u2014 "),sZ=a("a"),gvr=o("IBertForQuestionAnswering"),hvr=o(" (I-BERT model)"),uvr=l(),ZE=a("li"),dCe=a("strong"),pvr=o("layoutlmv2"),_vr=o(" \u2014 "),lZ=a("a"),bvr=o("LayoutLMv2ForQuestionAnswering"),vvr=o(" (LayoutLMv2 model)"),Fvr=l(),KE=a("li"),cCe=a("strong"),Tvr=o("layoutlmv3"),Mvr=o(" \u2014 "),iZ=a("a"),Evr=o("LayoutLMv3ForQuestionAnswering"),Cvr=o(" (LayoutLMv3 model)"),wvr=l(),e4=a("li"),mCe=a("strong"),Avr=o("led"),Lvr=o(" \u2014 "),dZ=a("a"),yvr=o("LEDForQuestionAnswering"),xvr=o(" (LED model)"),$vr=l(),o4=a("li"),fCe=a("strong"),kvr=o("longformer"),Svr=o(" \u2014 "),cZ=a("a"),Rvr=o("LongformerForQuestionAnswering"),Pvr=o(" (Longformer model)"),Bvr=l(),r4=a("li"),gCe=a("strong"),Ivr=o("luke"),Nvr=o(" \u2014 "),mZ=a("a"),qvr=o("LukeForQuestionAnswering"),jvr=o(" (LUKE model)"),Dvr=l(),t4=a("li"),hCe=a("strong"),Gvr=o("lxmert"),Ovr=o(" \u2014 "),fZ=a("a"),Vvr=o("LxmertForQuestionAnswering"),Xvr=o(" (LXMERT model)"),zvr=l(),a4=a("li"),uCe=a("strong"),Qvr=o("markuplm"),Wvr=o(" \u2014 "),gZ=a("a"),Uvr=o("MarkupLMForQuestionAnswering"),Hvr=o(" (MarkupLM model)"),Jvr=l(),n4=a("li"),pCe=a("strong"),Yvr=o("mbart"),Zvr=o(" \u2014 "),hZ=a("a"),Kvr=o("MBartForQuestionAnswering"),eFr=o(" (mBART model)"),oFr=l(),s4=a("li"),_Ce=a("strong"),rFr=o("megatron-bert"),tFr=o(" \u2014 "),uZ=a("a"),aFr=o("MegatronBertForQuestionAnswering"),nFr=o(" (Megatron-BERT model)"),sFr=l(),l4=a("li"),bCe=a("strong"),lFr=o("mobilebert"),iFr=o(" \u2014 "),pZ=a("a"),dFr=o("MobileBertForQuestionAnswering"),cFr=o(" (MobileBERT model)"),mFr=l(),i4=a("li"),vCe=a("strong"),fFr=o("mpnet"),gFr=o(" \u2014 "),_Z=a("a"),hFr=o("MPNetForQuestionAnswering"),uFr=o(" (MPNet model)"),pFr=l(),d4=a("li"),FCe=a("strong"),_Fr=o("mvp"),bFr=o(" \u2014 "),bZ=a("a"),vFr=o("MvpForQuestionAnswering"),FFr=o(" (MVP model)"),TFr=l(),c4=a("li"),TCe=a("strong"),MFr=o("nezha"),EFr=o(" \u2014 "),vZ=a("a"),CFr=o("NezhaForQuestionAnswering"),wFr=o(" (Nezha model)"),AFr=l(),m4=a("li"),MCe=a("strong"),LFr=o("nystromformer"),yFr=o(" \u2014 "),FZ=a("a"),xFr=o("NystromformerForQuestionAnswering"),$Fr=o(" (Nystr\xF6mformer model)"),kFr=l(),f4=a("li"),ECe=a("strong"),SFr=o("opt"),RFr=o(" \u2014 "),TZ=a("a"),PFr=o("OPTForQuestionAnswering"),BFr=o(" (OPT model)"),IFr=l(),g4=a("li"),CCe=a("strong"),NFr=o("qdqbert"),qFr=o(" \u2014 "),MZ=a("a"),jFr=o("QDQBertForQuestionAnswering"),DFr=o(" (QDQBert model)"),GFr=l(),h4=a("li"),wCe=a("strong"),OFr=o("reformer"),VFr=o(" \u2014 "),EZ=a("a"),XFr=o("ReformerForQuestionAnswering"),zFr=o(" (Reformer model)"),QFr=l(),u4=a("li"),ACe=a("strong"),WFr=o("rembert"),UFr=o(" \u2014 "),CZ=a("a"),HFr=o("RemBertForQuestionAnswering"),JFr=o(" (RemBERT model)"),YFr=l(),p4=a("li"),LCe=a("strong"),ZFr=o("roberta"),KFr=o(" \u2014 "),wZ=a("a"),eTr=o("RobertaForQuestionAnswering"),oTr=o(" (RoBERTa model)"),rTr=l(),_4=a("li"),yCe=a("strong"),tTr=o("roformer"),aTr=o(" \u2014 "),AZ=a("a"),nTr=o("RoFormerForQuestionAnswering"),sTr=o(" (RoFormer model)"),lTr=l(),b4=a("li"),xCe=a("strong"),iTr=o("splinter"),dTr=o(" \u2014 "),LZ=a("a"),cTr=o("SplinterForQuestionAnswering"),mTr=o(" (Splinter model)"),fTr=l(),v4=a("li"),$Ce=a("strong"),gTr=o("squeezebert"),hTr=o(" \u2014 "),yZ=a("a"),uTr=o("SqueezeBertForQuestionAnswering"),pTr=o(" (SqueezeBERT model)"),_Tr=l(),F4=a("li"),kCe=a("strong"),bTr=o("xlm"),vTr=o(" \u2014 "),xZ=a("a"),FTr=o("XLMForQuestionAnsweringSimple"),TTr=o(" (XLM model)"),MTr=l(),T4=a("li"),SCe=a("strong"),ETr=o("xlm-roberta"),CTr=o(" \u2014 "),$Z=a("a"),wTr=o("XLMRobertaForQuestionAnswering"),ATr=o(" (XLM-RoBERTa model)"),LTr=l(),M4=a("li"),RCe=a("strong"),yTr=o("xlm-roberta-xl"),xTr=o(" \u2014 "),kZ=a("a"),$Tr=o("XLMRobertaXLForQuestionAnswering"),kTr=o(" (XLM-RoBERTa-XL model)"),STr=l(),E4=a("li"),PCe=a("strong"),RTr=o("xlnet"),PTr=o(" \u2014 "),SZ=a("a"),BTr=o("XLNetForQuestionAnsweringSimple"),ITr=o(" (XLNet model)"),NTr=l(),C4=a("li"),BCe=a("strong"),qTr=o("yoso"),jTr=o(" \u2014 "),RZ=a("a"),DTr=o("YosoForQuestionAnswering"),GTr=o(" (YOSO model)"),OTr=l(),w4=a("p"),VTr=o("The model is set in evaluation mode by default using "),ICe=a("code"),XTr=o("model.eval()"),zTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NCe=a("code"),QTr=o("model.train()"),WTr=l(),F(A4.$$.fragment),tro=l(),Kd=a("h2"),L4=a("a"),qCe=a("span"),F(Z$.$$.fragment),UTr=l(),jCe=a("span"),HTr=o("AutoModelForTableQuestionAnswering"),aro=l(),zo=a("div"),F(K$.$$.fragment),JTr=l(),ec=a("p"),YTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PZ=a("a"),ZTr=o("from_pretrained()"),KTr=o(" class method or the "),BZ=a("a"),eMr=o("from_config()"),oMr=o(` class
method.`),rMr=l(),ek=a("p"),tMr=o("This class cannot be instantiated directly using "),DCe=a("code"),aMr=o("__init__()"),nMr=o(" (throws an error)."),sMr=l(),xt=a("div"),F(ok.$$.fragment),lMr=l(),GCe=a("p"),iMr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),dMr=l(),oc=a("p"),cMr=o(`Note:
Loading a model from its configuration file does `),OCe=a("strong"),mMr=o("not"),fMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IZ=a("a"),gMr=o("from_pretrained()"),hMr=o(" to load the model weights."),uMr=l(),F(y4.$$.fragment),pMr=l(),co=a("div"),F(rk.$$.fragment),_Mr=l(),VCe=a("p"),bMr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),vMr=l(),mn=a("p"),FMr=o("The model class to instantiate is selected based on the "),XCe=a("code"),TMr=o("model_type"),MMr=o(` property of the config object (either
passed as an argument or loaded from `),zCe=a("code"),EMr=o("pretrained_model_name_or_path"),CMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QCe=a("code"),wMr=o("pretrained_model_name_or_path"),AMr=o(":"),LMr=l(),WCe=a("ul"),x4=a("li"),UCe=a("strong"),yMr=o("tapas"),xMr=o(" \u2014 "),NZ=a("a"),$Mr=o("TapasForQuestionAnswering"),kMr=o(" (TAPAS model)"),SMr=l(),$4=a("p"),RMr=o("The model is set in evaluation mode by default using "),HCe=a("code"),PMr=o("model.eval()"),BMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JCe=a("code"),IMr=o("model.train()"),NMr=l(),F(k4.$$.fragment),nro=l(),rc=a("h2"),S4=a("a"),YCe=a("span"),F(tk.$$.fragment),qMr=l(),ZCe=a("span"),jMr=o("AutoModelForDocumentQuestionAnswering"),sro=l(),Qo=a("div"),F(ak.$$.fragment),DMr=l(),tc=a("p"),GMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),qZ=a("a"),OMr=o("from_pretrained()"),VMr=o(" class method or the "),jZ=a("a"),XMr=o("from_config()"),zMr=o(` class
method.`),QMr=l(),nk=a("p"),WMr=o("This class cannot be instantiated directly using "),KCe=a("code"),UMr=o("__init__()"),HMr=o(" (throws an error)."),JMr=l(),$t=a("div"),F(sk.$$.fragment),YMr=l(),e3e=a("p"),ZMr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),KMr=l(),ac=a("p"),eEr=o(`Note:
Loading a model from its configuration file does `),o3e=a("strong"),oEr=o("not"),rEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=a("a"),tEr=o("from_pretrained()"),aEr=o(" to load the model weights."),nEr=l(),F(R4.$$.fragment),sEr=l(),mo=a("div"),F(lk.$$.fragment),lEr=l(),r3e=a("p"),iEr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),dEr=l(),fn=a("p"),cEr=o("The model class to instantiate is selected based on the "),t3e=a("code"),mEr=o("model_type"),fEr=o(` property of the config object (either
passed as an argument or loaded from `),a3e=a("code"),gEr=o("pretrained_model_name_or_path"),hEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n3e=a("code"),uEr=o("pretrained_model_name_or_path"),pEr=o(":"),_Er=l(),nc=a("ul"),P4=a("li"),s3e=a("strong"),bEr=o("layoutlm"),vEr=o(" \u2014 "),GZ=a("a"),FEr=o("LayoutLMForQuestionAnswering"),TEr=o(" (LayoutLM model)"),MEr=l(),B4=a("li"),l3e=a("strong"),EEr=o("layoutlmv2"),CEr=o(" \u2014 "),OZ=a("a"),wEr=o("LayoutLMv2ForQuestionAnswering"),AEr=o(" (LayoutLMv2 model)"),LEr=l(),I4=a("li"),i3e=a("strong"),yEr=o("layoutlmv3"),xEr=o(" \u2014 "),VZ=a("a"),$Er=o("LayoutLMv3ForQuestionAnswering"),kEr=o(" (LayoutLMv3 model)"),SEr=l(),N4=a("p"),REr=o("The model is set in evaluation mode by default using "),d3e=a("code"),PEr=o("model.eval()"),BEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c3e=a("code"),IEr=o("model.train()"),NEr=l(),F(q4.$$.fragment),lro=l(),sc=a("h2"),j4=a("a"),m3e=a("span"),F(ik.$$.fragment),qEr=l(),f3e=a("span"),jEr=o("AutoModelForImageClassification"),iro=l(),Wo=a("div"),F(dk.$$.fragment),DEr=l(),lc=a("p"),GEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),XZ=a("a"),OEr=o("from_pretrained()"),VEr=o(" class method or the "),zZ=a("a"),XEr=o("from_config()"),zEr=o(` class
method.`),QEr=l(),ck=a("p"),WEr=o("This class cannot be instantiated directly using "),g3e=a("code"),UEr=o("__init__()"),HEr=o(" (throws an error)."),JEr=l(),kt=a("div"),F(mk.$$.fragment),YEr=l(),h3e=a("p"),ZEr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),KEr=l(),ic=a("p"),e4r=o(`Note:
Loading a model from its configuration file does `),u3e=a("strong"),o4r=o("not"),r4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QZ=a("a"),t4r=o("from_pretrained()"),a4r=o(" to load the model weights."),n4r=l(),F(D4.$$.fragment),s4r=l(),fo=a("div"),F(fk.$$.fragment),l4r=l(),p3e=a("p"),i4r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),d4r=l(),gn=a("p"),c4r=o("The model class to instantiate is selected based on the "),_3e=a("code"),m4r=o("model_type"),f4r=o(` property of the config object (either
passed as an argument or loaded from `),b3e=a("code"),g4r=o("pretrained_model_name_or_path"),h4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v3e=a("code"),u4r=o("pretrained_model_name_or_path"),p4r=o(":"),_4r=l(),be=a("ul"),G4=a("li"),F3e=a("strong"),b4r=o("beit"),v4r=o(" \u2014 "),WZ=a("a"),F4r=o("BeitForImageClassification"),T4r=o(" (BEiT model)"),M4r=l(),O4=a("li"),T3e=a("strong"),E4r=o("convnext"),C4r=o(" \u2014 "),UZ=a("a"),w4r=o("ConvNextForImageClassification"),A4r=o(" (ConvNeXT model)"),L4r=l(),V4=a("li"),M3e=a("strong"),y4r=o("cvt"),x4r=o(" \u2014 "),HZ=a("a"),$4r=o("CvtForImageClassification"),k4r=o(" (CvT model)"),S4r=l(),X4=a("li"),E3e=a("strong"),R4r=o("data2vec-vision"),P4r=o(" \u2014 "),JZ=a("a"),B4r=o("Data2VecVisionForImageClassification"),I4r=o(" (Data2VecVision model)"),N4r=l(),El=a("li"),C3e=a("strong"),q4r=o("deit"),j4r=o(" \u2014 "),YZ=a("a"),D4r=o("DeiTForImageClassification"),G4r=o(" or "),ZZ=a("a"),O4r=o("DeiTForImageClassificationWithTeacher"),V4r=o(" (DeiT model)"),X4r=l(),z4=a("li"),w3e=a("strong"),z4r=o("imagegpt"),Q4r=o(" \u2014 "),KZ=a("a"),W4r=o("ImageGPTForImageClassification"),U4r=o(" (ImageGPT model)"),H4r=l(),Cl=a("li"),A3e=a("strong"),J4r=o("levit"),Y4r=o(" \u2014 "),eK=a("a"),Z4r=o("LevitForImageClassification"),K4r=o(" or "),oK=a("a"),eCr=o("LevitForImageClassificationWithTeacher"),oCr=o(" (LeViT model)"),rCr=l(),Q4=a("li"),L3e=a("strong"),tCr=o("mobilevit"),aCr=o(" \u2014 "),rK=a("a"),nCr=o("MobileViTForImageClassification"),sCr=o(" (MobileViT model)"),lCr=l(),St=a("li"),y3e=a("strong"),iCr=o("perceiver"),dCr=o(" \u2014 "),tK=a("a"),cCr=o("PerceiverForImageClassificationLearned"),mCr=o(" or "),aK=a("a"),fCr=o("PerceiverForImageClassificationFourier"),gCr=o(" or "),nK=a("a"),hCr=o("PerceiverForImageClassificationConvProcessing"),uCr=o(" (Perceiver model)"),pCr=l(),W4=a("li"),x3e=a("strong"),_Cr=o("poolformer"),bCr=o(" \u2014 "),sK=a("a"),vCr=o("PoolFormerForImageClassification"),FCr=o(" (PoolFormer model)"),TCr=l(),U4=a("li"),$3e=a("strong"),MCr=o("regnet"),ECr=o(" \u2014 "),lK=a("a"),CCr=o("RegNetForImageClassification"),wCr=o(" (RegNet model)"),ACr=l(),H4=a("li"),k3e=a("strong"),LCr=o("resnet"),yCr=o(" \u2014 "),iK=a("a"),xCr=o("ResNetForImageClassification"),$Cr=o(" (ResNet model)"),kCr=l(),J4=a("li"),S3e=a("strong"),SCr=o("segformer"),RCr=o(" \u2014 "),dK=a("a"),PCr=o("SegformerForImageClassification"),BCr=o(" (SegFormer model)"),ICr=l(),Y4=a("li"),R3e=a("strong"),NCr=o("swin"),qCr=o(" \u2014 "),cK=a("a"),jCr=o("SwinForImageClassification"),DCr=o(" (Swin Transformer model)"),GCr=l(),Z4=a("li"),P3e=a("strong"),OCr=o("swinv2"),VCr=o(" \u2014 "),mK=a("a"),XCr=o("Swinv2ForImageClassification"),zCr=o(" (Swin Transformer V2 model)"),QCr=l(),K4=a("li"),B3e=a("strong"),WCr=o("van"),UCr=o(" \u2014 "),fK=a("a"),HCr=o("VanForImageClassification"),JCr=o(" (VAN model)"),YCr=l(),eC=a("li"),I3e=a("strong"),ZCr=o("vit"),KCr=o(" \u2014 "),gK=a("a"),e3r=o("ViTForImageClassification"),o3r=o(" (ViT model)"),r3r=l(),oC=a("li"),N3e=a("strong"),t3r=o("vit_msn"),a3r=o(" \u2014 "),hK=a("a"),n3r=o("ViTMSNForImageClassification"),s3r=o(" (ViTMSN model)"),l3r=l(),rC=a("p"),i3r=o("The model is set in evaluation mode by default using "),q3e=a("code"),d3r=o("model.eval()"),c3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j3e=a("code"),m3r=o("model.train()"),f3r=l(),F(tC.$$.fragment),dro=l(),dc=a("h2"),aC=a("a"),D3e=a("span"),F(gk.$$.fragment),g3r=l(),G3e=a("span"),h3r=o("AutoModelForVideoClassification"),cro=l(),Uo=a("div"),F(hk.$$.fragment),u3r=l(),cc=a("p"),p3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),uK=a("a"),_3r=o("from_pretrained()"),b3r=o(" class method or the "),pK=a("a"),v3r=o("from_config()"),F3r=o(` class
method.`),T3r=l(),uk=a("p"),M3r=o("This class cannot be instantiated directly using "),O3e=a("code"),E3r=o("__init__()"),C3r=o(" (throws an error)."),w3r=l(),Rt=a("div"),F(pk.$$.fragment),A3r=l(),V3e=a("p"),L3r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),y3r=l(),mc=a("p"),x3r=o(`Note:
Loading a model from its configuration file does `),X3e=a("strong"),$3r=o("not"),k3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=a("a"),S3r=o("from_pretrained()"),R3r=o(" to load the model weights."),P3r=l(),F(nC.$$.fragment),B3r=l(),go=a("div"),F(_k.$$.fragment),I3r=l(),z3e=a("p"),N3r=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),q3r=l(),hn=a("p"),j3r=o("The model class to instantiate is selected based on the "),Q3e=a("code"),D3r=o("model_type"),G3r=o(` property of the config object (either
passed as an argument or loaded from `),W3e=a("code"),O3r=o("pretrained_model_name_or_path"),V3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U3e=a("code"),X3r=o("pretrained_model_name_or_path"),z3r=o(":"),Q3r=l(),H3e=a("ul"),sC=a("li"),J3e=a("strong"),W3r=o("videomae"),U3r=o(" \u2014 "),bK=a("a"),H3r=o("VideoMAEForVideoClassification"),J3r=o(" (VideoMAE model)"),Y3r=l(),lC=a("p"),Z3r=o("The model is set in evaluation mode by default using "),Y3e=a("code"),K3r=o("model.eval()"),e5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z3e=a("code"),o5r=o("model.train()"),r5r=l(),F(iC.$$.fragment),mro=l(),fc=a("h2"),dC=a("a"),K3e=a("span"),F(bk.$$.fragment),t5r=l(),e5e=a("span"),a5r=o("AutoModelForVision2Seq"),fro=l(),Ho=a("div"),F(vk.$$.fragment),n5r=l(),gc=a("p"),s5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vK=a("a"),l5r=o("from_pretrained()"),i5r=o(" class method or the "),FK=a("a"),d5r=o("from_config()"),c5r=o(` class
method.`),m5r=l(),Fk=a("p"),f5r=o("This class cannot be instantiated directly using "),o5e=a("code"),g5r=o("__init__()"),h5r=o(" (throws an error)."),u5r=l(),Pt=a("div"),F(Tk.$$.fragment),p5r=l(),r5e=a("p"),_5r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),b5r=l(),hc=a("p"),v5r=o(`Note:
Loading a model from its configuration file does `),t5e=a("strong"),F5r=o("not"),T5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TK=a("a"),M5r=o("from_pretrained()"),E5r=o(" to load the model weights."),C5r=l(),F(cC.$$.fragment),w5r=l(),ho=a("div"),F(Mk.$$.fragment),A5r=l(),a5e=a("p"),L5r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),y5r=l(),un=a("p"),x5r=o("The model class to instantiate is selected based on the "),n5e=a("code"),$5r=o("model_type"),k5r=o(` property of the config object (either
passed as an argument or loaded from `),s5e=a("code"),S5r=o("pretrained_model_name_or_path"),R5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l5e=a("code"),P5r=o("pretrained_model_name_or_path"),B5r=o(":"),I5r=l(),i5e=a("ul"),mC=a("li"),d5e=a("strong"),N5r=o("vision-encoder-decoder"),q5r=o(" \u2014 "),MK=a("a"),j5r=o("VisionEncoderDecoderModel"),D5r=o(" (Vision Encoder decoder model)"),G5r=l(),fC=a("p"),O5r=o("The model is set in evaluation mode by default using "),c5e=a("code"),V5r=o("model.eval()"),X5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m5e=a("code"),z5r=o("model.train()"),Q5r=l(),F(gC.$$.fragment),gro=l(),uc=a("h2"),hC=a("a"),f5e=a("span"),F(Ek.$$.fragment),W5r=l(),g5e=a("span"),U5r=o("AutoModelForVisualQuestionAnswering"),hro=l(),Jo=a("div"),F(Ck.$$.fragment),H5r=l(),pc=a("p"),J5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),EK=a("a"),Y5r=o("from_pretrained()"),Z5r=o(" class method or the "),CK=a("a"),K5r=o("from_config()"),e0r=o(` class
method.`),o0r=l(),wk=a("p"),r0r=o("This class cannot be instantiated directly using "),h5e=a("code"),t0r=o("__init__()"),a0r=o(" (throws an error)."),n0r=l(),Bt=a("div"),F(Ak.$$.fragment),s0r=l(),u5e=a("p"),l0r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),i0r=l(),_c=a("p"),d0r=o(`Note:
Loading a model from its configuration file does `),p5e=a("strong"),c0r=o("not"),m0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=a("a"),f0r=o("from_pretrained()"),g0r=o(" to load the model weights."),h0r=l(),F(uC.$$.fragment),u0r=l(),uo=a("div"),F(Lk.$$.fragment),p0r=l(),_5e=a("p"),_0r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),b0r=l(),pn=a("p"),v0r=o("The model class to instantiate is selected based on the "),b5e=a("code"),F0r=o("model_type"),T0r=o(` property of the config object (either
passed as an argument or loaded from `),v5e=a("code"),M0r=o("pretrained_model_name_or_path"),E0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F5e=a("code"),C0r=o("pretrained_model_name_or_path"),w0r=o(":"),A0r=l(),T5e=a("ul"),pC=a("li"),M5e=a("strong"),L0r=o("vilt"),y0r=o(" \u2014 "),AK=a("a"),x0r=o("ViltForQuestionAnswering"),$0r=o(" (ViLT model)"),k0r=l(),_C=a("p"),S0r=o("The model is set in evaluation mode by default using "),E5e=a("code"),R0r=o("model.eval()"),P0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C5e=a("code"),B0r=o("model.train()"),I0r=l(),F(bC.$$.fragment),uro=l(),bc=a("h2"),vC=a("a"),w5e=a("span"),F(yk.$$.fragment),N0r=l(),A5e=a("span"),q0r=o("AutoModelForAudioClassification"),pro=l(),Yo=a("div"),F(xk.$$.fragment),j0r=l(),vc=a("p"),D0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),LK=a("a"),G0r=o("from_pretrained()"),O0r=o(" class method or the "),yK=a("a"),V0r=o("from_config()"),X0r=o(` class
method.`),z0r=l(),$k=a("p"),Q0r=o("This class cannot be instantiated directly using "),L5e=a("code"),W0r=o("__init__()"),U0r=o(" (throws an error)."),H0r=l(),It=a("div"),F(kk.$$.fragment),J0r=l(),y5e=a("p"),Y0r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Z0r=l(),Fc=a("p"),K0r=o(`Note:
Loading a model from its configuration file does `),x5e=a("strong"),ewr=o("not"),owr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=a("a"),rwr=o("from_pretrained()"),twr=o(" to load the model weights."),awr=l(),F(FC.$$.fragment),nwr=l(),po=a("div"),F(Sk.$$.fragment),swr=l(),$5e=a("p"),lwr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),iwr=l(),_n=a("p"),dwr=o("The model class to instantiate is selected based on the "),k5e=a("code"),cwr=o("model_type"),mwr=o(` property of the config object (either
passed as an argument or loaded from `),S5e=a("code"),fwr=o("pretrained_model_name_or_path"),gwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R5e=a("code"),hwr=o("pretrained_model_name_or_path"),uwr=o(":"),pwr=l(),Be=a("ul"),TC=a("li"),P5e=a("strong"),_wr=o("data2vec-audio"),bwr=o(" \u2014 "),$K=a("a"),vwr=o("Data2VecAudioForSequenceClassification"),Fwr=o(" (Data2VecAudio model)"),Twr=l(),MC=a("li"),B5e=a("strong"),Mwr=o("hubert"),Ewr=o(" \u2014 "),kK=a("a"),Cwr=o("HubertForSequenceClassification"),wwr=o(" (Hubert model)"),Awr=l(),EC=a("li"),I5e=a("strong"),Lwr=o("sew"),ywr=o(" \u2014 "),SK=a("a"),xwr=o("SEWForSequenceClassification"),$wr=o(" (SEW model)"),kwr=l(),CC=a("li"),N5e=a("strong"),Swr=o("sew-d"),Rwr=o(" \u2014 "),RK=a("a"),Pwr=o("SEWDForSequenceClassification"),Bwr=o(" (SEW-D model)"),Iwr=l(),wC=a("li"),q5e=a("strong"),Nwr=o("unispeech"),qwr=o(" \u2014 "),PK=a("a"),jwr=o("UniSpeechForSequenceClassification"),Dwr=o(" (UniSpeech model)"),Gwr=l(),AC=a("li"),j5e=a("strong"),Owr=o("unispeech-sat"),Vwr=o(" \u2014 "),BK=a("a"),Xwr=o("UniSpeechSatForSequenceClassification"),zwr=o(" (UniSpeechSat model)"),Qwr=l(),LC=a("li"),D5e=a("strong"),Wwr=o("wav2vec2"),Uwr=o(" \u2014 "),IK=a("a"),Hwr=o("Wav2Vec2ForSequenceClassification"),Jwr=o(" (Wav2Vec2 model)"),Ywr=l(),yC=a("li"),G5e=a("strong"),Zwr=o("wav2vec2-conformer"),Kwr=o(" \u2014 "),NK=a("a"),eAr=o("Wav2Vec2ConformerForSequenceClassification"),oAr=o(" (Wav2Vec2-Conformer model)"),rAr=l(),xC=a("li"),O5e=a("strong"),tAr=o("wavlm"),aAr=o(" \u2014 "),qK=a("a"),nAr=o("WavLMForSequenceClassification"),sAr=o(" (WavLM model)"),lAr=l(),$C=a("p"),iAr=o("The model is set in evaluation mode by default using "),V5e=a("code"),dAr=o("model.eval()"),cAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X5e=a("code"),mAr=o("model.train()"),fAr=l(),F(kC.$$.fragment),_ro=l(),Tc=a("h2"),SC=a("a"),z5e=a("span"),F(Rk.$$.fragment),gAr=l(),Q5e=a("span"),hAr=o("AutoModelForAudioFrameClassification"),bro=l(),Zo=a("div"),F(Pk.$$.fragment),uAr=l(),Mc=a("p"),pAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),jK=a("a"),_Ar=o("from_pretrained()"),bAr=o(" class method or the "),DK=a("a"),vAr=o("from_config()"),FAr=o(` class
method.`),TAr=l(),Bk=a("p"),MAr=o("This class cannot be instantiated directly using "),W5e=a("code"),EAr=o("__init__()"),CAr=o(" (throws an error)."),wAr=l(),Nt=a("div"),F(Ik.$$.fragment),AAr=l(),U5e=a("p"),LAr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),yAr=l(),Ec=a("p"),xAr=o(`Note:
Loading a model from its configuration file does `),H5e=a("strong"),$Ar=o("not"),kAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=a("a"),SAr=o("from_pretrained()"),RAr=o(" to load the model weights."),PAr=l(),F(RC.$$.fragment),BAr=l(),_o=a("div"),F(Nk.$$.fragment),IAr=l(),J5e=a("p"),NAr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),qAr=l(),bn=a("p"),jAr=o("The model class to instantiate is selected based on the "),Y5e=a("code"),DAr=o("model_type"),GAr=o(` property of the config object (either
passed as an argument or loaded from `),Z5e=a("code"),OAr=o("pretrained_model_name_or_path"),VAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=a("code"),XAr=o("pretrained_model_name_or_path"),zAr=o(":"),QAr=l(),gt=a("ul"),PC=a("li"),e0e=a("strong"),WAr=o("data2vec-audio"),UAr=o(" \u2014 "),OK=a("a"),HAr=o("Data2VecAudioForAudioFrameClassification"),JAr=o(" (Data2VecAudio model)"),YAr=l(),BC=a("li"),o0e=a("strong"),ZAr=o("unispeech-sat"),KAr=o(" \u2014 "),VK=a("a"),e6r=o("UniSpeechSatForAudioFrameClassification"),o6r=o(" (UniSpeechSat model)"),r6r=l(),IC=a("li"),r0e=a("strong"),t6r=o("wav2vec2"),a6r=o(" \u2014 "),XK=a("a"),n6r=o("Wav2Vec2ForAudioFrameClassification"),s6r=o(" (Wav2Vec2 model)"),l6r=l(),NC=a("li"),t0e=a("strong"),i6r=o("wav2vec2-conformer"),d6r=o(" \u2014 "),zK=a("a"),c6r=o("Wav2Vec2ConformerForAudioFrameClassification"),m6r=o(" (Wav2Vec2-Conformer model)"),f6r=l(),qC=a("li"),a0e=a("strong"),g6r=o("wavlm"),h6r=o(" \u2014 "),QK=a("a"),u6r=o("WavLMForAudioFrameClassification"),p6r=o(" (WavLM model)"),_6r=l(),jC=a("p"),b6r=o("The model is set in evaluation mode by default using "),n0e=a("code"),v6r=o("model.eval()"),F6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s0e=a("code"),T6r=o("model.train()"),M6r=l(),F(DC.$$.fragment),vro=l(),Cc=a("h2"),GC=a("a"),l0e=a("span"),F(qk.$$.fragment),E6r=l(),i0e=a("span"),C6r=o("AutoModelForCTC"),Fro=l(),Ko=a("div"),F(jk.$$.fragment),w6r=l(),wc=a("p"),A6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),WK=a("a"),L6r=o("from_pretrained()"),y6r=o(" class method or the "),UK=a("a"),x6r=o("from_config()"),$6r=o(` class
method.`),k6r=l(),Dk=a("p"),S6r=o("This class cannot be instantiated directly using "),d0e=a("code"),R6r=o("__init__()"),P6r=o(" (throws an error)."),B6r=l(),qt=a("div"),F(Gk.$$.fragment),I6r=l(),c0e=a("p"),N6r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),q6r=l(),Ac=a("p"),j6r=o(`Note:
Loading a model from its configuration file does `),m0e=a("strong"),D6r=o("not"),G6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HK=a("a"),O6r=o("from_pretrained()"),V6r=o(" to load the model weights."),X6r=l(),F(OC.$$.fragment),z6r=l(),bo=a("div"),F(Ok.$$.fragment),Q6r=l(),f0e=a("p"),W6r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),U6r=l(),vn=a("p"),H6r=o("The model class to instantiate is selected based on the "),g0e=a("code"),J6r=o("model_type"),Y6r=o(` property of the config object (either
passed as an argument or loaded from `),h0e=a("code"),Z6r=o("pretrained_model_name_or_path"),K6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u0e=a("code"),e7r=o("pretrained_model_name_or_path"),o7r=o(":"),r7r=l(),Le=a("ul"),VC=a("li"),p0e=a("strong"),t7r=o("data2vec-audio"),a7r=o(" \u2014 "),JK=a("a"),n7r=o("Data2VecAudioForCTC"),s7r=o(" (Data2VecAudio model)"),l7r=l(),XC=a("li"),_0e=a("strong"),i7r=o("hubert"),d7r=o(" \u2014 "),YK=a("a"),c7r=o("HubertForCTC"),m7r=o(" (Hubert model)"),f7r=l(),zC=a("li"),b0e=a("strong"),g7r=o("mctct"),h7r=o(" \u2014 "),ZK=a("a"),u7r=o("MCTCTForCTC"),p7r=o(" (M-CTC-T model)"),_7r=l(),QC=a("li"),v0e=a("strong"),b7r=o("sew"),v7r=o(" \u2014 "),KK=a("a"),F7r=o("SEWForCTC"),T7r=o(" (SEW model)"),M7r=l(),WC=a("li"),F0e=a("strong"),E7r=o("sew-d"),C7r=o(" \u2014 "),eee=a("a"),w7r=o("SEWDForCTC"),A7r=o(" (SEW-D model)"),L7r=l(),UC=a("li"),T0e=a("strong"),y7r=o("unispeech"),x7r=o(" \u2014 "),oee=a("a"),$7r=o("UniSpeechForCTC"),k7r=o(" (UniSpeech model)"),S7r=l(),HC=a("li"),M0e=a("strong"),R7r=o("unispeech-sat"),P7r=o(" \u2014 "),ree=a("a"),B7r=o("UniSpeechSatForCTC"),I7r=o(" (UniSpeechSat model)"),N7r=l(),JC=a("li"),E0e=a("strong"),q7r=o("wav2vec2"),j7r=o(" \u2014 "),tee=a("a"),D7r=o("Wav2Vec2ForCTC"),G7r=o(" (Wav2Vec2 model)"),O7r=l(),YC=a("li"),C0e=a("strong"),V7r=o("wav2vec2-conformer"),X7r=o(" \u2014 "),aee=a("a"),z7r=o("Wav2Vec2ConformerForCTC"),Q7r=o(" (Wav2Vec2-Conformer model)"),W7r=l(),ZC=a("li"),w0e=a("strong"),U7r=o("wavlm"),H7r=o(" \u2014 "),nee=a("a"),J7r=o("WavLMForCTC"),Y7r=o(" (WavLM model)"),Z7r=l(),KC=a("p"),K7r=o("The model is set in evaluation mode by default using "),A0e=a("code"),eLr=o("model.eval()"),oLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L0e=a("code"),rLr=o("model.train()"),tLr=l(),F(e3.$$.fragment),Tro=l(),Lc=a("h2"),o3=a("a"),y0e=a("span"),F(Vk.$$.fragment),aLr=l(),x0e=a("span"),nLr=o("AutoModelForSpeechSeq2Seq"),Mro=l(),er=a("div"),F(Xk.$$.fragment),sLr=l(),yc=a("p"),lLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),see=a("a"),iLr=o("from_pretrained()"),dLr=o(" class method or the "),lee=a("a"),cLr=o("from_config()"),mLr=o(` class
method.`),fLr=l(),zk=a("p"),gLr=o("This class cannot be instantiated directly using "),$0e=a("code"),hLr=o("__init__()"),uLr=o(" (throws an error)."),pLr=l(),jt=a("div"),F(Qk.$$.fragment),_Lr=l(),k0e=a("p"),bLr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),vLr=l(),xc=a("p"),FLr=o(`Note:
Loading a model from its configuration file does `),S0e=a("strong"),TLr=o("not"),MLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iee=a("a"),ELr=o("from_pretrained()"),CLr=o(" to load the model weights."),wLr=l(),F(r3.$$.fragment),ALr=l(),vo=a("div"),F(Wk.$$.fragment),LLr=l(),R0e=a("p"),yLr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),xLr=l(),Fn=a("p"),$Lr=o("The model class to instantiate is selected based on the "),P0e=a("code"),kLr=o("model_type"),SLr=o(` property of the config object (either
passed as an argument or loaded from `),B0e=a("code"),RLr=o("pretrained_model_name_or_path"),PLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I0e=a("code"),BLr=o("pretrained_model_name_or_path"),ILr=o(":"),NLr=l(),$c=a("ul"),t3=a("li"),N0e=a("strong"),qLr=o("speech-encoder-decoder"),jLr=o(" \u2014 "),dee=a("a"),DLr=o("SpeechEncoderDecoderModel"),GLr=o(" (Speech Encoder decoder model)"),OLr=l(),a3=a("li"),q0e=a("strong"),VLr=o("speech_to_text"),XLr=o(" \u2014 "),cee=a("a"),zLr=o("Speech2TextForConditionalGeneration"),QLr=o(" (Speech2Text model)"),WLr=l(),n3=a("li"),j0e=a("strong"),ULr=o("whisper"),HLr=o(" \u2014 "),mee=a("a"),JLr=o("WhisperForConditionalGeneration"),YLr=o(" (Whisper model)"),ZLr=l(),s3=a("p"),KLr=o("The model is set in evaluation mode by default using "),D0e=a("code"),e8r=o("model.eval()"),o8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G0e=a("code"),r8r=o("model.train()"),t8r=l(),F(l3.$$.fragment),Ero=l(),kc=a("h2"),i3=a("a"),O0e=a("span"),F(Uk.$$.fragment),a8r=l(),V0e=a("span"),n8r=o("AutoModelForAudioXVector"),Cro=l(),or=a("div"),F(Hk.$$.fragment),s8r=l(),Sc=a("p"),l8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),fee=a("a"),i8r=o("from_pretrained()"),d8r=o(" class method or the "),gee=a("a"),c8r=o("from_config()"),m8r=o(` class
method.`),f8r=l(),Jk=a("p"),g8r=o("This class cannot be instantiated directly using "),X0e=a("code"),h8r=o("__init__()"),u8r=o(" (throws an error)."),p8r=l(),Dt=a("div"),F(Yk.$$.fragment),_8r=l(),z0e=a("p"),b8r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),v8r=l(),Rc=a("p"),F8r=o(`Note:
Loading a model from its configuration file does `),Q0e=a("strong"),T8r=o("not"),M8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hee=a("a"),E8r=o("from_pretrained()"),C8r=o(" to load the model weights."),w8r=l(),F(d3.$$.fragment),A8r=l(),Fo=a("div"),F(Zk.$$.fragment),L8r=l(),W0e=a("p"),y8r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),x8r=l(),Tn=a("p"),$8r=o("The model class to instantiate is selected based on the "),U0e=a("code"),k8r=o("model_type"),S8r=o(` property of the config object (either
passed as an argument or loaded from `),H0e=a("code"),R8r=o("pretrained_model_name_or_path"),P8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J0e=a("code"),B8r=o("pretrained_model_name_or_path"),I8r=o(":"),N8r=l(),ht=a("ul"),c3=a("li"),Y0e=a("strong"),q8r=o("data2vec-audio"),j8r=o(" \u2014 "),uee=a("a"),D8r=o("Data2VecAudioForXVector"),G8r=o(" (Data2VecAudio model)"),O8r=l(),m3=a("li"),Z0e=a("strong"),V8r=o("unispeech-sat"),X8r=o(" \u2014 "),pee=a("a"),z8r=o("UniSpeechSatForXVector"),Q8r=o(" (UniSpeechSat model)"),W8r=l(),f3=a("li"),K0e=a("strong"),U8r=o("wav2vec2"),H8r=o(" \u2014 "),_ee=a("a"),J8r=o("Wav2Vec2ForXVector"),Y8r=o(" (Wav2Vec2 model)"),Z8r=l(),g3=a("li"),ewe=a("strong"),K8r=o("wav2vec2-conformer"),eyr=o(" \u2014 "),bee=a("a"),oyr=o("Wav2Vec2ConformerForXVector"),ryr=o(" (Wav2Vec2-Conformer model)"),tyr=l(),h3=a("li"),owe=a("strong"),ayr=o("wavlm"),nyr=o(" \u2014 "),vee=a("a"),syr=o("WavLMForXVector"),lyr=o(" (WavLM model)"),iyr=l(),u3=a("p"),dyr=o("The model is set in evaluation mode by default using "),rwe=a("code"),cyr=o("model.eval()"),myr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),twe=a("code"),fyr=o("model.train()"),gyr=l(),F(p3.$$.fragment),wro=l(),Pc=a("h2"),_3=a("a"),awe=a("span"),F(Kk.$$.fragment),hyr=l(),nwe=a("span"),uyr=o("AutoModelForMaskedImageModeling"),Aro=l(),rr=a("div"),F(eS.$$.fragment),pyr=l(),Bc=a("p"),_yr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Fee=a("a"),byr=o("from_pretrained()"),vyr=o(" class method or the "),Tee=a("a"),Fyr=o("from_config()"),Tyr=o(` class
method.`),Myr=l(),oS=a("p"),Eyr=o("This class cannot be instantiated directly using "),swe=a("code"),Cyr=o("__init__()"),wyr=o(" (throws an error)."),Ayr=l(),Gt=a("div"),F(rS.$$.fragment),Lyr=l(),lwe=a("p"),yyr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),xyr=l(),Ic=a("p"),$yr=o(`Note:
Loading a model from its configuration file does `),iwe=a("strong"),kyr=o("not"),Syr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mee=a("a"),Ryr=o("from_pretrained()"),Pyr=o(" to load the model weights."),Byr=l(),F(b3.$$.fragment),Iyr=l(),To=a("div"),F(tS.$$.fragment),Nyr=l(),dwe=a("p"),qyr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),jyr=l(),Mn=a("p"),Dyr=o("The model class to instantiate is selected based on the "),cwe=a("code"),Gyr=o("model_type"),Oyr=o(` property of the config object (either
passed as an argument or loaded from `),mwe=a("code"),Vyr=o("pretrained_model_name_or_path"),Xyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fwe=a("code"),zyr=o("pretrained_model_name_or_path"),Qyr=o(":"),Wyr=l(),En=a("ul"),v3=a("li"),gwe=a("strong"),Uyr=o("deit"),Hyr=o(" \u2014 "),Eee=a("a"),Jyr=o("DeiTForMaskedImageModeling"),Yyr=o(" (DeiT model)"),Zyr=l(),F3=a("li"),hwe=a("strong"),Kyr=o("swin"),e9r=o(" \u2014 "),Cee=a("a"),o9r=o("SwinForMaskedImageModeling"),r9r=o(" (Swin Transformer model)"),t9r=l(),T3=a("li"),uwe=a("strong"),a9r=o("swinv2"),n9r=o(" \u2014 "),wee=a("a"),s9r=o("Swinv2ForMaskedImageModeling"),l9r=o(" (Swin Transformer V2 model)"),i9r=l(),M3=a("li"),pwe=a("strong"),d9r=o("vit"),c9r=o(" \u2014 "),Aee=a("a"),m9r=o("ViTForMaskedImageModeling"),f9r=o(" (ViT model)"),g9r=l(),E3=a("p"),h9r=o("The model is set in evaluation mode by default using "),_we=a("code"),u9r=o("model.eval()"),p9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bwe=a("code"),_9r=o("model.train()"),b9r=l(),F(C3.$$.fragment),Lro=l(),Nc=a("h2"),w3=a("a"),vwe=a("span"),F(aS.$$.fragment),v9r=l(),Fwe=a("span"),F9r=o("AutoModelForObjectDetection"),yro=l(),tr=a("div"),F(nS.$$.fragment),T9r=l(),qc=a("p"),M9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Lee=a("a"),E9r=o("from_pretrained()"),C9r=o(" class method or the "),yee=a("a"),w9r=o("from_config()"),A9r=o(` class
method.`),L9r=l(),sS=a("p"),y9r=o("This class cannot be instantiated directly using "),Twe=a("code"),x9r=o("__init__()"),$9r=o(" (throws an error)."),k9r=l(),Ot=a("div"),F(lS.$$.fragment),S9r=l(),Mwe=a("p"),R9r=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),P9r=l(),jc=a("p"),B9r=o(`Note:
Loading a model from its configuration file does `),Ewe=a("strong"),I9r=o("not"),N9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=a("a"),q9r=o("from_pretrained()"),j9r=o(" to load the model weights."),D9r=l(),F(A3.$$.fragment),G9r=l(),Mo=a("div"),F(iS.$$.fragment),O9r=l(),Cwe=a("p"),V9r=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),X9r=l(),Cn=a("p"),z9r=o("The model class to instantiate is selected based on the "),wwe=a("code"),Q9r=o("model_type"),W9r=o(` property of the config object (either
passed as an argument or loaded from `),Awe=a("code"),U9r=o("pretrained_model_name_or_path"),H9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lwe=a("code"),J9r=o("pretrained_model_name_or_path"),Y9r=o(":"),Z9r=l(),wn=a("ul"),L3=a("li"),ywe=a("strong"),K9r=o("conditional_detr"),exr=o(" \u2014 "),$ee=a("a"),oxr=o("ConditionalDetrForObjectDetection"),rxr=o(" (Conditional DETR model)"),txr=l(),y3=a("li"),xwe=a("strong"),axr=o("deformable_detr"),nxr=o(" \u2014 "),kee=a("a"),sxr=o("DeformableDetrForObjectDetection"),lxr=o(" (Deformable DETR model)"),ixr=l(),x3=a("li"),$we=a("strong"),dxr=o("detr"),cxr=o(" \u2014 "),See=a("a"),mxr=o("DetrForObjectDetection"),fxr=o(" (DETR model)"),gxr=l(),$3=a("li"),kwe=a("strong"),hxr=o("yolos"),uxr=o(" \u2014 "),Ree=a("a"),pxr=o("YolosForObjectDetection"),_xr=o(" (YOLOS model)"),bxr=l(),k3=a("p"),vxr=o("The model is set in evaluation mode by default using "),Swe=a("code"),Fxr=o("model.eval()"),Txr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rwe=a("code"),Mxr=o("model.train()"),Exr=l(),F(S3.$$.fragment),xro=l(),Dc=a("h2"),R3=a("a"),Pwe=a("span"),F(dS.$$.fragment),Cxr=l(),Bwe=a("span"),wxr=o("AutoModelForImageSegmentation"),$ro=l(),ar=a("div"),F(cS.$$.fragment),Axr=l(),Gc=a("p"),Lxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Pee=a("a"),yxr=o("from_pretrained()"),xxr=o(" class method or the "),Bee=a("a"),$xr=o("from_config()"),kxr=o(` class
method.`),Sxr=l(),mS=a("p"),Rxr=o("This class cannot be instantiated directly using "),Iwe=a("code"),Pxr=o("__init__()"),Bxr=o(" (throws an error)."),Ixr=l(),Vt=a("div"),F(fS.$$.fragment),Nxr=l(),Nwe=a("p"),qxr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),jxr=l(),Oc=a("p"),Dxr=o(`Note:
Loading a model from its configuration file does `),qwe=a("strong"),Gxr=o("not"),Oxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=a("a"),Vxr=o("from_pretrained()"),Xxr=o(" to load the model weights."),zxr=l(),F(P3.$$.fragment),Qxr=l(),Eo=a("div"),F(gS.$$.fragment),Wxr=l(),jwe=a("p"),Uxr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Hxr=l(),An=a("p"),Jxr=o("The model class to instantiate is selected based on the "),Dwe=a("code"),Yxr=o("model_type"),Zxr=o(` property of the config object (either
passed as an argument or loaded from `),Gwe=a("code"),Kxr=o("pretrained_model_name_or_path"),e$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Owe=a("code"),o$r=o("pretrained_model_name_or_path"),r$r=o(":"),t$r=l(),Vwe=a("ul"),B3=a("li"),Xwe=a("strong"),a$r=o("detr"),n$r=o(" \u2014 "),Nee=a("a"),s$r=o("DetrForSegmentation"),l$r=o(" (DETR model)"),i$r=l(),I3=a("p"),d$r=o("The model is set in evaluation mode by default using "),zwe=a("code"),c$r=o("model.eval()"),m$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qwe=a("code"),f$r=o("model.train()"),g$r=l(),F(N3.$$.fragment),kro=l(),Vc=a("h2"),q3=a("a"),Wwe=a("span"),F(hS.$$.fragment),h$r=l(),Uwe=a("span"),u$r=o("AutoModelForSemanticSegmentation"),Sro=l(),nr=a("div"),F(uS.$$.fragment),p$r=l(),Xc=a("p"),_$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),qee=a("a"),b$r=o("from_pretrained()"),v$r=o(" class method or the "),jee=a("a"),F$r=o("from_config()"),T$r=o(` class
method.`),M$r=l(),pS=a("p"),E$r=o("This class cannot be instantiated directly using "),Hwe=a("code"),C$r=o("__init__()"),w$r=o(" (throws an error)."),A$r=l(),Xt=a("div"),F(_S.$$.fragment),L$r=l(),Jwe=a("p"),y$r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),x$r=l(),zc=a("p"),$$r=o(`Note:
Loading a model from its configuration file does `),Ywe=a("strong"),k$r=o("not"),S$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dee=a("a"),R$r=o("from_pretrained()"),P$r=o(" to load the model weights."),B$r=l(),F(j3.$$.fragment),I$r=l(),Co=a("div"),F(bS.$$.fragment),N$r=l(),Zwe=a("p"),q$r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),j$r=l(),Ln=a("p"),D$r=o("The model class to instantiate is selected based on the "),Kwe=a("code"),G$r=o("model_type"),O$r=o(` property of the config object (either
passed as an argument or loaded from `),eAe=a("code"),V$r=o("pretrained_model_name_or_path"),X$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oAe=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(":"),W$r=l(),ut=a("ul"),D3=a("li"),rAe=a("strong"),U$r=o("beit"),H$r=o(" \u2014 "),Gee=a("a"),J$r=o("BeitForSemanticSegmentation"),Y$r=o(" (BEiT model)"),Z$r=l(),G3=a("li"),tAe=a("strong"),K$r=o("data2vec-vision"),ekr=o(" \u2014 "),Oee=a("a"),okr=o("Data2VecVisionForSemanticSegmentation"),rkr=o(" (Data2VecVision model)"),tkr=l(),O3=a("li"),aAe=a("strong"),akr=o("dpt"),nkr=o(" \u2014 "),Vee=a("a"),skr=o("DPTForSemanticSegmentation"),lkr=o(" (DPT model)"),ikr=l(),V3=a("li"),nAe=a("strong"),dkr=o("mobilevit"),ckr=o(" \u2014 "),Xee=a("a"),mkr=o("MobileViTForSemanticSegmentation"),fkr=o(" (MobileViT model)"),gkr=l(),X3=a("li"),sAe=a("strong"),hkr=o("segformer"),ukr=o(" \u2014 "),zee=a("a"),pkr=o("SegformerForSemanticSegmentation"),_kr=o(" (SegFormer model)"),bkr=l(),z3=a("p"),vkr=o("The model is set in evaluation mode by default using "),lAe=a("code"),Fkr=o("model.eval()"),Tkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iAe=a("code"),Mkr=o("model.train()"),Ekr=l(),F(Q3.$$.fragment),Rro=l(),Qc=a("h2"),W3=a("a"),dAe=a("span"),F(vS.$$.fragment),Ckr=l(),cAe=a("span"),wkr=o("AutoModelForInstanceSegmentation"),Pro=l(),sr=a("div"),F(FS.$$.fragment),Akr=l(),Wc=a("p"),Lkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Qee=a("a"),ykr=o("from_pretrained()"),xkr=o(" class method or the "),Wee=a("a"),$kr=o("from_config()"),kkr=o(` class
method.`),Skr=l(),TS=a("p"),Rkr=o("This class cannot be instantiated directly using "),mAe=a("code"),Pkr=o("__init__()"),Bkr=o(" (throws an error)."),Ikr=l(),zt=a("div"),F(MS.$$.fragment),Nkr=l(),fAe=a("p"),qkr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),jkr=l(),Uc=a("p"),Dkr=o(`Note:
Loading a model from its configuration file does `),gAe=a("strong"),Gkr=o("not"),Okr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uee=a("a"),Vkr=o("from_pretrained()"),Xkr=o(" to load the model weights."),zkr=l(),F(U3.$$.fragment),Qkr=l(),wo=a("div"),F(ES.$$.fragment),Wkr=l(),hAe=a("p"),Ukr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Hkr=l(),yn=a("p"),Jkr=o("The model class to instantiate is selected based on the "),uAe=a("code"),Ykr=o("model_type"),Zkr=o(` property of the config object (either
passed as an argument or loaded from `),pAe=a("code"),Kkr=o("pretrained_model_name_or_path"),eSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=a("code"),oSr=o("pretrained_model_name_or_path"),rSr=o(":"),tSr=l(),bAe=a("ul"),H3=a("li"),vAe=a("strong"),aSr=o("maskformer"),nSr=o(" \u2014 "),Hee=a("a"),sSr=o("MaskFormerForInstanceSegmentation"),lSr=o(" (MaskFormer model)"),iSr=l(),J3=a("p"),dSr=o("The model is set in evaluation mode by default using "),FAe=a("code"),cSr=o("model.eval()"),mSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TAe=a("code"),fSr=o("model.train()"),gSr=l(),F(Y3.$$.fragment),Bro=l(),Hc=a("h2"),Z3=a("a"),MAe=a("span"),F(CS.$$.fragment),hSr=l(),EAe=a("span"),uSr=o("AutoModelForZeroShotObjectDetection"),Iro=l(),lr=a("div"),F(wS.$$.fragment),pSr=l(),Jc=a("p"),_Sr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),Jee=a("a"),bSr=o("from_pretrained()"),vSr=o(" class method or the "),Yee=a("a"),FSr=o("from_config()"),TSr=o(` class
method.`),MSr=l(),AS=a("p"),ESr=o("This class cannot be instantiated directly using "),CAe=a("code"),CSr=o("__init__()"),wSr=o(" (throws an error)."),ASr=l(),Qt=a("div"),F(LS.$$.fragment),LSr=l(),wAe=a("p"),ySr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),xSr=l(),Yc=a("p"),$Sr=o(`Note:
Loading a model from its configuration file does `),AAe=a("strong"),kSr=o("not"),SSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zee=a("a"),RSr=o("from_pretrained()"),PSr=o(" to load the model weights."),BSr=l(),F(K3.$$.fragment),ISr=l(),Ao=a("div"),F(yS.$$.fragment),NSr=l(),LAe=a("p"),qSr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),jSr=l(),xn=a("p"),DSr=o("The model class to instantiate is selected based on the "),yAe=a("code"),GSr=o("model_type"),OSr=o(` property of the config object (either
passed as an argument or loaded from `),xAe=a("code"),VSr=o("pretrained_model_name_or_path"),XSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=a("code"),zSr=o("pretrained_model_name_or_path"),QSr=o(":"),WSr=l(),kAe=a("ul"),e5=a("li"),SAe=a("strong"),USr=o("owlvit"),HSr=o(" \u2014 "),Kee=a("a"),JSr=o("OwlViTForObjectDetection"),YSr=o(" (OWL-ViT model)"),ZSr=l(),o5=a("p"),KSr=o("The model is set in evaluation mode by default using "),RAe=a("code"),eRr=o("model.eval()"),oRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PAe=a("code"),rRr=o("model.train()"),tRr=l(),F(r5.$$.fragment),Nro=l(),Zc=a("h2"),t5=a("a"),BAe=a("span"),F(xS.$$.fragment),aRr=l(),IAe=a("span"),nRr=o("TFAutoModel"),qro=l(),ir=a("div"),F($S.$$.fragment),sRr=l(),Kc=a("p"),lRr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),eoe=a("a"),iRr=o("from_pretrained()"),dRr=o(" class method or the "),ooe=a("a"),cRr=o("from_config()"),mRr=o(` class
method.`),fRr=l(),kS=a("p"),gRr=o("This class cannot be instantiated directly using "),NAe=a("code"),hRr=o("__init__()"),uRr=o(" (throws an error)."),pRr=l(),Wt=a("div"),F(SS.$$.fragment),_Rr=l(),qAe=a("p"),bRr=o("Instantiates one of the base model classes of the library from a configuration."),vRr=l(),em=a("p"),FRr=o(`Note:
Loading a model from its configuration file does `),jAe=a("strong"),TRr=o("not"),MRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=a("a"),ERr=o("from_pretrained()"),CRr=o(" to load the model weights."),wRr=l(),F(a5.$$.fragment),ARr=l(),qr=a("div"),F(RS.$$.fragment),LRr=l(),DAe=a("p"),yRr=o("Instantiate one of the base model classes of the library from a pretrained model."),xRr=l(),$n=a("p"),$Rr=o("The model class to instantiate is selected based on the "),GAe=a("code"),kRr=o("model_type"),SRr=o(` property of the config object (either
passed as an argument or loaded from `),OAe=a("code"),RRr=o("pretrained_model_name_or_path"),PRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VAe=a("code"),BRr=o("pretrained_model_name_or_path"),IRr=o(":"),NRr=l(),P=a("ul"),n5=a("li"),XAe=a("strong"),qRr=o("albert"),jRr=o(" \u2014 "),toe=a("a"),DRr=o("TFAlbertModel"),GRr=o(" (ALBERT model)"),ORr=l(),s5=a("li"),zAe=a("strong"),VRr=o("bart"),XRr=o(" \u2014 "),aoe=a("a"),zRr=o("TFBartModel"),QRr=o(" (BART model)"),WRr=l(),l5=a("li"),QAe=a("strong"),URr=o("bert"),HRr=o(" \u2014 "),noe=a("a"),JRr=o("TFBertModel"),YRr=o(" (BERT model)"),ZRr=l(),i5=a("li"),WAe=a("strong"),KRr=o("blenderbot"),ePr=o(" \u2014 "),soe=a("a"),oPr=o("TFBlenderbotModel"),rPr=o(" (Blenderbot model)"),tPr=l(),d5=a("li"),UAe=a("strong"),aPr=o("blenderbot-small"),nPr=o(" \u2014 "),loe=a("a"),sPr=o("TFBlenderbotSmallModel"),lPr=o(" (BlenderbotSmall model)"),iPr=l(),c5=a("li"),HAe=a("strong"),dPr=o("camembert"),cPr=o(" \u2014 "),ioe=a("a"),mPr=o("TFCamembertModel"),fPr=o(" (CamemBERT model)"),gPr=l(),m5=a("li"),JAe=a("strong"),hPr=o("clip"),uPr=o(" \u2014 "),doe=a("a"),pPr=o("TFCLIPModel"),_Pr=o(" (CLIP model)"),bPr=l(),f5=a("li"),YAe=a("strong"),vPr=o("convbert"),FPr=o(" \u2014 "),coe=a("a"),TPr=o("TFConvBertModel"),MPr=o(" (ConvBERT model)"),EPr=l(),g5=a("li"),ZAe=a("strong"),CPr=o("convnext"),wPr=o(" \u2014 "),moe=a("a"),APr=o("TFConvNextModel"),LPr=o(" (ConvNeXT model)"),yPr=l(),h5=a("li"),KAe=a("strong"),xPr=o("ctrl"),$Pr=o(" \u2014 "),foe=a("a"),kPr=o("TFCTRLModel"),SPr=o(" (CTRL model)"),RPr=l(),u5=a("li"),e6e=a("strong"),PPr=o("cvt"),BPr=o(" \u2014 "),goe=a("a"),IPr=o("TFCvtModel"),NPr=o(" (CvT model)"),qPr=l(),p5=a("li"),o6e=a("strong"),jPr=o("data2vec-vision"),DPr=o(" \u2014 "),hoe=a("a"),GPr=o("TFData2VecVisionModel"),OPr=o(" (Data2VecVision model)"),VPr=l(),_5=a("li"),r6e=a("strong"),XPr=o("deberta"),zPr=o(" \u2014 "),uoe=a("a"),QPr=o("TFDebertaModel"),WPr=o(" (DeBERTa model)"),UPr=l(),b5=a("li"),t6e=a("strong"),HPr=o("deberta-v2"),JPr=o(" \u2014 "),poe=a("a"),YPr=o("TFDebertaV2Model"),ZPr=o(" (DeBERTa-v2 model)"),KPr=l(),v5=a("li"),a6e=a("strong"),eBr=o("deit"),oBr=o(" \u2014 "),_oe=a("a"),rBr=o("TFDeiTModel"),tBr=o(" (DeiT model)"),aBr=l(),F5=a("li"),n6e=a("strong"),nBr=o("distilbert"),sBr=o(" \u2014 "),boe=a("a"),lBr=o("TFDistilBertModel"),iBr=o(" (DistilBERT model)"),dBr=l(),T5=a("li"),s6e=a("strong"),cBr=o("dpr"),mBr=o(" \u2014 "),voe=a("a"),fBr=o("TFDPRQuestionEncoder"),gBr=o(" (DPR model)"),hBr=l(),M5=a("li"),l6e=a("strong"),uBr=o("electra"),pBr=o(" \u2014 "),Foe=a("a"),_Br=o("TFElectraModel"),bBr=o(" (ELECTRA model)"),vBr=l(),E5=a("li"),i6e=a("strong"),FBr=o("flaubert"),TBr=o(" \u2014 "),Toe=a("a"),MBr=o("TFFlaubertModel"),EBr=o(" (FlauBERT model)"),CBr=l(),wl=a("li"),d6e=a("strong"),wBr=o("funnel"),ABr=o(" \u2014 "),Moe=a("a"),LBr=o("TFFunnelModel"),yBr=o(" or "),Eoe=a("a"),xBr=o("TFFunnelBaseModel"),$Br=o(" (Funnel Transformer model)"),kBr=l(),C5=a("li"),c6e=a("strong"),SBr=o("gpt2"),RBr=o(" \u2014 "),Coe=a("a"),PBr=o("TFGPT2Model"),BBr=o(" (OpenAI GPT-2 model)"),IBr=l(),w5=a("li"),m6e=a("strong"),NBr=o("gptj"),qBr=o(" \u2014 "),woe=a("a"),jBr=o("TFGPTJModel"),DBr=o(" (GPT-J model)"),GBr=l(),A5=a("li"),f6e=a("strong"),OBr=o("groupvit"),VBr=o(" \u2014 "),Aoe=a("a"),XBr=o("TFGroupViTModel"),zBr=o(" (GroupViT model)"),QBr=l(),L5=a("li"),g6e=a("strong"),WBr=o("hubert"),UBr=o(" \u2014 "),Loe=a("a"),HBr=o("TFHubertModel"),JBr=o(" (Hubert model)"),YBr=l(),y5=a("li"),h6e=a("strong"),ZBr=o("layoutlm"),KBr=o(" \u2014 "),yoe=a("a"),eIr=o("TFLayoutLMModel"),oIr=o(" (LayoutLM model)"),rIr=l(),x5=a("li"),u6e=a("strong"),tIr=o("layoutlmv3"),aIr=o(" \u2014 "),xoe=a("a"),nIr=o("TFLayoutLMv3Model"),sIr=o(" (LayoutLMv3 model)"),lIr=l(),$5=a("li"),p6e=a("strong"),iIr=o("led"),dIr=o(" \u2014 "),$oe=a("a"),cIr=o("TFLEDModel"),mIr=o(" (LED model)"),fIr=l(),k5=a("li"),_6e=a("strong"),gIr=o("longformer"),hIr=o(" \u2014 "),koe=a("a"),uIr=o("TFLongformerModel"),pIr=o(" (Longformer model)"),_Ir=l(),S5=a("li"),b6e=a("strong"),bIr=o("lxmert"),vIr=o(" \u2014 "),Soe=a("a"),FIr=o("TFLxmertModel"),TIr=o(" (LXMERT model)"),MIr=l(),R5=a("li"),v6e=a("strong"),EIr=o("marian"),CIr=o(" \u2014 "),Roe=a("a"),wIr=o("TFMarianModel"),AIr=o(" (Marian model)"),LIr=l(),P5=a("li"),F6e=a("strong"),yIr=o("mbart"),xIr=o(" \u2014 "),Poe=a("a"),$Ir=o("TFMBartModel"),kIr=o(" (mBART model)"),SIr=l(),B5=a("li"),T6e=a("strong"),RIr=o("mobilebert"),PIr=o(" \u2014 "),Boe=a("a"),BIr=o("TFMobileBertModel"),IIr=o(" (MobileBERT model)"),NIr=l(),I5=a("li"),M6e=a("strong"),qIr=o("mobilevit"),jIr=o(" \u2014 "),Ioe=a("a"),DIr=o("TFMobileViTModel"),GIr=o(" (MobileViT model)"),OIr=l(),N5=a("li"),E6e=a("strong"),VIr=o("mpnet"),XIr=o(" \u2014 "),Noe=a("a"),zIr=o("TFMPNetModel"),QIr=o(" (MPNet model)"),WIr=l(),q5=a("li"),C6e=a("strong"),UIr=o("mt5"),HIr=o(" \u2014 "),qoe=a("a"),JIr=o("TFMT5Model"),YIr=o(" (MT5 model)"),ZIr=l(),j5=a("li"),w6e=a("strong"),KIr=o("openai-gpt"),eNr=o(" \u2014 "),joe=a("a"),oNr=o("TFOpenAIGPTModel"),rNr=o(" (OpenAI GPT model)"),tNr=l(),D5=a("li"),A6e=a("strong"),aNr=o("opt"),nNr=o(" \u2014 "),Doe=a("a"),sNr=o("TFOPTModel"),lNr=o(" (OPT model)"),iNr=l(),G5=a("li"),L6e=a("strong"),dNr=o("pegasus"),cNr=o(" \u2014 "),Goe=a("a"),mNr=o("TFPegasusModel"),fNr=o(" (Pegasus model)"),gNr=l(),O5=a("li"),y6e=a("strong"),hNr=o("regnet"),uNr=o(" \u2014 "),Ooe=a("a"),pNr=o("TFRegNetModel"),_Nr=o(" (RegNet model)"),bNr=l(),V5=a("li"),x6e=a("strong"),vNr=o("rembert"),FNr=o(" \u2014 "),Voe=a("a"),TNr=o("TFRemBertModel"),MNr=o(" (RemBERT model)"),ENr=l(),X5=a("li"),$6e=a("strong"),CNr=o("resnet"),wNr=o(" \u2014 "),Xoe=a("a"),ANr=o("TFResNetModel"),LNr=o(" (ResNet model)"),yNr=l(),z5=a("li"),k6e=a("strong"),xNr=o("roberta"),$Nr=o(" \u2014 "),zoe=a("a"),kNr=o("TFRobertaModel"),SNr=o(" (RoBERTa model)"),RNr=l(),Q5=a("li"),S6e=a("strong"),PNr=o("roformer"),BNr=o(" \u2014 "),Qoe=a("a"),INr=o("TFRoFormerModel"),NNr=o(" (RoFormer model)"),qNr=l(),W5=a("li"),R6e=a("strong"),jNr=o("segformer"),DNr=o(" \u2014 "),Woe=a("a"),GNr=o("TFSegformerModel"),ONr=o(" (SegFormer model)"),VNr=l(),U5=a("li"),P6e=a("strong"),XNr=o("speech_to_text"),zNr=o(" \u2014 "),Uoe=a("a"),QNr=o("TFSpeech2TextModel"),WNr=o(" (Speech2Text model)"),UNr=l(),H5=a("li"),B6e=a("strong"),HNr=o("swin"),JNr=o(" \u2014 "),Hoe=a("a"),YNr=o("TFSwinModel"),ZNr=o(" (Swin Transformer model)"),KNr=l(),J5=a("li"),I6e=a("strong"),eqr=o("t5"),oqr=o(" \u2014 "),Joe=a("a"),rqr=o("TFT5Model"),tqr=o(" (T5 model)"),aqr=l(),Y5=a("li"),N6e=a("strong"),nqr=o("tapas"),sqr=o(" \u2014 "),Yoe=a("a"),lqr=o("TFTapasModel"),iqr=o(" (TAPAS model)"),dqr=l(),Z5=a("li"),q6e=a("strong"),cqr=o("transfo-xl"),mqr=o(" \u2014 "),Zoe=a("a"),fqr=o("TFTransfoXLModel"),gqr=o(" (Transformer-XL model)"),hqr=l(),K5=a("li"),j6e=a("strong"),uqr=o("vit"),pqr=o(" \u2014 "),Koe=a("a"),_qr=o("TFViTModel"),bqr=o(" (ViT model)"),vqr=l(),e0=a("li"),D6e=a("strong"),Fqr=o("vit_mae"),Tqr=o(" \u2014 "),ere=a("a"),Mqr=o("TFViTMAEModel"),Eqr=o(" (ViTMAE model)"),Cqr=l(),o0=a("li"),G6e=a("strong"),wqr=o("wav2vec2"),Aqr=o(" \u2014 "),ore=a("a"),Lqr=o("TFWav2Vec2Model"),yqr=o(" (Wav2Vec2 model)"),xqr=l(),r0=a("li"),O6e=a("strong"),$qr=o("whisper"),kqr=o(" \u2014 "),rre=a("a"),Sqr=o("TFWhisperModel"),Rqr=o(" (Whisper model)"),Pqr=l(),t0=a("li"),V6e=a("strong"),Bqr=o("xglm"),Iqr=o(" \u2014 "),tre=a("a"),Nqr=o("TFXGLMModel"),qqr=o(" (XGLM model)"),jqr=l(),a0=a("li"),X6e=a("strong"),Dqr=o("xlm"),Gqr=o(" \u2014 "),are=a("a"),Oqr=o("TFXLMModel"),Vqr=o(" (XLM model)"),Xqr=l(),n0=a("li"),z6e=a("strong"),zqr=o("xlm-roberta"),Qqr=o(" \u2014 "),nre=a("a"),Wqr=o("TFXLMRobertaModel"),Uqr=o(" (XLM-RoBERTa model)"),Hqr=l(),s0=a("li"),Q6e=a("strong"),Jqr=o("xlnet"),Yqr=o(" \u2014 "),sre=a("a"),Zqr=o("TFXLNetModel"),Kqr=o(" (XLNet model)"),ejr=l(),F(l0.$$.fragment),jro=l(),om=a("h2"),i0=a("a"),W6e=a("span"),F(PS.$$.fragment),ojr=l(),U6e=a("span"),rjr=o("TFAutoModelForPreTraining"),Dro=l(),dr=a("div"),F(BS.$$.fragment),tjr=l(),rm=a("p"),ajr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lre=a("a"),njr=o("from_pretrained()"),sjr=o(" class method or the "),ire=a("a"),ljr=o("from_config()"),ijr=o(` class
method.`),djr=l(),IS=a("p"),cjr=o("This class cannot be instantiated directly using "),H6e=a("code"),mjr=o("__init__()"),fjr=o(" (throws an error)."),gjr=l(),Ut=a("div"),F(NS.$$.fragment),hjr=l(),J6e=a("p"),ujr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),pjr=l(),tm=a("p"),_jr=o(`Note:
Loading a model from its configuration file does `),Y6e=a("strong"),bjr=o("not"),vjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dre=a("a"),Fjr=o("from_pretrained()"),Tjr=o(" to load the model weights."),Mjr=l(),F(d0.$$.fragment),Ejr=l(),jr=a("div"),F(qS.$$.fragment),Cjr=l(),Z6e=a("p"),wjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Ajr=l(),kn=a("p"),Ljr=o("The model class to instantiate is selected based on the "),K6e=a("code"),yjr=o("model_type"),xjr=o(` property of the config object (either
passed as an argument or loaded from `),e7e=a("code"),$jr=o("pretrained_model_name_or_path"),kjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=a("code"),Sjr=o("pretrained_model_name_or_path"),Rjr=o(":"),Pjr=l(),le=a("ul"),c0=a("li"),r7e=a("strong"),Bjr=o("albert"),Ijr=o(" \u2014 "),cre=a("a"),Njr=o("TFAlbertForPreTraining"),qjr=o(" (ALBERT model)"),jjr=l(),m0=a("li"),t7e=a("strong"),Djr=o("bart"),Gjr=o(" \u2014 "),mre=a("a"),Ojr=o("TFBartForConditionalGeneration"),Vjr=o(" (BART model)"),Xjr=l(),f0=a("li"),a7e=a("strong"),zjr=o("bert"),Qjr=o(" \u2014 "),fre=a("a"),Wjr=o("TFBertForPreTraining"),Ujr=o(" (BERT model)"),Hjr=l(),g0=a("li"),n7e=a("strong"),Jjr=o("camembert"),Yjr=o(" \u2014 "),gre=a("a"),Zjr=o("TFCamembertForMaskedLM"),Kjr=o(" (CamemBERT model)"),eDr=l(),h0=a("li"),s7e=a("strong"),oDr=o("ctrl"),rDr=o(" \u2014 "),hre=a("a"),tDr=o("TFCTRLLMHeadModel"),aDr=o(" (CTRL model)"),nDr=l(),u0=a("li"),l7e=a("strong"),sDr=o("distilbert"),lDr=o(" \u2014 "),ure=a("a"),iDr=o("TFDistilBertForMaskedLM"),dDr=o(" (DistilBERT model)"),cDr=l(),p0=a("li"),i7e=a("strong"),mDr=o("electra"),fDr=o(" \u2014 "),pre=a("a"),gDr=o("TFElectraForPreTraining"),hDr=o(" (ELECTRA model)"),uDr=l(),_0=a("li"),d7e=a("strong"),pDr=o("flaubert"),_Dr=o(" \u2014 "),_re=a("a"),bDr=o("TFFlaubertWithLMHeadModel"),vDr=o(" (FlauBERT model)"),FDr=l(),b0=a("li"),c7e=a("strong"),TDr=o("funnel"),MDr=o(" \u2014 "),bre=a("a"),EDr=o("TFFunnelForPreTraining"),CDr=o(" (Funnel Transformer model)"),wDr=l(),v0=a("li"),m7e=a("strong"),ADr=o("gpt2"),LDr=o(" \u2014 "),vre=a("a"),yDr=o("TFGPT2LMHeadModel"),xDr=o(" (OpenAI GPT-2 model)"),$Dr=l(),F0=a("li"),f7e=a("strong"),kDr=o("layoutlm"),SDr=o(" \u2014 "),Fre=a("a"),RDr=o("TFLayoutLMForMaskedLM"),PDr=o(" (LayoutLM model)"),BDr=l(),T0=a("li"),g7e=a("strong"),IDr=o("lxmert"),NDr=o(" \u2014 "),Tre=a("a"),qDr=o("TFLxmertForPreTraining"),jDr=o(" (LXMERT model)"),DDr=l(),M0=a("li"),h7e=a("strong"),GDr=o("mobilebert"),ODr=o(" \u2014 "),Mre=a("a"),VDr=o("TFMobileBertForPreTraining"),XDr=o(" (MobileBERT model)"),zDr=l(),E0=a("li"),u7e=a("strong"),QDr=o("mpnet"),WDr=o(" \u2014 "),Ere=a("a"),UDr=o("TFMPNetForMaskedLM"),HDr=o(" (MPNet model)"),JDr=l(),C0=a("li"),p7e=a("strong"),YDr=o("openai-gpt"),ZDr=o(" \u2014 "),Cre=a("a"),KDr=o("TFOpenAIGPTLMHeadModel"),eGr=o(" (OpenAI GPT model)"),oGr=l(),w0=a("li"),_7e=a("strong"),rGr=o("roberta"),tGr=o(" \u2014 "),wre=a("a"),aGr=o("TFRobertaForMaskedLM"),nGr=o(" (RoBERTa model)"),sGr=l(),A0=a("li"),b7e=a("strong"),lGr=o("t5"),iGr=o(" \u2014 "),Are=a("a"),dGr=o("TFT5ForConditionalGeneration"),cGr=o(" (T5 model)"),mGr=l(),L0=a("li"),v7e=a("strong"),fGr=o("tapas"),gGr=o(" \u2014 "),Lre=a("a"),hGr=o("TFTapasForMaskedLM"),uGr=o(" (TAPAS model)"),pGr=l(),y0=a("li"),F7e=a("strong"),_Gr=o("transfo-xl"),bGr=o(" \u2014 "),yre=a("a"),vGr=o("TFTransfoXLLMHeadModel"),FGr=o(" (Transformer-XL model)"),TGr=l(),x0=a("li"),T7e=a("strong"),MGr=o("vit_mae"),EGr=o(" \u2014 "),xre=a("a"),CGr=o("TFViTMAEForPreTraining"),wGr=o(" (ViTMAE model)"),AGr=l(),$0=a("li"),M7e=a("strong"),LGr=o("xlm"),yGr=o(" \u2014 "),$re=a("a"),xGr=o("TFXLMWithLMHeadModel"),$Gr=o(" (XLM model)"),kGr=l(),k0=a("li"),E7e=a("strong"),SGr=o("xlm-roberta"),RGr=o(" \u2014 "),kre=a("a"),PGr=o("TFXLMRobertaForMaskedLM"),BGr=o(" (XLM-RoBERTa model)"),IGr=l(),S0=a("li"),C7e=a("strong"),NGr=o("xlnet"),qGr=o(" \u2014 "),Sre=a("a"),jGr=o("TFXLNetLMHeadModel"),DGr=o(" (XLNet model)"),GGr=l(),F(R0.$$.fragment),Gro=l(),am=a("h2"),P0=a("a"),w7e=a("span"),F(jS.$$.fragment),OGr=l(),A7e=a("span"),VGr=o("TFAutoModelForCausalLM"),Oro=l(),cr=a("div"),F(DS.$$.fragment),XGr=l(),nm=a("p"),zGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Rre=a("a"),QGr=o("from_pretrained()"),WGr=o(" class method or the "),Pre=a("a"),UGr=o("from_config()"),HGr=o(` class
method.`),JGr=l(),GS=a("p"),YGr=o("This class cannot be instantiated directly using "),L7e=a("code"),ZGr=o("__init__()"),KGr=o(" (throws an error)."),eOr=l(),Ht=a("div"),F(OS.$$.fragment),oOr=l(),y7e=a("p"),rOr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),tOr=l(),sm=a("p"),aOr=o(`Note:
Loading a model from its configuration file does `),x7e=a("strong"),nOr=o("not"),sOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bre=a("a"),lOr=o("from_pretrained()"),iOr=o(" to load the model weights."),dOr=l(),F(B0.$$.fragment),cOr=l(),Dr=a("div"),F(VS.$$.fragment),mOr=l(),$7e=a("p"),fOr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),gOr=l(),Sn=a("p"),hOr=o("The model class to instantiate is selected based on the "),k7e=a("code"),uOr=o("model_type"),pOr=o(` property of the config object (either
passed as an argument or loaded from `),S7e=a("code"),_Or=o("pretrained_model_name_or_path"),bOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R7e=a("code"),vOr=o("pretrained_model_name_or_path"),FOr=o(":"),TOr=l(),Me=a("ul"),I0=a("li"),P7e=a("strong"),MOr=o("bert"),EOr=o(" \u2014 "),Ire=a("a"),COr=o("TFBertLMHeadModel"),wOr=o(" (BERT model)"),AOr=l(),N0=a("li"),B7e=a("strong"),LOr=o("camembert"),yOr=o(" \u2014 "),Nre=a("a"),xOr=o("TFCamembertForCausalLM"),$Or=o(" (CamemBERT model)"),kOr=l(),q0=a("li"),I7e=a("strong"),SOr=o("ctrl"),ROr=o(" \u2014 "),qre=a("a"),POr=o("TFCTRLLMHeadModel"),BOr=o(" (CTRL model)"),IOr=l(),j0=a("li"),N7e=a("strong"),NOr=o("gpt2"),qOr=o(" \u2014 "),jre=a("a"),jOr=o("TFGPT2LMHeadModel"),DOr=o(" (OpenAI GPT-2 model)"),GOr=l(),D0=a("li"),q7e=a("strong"),OOr=o("gptj"),VOr=o(" \u2014 "),Dre=a("a"),XOr=o("TFGPTJForCausalLM"),zOr=o(" (GPT-J model)"),QOr=l(),G0=a("li"),j7e=a("strong"),WOr=o("openai-gpt"),UOr=o(" \u2014 "),Gre=a("a"),HOr=o("TFOpenAIGPTLMHeadModel"),JOr=o(" (OpenAI GPT model)"),YOr=l(),O0=a("li"),D7e=a("strong"),ZOr=o("opt"),KOr=o(" \u2014 "),Ore=a("a"),eVr=o("TFOPTForCausalLM"),oVr=o(" (OPT model)"),rVr=l(),V0=a("li"),G7e=a("strong"),tVr=o("rembert"),aVr=o(" \u2014 "),Vre=a("a"),nVr=o("TFRemBertForCausalLM"),sVr=o(" (RemBERT model)"),lVr=l(),X0=a("li"),O7e=a("strong"),iVr=o("roberta"),dVr=o(" \u2014 "),Xre=a("a"),cVr=o("TFRobertaForCausalLM"),mVr=o(" (RoBERTa model)"),fVr=l(),z0=a("li"),V7e=a("strong"),gVr=o("roformer"),hVr=o(" \u2014 "),zre=a("a"),uVr=o("TFRoFormerForCausalLM"),pVr=o(" (RoFormer model)"),_Vr=l(),Q0=a("li"),X7e=a("strong"),bVr=o("transfo-xl"),vVr=o(" \u2014 "),Qre=a("a"),FVr=o("TFTransfoXLLMHeadModel"),TVr=o(" (Transformer-XL model)"),MVr=l(),W0=a("li"),z7e=a("strong"),EVr=o("xglm"),CVr=o(" \u2014 "),Wre=a("a"),wVr=o("TFXGLMForCausalLM"),AVr=o(" (XGLM model)"),LVr=l(),U0=a("li"),Q7e=a("strong"),yVr=o("xlm"),xVr=o(" \u2014 "),Ure=a("a"),$Vr=o("TFXLMWithLMHeadModel"),kVr=o(" (XLM model)"),SVr=l(),H0=a("li"),W7e=a("strong"),RVr=o("xlnet"),PVr=o(" \u2014 "),Hre=a("a"),BVr=o("TFXLNetLMHeadModel"),IVr=o(" (XLNet model)"),NVr=l(),F(J0.$$.fragment),Vro=l(),lm=a("h2"),Y0=a("a"),U7e=a("span"),F(XS.$$.fragment),qVr=l(),H7e=a("span"),jVr=o("TFAutoModelForImageClassification"),Xro=l(),mr=a("div"),F(zS.$$.fragment),DVr=l(),im=a("p"),GVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jre=a("a"),OVr=o("from_pretrained()"),VVr=o(" class method or the "),Yre=a("a"),XVr=o("from_config()"),zVr=o(` class
method.`),QVr=l(),QS=a("p"),WVr=o("This class cannot be instantiated directly using "),J7e=a("code"),UVr=o("__init__()"),HVr=o(" (throws an error)."),JVr=l(),Jt=a("div"),F(WS.$$.fragment),YVr=l(),Y7e=a("p"),ZVr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),KVr=l(),dm=a("p"),eXr=o(`Note:
Loading a model from its configuration file does `),Z7e=a("strong"),oXr=o("not"),rXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=a("a"),tXr=o("from_pretrained()"),aXr=o(" to load the model weights."),nXr=l(),F(Z0.$$.fragment),sXr=l(),Gr=a("div"),F(US.$$.fragment),lXr=l(),K7e=a("p"),iXr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dXr=l(),Rn=a("p"),cXr=o("The model class to instantiate is selected based on the "),eLe=a("code"),mXr=o("model_type"),fXr=o(` property of the config object (either
passed as an argument or loaded from `),oLe=a("code"),gXr=o("pretrained_model_name_or_path"),hXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rLe=a("code"),uXr=o("pretrained_model_name_or_path"),pXr=o(":"),_Xr=l(),ye=a("ul"),K0=a("li"),tLe=a("strong"),bXr=o("convnext"),vXr=o(" \u2014 "),Kre=a("a"),FXr=o("TFConvNextForImageClassification"),TXr=o(" (ConvNeXT model)"),MXr=l(),ew=a("li"),aLe=a("strong"),EXr=o("cvt"),CXr=o(" \u2014 "),ete=a("a"),wXr=o("TFCvtForImageClassification"),AXr=o(" (CvT model)"),LXr=l(),ow=a("li"),nLe=a("strong"),yXr=o("data2vec-vision"),xXr=o(" \u2014 "),ote=a("a"),$Xr=o("TFData2VecVisionForImageClassification"),kXr=o(" (Data2VecVision model)"),SXr=l(),Al=a("li"),sLe=a("strong"),RXr=o("deit"),PXr=o(" \u2014 "),rte=a("a"),BXr=o("TFDeiTForImageClassification"),IXr=o(" or "),tte=a("a"),NXr=o("TFDeiTForImageClassificationWithTeacher"),qXr=o(" (DeiT model)"),jXr=l(),rw=a("li"),lLe=a("strong"),DXr=o("mobilevit"),GXr=o(" \u2014 "),ate=a("a"),OXr=o("TFMobileViTForImageClassification"),VXr=o(" (MobileViT model)"),XXr=l(),tw=a("li"),iLe=a("strong"),zXr=o("regnet"),QXr=o(" \u2014 "),nte=a("a"),WXr=o("TFRegNetForImageClassification"),UXr=o(" (RegNet model)"),HXr=l(),aw=a("li"),dLe=a("strong"),JXr=o("resnet"),YXr=o(" \u2014 "),ste=a("a"),ZXr=o("TFResNetForImageClassification"),KXr=o(" (ResNet model)"),ezr=l(),nw=a("li"),cLe=a("strong"),ozr=o("segformer"),rzr=o(" \u2014 "),lte=a("a"),tzr=o("TFSegformerForImageClassification"),azr=o(" (SegFormer model)"),nzr=l(),sw=a("li"),mLe=a("strong"),szr=o("swin"),lzr=o(" \u2014 "),ite=a("a"),izr=o("TFSwinForImageClassification"),dzr=o(" (Swin Transformer model)"),czr=l(),lw=a("li"),fLe=a("strong"),mzr=o("vit"),fzr=o(" \u2014 "),dte=a("a"),gzr=o("TFViTForImageClassification"),hzr=o(" (ViT model)"),uzr=l(),F(iw.$$.fragment),zro=l(),cm=a("h2"),dw=a("a"),gLe=a("span"),F(HS.$$.fragment),pzr=l(),hLe=a("span"),_zr=o("TFAutoModelForSemanticSegmentation"),Qro=l(),fr=a("div"),F(JS.$$.fragment),bzr=l(),mm=a("p"),vzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),cte=a("a"),Fzr=o("from_pretrained()"),Tzr=o(" class method or the "),mte=a("a"),Mzr=o("from_config()"),Ezr=o(` class
method.`),Czr=l(),YS=a("p"),wzr=o("This class cannot be instantiated directly using "),uLe=a("code"),Azr=o("__init__()"),Lzr=o(" (throws an error)."),yzr=l(),Yt=a("div"),F(ZS.$$.fragment),xzr=l(),pLe=a("p"),$zr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),kzr=l(),fm=a("p"),Szr=o(`Note:
Loading a model from its configuration file does `),_Le=a("strong"),Rzr=o("not"),Pzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fte=a("a"),Bzr=o("from_pretrained()"),Izr=o(" to load the model weights."),Nzr=l(),F(cw.$$.fragment),qzr=l(),Or=a("div"),F(KS.$$.fragment),jzr=l(),bLe=a("p"),Dzr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Gzr=l(),Pn=a("p"),Ozr=o("The model class to instantiate is selected based on the "),vLe=a("code"),Vzr=o("model_type"),Xzr=o(` property of the config object (either
passed as an argument or loaded from `),FLe=a("code"),zzr=o("pretrained_model_name_or_path"),Qzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TLe=a("code"),Wzr=o("pretrained_model_name_or_path"),Uzr=o(":"),Hzr=l(),gm=a("ul"),mw=a("li"),MLe=a("strong"),Jzr=o("data2vec-vision"),Yzr=o(" \u2014 "),gte=a("a"),Zzr=o("TFData2VecVisionForSemanticSegmentation"),Kzr=o(" (Data2VecVision model)"),eQr=l(),fw=a("li"),ELe=a("strong"),oQr=o("mobilevit"),rQr=o(" \u2014 "),hte=a("a"),tQr=o("TFMobileViTForSemanticSegmentation"),aQr=o(" (MobileViT model)"),nQr=l(),gw=a("li"),CLe=a("strong"),sQr=o("segformer"),lQr=o(" \u2014 "),ute=a("a"),iQr=o("TFSegformerForSemanticSegmentation"),dQr=o(" (SegFormer model)"),cQr=l(),F(hw.$$.fragment),Wro=l(),hm=a("h2"),uw=a("a"),wLe=a("span"),F(eR.$$.fragment),mQr=l(),ALe=a("span"),fQr=o("TFAutoModelForMaskedLM"),Uro=l(),gr=a("div"),F(oR.$$.fragment),gQr=l(),um=a("p"),hQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pte=a("a"),uQr=o("from_pretrained()"),pQr=o(" class method or the "),_te=a("a"),_Qr=o("from_config()"),bQr=o(` class
method.`),vQr=l(),rR=a("p"),FQr=o("This class cannot be instantiated directly using "),LLe=a("code"),TQr=o("__init__()"),MQr=o(" (throws an error)."),EQr=l(),Zt=a("div"),F(tR.$$.fragment),CQr=l(),yLe=a("p"),wQr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),AQr=l(),pm=a("p"),LQr=o(`Note:
Loading a model from its configuration file does `),xLe=a("strong"),yQr=o("not"),xQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=a("a"),$Qr=o("from_pretrained()"),kQr=o(" to load the model weights."),SQr=l(),F(pw.$$.fragment),RQr=l(),Vr=a("div"),F(aR.$$.fragment),PQr=l(),$Le=a("p"),BQr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),IQr=l(),Bn=a("p"),NQr=o("The model class to instantiate is selected based on the "),kLe=a("code"),qQr=o("model_type"),jQr=o(` property of the config object (either
passed as an argument or loaded from `),SLe=a("code"),DQr=o("pretrained_model_name_or_path"),GQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RLe=a("code"),OQr=o("pretrained_model_name_or_path"),VQr=o(":"),XQr=l(),ge=a("ul"),_w=a("li"),PLe=a("strong"),zQr=o("albert"),QQr=o(" \u2014 "),vte=a("a"),WQr=o("TFAlbertForMaskedLM"),UQr=o(" (ALBERT model)"),HQr=l(),bw=a("li"),BLe=a("strong"),JQr=o("bert"),YQr=o(" \u2014 "),Fte=a("a"),ZQr=o("TFBertForMaskedLM"),KQr=o(" (BERT model)"),eWr=l(),vw=a("li"),ILe=a("strong"),oWr=o("camembert"),rWr=o(" \u2014 "),Tte=a("a"),tWr=o("TFCamembertForMaskedLM"),aWr=o(" (CamemBERT model)"),nWr=l(),Fw=a("li"),NLe=a("strong"),sWr=o("convbert"),lWr=o(" \u2014 "),Mte=a("a"),iWr=o("TFConvBertForMaskedLM"),dWr=o(" (ConvBERT model)"),cWr=l(),Tw=a("li"),qLe=a("strong"),mWr=o("deberta"),fWr=o(" \u2014 "),Ete=a("a"),gWr=o("TFDebertaForMaskedLM"),hWr=o(" (DeBERTa model)"),uWr=l(),Mw=a("li"),jLe=a("strong"),pWr=o("deberta-v2"),_Wr=o(" \u2014 "),Cte=a("a"),bWr=o("TFDebertaV2ForMaskedLM"),vWr=o(" (DeBERTa-v2 model)"),FWr=l(),Ew=a("li"),DLe=a("strong"),TWr=o("distilbert"),MWr=o(" \u2014 "),wte=a("a"),EWr=o("TFDistilBertForMaskedLM"),CWr=o(" (DistilBERT model)"),wWr=l(),Cw=a("li"),GLe=a("strong"),AWr=o("electra"),LWr=o(" \u2014 "),Ate=a("a"),yWr=o("TFElectraForMaskedLM"),xWr=o(" (ELECTRA model)"),$Wr=l(),ww=a("li"),OLe=a("strong"),kWr=o("flaubert"),SWr=o(" \u2014 "),Lte=a("a"),RWr=o("TFFlaubertWithLMHeadModel"),PWr=o(" (FlauBERT model)"),BWr=l(),Aw=a("li"),VLe=a("strong"),IWr=o("funnel"),NWr=o(" \u2014 "),yte=a("a"),qWr=o("TFFunnelForMaskedLM"),jWr=o(" (Funnel Transformer model)"),DWr=l(),Lw=a("li"),XLe=a("strong"),GWr=o("layoutlm"),OWr=o(" \u2014 "),xte=a("a"),VWr=o("TFLayoutLMForMaskedLM"),XWr=o(" (LayoutLM model)"),zWr=l(),yw=a("li"),zLe=a("strong"),QWr=o("longformer"),WWr=o(" \u2014 "),$te=a("a"),UWr=o("TFLongformerForMaskedLM"),HWr=o(" (Longformer model)"),JWr=l(),xw=a("li"),QLe=a("strong"),YWr=o("mobilebert"),ZWr=o(" \u2014 "),kte=a("a"),KWr=o("TFMobileBertForMaskedLM"),eUr=o(" (MobileBERT model)"),oUr=l(),$w=a("li"),WLe=a("strong"),rUr=o("mpnet"),tUr=o(" \u2014 "),Ste=a("a"),aUr=o("TFMPNetForMaskedLM"),nUr=o(" (MPNet model)"),sUr=l(),kw=a("li"),ULe=a("strong"),lUr=o("rembert"),iUr=o(" \u2014 "),Rte=a("a"),dUr=o("TFRemBertForMaskedLM"),cUr=o(" (RemBERT model)"),mUr=l(),Sw=a("li"),HLe=a("strong"),fUr=o("roberta"),gUr=o(" \u2014 "),Pte=a("a"),hUr=o("TFRobertaForMaskedLM"),uUr=o(" (RoBERTa model)"),pUr=l(),Rw=a("li"),JLe=a("strong"),_Ur=o("roformer"),bUr=o(" \u2014 "),Bte=a("a"),vUr=o("TFRoFormerForMaskedLM"),FUr=o(" (RoFormer model)"),TUr=l(),Pw=a("li"),YLe=a("strong"),MUr=o("tapas"),EUr=o(" \u2014 "),Ite=a("a"),CUr=o("TFTapasForMaskedLM"),wUr=o(" (TAPAS model)"),AUr=l(),Bw=a("li"),ZLe=a("strong"),LUr=o("xlm"),yUr=o(" \u2014 "),Nte=a("a"),xUr=o("TFXLMWithLMHeadModel"),$Ur=o(" (XLM model)"),kUr=l(),Iw=a("li"),KLe=a("strong"),SUr=o("xlm-roberta"),RUr=o(" \u2014 "),qte=a("a"),PUr=o("TFXLMRobertaForMaskedLM"),BUr=o(" (XLM-RoBERTa model)"),IUr=l(),F(Nw.$$.fragment),Hro=l(),_m=a("h2"),qw=a("a"),e8e=a("span"),F(nR.$$.fragment),NUr=l(),o8e=a("span"),qUr=o("TFAutoModelForSeq2SeqLM"),Jro=l(),hr=a("div"),F(sR.$$.fragment),jUr=l(),bm=a("p"),DUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),jte=a("a"),GUr=o("from_pretrained()"),OUr=o(" class method or the "),Dte=a("a"),VUr=o("from_config()"),XUr=o(` class
method.`),zUr=l(),lR=a("p"),QUr=o("This class cannot be instantiated directly using "),r8e=a("code"),WUr=o("__init__()"),UUr=o(" (throws an error)."),HUr=l(),Kt=a("div"),F(iR.$$.fragment),JUr=l(),t8e=a("p"),YUr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ZUr=l(),vm=a("p"),KUr=o(`Note:
Loading a model from its configuration file does `),a8e=a("strong"),eHr=o("not"),oHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("a"),rHr=o("from_pretrained()"),tHr=o(" to load the model weights."),aHr=l(),F(jw.$$.fragment),nHr=l(),Xr=a("div"),F(dR.$$.fragment),sHr=l(),n8e=a("p"),lHr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),iHr=l(),In=a("p"),dHr=o("The model class to instantiate is selected based on the "),s8e=a("code"),cHr=o("model_type"),mHr=o(` property of the config object (either
passed as an argument or loaded from `),l8e=a("code"),fHr=o("pretrained_model_name_or_path"),gHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i8e=a("code"),hHr=o("pretrained_model_name_or_path"),uHr=o(":"),pHr=l(),xe=a("ul"),Dw=a("li"),d8e=a("strong"),_Hr=o("bart"),bHr=o(" \u2014 "),Ote=a("a"),vHr=o("TFBartForConditionalGeneration"),FHr=o(" (BART model)"),THr=l(),Gw=a("li"),c8e=a("strong"),MHr=o("blenderbot"),EHr=o(" \u2014 "),Vte=a("a"),CHr=o("TFBlenderbotForConditionalGeneration"),wHr=o(" (Blenderbot model)"),AHr=l(),Ow=a("li"),m8e=a("strong"),LHr=o("blenderbot-small"),yHr=o(" \u2014 "),Xte=a("a"),xHr=o("TFBlenderbotSmallForConditionalGeneration"),$Hr=o(" (BlenderbotSmall model)"),kHr=l(),Vw=a("li"),f8e=a("strong"),SHr=o("encoder-decoder"),RHr=o(" \u2014 "),zte=a("a"),PHr=o("TFEncoderDecoderModel"),BHr=o(" (Encoder decoder model)"),IHr=l(),Xw=a("li"),g8e=a("strong"),NHr=o("led"),qHr=o(" \u2014 "),Qte=a("a"),jHr=o("TFLEDForConditionalGeneration"),DHr=o(" (LED model)"),GHr=l(),zw=a("li"),h8e=a("strong"),OHr=o("marian"),VHr=o(" \u2014 "),Wte=a("a"),XHr=o("TFMarianMTModel"),zHr=o(" (Marian model)"),QHr=l(),Qw=a("li"),u8e=a("strong"),WHr=o("mbart"),UHr=o(" \u2014 "),Ute=a("a"),HHr=o("TFMBartForConditionalGeneration"),JHr=o(" (mBART model)"),YHr=l(),Ww=a("li"),p8e=a("strong"),ZHr=o("mt5"),KHr=o(" \u2014 "),Hte=a("a"),eJr=o("TFMT5ForConditionalGeneration"),oJr=o(" (MT5 model)"),rJr=l(),Uw=a("li"),_8e=a("strong"),tJr=o("pegasus"),aJr=o(" \u2014 "),Jte=a("a"),nJr=o("TFPegasusForConditionalGeneration"),sJr=o(" (Pegasus model)"),lJr=l(),Hw=a("li"),b8e=a("strong"),iJr=o("t5"),dJr=o(" \u2014 "),Yte=a("a"),cJr=o("TFT5ForConditionalGeneration"),mJr=o(" (T5 model)"),fJr=l(),F(Jw.$$.fragment),Yro=l(),Fm=a("h2"),Yw=a("a"),v8e=a("span"),F(cR.$$.fragment),gJr=l(),F8e=a("span"),hJr=o("TFAutoModelForSequenceClassification"),Zro=l(),ur=a("div"),F(mR.$$.fragment),uJr=l(),Tm=a("p"),pJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Zte=a("a"),_Jr=o("from_pretrained()"),bJr=o(" class method or the "),Kte=a("a"),vJr=o("from_config()"),FJr=o(` class
method.`),TJr=l(),fR=a("p"),MJr=o("This class cannot be instantiated directly using "),T8e=a("code"),EJr=o("__init__()"),CJr=o(" (throws an error)."),wJr=l(),ea=a("div"),F(gR.$$.fragment),AJr=l(),M8e=a("p"),LJr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yJr=l(),Mm=a("p"),xJr=o(`Note:
Loading a model from its configuration file does `),E8e=a("strong"),$Jr=o("not"),kJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eae=a("a"),SJr=o("from_pretrained()"),RJr=o(" to load the model weights."),PJr=l(),F(Zw.$$.fragment),BJr=l(),zr=a("div"),F(hR.$$.fragment),IJr=l(),C8e=a("p"),NJr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qJr=l(),Nn=a("p"),jJr=o("The model class to instantiate is selected based on the "),w8e=a("code"),DJr=o("model_type"),GJr=o(` property of the config object (either
passed as an argument or loaded from `),A8e=a("code"),OJr=o("pretrained_model_name_or_path"),VJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L8e=a("code"),XJr=o("pretrained_model_name_or_path"),zJr=o(":"),QJr=l(),re=a("ul"),Kw=a("li"),y8e=a("strong"),WJr=o("albert"),UJr=o(" \u2014 "),oae=a("a"),HJr=o("TFAlbertForSequenceClassification"),JJr=o(" (ALBERT model)"),YJr=l(),eA=a("li"),x8e=a("strong"),ZJr=o("bert"),KJr=o(" \u2014 "),rae=a("a"),eYr=o("TFBertForSequenceClassification"),oYr=o(" (BERT model)"),rYr=l(),oA=a("li"),$8e=a("strong"),tYr=o("camembert"),aYr=o(" \u2014 "),tae=a("a"),nYr=o("TFCamembertForSequenceClassification"),sYr=o(" (CamemBERT model)"),lYr=l(),rA=a("li"),k8e=a("strong"),iYr=o("convbert"),dYr=o(" \u2014 "),aae=a("a"),cYr=o("TFConvBertForSequenceClassification"),mYr=o(" (ConvBERT model)"),fYr=l(),tA=a("li"),S8e=a("strong"),gYr=o("ctrl"),hYr=o(" \u2014 "),nae=a("a"),uYr=o("TFCTRLForSequenceClassification"),pYr=o(" (CTRL model)"),_Yr=l(),aA=a("li"),R8e=a("strong"),bYr=o("deberta"),vYr=o(" \u2014 "),sae=a("a"),FYr=o("TFDebertaForSequenceClassification"),TYr=o(" (DeBERTa model)"),MYr=l(),nA=a("li"),P8e=a("strong"),EYr=o("deberta-v2"),CYr=o(" \u2014 "),lae=a("a"),wYr=o("TFDebertaV2ForSequenceClassification"),AYr=o(" (DeBERTa-v2 model)"),LYr=l(),sA=a("li"),B8e=a("strong"),yYr=o("distilbert"),xYr=o(" \u2014 "),iae=a("a"),$Yr=o("TFDistilBertForSequenceClassification"),kYr=o(" (DistilBERT model)"),SYr=l(),lA=a("li"),I8e=a("strong"),RYr=o("electra"),PYr=o(" \u2014 "),dae=a("a"),BYr=o("TFElectraForSequenceClassification"),IYr=o(" (ELECTRA model)"),NYr=l(),iA=a("li"),N8e=a("strong"),qYr=o("flaubert"),jYr=o(" \u2014 "),cae=a("a"),DYr=o("TFFlaubertForSequenceClassification"),GYr=o(" (FlauBERT model)"),OYr=l(),dA=a("li"),q8e=a("strong"),VYr=o("funnel"),XYr=o(" \u2014 "),mae=a("a"),zYr=o("TFFunnelForSequenceClassification"),QYr=o(" (Funnel Transformer model)"),WYr=l(),cA=a("li"),j8e=a("strong"),UYr=o("gpt2"),HYr=o(" \u2014 "),fae=a("a"),JYr=o("TFGPT2ForSequenceClassification"),YYr=o(" (OpenAI GPT-2 model)"),ZYr=l(),mA=a("li"),D8e=a("strong"),KYr=o("gptj"),eZr=o(" \u2014 "),gae=a("a"),oZr=o("TFGPTJForSequenceClassification"),rZr=o(" (GPT-J model)"),tZr=l(),fA=a("li"),G8e=a("strong"),aZr=o("layoutlm"),nZr=o(" \u2014 "),hae=a("a"),sZr=o("TFLayoutLMForSequenceClassification"),lZr=o(" (LayoutLM model)"),iZr=l(),gA=a("li"),O8e=a("strong"),dZr=o("layoutlmv3"),cZr=o(" \u2014 "),uae=a("a"),mZr=o("TFLayoutLMv3ForSequenceClassification"),fZr=o(" (LayoutLMv3 model)"),gZr=l(),hA=a("li"),V8e=a("strong"),hZr=o("longformer"),uZr=o(" \u2014 "),pae=a("a"),pZr=o("TFLongformerForSequenceClassification"),_Zr=o(" (Longformer model)"),bZr=l(),uA=a("li"),X8e=a("strong"),vZr=o("mobilebert"),FZr=o(" \u2014 "),_ae=a("a"),TZr=o("TFMobileBertForSequenceClassification"),MZr=o(" (MobileBERT model)"),EZr=l(),pA=a("li"),z8e=a("strong"),CZr=o("mpnet"),wZr=o(" \u2014 "),bae=a("a"),AZr=o("TFMPNetForSequenceClassification"),LZr=o(" (MPNet model)"),yZr=l(),_A=a("li"),Q8e=a("strong"),xZr=o("openai-gpt"),$Zr=o(" \u2014 "),vae=a("a"),kZr=o("TFOpenAIGPTForSequenceClassification"),SZr=o(" (OpenAI GPT model)"),RZr=l(),bA=a("li"),W8e=a("strong"),PZr=o("rembert"),BZr=o(" \u2014 "),Fae=a("a"),IZr=o("TFRemBertForSequenceClassification"),NZr=o(" (RemBERT model)"),qZr=l(),vA=a("li"),U8e=a("strong"),jZr=o("roberta"),DZr=o(" \u2014 "),Tae=a("a"),GZr=o("TFRobertaForSequenceClassification"),OZr=o(" (RoBERTa model)"),VZr=l(),FA=a("li"),H8e=a("strong"),XZr=o("roformer"),zZr=o(" \u2014 "),Mae=a("a"),QZr=o("TFRoFormerForSequenceClassification"),WZr=o(" (RoFormer model)"),UZr=l(),TA=a("li"),J8e=a("strong"),HZr=o("tapas"),JZr=o(" \u2014 "),Eae=a("a"),YZr=o("TFTapasForSequenceClassification"),ZZr=o(" (TAPAS model)"),KZr=l(),MA=a("li"),Y8e=a("strong"),eKr=o("transfo-xl"),oKr=o(" \u2014 "),Cae=a("a"),rKr=o("TFTransfoXLForSequenceClassification"),tKr=o(" (Transformer-XL model)"),aKr=l(),EA=a("li"),Z8e=a("strong"),nKr=o("xlm"),sKr=o(" \u2014 "),wae=a("a"),lKr=o("TFXLMForSequenceClassification"),iKr=o(" (XLM model)"),dKr=l(),CA=a("li"),K8e=a("strong"),cKr=o("xlm-roberta"),mKr=o(" \u2014 "),Aae=a("a"),fKr=o("TFXLMRobertaForSequenceClassification"),gKr=o(" (XLM-RoBERTa model)"),hKr=l(),wA=a("li"),eye=a("strong"),uKr=o("xlnet"),pKr=o(" \u2014 "),Lae=a("a"),_Kr=o("TFXLNetForSequenceClassification"),bKr=o(" (XLNet model)"),vKr=l(),F(AA.$$.fragment),Kro=l(),Em=a("h2"),LA=a("a"),oye=a("span"),F(uR.$$.fragment),FKr=l(),rye=a("span"),TKr=o("TFAutoModelForMultipleChoice"),eto=l(),pr=a("div"),F(pR.$$.fragment),MKr=l(),Cm=a("p"),EKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),yae=a("a"),CKr=o("from_pretrained()"),wKr=o(" class method or the "),xae=a("a"),AKr=o("from_config()"),LKr=o(` class
method.`),yKr=l(),_R=a("p"),xKr=o("This class cannot be instantiated directly using "),tye=a("code"),$Kr=o("__init__()"),kKr=o(" (throws an error)."),SKr=l(),oa=a("div"),F(bR.$$.fragment),RKr=l(),aye=a("p"),PKr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),BKr=l(),wm=a("p"),IKr=o(`Note:
Loading a model from its configuration file does `),nye=a("strong"),NKr=o("not"),qKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ae=a("a"),jKr=o("from_pretrained()"),DKr=o(" to load the model weights."),GKr=l(),F(yA.$$.fragment),OKr=l(),Qr=a("div"),F(vR.$$.fragment),VKr=l(),sye=a("p"),XKr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),zKr=l(),qn=a("p"),QKr=o("The model class to instantiate is selected based on the "),lye=a("code"),WKr=o("model_type"),UKr=o(` property of the config object (either
passed as an argument or loaded from `),iye=a("code"),HKr=o("pretrained_model_name_or_path"),JKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dye=a("code"),YKr=o("pretrained_model_name_or_path"),ZKr=o(":"),KKr=l(),ve=a("ul"),xA=a("li"),cye=a("strong"),eet=o("albert"),oet=o(" \u2014 "),kae=a("a"),ret=o("TFAlbertForMultipleChoice"),tet=o(" (ALBERT model)"),aet=l(),$A=a("li"),mye=a("strong"),net=o("bert"),set=o(" \u2014 "),Sae=a("a"),iet=o("TFBertForMultipleChoice"),det=o(" (BERT model)"),cet=l(),kA=a("li"),fye=a("strong"),met=o("camembert"),fet=o(" \u2014 "),Rae=a("a"),get=o("TFCamembertForMultipleChoice"),het=o(" (CamemBERT model)"),uet=l(),SA=a("li"),gye=a("strong"),pet=o("convbert"),_et=o(" \u2014 "),Pae=a("a"),bet=o("TFConvBertForMultipleChoice"),vet=o(" (ConvBERT model)"),Fet=l(),RA=a("li"),hye=a("strong"),Tet=o("distilbert"),Met=o(" \u2014 "),Bae=a("a"),Eet=o("TFDistilBertForMultipleChoice"),Cet=o(" (DistilBERT model)"),wet=l(),PA=a("li"),uye=a("strong"),Aet=o("electra"),Let=o(" \u2014 "),Iae=a("a"),yet=o("TFElectraForMultipleChoice"),xet=o(" (ELECTRA model)"),$et=l(),BA=a("li"),pye=a("strong"),ket=o("flaubert"),Set=o(" \u2014 "),Nae=a("a"),Ret=o("TFFlaubertForMultipleChoice"),Pet=o(" (FlauBERT model)"),Bet=l(),IA=a("li"),_ye=a("strong"),Iet=o("funnel"),Net=o(" \u2014 "),qae=a("a"),qet=o("TFFunnelForMultipleChoice"),jet=o(" (Funnel Transformer model)"),Det=l(),NA=a("li"),bye=a("strong"),Get=o("longformer"),Oet=o(" \u2014 "),jae=a("a"),Vet=o("TFLongformerForMultipleChoice"),Xet=o(" (Longformer model)"),zet=l(),qA=a("li"),vye=a("strong"),Qet=o("mobilebert"),Wet=o(" \u2014 "),Dae=a("a"),Uet=o("TFMobileBertForMultipleChoice"),Het=o(" (MobileBERT model)"),Jet=l(),jA=a("li"),Fye=a("strong"),Yet=o("mpnet"),Zet=o(" \u2014 "),Gae=a("a"),Ket=o("TFMPNetForMultipleChoice"),eot=o(" (MPNet model)"),oot=l(),DA=a("li"),Tye=a("strong"),rot=o("rembert"),tot=o(" \u2014 "),Oae=a("a"),aot=o("TFRemBertForMultipleChoice"),not=o(" (RemBERT model)"),sot=l(),GA=a("li"),Mye=a("strong"),lot=o("roberta"),iot=o(" \u2014 "),Vae=a("a"),dot=o("TFRobertaForMultipleChoice"),cot=o(" (RoBERTa model)"),mot=l(),OA=a("li"),Eye=a("strong"),fot=o("roformer"),got=o(" \u2014 "),Xae=a("a"),hot=o("TFRoFormerForMultipleChoice"),uot=o(" (RoFormer model)"),pot=l(),VA=a("li"),Cye=a("strong"),_ot=o("xlm"),bot=o(" \u2014 "),zae=a("a"),vot=o("TFXLMForMultipleChoice"),Fot=o(" (XLM model)"),Tot=l(),XA=a("li"),wye=a("strong"),Mot=o("xlm-roberta"),Eot=o(" \u2014 "),Qae=a("a"),Cot=o("TFXLMRobertaForMultipleChoice"),wot=o(" (XLM-RoBERTa model)"),Aot=l(),zA=a("li"),Aye=a("strong"),Lot=o("xlnet"),yot=o(" \u2014 "),Wae=a("a"),xot=o("TFXLNetForMultipleChoice"),$ot=o(" (XLNet model)"),kot=l(),F(QA.$$.fragment),oto=l(),Am=a("h2"),WA=a("a"),Lye=a("span"),F(FR.$$.fragment),Sot=l(),yye=a("span"),Rot=o("TFAutoModelForNextSentencePrediction"),rto=l(),_r=a("div"),F(TR.$$.fragment),Pot=l(),Lm=a("p"),Bot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Uae=a("a"),Iot=o("from_pretrained()"),Not=o(" class method or the "),Hae=a("a"),qot=o("from_config()"),jot=o(` class
method.`),Dot=l(),MR=a("p"),Got=o("This class cannot be instantiated directly using "),xye=a("code"),Oot=o("__init__()"),Vot=o(" (throws an error)."),Xot=l(),ra=a("div"),F(ER.$$.fragment),zot=l(),$ye=a("p"),Qot=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wot=l(),ym=a("p"),Uot=o(`Note:
Loading a model from its configuration file does `),kye=a("strong"),Hot=o("not"),Jot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jae=a("a"),Yot=o("from_pretrained()"),Zot=o(" to load the model weights."),Kot=l(),F(UA.$$.fragment),ert=l(),Wr=a("div"),F(CR.$$.fragment),ort=l(),Sye=a("p"),rrt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),trt=l(),jn=a("p"),art=o("The model class to instantiate is selected based on the "),Rye=a("code"),nrt=o("model_type"),srt=o(` property of the config object (either
passed as an argument or loaded from `),Pye=a("code"),lrt=o("pretrained_model_name_or_path"),irt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bye=a("code"),drt=o("pretrained_model_name_or_path"),crt=o(":"),mrt=l(),wR=a("ul"),HA=a("li"),Iye=a("strong"),frt=o("bert"),grt=o(" \u2014 "),Yae=a("a"),hrt=o("TFBertForNextSentencePrediction"),urt=o(" (BERT model)"),prt=l(),JA=a("li"),Nye=a("strong"),_rt=o("mobilebert"),brt=o(" \u2014 "),Zae=a("a"),vrt=o("TFMobileBertForNextSentencePrediction"),Frt=o(" (MobileBERT model)"),Trt=l(),F(YA.$$.fragment),tto=l(),xm=a("h2"),ZA=a("a"),qye=a("span"),F(AR.$$.fragment),Mrt=l(),jye=a("span"),Ert=o("TFAutoModelForTableQuestionAnswering"),ato=l(),br=a("div"),F(LR.$$.fragment),Crt=l(),$m=a("p"),wrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kae=a("a"),Art=o("from_pretrained()"),Lrt=o(" class method or the "),ene=a("a"),yrt=o("from_config()"),xrt=o(` class
method.`),$rt=l(),yR=a("p"),krt=o("This class cannot be instantiated directly using "),Dye=a("code"),Srt=o("__init__()"),Rrt=o(" (throws an error)."),Prt=l(),ta=a("div"),F(xR.$$.fragment),Brt=l(),Gye=a("p"),Irt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Nrt=l(),km=a("p"),qrt=o(`Note:
Loading a model from its configuration file does `),Oye=a("strong"),jrt=o("not"),Drt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),one=a("a"),Grt=o("from_pretrained()"),Ort=o(" to load the model weights."),Vrt=l(),F(KA.$$.fragment),Xrt=l(),Ur=a("div"),F($R.$$.fragment),zrt=l(),Vye=a("p"),Qrt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Wrt=l(),Dn=a("p"),Urt=o("The model class to instantiate is selected based on the "),Xye=a("code"),Hrt=o("model_type"),Jrt=o(` property of the config object (either
passed as an argument or loaded from `),zye=a("code"),Yrt=o("pretrained_model_name_or_path"),Zrt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qye=a("code"),Krt=o("pretrained_model_name_or_path"),ett=o(":"),ott=l(),Wye=a("ul"),e6=a("li"),Uye=a("strong"),rtt=o("tapas"),ttt=o(" \u2014 "),rne=a("a"),att=o("TFTapasForQuestionAnswering"),ntt=o(" (TAPAS model)"),stt=l(),F(o6.$$.fragment),nto=l(),Sm=a("h2"),r6=a("a"),Hye=a("span"),F(kR.$$.fragment),ltt=l(),Jye=a("span"),itt=o("TFAutoModelForDocumentQuestionAnswering"),sto=l(),vr=a("div"),F(SR.$$.fragment),dtt=l(),Rm=a("p"),ctt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),tne=a("a"),mtt=o("from_pretrained()"),ftt=o(" class method or the "),ane=a("a"),gtt=o("from_config()"),htt=o(` class
method.`),utt=l(),RR=a("p"),ptt=o("This class cannot be instantiated directly using "),Yye=a("code"),_tt=o("__init__()"),btt=o(" (throws an error)."),vtt=l(),aa=a("div"),F(PR.$$.fragment),Ftt=l(),Zye=a("p"),Ttt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Mtt=l(),Pm=a("p"),Ett=o(`Note:
Loading a model from its configuration file does `),Kye=a("strong"),Ctt=o("not"),wtt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nne=a("a"),Att=o("from_pretrained()"),Ltt=o(" to load the model weights."),ytt=l(),F(t6.$$.fragment),xtt=l(),Hr=a("div"),F(BR.$$.fragment),$tt=l(),e9e=a("p"),ktt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Stt=l(),Gn=a("p"),Rtt=o("The model class to instantiate is selected based on the "),o9e=a("code"),Ptt=o("model_type"),Btt=o(` property of the config object (either
passed as an argument or loaded from `),r9e=a("code"),Itt=o("pretrained_model_name_or_path"),Ntt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t9e=a("code"),qtt=o("pretrained_model_name_or_path"),jtt=o(":"),Dtt=l(),a9e=a("ul"),a6=a("li"),n9e=a("strong"),Gtt=o("layoutlm"),Ott=o(" \u2014 "),sne=a("a"),Vtt=o("TFLayoutLMForQuestionAnswering"),Xtt=o(" (LayoutLM model)"),ztt=l(),F(n6.$$.fragment),lto=l(),Bm=a("h2"),s6=a("a"),s9e=a("span"),F(IR.$$.fragment),Qtt=l(),l9e=a("span"),Wtt=o("TFAutoModelForTokenClassification"),ito=l(),Fr=a("div"),F(NR.$$.fragment),Utt=l(),Im=a("p"),Htt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),lne=a("a"),Jtt=o("from_pretrained()"),Ytt=o(" class method or the "),ine=a("a"),Ztt=o("from_config()"),Ktt=o(` class
method.`),eat=l(),qR=a("p"),oat=o("This class cannot be instantiated directly using "),i9e=a("code"),rat=o("__init__()"),tat=o(" (throws an error)."),aat=l(),na=a("div"),F(jR.$$.fragment),nat=l(),d9e=a("p"),sat=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),lat=l(),Nm=a("p"),iat=o(`Note:
Loading a model from its configuration file does `),c9e=a("strong"),dat=o("not"),cat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dne=a("a"),mat=o("from_pretrained()"),fat=o(" to load the model weights."),gat=l(),F(l6.$$.fragment),hat=l(),Jr=a("div"),F(DR.$$.fragment),uat=l(),m9e=a("p"),pat=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),_at=l(),On=a("p"),bat=o("The model class to instantiate is selected based on the "),f9e=a("code"),vat=o("model_type"),Fat=o(` property of the config object (either
passed as an argument or loaded from `),g9e=a("code"),Tat=o("pretrained_model_name_or_path"),Mat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h9e=a("code"),Eat=o("pretrained_model_name_or_path"),Cat=o(":"),wat=l(),ce=a("ul"),i6=a("li"),u9e=a("strong"),Aat=o("albert"),Lat=o(" \u2014 "),cne=a("a"),yat=o("TFAlbertForTokenClassification"),xat=o(" (ALBERT model)"),$at=l(),d6=a("li"),p9e=a("strong"),kat=o("bert"),Sat=o(" \u2014 "),mne=a("a"),Rat=o("TFBertForTokenClassification"),Pat=o(" (BERT model)"),Bat=l(),c6=a("li"),_9e=a("strong"),Iat=o("camembert"),Nat=o(" \u2014 "),fne=a("a"),qat=o("TFCamembertForTokenClassification"),jat=o(" (CamemBERT model)"),Dat=l(),m6=a("li"),b9e=a("strong"),Gat=o("convbert"),Oat=o(" \u2014 "),gne=a("a"),Vat=o("TFConvBertForTokenClassification"),Xat=o(" (ConvBERT model)"),zat=l(),f6=a("li"),v9e=a("strong"),Qat=o("deberta"),Wat=o(" \u2014 "),hne=a("a"),Uat=o("TFDebertaForTokenClassification"),Hat=o(" (DeBERTa model)"),Jat=l(),g6=a("li"),F9e=a("strong"),Yat=o("deberta-v2"),Zat=o(" \u2014 "),une=a("a"),Kat=o("TFDebertaV2ForTokenClassification"),ent=o(" (DeBERTa-v2 model)"),ont=l(),h6=a("li"),T9e=a("strong"),rnt=o("distilbert"),tnt=o(" \u2014 "),pne=a("a"),ant=o("TFDistilBertForTokenClassification"),nnt=o(" (DistilBERT model)"),snt=l(),u6=a("li"),M9e=a("strong"),lnt=o("electra"),int=o(" \u2014 "),_ne=a("a"),dnt=o("TFElectraForTokenClassification"),cnt=o(" (ELECTRA model)"),mnt=l(),p6=a("li"),E9e=a("strong"),fnt=o("flaubert"),gnt=o(" \u2014 "),bne=a("a"),hnt=o("TFFlaubertForTokenClassification"),unt=o(" (FlauBERT model)"),pnt=l(),_6=a("li"),C9e=a("strong"),_nt=o("funnel"),bnt=o(" \u2014 "),vne=a("a"),vnt=o("TFFunnelForTokenClassification"),Fnt=o(" (Funnel Transformer model)"),Tnt=l(),b6=a("li"),w9e=a("strong"),Mnt=o("layoutlm"),Ent=o(" \u2014 "),Fne=a("a"),Cnt=o("TFLayoutLMForTokenClassification"),wnt=o(" (LayoutLM model)"),Ant=l(),v6=a("li"),A9e=a("strong"),Lnt=o("layoutlmv3"),ynt=o(" \u2014 "),Tne=a("a"),xnt=o("TFLayoutLMv3ForTokenClassification"),$nt=o(" (LayoutLMv3 model)"),knt=l(),F6=a("li"),L9e=a("strong"),Snt=o("longformer"),Rnt=o(" \u2014 "),Mne=a("a"),Pnt=o("TFLongformerForTokenClassification"),Bnt=o(" (Longformer model)"),Int=l(),T6=a("li"),y9e=a("strong"),Nnt=o("mobilebert"),qnt=o(" \u2014 "),Ene=a("a"),jnt=o("TFMobileBertForTokenClassification"),Dnt=o(" (MobileBERT model)"),Gnt=l(),M6=a("li"),x9e=a("strong"),Ont=o("mpnet"),Vnt=o(" \u2014 "),Cne=a("a"),Xnt=o("TFMPNetForTokenClassification"),znt=o(" (MPNet model)"),Qnt=l(),E6=a("li"),$9e=a("strong"),Wnt=o("rembert"),Unt=o(" \u2014 "),wne=a("a"),Hnt=o("TFRemBertForTokenClassification"),Jnt=o(" (RemBERT model)"),Ynt=l(),C6=a("li"),k9e=a("strong"),Znt=o("roberta"),Knt=o(" \u2014 "),Ane=a("a"),est=o("TFRobertaForTokenClassification"),ost=o(" (RoBERTa model)"),rst=l(),w6=a("li"),S9e=a("strong"),tst=o("roformer"),ast=o(" \u2014 "),Lne=a("a"),nst=o("TFRoFormerForTokenClassification"),sst=o(" (RoFormer model)"),lst=l(),A6=a("li"),R9e=a("strong"),ist=o("xlm"),dst=o(" \u2014 "),yne=a("a"),cst=o("TFXLMForTokenClassification"),mst=o(" (XLM model)"),fst=l(),L6=a("li"),P9e=a("strong"),gst=o("xlm-roberta"),hst=o(" \u2014 "),xne=a("a"),ust=o("TFXLMRobertaForTokenClassification"),pst=o(" (XLM-RoBERTa model)"),_st=l(),y6=a("li"),B9e=a("strong"),bst=o("xlnet"),vst=o(" \u2014 "),$ne=a("a"),Fst=o("TFXLNetForTokenClassification"),Tst=o(" (XLNet model)"),Mst=l(),F(x6.$$.fragment),dto=l(),qm=a("h2"),$6=a("a"),I9e=a("span"),F(GR.$$.fragment),Est=l(),N9e=a("span"),Cst=o("TFAutoModelForQuestionAnswering"),cto=l(),Tr=a("div"),F(OR.$$.fragment),wst=l(),jm=a("p"),Ast=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),kne=a("a"),Lst=o("from_pretrained()"),yst=o(" class method or the "),Sne=a("a"),xst=o("from_config()"),$st=o(` class
method.`),kst=l(),VR=a("p"),Sst=o("This class cannot be instantiated directly using "),q9e=a("code"),Rst=o("__init__()"),Pst=o(" (throws an error)."),Bst=l(),sa=a("div"),F(XR.$$.fragment),Ist=l(),j9e=a("p"),Nst=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),qst=l(),Dm=a("p"),jst=o(`Note:
Loading a model from its configuration file does `),D9e=a("strong"),Dst=o("not"),Gst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rne=a("a"),Ost=o("from_pretrained()"),Vst=o(" to load the model weights."),Xst=l(),F(k6.$$.fragment),zst=l(),Yr=a("div"),F(zR.$$.fragment),Qst=l(),G9e=a("p"),Wst=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ust=l(),Vn=a("p"),Hst=o("The model class to instantiate is selected based on the "),O9e=a("code"),Jst=o("model_type"),Yst=o(` property of the config object (either
passed as an argument or loaded from `),V9e=a("code"),Zst=o("pretrained_model_name_or_path"),Kst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X9e=a("code"),elt=o("pretrained_model_name_or_path"),olt=o(":"),rlt=l(),me=a("ul"),S6=a("li"),z9e=a("strong"),tlt=o("albert"),alt=o(" \u2014 "),Pne=a("a"),nlt=o("TFAlbertForQuestionAnswering"),slt=o(" (ALBERT model)"),llt=l(),R6=a("li"),Q9e=a("strong"),ilt=o("bert"),dlt=o(" \u2014 "),Bne=a("a"),clt=o("TFBertForQuestionAnswering"),mlt=o(" (BERT model)"),flt=l(),P6=a("li"),W9e=a("strong"),glt=o("camembert"),hlt=o(" \u2014 "),Ine=a("a"),ult=o("TFCamembertForQuestionAnswering"),plt=o(" (CamemBERT model)"),_lt=l(),B6=a("li"),U9e=a("strong"),blt=o("convbert"),vlt=o(" \u2014 "),Nne=a("a"),Flt=o("TFConvBertForQuestionAnswering"),Tlt=o(" (ConvBERT model)"),Mlt=l(),I6=a("li"),H9e=a("strong"),Elt=o("deberta"),Clt=o(" \u2014 "),qne=a("a"),wlt=o("TFDebertaForQuestionAnswering"),Alt=o(" (DeBERTa model)"),Llt=l(),N6=a("li"),J9e=a("strong"),ylt=o("deberta-v2"),xlt=o(" \u2014 "),jne=a("a"),$lt=o("TFDebertaV2ForQuestionAnswering"),klt=o(" (DeBERTa-v2 model)"),Slt=l(),q6=a("li"),Y9e=a("strong"),Rlt=o("distilbert"),Plt=o(" \u2014 "),Dne=a("a"),Blt=o("TFDistilBertForQuestionAnswering"),Ilt=o(" (DistilBERT model)"),Nlt=l(),j6=a("li"),Z9e=a("strong"),qlt=o("electra"),jlt=o(" \u2014 "),Gne=a("a"),Dlt=o("TFElectraForQuestionAnswering"),Glt=o(" (ELECTRA model)"),Olt=l(),D6=a("li"),K9e=a("strong"),Vlt=o("flaubert"),Xlt=o(" \u2014 "),One=a("a"),zlt=o("TFFlaubertForQuestionAnsweringSimple"),Qlt=o(" (FlauBERT model)"),Wlt=l(),G6=a("li"),exe=a("strong"),Ult=o("funnel"),Hlt=o(" \u2014 "),Vne=a("a"),Jlt=o("TFFunnelForQuestionAnswering"),Ylt=o(" (Funnel Transformer model)"),Zlt=l(),O6=a("li"),oxe=a("strong"),Klt=o("gptj"),eit=o(" \u2014 "),Xne=a("a"),oit=o("TFGPTJForQuestionAnswering"),rit=o(" (GPT-J model)"),tit=l(),V6=a("li"),rxe=a("strong"),ait=o("layoutlmv3"),nit=o(" \u2014 "),zne=a("a"),sit=o("TFLayoutLMv3ForQuestionAnswering"),lit=o(" (LayoutLMv3 model)"),iit=l(),X6=a("li"),txe=a("strong"),dit=o("longformer"),cit=o(" \u2014 "),Qne=a("a"),mit=o("TFLongformerForQuestionAnswering"),fit=o(" (Longformer model)"),git=l(),z6=a("li"),axe=a("strong"),hit=o("mobilebert"),uit=o(" \u2014 "),Wne=a("a"),pit=o("TFMobileBertForQuestionAnswering"),_it=o(" (MobileBERT model)"),bit=l(),Q6=a("li"),nxe=a("strong"),vit=o("mpnet"),Fit=o(" \u2014 "),Une=a("a"),Tit=o("TFMPNetForQuestionAnswering"),Mit=o(" (MPNet model)"),Eit=l(),W6=a("li"),sxe=a("strong"),Cit=o("rembert"),wit=o(" \u2014 "),Hne=a("a"),Ait=o("TFRemBertForQuestionAnswering"),Lit=o(" (RemBERT model)"),yit=l(),U6=a("li"),lxe=a("strong"),xit=o("roberta"),$it=o(" \u2014 "),Jne=a("a"),kit=o("TFRobertaForQuestionAnswering"),Sit=o(" (RoBERTa model)"),Rit=l(),H6=a("li"),ixe=a("strong"),Pit=o("roformer"),Bit=o(" \u2014 "),Yne=a("a"),Iit=o("TFRoFormerForQuestionAnswering"),Nit=o(" (RoFormer model)"),qit=l(),J6=a("li"),dxe=a("strong"),jit=o("xlm"),Dit=o(" \u2014 "),Zne=a("a"),Git=o("TFXLMForQuestionAnsweringSimple"),Oit=o(" (XLM model)"),Vit=l(),Y6=a("li"),cxe=a("strong"),Xit=o("xlm-roberta"),zit=o(" \u2014 "),Kne=a("a"),Qit=o("TFXLMRobertaForQuestionAnswering"),Wit=o(" (XLM-RoBERTa model)"),Uit=l(),Z6=a("li"),mxe=a("strong"),Hit=o("xlnet"),Jit=o(" \u2014 "),ese=a("a"),Yit=o("TFXLNetForQuestionAnsweringSimple"),Zit=o(" (XLNet model)"),Kit=l(),F(K6.$$.fragment),mto=l(),Gm=a("h2"),e7=a("a"),fxe=a("span"),F(QR.$$.fragment),edt=l(),gxe=a("span"),odt=o("TFAutoModelForVision2Seq"),fto=l(),Mr=a("div"),F(WR.$$.fragment),rdt=l(),Om=a("p"),tdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ose=a("a"),adt=o("from_pretrained()"),ndt=o(" class method or the "),rse=a("a"),sdt=o("from_config()"),ldt=o(` class
method.`),idt=l(),UR=a("p"),ddt=o("This class cannot be instantiated directly using "),hxe=a("code"),cdt=o("__init__()"),mdt=o(" (throws an error)."),fdt=l(),la=a("div"),F(HR.$$.fragment),gdt=l(),uxe=a("p"),hdt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),udt=l(),Vm=a("p"),pdt=o(`Note:
Loading a model from its configuration file does `),pxe=a("strong"),_dt=o("not"),bdt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tse=a("a"),vdt=o("from_pretrained()"),Fdt=o(" to load the model weights."),Tdt=l(),F(o7.$$.fragment),Mdt=l(),Zr=a("div"),F(JR.$$.fragment),Edt=l(),_xe=a("p"),Cdt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),wdt=l(),Xn=a("p"),Adt=o("The model class to instantiate is selected based on the "),bxe=a("code"),Ldt=o("model_type"),ydt=o(` property of the config object (either
passed as an argument or loaded from `),vxe=a("code"),xdt=o("pretrained_model_name_or_path"),$dt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fxe=a("code"),kdt=o("pretrained_model_name_or_path"),Sdt=o(":"),Rdt=l(),Txe=a("ul"),r7=a("li"),Mxe=a("strong"),Pdt=o("vision-encoder-decoder"),Bdt=o(" \u2014 "),ase=a("a"),Idt=o("TFVisionEncoderDecoderModel"),Ndt=o(" (Vision Encoder decoder model)"),qdt=l(),F(t7.$$.fragment),gto=l(),Xm=a("h2"),a7=a("a"),Exe=a("span"),F(YR.$$.fragment),jdt=l(),Cxe=a("span"),Ddt=o("TFAutoModelForSpeechSeq2Seq"),hto=l(),Er=a("div"),F(ZR.$$.fragment),Gdt=l(),zm=a("p"),Odt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),nse=a("a"),Vdt=o("from_pretrained()"),Xdt=o(" class method or the "),sse=a("a"),zdt=o("from_config()"),Qdt=o(` class
method.`),Wdt=l(),KR=a("p"),Udt=o("This class cannot be instantiated directly using "),wxe=a("code"),Hdt=o("__init__()"),Jdt=o(" (throws an error)."),Ydt=l(),ia=a("div"),F(eP.$$.fragment),Zdt=l(),Axe=a("p"),Kdt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ect=l(),Qm=a("p"),oct=o(`Note:
Loading a model from its configuration file does `),Lxe=a("strong"),rct=o("not"),tct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=a("a"),act=o("from_pretrained()"),nct=o(" to load the model weights."),sct=l(),F(n7.$$.fragment),lct=l(),Kr=a("div"),F(oP.$$.fragment),ict=l(),yxe=a("p"),dct=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),cct=l(),zn=a("p"),mct=o("The model class to instantiate is selected based on the "),xxe=a("code"),fct=o("model_type"),gct=o(` property of the config object (either
passed as an argument or loaded from `),$xe=a("code"),hct=o("pretrained_model_name_or_path"),uct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kxe=a("code"),pct=o("pretrained_model_name_or_path"),_ct=o(":"),bct=l(),rP=a("ul"),s7=a("li"),Sxe=a("strong"),vct=o("speech_to_text"),Fct=o(" \u2014 "),ise=a("a"),Tct=o("TFSpeech2TextForConditionalGeneration"),Mct=o(" (Speech2Text model)"),Ect=l(),l7=a("li"),Rxe=a("strong"),Cct=o("whisper"),wct=o(" \u2014 "),dse=a("a"),Act=o("TFWhisperForConditionalGeneration"),Lct=o(" (Whisper model)"),yct=l(),F(i7.$$.fragment),uto=l(),Wm=a("h2"),d7=a("a"),Pxe=a("span"),F(tP.$$.fragment),xct=l(),Bxe=a("span"),$ct=o("FlaxAutoModel"),pto=l(),Cr=a("div"),F(aP.$$.fragment),kct=l(),Um=a("p"),Sct=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),cse=a("a"),Rct=o("from_pretrained()"),Pct=o(" class method or the "),mse=a("a"),Bct=o("from_config()"),Ict=o(` class
method.`),Nct=l(),nP=a("p"),qct=o("This class cannot be instantiated directly using "),Ixe=a("code"),jct=o("__init__()"),Dct=o(" (throws an error)."),Gct=l(),da=a("div"),F(sP.$$.fragment),Oct=l(),Nxe=a("p"),Vct=o("Instantiates one of the base model classes of the library from a configuration."),Xct=l(),Hm=a("p"),zct=o(`Note:
Loading a model from its configuration file does `),qxe=a("strong"),Qct=o("not"),Wct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fse=a("a"),Uct=o("from_pretrained()"),Hct=o(" to load the model weights."),Jct=l(),F(c7.$$.fragment),Yct=l(),et=a("div"),F(lP.$$.fragment),Zct=l(),jxe=a("p"),Kct=o("Instantiate one of the base model classes of the library from a pretrained model."),emt=l(),Qn=a("p"),omt=o("The model class to instantiate is selected based on the "),Dxe=a("code"),rmt=o("model_type"),tmt=o(` property of the config object (either
passed as an argument or loaded from `),Gxe=a("code"),amt=o("pretrained_model_name_or_path"),nmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=a("code"),smt=o("pretrained_model_name_or_path"),lmt=o(":"),imt=l(),te=a("ul"),m7=a("li"),Vxe=a("strong"),dmt=o("albert"),cmt=o(" \u2014 "),gse=a("a"),mmt=o("FlaxAlbertModel"),fmt=o(" (ALBERT model)"),gmt=l(),f7=a("li"),Xxe=a("strong"),hmt=o("bart"),umt=o(" \u2014 "),hse=a("a"),pmt=o("FlaxBartModel"),_mt=o(" (BART model)"),bmt=l(),g7=a("li"),zxe=a("strong"),vmt=o("beit"),Fmt=o(" \u2014 "),use=a("a"),Tmt=o("FlaxBeitModel"),Mmt=o(" (BEiT model)"),Emt=l(),h7=a("li"),Qxe=a("strong"),Cmt=o("bert"),wmt=o(" \u2014 "),pse=a("a"),Amt=o("FlaxBertModel"),Lmt=o(" (BERT model)"),ymt=l(),u7=a("li"),Wxe=a("strong"),xmt=o("big_bird"),$mt=o(" \u2014 "),_se=a("a"),kmt=o("FlaxBigBirdModel"),Smt=o(" (BigBird model)"),Rmt=l(),p7=a("li"),Uxe=a("strong"),Pmt=o("blenderbot"),Bmt=o(" \u2014 "),bse=a("a"),Imt=o("FlaxBlenderbotModel"),Nmt=o(" (Blenderbot model)"),qmt=l(),_7=a("li"),Hxe=a("strong"),jmt=o("blenderbot-small"),Dmt=o(" \u2014 "),vse=a("a"),Gmt=o("FlaxBlenderbotSmallModel"),Omt=o(" (BlenderbotSmall model)"),Vmt=l(),b7=a("li"),Jxe=a("strong"),Xmt=o("clip"),zmt=o(" \u2014 "),Fse=a("a"),Qmt=o("FlaxCLIPModel"),Wmt=o(" (CLIP model)"),Umt=l(),v7=a("li"),Yxe=a("strong"),Hmt=o("distilbert"),Jmt=o(" \u2014 "),Tse=a("a"),Ymt=o("FlaxDistilBertModel"),Zmt=o(" (DistilBERT model)"),Kmt=l(),F7=a("li"),Zxe=a("strong"),eft=o("electra"),oft=o(" \u2014 "),Mse=a("a"),rft=o("FlaxElectraModel"),tft=o(" (ELECTRA model)"),aft=l(),T7=a("li"),Kxe=a("strong"),nft=o("gpt2"),sft=o(" \u2014 "),Ese=a("a"),lft=o("FlaxGPT2Model"),ift=o(" (OpenAI GPT-2 model)"),dft=l(),M7=a("li"),e$e=a("strong"),cft=o("gpt_neo"),mft=o(" \u2014 "),Cse=a("a"),fft=o("FlaxGPTNeoModel"),gft=o(" (GPT Neo model)"),hft=l(),E7=a("li"),o$e=a("strong"),uft=o("gptj"),pft=o(" \u2014 "),wse=a("a"),_ft=o("FlaxGPTJModel"),bft=o(" (GPT-J model)"),vft=l(),C7=a("li"),r$e=a("strong"),Fft=o("longt5"),Tft=o(" \u2014 "),Ase=a("a"),Mft=o("FlaxLongT5Model"),Eft=o(" (LongT5 model)"),Cft=l(),w7=a("li"),t$e=a("strong"),wft=o("marian"),Aft=o(" \u2014 "),Lse=a("a"),Lft=o("FlaxMarianModel"),yft=o(" (Marian model)"),xft=l(),A7=a("li"),a$e=a("strong"),$ft=o("mbart"),kft=o(" \u2014 "),yse=a("a"),Sft=o("FlaxMBartModel"),Rft=o(" (mBART model)"),Pft=l(),L7=a("li"),n$e=a("strong"),Bft=o("mt5"),Ift=o(" \u2014 "),xse=a("a"),Nft=o("FlaxMT5Model"),qft=o(" (MT5 model)"),jft=l(),y7=a("li"),s$e=a("strong"),Dft=o("opt"),Gft=o(" \u2014 "),$se=a("a"),Oft=o("FlaxOPTModel"),Vft=o(" (OPT model)"),Xft=l(),x7=a("li"),l$e=a("strong"),zft=o("pegasus"),Qft=o(" \u2014 "),kse=a("a"),Wft=o("FlaxPegasusModel"),Uft=o(" (Pegasus model)"),Hft=l(),$7=a("li"),i$e=a("strong"),Jft=o("roberta"),Yft=o(" \u2014 "),Sse=a("a"),Zft=o("FlaxRobertaModel"),Kft=o(" (RoBERTa model)"),egt=l(),k7=a("li"),d$e=a("strong"),ogt=o("roformer"),rgt=o(" \u2014 "),Rse=a("a"),tgt=o("FlaxRoFormerModel"),agt=o(" (RoFormer model)"),ngt=l(),S7=a("li"),c$e=a("strong"),sgt=o("t5"),lgt=o(" \u2014 "),Pse=a("a"),igt=o("FlaxT5Model"),dgt=o(" (T5 model)"),cgt=l(),R7=a("li"),m$e=a("strong"),mgt=o("vision-text-dual-encoder"),fgt=o(" \u2014 "),Bse=a("a"),ggt=o("FlaxVisionTextDualEncoderModel"),hgt=o(" (VisionTextDualEncoder model)"),ugt=l(),P7=a("li"),f$e=a("strong"),pgt=o("vit"),_gt=o(" \u2014 "),Ise=a("a"),bgt=o("FlaxViTModel"),vgt=o(" (ViT model)"),Fgt=l(),B7=a("li"),g$e=a("strong"),Tgt=o("wav2vec2"),Mgt=o(" \u2014 "),Nse=a("a"),Egt=o("FlaxWav2Vec2Model"),Cgt=o(" (Wav2Vec2 model)"),wgt=l(),I7=a("li"),h$e=a("strong"),Agt=o("xglm"),Lgt=o(" \u2014 "),qse=a("a"),ygt=o("FlaxXGLMModel"),xgt=o(" (XGLM model)"),$gt=l(),N7=a("li"),u$e=a("strong"),kgt=o("xlm-roberta"),Sgt=o(" \u2014 "),jse=a("a"),Rgt=o("FlaxXLMRobertaModel"),Pgt=o(" (XLM-RoBERTa model)"),Bgt=l(),F(q7.$$.fragment),_to=l(),Jm=a("h2"),j7=a("a"),p$e=a("span"),F(iP.$$.fragment),Igt=l(),_$e=a("span"),Ngt=o("FlaxAutoModelForCausalLM"),bto=l(),wr=a("div"),F(dP.$$.fragment),qgt=l(),Ym=a("p"),jgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Dse=a("a"),Dgt=o("from_pretrained()"),Ggt=o(" class method or the "),Gse=a("a"),Ogt=o("from_config()"),Vgt=o(` class
method.`),Xgt=l(),cP=a("p"),zgt=o("This class cannot be instantiated directly using "),b$e=a("code"),Qgt=o("__init__()"),Wgt=o(" (throws an error)."),Ugt=l(),ca=a("div"),F(mP.$$.fragment),Hgt=l(),v$e=a("p"),Jgt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Ygt=l(),Zm=a("p"),Zgt=o(`Note:
Loading a model from its configuration file does `),F$e=a("strong"),Kgt=o("not"),eht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ose=a("a"),oht=o("from_pretrained()"),rht=o(" to load the model weights."),tht=l(),F(D7.$$.fragment),aht=l(),ot=a("div"),F(fP.$$.fragment),nht=l(),T$e=a("p"),sht=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),lht=l(),Wn=a("p"),iht=o("The model class to instantiate is selected based on the "),M$e=a("code"),dht=o("model_type"),cht=o(` property of the config object (either
passed as an argument or loaded from `),E$e=a("code"),mht=o("pretrained_model_name_or_path"),fht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C$e=a("code"),ght=o("pretrained_model_name_or_path"),hht=o(":"),uht=l(),$e=a("ul"),G7=a("li"),w$e=a("strong"),pht=o("bart"),_ht=o(" \u2014 "),Vse=a("a"),bht=o("FlaxBartForCausalLM"),vht=o(" (BART model)"),Fht=l(),O7=a("li"),A$e=a("strong"),Tht=o("bert"),Mht=o(" \u2014 "),Xse=a("a"),Eht=o("FlaxBertForCausalLM"),Cht=o(" (BERT model)"),wht=l(),V7=a("li"),L$e=a("strong"),Aht=o("big_bird"),Lht=o(" \u2014 "),zse=a("a"),yht=o("FlaxBigBirdForCausalLM"),xht=o(" (BigBird model)"),$ht=l(),X7=a("li"),y$e=a("strong"),kht=o("electra"),Sht=o(" \u2014 "),Qse=a("a"),Rht=o("FlaxElectraForCausalLM"),Pht=o(" (ELECTRA model)"),Bht=l(),z7=a("li"),x$e=a("strong"),Iht=o("gpt2"),Nht=o(" \u2014 "),Wse=a("a"),qht=o("FlaxGPT2LMHeadModel"),jht=o(" (OpenAI GPT-2 model)"),Dht=l(),Q7=a("li"),$$e=a("strong"),Ght=o("gpt_neo"),Oht=o(" \u2014 "),Use=a("a"),Vht=o("FlaxGPTNeoForCausalLM"),Xht=o(" (GPT Neo model)"),zht=l(),W7=a("li"),k$e=a("strong"),Qht=o("gptj"),Wht=o(" \u2014 "),Hse=a("a"),Uht=o("FlaxGPTJForCausalLM"),Hht=o(" (GPT-J model)"),Jht=l(),U7=a("li"),S$e=a("strong"),Yht=o("opt"),Zht=o(" \u2014 "),Jse=a("a"),Kht=o("FlaxOPTForCausalLM"),eut=o(" (OPT model)"),out=l(),H7=a("li"),R$e=a("strong"),rut=o("roberta"),tut=o(" \u2014 "),Yse=a("a"),aut=o("FlaxRobertaForCausalLM"),nut=o(" (RoBERTa model)"),sut=l(),J7=a("li"),P$e=a("strong"),lut=o("xglm"),iut=o(" \u2014 "),Zse=a("a"),dut=o("FlaxXGLMForCausalLM"),cut=o(" (XGLM model)"),mut=l(),F(Y7.$$.fragment),vto=l(),Km=a("h2"),Z7=a("a"),B$e=a("span"),F(gP.$$.fragment),fut=l(),I$e=a("span"),gut=o("FlaxAutoModelForPreTraining"),Fto=l(),Ar=a("div"),F(hP.$$.fragment),hut=l(),ef=a("p"),uut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Kse=a("a"),put=o("from_pretrained()"),_ut=o(" class method or the "),ele=a("a"),but=o("from_config()"),vut=o(` class
method.`),Fut=l(),uP=a("p"),Tut=o("This class cannot be instantiated directly using "),N$e=a("code"),Mut=o("__init__()"),Eut=o(" (throws an error)."),Cut=l(),ma=a("div"),F(pP.$$.fragment),wut=l(),q$e=a("p"),Aut=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Lut=l(),of=a("p"),yut=o(`Note:
Loading a model from its configuration file does `),j$e=a("strong"),xut=o("not"),$ut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ole=a("a"),kut=o("from_pretrained()"),Sut=o(" to load the model weights."),Rut=l(),F(K7.$$.fragment),Put=l(),rt=a("div"),F(_P.$$.fragment),But=l(),D$e=a("p"),Iut=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Nut=l(),Un=a("p"),qut=o("The model class to instantiate is selected based on the "),G$e=a("code"),jut=o("model_type"),Dut=o(` property of the config object (either
passed as an argument or loaded from `),O$e=a("code"),Gut=o("pretrained_model_name_or_path"),Out=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V$e=a("code"),Vut=o("pretrained_model_name_or_path"),Xut=o(":"),zut=l(),Ee=a("ul"),eL=a("li"),X$e=a("strong"),Qut=o("albert"),Wut=o(" \u2014 "),rle=a("a"),Uut=o("FlaxAlbertForPreTraining"),Hut=o(" (ALBERT model)"),Jut=l(),oL=a("li"),z$e=a("strong"),Yut=o("bart"),Zut=o(" \u2014 "),tle=a("a"),Kut=o("FlaxBartForConditionalGeneration"),ept=o(" (BART model)"),opt=l(),rL=a("li"),Q$e=a("strong"),rpt=o("bert"),tpt=o(" \u2014 "),ale=a("a"),apt=o("FlaxBertForPreTraining"),npt=o(" (BERT model)"),spt=l(),tL=a("li"),W$e=a("strong"),lpt=o("big_bird"),ipt=o(" \u2014 "),nle=a("a"),dpt=o("FlaxBigBirdForPreTraining"),cpt=o(" (BigBird model)"),mpt=l(),aL=a("li"),U$e=a("strong"),fpt=o("electra"),gpt=o(" \u2014 "),sle=a("a"),hpt=o("FlaxElectraForPreTraining"),upt=o(" (ELECTRA model)"),ppt=l(),nL=a("li"),H$e=a("strong"),_pt=o("longt5"),bpt=o(" \u2014 "),lle=a("a"),vpt=o("FlaxLongT5ForConditionalGeneration"),Fpt=o(" (LongT5 model)"),Tpt=l(),sL=a("li"),J$e=a("strong"),Mpt=o("mbart"),Ept=o(" \u2014 "),ile=a("a"),Cpt=o("FlaxMBartForConditionalGeneration"),wpt=o(" (mBART model)"),Apt=l(),lL=a("li"),Y$e=a("strong"),Lpt=o("mt5"),ypt=o(" \u2014 "),dle=a("a"),xpt=o("FlaxMT5ForConditionalGeneration"),$pt=o(" (MT5 model)"),kpt=l(),iL=a("li"),Z$e=a("strong"),Spt=o("roberta"),Rpt=o(" \u2014 "),cle=a("a"),Ppt=o("FlaxRobertaForMaskedLM"),Bpt=o(" (RoBERTa model)"),Ipt=l(),dL=a("li"),K$e=a("strong"),Npt=o("roformer"),qpt=o(" \u2014 "),mle=a("a"),jpt=o("FlaxRoFormerForMaskedLM"),Dpt=o(" (RoFormer model)"),Gpt=l(),cL=a("li"),eke=a("strong"),Opt=o("t5"),Vpt=o(" \u2014 "),fle=a("a"),Xpt=o("FlaxT5ForConditionalGeneration"),zpt=o(" (T5 model)"),Qpt=l(),mL=a("li"),oke=a("strong"),Wpt=o("wav2vec2"),Upt=o(" \u2014 "),gle=a("a"),Hpt=o("FlaxWav2Vec2ForPreTraining"),Jpt=o(" (Wav2Vec2 model)"),Ypt=l(),fL=a("li"),rke=a("strong"),Zpt=o("xlm-roberta"),Kpt=o(" \u2014 "),hle=a("a"),e_t=o("FlaxXLMRobertaForMaskedLM"),o_t=o(" (XLM-RoBERTa model)"),r_t=l(),F(gL.$$.fragment),Tto=l(),rf=a("h2"),hL=a("a"),tke=a("span"),F(bP.$$.fragment),t_t=l(),ake=a("span"),a_t=o("FlaxAutoModelForMaskedLM"),Mto=l(),Lr=a("div"),F(vP.$$.fragment),n_t=l(),tf=a("p"),s_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ule=a("a"),l_t=o("from_pretrained()"),i_t=o(" class method or the "),ple=a("a"),d_t=o("from_config()"),c_t=o(` class
method.`),m_t=l(),FP=a("p"),f_t=o("This class cannot be instantiated directly using "),nke=a("code"),g_t=o("__init__()"),h_t=o(" (throws an error)."),u_t=l(),fa=a("div"),F(TP.$$.fragment),p_t=l(),ske=a("p"),__t=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),b_t=l(),af=a("p"),v_t=o(`Note:
Loading a model from its configuration file does `),lke=a("strong"),F_t=o("not"),T_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_le=a("a"),M_t=o("from_pretrained()"),E_t=o(" to load the model weights."),C_t=l(),F(uL.$$.fragment),w_t=l(),tt=a("div"),F(MP.$$.fragment),A_t=l(),ike=a("p"),L_t=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),y_t=l(),Hn=a("p"),x_t=o("The model class to instantiate is selected based on the "),dke=a("code"),$_t=o("model_type"),k_t=o(` property of the config object (either
passed as an argument or loaded from `),cke=a("code"),S_t=o("pretrained_model_name_or_path"),R_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mke=a("code"),P_t=o("pretrained_model_name_or_path"),B_t=o(":"),I_t=l(),ke=a("ul"),pL=a("li"),fke=a("strong"),N_t=o("albert"),q_t=o(" \u2014 "),ble=a("a"),j_t=o("FlaxAlbertForMaskedLM"),D_t=o(" (ALBERT model)"),G_t=l(),_L=a("li"),gke=a("strong"),O_t=o("bart"),V_t=o(" \u2014 "),vle=a("a"),X_t=o("FlaxBartForConditionalGeneration"),z_t=o(" (BART model)"),Q_t=l(),bL=a("li"),hke=a("strong"),W_t=o("bert"),U_t=o(" \u2014 "),Fle=a("a"),H_t=o("FlaxBertForMaskedLM"),J_t=o(" (BERT model)"),Y_t=l(),vL=a("li"),uke=a("strong"),Z_t=o("big_bird"),K_t=o(" \u2014 "),Tle=a("a"),e1t=o("FlaxBigBirdForMaskedLM"),o1t=o(" (BigBird model)"),r1t=l(),FL=a("li"),pke=a("strong"),t1t=o("distilbert"),a1t=o(" \u2014 "),Mle=a("a"),n1t=o("FlaxDistilBertForMaskedLM"),s1t=o(" (DistilBERT model)"),l1t=l(),TL=a("li"),_ke=a("strong"),i1t=o("electra"),d1t=o(" \u2014 "),Ele=a("a"),c1t=o("FlaxElectraForMaskedLM"),m1t=o(" (ELECTRA model)"),f1t=l(),ML=a("li"),bke=a("strong"),g1t=o("mbart"),h1t=o(" \u2014 "),Cle=a("a"),u1t=o("FlaxMBartForConditionalGeneration"),p1t=o(" (mBART model)"),_1t=l(),EL=a("li"),vke=a("strong"),b1t=o("roberta"),v1t=o(" \u2014 "),wle=a("a"),F1t=o("FlaxRobertaForMaskedLM"),T1t=o(" (RoBERTa model)"),M1t=l(),CL=a("li"),Fke=a("strong"),E1t=o("roformer"),C1t=o(" \u2014 "),Ale=a("a"),w1t=o("FlaxRoFormerForMaskedLM"),A1t=o(" (RoFormer model)"),L1t=l(),wL=a("li"),Tke=a("strong"),y1t=o("xlm-roberta"),x1t=o(" \u2014 "),Lle=a("a"),$1t=o("FlaxXLMRobertaForMaskedLM"),k1t=o(" (XLM-RoBERTa model)"),S1t=l(),F(AL.$$.fragment),Eto=l(),nf=a("h2"),LL=a("a"),Mke=a("span"),F(EP.$$.fragment),R1t=l(),Eke=a("span"),P1t=o("FlaxAutoModelForSeq2SeqLM"),Cto=l(),yr=a("div"),F(CP.$$.fragment),B1t=l(),sf=a("p"),I1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yle=a("a"),N1t=o("from_pretrained()"),q1t=o(" class method or the "),xle=a("a"),j1t=o("from_config()"),D1t=o(` class
method.`),G1t=l(),wP=a("p"),O1t=o("This class cannot be instantiated directly using "),Cke=a("code"),V1t=o("__init__()"),X1t=o(" (throws an error)."),z1t=l(),ga=a("div"),F(AP.$$.fragment),Q1t=l(),wke=a("p"),W1t=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),U1t=l(),lf=a("p"),H1t=o(`Note:
Loading a model from its configuration file does `),Ake=a("strong"),J1t=o("not"),Y1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$le=a("a"),Z1t=o("from_pretrained()"),K1t=o(" to load the model weights."),e2t=l(),F(yL.$$.fragment),o2t=l(),at=a("div"),F(LP.$$.fragment),r2t=l(),Lke=a("p"),t2t=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),a2t=l(),Jn=a("p"),n2t=o("The model class to instantiate is selected based on the "),yke=a("code"),s2t=o("model_type"),l2t=o(` property of the config object (either
passed as an argument or loaded from `),xke=a("code"),i2t=o("pretrained_model_name_or_path"),d2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ke=a("code"),c2t=o("pretrained_model_name_or_path"),m2t=o(":"),f2t=l(),Se=a("ul"),xL=a("li"),kke=a("strong"),g2t=o("bart"),h2t=o(" \u2014 "),kle=a("a"),u2t=o("FlaxBartForConditionalGeneration"),p2t=o(" (BART model)"),_2t=l(),$L=a("li"),Ske=a("strong"),b2t=o("blenderbot"),v2t=o(" \u2014 "),Sle=a("a"),F2t=o("FlaxBlenderbotForConditionalGeneration"),T2t=o(" (Blenderbot model)"),M2t=l(),kL=a("li"),Rke=a("strong"),E2t=o("blenderbot-small"),C2t=o(" \u2014 "),Rle=a("a"),w2t=o("FlaxBlenderbotSmallForConditionalGeneration"),A2t=o(" (BlenderbotSmall model)"),L2t=l(),SL=a("li"),Pke=a("strong"),y2t=o("encoder-decoder"),x2t=o(" \u2014 "),Ple=a("a"),$2t=o("FlaxEncoderDecoderModel"),k2t=o(" (Encoder decoder model)"),S2t=l(),RL=a("li"),Bke=a("strong"),R2t=o("longt5"),P2t=o(" \u2014 "),Ble=a("a"),B2t=o("FlaxLongT5ForConditionalGeneration"),I2t=o(" (LongT5 model)"),N2t=l(),PL=a("li"),Ike=a("strong"),q2t=o("marian"),j2t=o(" \u2014 "),Ile=a("a"),D2t=o("FlaxMarianMTModel"),G2t=o(" (Marian model)"),O2t=l(),BL=a("li"),Nke=a("strong"),V2t=o("mbart"),X2t=o(" \u2014 "),Nle=a("a"),z2t=o("FlaxMBartForConditionalGeneration"),Q2t=o(" (mBART model)"),W2t=l(),IL=a("li"),qke=a("strong"),U2t=o("mt5"),H2t=o(" \u2014 "),qle=a("a"),J2t=o("FlaxMT5ForConditionalGeneration"),Y2t=o(" (MT5 model)"),Z2t=l(),NL=a("li"),jke=a("strong"),K2t=o("pegasus"),ebt=o(" \u2014 "),jle=a("a"),obt=o("FlaxPegasusForConditionalGeneration"),rbt=o(" (Pegasus model)"),tbt=l(),qL=a("li"),Dke=a("strong"),abt=o("t5"),nbt=o(" \u2014 "),Dle=a("a"),sbt=o("FlaxT5ForConditionalGeneration"),lbt=o(" (T5 model)"),ibt=l(),F(jL.$$.fragment),wto=l(),df=a("h2"),DL=a("a"),Gke=a("span"),F(yP.$$.fragment),dbt=l(),Oke=a("span"),cbt=o("FlaxAutoModelForSequenceClassification"),Ato=l(),xr=a("div"),F(xP.$$.fragment),mbt=l(),cf=a("p"),fbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Gle=a("a"),gbt=o("from_pretrained()"),hbt=o(" class method or the "),Ole=a("a"),ubt=o("from_config()"),pbt=o(` class
method.`),_bt=l(),$P=a("p"),bbt=o("This class cannot be instantiated directly using "),Vke=a("code"),vbt=o("__init__()"),Fbt=o(" (throws an error)."),Tbt=l(),ha=a("div"),F(kP.$$.fragment),Mbt=l(),Xke=a("p"),Ebt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Cbt=l(),mf=a("p"),wbt=o(`Note:
Loading a model from its configuration file does `),zke=a("strong"),Abt=o("not"),Lbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vle=a("a"),ybt=o("from_pretrained()"),xbt=o(" to load the model weights."),$bt=l(),F(GL.$$.fragment),kbt=l(),nt=a("div"),F(SP.$$.fragment),Sbt=l(),Qke=a("p"),Rbt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Pbt=l(),Yn=a("p"),Bbt=o("The model class to instantiate is selected based on the "),Wke=a("code"),Ibt=o("model_type"),Nbt=o(` property of the config object (either
passed as an argument or loaded from `),Uke=a("code"),qbt=o("pretrained_model_name_or_path"),jbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hke=a("code"),Dbt=o("pretrained_model_name_or_path"),Gbt=o(":"),Obt=l(),Re=a("ul"),OL=a("li"),Jke=a("strong"),Vbt=o("albert"),Xbt=o(" \u2014 "),Xle=a("a"),zbt=o("FlaxAlbertForSequenceClassification"),Qbt=o(" (ALBERT model)"),Wbt=l(),VL=a("li"),Yke=a("strong"),Ubt=o("bart"),Hbt=o(" \u2014 "),zle=a("a"),Jbt=o("FlaxBartForSequenceClassification"),Ybt=o(" (BART model)"),Zbt=l(),XL=a("li"),Zke=a("strong"),Kbt=o("bert"),evt=o(" \u2014 "),Qle=a("a"),ovt=o("FlaxBertForSequenceClassification"),rvt=o(" (BERT model)"),tvt=l(),zL=a("li"),Kke=a("strong"),avt=o("big_bird"),nvt=o(" \u2014 "),Wle=a("a"),svt=o("FlaxBigBirdForSequenceClassification"),lvt=o(" (BigBird model)"),ivt=l(),QL=a("li"),eSe=a("strong"),dvt=o("distilbert"),cvt=o(" \u2014 "),Ule=a("a"),mvt=o("FlaxDistilBertForSequenceClassification"),fvt=o(" (DistilBERT model)"),gvt=l(),WL=a("li"),oSe=a("strong"),hvt=o("electra"),uvt=o(" \u2014 "),Hle=a("a"),pvt=o("FlaxElectraForSequenceClassification"),_vt=o(" (ELECTRA model)"),bvt=l(),UL=a("li"),rSe=a("strong"),vvt=o("mbart"),Fvt=o(" \u2014 "),Jle=a("a"),Tvt=o("FlaxMBartForSequenceClassification"),Mvt=o(" (mBART model)"),Evt=l(),HL=a("li"),tSe=a("strong"),Cvt=o("roberta"),wvt=o(" \u2014 "),Yle=a("a"),Avt=o("FlaxRobertaForSequenceClassification"),Lvt=o(" (RoBERTa model)"),yvt=l(),JL=a("li"),aSe=a("strong"),xvt=o("roformer"),$vt=o(" \u2014 "),Zle=a("a"),kvt=o("FlaxRoFormerForSequenceClassification"),Svt=o(" (RoFormer model)"),Rvt=l(),YL=a("li"),nSe=a("strong"),Pvt=o("xlm-roberta"),Bvt=o(" \u2014 "),Kle=a("a"),Ivt=o("FlaxXLMRobertaForSequenceClassification"),Nvt=o(" (XLM-RoBERTa model)"),qvt=l(),F(ZL.$$.fragment),Lto=l(),ff=a("h2"),KL=a("a"),sSe=a("span"),F(RP.$$.fragment),jvt=l(),lSe=a("span"),Dvt=o("FlaxAutoModelForQuestionAnswering"),yto=l(),$r=a("div"),F(PP.$$.fragment),Gvt=l(),gf=a("p"),Ovt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),eie=a("a"),Vvt=o("from_pretrained()"),Xvt=o(" class method or the "),oie=a("a"),zvt=o("from_config()"),Qvt=o(` class
method.`),Wvt=l(),BP=a("p"),Uvt=o("This class cannot be instantiated directly using "),iSe=a("code"),Hvt=o("__init__()"),Jvt=o(" (throws an error)."),Yvt=l(),ua=a("div"),F(IP.$$.fragment),Zvt=l(),dSe=a("p"),Kvt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),eFt=l(),hf=a("p"),oFt=o(`Note:
Loading a model from its configuration file does `),cSe=a("strong"),rFt=o("not"),tFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rie=a("a"),aFt=o("from_pretrained()"),nFt=o(" to load the model weights."),sFt=l(),F(e8.$$.fragment),lFt=l(),st=a("div"),F(NP.$$.fragment),iFt=l(),mSe=a("p"),dFt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cFt=l(),Zn=a("p"),mFt=o("The model class to instantiate is selected based on the "),fSe=a("code"),fFt=o("model_type"),gFt=o(` property of the config object (either
passed as an argument or loaded from `),gSe=a("code"),hFt=o("pretrained_model_name_or_path"),uFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hSe=a("code"),pFt=o("pretrained_model_name_or_path"),_Ft=o(":"),bFt=l(),Pe=a("ul"),o8=a("li"),uSe=a("strong"),vFt=o("albert"),FFt=o(" \u2014 "),tie=a("a"),TFt=o("FlaxAlbertForQuestionAnswering"),MFt=o(" (ALBERT model)"),EFt=l(),r8=a("li"),pSe=a("strong"),CFt=o("bart"),wFt=o(" \u2014 "),aie=a("a"),AFt=o("FlaxBartForQuestionAnswering"),LFt=o(" (BART model)"),yFt=l(),t8=a("li"),_Se=a("strong"),xFt=o("bert"),$Ft=o(" \u2014 "),nie=a("a"),kFt=o("FlaxBertForQuestionAnswering"),SFt=o(" (BERT model)"),RFt=l(),a8=a("li"),bSe=a("strong"),PFt=o("big_bird"),BFt=o(" \u2014 "),sie=a("a"),IFt=o("FlaxBigBirdForQuestionAnswering"),NFt=o(" (BigBird model)"),qFt=l(),n8=a("li"),vSe=a("strong"),jFt=o("distilbert"),DFt=o(" \u2014 "),lie=a("a"),GFt=o("FlaxDistilBertForQuestionAnswering"),OFt=o(" (DistilBERT model)"),VFt=l(),s8=a("li"),FSe=a("strong"),XFt=o("electra"),zFt=o(" \u2014 "),iie=a("a"),QFt=o("FlaxElectraForQuestionAnswering"),WFt=o(" (ELECTRA model)"),UFt=l(),l8=a("li"),TSe=a("strong"),HFt=o("mbart"),JFt=o(" \u2014 "),die=a("a"),YFt=o("FlaxMBartForQuestionAnswering"),ZFt=o(" (mBART model)"),KFt=l(),i8=a("li"),MSe=a("strong"),eTt=o("roberta"),oTt=o(" \u2014 "),cie=a("a"),rTt=o("FlaxRobertaForQuestionAnswering"),tTt=o(" (RoBERTa model)"),aTt=l(),d8=a("li"),ESe=a("strong"),nTt=o("roformer"),sTt=o(" \u2014 "),mie=a("a"),lTt=o("FlaxRoFormerForQuestionAnswering"),iTt=o(" (RoFormer model)"),dTt=l(),c8=a("li"),CSe=a("strong"),cTt=o("xlm-roberta"),mTt=o(" \u2014 "),fie=a("a"),fTt=o("FlaxXLMRobertaForQuestionAnswering"),gTt=o(" (XLM-RoBERTa model)"),hTt=l(),F(m8.$$.fragment),xto=l(),uf=a("h2"),f8=a("a"),wSe=a("span"),F(qP.$$.fragment),uTt=l(),ASe=a("span"),pTt=o("FlaxAutoModelForTokenClassification"),$to=l(),kr=a("div"),F(jP.$$.fragment),_Tt=l(),pf=a("p"),bTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),gie=a("a"),vTt=o("from_pretrained()"),FTt=o(" class method or the "),hie=a("a"),TTt=o("from_config()"),MTt=o(` class
method.`),ETt=l(),DP=a("p"),CTt=o("This class cannot be instantiated directly using "),LSe=a("code"),wTt=o("__init__()"),ATt=o(" (throws an error)."),LTt=l(),pa=a("div"),F(GP.$$.fragment),yTt=l(),ySe=a("p"),xTt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$Tt=l(),_f=a("p"),kTt=o(`Note:
Loading a model from its configuration file does `),xSe=a("strong"),STt=o("not"),RTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uie=a("a"),PTt=o("from_pretrained()"),BTt=o(" to load the model weights."),ITt=l(),F(g8.$$.fragment),NTt=l(),lt=a("div"),F(OP.$$.fragment),qTt=l(),$Se=a("p"),jTt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),DTt=l(),Kn=a("p"),GTt=o("The model class to instantiate is selected based on the "),kSe=a("code"),OTt=o("model_type"),VTt=o(` property of the config object (either
passed as an argument or loaded from `),SSe=a("code"),XTt=o("pretrained_model_name_or_path"),zTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RSe=a("code"),QTt=o("pretrained_model_name_or_path"),WTt=o(":"),UTt=l(),ze=a("ul"),h8=a("li"),PSe=a("strong"),HTt=o("albert"),JTt=o(" \u2014 "),pie=a("a"),YTt=o("FlaxAlbertForTokenClassification"),ZTt=o(" (ALBERT model)"),KTt=l(),u8=a("li"),BSe=a("strong"),eMt=o("bert"),oMt=o(" \u2014 "),_ie=a("a"),rMt=o("FlaxBertForTokenClassification"),tMt=o(" (BERT model)"),aMt=l(),p8=a("li"),ISe=a("strong"),nMt=o("big_bird"),sMt=o(" \u2014 "),bie=a("a"),lMt=o("FlaxBigBirdForTokenClassification"),iMt=o(" (BigBird model)"),dMt=l(),_8=a("li"),NSe=a("strong"),cMt=o("distilbert"),mMt=o(" \u2014 "),vie=a("a"),fMt=o("FlaxDistilBertForTokenClassification"),gMt=o(" (DistilBERT model)"),hMt=l(),b8=a("li"),qSe=a("strong"),uMt=o("electra"),pMt=o(" \u2014 "),Fie=a("a"),_Mt=o("FlaxElectraForTokenClassification"),bMt=o(" (ELECTRA model)"),vMt=l(),v8=a("li"),jSe=a("strong"),FMt=o("roberta"),TMt=o(" \u2014 "),Tie=a("a"),MMt=o("FlaxRobertaForTokenClassification"),EMt=o(" (RoBERTa model)"),CMt=l(),F8=a("li"),DSe=a("strong"),wMt=o("roformer"),AMt=o(" \u2014 "),Mie=a("a"),LMt=o("FlaxRoFormerForTokenClassification"),yMt=o(" (RoFormer model)"),xMt=l(),T8=a("li"),GSe=a("strong"),$Mt=o("xlm-roberta"),kMt=o(" \u2014 "),Eie=a("a"),SMt=o("FlaxXLMRobertaForTokenClassification"),RMt=o(" (XLM-RoBERTa model)"),PMt=l(),F(M8.$$.fragment),kto=l(),bf=a("h2"),E8=a("a"),OSe=a("span"),F(VP.$$.fragment),BMt=l(),VSe=a("span"),IMt=o("FlaxAutoModelForMultipleChoice"),Sto=l(),Sr=a("div"),F(XP.$$.fragment),NMt=l(),vf=a("p"),qMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Cie=a("a"),jMt=o("from_pretrained()"),DMt=o(" class method or the "),wie=a("a"),GMt=o("from_config()"),OMt=o(` class
method.`),VMt=l(),zP=a("p"),XMt=o("This class cannot be instantiated directly using "),XSe=a("code"),zMt=o("__init__()"),QMt=o(" (throws an error)."),WMt=l(),_a=a("div"),F(QP.$$.fragment),UMt=l(),zSe=a("p"),HMt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),JMt=l(),Ff=a("p"),YMt=o(`Note:
Loading a model from its configuration file does `),QSe=a("strong"),ZMt=o("not"),KMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aie=a("a"),eEt=o("from_pretrained()"),oEt=o(" to load the model weights."),rEt=l(),F(C8.$$.fragment),tEt=l(),it=a("div"),F(WP.$$.fragment),aEt=l(),WSe=a("p"),nEt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),sEt=l(),es=a("p"),lEt=o("The model class to instantiate is selected based on the "),USe=a("code"),iEt=o("model_type"),dEt=o(` property of the config object (either
passed as an argument or loaded from `),HSe=a("code"),cEt=o("pretrained_model_name_or_path"),mEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=a("code"),fEt=o("pretrained_model_name_or_path"),gEt=o(":"),hEt=l(),Qe=a("ul"),w8=a("li"),YSe=a("strong"),uEt=o("albert"),pEt=o(" \u2014 "),Lie=a("a"),_Et=o("FlaxAlbertForMultipleChoice"),bEt=o(" (ALBERT model)"),vEt=l(),A8=a("li"),ZSe=a("strong"),FEt=o("bert"),TEt=o(" \u2014 "),yie=a("a"),MEt=o("FlaxBertForMultipleChoice"),EEt=o(" (BERT model)"),CEt=l(),L8=a("li"),KSe=a("strong"),wEt=o("big_bird"),AEt=o(" \u2014 "),xie=a("a"),LEt=o("FlaxBigBirdForMultipleChoice"),yEt=o(" (BigBird model)"),xEt=l(),y8=a("li"),eRe=a("strong"),$Et=o("distilbert"),kEt=o(" \u2014 "),$ie=a("a"),SEt=o("FlaxDistilBertForMultipleChoice"),REt=o(" (DistilBERT model)"),PEt=l(),x8=a("li"),oRe=a("strong"),BEt=o("electra"),IEt=o(" \u2014 "),kie=a("a"),NEt=o("FlaxElectraForMultipleChoice"),qEt=o(" (ELECTRA model)"),jEt=l(),$8=a("li"),rRe=a("strong"),DEt=o("roberta"),GEt=o(" \u2014 "),Sie=a("a"),OEt=o("FlaxRobertaForMultipleChoice"),VEt=o(" (RoBERTa model)"),XEt=l(),k8=a("li"),tRe=a("strong"),zEt=o("roformer"),QEt=o(" \u2014 "),Rie=a("a"),WEt=o("FlaxRoFormerForMultipleChoice"),UEt=o(" (RoFormer model)"),HEt=l(),S8=a("li"),aRe=a("strong"),JEt=o("xlm-roberta"),YEt=o(" \u2014 "),Pie=a("a"),ZEt=o("FlaxXLMRobertaForMultipleChoice"),KEt=o(" (XLM-RoBERTa model)"),e4t=l(),F(R8.$$.fragment),Rto=l(),Tf=a("h2"),P8=a("a"),nRe=a("span"),F(UP.$$.fragment),o4t=l(),sRe=a("span"),r4t=o("FlaxAutoModelForNextSentencePrediction"),Pto=l(),Rr=a("div"),F(HP.$$.fragment),t4t=l(),Mf=a("p"),a4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Bie=a("a"),n4t=o("from_pretrained()"),s4t=o(" class method or the "),Iie=a("a"),l4t=o("from_config()"),i4t=o(` class
method.`),d4t=l(),JP=a("p"),c4t=o("This class cannot be instantiated directly using "),lRe=a("code"),m4t=o("__init__()"),f4t=o(" (throws an error)."),g4t=l(),ba=a("div"),F(YP.$$.fragment),h4t=l(),iRe=a("p"),u4t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),p4t=l(),Ef=a("p"),_4t=o(`Note:
Loading a model from its configuration file does `),dRe=a("strong"),b4t=o("not"),v4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=a("a"),F4t=o("from_pretrained()"),T4t=o(" to load the model weights."),M4t=l(),F(B8.$$.fragment),E4t=l(),dt=a("div"),F(ZP.$$.fragment),C4t=l(),cRe=a("p"),w4t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),A4t=l(),os=a("p"),L4t=o("The model class to instantiate is selected based on the "),mRe=a("code"),y4t=o("model_type"),x4t=o(` property of the config object (either
passed as an argument or loaded from `),fRe=a("code"),$4t=o("pretrained_model_name_or_path"),k4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gRe=a("code"),S4t=o("pretrained_model_name_or_path"),R4t=o(":"),P4t=l(),hRe=a("ul"),I8=a("li"),uRe=a("strong"),B4t=o("bert"),I4t=o(" \u2014 "),qie=a("a"),N4t=o("FlaxBertForNextSentencePrediction"),q4t=o(" (BERT model)"),j4t=l(),F(N8.$$.fragment),Bto=l(),Cf=a("h2"),q8=a("a"),pRe=a("span"),F(KP.$$.fragment),D4t=l(),_Re=a("span"),G4t=o("FlaxAutoModelForImageClassification"),Ito=l(),Pr=a("div"),F(eB.$$.fragment),O4t=l(),wf=a("p"),V4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jie=a("a"),X4t=o("from_pretrained()"),z4t=o(" class method or the "),Die=a("a"),Q4t=o("from_config()"),W4t=o(` class
method.`),U4t=l(),oB=a("p"),H4t=o("This class cannot be instantiated directly using "),bRe=a("code"),J4t=o("__init__()"),Y4t=o(" (throws an error)."),Z4t=l(),va=a("div"),F(rB.$$.fragment),K4t=l(),vRe=a("p"),eCt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),oCt=l(),Af=a("p"),rCt=o(`Note:
Loading a model from its configuration file does `),FRe=a("strong"),tCt=o("not"),aCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gie=a("a"),nCt=o("from_pretrained()"),sCt=o(" to load the model weights."),lCt=l(),F(j8.$$.fragment),iCt=l(),ct=a("div"),F(tB.$$.fragment),dCt=l(),TRe=a("p"),cCt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),mCt=l(),rs=a("p"),fCt=o("The model class to instantiate is selected based on the "),MRe=a("code"),gCt=o("model_type"),hCt=o(` property of the config object (either
passed as an argument or loaded from `),ERe=a("code"),uCt=o("pretrained_model_name_or_path"),pCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CRe=a("code"),_Ct=o("pretrained_model_name_or_path"),bCt=o(":"),vCt=l(),aB=a("ul"),D8=a("li"),wRe=a("strong"),FCt=o("beit"),TCt=o(" \u2014 "),Oie=a("a"),MCt=o("FlaxBeitForImageClassification"),ECt=o(" (BEiT model)"),CCt=l(),G8=a("li"),ARe=a("strong"),wCt=o("vit"),ACt=o(" \u2014 "),Vie=a("a"),LCt=o("FlaxViTForImageClassification"),yCt=o(" (ViT model)"),xCt=l(),F(O8.$$.fragment),Nto=l(),Lf=a("h2"),V8=a("a"),LRe=a("span"),F(nB.$$.fragment),$Ct=l(),yRe=a("span"),kCt=o("FlaxAutoModelForVision2Seq"),qto=l(),Br=a("div"),F(sB.$$.fragment),SCt=l(),yf=a("p"),RCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Xie=a("a"),PCt=o("from_pretrained()"),BCt=o(" class method or the "),zie=a("a"),ICt=o("from_config()"),NCt=o(` class
method.`),qCt=l(),lB=a("p"),jCt=o("This class cannot be instantiated directly using "),xRe=a("code"),DCt=o("__init__()"),GCt=o(" (throws an error)."),OCt=l(),Fa=a("div"),F(iB.$$.fragment),VCt=l(),$Re=a("p"),XCt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zCt=l(),xf=a("p"),QCt=o(`Note:
Loading a model from its configuration file does `),kRe=a("strong"),WCt=o("not"),UCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qie=a("a"),HCt=o("from_pretrained()"),JCt=o(" to load the model weights."),YCt=l(),F(X8.$$.fragment),ZCt=l(),mt=a("div"),F(dB.$$.fragment),KCt=l(),SRe=a("p"),e3t=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),o3t=l(),ts=a("p"),r3t=o("The model class to instantiate is selected based on the "),RRe=a("code"),t3t=o("model_type"),a3t=o(` property of the config object (either
passed as an argument or loaded from `),PRe=a("code"),n3t=o("pretrained_model_name_or_path"),s3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BRe=a("code"),l3t=o("pretrained_model_name_or_path"),i3t=o(":"),d3t=l(),IRe=a("ul"),z8=a("li"),NRe=a("strong"),c3t=o("vision-encoder-decoder"),m3t=o(" \u2014 "),Wie=a("a"),f3t=o("FlaxVisionEncoderDecoderModel"),g3t=o(" (Vision Encoder decoder model)"),h3t=l(),F(Q8.$$.fragment),this.h()},l(m){const _=aTa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var cB=s(u);f=n(cB,"A",{id:!0,class:!0,href:!0});var qRe=s(f);p=n(qRe,"SPAN",{});var jRe=s(p);T(d.$$.fragment,jRe),jRe.forEach(t),qRe.forEach(t),h=i(cB),xo=n(cB,"SPAN",{});var DRe=s(xo);dd=r(DRe,"Auto Classes"),DRe.forEach(t),cB.forEach(t),Rf=i(m),bt=n(m,"P",{});var mB=s(bt);cd=r(mB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),md=n(mB,"CODE",{});var GRe=s(md);Ax=r(GRe,"from_pretrained()"),GRe.forEach(t),Pf=r(mB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),mB.forEach(t),Xe=i(m),He=n(m,"P",{});var as=s(He);fd=r(as,"Instantiating one of "),ns=n(as,"A",{href:!0});var ORe=s(ns);Lx=r(ORe,"AutoConfig"),ORe.forEach(t),ss=r(as,", "),ls=n(as,"A",{href:!0});var VRe=s(ls);yx=r(VRe,"AutoModel"),VRe.forEach(t),gd=r(as,`, and
`),is=n(as,"A",{href:!0});var XRe=s(is);xx=r(XRe,"AutoTokenizer"),XRe.forEach(t),hd=r(as," will directly create a class of the relevant architecture. For instance"),as.forEach(t),Bf=i(m),T(Ja.$$.fragment,m),Je=i(m),Ae=n(m,"P",{});var fB=s(Ae);BI=r(fB,"will create a model that is an instance of "),ud=n(fB,"A",{href:!0});var zRe=s(ud);II=r(zRe,"BertModel"),zRe.forEach(t),NI=r(fB,"."),fB.forEach(t),$o=i(m),Ya=n(m,"P",{});var gB=s(Ya);qI=r(gB,"There is one class of "),If=n(gB,"CODE",{});var QRe=s(If);jI=r(QRe,"AutoModel"),QRe.forEach(t),aso=r(gB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),gB.forEach(t),Coo=i(m),pd=n(m,"H2",{class:!0});var hB=s(pd);Nf=n(hB,"A",{id:!0,class:!0,href:!0});var WRe=s(Nf);eme=n(WRe,"SPAN",{});var URe=s(eme);T($x.$$.fragment,URe),URe.forEach(t),WRe.forEach(t),nso=i(hB),ome=n(hB,"SPAN",{});var HRe=s(ome);sso=r(HRe,"Extending the Auto Classes"),HRe.forEach(t),hB.forEach(t),woo=i(m),ds=n(m,"P",{});var $f=s(ds);lso=r($f,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),rme=n($f,"CODE",{});var JRe=s(rme);iso=r(JRe,"NewModel"),JRe.forEach(t),dso=r($f,", make sure you have a "),tme=n($f,"CODE",{});var YRe=s(tme);cso=r(YRe,"NewModelConfig"),YRe.forEach(t),mso=r($f,` then you can add those to the auto
classes like this:`),$f.forEach(t),Aoo=i(m),T(kx.$$.fragment,m),Loo=i(m),DI=n(m,"P",{});var ZRe=s(DI);fso=r(ZRe,"You will then be able to use the auto classes like you would usually do!"),ZRe.forEach(t),yoo=i(m),T(qf.$$.fragment,m),xoo=i(m),_d=n(m,"H2",{class:!0});var uB=s(_d);jf=n(uB,"A",{id:!0,class:!0,href:!0});var KRe=s(jf);ame=n(KRe,"SPAN",{});var ePe=s(ame);T(Sx.$$.fragment,ePe),ePe.forEach(t),KRe.forEach(t),gso=i(uB),nme=n(uB,"SPAN",{});var oPe=s(nme);hso=r(oPe,"AutoConfig"),oPe.forEach(t),uB.forEach(t),$oo=i(m),ko=n(m,"DIV",{class:!0});var pt=s(ko);T(Rx.$$.fragment,pt),uso=i(pt),Px=n(pt,"P",{});var pB=s(Px);pso=r(pB,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),GI=n(pB,"A",{href:!0});var rPe=s(GI);_so=r(rPe,"from_pretrained()"),rPe.forEach(t),bso=r(pB," class method."),pB.forEach(t),vso=i(pt),Bx=n(pt,"P",{});var _B=s(Bx);Fso=r(_B,"This class cannot be instantiated directly using "),sme=n(_B,"CODE",{});var tPe=s(sme);Tso=r(tPe,"__init__()"),tPe.forEach(t),Mso=r(_B," (throws an error)."),_B.forEach(t),Eso=i(pt),Ir=n(pt,"DIV",{class:!0});var _t=s(Ir);T(Ix.$$.fragment,_t),Cso=i(_t),lme=n(_t,"P",{});var aPe=s(lme);wso=r(aPe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),aPe.forEach(t),Aso=i(_t),bd=n(_t,"P",{});var kf=s(bd);Lso=r(kf,"The configuration class to instantiate is selected based on the "),ime=n(kf,"CODE",{});var nPe=s(ime);yso=r(nPe,"model_type"),nPe.forEach(t),xso=r(kf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),dme=n(kf,"CODE",{});var sPe=s(dme);$so=r(sPe,"pretrained_model_name_or_path"),sPe.forEach(t),kso=r(kf,":"),kf.forEach(t),Sso=i(_t),A=n(_t,"UL",{});var L=s(A);Df=n(L,"LI",{});var W8=s(Df);cme=n(W8,"STRONG",{});var lPe=s(cme);Rso=r(lPe,"albert"),lPe.forEach(t),Pso=r(W8," \u2014 "),OI=n(W8,"A",{href:!0});var iPe=s(OI);Bso=r(iPe,"AlbertConfig"),iPe.forEach(t),Iso=r(W8," (ALBERT model)"),W8.forEach(t),Nso=i(L),Gf=n(L,"LI",{});var U8=s(Gf);mme=n(U8,"STRONG",{});var dPe=s(mme);qso=r(dPe,"bart"),dPe.forEach(t),jso=r(U8," \u2014 "),VI=n(U8,"A",{href:!0});var cPe=s(VI);Dso=r(cPe,"BartConfig"),cPe.forEach(t),Gso=r(U8," (BART model)"),U8.forEach(t),Oso=i(L),Of=n(L,"LI",{});var H8=s(Of);fme=n(H8,"STRONG",{});var mPe=s(fme);Vso=r(mPe,"beit"),mPe.forEach(t),Xso=r(H8," \u2014 "),XI=n(H8,"A",{href:!0});var fPe=s(XI);zso=r(fPe,"BeitConfig"),fPe.forEach(t),Qso=r(H8," (BEiT model)"),H8.forEach(t),Wso=i(L),Vf=n(L,"LI",{});var J8=s(Vf);gme=n(J8,"STRONG",{});var gPe=s(gme);Uso=r(gPe,"bert"),gPe.forEach(t),Hso=r(J8," \u2014 "),zI=n(J8,"A",{href:!0});var hPe=s(zI);Jso=r(hPe,"BertConfig"),hPe.forEach(t),Yso=r(J8," (BERT model)"),J8.forEach(t),Zso=i(L),Xf=n(L,"LI",{});var Y8=s(Xf);hme=n(Y8,"STRONG",{});var uPe=s(hme);Kso=r(uPe,"bert-generation"),uPe.forEach(t),elo=r(Y8," \u2014 "),QI=n(Y8,"A",{href:!0});var pPe=s(QI);olo=r(pPe,"BertGenerationConfig"),pPe.forEach(t),rlo=r(Y8," (Bert Generation model)"),Y8.forEach(t),tlo=i(L),zf=n(L,"LI",{});var Z8=s(zf);ume=n(Z8,"STRONG",{});var _Pe=s(ume);alo=r(_Pe,"big_bird"),_Pe.forEach(t),nlo=r(Z8," \u2014 "),WI=n(Z8,"A",{href:!0});var bPe=s(WI);slo=r(bPe,"BigBirdConfig"),bPe.forEach(t),llo=r(Z8," (BigBird model)"),Z8.forEach(t),ilo=i(L),Qf=n(L,"LI",{});var K8=s(Qf);pme=n(K8,"STRONG",{});var vPe=s(pme);dlo=r(vPe,"bigbird_pegasus"),vPe.forEach(t),clo=r(K8," \u2014 "),UI=n(K8,"A",{href:!0});var FPe=s(UI);mlo=r(FPe,"BigBirdPegasusConfig"),FPe.forEach(t),flo=r(K8," (BigBird-Pegasus model)"),K8.forEach(t),glo=i(L),Wf=n(L,"LI",{});var ey=s(Wf);_me=n(ey,"STRONG",{});var TPe=s(_me);hlo=r(TPe,"blenderbot"),TPe.forEach(t),ulo=r(ey," \u2014 "),HI=n(ey,"A",{href:!0});var MPe=s(HI);plo=r(MPe,"BlenderbotConfig"),MPe.forEach(t),_lo=r(ey," (Blenderbot model)"),ey.forEach(t),blo=i(L),Uf=n(L,"LI",{});var oy=s(Uf);bme=n(oy,"STRONG",{});var EPe=s(bme);vlo=r(EPe,"blenderbot-small"),EPe.forEach(t),Flo=r(oy," \u2014 "),JI=n(oy,"A",{href:!0});var CPe=s(JI);Tlo=r(CPe,"BlenderbotSmallConfig"),CPe.forEach(t),Mlo=r(oy," (BlenderbotSmall model)"),oy.forEach(t),Elo=i(L),Hf=n(L,"LI",{});var ry=s(Hf);vme=n(ry,"STRONG",{});var wPe=s(vme);Clo=r(wPe,"bloom"),wPe.forEach(t),wlo=r(ry," \u2014 "),YI=n(ry,"A",{href:!0});var APe=s(YI);Alo=r(APe,"BloomConfig"),APe.forEach(t),Llo=r(ry," (BLOOM model)"),ry.forEach(t),ylo=i(L),Jf=n(L,"LI",{});var ty=s(Jf);Fme=n(ty,"STRONG",{});var LPe=s(Fme);xlo=r(LPe,"camembert"),LPe.forEach(t),$lo=r(ty," \u2014 "),ZI=n(ty,"A",{href:!0});var yPe=s(ZI);klo=r(yPe,"CamembertConfig"),yPe.forEach(t),Slo=r(ty," (CamemBERT model)"),ty.forEach(t),Rlo=i(L),Yf=n(L,"LI",{});var ay=s(Yf);Tme=n(ay,"STRONG",{});var xPe=s(Tme);Plo=r(xPe,"canine"),xPe.forEach(t),Blo=r(ay," \u2014 "),KI=n(ay,"A",{href:!0});var $Pe=s(KI);Ilo=r($Pe,"CanineConfig"),$Pe.forEach(t),Nlo=r(ay," (CANINE model)"),ay.forEach(t),qlo=i(L),Zf=n(L,"LI",{});var ny=s(Zf);Mme=n(ny,"STRONG",{});var kPe=s(Mme);jlo=r(kPe,"clip"),kPe.forEach(t),Dlo=r(ny," \u2014 "),eN=n(ny,"A",{href:!0});var SPe=s(eN);Glo=r(SPe,"CLIPConfig"),SPe.forEach(t),Olo=r(ny," (CLIP model)"),ny.forEach(t),Vlo=i(L),Kf=n(L,"LI",{});var sy=s(Kf);Eme=n(sy,"STRONG",{});var RPe=s(Eme);Xlo=r(RPe,"codegen"),RPe.forEach(t),zlo=r(sy," \u2014 "),oN=n(sy,"A",{href:!0});var PPe=s(oN);Qlo=r(PPe,"CodeGenConfig"),PPe.forEach(t),Wlo=r(sy," (CodeGen model)"),sy.forEach(t),Ulo=i(L),eg=n(L,"LI",{});var ly=s(eg);Cme=n(ly,"STRONG",{});var BPe=s(Cme);Hlo=r(BPe,"conditional_detr"),BPe.forEach(t),Jlo=r(ly," \u2014 "),rN=n(ly,"A",{href:!0});var IPe=s(rN);Ylo=r(IPe,"ConditionalDetrConfig"),IPe.forEach(t),Zlo=r(ly," (Conditional DETR model)"),ly.forEach(t),Klo=i(L),og=n(L,"LI",{});var iy=s(og);wme=n(iy,"STRONG",{});var NPe=s(wme);eio=r(NPe,"convbert"),NPe.forEach(t),oio=r(iy," \u2014 "),tN=n(iy,"A",{href:!0});var qPe=s(tN);rio=r(qPe,"ConvBertConfig"),qPe.forEach(t),tio=r(iy," (ConvBERT model)"),iy.forEach(t),aio=i(L),rg=n(L,"LI",{});var dy=s(rg);Ame=n(dy,"STRONG",{});var jPe=s(Ame);nio=r(jPe,"convnext"),jPe.forEach(t),sio=r(dy," \u2014 "),aN=n(dy,"A",{href:!0});var DPe=s(aN);lio=r(DPe,"ConvNextConfig"),DPe.forEach(t),iio=r(dy," (ConvNeXT model)"),dy.forEach(t),dio=i(L),tg=n(L,"LI",{});var cy=s(tg);Lme=n(cy,"STRONG",{});var GPe=s(Lme);cio=r(GPe,"ctrl"),GPe.forEach(t),mio=r(cy," \u2014 "),nN=n(cy,"A",{href:!0});var OPe=s(nN);fio=r(OPe,"CTRLConfig"),OPe.forEach(t),gio=r(cy," (CTRL model)"),cy.forEach(t),hio=i(L),ag=n(L,"LI",{});var my=s(ag);yme=n(my,"STRONG",{});var VPe=s(yme);uio=r(VPe,"cvt"),VPe.forEach(t),pio=r(my," \u2014 "),sN=n(my,"A",{href:!0});var XPe=s(sN);_io=r(XPe,"CvtConfig"),XPe.forEach(t),bio=r(my," (CvT model)"),my.forEach(t),vio=i(L),ng=n(L,"LI",{});var fy=s(ng);xme=n(fy,"STRONG",{});var zPe=s(xme);Fio=r(zPe,"data2vec-audio"),zPe.forEach(t),Tio=r(fy," \u2014 "),lN=n(fy,"A",{href:!0});var QPe=s(lN);Mio=r(QPe,"Data2VecAudioConfig"),QPe.forEach(t),Eio=r(fy," (Data2VecAudio model)"),fy.forEach(t),Cio=i(L),sg=n(L,"LI",{});var gy=s(sg);$me=n(gy,"STRONG",{});var WPe=s($me);wio=r(WPe,"data2vec-text"),WPe.forEach(t),Aio=r(gy," \u2014 "),iN=n(gy,"A",{href:!0});var UPe=s(iN);Lio=r(UPe,"Data2VecTextConfig"),UPe.forEach(t),yio=r(gy," (Data2VecText model)"),gy.forEach(t),xio=i(L),lg=n(L,"LI",{});var hy=s(lg);kme=n(hy,"STRONG",{});var HPe=s(kme);$io=r(HPe,"data2vec-vision"),HPe.forEach(t),kio=r(hy," \u2014 "),dN=n(hy,"A",{href:!0});var JPe=s(dN);Sio=r(JPe,"Data2VecVisionConfig"),JPe.forEach(t),Rio=r(hy," (Data2VecVision model)"),hy.forEach(t),Pio=i(L),ig=n(L,"LI",{});var uy=s(ig);Sme=n(uy,"STRONG",{});var YPe=s(Sme);Bio=r(YPe,"deberta"),YPe.forEach(t),Iio=r(uy," \u2014 "),cN=n(uy,"A",{href:!0});var ZPe=s(cN);Nio=r(ZPe,"DebertaConfig"),ZPe.forEach(t),qio=r(uy," (DeBERTa model)"),uy.forEach(t),jio=i(L),dg=n(L,"LI",{});var py=s(dg);Rme=n(py,"STRONG",{});var KPe=s(Rme);Dio=r(KPe,"deberta-v2"),KPe.forEach(t),Gio=r(py," \u2014 "),mN=n(py,"A",{href:!0});var eBe=s(mN);Oio=r(eBe,"DebertaV2Config"),eBe.forEach(t),Vio=r(py," (DeBERTa-v2 model)"),py.forEach(t),Xio=i(L),cg=n(L,"LI",{});var _y=s(cg);Pme=n(_y,"STRONG",{});var oBe=s(Pme);zio=r(oBe,"decision_transformer"),oBe.forEach(t),Qio=r(_y," \u2014 "),fN=n(_y,"A",{href:!0});var rBe=s(fN);Wio=r(rBe,"DecisionTransformerConfig"),rBe.forEach(t),Uio=r(_y," (Decision Transformer model)"),_y.forEach(t),Hio=i(L),mg=n(L,"LI",{});var by=s(mg);Bme=n(by,"STRONG",{});var tBe=s(Bme);Jio=r(tBe,"deformable_detr"),tBe.forEach(t),Yio=r(by," \u2014 "),gN=n(by,"A",{href:!0});var aBe=s(gN);Zio=r(aBe,"DeformableDetrConfig"),aBe.forEach(t),Kio=r(by," (Deformable DETR model)"),by.forEach(t),edo=i(L),fg=n(L,"LI",{});var vy=s(fg);Ime=n(vy,"STRONG",{});var nBe=s(Ime);odo=r(nBe,"deit"),nBe.forEach(t),rdo=r(vy," \u2014 "),hN=n(vy,"A",{href:!0});var p3t=s(hN);tdo=r(p3t,"DeiTConfig"),p3t.forEach(t),ado=r(vy," (DeiT model)"),vy.forEach(t),ndo=i(L),gg=n(L,"LI",{});var sBe=s(gg);Nme=n(sBe,"STRONG",{});var _3t=s(Nme);sdo=r(_3t,"detr"),_3t.forEach(t),ldo=r(sBe," \u2014 "),uN=n(sBe,"A",{href:!0});var b3t=s(uN);ido=r(b3t,"DetrConfig"),b3t.forEach(t),ddo=r(sBe," (DETR model)"),sBe.forEach(t),cdo=i(L),hg=n(L,"LI",{});var lBe=s(hg);qme=n(lBe,"STRONG",{});var v3t=s(qme);mdo=r(v3t,"distilbert"),v3t.forEach(t),fdo=r(lBe," \u2014 "),pN=n(lBe,"A",{href:!0});var F3t=s(pN);gdo=r(F3t,"DistilBertConfig"),F3t.forEach(t),hdo=r(lBe," (DistilBERT model)"),lBe.forEach(t),udo=i(L),ug=n(L,"LI",{});var iBe=s(ug);jme=n(iBe,"STRONG",{});var T3t=s(jme);pdo=r(T3t,"donut-swin"),T3t.forEach(t),_do=r(iBe," \u2014 "),_N=n(iBe,"A",{href:!0});var M3t=s(_N);bdo=r(M3t,"DonutSwinConfig"),M3t.forEach(t),vdo=r(iBe," (DonutSwin model)"),iBe.forEach(t),Fdo=i(L),pg=n(L,"LI",{});var dBe=s(pg);Dme=n(dBe,"STRONG",{});var E3t=s(Dme);Tdo=r(E3t,"dpr"),E3t.forEach(t),Mdo=r(dBe," \u2014 "),bN=n(dBe,"A",{href:!0});var C3t=s(bN);Edo=r(C3t,"DPRConfig"),C3t.forEach(t),Cdo=r(dBe," (DPR model)"),dBe.forEach(t),wdo=i(L),_g=n(L,"LI",{});var cBe=s(_g);Gme=n(cBe,"STRONG",{});var w3t=s(Gme);Ado=r(w3t,"dpt"),w3t.forEach(t),Ldo=r(cBe," \u2014 "),vN=n(cBe,"A",{href:!0});var A3t=s(vN);ydo=r(A3t,"DPTConfig"),A3t.forEach(t),xdo=r(cBe," (DPT model)"),cBe.forEach(t),$do=i(L),bg=n(L,"LI",{});var mBe=s(bg);Ome=n(mBe,"STRONG",{});var L3t=s(Ome);kdo=r(L3t,"electra"),L3t.forEach(t),Sdo=r(mBe," \u2014 "),FN=n(mBe,"A",{href:!0});var y3t=s(FN);Rdo=r(y3t,"ElectraConfig"),y3t.forEach(t),Pdo=r(mBe," (ELECTRA model)"),mBe.forEach(t),Bdo=i(L),vg=n(L,"LI",{});var fBe=s(vg);Vme=n(fBe,"STRONG",{});var x3t=s(Vme);Ido=r(x3t,"encoder-decoder"),x3t.forEach(t),Ndo=r(fBe," \u2014 "),TN=n(fBe,"A",{href:!0});var $3t=s(TN);qdo=r($3t,"EncoderDecoderConfig"),$3t.forEach(t),jdo=r(fBe," (Encoder decoder model)"),fBe.forEach(t),Ddo=i(L),Fg=n(L,"LI",{});var gBe=s(Fg);Xme=n(gBe,"STRONG",{});var k3t=s(Xme);Gdo=r(k3t,"ernie"),k3t.forEach(t),Odo=r(gBe," \u2014 "),MN=n(gBe,"A",{href:!0});var S3t=s(MN);Vdo=r(S3t,"ErnieConfig"),S3t.forEach(t),Xdo=r(gBe," (ERNIE model)"),gBe.forEach(t),zdo=i(L),Tg=n(L,"LI",{});var hBe=s(Tg);zme=n(hBe,"STRONG",{});var R3t=s(zme);Qdo=r(R3t,"esm"),R3t.forEach(t),Wdo=r(hBe," \u2014 "),EN=n(hBe,"A",{href:!0});var P3t=s(EN);Udo=r(P3t,"EsmConfig"),P3t.forEach(t),Hdo=r(hBe," (ESM model)"),hBe.forEach(t),Jdo=i(L),Mg=n(L,"LI",{});var uBe=s(Mg);Qme=n(uBe,"STRONG",{});var B3t=s(Qme);Ydo=r(B3t,"flaubert"),B3t.forEach(t),Zdo=r(uBe," \u2014 "),CN=n(uBe,"A",{href:!0});var I3t=s(CN);Kdo=r(I3t,"FlaubertConfig"),I3t.forEach(t),eco=r(uBe," (FlauBERT model)"),uBe.forEach(t),oco=i(L),Eg=n(L,"LI",{});var pBe=s(Eg);Wme=n(pBe,"STRONG",{});var N3t=s(Wme);rco=r(N3t,"flava"),N3t.forEach(t),tco=r(pBe," \u2014 "),wN=n(pBe,"A",{href:!0});var q3t=s(wN);aco=r(q3t,"FlavaConfig"),q3t.forEach(t),nco=r(pBe," (FLAVA model)"),pBe.forEach(t),sco=i(L),Cg=n(L,"LI",{});var _Be=s(Cg);Ume=n(_Be,"STRONG",{});var j3t=s(Ume);lco=r(j3t,"fnet"),j3t.forEach(t),ico=r(_Be," \u2014 "),AN=n(_Be,"A",{href:!0});var D3t=s(AN);dco=r(D3t,"FNetConfig"),D3t.forEach(t),cco=r(_Be," (FNet model)"),_Be.forEach(t),mco=i(L),wg=n(L,"LI",{});var bBe=s(wg);Hme=n(bBe,"STRONG",{});var G3t=s(Hme);fco=r(G3t,"fsmt"),G3t.forEach(t),gco=r(bBe," \u2014 "),LN=n(bBe,"A",{href:!0});var O3t=s(LN);hco=r(O3t,"FSMTConfig"),O3t.forEach(t),uco=r(bBe," (FairSeq Machine-Translation model)"),bBe.forEach(t),pco=i(L),Ag=n(L,"LI",{});var vBe=s(Ag);Jme=n(vBe,"STRONG",{});var V3t=s(Jme);_co=r(V3t,"funnel"),V3t.forEach(t),bco=r(vBe," \u2014 "),yN=n(vBe,"A",{href:!0});var X3t=s(yN);vco=r(X3t,"FunnelConfig"),X3t.forEach(t),Fco=r(vBe," (Funnel Transformer model)"),vBe.forEach(t),Tco=i(L),Lg=n(L,"LI",{});var FBe=s(Lg);Yme=n(FBe,"STRONG",{});var z3t=s(Yme);Mco=r(z3t,"glpn"),z3t.forEach(t),Eco=r(FBe," \u2014 "),xN=n(FBe,"A",{href:!0});var Q3t=s(xN);Cco=r(Q3t,"GLPNConfig"),Q3t.forEach(t),wco=r(FBe," (GLPN model)"),FBe.forEach(t),Aco=i(L),yg=n(L,"LI",{});var TBe=s(yg);Zme=n(TBe,"STRONG",{});var W3t=s(Zme);Lco=r(W3t,"gpt2"),W3t.forEach(t),yco=r(TBe," \u2014 "),$N=n(TBe,"A",{href:!0});var U3t=s($N);xco=r(U3t,"GPT2Config"),U3t.forEach(t),$co=r(TBe," (OpenAI GPT-2 model)"),TBe.forEach(t),kco=i(L),xg=n(L,"LI",{});var MBe=s(xg);Kme=n(MBe,"STRONG",{});var H3t=s(Kme);Sco=r(H3t,"gpt_neo"),H3t.forEach(t),Rco=r(MBe," \u2014 "),kN=n(MBe,"A",{href:!0});var J3t=s(kN);Pco=r(J3t,"GPTNeoConfig"),J3t.forEach(t),Bco=r(MBe," (GPT Neo model)"),MBe.forEach(t),Ico=i(L),$g=n(L,"LI",{});var EBe=s($g);efe=n(EBe,"STRONG",{});var Y3t=s(efe);Nco=r(Y3t,"gpt_neox"),Y3t.forEach(t),qco=r(EBe," \u2014 "),SN=n(EBe,"A",{href:!0});var Z3t=s(SN);jco=r(Z3t,"GPTNeoXConfig"),Z3t.forEach(t),Dco=r(EBe," (GPT NeoX model)"),EBe.forEach(t),Gco=i(L),kg=n(L,"LI",{});var CBe=s(kg);ofe=n(CBe,"STRONG",{});var K3t=s(ofe);Oco=r(K3t,"gpt_neox_japanese"),K3t.forEach(t),Vco=r(CBe," \u2014 "),RN=n(CBe,"A",{href:!0});var e5t=s(RN);Xco=r(e5t,"GPTNeoXJapaneseConfig"),e5t.forEach(t),zco=r(CBe," (GPT NeoX Japanese model)"),CBe.forEach(t),Qco=i(L),Sg=n(L,"LI",{});var wBe=s(Sg);rfe=n(wBe,"STRONG",{});var o5t=s(rfe);Wco=r(o5t,"gptj"),o5t.forEach(t),Uco=r(wBe," \u2014 "),PN=n(wBe,"A",{href:!0});var r5t=s(PN);Hco=r(r5t,"GPTJConfig"),r5t.forEach(t),Jco=r(wBe," (GPT-J model)"),wBe.forEach(t),Yco=i(L),Rg=n(L,"LI",{});var ABe=s(Rg);tfe=n(ABe,"STRONG",{});var t5t=s(tfe);Zco=r(t5t,"groupvit"),t5t.forEach(t),Kco=r(ABe," \u2014 "),BN=n(ABe,"A",{href:!0});var a5t=s(BN);emo=r(a5t,"GroupViTConfig"),a5t.forEach(t),omo=r(ABe," (GroupViT model)"),ABe.forEach(t),rmo=i(L),Pg=n(L,"LI",{});var LBe=s(Pg);afe=n(LBe,"STRONG",{});var n5t=s(afe);tmo=r(n5t,"hubert"),n5t.forEach(t),amo=r(LBe," \u2014 "),IN=n(LBe,"A",{href:!0});var s5t=s(IN);nmo=r(s5t,"HubertConfig"),s5t.forEach(t),smo=r(LBe," (Hubert model)"),LBe.forEach(t),lmo=i(L),Bg=n(L,"LI",{});var yBe=s(Bg);nfe=n(yBe,"STRONG",{});var l5t=s(nfe);imo=r(l5t,"ibert"),l5t.forEach(t),dmo=r(yBe," \u2014 "),NN=n(yBe,"A",{href:!0});var i5t=s(NN);cmo=r(i5t,"IBertConfig"),i5t.forEach(t),mmo=r(yBe," (I-BERT model)"),yBe.forEach(t),fmo=i(L),Ig=n(L,"LI",{});var xBe=s(Ig);sfe=n(xBe,"STRONG",{});var d5t=s(sfe);gmo=r(d5t,"imagegpt"),d5t.forEach(t),hmo=r(xBe," \u2014 "),qN=n(xBe,"A",{href:!0});var c5t=s(qN);umo=r(c5t,"ImageGPTConfig"),c5t.forEach(t),pmo=r(xBe," (ImageGPT model)"),xBe.forEach(t),_mo=i(L),Ng=n(L,"LI",{});var $Be=s(Ng);lfe=n($Be,"STRONG",{});var m5t=s(lfe);bmo=r(m5t,"layoutlm"),m5t.forEach(t),vmo=r($Be," \u2014 "),jN=n($Be,"A",{href:!0});var f5t=s(jN);Fmo=r(f5t,"LayoutLMConfig"),f5t.forEach(t),Tmo=r($Be," (LayoutLM model)"),$Be.forEach(t),Mmo=i(L),qg=n(L,"LI",{});var kBe=s(qg);ife=n(kBe,"STRONG",{});var g5t=s(ife);Emo=r(g5t,"layoutlmv2"),g5t.forEach(t),Cmo=r(kBe," \u2014 "),DN=n(kBe,"A",{href:!0});var h5t=s(DN);wmo=r(h5t,"LayoutLMv2Config"),h5t.forEach(t),Amo=r(kBe," (LayoutLMv2 model)"),kBe.forEach(t),Lmo=i(L),jg=n(L,"LI",{});var SBe=s(jg);dfe=n(SBe,"STRONG",{});var u5t=s(dfe);ymo=r(u5t,"layoutlmv3"),u5t.forEach(t),xmo=r(SBe," \u2014 "),GN=n(SBe,"A",{href:!0});var p5t=s(GN);$mo=r(p5t,"LayoutLMv3Config"),p5t.forEach(t),kmo=r(SBe," (LayoutLMv3 model)"),SBe.forEach(t),Smo=i(L),Dg=n(L,"LI",{});var RBe=s(Dg);cfe=n(RBe,"STRONG",{});var _5t=s(cfe);Rmo=r(_5t,"led"),_5t.forEach(t),Pmo=r(RBe," \u2014 "),ON=n(RBe,"A",{href:!0});var b5t=s(ON);Bmo=r(b5t,"LEDConfig"),b5t.forEach(t),Imo=r(RBe," (LED model)"),RBe.forEach(t),Nmo=i(L),Gg=n(L,"LI",{});var PBe=s(Gg);mfe=n(PBe,"STRONG",{});var v5t=s(mfe);qmo=r(v5t,"levit"),v5t.forEach(t),jmo=r(PBe," \u2014 "),VN=n(PBe,"A",{href:!0});var F5t=s(VN);Dmo=r(F5t,"LevitConfig"),F5t.forEach(t),Gmo=r(PBe," (LeViT model)"),PBe.forEach(t),Omo=i(L),Og=n(L,"LI",{});var BBe=s(Og);ffe=n(BBe,"STRONG",{});var T5t=s(ffe);Vmo=r(T5t,"longformer"),T5t.forEach(t),Xmo=r(BBe," \u2014 "),XN=n(BBe,"A",{href:!0});var M5t=s(XN);zmo=r(M5t,"LongformerConfig"),M5t.forEach(t),Qmo=r(BBe," (Longformer model)"),BBe.forEach(t),Wmo=i(L),Vg=n(L,"LI",{});var IBe=s(Vg);gfe=n(IBe,"STRONG",{});var E5t=s(gfe);Umo=r(E5t,"longt5"),E5t.forEach(t),Hmo=r(IBe," \u2014 "),zN=n(IBe,"A",{href:!0});var C5t=s(zN);Jmo=r(C5t,"LongT5Config"),C5t.forEach(t),Ymo=r(IBe," (LongT5 model)"),IBe.forEach(t),Zmo=i(L),Xg=n(L,"LI",{});var NBe=s(Xg);hfe=n(NBe,"STRONG",{});var w5t=s(hfe);Kmo=r(w5t,"luke"),w5t.forEach(t),efo=r(NBe," \u2014 "),QN=n(NBe,"A",{href:!0});var A5t=s(QN);ofo=r(A5t,"LukeConfig"),A5t.forEach(t),rfo=r(NBe," (LUKE model)"),NBe.forEach(t),tfo=i(L),zg=n(L,"LI",{});var qBe=s(zg);ufe=n(qBe,"STRONG",{});var L5t=s(ufe);afo=r(L5t,"lxmert"),L5t.forEach(t),nfo=r(qBe," \u2014 "),WN=n(qBe,"A",{href:!0});var y5t=s(WN);sfo=r(y5t,"LxmertConfig"),y5t.forEach(t),lfo=r(qBe," (LXMERT model)"),qBe.forEach(t),ifo=i(L),Qg=n(L,"LI",{});var jBe=s(Qg);pfe=n(jBe,"STRONG",{});var x5t=s(pfe);dfo=r(x5t,"m2m_100"),x5t.forEach(t),cfo=r(jBe," \u2014 "),UN=n(jBe,"A",{href:!0});var $5t=s(UN);mfo=r($5t,"M2M100Config"),$5t.forEach(t),ffo=r(jBe," (M2M100 model)"),jBe.forEach(t),gfo=i(L),Wg=n(L,"LI",{});var DBe=s(Wg);_fe=n(DBe,"STRONG",{});var k5t=s(_fe);hfo=r(k5t,"marian"),k5t.forEach(t),ufo=r(DBe," \u2014 "),HN=n(DBe,"A",{href:!0});var S5t=s(HN);pfo=r(S5t,"MarianConfig"),S5t.forEach(t),_fo=r(DBe," (Marian model)"),DBe.forEach(t),bfo=i(L),Ug=n(L,"LI",{});var GBe=s(Ug);bfe=n(GBe,"STRONG",{});var R5t=s(bfe);vfo=r(R5t,"markuplm"),R5t.forEach(t),Ffo=r(GBe," \u2014 "),JN=n(GBe,"A",{href:!0});var P5t=s(JN);Tfo=r(P5t,"MarkupLMConfig"),P5t.forEach(t),Mfo=r(GBe," (MarkupLM model)"),GBe.forEach(t),Efo=i(L),Hg=n(L,"LI",{});var OBe=s(Hg);vfe=n(OBe,"STRONG",{});var B5t=s(vfe);Cfo=r(B5t,"maskformer"),B5t.forEach(t),wfo=r(OBe," \u2014 "),YN=n(OBe,"A",{href:!0});var I5t=s(YN);Afo=r(I5t,"MaskFormerConfig"),I5t.forEach(t),Lfo=r(OBe," (MaskFormer model)"),OBe.forEach(t),yfo=i(L),Jg=n(L,"LI",{});var VBe=s(Jg);Ffe=n(VBe,"STRONG",{});var N5t=s(Ffe);xfo=r(N5t,"mbart"),N5t.forEach(t),$fo=r(VBe," \u2014 "),ZN=n(VBe,"A",{href:!0});var q5t=s(ZN);kfo=r(q5t,"MBartConfig"),q5t.forEach(t),Sfo=r(VBe," (mBART model)"),VBe.forEach(t),Rfo=i(L),Yg=n(L,"LI",{});var XBe=s(Yg);Tfe=n(XBe,"STRONG",{});var j5t=s(Tfe);Pfo=r(j5t,"mctct"),j5t.forEach(t),Bfo=r(XBe," \u2014 "),KN=n(XBe,"A",{href:!0});var D5t=s(KN);Ifo=r(D5t,"MCTCTConfig"),D5t.forEach(t),Nfo=r(XBe," (M-CTC-T model)"),XBe.forEach(t),qfo=i(L),Zg=n(L,"LI",{});var zBe=s(Zg);Mfe=n(zBe,"STRONG",{});var G5t=s(Mfe);jfo=r(G5t,"megatron-bert"),G5t.forEach(t),Dfo=r(zBe," \u2014 "),eq=n(zBe,"A",{href:!0});var O5t=s(eq);Gfo=r(O5t,"MegatronBertConfig"),O5t.forEach(t),Ofo=r(zBe," (Megatron-BERT model)"),zBe.forEach(t),Vfo=i(L),Kg=n(L,"LI",{});var QBe=s(Kg);Efe=n(QBe,"STRONG",{});var V5t=s(Efe);Xfo=r(V5t,"mobilebert"),V5t.forEach(t),zfo=r(QBe," \u2014 "),oq=n(QBe,"A",{href:!0});var X5t=s(oq);Qfo=r(X5t,"MobileBertConfig"),X5t.forEach(t),Wfo=r(QBe," (MobileBERT model)"),QBe.forEach(t),Ufo=i(L),eh=n(L,"LI",{});var WBe=s(eh);Cfe=n(WBe,"STRONG",{});var z5t=s(Cfe);Hfo=r(z5t,"mobilevit"),z5t.forEach(t),Jfo=r(WBe," \u2014 "),rq=n(WBe,"A",{href:!0});var Q5t=s(rq);Yfo=r(Q5t,"MobileViTConfig"),Q5t.forEach(t),Zfo=r(WBe," (MobileViT model)"),WBe.forEach(t),Kfo=i(L),oh=n(L,"LI",{});var UBe=s(oh);wfe=n(UBe,"STRONG",{});var W5t=s(wfe);ego=r(W5t,"mpnet"),W5t.forEach(t),ogo=r(UBe," \u2014 "),tq=n(UBe,"A",{href:!0});var U5t=s(tq);rgo=r(U5t,"MPNetConfig"),U5t.forEach(t),tgo=r(UBe," (MPNet model)"),UBe.forEach(t),ago=i(L),rh=n(L,"LI",{});var HBe=s(rh);Afe=n(HBe,"STRONG",{});var H5t=s(Afe);ngo=r(H5t,"mt5"),H5t.forEach(t),sgo=r(HBe," \u2014 "),aq=n(HBe,"A",{href:!0});var J5t=s(aq);lgo=r(J5t,"MT5Config"),J5t.forEach(t),igo=r(HBe," (MT5 model)"),HBe.forEach(t),dgo=i(L),th=n(L,"LI",{});var JBe=s(th);Lfe=n(JBe,"STRONG",{});var Y5t=s(Lfe);cgo=r(Y5t,"mvp"),Y5t.forEach(t),mgo=r(JBe," \u2014 "),nq=n(JBe,"A",{href:!0});var Z5t=s(nq);fgo=r(Z5t,"MvpConfig"),Z5t.forEach(t),ggo=r(JBe," (MVP model)"),JBe.forEach(t),hgo=i(L),ah=n(L,"LI",{});var YBe=s(ah);yfe=n(YBe,"STRONG",{});var K5t=s(yfe);ugo=r(K5t,"nezha"),K5t.forEach(t),pgo=r(YBe," \u2014 "),sq=n(YBe,"A",{href:!0});var e0t=s(sq);_go=r(e0t,"NezhaConfig"),e0t.forEach(t),bgo=r(YBe," (Nezha model)"),YBe.forEach(t),vgo=i(L),nh=n(L,"LI",{});var ZBe=s(nh);xfe=n(ZBe,"STRONG",{});var o0t=s(xfe);Fgo=r(o0t,"nystromformer"),o0t.forEach(t),Tgo=r(ZBe," \u2014 "),lq=n(ZBe,"A",{href:!0});var r0t=s(lq);Mgo=r(r0t,"NystromformerConfig"),r0t.forEach(t),Ego=r(ZBe," (Nystr\xF6mformer model)"),ZBe.forEach(t),Cgo=i(L),sh=n(L,"LI",{});var KBe=s(sh);$fe=n(KBe,"STRONG",{});var t0t=s($fe);wgo=r(t0t,"openai-gpt"),t0t.forEach(t),Ago=r(KBe," \u2014 "),iq=n(KBe,"A",{href:!0});var a0t=s(iq);Lgo=r(a0t,"OpenAIGPTConfig"),a0t.forEach(t),ygo=r(KBe," (OpenAI GPT model)"),KBe.forEach(t),xgo=i(L),lh=n(L,"LI",{});var eIe=s(lh);kfe=n(eIe,"STRONG",{});var n0t=s(kfe);$go=r(n0t,"opt"),n0t.forEach(t),kgo=r(eIe," \u2014 "),dq=n(eIe,"A",{href:!0});var s0t=s(dq);Sgo=r(s0t,"OPTConfig"),s0t.forEach(t),Rgo=r(eIe," (OPT model)"),eIe.forEach(t),Pgo=i(L),ih=n(L,"LI",{});var oIe=s(ih);Sfe=n(oIe,"STRONG",{});var l0t=s(Sfe);Bgo=r(l0t,"owlvit"),l0t.forEach(t),Igo=r(oIe," \u2014 "),cq=n(oIe,"A",{href:!0});var i0t=s(cq);Ngo=r(i0t,"OwlViTConfig"),i0t.forEach(t),qgo=r(oIe," (OWL-ViT model)"),oIe.forEach(t),jgo=i(L),dh=n(L,"LI",{});var rIe=s(dh);Rfe=n(rIe,"STRONG",{});var d0t=s(Rfe);Dgo=r(d0t,"pegasus"),d0t.forEach(t),Ggo=r(rIe," \u2014 "),mq=n(rIe,"A",{href:!0});var c0t=s(mq);Ogo=r(c0t,"PegasusConfig"),c0t.forEach(t),Vgo=r(rIe," (Pegasus model)"),rIe.forEach(t),Xgo=i(L),ch=n(L,"LI",{});var tIe=s(ch);Pfe=n(tIe,"STRONG",{});var m0t=s(Pfe);zgo=r(m0t,"pegasus_x"),m0t.forEach(t),Qgo=r(tIe," \u2014 "),fq=n(tIe,"A",{href:!0});var f0t=s(fq);Wgo=r(f0t,"PegasusXConfig"),f0t.forEach(t),Ugo=r(tIe," (PEGASUS-X model)"),tIe.forEach(t),Hgo=i(L),mh=n(L,"LI",{});var aIe=s(mh);Bfe=n(aIe,"STRONG",{});var g0t=s(Bfe);Jgo=r(g0t,"perceiver"),g0t.forEach(t),Ygo=r(aIe," \u2014 "),gq=n(aIe,"A",{href:!0});var h0t=s(gq);Zgo=r(h0t,"PerceiverConfig"),h0t.forEach(t),Kgo=r(aIe," (Perceiver model)"),aIe.forEach(t),eho=i(L),fh=n(L,"LI",{});var nIe=s(fh);Ife=n(nIe,"STRONG",{});var u0t=s(Ife);oho=r(u0t,"plbart"),u0t.forEach(t),rho=r(nIe," \u2014 "),hq=n(nIe,"A",{href:!0});var p0t=s(hq);tho=r(p0t,"PLBartConfig"),p0t.forEach(t),aho=r(nIe," (PLBart model)"),nIe.forEach(t),nho=i(L),gh=n(L,"LI",{});var sIe=s(gh);Nfe=n(sIe,"STRONG",{});var _0t=s(Nfe);sho=r(_0t,"poolformer"),_0t.forEach(t),lho=r(sIe," \u2014 "),uq=n(sIe,"A",{href:!0});var b0t=s(uq);iho=r(b0t,"PoolFormerConfig"),b0t.forEach(t),dho=r(sIe," (PoolFormer model)"),sIe.forEach(t),cho=i(L),hh=n(L,"LI",{});var lIe=s(hh);qfe=n(lIe,"STRONG",{});var v0t=s(qfe);mho=r(v0t,"prophetnet"),v0t.forEach(t),fho=r(lIe," \u2014 "),pq=n(lIe,"A",{href:!0});var F0t=s(pq);gho=r(F0t,"ProphetNetConfig"),F0t.forEach(t),hho=r(lIe," (ProphetNet model)"),lIe.forEach(t),uho=i(L),uh=n(L,"LI",{});var iIe=s(uh);jfe=n(iIe,"STRONG",{});var T0t=s(jfe);pho=r(T0t,"qdqbert"),T0t.forEach(t),_ho=r(iIe," \u2014 "),_q=n(iIe,"A",{href:!0});var M0t=s(_q);bho=r(M0t,"QDQBertConfig"),M0t.forEach(t),vho=r(iIe," (QDQBert model)"),iIe.forEach(t),Fho=i(L),ph=n(L,"LI",{});var dIe=s(ph);Dfe=n(dIe,"STRONG",{});var E0t=s(Dfe);Tho=r(E0t,"rag"),E0t.forEach(t),Mho=r(dIe," \u2014 "),bq=n(dIe,"A",{href:!0});var C0t=s(bq);Eho=r(C0t,"RagConfig"),C0t.forEach(t),Cho=r(dIe," (RAG model)"),dIe.forEach(t),who=i(L),_h=n(L,"LI",{});var cIe=s(_h);Gfe=n(cIe,"STRONG",{});var w0t=s(Gfe);Aho=r(w0t,"realm"),w0t.forEach(t),Lho=r(cIe," \u2014 "),vq=n(cIe,"A",{href:!0});var A0t=s(vq);yho=r(A0t,"RealmConfig"),A0t.forEach(t),xho=r(cIe," (REALM model)"),cIe.forEach(t),$ho=i(L),bh=n(L,"LI",{});var mIe=s(bh);Ofe=n(mIe,"STRONG",{});var L0t=s(Ofe);kho=r(L0t,"reformer"),L0t.forEach(t),Sho=r(mIe," \u2014 "),Fq=n(mIe,"A",{href:!0});var y0t=s(Fq);Rho=r(y0t,"ReformerConfig"),y0t.forEach(t),Pho=r(mIe," (Reformer model)"),mIe.forEach(t),Bho=i(L),vh=n(L,"LI",{});var fIe=s(vh);Vfe=n(fIe,"STRONG",{});var x0t=s(Vfe);Iho=r(x0t,"regnet"),x0t.forEach(t),Nho=r(fIe," \u2014 "),Tq=n(fIe,"A",{href:!0});var $0t=s(Tq);qho=r($0t,"RegNetConfig"),$0t.forEach(t),jho=r(fIe," (RegNet model)"),fIe.forEach(t),Dho=i(L),Fh=n(L,"LI",{});var gIe=s(Fh);Xfe=n(gIe,"STRONG",{});var k0t=s(Xfe);Gho=r(k0t,"rembert"),k0t.forEach(t),Oho=r(gIe," \u2014 "),Mq=n(gIe,"A",{href:!0});var S0t=s(Mq);Vho=r(S0t,"RemBertConfig"),S0t.forEach(t),Xho=r(gIe," (RemBERT model)"),gIe.forEach(t),zho=i(L),Th=n(L,"LI",{});var hIe=s(Th);zfe=n(hIe,"STRONG",{});var R0t=s(zfe);Qho=r(R0t,"resnet"),R0t.forEach(t),Who=r(hIe," \u2014 "),Eq=n(hIe,"A",{href:!0});var P0t=s(Eq);Uho=r(P0t,"ResNetConfig"),P0t.forEach(t),Hho=r(hIe," (ResNet model)"),hIe.forEach(t),Jho=i(L),Mh=n(L,"LI",{});var uIe=s(Mh);Qfe=n(uIe,"STRONG",{});var B0t=s(Qfe);Yho=r(B0t,"retribert"),B0t.forEach(t),Zho=r(uIe," \u2014 "),Cq=n(uIe,"A",{href:!0});var I0t=s(Cq);Kho=r(I0t,"RetriBertConfig"),I0t.forEach(t),euo=r(uIe," (RetriBERT model)"),uIe.forEach(t),ouo=i(L),Eh=n(L,"LI",{});var pIe=s(Eh);Wfe=n(pIe,"STRONG",{});var N0t=s(Wfe);ruo=r(N0t,"roberta"),N0t.forEach(t),tuo=r(pIe," \u2014 "),wq=n(pIe,"A",{href:!0});var q0t=s(wq);auo=r(q0t,"RobertaConfig"),q0t.forEach(t),nuo=r(pIe," (RoBERTa model)"),pIe.forEach(t),suo=i(L),Ch=n(L,"LI",{});var _Ie=s(Ch);Ufe=n(_Ie,"STRONG",{});var j0t=s(Ufe);luo=r(j0t,"roformer"),j0t.forEach(t),iuo=r(_Ie," \u2014 "),Aq=n(_Ie,"A",{href:!0});var D0t=s(Aq);duo=r(D0t,"RoFormerConfig"),D0t.forEach(t),cuo=r(_Ie," (RoFormer model)"),_Ie.forEach(t),muo=i(L),wh=n(L,"LI",{});var bIe=s(wh);Hfe=n(bIe,"STRONG",{});var G0t=s(Hfe);fuo=r(G0t,"segformer"),G0t.forEach(t),guo=r(bIe," \u2014 "),Lq=n(bIe,"A",{href:!0});var O0t=s(Lq);huo=r(O0t,"SegformerConfig"),O0t.forEach(t),uuo=r(bIe," (SegFormer model)"),bIe.forEach(t),puo=i(L),Ah=n(L,"LI",{});var vIe=s(Ah);Jfe=n(vIe,"STRONG",{});var V0t=s(Jfe);_uo=r(V0t,"sew"),V0t.forEach(t),buo=r(vIe," \u2014 "),yq=n(vIe,"A",{href:!0});var X0t=s(yq);vuo=r(X0t,"SEWConfig"),X0t.forEach(t),Fuo=r(vIe," (SEW model)"),vIe.forEach(t),Tuo=i(L),Lh=n(L,"LI",{});var FIe=s(Lh);Yfe=n(FIe,"STRONG",{});var z0t=s(Yfe);Muo=r(z0t,"sew-d"),z0t.forEach(t),Euo=r(FIe," \u2014 "),xq=n(FIe,"A",{href:!0});var Q0t=s(xq);Cuo=r(Q0t,"SEWDConfig"),Q0t.forEach(t),wuo=r(FIe," (SEW-D model)"),FIe.forEach(t),Auo=i(L),yh=n(L,"LI",{});var TIe=s(yh);Zfe=n(TIe,"STRONG",{});var W0t=s(Zfe);Luo=r(W0t,"speech-encoder-decoder"),W0t.forEach(t),yuo=r(TIe," \u2014 "),$q=n(TIe,"A",{href:!0});var U0t=s($q);xuo=r(U0t,"SpeechEncoderDecoderConfig"),U0t.forEach(t),$uo=r(TIe," (Speech Encoder decoder model)"),TIe.forEach(t),kuo=i(L),xh=n(L,"LI",{});var MIe=s(xh);Kfe=n(MIe,"STRONG",{});var H0t=s(Kfe);Suo=r(H0t,"speech_to_text"),H0t.forEach(t),Ruo=r(MIe," \u2014 "),kq=n(MIe,"A",{href:!0});var J0t=s(kq);Puo=r(J0t,"Speech2TextConfig"),J0t.forEach(t),Buo=r(MIe," (Speech2Text model)"),MIe.forEach(t),Iuo=i(L),$h=n(L,"LI",{});var EIe=s($h);ege=n(EIe,"STRONG",{});var Y0t=s(ege);Nuo=r(Y0t,"speech_to_text_2"),Y0t.forEach(t),quo=r(EIe," \u2014 "),Sq=n(EIe,"A",{href:!0});var Z0t=s(Sq);juo=r(Z0t,"Speech2Text2Config"),Z0t.forEach(t),Duo=r(EIe," (Speech2Text2 model)"),EIe.forEach(t),Guo=i(L),kh=n(L,"LI",{});var CIe=s(kh);oge=n(CIe,"STRONG",{});var K0t=s(oge);Ouo=r(K0t,"splinter"),K0t.forEach(t),Vuo=r(CIe," \u2014 "),Rq=n(CIe,"A",{href:!0});var ewt=s(Rq);Xuo=r(ewt,"SplinterConfig"),ewt.forEach(t),zuo=r(CIe," (Splinter model)"),CIe.forEach(t),Quo=i(L),Sh=n(L,"LI",{});var wIe=s(Sh);rge=n(wIe,"STRONG",{});var owt=s(rge);Wuo=r(owt,"squeezebert"),owt.forEach(t),Uuo=r(wIe," \u2014 "),Pq=n(wIe,"A",{href:!0});var rwt=s(Pq);Huo=r(rwt,"SqueezeBertConfig"),rwt.forEach(t),Juo=r(wIe," (SqueezeBERT model)"),wIe.forEach(t),Yuo=i(L),Rh=n(L,"LI",{});var AIe=s(Rh);tge=n(AIe,"STRONG",{});var twt=s(tge);Zuo=r(twt,"swin"),twt.forEach(t),Kuo=r(AIe," \u2014 "),Bq=n(AIe,"A",{href:!0});var awt=s(Bq);epo=r(awt,"SwinConfig"),awt.forEach(t),opo=r(AIe," (Swin Transformer model)"),AIe.forEach(t),rpo=i(L),Ph=n(L,"LI",{});var LIe=s(Ph);age=n(LIe,"STRONG",{});var nwt=s(age);tpo=r(nwt,"swinv2"),nwt.forEach(t),apo=r(LIe," \u2014 "),Iq=n(LIe,"A",{href:!0});var swt=s(Iq);npo=r(swt,"Swinv2Config"),swt.forEach(t),spo=r(LIe," (Swin Transformer V2 model)"),LIe.forEach(t),lpo=i(L),Bh=n(L,"LI",{});var yIe=s(Bh);nge=n(yIe,"STRONG",{});var lwt=s(nge);ipo=r(lwt,"t5"),lwt.forEach(t),dpo=r(yIe," \u2014 "),Nq=n(yIe,"A",{href:!0});var iwt=s(Nq);cpo=r(iwt,"T5Config"),iwt.forEach(t),mpo=r(yIe," (T5 model)"),yIe.forEach(t),fpo=i(L),Ih=n(L,"LI",{});var xIe=s(Ih);sge=n(xIe,"STRONG",{});var dwt=s(sge);gpo=r(dwt,"tapas"),dwt.forEach(t),hpo=r(xIe," \u2014 "),qq=n(xIe,"A",{href:!0});var cwt=s(qq);upo=r(cwt,"TapasConfig"),cwt.forEach(t),ppo=r(xIe," (TAPAS model)"),xIe.forEach(t),_po=i(L),Nh=n(L,"LI",{});var $Ie=s(Nh);lge=n($Ie,"STRONG",{});var mwt=s(lge);bpo=r(mwt,"time_series_transformer"),mwt.forEach(t),vpo=r($Ie," \u2014 "),jq=n($Ie,"A",{href:!0});var fwt=s(jq);Fpo=r(fwt,"TimeSeriesTransformerConfig"),fwt.forEach(t),Tpo=r($Ie," (Time Series Transformer model)"),$Ie.forEach(t),Mpo=i(L),qh=n(L,"LI",{});var kIe=s(qh);ige=n(kIe,"STRONG",{});var gwt=s(ige);Epo=r(gwt,"trajectory_transformer"),gwt.forEach(t),Cpo=r(kIe," \u2014 "),Dq=n(kIe,"A",{href:!0});var hwt=s(Dq);wpo=r(hwt,"TrajectoryTransformerConfig"),hwt.forEach(t),Apo=r(kIe," (Trajectory Transformer model)"),kIe.forEach(t),Lpo=i(L),jh=n(L,"LI",{});var SIe=s(jh);dge=n(SIe,"STRONG",{});var uwt=s(dge);ypo=r(uwt,"transfo-xl"),uwt.forEach(t),xpo=r(SIe," \u2014 "),Gq=n(SIe,"A",{href:!0});var pwt=s(Gq);$po=r(pwt,"TransfoXLConfig"),pwt.forEach(t),kpo=r(SIe," (Transformer-XL model)"),SIe.forEach(t),Spo=i(L),Dh=n(L,"LI",{});var RIe=s(Dh);cge=n(RIe,"STRONG",{});var _wt=s(cge);Rpo=r(_wt,"trocr"),_wt.forEach(t),Ppo=r(RIe," \u2014 "),Oq=n(RIe,"A",{href:!0});var bwt=s(Oq);Bpo=r(bwt,"TrOCRConfig"),bwt.forEach(t),Ipo=r(RIe," (TrOCR model)"),RIe.forEach(t),Npo=i(L),Gh=n(L,"LI",{});var PIe=s(Gh);mge=n(PIe,"STRONG",{});var vwt=s(mge);qpo=r(vwt,"unispeech"),vwt.forEach(t),jpo=r(PIe," \u2014 "),Vq=n(PIe,"A",{href:!0});var Fwt=s(Vq);Dpo=r(Fwt,"UniSpeechConfig"),Fwt.forEach(t),Gpo=r(PIe," (UniSpeech model)"),PIe.forEach(t),Opo=i(L),Oh=n(L,"LI",{});var BIe=s(Oh);fge=n(BIe,"STRONG",{});var Twt=s(fge);Vpo=r(Twt,"unispeech-sat"),Twt.forEach(t),Xpo=r(BIe," \u2014 "),Xq=n(BIe,"A",{href:!0});var Mwt=s(Xq);zpo=r(Mwt,"UniSpeechSatConfig"),Mwt.forEach(t),Qpo=r(BIe," (UniSpeechSat model)"),BIe.forEach(t),Wpo=i(L),Vh=n(L,"LI",{});var IIe=s(Vh);gge=n(IIe,"STRONG",{});var Ewt=s(gge);Upo=r(Ewt,"van"),Ewt.forEach(t),Hpo=r(IIe," \u2014 "),zq=n(IIe,"A",{href:!0});var Cwt=s(zq);Jpo=r(Cwt,"VanConfig"),Cwt.forEach(t),Ypo=r(IIe," (VAN model)"),IIe.forEach(t),Zpo=i(L),Xh=n(L,"LI",{});var NIe=s(Xh);hge=n(NIe,"STRONG",{});var wwt=s(hge);Kpo=r(wwt,"videomae"),wwt.forEach(t),e_o=r(NIe," \u2014 "),Qq=n(NIe,"A",{href:!0});var Awt=s(Qq);o_o=r(Awt,"VideoMAEConfig"),Awt.forEach(t),r_o=r(NIe," (VideoMAE model)"),NIe.forEach(t),t_o=i(L),zh=n(L,"LI",{});var qIe=s(zh);uge=n(qIe,"STRONG",{});var Lwt=s(uge);a_o=r(Lwt,"vilt"),Lwt.forEach(t),n_o=r(qIe," \u2014 "),Wq=n(qIe,"A",{href:!0});var ywt=s(Wq);s_o=r(ywt,"ViltConfig"),ywt.forEach(t),l_o=r(qIe," (ViLT model)"),qIe.forEach(t),i_o=i(L),Qh=n(L,"LI",{});var jIe=s(Qh);pge=n(jIe,"STRONG",{});var xwt=s(pge);d_o=r(xwt,"vision-encoder-decoder"),xwt.forEach(t),c_o=r(jIe," \u2014 "),Uq=n(jIe,"A",{href:!0});var $wt=s(Uq);m_o=r($wt,"VisionEncoderDecoderConfig"),$wt.forEach(t),f_o=r(jIe," (Vision Encoder decoder model)"),jIe.forEach(t),g_o=i(L),Wh=n(L,"LI",{});var DIe=s(Wh);_ge=n(DIe,"STRONG",{});var kwt=s(_ge);h_o=r(kwt,"vision-text-dual-encoder"),kwt.forEach(t),u_o=r(DIe," \u2014 "),Hq=n(DIe,"A",{href:!0});var Swt=s(Hq);p_o=r(Swt,"VisionTextDualEncoderConfig"),Swt.forEach(t),__o=r(DIe," (VisionTextDualEncoder model)"),DIe.forEach(t),b_o=i(L),Uh=n(L,"LI",{});var GIe=s(Uh);bge=n(GIe,"STRONG",{});var Rwt=s(bge);v_o=r(Rwt,"visual_bert"),Rwt.forEach(t),F_o=r(GIe," \u2014 "),Jq=n(GIe,"A",{href:!0});var Pwt=s(Jq);T_o=r(Pwt,"VisualBertConfig"),Pwt.forEach(t),M_o=r(GIe," (VisualBERT model)"),GIe.forEach(t),E_o=i(L),Hh=n(L,"LI",{});var OIe=s(Hh);vge=n(OIe,"STRONG",{});var Bwt=s(vge);C_o=r(Bwt,"vit"),Bwt.forEach(t),w_o=r(OIe," \u2014 "),Yq=n(OIe,"A",{href:!0});var Iwt=s(Yq);A_o=r(Iwt,"ViTConfig"),Iwt.forEach(t),L_o=r(OIe," (ViT model)"),OIe.forEach(t),y_o=i(L),Jh=n(L,"LI",{});var VIe=s(Jh);Fge=n(VIe,"STRONG",{});var Nwt=s(Fge);x_o=r(Nwt,"vit_mae"),Nwt.forEach(t),$_o=r(VIe," \u2014 "),Zq=n(VIe,"A",{href:!0});var qwt=s(Zq);k_o=r(qwt,"ViTMAEConfig"),qwt.forEach(t),S_o=r(VIe," (ViTMAE model)"),VIe.forEach(t),R_o=i(L),Yh=n(L,"LI",{});var XIe=s(Yh);Tge=n(XIe,"STRONG",{});var jwt=s(Tge);P_o=r(jwt,"vit_msn"),jwt.forEach(t),B_o=r(XIe," \u2014 "),Kq=n(XIe,"A",{href:!0});var Dwt=s(Kq);I_o=r(Dwt,"ViTMSNConfig"),Dwt.forEach(t),N_o=r(XIe," (ViTMSN model)"),XIe.forEach(t),q_o=i(L),Zh=n(L,"LI",{});var zIe=s(Zh);Mge=n(zIe,"STRONG",{});var Gwt=s(Mge);j_o=r(Gwt,"wav2vec2"),Gwt.forEach(t),D_o=r(zIe," \u2014 "),ej=n(zIe,"A",{href:!0});var Owt=s(ej);G_o=r(Owt,"Wav2Vec2Config"),Owt.forEach(t),O_o=r(zIe," (Wav2Vec2 model)"),zIe.forEach(t),V_o=i(L),Kh=n(L,"LI",{});var QIe=s(Kh);Ege=n(QIe,"STRONG",{});var Vwt=s(Ege);X_o=r(Vwt,"wav2vec2-conformer"),Vwt.forEach(t),z_o=r(QIe," \u2014 "),oj=n(QIe,"A",{href:!0});var Xwt=s(oj);Q_o=r(Xwt,"Wav2Vec2ConformerConfig"),Xwt.forEach(t),W_o=r(QIe," (Wav2Vec2-Conformer model)"),QIe.forEach(t),U_o=i(L),eu=n(L,"LI",{});var WIe=s(eu);Cge=n(WIe,"STRONG",{});var zwt=s(Cge);H_o=r(zwt,"wavlm"),zwt.forEach(t),J_o=r(WIe," \u2014 "),rj=n(WIe,"A",{href:!0});var Qwt=s(rj);Y_o=r(Qwt,"WavLMConfig"),Qwt.forEach(t),Z_o=r(WIe," (WavLM model)"),WIe.forEach(t),K_o=i(L),ou=n(L,"LI",{});var UIe=s(ou);wge=n(UIe,"STRONG",{});var Wwt=s(wge);e1o=r(Wwt,"whisper"),Wwt.forEach(t),o1o=r(UIe," \u2014 "),tj=n(UIe,"A",{href:!0});var Uwt=s(tj);r1o=r(Uwt,"WhisperConfig"),Uwt.forEach(t),t1o=r(UIe," (Whisper model)"),UIe.forEach(t),a1o=i(L),ru=n(L,"LI",{});var HIe=s(ru);Age=n(HIe,"STRONG",{});var Hwt=s(Age);n1o=r(Hwt,"xclip"),Hwt.forEach(t),s1o=r(HIe," \u2014 "),aj=n(HIe,"A",{href:!0});var Jwt=s(aj);l1o=r(Jwt,"XCLIPConfig"),Jwt.forEach(t),i1o=r(HIe," (X-CLIP model)"),HIe.forEach(t),d1o=i(L),tu=n(L,"LI",{});var JIe=s(tu);Lge=n(JIe,"STRONG",{});var Ywt=s(Lge);c1o=r(Ywt,"xglm"),Ywt.forEach(t),m1o=r(JIe," \u2014 "),nj=n(JIe,"A",{href:!0});var Zwt=s(nj);f1o=r(Zwt,"XGLMConfig"),Zwt.forEach(t),g1o=r(JIe," (XGLM model)"),JIe.forEach(t),h1o=i(L),au=n(L,"LI",{});var YIe=s(au);yge=n(YIe,"STRONG",{});var Kwt=s(yge);u1o=r(Kwt,"xlm"),Kwt.forEach(t),p1o=r(YIe," \u2014 "),sj=n(YIe,"A",{href:!0});var eAt=s(sj);_1o=r(eAt,"XLMConfig"),eAt.forEach(t),b1o=r(YIe," (XLM model)"),YIe.forEach(t),v1o=i(L),nu=n(L,"LI",{});var ZIe=s(nu);xge=n(ZIe,"STRONG",{});var oAt=s(xge);F1o=r(oAt,"xlm-prophetnet"),oAt.forEach(t),T1o=r(ZIe," \u2014 "),lj=n(ZIe,"A",{href:!0});var rAt=s(lj);M1o=r(rAt,"XLMProphetNetConfig"),rAt.forEach(t),E1o=r(ZIe," (XLM-ProphetNet model)"),ZIe.forEach(t),C1o=i(L),su=n(L,"LI",{});var KIe=s(su);$ge=n(KIe,"STRONG",{});var tAt=s($ge);w1o=r(tAt,"xlm-roberta"),tAt.forEach(t),A1o=r(KIe," \u2014 "),ij=n(KIe,"A",{href:!0});var aAt=s(ij);L1o=r(aAt,"XLMRobertaConfig"),aAt.forEach(t),y1o=r(KIe," (XLM-RoBERTa model)"),KIe.forEach(t),x1o=i(L),lu=n(L,"LI",{});var eNe=s(lu);kge=n(eNe,"STRONG",{});var nAt=s(kge);$1o=r(nAt,"xlm-roberta-xl"),nAt.forEach(t),k1o=r(eNe," \u2014 "),dj=n(eNe,"A",{href:!0});var sAt=s(dj);S1o=r(sAt,"XLMRobertaXLConfig"),sAt.forEach(t),R1o=r(eNe," (XLM-RoBERTa-XL model)"),eNe.forEach(t),P1o=i(L),iu=n(L,"LI",{});var oNe=s(iu);Sge=n(oNe,"STRONG",{});var lAt=s(Sge);B1o=r(lAt,"xlnet"),lAt.forEach(t),I1o=r(oNe," \u2014 "),cj=n(oNe,"A",{href:!0});var iAt=s(cj);N1o=r(iAt,"XLNetConfig"),iAt.forEach(t),q1o=r(oNe," (XLNet model)"),oNe.forEach(t),j1o=i(L),du=n(L,"LI",{});var rNe=s(du);Rge=n(rNe,"STRONG",{});var dAt=s(Rge);D1o=r(dAt,"yolos"),dAt.forEach(t),G1o=r(rNe," \u2014 "),mj=n(rNe,"A",{href:!0});var cAt=s(mj);O1o=r(cAt,"YolosConfig"),cAt.forEach(t),V1o=r(rNe," (YOLOS model)"),rNe.forEach(t),X1o=i(L),cu=n(L,"LI",{});var tNe=s(cu);Pge=n(tNe,"STRONG",{});var mAt=s(Pge);z1o=r(mAt,"yoso"),mAt.forEach(t),Q1o=r(tNe," \u2014 "),fj=n(tNe,"A",{href:!0});var fAt=s(fj);W1o=r(fAt,"YosoConfig"),fAt.forEach(t),U1o=r(tNe," (YOSO model)"),tNe.forEach(t),L.forEach(t),H1o=i(_t),T(mu.$$.fragment,_t),_t.forEach(t),J1o=i(pt),fu=n(pt,"DIV",{class:!0});var Dto=s(fu);T(Nx.$$.fragment,Dto),Y1o=i(Dto),Bge=n(Dto,"P",{});var gAt=s(Bge);Z1o=r(gAt,"Register a new configuration for this class."),gAt.forEach(t),Dto.forEach(t),pt.forEach(t),koo=i(m),vd=n(m,"H2",{class:!0});var Gto=s(vd);gu=n(Gto,"A",{id:!0,class:!0,href:!0});var hAt=s(gu);Ige=n(hAt,"SPAN",{});var uAt=s(Ige);T(qx.$$.fragment,uAt),uAt.forEach(t),hAt.forEach(t),K1o=i(Gto),Nge=n(Gto,"SPAN",{});var pAt=s(Nge);e2o=r(pAt,"AutoTokenizer"),pAt.forEach(t),Gto.forEach(t),Soo=i(m),So=n(m,"DIV",{class:!0});var Ll=s(So);T(jx.$$.fragment,Ll),o2o=i(Ll),Dx=n(Ll,"P",{});var Oto=s(Dx);r2o=r(Oto,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),gj=n(Oto,"A",{href:!0});var _At=s(gj);t2o=r(_At,"AutoTokenizer.from_pretrained()"),_At.forEach(t),a2o=r(Oto," class method."),Oto.forEach(t),n2o=i(Ll),Gx=n(Ll,"P",{});var Vto=s(Gx);s2o=r(Vto,"This class cannot be instantiated directly using "),qge=n(Vto,"CODE",{});var bAt=s(qge);l2o=r(bAt,"__init__()"),bAt.forEach(t),i2o=r(Vto," (throws an error)."),Vto.forEach(t),d2o=i(Ll),Nr=n(Ll,"DIV",{class:!0});var yl=s(Nr);T(Ox.$$.fragment,yl),c2o=i(yl),jge=n(yl,"P",{});var vAt=s(jge);m2o=r(vAt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),vAt.forEach(t),f2o=i(yl),Za=n(yl,"P",{});var Fy=s(Za);g2o=r(Fy,"The tokenizer class to instantiate is selected based on the "),Dge=n(Fy,"CODE",{});var FAt=s(Dge);h2o=r(FAt,"model_type"),FAt.forEach(t),u2o=r(Fy,` property of the config object (either
passed as an argument or loaded from `),Gge=n(Fy,"CODE",{});var TAt=s(Gge);p2o=r(TAt,"pretrained_model_name_or_path"),TAt.forEach(t),_2o=r(Fy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oge=n(Fy,"CODE",{});var MAt=s(Oge);b2o=r(MAt,"pretrained_model_name_or_path"),MAt.forEach(t),v2o=r(Fy,":"),Fy.forEach(t),F2o=i(yl),k=n(yl,"UL",{});var S=s(k);cs=n(S,"LI",{});var bB=s(cs);Vge=n(bB,"STRONG",{});var EAt=s(Vge);T2o=r(EAt,"albert"),EAt.forEach(t),M2o=r(bB," \u2014 "),hj=n(bB,"A",{href:!0});var CAt=s(hj);E2o=r(CAt,"AlbertTokenizer"),CAt.forEach(t),C2o=r(bB," or "),uj=n(bB,"A",{href:!0});var wAt=s(uj);w2o=r(wAt,"AlbertTokenizerFast"),wAt.forEach(t),A2o=r(bB," (ALBERT model)"),bB.forEach(t),L2o=i(S),ms=n(S,"LI",{});var vB=s(ms);Xge=n(vB,"STRONG",{});var AAt=s(Xge);y2o=r(AAt,"bart"),AAt.forEach(t),x2o=r(vB," \u2014 "),pj=n(vB,"A",{href:!0});var LAt=s(pj);$2o=r(LAt,"BartTokenizer"),LAt.forEach(t),k2o=r(vB," or "),_j=n(vB,"A",{href:!0});var yAt=s(_j);S2o=r(yAt,"BartTokenizerFast"),yAt.forEach(t),R2o=r(vB," (BART model)"),vB.forEach(t),P2o=i(S),fs=n(S,"LI",{});var FB=s(fs);zge=n(FB,"STRONG",{});var xAt=s(zge);B2o=r(xAt,"barthez"),xAt.forEach(t),I2o=r(FB," \u2014 "),bj=n(FB,"A",{href:!0});var $At=s(bj);N2o=r($At,"BarthezTokenizer"),$At.forEach(t),q2o=r(FB," or "),vj=n(FB,"A",{href:!0});var kAt=s(vj);j2o=r(kAt,"BarthezTokenizerFast"),kAt.forEach(t),D2o=r(FB," (BARThez model)"),FB.forEach(t),G2o=i(S),hu=n(S,"LI",{});var aNe=s(hu);Qge=n(aNe,"STRONG",{});var SAt=s(Qge);O2o=r(SAt,"bartpho"),SAt.forEach(t),V2o=r(aNe," \u2014 "),Fj=n(aNe,"A",{href:!0});var RAt=s(Fj);X2o=r(RAt,"BartphoTokenizer"),RAt.forEach(t),z2o=r(aNe," (BARTpho model)"),aNe.forEach(t),Q2o=i(S),gs=n(S,"LI",{});var TB=s(gs);Wge=n(TB,"STRONG",{});var PAt=s(Wge);W2o=r(PAt,"bert"),PAt.forEach(t),U2o=r(TB," \u2014 "),Tj=n(TB,"A",{href:!0});var BAt=s(Tj);H2o=r(BAt,"BertTokenizer"),BAt.forEach(t),J2o=r(TB," or "),Mj=n(TB,"A",{href:!0});var IAt=s(Mj);Y2o=r(IAt,"BertTokenizerFast"),IAt.forEach(t),Z2o=r(TB," (BERT model)"),TB.forEach(t),K2o=i(S),uu=n(S,"LI",{});var nNe=s(uu);Uge=n(nNe,"STRONG",{});var NAt=s(Uge);ebo=r(NAt,"bert-generation"),NAt.forEach(t),obo=r(nNe," \u2014 "),Ej=n(nNe,"A",{href:!0});var qAt=s(Ej);rbo=r(qAt,"BertGenerationTokenizer"),qAt.forEach(t),tbo=r(nNe," (Bert Generation model)"),nNe.forEach(t),abo=i(S),pu=n(S,"LI",{});var sNe=s(pu);Hge=n(sNe,"STRONG",{});var jAt=s(Hge);nbo=r(jAt,"bert-japanese"),jAt.forEach(t),sbo=r(sNe," \u2014 "),Cj=n(sNe,"A",{href:!0});var DAt=s(Cj);lbo=r(DAt,"BertJapaneseTokenizer"),DAt.forEach(t),ibo=r(sNe," (BertJapanese model)"),sNe.forEach(t),dbo=i(S),_u=n(S,"LI",{});var lNe=s(_u);Jge=n(lNe,"STRONG",{});var GAt=s(Jge);cbo=r(GAt,"bertweet"),GAt.forEach(t),mbo=r(lNe," \u2014 "),wj=n(lNe,"A",{href:!0});var OAt=s(wj);fbo=r(OAt,"BertweetTokenizer"),OAt.forEach(t),gbo=r(lNe," (BERTweet model)"),lNe.forEach(t),hbo=i(S),hs=n(S,"LI",{});var MB=s(hs);Yge=n(MB,"STRONG",{});var VAt=s(Yge);ubo=r(VAt,"big_bird"),VAt.forEach(t),pbo=r(MB," \u2014 "),Aj=n(MB,"A",{href:!0});var XAt=s(Aj);_bo=r(XAt,"BigBirdTokenizer"),XAt.forEach(t),bbo=r(MB," or "),Lj=n(MB,"A",{href:!0});var zAt=s(Lj);vbo=r(zAt,"BigBirdTokenizerFast"),zAt.forEach(t),Fbo=r(MB," (BigBird model)"),MB.forEach(t),Tbo=i(S),us=n(S,"LI",{});var EB=s(us);Zge=n(EB,"STRONG",{});var QAt=s(Zge);Mbo=r(QAt,"bigbird_pegasus"),QAt.forEach(t),Ebo=r(EB," \u2014 "),yj=n(EB,"A",{href:!0});var WAt=s(yj);Cbo=r(WAt,"PegasusTokenizer"),WAt.forEach(t),wbo=r(EB," or "),xj=n(EB,"A",{href:!0});var UAt=s(xj);Abo=r(UAt,"PegasusTokenizerFast"),UAt.forEach(t),Lbo=r(EB," (BigBird-Pegasus model)"),EB.forEach(t),ybo=i(S),ps=n(S,"LI",{});var CB=s(ps);Kge=n(CB,"STRONG",{});var HAt=s(Kge);xbo=r(HAt,"blenderbot"),HAt.forEach(t),$bo=r(CB," \u2014 "),$j=n(CB,"A",{href:!0});var JAt=s($j);kbo=r(JAt,"BlenderbotTokenizer"),JAt.forEach(t),Sbo=r(CB," or "),kj=n(CB,"A",{href:!0});var YAt=s(kj);Rbo=r(YAt,"BlenderbotTokenizerFast"),YAt.forEach(t),Pbo=r(CB," (Blenderbot model)"),CB.forEach(t),Bbo=i(S),bu=n(S,"LI",{});var iNe=s(bu);ehe=n(iNe,"STRONG",{});var ZAt=s(ehe);Ibo=r(ZAt,"blenderbot-small"),ZAt.forEach(t),Nbo=r(iNe," \u2014 "),Sj=n(iNe,"A",{href:!0});var KAt=s(Sj);qbo=r(KAt,"BlenderbotSmallTokenizer"),KAt.forEach(t),jbo=r(iNe," (BlenderbotSmall model)"),iNe.forEach(t),Dbo=i(S),vu=n(S,"LI",{});var dNe=s(vu);ohe=n(dNe,"STRONG",{});var e6t=s(ohe);Gbo=r(e6t,"bloom"),e6t.forEach(t),Obo=r(dNe," \u2014 "),Rj=n(dNe,"A",{href:!0});var o6t=s(Rj);Vbo=r(o6t,"BloomTokenizerFast"),o6t.forEach(t),Xbo=r(dNe," (BLOOM model)"),dNe.forEach(t),zbo=i(S),Fu=n(S,"LI",{});var cNe=s(Fu);rhe=n(cNe,"STRONG",{});var r6t=s(rhe);Qbo=r(r6t,"byt5"),r6t.forEach(t),Wbo=r(cNe," \u2014 "),Pj=n(cNe,"A",{href:!0});var t6t=s(Pj);Ubo=r(t6t,"ByT5Tokenizer"),t6t.forEach(t),Hbo=r(cNe," (ByT5 model)"),cNe.forEach(t),Jbo=i(S),_s=n(S,"LI",{});var wB=s(_s);the=n(wB,"STRONG",{});var a6t=s(the);Ybo=r(a6t,"camembert"),a6t.forEach(t),Zbo=r(wB," \u2014 "),Bj=n(wB,"A",{href:!0});var n6t=s(Bj);Kbo=r(n6t,"CamembertTokenizer"),n6t.forEach(t),evo=r(wB," or "),Ij=n(wB,"A",{href:!0});var s6t=s(Ij);ovo=r(s6t,"CamembertTokenizerFast"),s6t.forEach(t),rvo=r(wB," (CamemBERT model)"),wB.forEach(t),tvo=i(S),Tu=n(S,"LI",{});var mNe=s(Tu);ahe=n(mNe,"STRONG",{});var l6t=s(ahe);avo=r(l6t,"canine"),l6t.forEach(t),nvo=r(mNe," \u2014 "),Nj=n(mNe,"A",{href:!0});var i6t=s(Nj);svo=r(i6t,"CanineTokenizer"),i6t.forEach(t),lvo=r(mNe," (CANINE model)"),mNe.forEach(t),ivo=i(S),bs=n(S,"LI",{});var AB=s(bs);nhe=n(AB,"STRONG",{});var d6t=s(nhe);dvo=r(d6t,"clip"),d6t.forEach(t),cvo=r(AB," \u2014 "),qj=n(AB,"A",{href:!0});var c6t=s(qj);mvo=r(c6t,"CLIPTokenizer"),c6t.forEach(t),fvo=r(AB," or "),jj=n(AB,"A",{href:!0});var m6t=s(jj);gvo=r(m6t,"CLIPTokenizerFast"),m6t.forEach(t),hvo=r(AB," (CLIP model)"),AB.forEach(t),uvo=i(S),vs=n(S,"LI",{});var LB=s(vs);she=n(LB,"STRONG",{});var f6t=s(she);pvo=r(f6t,"codegen"),f6t.forEach(t),_vo=r(LB," \u2014 "),Dj=n(LB,"A",{href:!0});var g6t=s(Dj);bvo=r(g6t,"CodeGenTokenizer"),g6t.forEach(t),vvo=r(LB," or "),Gj=n(LB,"A",{href:!0});var h6t=s(Gj);Fvo=r(h6t,"CodeGenTokenizerFast"),h6t.forEach(t),Tvo=r(LB," (CodeGen model)"),LB.forEach(t),Mvo=i(S),Fs=n(S,"LI",{});var yB=s(Fs);lhe=n(yB,"STRONG",{});var u6t=s(lhe);Evo=r(u6t,"convbert"),u6t.forEach(t),Cvo=r(yB," \u2014 "),Oj=n(yB,"A",{href:!0});var p6t=s(Oj);wvo=r(p6t,"ConvBertTokenizer"),p6t.forEach(t),Avo=r(yB," or "),Vj=n(yB,"A",{href:!0});var _6t=s(Vj);Lvo=r(_6t,"ConvBertTokenizerFast"),_6t.forEach(t),yvo=r(yB," (ConvBERT model)"),yB.forEach(t),xvo=i(S),Ts=n(S,"LI",{});var xB=s(Ts);ihe=n(xB,"STRONG",{});var b6t=s(ihe);$vo=r(b6t,"cpm"),b6t.forEach(t),kvo=r(xB," \u2014 "),Xj=n(xB,"A",{href:!0});var v6t=s(Xj);Svo=r(v6t,"CpmTokenizer"),v6t.forEach(t),Rvo=r(xB," or "),zj=n(xB,"A",{href:!0});var F6t=s(zj);Pvo=r(F6t,"CpmTokenizerFast"),F6t.forEach(t),Bvo=r(xB," (CPM model)"),xB.forEach(t),Ivo=i(S),Mu=n(S,"LI",{});var fNe=s(Mu);dhe=n(fNe,"STRONG",{});var T6t=s(dhe);Nvo=r(T6t,"ctrl"),T6t.forEach(t),qvo=r(fNe," \u2014 "),Qj=n(fNe,"A",{href:!0});var M6t=s(Qj);jvo=r(M6t,"CTRLTokenizer"),M6t.forEach(t),Dvo=r(fNe," (CTRL model)"),fNe.forEach(t),Gvo=i(S),Ms=n(S,"LI",{});var $B=s(Ms);che=n($B,"STRONG",{});var E6t=s(che);Ovo=r(E6t,"data2vec-text"),E6t.forEach(t),Vvo=r($B," \u2014 "),Wj=n($B,"A",{href:!0});var C6t=s(Wj);Xvo=r(C6t,"RobertaTokenizer"),C6t.forEach(t),zvo=r($B," or "),Uj=n($B,"A",{href:!0});var w6t=s(Uj);Qvo=r(w6t,"RobertaTokenizerFast"),w6t.forEach(t),Wvo=r($B," (Data2VecText model)"),$B.forEach(t),Uvo=i(S),Es=n(S,"LI",{});var kB=s(Es);mhe=n(kB,"STRONG",{});var A6t=s(mhe);Hvo=r(A6t,"deberta"),A6t.forEach(t),Jvo=r(kB," \u2014 "),Hj=n(kB,"A",{href:!0});var L6t=s(Hj);Yvo=r(L6t,"DebertaTokenizer"),L6t.forEach(t),Zvo=r(kB," or "),Jj=n(kB,"A",{href:!0});var y6t=s(Jj);Kvo=r(y6t,"DebertaTokenizerFast"),y6t.forEach(t),eFo=r(kB," (DeBERTa model)"),kB.forEach(t),oFo=i(S),Cs=n(S,"LI",{});var SB=s(Cs);fhe=n(SB,"STRONG",{});var x6t=s(fhe);rFo=r(x6t,"deberta-v2"),x6t.forEach(t),tFo=r(SB," \u2014 "),Yj=n(SB,"A",{href:!0});var $6t=s(Yj);aFo=r($6t,"DebertaV2Tokenizer"),$6t.forEach(t),nFo=r(SB," or "),Zj=n(SB,"A",{href:!0});var k6t=s(Zj);sFo=r(k6t,"DebertaV2TokenizerFast"),k6t.forEach(t),lFo=r(SB," (DeBERTa-v2 model)"),SB.forEach(t),iFo=i(S),ws=n(S,"LI",{});var RB=s(ws);ghe=n(RB,"STRONG",{});var S6t=s(ghe);dFo=r(S6t,"distilbert"),S6t.forEach(t),cFo=r(RB," \u2014 "),Kj=n(RB,"A",{href:!0});var R6t=s(Kj);mFo=r(R6t,"DistilBertTokenizer"),R6t.forEach(t),fFo=r(RB," or "),eD=n(RB,"A",{href:!0});var P6t=s(eD);gFo=r(P6t,"DistilBertTokenizerFast"),P6t.forEach(t),hFo=r(RB," (DistilBERT model)"),RB.forEach(t),uFo=i(S),As=n(S,"LI",{});var PB=s(As);hhe=n(PB,"STRONG",{});var B6t=s(hhe);pFo=r(B6t,"dpr"),B6t.forEach(t),_Fo=r(PB," \u2014 "),oD=n(PB,"A",{href:!0});var I6t=s(oD);bFo=r(I6t,"DPRQuestionEncoderTokenizer"),I6t.forEach(t),vFo=r(PB," or "),rD=n(PB,"A",{href:!0});var N6t=s(rD);FFo=r(N6t,"DPRQuestionEncoderTokenizerFast"),N6t.forEach(t),TFo=r(PB," (DPR model)"),PB.forEach(t),MFo=i(S),Ls=n(S,"LI",{});var BB=s(Ls);uhe=n(BB,"STRONG",{});var q6t=s(uhe);EFo=r(q6t,"electra"),q6t.forEach(t),CFo=r(BB," \u2014 "),tD=n(BB,"A",{href:!0});var j6t=s(tD);wFo=r(j6t,"ElectraTokenizer"),j6t.forEach(t),AFo=r(BB," or "),aD=n(BB,"A",{href:!0});var D6t=s(aD);LFo=r(D6t,"ElectraTokenizerFast"),D6t.forEach(t),yFo=r(BB," (ELECTRA model)"),BB.forEach(t),xFo=i(S),ys=n(S,"LI",{});var IB=s(ys);phe=n(IB,"STRONG",{});var G6t=s(phe);$Fo=r(G6t,"ernie"),G6t.forEach(t),kFo=r(IB," \u2014 "),nD=n(IB,"A",{href:!0});var O6t=s(nD);SFo=r(O6t,"BertTokenizer"),O6t.forEach(t),RFo=r(IB," or "),sD=n(IB,"A",{href:!0});var V6t=s(sD);PFo=r(V6t,"BertTokenizerFast"),V6t.forEach(t),BFo=r(IB," (ERNIE model)"),IB.forEach(t),IFo=i(S),Eu=n(S,"LI",{});var gNe=s(Eu);_he=n(gNe,"STRONG",{});var X6t=s(_he);NFo=r(X6t,"flaubert"),X6t.forEach(t),qFo=r(gNe," \u2014 "),lD=n(gNe,"A",{href:!0});var z6t=s(lD);jFo=r(z6t,"FlaubertTokenizer"),z6t.forEach(t),DFo=r(gNe," (FlauBERT model)"),gNe.forEach(t),GFo=i(S),xs=n(S,"LI",{});var NB=s(xs);bhe=n(NB,"STRONG",{});var Q6t=s(bhe);OFo=r(Q6t,"fnet"),Q6t.forEach(t),VFo=r(NB," \u2014 "),iD=n(NB,"A",{href:!0});var W6t=s(iD);XFo=r(W6t,"FNetTokenizer"),W6t.forEach(t),zFo=r(NB," or "),dD=n(NB,"A",{href:!0});var U6t=s(dD);QFo=r(U6t,"FNetTokenizerFast"),U6t.forEach(t),WFo=r(NB," (FNet model)"),NB.forEach(t),UFo=i(S),Cu=n(S,"LI",{});var hNe=s(Cu);vhe=n(hNe,"STRONG",{});var H6t=s(vhe);HFo=r(H6t,"fsmt"),H6t.forEach(t),JFo=r(hNe," \u2014 "),cD=n(hNe,"A",{href:!0});var J6t=s(cD);YFo=r(J6t,"FSMTTokenizer"),J6t.forEach(t),ZFo=r(hNe," (FairSeq Machine-Translation model)"),hNe.forEach(t),KFo=i(S),$s=n(S,"LI",{});var qB=s($s);Fhe=n(qB,"STRONG",{});var Y6t=s(Fhe);eTo=r(Y6t,"funnel"),Y6t.forEach(t),oTo=r(qB," \u2014 "),mD=n(qB,"A",{href:!0});var Z6t=s(mD);rTo=r(Z6t,"FunnelTokenizer"),Z6t.forEach(t),tTo=r(qB," or "),fD=n(qB,"A",{href:!0});var K6t=s(fD);aTo=r(K6t,"FunnelTokenizerFast"),K6t.forEach(t),nTo=r(qB," (Funnel Transformer model)"),qB.forEach(t),sTo=i(S),ks=n(S,"LI",{});var jB=s(ks);The=n(jB,"STRONG",{});var e7t=s(The);lTo=r(e7t,"gpt2"),e7t.forEach(t),iTo=r(jB," \u2014 "),gD=n(jB,"A",{href:!0});var o7t=s(gD);dTo=r(o7t,"GPT2Tokenizer"),o7t.forEach(t),cTo=r(jB," or "),hD=n(jB,"A",{href:!0});var r7t=s(hD);mTo=r(r7t,"GPT2TokenizerFast"),r7t.forEach(t),fTo=r(jB," (OpenAI GPT-2 model)"),jB.forEach(t),gTo=i(S),Ss=n(S,"LI",{});var DB=s(Ss);Mhe=n(DB,"STRONG",{});var t7t=s(Mhe);hTo=r(t7t,"gpt_neo"),t7t.forEach(t),uTo=r(DB," \u2014 "),uD=n(DB,"A",{href:!0});var a7t=s(uD);pTo=r(a7t,"GPT2Tokenizer"),a7t.forEach(t),_To=r(DB," or "),pD=n(DB,"A",{href:!0});var n7t=s(pD);bTo=r(n7t,"GPT2TokenizerFast"),n7t.forEach(t),vTo=r(DB," (GPT Neo model)"),DB.forEach(t),FTo=i(S),wu=n(S,"LI",{});var uNe=s(wu);Ehe=n(uNe,"STRONG",{});var s7t=s(Ehe);TTo=r(s7t,"gpt_neox"),s7t.forEach(t),MTo=r(uNe," \u2014 "),_D=n(uNe,"A",{href:!0});var l7t=s(_D);ETo=r(l7t,"GPTNeoXTokenizerFast"),l7t.forEach(t),CTo=r(uNe," (GPT NeoX model)"),uNe.forEach(t),wTo=i(S),Au=n(S,"LI",{});var pNe=s(Au);Che=n(pNe,"STRONG",{});var i7t=s(Che);ATo=r(i7t,"gpt_neox_japanese"),i7t.forEach(t),LTo=r(pNe," \u2014 "),bD=n(pNe,"A",{href:!0});var d7t=s(bD);yTo=r(d7t,"GPTNeoXJapaneseTokenizer"),d7t.forEach(t),xTo=r(pNe," (GPT NeoX Japanese model)"),pNe.forEach(t),$To=i(S),Rs=n(S,"LI",{});var GB=s(Rs);whe=n(GB,"STRONG",{});var c7t=s(whe);kTo=r(c7t,"gptj"),c7t.forEach(t),STo=r(GB," \u2014 "),vD=n(GB,"A",{href:!0});var m7t=s(vD);RTo=r(m7t,"GPT2Tokenizer"),m7t.forEach(t),PTo=r(GB," or "),FD=n(GB,"A",{href:!0});var f7t=s(FD);BTo=r(f7t,"GPT2TokenizerFast"),f7t.forEach(t),ITo=r(GB," (GPT-J model)"),GB.forEach(t),NTo=i(S),Ps=n(S,"LI",{});var OB=s(Ps);Ahe=n(OB,"STRONG",{});var g7t=s(Ahe);qTo=r(g7t,"groupvit"),g7t.forEach(t),jTo=r(OB," \u2014 "),TD=n(OB,"A",{href:!0});var h7t=s(TD);DTo=r(h7t,"CLIPTokenizer"),h7t.forEach(t),GTo=r(OB," or "),MD=n(OB,"A",{href:!0});var u7t=s(MD);OTo=r(u7t,"CLIPTokenizerFast"),u7t.forEach(t),VTo=r(OB," (GroupViT model)"),OB.forEach(t),XTo=i(S),Bs=n(S,"LI",{});var VB=s(Bs);Lhe=n(VB,"STRONG",{});var p7t=s(Lhe);zTo=r(p7t,"herbert"),p7t.forEach(t),QTo=r(VB," \u2014 "),ED=n(VB,"A",{href:!0});var _7t=s(ED);WTo=r(_7t,"HerbertTokenizer"),_7t.forEach(t),UTo=r(VB," or "),CD=n(VB,"A",{href:!0});var b7t=s(CD);HTo=r(b7t,"HerbertTokenizerFast"),b7t.forEach(t),JTo=r(VB," (HerBERT model)"),VB.forEach(t),YTo=i(S),Lu=n(S,"LI",{});var _Ne=s(Lu);yhe=n(_Ne,"STRONG",{});var v7t=s(yhe);ZTo=r(v7t,"hubert"),v7t.forEach(t),KTo=r(_Ne," \u2014 "),wD=n(_Ne,"A",{href:!0});var F7t=s(wD);eMo=r(F7t,"Wav2Vec2CTCTokenizer"),F7t.forEach(t),oMo=r(_Ne," (Hubert model)"),_Ne.forEach(t),rMo=i(S),Is=n(S,"LI",{});var XB=s(Is);xhe=n(XB,"STRONG",{});var T7t=s(xhe);tMo=r(T7t,"ibert"),T7t.forEach(t),aMo=r(XB," \u2014 "),AD=n(XB,"A",{href:!0});var M7t=s(AD);nMo=r(M7t,"RobertaTokenizer"),M7t.forEach(t),sMo=r(XB," or "),LD=n(XB,"A",{href:!0});var E7t=s(LD);lMo=r(E7t,"RobertaTokenizerFast"),E7t.forEach(t),iMo=r(XB," (I-BERT model)"),XB.forEach(t),dMo=i(S),Ns=n(S,"LI",{});var zB=s(Ns);$he=n(zB,"STRONG",{});var C7t=s($he);cMo=r(C7t,"layoutlm"),C7t.forEach(t),mMo=r(zB," \u2014 "),yD=n(zB,"A",{href:!0});var w7t=s(yD);fMo=r(w7t,"LayoutLMTokenizer"),w7t.forEach(t),gMo=r(zB," or "),xD=n(zB,"A",{href:!0});var A7t=s(xD);hMo=r(A7t,"LayoutLMTokenizerFast"),A7t.forEach(t),uMo=r(zB," (LayoutLM model)"),zB.forEach(t),pMo=i(S),qs=n(S,"LI",{});var QB=s(qs);khe=n(QB,"STRONG",{});var L7t=s(khe);_Mo=r(L7t,"layoutlmv2"),L7t.forEach(t),bMo=r(QB," \u2014 "),$D=n(QB,"A",{href:!0});var y7t=s($D);vMo=r(y7t,"LayoutLMv2Tokenizer"),y7t.forEach(t),FMo=r(QB," or "),kD=n(QB,"A",{href:!0});var x7t=s(kD);TMo=r(x7t,"LayoutLMv2TokenizerFast"),x7t.forEach(t),MMo=r(QB," (LayoutLMv2 model)"),QB.forEach(t),EMo=i(S),js=n(S,"LI",{});var WB=s(js);She=n(WB,"STRONG",{});var $7t=s(She);CMo=r($7t,"layoutlmv3"),$7t.forEach(t),wMo=r(WB," \u2014 "),SD=n(WB,"A",{href:!0});var k7t=s(SD);AMo=r(k7t,"LayoutLMv3Tokenizer"),k7t.forEach(t),LMo=r(WB," or "),RD=n(WB,"A",{href:!0});var S7t=s(RD);yMo=r(S7t,"LayoutLMv3TokenizerFast"),S7t.forEach(t),xMo=r(WB," (LayoutLMv3 model)"),WB.forEach(t),$Mo=i(S),Ds=n(S,"LI",{});var UB=s(Ds);Rhe=n(UB,"STRONG",{});var R7t=s(Rhe);kMo=r(R7t,"layoutxlm"),R7t.forEach(t),SMo=r(UB," \u2014 "),PD=n(UB,"A",{href:!0});var P7t=s(PD);RMo=r(P7t,"LayoutXLMTokenizer"),P7t.forEach(t),PMo=r(UB," or "),BD=n(UB,"A",{href:!0});var B7t=s(BD);BMo=r(B7t,"LayoutXLMTokenizerFast"),B7t.forEach(t),IMo=r(UB," (LayoutXLM model)"),UB.forEach(t),NMo=i(S),Gs=n(S,"LI",{});var HB=s(Gs);Phe=n(HB,"STRONG",{});var I7t=s(Phe);qMo=r(I7t,"led"),I7t.forEach(t),jMo=r(HB," \u2014 "),ID=n(HB,"A",{href:!0});var N7t=s(ID);DMo=r(N7t,"LEDTokenizer"),N7t.forEach(t),GMo=r(HB," or "),ND=n(HB,"A",{href:!0});var q7t=s(ND);OMo=r(q7t,"LEDTokenizerFast"),q7t.forEach(t),VMo=r(HB," (LED model)"),HB.forEach(t),XMo=i(S),Os=n(S,"LI",{});var JB=s(Os);Bhe=n(JB,"STRONG",{});var j7t=s(Bhe);zMo=r(j7t,"longformer"),j7t.forEach(t),QMo=r(JB," \u2014 "),qD=n(JB,"A",{href:!0});var D7t=s(qD);WMo=r(D7t,"LongformerTokenizer"),D7t.forEach(t),UMo=r(JB," or "),jD=n(JB,"A",{href:!0});var G7t=s(jD);HMo=r(G7t,"LongformerTokenizerFast"),G7t.forEach(t),JMo=r(JB," (Longformer model)"),JB.forEach(t),YMo=i(S),Vs=n(S,"LI",{});var YB=s(Vs);Ihe=n(YB,"STRONG",{});var O7t=s(Ihe);ZMo=r(O7t,"longt5"),O7t.forEach(t),KMo=r(YB," \u2014 "),DD=n(YB,"A",{href:!0});var V7t=s(DD);eEo=r(V7t,"T5Tokenizer"),V7t.forEach(t),oEo=r(YB," or "),GD=n(YB,"A",{href:!0});var X7t=s(GD);rEo=r(X7t,"T5TokenizerFast"),X7t.forEach(t),tEo=r(YB," (LongT5 model)"),YB.forEach(t),aEo=i(S),yu=n(S,"LI",{});var bNe=s(yu);Nhe=n(bNe,"STRONG",{});var z7t=s(Nhe);nEo=r(z7t,"luke"),z7t.forEach(t),sEo=r(bNe," \u2014 "),OD=n(bNe,"A",{href:!0});var Q7t=s(OD);lEo=r(Q7t,"LukeTokenizer"),Q7t.forEach(t),iEo=r(bNe," (LUKE model)"),bNe.forEach(t),dEo=i(S),Xs=n(S,"LI",{});var ZB=s(Xs);qhe=n(ZB,"STRONG",{});var W7t=s(qhe);cEo=r(W7t,"lxmert"),W7t.forEach(t),mEo=r(ZB," \u2014 "),VD=n(ZB,"A",{href:!0});var U7t=s(VD);fEo=r(U7t,"LxmertTokenizer"),U7t.forEach(t),gEo=r(ZB," or "),XD=n(ZB,"A",{href:!0});var H7t=s(XD);hEo=r(H7t,"LxmertTokenizerFast"),H7t.forEach(t),uEo=r(ZB," (LXMERT model)"),ZB.forEach(t),pEo=i(S),xu=n(S,"LI",{});var vNe=s(xu);jhe=n(vNe,"STRONG",{});var J7t=s(jhe);_Eo=r(J7t,"m2m_100"),J7t.forEach(t),bEo=r(vNe," \u2014 "),zD=n(vNe,"A",{href:!0});var Y7t=s(zD);vEo=r(Y7t,"M2M100Tokenizer"),Y7t.forEach(t),FEo=r(vNe," (M2M100 model)"),vNe.forEach(t),TEo=i(S),$u=n(S,"LI",{});var FNe=s($u);Dhe=n(FNe,"STRONG",{});var Z7t=s(Dhe);MEo=r(Z7t,"marian"),Z7t.forEach(t),EEo=r(FNe," \u2014 "),QD=n(FNe,"A",{href:!0});var K7t=s(QD);CEo=r(K7t,"MarianTokenizer"),K7t.forEach(t),wEo=r(FNe," (Marian model)"),FNe.forEach(t),AEo=i(S),zs=n(S,"LI",{});var KB=s(zs);Ghe=n(KB,"STRONG",{});var eLt=s(Ghe);LEo=r(eLt,"mbart"),eLt.forEach(t),yEo=r(KB," \u2014 "),WD=n(KB,"A",{href:!0});var oLt=s(WD);xEo=r(oLt,"MBartTokenizer"),oLt.forEach(t),$Eo=r(KB," or "),UD=n(KB,"A",{href:!0});var rLt=s(UD);kEo=r(rLt,"MBartTokenizerFast"),rLt.forEach(t),SEo=r(KB," (mBART model)"),KB.forEach(t),REo=i(S),Qs=n(S,"LI",{});var eI=s(Qs);Ohe=n(eI,"STRONG",{});var tLt=s(Ohe);PEo=r(tLt,"mbart50"),tLt.forEach(t),BEo=r(eI," \u2014 "),HD=n(eI,"A",{href:!0});var aLt=s(HD);IEo=r(aLt,"MBart50Tokenizer"),aLt.forEach(t),NEo=r(eI," or "),JD=n(eI,"A",{href:!0});var nLt=s(JD);qEo=r(nLt,"MBart50TokenizerFast"),nLt.forEach(t),jEo=r(eI," (mBART-50 model)"),eI.forEach(t),DEo=i(S),Ws=n(S,"LI",{});var oI=s(Ws);Vhe=n(oI,"STRONG",{});var sLt=s(Vhe);GEo=r(sLt,"megatron-bert"),sLt.forEach(t),OEo=r(oI," \u2014 "),YD=n(oI,"A",{href:!0});var lLt=s(YD);VEo=r(lLt,"BertTokenizer"),lLt.forEach(t),XEo=r(oI," or "),ZD=n(oI,"A",{href:!0});var iLt=s(ZD);zEo=r(iLt,"BertTokenizerFast"),iLt.forEach(t),QEo=r(oI," (Megatron-BERT model)"),oI.forEach(t),WEo=i(S),ku=n(S,"LI",{});var TNe=s(ku);Xhe=n(TNe,"STRONG",{});var dLt=s(Xhe);UEo=r(dLt,"mluke"),dLt.forEach(t),HEo=r(TNe," \u2014 "),KD=n(TNe,"A",{href:!0});var cLt=s(KD);JEo=r(cLt,"MLukeTokenizer"),cLt.forEach(t),YEo=r(TNe," (mLUKE model)"),TNe.forEach(t),ZEo=i(S),Us=n(S,"LI",{});var rI=s(Us);zhe=n(rI,"STRONG",{});var mLt=s(zhe);KEo=r(mLt,"mobilebert"),mLt.forEach(t),e4o=r(rI," \u2014 "),eG=n(rI,"A",{href:!0});var fLt=s(eG);o4o=r(fLt,"MobileBertTokenizer"),fLt.forEach(t),r4o=r(rI," or "),oG=n(rI,"A",{href:!0});var gLt=s(oG);t4o=r(gLt,"MobileBertTokenizerFast"),gLt.forEach(t),a4o=r(rI," (MobileBERT model)"),rI.forEach(t),n4o=i(S),Hs=n(S,"LI",{});var tI=s(Hs);Qhe=n(tI,"STRONG",{});var hLt=s(Qhe);s4o=r(hLt,"mpnet"),hLt.forEach(t),l4o=r(tI," \u2014 "),rG=n(tI,"A",{href:!0});var uLt=s(rG);i4o=r(uLt,"MPNetTokenizer"),uLt.forEach(t),d4o=r(tI," or "),tG=n(tI,"A",{href:!0});var pLt=s(tG);c4o=r(pLt,"MPNetTokenizerFast"),pLt.forEach(t),m4o=r(tI," (MPNet model)"),tI.forEach(t),f4o=i(S),Js=n(S,"LI",{});var aI=s(Js);Whe=n(aI,"STRONG",{});var _Lt=s(Whe);g4o=r(_Lt,"mt5"),_Lt.forEach(t),h4o=r(aI," \u2014 "),aG=n(aI,"A",{href:!0});var bLt=s(aG);u4o=r(bLt,"MT5Tokenizer"),bLt.forEach(t),p4o=r(aI," or "),nG=n(aI,"A",{href:!0});var vLt=s(nG);_4o=r(vLt,"MT5TokenizerFast"),vLt.forEach(t),b4o=r(aI," (MT5 model)"),aI.forEach(t),v4o=i(S),Ys=n(S,"LI",{});var nI=s(Ys);Uhe=n(nI,"STRONG",{});var FLt=s(Uhe);F4o=r(FLt,"mvp"),FLt.forEach(t),T4o=r(nI," \u2014 "),sG=n(nI,"A",{href:!0});var TLt=s(sG);M4o=r(TLt,"MvpTokenizer"),TLt.forEach(t),E4o=r(nI," or "),lG=n(nI,"A",{href:!0});var MLt=s(lG);C4o=r(MLt,"MvpTokenizerFast"),MLt.forEach(t),w4o=r(nI," (MVP model)"),nI.forEach(t),A4o=i(S),Zs=n(S,"LI",{});var sI=s(Zs);Hhe=n(sI,"STRONG",{});var ELt=s(Hhe);L4o=r(ELt,"nezha"),ELt.forEach(t),y4o=r(sI," \u2014 "),iG=n(sI,"A",{href:!0});var CLt=s(iG);x4o=r(CLt,"BertTokenizer"),CLt.forEach(t),$4o=r(sI," or "),dG=n(sI,"A",{href:!0});var wLt=s(dG);k4o=r(wLt,"BertTokenizerFast"),wLt.forEach(t),S4o=r(sI," (Nezha model)"),sI.forEach(t),R4o=i(S),Ks=n(S,"LI",{});var lI=s(Ks);Jhe=n(lI,"STRONG",{});var ALt=s(Jhe);P4o=r(ALt,"nllb"),ALt.forEach(t),B4o=r(lI," \u2014 "),cG=n(lI,"A",{href:!0});var LLt=s(cG);I4o=r(LLt,"NllbTokenizer"),LLt.forEach(t),N4o=r(lI," or "),mG=n(lI,"A",{href:!0});var yLt=s(mG);q4o=r(yLt,"NllbTokenizerFast"),yLt.forEach(t),j4o=r(lI," (NLLB model)"),lI.forEach(t),D4o=i(S),el=n(S,"LI",{});var iI=s(el);Yhe=n(iI,"STRONG",{});var xLt=s(Yhe);G4o=r(xLt,"nystromformer"),xLt.forEach(t),O4o=r(iI," \u2014 "),fG=n(iI,"A",{href:!0});var $Lt=s(fG);V4o=r($Lt,"AlbertTokenizer"),$Lt.forEach(t),X4o=r(iI," or "),gG=n(iI,"A",{href:!0});var kLt=s(gG);z4o=r(kLt,"AlbertTokenizerFast"),kLt.forEach(t),Q4o=r(iI," (Nystr\xF6mformer model)"),iI.forEach(t),W4o=i(S),ol=n(S,"LI",{});var dI=s(ol);Zhe=n(dI,"STRONG",{});var SLt=s(Zhe);U4o=r(SLt,"openai-gpt"),SLt.forEach(t),H4o=r(dI," \u2014 "),hG=n(dI,"A",{href:!0});var RLt=s(hG);J4o=r(RLt,"OpenAIGPTTokenizer"),RLt.forEach(t),Y4o=r(dI," or "),uG=n(dI,"A",{href:!0});var PLt=s(uG);Z4o=r(PLt,"OpenAIGPTTokenizerFast"),PLt.forEach(t),K4o=r(dI," (OpenAI GPT model)"),dI.forEach(t),eCo=i(S),Su=n(S,"LI",{});var MNe=s(Su);Khe=n(MNe,"STRONG",{});var BLt=s(Khe);oCo=r(BLt,"opt"),BLt.forEach(t),rCo=r(MNe," \u2014 "),pG=n(MNe,"A",{href:!0});var ILt=s(pG);tCo=r(ILt,"GPT2Tokenizer"),ILt.forEach(t),aCo=r(MNe," (OPT model)"),MNe.forEach(t),nCo=i(S),rl=n(S,"LI",{});var cI=s(rl);eue=n(cI,"STRONG",{});var NLt=s(eue);sCo=r(NLt,"owlvit"),NLt.forEach(t),lCo=r(cI," \u2014 "),_G=n(cI,"A",{href:!0});var qLt=s(_G);iCo=r(qLt,"CLIPTokenizer"),qLt.forEach(t),dCo=r(cI," or "),bG=n(cI,"A",{href:!0});var jLt=s(bG);cCo=r(jLt,"CLIPTokenizerFast"),jLt.forEach(t),mCo=r(cI," (OWL-ViT model)"),cI.forEach(t),fCo=i(S),tl=n(S,"LI",{});var mI=s(tl);oue=n(mI,"STRONG",{});var DLt=s(oue);gCo=r(DLt,"pegasus"),DLt.forEach(t),hCo=r(mI," \u2014 "),vG=n(mI,"A",{href:!0});var GLt=s(vG);uCo=r(GLt,"PegasusTokenizer"),GLt.forEach(t),pCo=r(mI," or "),FG=n(mI,"A",{href:!0});var OLt=s(FG);_Co=r(OLt,"PegasusTokenizerFast"),OLt.forEach(t),bCo=r(mI," (Pegasus model)"),mI.forEach(t),vCo=i(S),Ru=n(S,"LI",{});var ENe=s(Ru);rue=n(ENe,"STRONG",{});var VLt=s(rue);FCo=r(VLt,"perceiver"),VLt.forEach(t),TCo=r(ENe," \u2014 "),TG=n(ENe,"A",{href:!0});var XLt=s(TG);MCo=r(XLt,"PerceiverTokenizer"),XLt.forEach(t),ECo=r(ENe," (Perceiver model)"),ENe.forEach(t),CCo=i(S),Pu=n(S,"LI",{});var CNe=s(Pu);tue=n(CNe,"STRONG",{});var zLt=s(tue);wCo=r(zLt,"phobert"),zLt.forEach(t),ACo=r(CNe," \u2014 "),MG=n(CNe,"A",{href:!0});var QLt=s(MG);LCo=r(QLt,"PhobertTokenizer"),QLt.forEach(t),yCo=r(CNe," (PhoBERT model)"),CNe.forEach(t),xCo=i(S),Bu=n(S,"LI",{});var wNe=s(Bu);aue=n(wNe,"STRONG",{});var WLt=s(aue);$Co=r(WLt,"plbart"),WLt.forEach(t),kCo=r(wNe," \u2014 "),EG=n(wNe,"A",{href:!0});var ULt=s(EG);SCo=r(ULt,"PLBartTokenizer"),ULt.forEach(t),RCo=r(wNe," (PLBart model)"),wNe.forEach(t),PCo=i(S),Iu=n(S,"LI",{});var ANe=s(Iu);nue=n(ANe,"STRONG",{});var HLt=s(nue);BCo=r(HLt,"prophetnet"),HLt.forEach(t),ICo=r(ANe," \u2014 "),CG=n(ANe,"A",{href:!0});var JLt=s(CG);NCo=r(JLt,"ProphetNetTokenizer"),JLt.forEach(t),qCo=r(ANe," (ProphetNet model)"),ANe.forEach(t),jCo=i(S),al=n(S,"LI",{});var fI=s(al);sue=n(fI,"STRONG",{});var YLt=s(sue);DCo=r(YLt,"qdqbert"),YLt.forEach(t),GCo=r(fI," \u2014 "),wG=n(fI,"A",{href:!0});var ZLt=s(wG);OCo=r(ZLt,"BertTokenizer"),ZLt.forEach(t),VCo=r(fI," or "),AG=n(fI,"A",{href:!0});var KLt=s(AG);XCo=r(KLt,"BertTokenizerFast"),KLt.forEach(t),zCo=r(fI," (QDQBert model)"),fI.forEach(t),QCo=i(S),Nu=n(S,"LI",{});var LNe=s(Nu);lue=n(LNe,"STRONG",{});var e8t=s(lue);WCo=r(e8t,"rag"),e8t.forEach(t),UCo=r(LNe," \u2014 "),LG=n(LNe,"A",{href:!0});var o8t=s(LG);HCo=r(o8t,"RagTokenizer"),o8t.forEach(t),JCo=r(LNe," (RAG model)"),LNe.forEach(t),YCo=i(S),nl=n(S,"LI",{});var gI=s(nl);iue=n(gI,"STRONG",{});var r8t=s(iue);ZCo=r(r8t,"realm"),r8t.forEach(t),KCo=r(gI," \u2014 "),yG=n(gI,"A",{href:!0});var t8t=s(yG);e3o=r(t8t,"RealmTokenizer"),t8t.forEach(t),o3o=r(gI," or "),xG=n(gI,"A",{href:!0});var a8t=s(xG);r3o=r(a8t,"RealmTokenizerFast"),a8t.forEach(t),t3o=r(gI," (REALM model)"),gI.forEach(t),a3o=i(S),sl=n(S,"LI",{});var hI=s(sl);due=n(hI,"STRONG",{});var n8t=s(due);n3o=r(n8t,"reformer"),n8t.forEach(t),s3o=r(hI," \u2014 "),$G=n(hI,"A",{href:!0});var s8t=s($G);l3o=r(s8t,"ReformerTokenizer"),s8t.forEach(t),i3o=r(hI," or "),kG=n(hI,"A",{href:!0});var l8t=s(kG);d3o=r(l8t,"ReformerTokenizerFast"),l8t.forEach(t),c3o=r(hI," (Reformer model)"),hI.forEach(t),m3o=i(S),ll=n(S,"LI",{});var uI=s(ll);cue=n(uI,"STRONG",{});var i8t=s(cue);f3o=r(i8t,"rembert"),i8t.forEach(t),g3o=r(uI," \u2014 "),SG=n(uI,"A",{href:!0});var d8t=s(SG);h3o=r(d8t,"RemBertTokenizer"),d8t.forEach(t),u3o=r(uI," or "),RG=n(uI,"A",{href:!0});var c8t=s(RG);p3o=r(c8t,"RemBertTokenizerFast"),c8t.forEach(t),_3o=r(uI," (RemBERT model)"),uI.forEach(t),b3o=i(S),il=n(S,"LI",{});var pI=s(il);mue=n(pI,"STRONG",{});var m8t=s(mue);v3o=r(m8t,"retribert"),m8t.forEach(t),F3o=r(pI," \u2014 "),PG=n(pI,"A",{href:!0});var f8t=s(PG);T3o=r(f8t,"RetriBertTokenizer"),f8t.forEach(t),M3o=r(pI," or "),BG=n(pI,"A",{href:!0});var g8t=s(BG);E3o=r(g8t,"RetriBertTokenizerFast"),g8t.forEach(t),C3o=r(pI," (RetriBERT model)"),pI.forEach(t),w3o=i(S),dl=n(S,"LI",{});var _I=s(dl);fue=n(_I,"STRONG",{});var h8t=s(fue);A3o=r(h8t,"roberta"),h8t.forEach(t),L3o=r(_I," \u2014 "),IG=n(_I,"A",{href:!0});var u8t=s(IG);y3o=r(u8t,"RobertaTokenizer"),u8t.forEach(t),x3o=r(_I," or "),NG=n(_I,"A",{href:!0});var p8t=s(NG);$3o=r(p8t,"RobertaTokenizerFast"),p8t.forEach(t),k3o=r(_I," (RoBERTa model)"),_I.forEach(t),S3o=i(S),cl=n(S,"LI",{});var bI=s(cl);gue=n(bI,"STRONG",{});var _8t=s(gue);R3o=r(_8t,"roformer"),_8t.forEach(t),P3o=r(bI," \u2014 "),qG=n(bI,"A",{href:!0});var b8t=s(qG);B3o=r(b8t,"RoFormerTokenizer"),b8t.forEach(t),I3o=r(bI," or "),jG=n(bI,"A",{href:!0});var v8t=s(jG);N3o=r(v8t,"RoFormerTokenizerFast"),v8t.forEach(t),q3o=r(bI," (RoFormer model)"),bI.forEach(t),j3o=i(S),qu=n(S,"LI",{});var yNe=s(qu);hue=n(yNe,"STRONG",{});var F8t=s(hue);D3o=r(F8t,"speech_to_text"),F8t.forEach(t),G3o=r(yNe," \u2014 "),DG=n(yNe,"A",{href:!0});var T8t=s(DG);O3o=r(T8t,"Speech2TextTokenizer"),T8t.forEach(t),V3o=r(yNe," (Speech2Text model)"),yNe.forEach(t),X3o=i(S),ju=n(S,"LI",{});var xNe=s(ju);uue=n(xNe,"STRONG",{});var M8t=s(uue);z3o=r(M8t,"speech_to_text_2"),M8t.forEach(t),Q3o=r(xNe," \u2014 "),GG=n(xNe,"A",{href:!0});var E8t=s(GG);W3o=r(E8t,"Speech2Text2Tokenizer"),E8t.forEach(t),U3o=r(xNe," (Speech2Text2 model)"),xNe.forEach(t),H3o=i(S),ml=n(S,"LI",{});var vI=s(ml);pue=n(vI,"STRONG",{});var C8t=s(pue);J3o=r(C8t,"splinter"),C8t.forEach(t),Y3o=r(vI," \u2014 "),OG=n(vI,"A",{href:!0});var w8t=s(OG);Z3o=r(w8t,"SplinterTokenizer"),w8t.forEach(t),K3o=r(vI," or "),VG=n(vI,"A",{href:!0});var A8t=s(VG);e5o=r(A8t,"SplinterTokenizerFast"),A8t.forEach(t),o5o=r(vI," (Splinter model)"),vI.forEach(t),r5o=i(S),fl=n(S,"LI",{});var FI=s(fl);_ue=n(FI,"STRONG",{});var L8t=s(_ue);t5o=r(L8t,"squeezebert"),L8t.forEach(t),a5o=r(FI," \u2014 "),XG=n(FI,"A",{href:!0});var y8t=s(XG);n5o=r(y8t,"SqueezeBertTokenizer"),y8t.forEach(t),s5o=r(FI," or "),zG=n(FI,"A",{href:!0});var x8t=s(zG);l5o=r(x8t,"SqueezeBertTokenizerFast"),x8t.forEach(t),i5o=r(FI," (SqueezeBERT model)"),FI.forEach(t),d5o=i(S),gl=n(S,"LI",{});var TI=s(gl);bue=n(TI,"STRONG",{});var $8t=s(bue);c5o=r($8t,"t5"),$8t.forEach(t),m5o=r(TI," \u2014 "),QG=n(TI,"A",{href:!0});var k8t=s(QG);f5o=r(k8t,"T5Tokenizer"),k8t.forEach(t),g5o=r(TI," or "),WG=n(TI,"A",{href:!0});var S8t=s(WG);h5o=r(S8t,"T5TokenizerFast"),S8t.forEach(t),u5o=r(TI," (T5 model)"),TI.forEach(t),p5o=i(S),Du=n(S,"LI",{});var $Ne=s(Du);vue=n($Ne,"STRONG",{});var R8t=s(vue);_5o=r(R8t,"tapas"),R8t.forEach(t),b5o=r($Ne," \u2014 "),UG=n($Ne,"A",{href:!0});var P8t=s(UG);v5o=r(P8t,"TapasTokenizer"),P8t.forEach(t),F5o=r($Ne," (TAPAS model)"),$Ne.forEach(t),T5o=i(S),Gu=n(S,"LI",{});var kNe=s(Gu);Fue=n(kNe,"STRONG",{});var B8t=s(Fue);M5o=r(B8t,"tapex"),B8t.forEach(t),E5o=r(kNe," \u2014 "),HG=n(kNe,"A",{href:!0});var I8t=s(HG);C5o=r(I8t,"TapexTokenizer"),I8t.forEach(t),w5o=r(kNe," (TAPEX model)"),kNe.forEach(t),A5o=i(S),Ou=n(S,"LI",{});var SNe=s(Ou);Tue=n(SNe,"STRONG",{});var N8t=s(Tue);L5o=r(N8t,"transfo-xl"),N8t.forEach(t),y5o=r(SNe," \u2014 "),JG=n(SNe,"A",{href:!0});var q8t=s(JG);x5o=r(q8t,"TransfoXLTokenizer"),q8t.forEach(t),$5o=r(SNe," (Transformer-XL model)"),SNe.forEach(t),k5o=i(S),hl=n(S,"LI",{});var MI=s(hl);Mue=n(MI,"STRONG",{});var j8t=s(Mue);S5o=r(j8t,"vilt"),j8t.forEach(t),R5o=r(MI," \u2014 "),YG=n(MI,"A",{href:!0});var D8t=s(YG);P5o=r(D8t,"BertTokenizer"),D8t.forEach(t),B5o=r(MI," or "),ZG=n(MI,"A",{href:!0});var G8t=s(ZG);I5o=r(G8t,"BertTokenizerFast"),G8t.forEach(t),N5o=r(MI," (ViLT model)"),MI.forEach(t),q5o=i(S),ul=n(S,"LI",{});var EI=s(ul);Eue=n(EI,"STRONG",{});var O8t=s(Eue);j5o=r(O8t,"visual_bert"),O8t.forEach(t),D5o=r(EI," \u2014 "),KG=n(EI,"A",{href:!0});var V8t=s(KG);G5o=r(V8t,"BertTokenizer"),V8t.forEach(t),O5o=r(EI," or "),eO=n(EI,"A",{href:!0});var X8t=s(eO);V5o=r(X8t,"BertTokenizerFast"),X8t.forEach(t),X5o=r(EI," (VisualBERT model)"),EI.forEach(t),z5o=i(S),Vu=n(S,"LI",{});var RNe=s(Vu);Cue=n(RNe,"STRONG",{});var z8t=s(Cue);Q5o=r(z8t,"wav2vec2"),z8t.forEach(t),W5o=r(RNe," \u2014 "),oO=n(RNe,"A",{href:!0});var Q8t=s(oO);U5o=r(Q8t,"Wav2Vec2CTCTokenizer"),Q8t.forEach(t),H5o=r(RNe," (Wav2Vec2 model)"),RNe.forEach(t),J5o=i(S),Xu=n(S,"LI",{});var PNe=s(Xu);wue=n(PNe,"STRONG",{});var W8t=s(wue);Y5o=r(W8t,"wav2vec2-conformer"),W8t.forEach(t),Z5o=r(PNe," \u2014 "),rO=n(PNe,"A",{href:!0});var U8t=s(rO);K5o=r(U8t,"Wav2Vec2CTCTokenizer"),U8t.forEach(t),e0o=r(PNe," (Wav2Vec2-Conformer model)"),PNe.forEach(t),o0o=i(S),zu=n(S,"LI",{});var BNe=s(zu);Aue=n(BNe,"STRONG",{});var H8t=s(Aue);r0o=r(H8t,"wav2vec2_phoneme"),H8t.forEach(t),t0o=r(BNe," \u2014 "),tO=n(BNe,"A",{href:!0});var J8t=s(tO);a0o=r(J8t,"Wav2Vec2PhonemeCTCTokenizer"),J8t.forEach(t),n0o=r(BNe," (Wav2Vec2Phoneme model)"),BNe.forEach(t),s0o=i(S),Qu=n(S,"LI",{});var INe=s(Qu);Lue=n(INe,"STRONG",{});var Y8t=s(Lue);l0o=r(Y8t,"whisper"),Y8t.forEach(t),i0o=r(INe," \u2014 "),aO=n(INe,"A",{href:!0});var Z8t=s(aO);d0o=r(Z8t,"WhisperTokenizer"),Z8t.forEach(t),c0o=r(INe," (Whisper model)"),INe.forEach(t),m0o=i(S),pl=n(S,"LI",{});var CI=s(pl);yue=n(CI,"STRONG",{});var K8t=s(yue);f0o=r(K8t,"xclip"),K8t.forEach(t),g0o=r(CI," \u2014 "),nO=n(CI,"A",{href:!0});var eyt=s(nO);h0o=r(eyt,"CLIPTokenizer"),eyt.forEach(t),u0o=r(CI," or "),sO=n(CI,"A",{href:!0});var oyt=s(sO);p0o=r(oyt,"CLIPTokenizerFast"),oyt.forEach(t),_0o=r(CI," (X-CLIP model)"),CI.forEach(t),b0o=i(S),_l=n(S,"LI",{});var wI=s(_l);xue=n(wI,"STRONG",{});var ryt=s(xue);v0o=r(ryt,"xglm"),ryt.forEach(t),F0o=r(wI," \u2014 "),lO=n(wI,"A",{href:!0});var tyt=s(lO);T0o=r(tyt,"XGLMTokenizer"),tyt.forEach(t),M0o=r(wI," or "),iO=n(wI,"A",{href:!0});var ayt=s(iO);E0o=r(ayt,"XGLMTokenizerFast"),ayt.forEach(t),C0o=r(wI," (XGLM model)"),wI.forEach(t),w0o=i(S),Wu=n(S,"LI",{});var NNe=s(Wu);$ue=n(NNe,"STRONG",{});var nyt=s($ue);A0o=r(nyt,"xlm"),nyt.forEach(t),L0o=r(NNe," \u2014 "),dO=n(NNe,"A",{href:!0});var syt=s(dO);y0o=r(syt,"XLMTokenizer"),syt.forEach(t),x0o=r(NNe," (XLM model)"),NNe.forEach(t),$0o=i(S),Uu=n(S,"LI",{});var qNe=s(Uu);kue=n(qNe,"STRONG",{});var lyt=s(kue);k0o=r(lyt,"xlm-prophetnet"),lyt.forEach(t),S0o=r(qNe," \u2014 "),cO=n(qNe,"A",{href:!0});var iyt=s(cO);R0o=r(iyt,"XLMProphetNetTokenizer"),iyt.forEach(t),P0o=r(qNe," (XLM-ProphetNet model)"),qNe.forEach(t),B0o=i(S),bl=n(S,"LI",{});var AI=s(bl);Sue=n(AI,"STRONG",{});var dyt=s(Sue);I0o=r(dyt,"xlm-roberta"),dyt.forEach(t),N0o=r(AI," \u2014 "),mO=n(AI,"A",{href:!0});var cyt=s(mO);q0o=r(cyt,"XLMRobertaTokenizer"),cyt.forEach(t),j0o=r(AI," or "),fO=n(AI,"A",{href:!0});var myt=s(fO);D0o=r(myt,"XLMRobertaTokenizerFast"),myt.forEach(t),G0o=r(AI," (XLM-RoBERTa model)"),AI.forEach(t),O0o=i(S),vl=n(S,"LI",{});var LI=s(vl);Rue=n(LI,"STRONG",{});var fyt=s(Rue);V0o=r(fyt,"xlm-roberta-xl"),fyt.forEach(t),X0o=r(LI," \u2014 "),gO=n(LI,"A",{href:!0});var gyt=s(gO);z0o=r(gyt,"XLMRobertaTokenizer"),gyt.forEach(t),Q0o=r(LI," or "),hO=n(LI,"A",{href:!0});var hyt=s(hO);W0o=r(hyt,"XLMRobertaTokenizerFast"),hyt.forEach(t),U0o=r(LI," (XLM-RoBERTa-XL model)"),LI.forEach(t),H0o=i(S),Fl=n(S,"LI",{});var yI=s(Fl);Pue=n(yI,"STRONG",{});var uyt=s(Pue);J0o=r(uyt,"xlnet"),uyt.forEach(t),Y0o=r(yI," \u2014 "),uO=n(yI,"A",{href:!0});var pyt=s(uO);Z0o=r(pyt,"XLNetTokenizer"),pyt.forEach(t),K0o=r(yI," or "),pO=n(yI,"A",{href:!0});var _yt=s(pO);ewo=r(_yt,"XLNetTokenizerFast"),_yt.forEach(t),owo=r(yI," (XLNet model)"),yI.forEach(t),rwo=i(S),Tl=n(S,"LI",{});var xI=s(Tl);Bue=n(xI,"STRONG",{});var byt=s(Bue);two=r(byt,"yoso"),byt.forEach(t),awo=r(xI," \u2014 "),_O=n(xI,"A",{href:!0});var vyt=s(_O);nwo=r(vyt,"AlbertTokenizer"),vyt.forEach(t),swo=r(xI," or "),bO=n(xI,"A",{href:!0});var Fyt=s(bO);lwo=r(Fyt,"AlbertTokenizerFast"),Fyt.forEach(t),iwo=r(xI," (YOSO model)"),xI.forEach(t),S.forEach(t),dwo=i(yl),T(Hu.$$.fragment,yl),yl.forEach(t),cwo=i(Ll),Ju=n(Ll,"DIV",{class:!0});var Xto=s(Ju);T(Vx.$$.fragment,Xto),mwo=i(Xto),Iue=n(Xto,"P",{});var Tyt=s(Iue);fwo=r(Tyt,"Register a new tokenizer in this mapping."),Tyt.forEach(t),Xto.forEach(t),Ll.forEach(t),Roo=i(m),Fd=n(m,"H2",{class:!0});var zto=s(Fd);Yu=n(zto,"A",{id:!0,class:!0,href:!0});var Myt=s(Yu);Nue=n(Myt,"SPAN",{});var Eyt=s(Nue);T(Xx.$$.fragment,Eyt),Eyt.forEach(t),Myt.forEach(t),gwo=i(zto),que=n(zto,"SPAN",{});var Cyt=s(que);hwo=r(Cyt,"AutoFeatureExtractor"),Cyt.forEach(t),zto.forEach(t),Poo=i(m),Ro=n(m,"DIV",{class:!0});var xl=s(Ro);T(zx.$$.fragment,xl),uwo=i(xl),Qx=n(xl,"P",{});var Qto=s(Qx);pwo=r(Qto,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),vO=n(Qto,"A",{href:!0});var wyt=s(vO);_wo=r(wyt,"AutoFeatureExtractor.from_pretrained()"),wyt.forEach(t),bwo=r(Qto," class method."),Qto.forEach(t),vwo=i(xl),Wx=n(xl,"P",{});var Wto=s(Wx);Fwo=r(Wto,"This class cannot be instantiated directly using "),jue=n(Wto,"CODE",{});var Ayt=s(jue);Two=r(Ayt,"__init__()"),Ayt.forEach(t),Mwo=r(Wto," (throws an error)."),Wto.forEach(t),Ewo=i(xl),Ye=n(xl,"DIV",{class:!0});var Ta=s(Ye);T(Ux.$$.fragment,Ta),Cwo=i(Ta),Due=n(Ta,"P",{});var Lyt=s(Due);wwo=r(Lyt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Lyt.forEach(t),Awo=i(Ta),Ka=n(Ta,"P",{});var Ty=s(Ka);Lwo=r(Ty,"The feature extractor class to instantiate is selected based on the "),Gue=n(Ty,"CODE",{});var yyt=s(Gue);ywo=r(yyt,"model_type"),yyt.forEach(t),xwo=r(Ty,` property of the config object
(either passed as an argument or loaded from `),Oue=n(Ty,"CODE",{});var xyt=s(Oue);$wo=r(xyt,"pretrained_model_name_or_path"),xyt.forEach(t),kwo=r(Ty,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Vue=n(Ty,"CODE",{});var $yt=s(Vue);Swo=r($yt,"pretrained_model_name_or_path"),$yt.forEach(t),Rwo=r(Ty,":"),Ty.forEach(t),Pwo=i(Ta),z=n(Ta,"UL",{});var W=s(z);Zu=n(W,"LI",{});var jNe=s(Zu);Xue=n(jNe,"STRONG",{});var kyt=s(Xue);Bwo=r(kyt,"beit"),kyt.forEach(t),Iwo=r(jNe," \u2014 "),FO=n(jNe,"A",{href:!0});var Syt=s(FO);Nwo=r(Syt,"BeitFeatureExtractor"),Syt.forEach(t),qwo=r(jNe," (BEiT model)"),jNe.forEach(t),jwo=i(W),Ku=n(W,"LI",{});var DNe=s(Ku);zue=n(DNe,"STRONG",{});var Ryt=s(zue);Dwo=r(Ryt,"clip"),Ryt.forEach(t),Gwo=r(DNe," \u2014 "),TO=n(DNe,"A",{href:!0});var Pyt=s(TO);Owo=r(Pyt,"CLIPFeatureExtractor"),Pyt.forEach(t),Vwo=r(DNe," (CLIP model)"),DNe.forEach(t),Xwo=i(W),ep=n(W,"LI",{});var GNe=s(ep);Que=n(GNe,"STRONG",{});var Byt=s(Que);zwo=r(Byt,"conditional_detr"),Byt.forEach(t),Qwo=r(GNe," \u2014 "),MO=n(GNe,"A",{href:!0});var Iyt=s(MO);Wwo=r(Iyt,"ConditionalDetrFeatureExtractor"),Iyt.forEach(t),Uwo=r(GNe," (Conditional DETR model)"),GNe.forEach(t),Hwo=i(W),op=n(W,"LI",{});var ONe=s(op);Wue=n(ONe,"STRONG",{});var Nyt=s(Wue);Jwo=r(Nyt,"convnext"),Nyt.forEach(t),Ywo=r(ONe," \u2014 "),EO=n(ONe,"A",{href:!0});var qyt=s(EO);Zwo=r(qyt,"ConvNextFeatureExtractor"),qyt.forEach(t),Kwo=r(ONe," (ConvNeXT model)"),ONe.forEach(t),eAo=i(W),rp=n(W,"LI",{});var VNe=s(rp);Uue=n(VNe,"STRONG",{});var jyt=s(Uue);oAo=r(jyt,"cvt"),jyt.forEach(t),rAo=r(VNe," \u2014 "),CO=n(VNe,"A",{href:!0});var Dyt=s(CO);tAo=r(Dyt,"ConvNextFeatureExtractor"),Dyt.forEach(t),aAo=r(VNe," (CvT model)"),VNe.forEach(t),nAo=i(W),tp=n(W,"LI",{});var XNe=s(tp);Hue=n(XNe,"STRONG",{});var Gyt=s(Hue);sAo=r(Gyt,"data2vec-audio"),Gyt.forEach(t),lAo=r(XNe," \u2014 "),wO=n(XNe,"A",{href:!0});var Oyt=s(wO);iAo=r(Oyt,"Wav2Vec2FeatureExtractor"),Oyt.forEach(t),dAo=r(XNe," (Data2VecAudio model)"),XNe.forEach(t),cAo=i(W),ap=n(W,"LI",{});var zNe=s(ap);Jue=n(zNe,"STRONG",{});var Vyt=s(Jue);mAo=r(Vyt,"data2vec-vision"),Vyt.forEach(t),fAo=r(zNe," \u2014 "),AO=n(zNe,"A",{href:!0});var Xyt=s(AO);gAo=r(Xyt,"BeitFeatureExtractor"),Xyt.forEach(t),hAo=r(zNe," (Data2VecVision model)"),zNe.forEach(t),uAo=i(W),np=n(W,"LI",{});var QNe=s(np);Yue=n(QNe,"STRONG",{});var zyt=s(Yue);pAo=r(zyt,"deformable_detr"),zyt.forEach(t),_Ao=r(QNe," \u2014 "),LO=n(QNe,"A",{href:!0});var Qyt=s(LO);bAo=r(Qyt,"DeformableDetrFeatureExtractor"),Qyt.forEach(t),vAo=r(QNe," (Deformable DETR model)"),QNe.forEach(t),FAo=i(W),sp=n(W,"LI",{});var WNe=s(sp);Zue=n(WNe,"STRONG",{});var Wyt=s(Zue);TAo=r(Wyt,"deit"),Wyt.forEach(t),MAo=r(WNe," \u2014 "),yO=n(WNe,"A",{href:!0});var Uyt=s(yO);EAo=r(Uyt,"DeiTFeatureExtractor"),Uyt.forEach(t),CAo=r(WNe," (DeiT model)"),WNe.forEach(t),wAo=i(W),lp=n(W,"LI",{});var UNe=s(lp);Kue=n(UNe,"STRONG",{});var Hyt=s(Kue);AAo=r(Hyt,"detr"),Hyt.forEach(t),LAo=r(UNe," \u2014 "),xO=n(UNe,"A",{href:!0});var Jyt=s(xO);yAo=r(Jyt,"DetrFeatureExtractor"),Jyt.forEach(t),xAo=r(UNe," (DETR model)"),UNe.forEach(t),$Ao=i(W),ip=n(W,"LI",{});var HNe=s(ip);epe=n(HNe,"STRONG",{});var Yyt=s(epe);kAo=r(Yyt,"donut"),Yyt.forEach(t),SAo=r(HNe," \u2014 "),$O=n(HNe,"A",{href:!0});var Zyt=s($O);RAo=r(Zyt,"DonutFeatureExtractor"),Zyt.forEach(t),PAo=r(HNe," (Donut model)"),HNe.forEach(t),BAo=i(W),dp=n(W,"LI",{});var JNe=s(dp);ope=n(JNe,"STRONG",{});var Kyt=s(ope);IAo=r(Kyt,"dpt"),Kyt.forEach(t),NAo=r(JNe," \u2014 "),kO=n(JNe,"A",{href:!0});var e9t=s(kO);qAo=r(e9t,"DPTFeatureExtractor"),e9t.forEach(t),jAo=r(JNe," (DPT model)"),JNe.forEach(t),DAo=i(W),cp=n(W,"LI",{});var YNe=s(cp);rpe=n(YNe,"STRONG",{});var o9t=s(rpe);GAo=r(o9t,"flava"),o9t.forEach(t),OAo=r(YNe," \u2014 "),SO=n(YNe,"A",{href:!0});var r9t=s(SO);VAo=r(r9t,"FlavaFeatureExtractor"),r9t.forEach(t),XAo=r(YNe," (FLAVA model)"),YNe.forEach(t),zAo=i(W),mp=n(W,"LI",{});var ZNe=s(mp);tpe=n(ZNe,"STRONG",{});var t9t=s(tpe);QAo=r(t9t,"glpn"),t9t.forEach(t),WAo=r(ZNe," \u2014 "),RO=n(ZNe,"A",{href:!0});var a9t=s(RO);UAo=r(a9t,"GLPNFeatureExtractor"),a9t.forEach(t),HAo=r(ZNe," (GLPN model)"),ZNe.forEach(t),JAo=i(W),fp=n(W,"LI",{});var KNe=s(fp);ape=n(KNe,"STRONG",{});var n9t=s(ape);YAo=r(n9t,"groupvit"),n9t.forEach(t),ZAo=r(KNe," \u2014 "),PO=n(KNe,"A",{href:!0});var s9t=s(PO);KAo=r(s9t,"CLIPFeatureExtractor"),s9t.forEach(t),e6o=r(KNe," (GroupViT model)"),KNe.forEach(t),o6o=i(W),gp=n(W,"LI",{});var eqe=s(gp);npe=n(eqe,"STRONG",{});var l9t=s(npe);r6o=r(l9t,"hubert"),l9t.forEach(t),t6o=r(eqe," \u2014 "),BO=n(eqe,"A",{href:!0});var i9t=s(BO);a6o=r(i9t,"Wav2Vec2FeatureExtractor"),i9t.forEach(t),n6o=r(eqe," (Hubert model)"),eqe.forEach(t),s6o=i(W),hp=n(W,"LI",{});var oqe=s(hp);spe=n(oqe,"STRONG",{});var d9t=s(spe);l6o=r(d9t,"imagegpt"),d9t.forEach(t),i6o=r(oqe," \u2014 "),IO=n(oqe,"A",{href:!0});var c9t=s(IO);d6o=r(c9t,"ImageGPTFeatureExtractor"),c9t.forEach(t),c6o=r(oqe," (ImageGPT model)"),oqe.forEach(t),m6o=i(W),up=n(W,"LI",{});var rqe=s(up);lpe=n(rqe,"STRONG",{});var m9t=s(lpe);f6o=r(m9t,"layoutlmv2"),m9t.forEach(t),g6o=r(rqe," \u2014 "),NO=n(rqe,"A",{href:!0});var f9t=s(NO);h6o=r(f9t,"LayoutLMv2FeatureExtractor"),f9t.forEach(t),u6o=r(rqe," (LayoutLMv2 model)"),rqe.forEach(t),p6o=i(W),pp=n(W,"LI",{});var tqe=s(pp);ipe=n(tqe,"STRONG",{});var g9t=s(ipe);_6o=r(g9t,"layoutlmv3"),g9t.forEach(t),b6o=r(tqe," \u2014 "),qO=n(tqe,"A",{href:!0});var h9t=s(qO);v6o=r(h9t,"LayoutLMv3FeatureExtractor"),h9t.forEach(t),F6o=r(tqe," (LayoutLMv3 model)"),tqe.forEach(t),T6o=i(W),_p=n(W,"LI",{});var aqe=s(_p);dpe=n(aqe,"STRONG",{});var u9t=s(dpe);M6o=r(u9t,"levit"),u9t.forEach(t),E6o=r(aqe," \u2014 "),jO=n(aqe,"A",{href:!0});var p9t=s(jO);C6o=r(p9t,"LevitFeatureExtractor"),p9t.forEach(t),w6o=r(aqe," (LeViT model)"),aqe.forEach(t),A6o=i(W),bp=n(W,"LI",{});var nqe=s(bp);cpe=n(nqe,"STRONG",{});var _9t=s(cpe);L6o=r(_9t,"maskformer"),_9t.forEach(t),y6o=r(nqe," \u2014 "),DO=n(nqe,"A",{href:!0});var b9t=s(DO);x6o=r(b9t,"MaskFormerFeatureExtractor"),b9t.forEach(t),$6o=r(nqe," (MaskFormer model)"),nqe.forEach(t),k6o=i(W),vp=n(W,"LI",{});var sqe=s(vp);mpe=n(sqe,"STRONG",{});var v9t=s(mpe);S6o=r(v9t,"mctct"),v9t.forEach(t),R6o=r(sqe," \u2014 "),GO=n(sqe,"A",{href:!0});var F9t=s(GO);P6o=r(F9t,"MCTCTFeatureExtractor"),F9t.forEach(t),B6o=r(sqe," (M-CTC-T model)"),sqe.forEach(t),I6o=i(W),Fp=n(W,"LI",{});var lqe=s(Fp);fpe=n(lqe,"STRONG",{});var T9t=s(fpe);N6o=r(T9t,"mobilevit"),T9t.forEach(t),q6o=r(lqe," \u2014 "),OO=n(lqe,"A",{href:!0});var M9t=s(OO);j6o=r(M9t,"MobileViTFeatureExtractor"),M9t.forEach(t),D6o=r(lqe," (MobileViT model)"),lqe.forEach(t),G6o=i(W),Tp=n(W,"LI",{});var iqe=s(Tp);gpe=n(iqe,"STRONG",{});var E9t=s(gpe);O6o=r(E9t,"owlvit"),E9t.forEach(t),V6o=r(iqe," \u2014 "),VO=n(iqe,"A",{href:!0});var C9t=s(VO);X6o=r(C9t,"OwlViTFeatureExtractor"),C9t.forEach(t),z6o=r(iqe," (OWL-ViT model)"),iqe.forEach(t),Q6o=i(W),Mp=n(W,"LI",{});var dqe=s(Mp);hpe=n(dqe,"STRONG",{});var w9t=s(hpe);W6o=r(w9t,"perceiver"),w9t.forEach(t),U6o=r(dqe," \u2014 "),XO=n(dqe,"A",{href:!0});var A9t=s(XO);H6o=r(A9t,"PerceiverFeatureExtractor"),A9t.forEach(t),J6o=r(dqe," (Perceiver model)"),dqe.forEach(t),Y6o=i(W),Ep=n(W,"LI",{});var cqe=s(Ep);upe=n(cqe,"STRONG",{});var L9t=s(upe);Z6o=r(L9t,"poolformer"),L9t.forEach(t),K6o=r(cqe," \u2014 "),zO=n(cqe,"A",{href:!0});var y9t=s(zO);e7o=r(y9t,"PoolFormerFeatureExtractor"),y9t.forEach(t),o7o=r(cqe," (PoolFormer model)"),cqe.forEach(t),r7o=i(W),Cp=n(W,"LI",{});var mqe=s(Cp);ppe=n(mqe,"STRONG",{});var x9t=s(ppe);t7o=r(x9t,"regnet"),x9t.forEach(t),a7o=r(mqe," \u2014 "),QO=n(mqe,"A",{href:!0});var $9t=s(QO);n7o=r($9t,"ConvNextFeatureExtractor"),$9t.forEach(t),s7o=r(mqe," (RegNet model)"),mqe.forEach(t),l7o=i(W),wp=n(W,"LI",{});var fqe=s(wp);_pe=n(fqe,"STRONG",{});var k9t=s(_pe);i7o=r(k9t,"resnet"),k9t.forEach(t),d7o=r(fqe," \u2014 "),WO=n(fqe,"A",{href:!0});var S9t=s(WO);c7o=r(S9t,"ConvNextFeatureExtractor"),S9t.forEach(t),m7o=r(fqe," (ResNet model)"),fqe.forEach(t),f7o=i(W),Ap=n(W,"LI",{});var gqe=s(Ap);bpe=n(gqe,"STRONG",{});var R9t=s(bpe);g7o=r(R9t,"segformer"),R9t.forEach(t),h7o=r(gqe," \u2014 "),UO=n(gqe,"A",{href:!0});var P9t=s(UO);u7o=r(P9t,"SegformerFeatureExtractor"),P9t.forEach(t),p7o=r(gqe," (SegFormer model)"),gqe.forEach(t),_7o=i(W),Lp=n(W,"LI",{});var hqe=s(Lp);vpe=n(hqe,"STRONG",{});var B9t=s(vpe);b7o=r(B9t,"speech_to_text"),B9t.forEach(t),v7o=r(hqe," \u2014 "),HO=n(hqe,"A",{href:!0});var I9t=s(HO);F7o=r(I9t,"Speech2TextFeatureExtractor"),I9t.forEach(t),T7o=r(hqe," (Speech2Text model)"),hqe.forEach(t),M7o=i(W),yp=n(W,"LI",{});var uqe=s(yp);Fpe=n(uqe,"STRONG",{});var N9t=s(Fpe);E7o=r(N9t,"swin"),N9t.forEach(t),C7o=r(uqe," \u2014 "),JO=n(uqe,"A",{href:!0});var q9t=s(JO);w7o=r(q9t,"ViTFeatureExtractor"),q9t.forEach(t),A7o=r(uqe," (Swin Transformer model)"),uqe.forEach(t),L7o=i(W),xp=n(W,"LI",{});var pqe=s(xp);Tpe=n(pqe,"STRONG",{});var j9t=s(Tpe);y7o=r(j9t,"swinv2"),j9t.forEach(t),x7o=r(pqe," \u2014 "),YO=n(pqe,"A",{href:!0});var D9t=s(YO);$7o=r(D9t,"ViTFeatureExtractor"),D9t.forEach(t),k7o=r(pqe," (Swin Transformer V2 model)"),pqe.forEach(t),S7o=i(W),$p=n(W,"LI",{});var _qe=s($p);Mpe=n(_qe,"STRONG",{});var G9t=s(Mpe);R7o=r(G9t,"van"),G9t.forEach(t),P7o=r(_qe," \u2014 "),ZO=n(_qe,"A",{href:!0});var O9t=s(ZO);B7o=r(O9t,"ConvNextFeatureExtractor"),O9t.forEach(t),I7o=r(_qe," (VAN model)"),_qe.forEach(t),N7o=i(W),kp=n(W,"LI",{});var bqe=s(kp);Epe=n(bqe,"STRONG",{});var V9t=s(Epe);q7o=r(V9t,"videomae"),V9t.forEach(t),j7o=r(bqe," \u2014 "),KO=n(bqe,"A",{href:!0});var X9t=s(KO);D7o=r(X9t,"VideoMAEFeatureExtractor"),X9t.forEach(t),G7o=r(bqe," (VideoMAE model)"),bqe.forEach(t),O7o=i(W),Sp=n(W,"LI",{});var vqe=s(Sp);Cpe=n(vqe,"STRONG",{});var z9t=s(Cpe);V7o=r(z9t,"vilt"),z9t.forEach(t),X7o=r(vqe," \u2014 "),eV=n(vqe,"A",{href:!0});var Q9t=s(eV);z7o=r(Q9t,"ViltFeatureExtractor"),Q9t.forEach(t),Q7o=r(vqe," (ViLT model)"),vqe.forEach(t),W7o=i(W),Rp=n(W,"LI",{});var Fqe=s(Rp);wpe=n(Fqe,"STRONG",{});var W9t=s(wpe);U7o=r(W9t,"vit"),W9t.forEach(t),H7o=r(Fqe," \u2014 "),oV=n(Fqe,"A",{href:!0});var U9t=s(oV);J7o=r(U9t,"ViTFeatureExtractor"),U9t.forEach(t),Y7o=r(Fqe," (ViT model)"),Fqe.forEach(t),Z7o=i(W),Pp=n(W,"LI",{});var Tqe=s(Pp);Ape=n(Tqe,"STRONG",{});var H9t=s(Ape);K7o=r(H9t,"vit_mae"),H9t.forEach(t),eLo=r(Tqe," \u2014 "),rV=n(Tqe,"A",{href:!0});var J9t=s(rV);oLo=r(J9t,"ViTFeatureExtractor"),J9t.forEach(t),rLo=r(Tqe," (ViTMAE model)"),Tqe.forEach(t),tLo=i(W),Bp=n(W,"LI",{});var Mqe=s(Bp);Lpe=n(Mqe,"STRONG",{});var Y9t=s(Lpe);aLo=r(Y9t,"vit_msn"),Y9t.forEach(t),nLo=r(Mqe," \u2014 "),tV=n(Mqe,"A",{href:!0});var Z9t=s(tV);sLo=r(Z9t,"ViTFeatureExtractor"),Z9t.forEach(t),lLo=r(Mqe," (ViTMSN model)"),Mqe.forEach(t),iLo=i(W),Ip=n(W,"LI",{});var Eqe=s(Ip);ype=n(Eqe,"STRONG",{});var K9t=s(ype);dLo=r(K9t,"wav2vec2"),K9t.forEach(t),cLo=r(Eqe," \u2014 "),aV=n(Eqe,"A",{href:!0});var ext=s(aV);mLo=r(ext,"Wav2Vec2FeatureExtractor"),ext.forEach(t),fLo=r(Eqe," (Wav2Vec2 model)"),Eqe.forEach(t),gLo=i(W),Np=n(W,"LI",{});var Cqe=s(Np);xpe=n(Cqe,"STRONG",{});var oxt=s(xpe);hLo=r(oxt,"wav2vec2-conformer"),oxt.forEach(t),uLo=r(Cqe," \u2014 "),nV=n(Cqe,"A",{href:!0});var rxt=s(nV);pLo=r(rxt,"Wav2Vec2FeatureExtractor"),rxt.forEach(t),_Lo=r(Cqe," (Wav2Vec2-Conformer model)"),Cqe.forEach(t),bLo=i(W),qp=n(W,"LI",{});var wqe=s(qp);$pe=n(wqe,"STRONG",{});var txt=s($pe);vLo=r(txt,"whisper"),txt.forEach(t),FLo=r(wqe," \u2014 "),sV=n(wqe,"A",{href:!0});var axt=s(sV);TLo=r(axt,"WhisperFeatureExtractor"),axt.forEach(t),MLo=r(wqe," (Whisper model)"),wqe.forEach(t),ELo=i(W),jp=n(W,"LI",{});var Aqe=s(jp);kpe=n(Aqe,"STRONG",{});var nxt=s(kpe);CLo=r(nxt,"xclip"),nxt.forEach(t),wLo=r(Aqe," \u2014 "),lV=n(Aqe,"A",{href:!0});var sxt=s(lV);ALo=r(sxt,"CLIPFeatureExtractor"),sxt.forEach(t),LLo=r(Aqe," (X-CLIP model)"),Aqe.forEach(t),yLo=i(W),Dp=n(W,"LI",{});var Lqe=s(Dp);Spe=n(Lqe,"STRONG",{});var lxt=s(Spe);xLo=r(lxt,"yolos"),lxt.forEach(t),$Lo=r(Lqe," \u2014 "),iV=n(Lqe,"A",{href:!0});var ixt=s(iV);kLo=r(ixt,"YolosFeatureExtractor"),ixt.forEach(t),SLo=r(Lqe," (YOLOS model)"),Lqe.forEach(t),W.forEach(t),RLo=i(Ta),T(Gp.$$.fragment,Ta),PLo=i(Ta),T(Op.$$.fragment,Ta),Ta.forEach(t),BLo=i(xl),Vp=n(xl,"DIV",{class:!0});var Uto=s(Vp);T(Hx.$$.fragment,Uto),ILo=i(Uto),Rpe=n(Uto,"P",{});var dxt=s(Rpe);NLo=r(dxt,"Register a new feature extractor for this class."),dxt.forEach(t),Uto.forEach(t),xl.forEach(t),Boo=i(m),Td=n(m,"H2",{class:!0});var Hto=s(Td);Xp=n(Hto,"A",{id:!0,class:!0,href:!0});var cxt=s(Xp);Ppe=n(cxt,"SPAN",{});var mxt=s(Ppe);T(Jx.$$.fragment,mxt),mxt.forEach(t),cxt.forEach(t),qLo=i(Hto),Bpe=n(Hto,"SPAN",{});var fxt=s(Bpe);jLo=r(fxt,"AutoProcessor"),fxt.forEach(t),Hto.forEach(t),Ioo=i(m),Po=n(m,"DIV",{class:!0});var $l=s(Po);T(Yx.$$.fragment,$l),DLo=i($l),Zx=n($l,"P",{});var Jto=s(Zx);GLo=r(Jto,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),dV=n(Jto,"A",{href:!0});var gxt=s(dV);OLo=r(gxt,"AutoProcessor.from_pretrained()"),gxt.forEach(t),VLo=r(Jto," class method."),Jto.forEach(t),XLo=i($l),Kx=n($l,"P",{});var Yto=s(Kx);zLo=r(Yto,"This class cannot be instantiated directly using "),Ipe=n(Yto,"CODE",{});var hxt=s(Ipe);QLo=r(hxt,"__init__()"),hxt.forEach(t),WLo=r(Yto," (throws an error)."),Yto.forEach(t),ULo=i($l),Ze=n($l,"DIV",{class:!0});var Ma=s(Ze);T(e$.$$.fragment,Ma),HLo=i(Ma),Npe=n(Ma,"P",{});var uxt=s(Npe);JLo=r(uxt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),uxt.forEach(t),YLo=i(Ma),Md=n(Ma,"P",{});var Uie=s(Md);ZLo=r(Uie,"The processor class to instantiate is selected based on the "),qpe=n(Uie,"CODE",{});var pxt=s(qpe);KLo=r(pxt,"model_type"),pxt.forEach(t),e8o=r(Uie,` property of the config object (either
passed as an argument or loaded from `),jpe=n(Uie,"CODE",{});var _xt=s(jpe);o8o=r(_xt,"pretrained_model_name_or_path"),_xt.forEach(t),r8o=r(Uie," if possible):"),Uie.forEach(t),t8o=i(Ma),se=n(Ma,"UL",{});var ie=s(se);zp=n(ie,"LI",{});var yqe=s(zp);Dpe=n(yqe,"STRONG",{});var bxt=s(Dpe);a8o=r(bxt,"clip"),bxt.forEach(t),n8o=r(yqe," \u2014 "),cV=n(yqe,"A",{href:!0});var vxt=s(cV);s8o=r(vxt,"CLIPProcessor"),vxt.forEach(t),l8o=r(yqe," (CLIP model)"),yqe.forEach(t),i8o=i(ie),Qp=n(ie,"LI",{});var xqe=s(Qp);Gpe=n(xqe,"STRONG",{});var Fxt=s(Gpe);d8o=r(Fxt,"donut"),Fxt.forEach(t),c8o=r(xqe," \u2014 "),mV=n(xqe,"A",{href:!0});var Txt=s(mV);m8o=r(Txt,"DonutProcessor"),Txt.forEach(t),f8o=r(xqe," (Donut model)"),xqe.forEach(t),g8o=i(ie),Wp=n(ie,"LI",{});var $qe=s(Wp);Ope=n($qe,"STRONG",{});var Mxt=s(Ope);h8o=r(Mxt,"flava"),Mxt.forEach(t),u8o=r($qe," \u2014 "),fV=n($qe,"A",{href:!0});var Ext=s(fV);p8o=r(Ext,"FlavaProcessor"),Ext.forEach(t),_8o=r($qe," (FLAVA model)"),$qe.forEach(t),b8o=i(ie),Up=n(ie,"LI",{});var kqe=s(Up);Vpe=n(kqe,"STRONG",{});var Cxt=s(Vpe);v8o=r(Cxt,"groupvit"),Cxt.forEach(t),F8o=r(kqe," \u2014 "),gV=n(kqe,"A",{href:!0});var wxt=s(gV);T8o=r(wxt,"CLIPProcessor"),wxt.forEach(t),M8o=r(kqe," (GroupViT model)"),kqe.forEach(t),E8o=i(ie),Hp=n(ie,"LI",{});var Sqe=s(Hp);Xpe=n(Sqe,"STRONG",{});var Axt=s(Xpe);C8o=r(Axt,"layoutlmv2"),Axt.forEach(t),w8o=r(Sqe," \u2014 "),hV=n(Sqe,"A",{href:!0});var Lxt=s(hV);A8o=r(Lxt,"LayoutLMv2Processor"),Lxt.forEach(t),L8o=r(Sqe," (LayoutLMv2 model)"),Sqe.forEach(t),y8o=i(ie),Jp=n(ie,"LI",{});var Rqe=s(Jp);zpe=n(Rqe,"STRONG",{});var yxt=s(zpe);x8o=r(yxt,"layoutlmv3"),yxt.forEach(t),$8o=r(Rqe," \u2014 "),uV=n(Rqe,"A",{href:!0});var xxt=s(uV);k8o=r(xxt,"LayoutLMv3Processor"),xxt.forEach(t),S8o=r(Rqe," (LayoutLMv3 model)"),Rqe.forEach(t),R8o=i(ie),Yp=n(ie,"LI",{});var Pqe=s(Yp);Qpe=n(Pqe,"STRONG",{});var $xt=s(Qpe);P8o=r($xt,"layoutxlm"),$xt.forEach(t),B8o=r(Pqe," \u2014 "),pV=n(Pqe,"A",{href:!0});var kxt=s(pV);I8o=r(kxt,"LayoutXLMProcessor"),kxt.forEach(t),N8o=r(Pqe," (LayoutXLM model)"),Pqe.forEach(t),q8o=i(ie),Zp=n(ie,"LI",{});var Bqe=s(Zp);Wpe=n(Bqe,"STRONG",{});var Sxt=s(Wpe);j8o=r(Sxt,"markuplm"),Sxt.forEach(t),D8o=r(Bqe," \u2014 "),_V=n(Bqe,"A",{href:!0});var Rxt=s(_V);G8o=r(Rxt,"MarkupLMProcessor"),Rxt.forEach(t),O8o=r(Bqe," (MarkupLM model)"),Bqe.forEach(t),V8o=i(ie),Kp=n(ie,"LI",{});var Iqe=s(Kp);Upe=n(Iqe,"STRONG",{});var Pxt=s(Upe);X8o=r(Pxt,"owlvit"),Pxt.forEach(t),z8o=r(Iqe," \u2014 "),bV=n(Iqe,"A",{href:!0});var Bxt=s(bV);Q8o=r(Bxt,"OwlViTProcessor"),Bxt.forEach(t),W8o=r(Iqe," (OWL-ViT model)"),Iqe.forEach(t),U8o=i(ie),e_=n(ie,"LI",{});var Nqe=s(e_);Hpe=n(Nqe,"STRONG",{});var Ixt=s(Hpe);H8o=r(Ixt,"sew"),Ixt.forEach(t),J8o=r(Nqe," \u2014 "),vV=n(Nqe,"A",{href:!0});var Nxt=s(vV);Y8o=r(Nxt,"Wav2Vec2Processor"),Nxt.forEach(t),Z8o=r(Nqe," (SEW model)"),Nqe.forEach(t),K8o=i(ie),o_=n(ie,"LI",{});var qqe=s(o_);Jpe=n(qqe,"STRONG",{});var qxt=s(Jpe);eyo=r(qxt,"sew-d"),qxt.forEach(t),oyo=r(qqe," \u2014 "),FV=n(qqe,"A",{href:!0});var jxt=s(FV);ryo=r(jxt,"Wav2Vec2Processor"),jxt.forEach(t),tyo=r(qqe," (SEW-D model)"),qqe.forEach(t),ayo=i(ie),r_=n(ie,"LI",{});var jqe=s(r_);Ype=n(jqe,"STRONG",{});var Dxt=s(Ype);nyo=r(Dxt,"speech_to_text"),Dxt.forEach(t),syo=r(jqe," \u2014 "),TV=n(jqe,"A",{href:!0});var Gxt=s(TV);lyo=r(Gxt,"Speech2TextProcessor"),Gxt.forEach(t),iyo=r(jqe," (Speech2Text model)"),jqe.forEach(t),dyo=i(ie),t_=n(ie,"LI",{});var Dqe=s(t_);Zpe=n(Dqe,"STRONG",{});var Oxt=s(Zpe);cyo=r(Oxt,"speech_to_text_2"),Oxt.forEach(t),myo=r(Dqe," \u2014 "),MV=n(Dqe,"A",{href:!0});var Vxt=s(MV);fyo=r(Vxt,"Speech2Text2Processor"),Vxt.forEach(t),gyo=r(Dqe," (Speech2Text2 model)"),Dqe.forEach(t),hyo=i(ie),a_=n(ie,"LI",{});var Gqe=s(a_);Kpe=n(Gqe,"STRONG",{});var Xxt=s(Kpe);uyo=r(Xxt,"trocr"),Xxt.forEach(t),pyo=r(Gqe," \u2014 "),EV=n(Gqe,"A",{href:!0});var zxt=s(EV);_yo=r(zxt,"TrOCRProcessor"),zxt.forEach(t),byo=r(Gqe," (TrOCR model)"),Gqe.forEach(t),vyo=i(ie),n_=n(ie,"LI",{});var Oqe=s(n_);e_e=n(Oqe,"STRONG",{});var Qxt=s(e_e);Fyo=r(Qxt,"unispeech"),Qxt.forEach(t),Tyo=r(Oqe," \u2014 "),CV=n(Oqe,"A",{href:!0});var Wxt=s(CV);Myo=r(Wxt,"Wav2Vec2Processor"),Wxt.forEach(t),Eyo=r(Oqe," (UniSpeech model)"),Oqe.forEach(t),Cyo=i(ie),s_=n(ie,"LI",{});var Vqe=s(s_);o_e=n(Vqe,"STRONG",{});var Uxt=s(o_e);wyo=r(Uxt,"unispeech-sat"),Uxt.forEach(t),Ayo=r(Vqe," \u2014 "),wV=n(Vqe,"A",{href:!0});var Hxt=s(wV);Lyo=r(Hxt,"Wav2Vec2Processor"),Hxt.forEach(t),yyo=r(Vqe," (UniSpeechSat model)"),Vqe.forEach(t),xyo=i(ie),l_=n(ie,"LI",{});var Xqe=s(l_);r_e=n(Xqe,"STRONG",{});var Jxt=s(r_e);$yo=r(Jxt,"vilt"),Jxt.forEach(t),kyo=r(Xqe," \u2014 "),AV=n(Xqe,"A",{href:!0});var Yxt=s(AV);Syo=r(Yxt,"ViltProcessor"),Yxt.forEach(t),Ryo=r(Xqe," (ViLT model)"),Xqe.forEach(t),Pyo=i(ie),i_=n(ie,"LI",{});var zqe=s(i_);t_e=n(zqe,"STRONG",{});var Zxt=s(t_e);Byo=r(Zxt,"vision-text-dual-encoder"),Zxt.forEach(t),Iyo=r(zqe," \u2014 "),LV=n(zqe,"A",{href:!0});var Kxt=s(LV);Nyo=r(Kxt,"VisionTextDualEncoderProcessor"),Kxt.forEach(t),qyo=r(zqe," (VisionTextDualEncoder model)"),zqe.forEach(t),jyo=i(ie),d_=n(ie,"LI",{});var Qqe=s(d_);a_e=n(Qqe,"STRONG",{});var e$t=s(a_e);Dyo=r(e$t,"wav2vec2"),e$t.forEach(t),Gyo=r(Qqe," \u2014 "),yV=n(Qqe,"A",{href:!0});var o$t=s(yV);Oyo=r(o$t,"Wav2Vec2Processor"),o$t.forEach(t),Vyo=r(Qqe," (Wav2Vec2 model)"),Qqe.forEach(t),Xyo=i(ie),c_=n(ie,"LI",{});var Wqe=s(c_);n_e=n(Wqe,"STRONG",{});var r$t=s(n_e);zyo=r(r$t,"wav2vec2-conformer"),r$t.forEach(t),Qyo=r(Wqe," \u2014 "),xV=n(Wqe,"A",{href:!0});var t$t=s(xV);Wyo=r(t$t,"Wav2Vec2Processor"),t$t.forEach(t),Uyo=r(Wqe," (Wav2Vec2-Conformer model)"),Wqe.forEach(t),Hyo=i(ie),m_=n(ie,"LI",{});var Uqe=s(m_);s_e=n(Uqe,"STRONG",{});var a$t=s(s_e);Jyo=r(a$t,"wavlm"),a$t.forEach(t),Yyo=r(Uqe," \u2014 "),$V=n(Uqe,"A",{href:!0});var n$t=s($V);Zyo=r(n$t,"Wav2Vec2Processor"),n$t.forEach(t),Kyo=r(Uqe," (WavLM model)"),Uqe.forEach(t),e9o=i(ie),f_=n(ie,"LI",{});var Hqe=s(f_);l_e=n(Hqe,"STRONG",{});var s$t=s(l_e);o9o=r(s$t,"whisper"),s$t.forEach(t),r9o=r(Hqe," \u2014 "),kV=n(Hqe,"A",{href:!0});var l$t=s(kV);t9o=r(l$t,"WhisperProcessor"),l$t.forEach(t),a9o=r(Hqe," (Whisper model)"),Hqe.forEach(t),n9o=i(ie),g_=n(ie,"LI",{});var Jqe=s(g_);i_e=n(Jqe,"STRONG",{});var i$t=s(i_e);s9o=r(i$t,"xclip"),i$t.forEach(t),l9o=r(Jqe," \u2014 "),SV=n(Jqe,"A",{href:!0});var d$t=s(SV);i9o=r(d$t,"CLIPProcessor"),d$t.forEach(t),d9o=r(Jqe," (X-CLIP model)"),Jqe.forEach(t),ie.forEach(t),c9o=i(Ma),T(h_.$$.fragment,Ma),m9o=i(Ma),T(u_.$$.fragment,Ma),Ma.forEach(t),f9o=i($l),p_=n($l,"DIV",{class:!0});var Zto=s(p_);T(o$.$$.fragment,Zto),g9o=i(Zto),d_e=n(Zto,"P",{});var c$t=s(d_e);h9o=r(c$t,"Register a new processor for this class."),c$t.forEach(t),Zto.forEach(t),$l.forEach(t),Noo=i(m),Ed=n(m,"H2",{class:!0});var Kto=s(Ed);__=n(Kto,"A",{id:!0,class:!0,href:!0});var m$t=s(__);c_e=n(m$t,"SPAN",{});var f$t=s(c_e);T(r$.$$.fragment,f$t),f$t.forEach(t),m$t.forEach(t),u9o=i(Kto),m_e=n(Kto,"SPAN",{});var g$t=s(m_e);p9o=r(g$t,"AutoModel"),g$t.forEach(t),Kto.forEach(t),qoo=i(m),Bo=n(m,"DIV",{class:!0});var kl=s(Bo);T(t$.$$.fragment,kl),_9o=i(kl),Cd=n(kl,"P",{});var Hie=s(Cd);b9o=r(Hie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RV=n(Hie,"A",{href:!0});var h$t=s(RV);v9o=r(h$t,"from_pretrained()"),h$t.forEach(t),F9o=r(Hie," class method or the "),PV=n(Hie,"A",{href:!0});var u$t=s(PV);T9o=r(u$t,"from_config()"),u$t.forEach(t),M9o=r(Hie,` class
method.`),Hie.forEach(t),E9o=i(kl),a$=n(kl,"P",{});var eao=s(a$);C9o=r(eao,"This class cannot be instantiated directly using "),f_e=n(eao,"CODE",{});var p$t=s(f_e);w9o=r(p$t,"__init__()"),p$t.forEach(t),A9o=r(eao," (throws an error)."),eao.forEach(t),L9o=i(kl),vt=n(kl,"DIV",{class:!0});var My=s(vt);T(n$.$$.fragment,My),y9o=i(My),g_e=n(My,"P",{});var _$t=s(g_e);x9o=r(_$t,"Instantiates one of the base model classes of the library from a configuration."),_$t.forEach(t),$9o=i(My),wd=n(My,"P",{});var Jie=s(wd);k9o=r(Jie,`Note:
Loading a model from its configuration file does `),h_e=n(Jie,"STRONG",{});var b$t=s(h_e);S9o=r(b$t,"not"),b$t.forEach(t),R9o=r(Jie,` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=n(Jie,"A",{href:!0});var v$t=s(BV);P9o=r(v$t,"from_pretrained()"),v$t.forEach(t),B9o=r(Jie," to load the model weights."),Jie.forEach(t),I9o=i(My),T(b_.$$.fragment,My),My.forEach(t),N9o=i(kl),Ke=n(kl,"DIV",{class:!0});var Ea=s(Ke);T(s$.$$.fragment,Ea),q9o=i(Ea),u_e=n(Ea,"P",{});var F$t=s(u_e);j9o=r(F$t,"Instantiate one of the base model classes of the library from a pretrained model."),F$t.forEach(t),D9o=i(Ea),en=n(Ea,"P",{});var Ey=s(en);G9o=r(Ey,"The model class to instantiate is selected based on the "),p_e=n(Ey,"CODE",{});var T$t=s(p_e);O9o=r(T$t,"model_type"),T$t.forEach(t),V9o=r(Ey,` property of the config object (either
passed as an argument or loaded from `),__e=n(Ey,"CODE",{});var M$t=s(__e);X9o=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),z9o=r(Ey,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=n(Ey,"CODE",{});var E$t=s(b_e);Q9o=r(E$t,"pretrained_model_name_or_path"),E$t.forEach(t),W9o=r(Ey,":"),Ey.forEach(t),U9o=i(Ea),y=n(Ea,"UL",{});var x=s(y);v_=n(x,"LI",{});var Yqe=s(v_);v_e=n(Yqe,"STRONG",{});var C$t=s(v_e);H9o=r(C$t,"albert"),C$t.forEach(t),J9o=r(Yqe," \u2014 "),IV=n(Yqe,"A",{href:!0});var w$t=s(IV);Y9o=r(w$t,"AlbertModel"),w$t.forEach(t),Z9o=r(Yqe," (ALBERT model)"),Yqe.forEach(t),K9o=i(x),F_=n(x,"LI",{});var Zqe=s(F_);F_e=n(Zqe,"STRONG",{});var A$t=s(F_e);exo=r(A$t,"bart"),A$t.forEach(t),oxo=r(Zqe," \u2014 "),NV=n(Zqe,"A",{href:!0});var L$t=s(NV);rxo=r(L$t,"BartModel"),L$t.forEach(t),txo=r(Zqe," (BART model)"),Zqe.forEach(t),axo=i(x),T_=n(x,"LI",{});var Kqe=s(T_);T_e=n(Kqe,"STRONG",{});var y$t=s(T_e);nxo=r(y$t,"beit"),y$t.forEach(t),sxo=r(Kqe," \u2014 "),qV=n(Kqe,"A",{href:!0});var x$t=s(qV);lxo=r(x$t,"BeitModel"),x$t.forEach(t),ixo=r(Kqe," (BEiT model)"),Kqe.forEach(t),dxo=i(x),M_=n(x,"LI",{});var eje=s(M_);M_e=n(eje,"STRONG",{});var $$t=s(M_e);cxo=r($$t,"bert"),$$t.forEach(t),mxo=r(eje," \u2014 "),jV=n(eje,"A",{href:!0});var k$t=s(jV);fxo=r(k$t,"BertModel"),k$t.forEach(t),gxo=r(eje," (BERT model)"),eje.forEach(t),hxo=i(x),E_=n(x,"LI",{});var oje=s(E_);E_e=n(oje,"STRONG",{});var S$t=s(E_e);uxo=r(S$t,"bert-generation"),S$t.forEach(t),pxo=r(oje," \u2014 "),DV=n(oje,"A",{href:!0});var R$t=s(DV);_xo=r(R$t,"BertGenerationEncoder"),R$t.forEach(t),bxo=r(oje," (Bert Generation model)"),oje.forEach(t),vxo=i(x),C_=n(x,"LI",{});var rje=s(C_);C_e=n(rje,"STRONG",{});var P$t=s(C_e);Fxo=r(P$t,"big_bird"),P$t.forEach(t),Txo=r(rje," \u2014 "),GV=n(rje,"A",{href:!0});var B$t=s(GV);Mxo=r(B$t,"BigBirdModel"),B$t.forEach(t),Exo=r(rje," (BigBird model)"),rje.forEach(t),Cxo=i(x),w_=n(x,"LI",{});var tje=s(w_);w_e=n(tje,"STRONG",{});var I$t=s(w_e);wxo=r(I$t,"bigbird_pegasus"),I$t.forEach(t),Axo=r(tje," \u2014 "),OV=n(tje,"A",{href:!0});var N$t=s(OV);Lxo=r(N$t,"BigBirdPegasusModel"),N$t.forEach(t),yxo=r(tje," (BigBird-Pegasus model)"),tje.forEach(t),xxo=i(x),A_=n(x,"LI",{});var aje=s(A_);A_e=n(aje,"STRONG",{});var q$t=s(A_e);$xo=r(q$t,"blenderbot"),q$t.forEach(t),kxo=r(aje," \u2014 "),VV=n(aje,"A",{href:!0});var j$t=s(VV);Sxo=r(j$t,"BlenderbotModel"),j$t.forEach(t),Rxo=r(aje," (Blenderbot model)"),aje.forEach(t),Pxo=i(x),L_=n(x,"LI",{});var nje=s(L_);L_e=n(nje,"STRONG",{});var D$t=s(L_e);Bxo=r(D$t,"blenderbot-small"),D$t.forEach(t),Ixo=r(nje," \u2014 "),XV=n(nje,"A",{href:!0});var G$t=s(XV);Nxo=r(G$t,"BlenderbotSmallModel"),G$t.forEach(t),qxo=r(nje," (BlenderbotSmall model)"),nje.forEach(t),jxo=i(x),y_=n(x,"LI",{});var sje=s(y_);y_e=n(sje,"STRONG",{});var O$t=s(y_e);Dxo=r(O$t,"bloom"),O$t.forEach(t),Gxo=r(sje," \u2014 "),zV=n(sje,"A",{href:!0});var V$t=s(zV);Oxo=r(V$t,"BloomModel"),V$t.forEach(t),Vxo=r(sje," (BLOOM model)"),sje.forEach(t),Xxo=i(x),x_=n(x,"LI",{});var lje=s(x_);x_e=n(lje,"STRONG",{});var X$t=s(x_e);zxo=r(X$t,"camembert"),X$t.forEach(t),Qxo=r(lje," \u2014 "),QV=n(lje,"A",{href:!0});var z$t=s(QV);Wxo=r(z$t,"CamembertModel"),z$t.forEach(t),Uxo=r(lje," (CamemBERT model)"),lje.forEach(t),Hxo=i(x),$_=n(x,"LI",{});var ije=s($_);$_e=n(ije,"STRONG",{});var Q$t=s($_e);Jxo=r(Q$t,"canine"),Q$t.forEach(t),Yxo=r(ije," \u2014 "),WV=n(ije,"A",{href:!0});var W$t=s(WV);Zxo=r(W$t,"CanineModel"),W$t.forEach(t),Kxo=r(ije," (CANINE model)"),ije.forEach(t),e$o=i(x),k_=n(x,"LI",{});var dje=s(k_);k_e=n(dje,"STRONG",{});var U$t=s(k_e);o$o=r(U$t,"clip"),U$t.forEach(t),r$o=r(dje," \u2014 "),UV=n(dje,"A",{href:!0});var H$t=s(UV);t$o=r(H$t,"CLIPModel"),H$t.forEach(t),a$o=r(dje," (CLIP model)"),dje.forEach(t),n$o=i(x),S_=n(x,"LI",{});var cje=s(S_);S_e=n(cje,"STRONG",{});var J$t=s(S_e);s$o=r(J$t,"codegen"),J$t.forEach(t),l$o=r(cje," \u2014 "),HV=n(cje,"A",{href:!0});var Y$t=s(HV);i$o=r(Y$t,"CodeGenModel"),Y$t.forEach(t),d$o=r(cje," (CodeGen model)"),cje.forEach(t),c$o=i(x),R_=n(x,"LI",{});var mje=s(R_);R_e=n(mje,"STRONG",{});var Z$t=s(R_e);m$o=r(Z$t,"conditional_detr"),Z$t.forEach(t),f$o=r(mje," \u2014 "),JV=n(mje,"A",{href:!0});var K$t=s(JV);g$o=r(K$t,"ConditionalDetrModel"),K$t.forEach(t),h$o=r(mje," (Conditional DETR model)"),mje.forEach(t),u$o=i(x),P_=n(x,"LI",{});var fje=s(P_);P_e=n(fje,"STRONG",{});var ekt=s(P_e);p$o=r(ekt,"convbert"),ekt.forEach(t),_$o=r(fje," \u2014 "),YV=n(fje,"A",{href:!0});var okt=s(YV);b$o=r(okt,"ConvBertModel"),okt.forEach(t),v$o=r(fje," (ConvBERT model)"),fje.forEach(t),F$o=i(x),B_=n(x,"LI",{});var gje=s(B_);B_e=n(gje,"STRONG",{});var rkt=s(B_e);T$o=r(rkt,"convnext"),rkt.forEach(t),M$o=r(gje," \u2014 "),ZV=n(gje,"A",{href:!0});var tkt=s(ZV);E$o=r(tkt,"ConvNextModel"),tkt.forEach(t),C$o=r(gje," (ConvNeXT model)"),gje.forEach(t),w$o=i(x),I_=n(x,"LI",{});var hje=s(I_);I_e=n(hje,"STRONG",{});var akt=s(I_e);A$o=r(akt,"ctrl"),akt.forEach(t),L$o=r(hje," \u2014 "),KV=n(hje,"A",{href:!0});var nkt=s(KV);y$o=r(nkt,"CTRLModel"),nkt.forEach(t),x$o=r(hje," (CTRL model)"),hje.forEach(t),$$o=i(x),N_=n(x,"LI",{});var uje=s(N_);N_e=n(uje,"STRONG",{});var skt=s(N_e);k$o=r(skt,"cvt"),skt.forEach(t),S$o=r(uje," \u2014 "),eX=n(uje,"A",{href:!0});var lkt=s(eX);R$o=r(lkt,"CvtModel"),lkt.forEach(t),P$o=r(uje," (CvT model)"),uje.forEach(t),B$o=i(x),q_=n(x,"LI",{});var pje=s(q_);q_e=n(pje,"STRONG",{});var ikt=s(q_e);I$o=r(ikt,"data2vec-audio"),ikt.forEach(t),N$o=r(pje," \u2014 "),oX=n(pje,"A",{href:!0});var dkt=s(oX);q$o=r(dkt,"Data2VecAudioModel"),dkt.forEach(t),j$o=r(pje," (Data2VecAudio model)"),pje.forEach(t),D$o=i(x),j_=n(x,"LI",{});var _je=s(j_);j_e=n(_je,"STRONG",{});var ckt=s(j_e);G$o=r(ckt,"data2vec-text"),ckt.forEach(t),O$o=r(_je," \u2014 "),rX=n(_je,"A",{href:!0});var mkt=s(rX);V$o=r(mkt,"Data2VecTextModel"),mkt.forEach(t),X$o=r(_je," (Data2VecText model)"),_je.forEach(t),z$o=i(x),D_=n(x,"LI",{});var bje=s(D_);D_e=n(bje,"STRONG",{});var fkt=s(D_e);Q$o=r(fkt,"data2vec-vision"),fkt.forEach(t),W$o=r(bje," \u2014 "),tX=n(bje,"A",{href:!0});var gkt=s(tX);U$o=r(gkt,"Data2VecVisionModel"),gkt.forEach(t),H$o=r(bje," (Data2VecVision model)"),bje.forEach(t),J$o=i(x),G_=n(x,"LI",{});var vje=s(G_);G_e=n(vje,"STRONG",{});var hkt=s(G_e);Y$o=r(hkt,"deberta"),hkt.forEach(t),Z$o=r(vje," \u2014 "),aX=n(vje,"A",{href:!0});var ukt=s(aX);K$o=r(ukt,"DebertaModel"),ukt.forEach(t),eko=r(vje," (DeBERTa model)"),vje.forEach(t),oko=i(x),O_=n(x,"LI",{});var Fje=s(O_);O_e=n(Fje,"STRONG",{});var pkt=s(O_e);rko=r(pkt,"deberta-v2"),pkt.forEach(t),tko=r(Fje," \u2014 "),nX=n(Fje,"A",{href:!0});var _kt=s(nX);ako=r(_kt,"DebertaV2Model"),_kt.forEach(t),nko=r(Fje," (DeBERTa-v2 model)"),Fje.forEach(t),sko=i(x),V_=n(x,"LI",{});var Tje=s(V_);V_e=n(Tje,"STRONG",{});var bkt=s(V_e);lko=r(bkt,"decision_transformer"),bkt.forEach(t),iko=r(Tje," \u2014 "),sX=n(Tje,"A",{href:!0});var vkt=s(sX);dko=r(vkt,"DecisionTransformerModel"),vkt.forEach(t),cko=r(Tje," (Decision Transformer model)"),Tje.forEach(t),mko=i(x),X_=n(x,"LI",{});var Mje=s(X_);X_e=n(Mje,"STRONG",{});var Fkt=s(X_e);fko=r(Fkt,"deformable_detr"),Fkt.forEach(t),gko=r(Mje," \u2014 "),lX=n(Mje,"A",{href:!0});var Tkt=s(lX);hko=r(Tkt,"DeformableDetrModel"),Tkt.forEach(t),uko=r(Mje," (Deformable DETR model)"),Mje.forEach(t),pko=i(x),z_=n(x,"LI",{});var Eje=s(z_);z_e=n(Eje,"STRONG",{});var Mkt=s(z_e);_ko=r(Mkt,"deit"),Mkt.forEach(t),bko=r(Eje," \u2014 "),iX=n(Eje,"A",{href:!0});var Ekt=s(iX);vko=r(Ekt,"DeiTModel"),Ekt.forEach(t),Fko=r(Eje," (DeiT model)"),Eje.forEach(t),Tko=i(x),Q_=n(x,"LI",{});var Cje=s(Q_);Q_e=n(Cje,"STRONG",{});var Ckt=s(Q_e);Mko=r(Ckt,"detr"),Ckt.forEach(t),Eko=r(Cje," \u2014 "),dX=n(Cje,"A",{href:!0});var wkt=s(dX);Cko=r(wkt,"DetrModel"),wkt.forEach(t),wko=r(Cje," (DETR model)"),Cje.forEach(t),Ako=i(x),W_=n(x,"LI",{});var wje=s(W_);W_e=n(wje,"STRONG",{});var Akt=s(W_e);Lko=r(Akt,"distilbert"),Akt.forEach(t),yko=r(wje," \u2014 "),cX=n(wje,"A",{href:!0});var Lkt=s(cX);xko=r(Lkt,"DistilBertModel"),Lkt.forEach(t),$ko=r(wje," (DistilBERT model)"),wje.forEach(t),kko=i(x),U_=n(x,"LI",{});var Aje=s(U_);U_e=n(Aje,"STRONG",{});var ykt=s(U_e);Sko=r(ykt,"donut-swin"),ykt.forEach(t),Rko=r(Aje," \u2014 "),mX=n(Aje,"A",{href:!0});var xkt=s(mX);Pko=r(xkt,"DonutSwinModel"),xkt.forEach(t),Bko=r(Aje," (DonutSwin model)"),Aje.forEach(t),Iko=i(x),H_=n(x,"LI",{});var Lje=s(H_);H_e=n(Lje,"STRONG",{});var $kt=s(H_e);Nko=r($kt,"dpr"),$kt.forEach(t),qko=r(Lje," \u2014 "),fX=n(Lje,"A",{href:!0});var kkt=s(fX);jko=r(kkt,"DPRQuestionEncoder"),kkt.forEach(t),Dko=r(Lje," (DPR model)"),Lje.forEach(t),Gko=i(x),J_=n(x,"LI",{});var yje=s(J_);J_e=n(yje,"STRONG",{});var Skt=s(J_e);Oko=r(Skt,"dpt"),Skt.forEach(t),Vko=r(yje," \u2014 "),gX=n(yje,"A",{href:!0});var Rkt=s(gX);Xko=r(Rkt,"DPTModel"),Rkt.forEach(t),zko=r(yje," (DPT model)"),yje.forEach(t),Qko=i(x),Y_=n(x,"LI",{});var xje=s(Y_);Y_e=n(xje,"STRONG",{});var Pkt=s(Y_e);Wko=r(Pkt,"electra"),Pkt.forEach(t),Uko=r(xje," \u2014 "),hX=n(xje,"A",{href:!0});var Bkt=s(hX);Hko=r(Bkt,"ElectraModel"),Bkt.forEach(t),Jko=r(xje," (ELECTRA model)"),xje.forEach(t),Yko=i(x),Z_=n(x,"LI",{});var $je=s(Z_);Z_e=n($je,"STRONG",{});var Ikt=s(Z_e);Zko=r(Ikt,"ernie"),Ikt.forEach(t),Kko=r($je," \u2014 "),uX=n($je,"A",{href:!0});var Nkt=s(uX);eSo=r(Nkt,"ErnieModel"),Nkt.forEach(t),oSo=r($je," (ERNIE model)"),$je.forEach(t),rSo=i(x),K_=n(x,"LI",{});var kje=s(K_);K_e=n(kje,"STRONG",{});var qkt=s(K_e);tSo=r(qkt,"esm"),qkt.forEach(t),aSo=r(kje," \u2014 "),pX=n(kje,"A",{href:!0});var jkt=s(pX);nSo=r(jkt,"EsmModel"),jkt.forEach(t),sSo=r(kje," (ESM model)"),kje.forEach(t),lSo=i(x),e1=n(x,"LI",{});var Sje=s(e1);e1e=n(Sje,"STRONG",{});var Dkt=s(e1e);iSo=r(Dkt,"flaubert"),Dkt.forEach(t),dSo=r(Sje," \u2014 "),_X=n(Sje,"A",{href:!0});var Gkt=s(_X);cSo=r(Gkt,"FlaubertModel"),Gkt.forEach(t),mSo=r(Sje," (FlauBERT model)"),Sje.forEach(t),fSo=i(x),o1=n(x,"LI",{});var Rje=s(o1);o1e=n(Rje,"STRONG",{});var Okt=s(o1e);gSo=r(Okt,"flava"),Okt.forEach(t),hSo=r(Rje," \u2014 "),bX=n(Rje,"A",{href:!0});var Vkt=s(bX);uSo=r(Vkt,"FlavaModel"),Vkt.forEach(t),pSo=r(Rje," (FLAVA model)"),Rje.forEach(t),_So=i(x),r1=n(x,"LI",{});var Pje=s(r1);r1e=n(Pje,"STRONG",{});var Xkt=s(r1e);bSo=r(Xkt,"fnet"),Xkt.forEach(t),vSo=r(Pje," \u2014 "),vX=n(Pje,"A",{href:!0});var zkt=s(vX);FSo=r(zkt,"FNetModel"),zkt.forEach(t),TSo=r(Pje," (FNet model)"),Pje.forEach(t),MSo=i(x),t1=n(x,"LI",{});var Bje=s(t1);t1e=n(Bje,"STRONG",{});var Qkt=s(t1e);ESo=r(Qkt,"fsmt"),Qkt.forEach(t),CSo=r(Bje," \u2014 "),FX=n(Bje,"A",{href:!0});var Wkt=s(FX);wSo=r(Wkt,"FSMTModel"),Wkt.forEach(t),ASo=r(Bje," (FairSeq Machine-Translation model)"),Bje.forEach(t),LSo=i(x),Ml=n(x,"LI",{});var $I=s(Ml);a1e=n($I,"STRONG",{});var Ukt=s(a1e);ySo=r(Ukt,"funnel"),Ukt.forEach(t),xSo=r($I," \u2014 "),TX=n($I,"A",{href:!0});var Hkt=s(TX);$So=r(Hkt,"FunnelModel"),Hkt.forEach(t),kSo=r($I," or "),MX=n($I,"A",{href:!0});var Jkt=s(MX);SSo=r(Jkt,"FunnelBaseModel"),Jkt.forEach(t),RSo=r($I," (Funnel Transformer model)"),$I.forEach(t),PSo=i(x),a1=n(x,"LI",{});var Ije=s(a1);n1e=n(Ije,"STRONG",{});var Ykt=s(n1e);BSo=r(Ykt,"glpn"),Ykt.forEach(t),ISo=r(Ije," \u2014 "),EX=n(Ije,"A",{href:!0});var Zkt=s(EX);NSo=r(Zkt,"GLPNModel"),Zkt.forEach(t),qSo=r(Ije," (GLPN model)"),Ije.forEach(t),jSo=i(x),n1=n(x,"LI",{});var Nje=s(n1);s1e=n(Nje,"STRONG",{});var Kkt=s(s1e);DSo=r(Kkt,"gpt2"),Kkt.forEach(t),GSo=r(Nje," \u2014 "),CX=n(Nje,"A",{href:!0});var eSt=s(CX);OSo=r(eSt,"GPT2Model"),eSt.forEach(t),VSo=r(Nje," (OpenAI GPT-2 model)"),Nje.forEach(t),XSo=i(x),s1=n(x,"LI",{});var qje=s(s1);l1e=n(qje,"STRONG",{});var oSt=s(l1e);zSo=r(oSt,"gpt_neo"),oSt.forEach(t),QSo=r(qje," \u2014 "),wX=n(qje,"A",{href:!0});var rSt=s(wX);WSo=r(rSt,"GPTNeoModel"),rSt.forEach(t),USo=r(qje," (GPT Neo model)"),qje.forEach(t),HSo=i(x),l1=n(x,"LI",{});var jje=s(l1);i1e=n(jje,"STRONG",{});var tSt=s(i1e);JSo=r(tSt,"gpt_neox"),tSt.forEach(t),YSo=r(jje," \u2014 "),AX=n(jje,"A",{href:!0});var aSt=s(AX);ZSo=r(aSt,"GPTNeoXModel"),aSt.forEach(t),KSo=r(jje," (GPT NeoX model)"),jje.forEach(t),eRo=i(x),i1=n(x,"LI",{});var Dje=s(i1);d1e=n(Dje,"STRONG",{});var nSt=s(d1e);oRo=r(nSt,"gpt_neox_japanese"),nSt.forEach(t),rRo=r(Dje," \u2014 "),LX=n(Dje,"A",{href:!0});var sSt=s(LX);tRo=r(sSt,"GPTNeoXJapaneseModel"),sSt.forEach(t),aRo=r(Dje," (GPT NeoX Japanese model)"),Dje.forEach(t),nRo=i(x),d1=n(x,"LI",{});var Gje=s(d1);c1e=n(Gje,"STRONG",{});var lSt=s(c1e);sRo=r(lSt,"gptj"),lSt.forEach(t),lRo=r(Gje," \u2014 "),yX=n(Gje,"A",{href:!0});var iSt=s(yX);iRo=r(iSt,"GPTJModel"),iSt.forEach(t),dRo=r(Gje," (GPT-J model)"),Gje.forEach(t),cRo=i(x),c1=n(x,"LI",{});var Oje=s(c1);m1e=n(Oje,"STRONG",{});var dSt=s(m1e);mRo=r(dSt,"groupvit"),dSt.forEach(t),fRo=r(Oje," \u2014 "),xX=n(Oje,"A",{href:!0});var cSt=s(xX);gRo=r(cSt,"GroupViTModel"),cSt.forEach(t),hRo=r(Oje," (GroupViT model)"),Oje.forEach(t),uRo=i(x),m1=n(x,"LI",{});var Vje=s(m1);f1e=n(Vje,"STRONG",{});var mSt=s(f1e);pRo=r(mSt,"hubert"),mSt.forEach(t),_Ro=r(Vje," \u2014 "),$X=n(Vje,"A",{href:!0});var fSt=s($X);bRo=r(fSt,"HubertModel"),fSt.forEach(t),vRo=r(Vje," (Hubert model)"),Vje.forEach(t),FRo=i(x),f1=n(x,"LI",{});var Xje=s(f1);g1e=n(Xje,"STRONG",{});var gSt=s(g1e);TRo=r(gSt,"ibert"),gSt.forEach(t),MRo=r(Xje," \u2014 "),kX=n(Xje,"A",{href:!0});var hSt=s(kX);ERo=r(hSt,"IBertModel"),hSt.forEach(t),CRo=r(Xje," (I-BERT model)"),Xje.forEach(t),wRo=i(x),g1=n(x,"LI",{});var zje=s(g1);h1e=n(zje,"STRONG",{});var uSt=s(h1e);ARo=r(uSt,"imagegpt"),uSt.forEach(t),LRo=r(zje," \u2014 "),SX=n(zje,"A",{href:!0});var pSt=s(SX);yRo=r(pSt,"ImageGPTModel"),pSt.forEach(t),xRo=r(zje," (ImageGPT model)"),zje.forEach(t),$Ro=i(x),h1=n(x,"LI",{});var Qje=s(h1);u1e=n(Qje,"STRONG",{});var _St=s(u1e);kRo=r(_St,"layoutlm"),_St.forEach(t),SRo=r(Qje," \u2014 "),RX=n(Qje,"A",{href:!0});var bSt=s(RX);RRo=r(bSt,"LayoutLMModel"),bSt.forEach(t),PRo=r(Qje," (LayoutLM model)"),Qje.forEach(t),BRo=i(x),u1=n(x,"LI",{});var Wje=s(u1);p1e=n(Wje,"STRONG",{});var vSt=s(p1e);IRo=r(vSt,"layoutlmv2"),vSt.forEach(t),NRo=r(Wje," \u2014 "),PX=n(Wje,"A",{href:!0});var FSt=s(PX);qRo=r(FSt,"LayoutLMv2Model"),FSt.forEach(t),jRo=r(Wje," (LayoutLMv2 model)"),Wje.forEach(t),DRo=i(x),p1=n(x,"LI",{});var Uje=s(p1);_1e=n(Uje,"STRONG",{});var TSt=s(_1e);GRo=r(TSt,"layoutlmv3"),TSt.forEach(t),ORo=r(Uje," \u2014 "),BX=n(Uje,"A",{href:!0});var MSt=s(BX);VRo=r(MSt,"LayoutLMv3Model"),MSt.forEach(t),XRo=r(Uje," (LayoutLMv3 model)"),Uje.forEach(t),zRo=i(x),_1=n(x,"LI",{});var Hje=s(_1);b1e=n(Hje,"STRONG",{});var ESt=s(b1e);QRo=r(ESt,"led"),ESt.forEach(t),WRo=r(Hje," \u2014 "),IX=n(Hje,"A",{href:!0});var CSt=s(IX);URo=r(CSt,"LEDModel"),CSt.forEach(t),HRo=r(Hje," (LED model)"),Hje.forEach(t),JRo=i(x),b1=n(x,"LI",{});var Jje=s(b1);v1e=n(Jje,"STRONG",{});var wSt=s(v1e);YRo=r(wSt,"levit"),wSt.forEach(t),ZRo=r(Jje," \u2014 "),NX=n(Jje,"A",{href:!0});var ASt=s(NX);KRo=r(ASt,"LevitModel"),ASt.forEach(t),ePo=r(Jje," (LeViT model)"),Jje.forEach(t),oPo=i(x),v1=n(x,"LI",{});var Yje=s(v1);F1e=n(Yje,"STRONG",{});var LSt=s(F1e);rPo=r(LSt,"longformer"),LSt.forEach(t),tPo=r(Yje," \u2014 "),qX=n(Yje,"A",{href:!0});var ySt=s(qX);aPo=r(ySt,"LongformerModel"),ySt.forEach(t),nPo=r(Yje," (Longformer model)"),Yje.forEach(t),sPo=i(x),F1=n(x,"LI",{});var Zje=s(F1);T1e=n(Zje,"STRONG",{});var xSt=s(T1e);lPo=r(xSt,"longt5"),xSt.forEach(t),iPo=r(Zje," \u2014 "),jX=n(Zje,"A",{href:!0});var $St=s(jX);dPo=r($St,"LongT5Model"),$St.forEach(t),cPo=r(Zje," (LongT5 model)"),Zje.forEach(t),mPo=i(x),T1=n(x,"LI",{});var Kje=s(T1);M1e=n(Kje,"STRONG",{});var kSt=s(M1e);fPo=r(kSt,"luke"),kSt.forEach(t),gPo=r(Kje," \u2014 "),DX=n(Kje,"A",{href:!0});var SSt=s(DX);hPo=r(SSt,"LukeModel"),SSt.forEach(t),uPo=r(Kje," (LUKE model)"),Kje.forEach(t),pPo=i(x),M1=n(x,"LI",{});var eDe=s(M1);E1e=n(eDe,"STRONG",{});var RSt=s(E1e);_Po=r(RSt,"lxmert"),RSt.forEach(t),bPo=r(eDe," \u2014 "),GX=n(eDe,"A",{href:!0});var PSt=s(GX);vPo=r(PSt,"LxmertModel"),PSt.forEach(t),FPo=r(eDe," (LXMERT model)"),eDe.forEach(t),TPo=i(x),E1=n(x,"LI",{});var oDe=s(E1);C1e=n(oDe,"STRONG",{});var BSt=s(C1e);MPo=r(BSt,"m2m_100"),BSt.forEach(t),EPo=r(oDe," \u2014 "),OX=n(oDe,"A",{href:!0});var ISt=s(OX);CPo=r(ISt,"M2M100Model"),ISt.forEach(t),wPo=r(oDe," (M2M100 model)"),oDe.forEach(t),APo=i(x),C1=n(x,"LI",{});var rDe=s(C1);w1e=n(rDe,"STRONG",{});var NSt=s(w1e);LPo=r(NSt,"marian"),NSt.forEach(t),yPo=r(rDe," \u2014 "),VX=n(rDe,"A",{href:!0});var qSt=s(VX);xPo=r(qSt,"MarianModel"),qSt.forEach(t),$Po=r(rDe," (Marian model)"),rDe.forEach(t),kPo=i(x),w1=n(x,"LI",{});var tDe=s(w1);A1e=n(tDe,"STRONG",{});var jSt=s(A1e);SPo=r(jSt,"markuplm"),jSt.forEach(t),RPo=r(tDe," \u2014 "),XX=n(tDe,"A",{href:!0});var DSt=s(XX);PPo=r(DSt,"MarkupLMModel"),DSt.forEach(t),BPo=r(tDe," (MarkupLM model)"),tDe.forEach(t),IPo=i(x),A1=n(x,"LI",{});var aDe=s(A1);L1e=n(aDe,"STRONG",{});var GSt=s(L1e);NPo=r(GSt,"maskformer"),GSt.forEach(t),qPo=r(aDe," \u2014 "),zX=n(aDe,"A",{href:!0});var OSt=s(zX);jPo=r(OSt,"MaskFormerModel"),OSt.forEach(t),DPo=r(aDe," (MaskFormer model)"),aDe.forEach(t),GPo=i(x),L1=n(x,"LI",{});var nDe=s(L1);y1e=n(nDe,"STRONG",{});var VSt=s(y1e);OPo=r(VSt,"mbart"),VSt.forEach(t),VPo=r(nDe," \u2014 "),QX=n(nDe,"A",{href:!0});var XSt=s(QX);XPo=r(XSt,"MBartModel"),XSt.forEach(t),zPo=r(nDe," (mBART model)"),nDe.forEach(t),QPo=i(x),y1=n(x,"LI",{});var sDe=s(y1);x1e=n(sDe,"STRONG",{});var zSt=s(x1e);WPo=r(zSt,"mctct"),zSt.forEach(t),UPo=r(sDe," \u2014 "),WX=n(sDe,"A",{href:!0});var QSt=s(WX);HPo=r(QSt,"MCTCTModel"),QSt.forEach(t),JPo=r(sDe," (M-CTC-T model)"),sDe.forEach(t),YPo=i(x),x1=n(x,"LI",{});var lDe=s(x1);$1e=n(lDe,"STRONG",{});var WSt=s($1e);ZPo=r(WSt,"megatron-bert"),WSt.forEach(t),KPo=r(lDe," \u2014 "),UX=n(lDe,"A",{href:!0});var USt=s(UX);eBo=r(USt,"MegatronBertModel"),USt.forEach(t),oBo=r(lDe," (Megatron-BERT model)"),lDe.forEach(t),rBo=i(x),$1=n(x,"LI",{});var iDe=s($1);k1e=n(iDe,"STRONG",{});var HSt=s(k1e);tBo=r(HSt,"mobilebert"),HSt.forEach(t),aBo=r(iDe," \u2014 "),HX=n(iDe,"A",{href:!0});var JSt=s(HX);nBo=r(JSt,"MobileBertModel"),JSt.forEach(t),sBo=r(iDe," (MobileBERT model)"),iDe.forEach(t),lBo=i(x),k1=n(x,"LI",{});var dDe=s(k1);S1e=n(dDe,"STRONG",{});var YSt=s(S1e);iBo=r(YSt,"mobilevit"),YSt.forEach(t),dBo=r(dDe," \u2014 "),JX=n(dDe,"A",{href:!0});var ZSt=s(JX);cBo=r(ZSt,"MobileViTModel"),ZSt.forEach(t),mBo=r(dDe," (MobileViT model)"),dDe.forEach(t),fBo=i(x),S1=n(x,"LI",{});var cDe=s(S1);R1e=n(cDe,"STRONG",{});var KSt=s(R1e);gBo=r(KSt,"mpnet"),KSt.forEach(t),hBo=r(cDe," \u2014 "),YX=n(cDe,"A",{href:!0});var eRt=s(YX);uBo=r(eRt,"MPNetModel"),eRt.forEach(t),pBo=r(cDe," (MPNet model)"),cDe.forEach(t),_Bo=i(x),R1=n(x,"LI",{});var mDe=s(R1);P1e=n(mDe,"STRONG",{});var oRt=s(P1e);bBo=r(oRt,"mt5"),oRt.forEach(t),vBo=r(mDe," \u2014 "),ZX=n(mDe,"A",{href:!0});var rRt=s(ZX);FBo=r(rRt,"MT5Model"),rRt.forEach(t),TBo=r(mDe," (MT5 model)"),mDe.forEach(t),MBo=i(x),P1=n(x,"LI",{});var fDe=s(P1);B1e=n(fDe,"STRONG",{});var tRt=s(B1e);EBo=r(tRt,"mvp"),tRt.forEach(t),CBo=r(fDe," \u2014 "),KX=n(fDe,"A",{href:!0});var aRt=s(KX);wBo=r(aRt,"MvpModel"),aRt.forEach(t),ABo=r(fDe," (MVP model)"),fDe.forEach(t),LBo=i(x),B1=n(x,"LI",{});var gDe=s(B1);I1e=n(gDe,"STRONG",{});var nRt=s(I1e);yBo=r(nRt,"nezha"),nRt.forEach(t),xBo=r(gDe," \u2014 "),ez=n(gDe,"A",{href:!0});var sRt=s(ez);$Bo=r(sRt,"NezhaModel"),sRt.forEach(t),kBo=r(gDe," (Nezha model)"),gDe.forEach(t),SBo=i(x),I1=n(x,"LI",{});var hDe=s(I1);N1e=n(hDe,"STRONG",{});var lRt=s(N1e);RBo=r(lRt,"nllb"),lRt.forEach(t),PBo=r(hDe," \u2014 "),oz=n(hDe,"A",{href:!0});var iRt=s(oz);BBo=r(iRt,"M2M100Model"),iRt.forEach(t),IBo=r(hDe," (NLLB model)"),hDe.forEach(t),NBo=i(x),N1=n(x,"LI",{});var uDe=s(N1);q1e=n(uDe,"STRONG",{});var dRt=s(q1e);qBo=r(dRt,"nystromformer"),dRt.forEach(t),jBo=r(uDe," \u2014 "),rz=n(uDe,"A",{href:!0});var cRt=s(rz);DBo=r(cRt,"NystromformerModel"),cRt.forEach(t),GBo=r(uDe," (Nystr\xF6mformer model)"),uDe.forEach(t),OBo=i(x),q1=n(x,"LI",{});var pDe=s(q1);j1e=n(pDe,"STRONG",{});var mRt=s(j1e);VBo=r(mRt,"openai-gpt"),mRt.forEach(t),XBo=r(pDe," \u2014 "),tz=n(pDe,"A",{href:!0});var fRt=s(tz);zBo=r(fRt,"OpenAIGPTModel"),fRt.forEach(t),QBo=r(pDe," (OpenAI GPT model)"),pDe.forEach(t),WBo=i(x),j1=n(x,"LI",{});var _De=s(j1);D1e=n(_De,"STRONG",{});var gRt=s(D1e);UBo=r(gRt,"opt"),gRt.forEach(t),HBo=r(_De," \u2014 "),az=n(_De,"A",{href:!0});var hRt=s(az);JBo=r(hRt,"OPTModel"),hRt.forEach(t),YBo=r(_De," (OPT model)"),_De.forEach(t),ZBo=i(x),D1=n(x,"LI",{});var bDe=s(D1);G1e=n(bDe,"STRONG",{});var uRt=s(G1e);KBo=r(uRt,"owlvit"),uRt.forEach(t),eIo=r(bDe," \u2014 "),nz=n(bDe,"A",{href:!0});var pRt=s(nz);oIo=r(pRt,"OwlViTModel"),pRt.forEach(t),rIo=r(bDe," (OWL-ViT model)"),bDe.forEach(t),tIo=i(x),G1=n(x,"LI",{});var vDe=s(G1);O1e=n(vDe,"STRONG",{});var _Rt=s(O1e);aIo=r(_Rt,"pegasus"),_Rt.forEach(t),nIo=r(vDe," \u2014 "),sz=n(vDe,"A",{href:!0});var bRt=s(sz);sIo=r(bRt,"PegasusModel"),bRt.forEach(t),lIo=r(vDe," (Pegasus model)"),vDe.forEach(t),iIo=i(x),O1=n(x,"LI",{});var FDe=s(O1);V1e=n(FDe,"STRONG",{});var vRt=s(V1e);dIo=r(vRt,"pegasus_x"),vRt.forEach(t),cIo=r(FDe," \u2014 "),lz=n(FDe,"A",{href:!0});var FRt=s(lz);mIo=r(FRt,"PegasusXModel"),FRt.forEach(t),fIo=r(FDe," (PEGASUS-X model)"),FDe.forEach(t),gIo=i(x),V1=n(x,"LI",{});var TDe=s(V1);X1e=n(TDe,"STRONG",{});var TRt=s(X1e);hIo=r(TRt,"perceiver"),TRt.forEach(t),uIo=r(TDe," \u2014 "),iz=n(TDe,"A",{href:!0});var MRt=s(iz);pIo=r(MRt,"PerceiverModel"),MRt.forEach(t),_Io=r(TDe," (Perceiver model)"),TDe.forEach(t),bIo=i(x),X1=n(x,"LI",{});var MDe=s(X1);z1e=n(MDe,"STRONG",{});var ERt=s(z1e);vIo=r(ERt,"plbart"),ERt.forEach(t),FIo=r(MDe," \u2014 "),dz=n(MDe,"A",{href:!0});var CRt=s(dz);TIo=r(CRt,"PLBartModel"),CRt.forEach(t),MIo=r(MDe," (PLBart model)"),MDe.forEach(t),EIo=i(x),z1=n(x,"LI",{});var EDe=s(z1);Q1e=n(EDe,"STRONG",{});var wRt=s(Q1e);CIo=r(wRt,"poolformer"),wRt.forEach(t),wIo=r(EDe," \u2014 "),cz=n(EDe,"A",{href:!0});var ARt=s(cz);AIo=r(ARt,"PoolFormerModel"),ARt.forEach(t),LIo=r(EDe," (PoolFormer model)"),EDe.forEach(t),yIo=i(x),Q1=n(x,"LI",{});var CDe=s(Q1);W1e=n(CDe,"STRONG",{});var LRt=s(W1e);xIo=r(LRt,"prophetnet"),LRt.forEach(t),$Io=r(CDe," \u2014 "),mz=n(CDe,"A",{href:!0});var yRt=s(mz);kIo=r(yRt,"ProphetNetModel"),yRt.forEach(t),SIo=r(CDe," (ProphetNet model)"),CDe.forEach(t),RIo=i(x),W1=n(x,"LI",{});var wDe=s(W1);U1e=n(wDe,"STRONG",{});var xRt=s(U1e);PIo=r(xRt,"qdqbert"),xRt.forEach(t),BIo=r(wDe," \u2014 "),fz=n(wDe,"A",{href:!0});var $Rt=s(fz);IIo=r($Rt,"QDQBertModel"),$Rt.forEach(t),NIo=r(wDe," (QDQBert model)"),wDe.forEach(t),qIo=i(x),U1=n(x,"LI",{});var ADe=s(U1);H1e=n(ADe,"STRONG",{});var kRt=s(H1e);jIo=r(kRt,"reformer"),kRt.forEach(t),DIo=r(ADe," \u2014 "),gz=n(ADe,"A",{href:!0});var SRt=s(gz);GIo=r(SRt,"ReformerModel"),SRt.forEach(t),OIo=r(ADe," (Reformer model)"),ADe.forEach(t),VIo=i(x),H1=n(x,"LI",{});var LDe=s(H1);J1e=n(LDe,"STRONG",{});var RRt=s(J1e);XIo=r(RRt,"regnet"),RRt.forEach(t),zIo=r(LDe," \u2014 "),hz=n(LDe,"A",{href:!0});var PRt=s(hz);QIo=r(PRt,"RegNetModel"),PRt.forEach(t),WIo=r(LDe," (RegNet model)"),LDe.forEach(t),UIo=i(x),J1=n(x,"LI",{});var yDe=s(J1);Y1e=n(yDe,"STRONG",{});var BRt=s(Y1e);HIo=r(BRt,"rembert"),BRt.forEach(t),JIo=r(yDe," \u2014 "),uz=n(yDe,"A",{href:!0});var IRt=s(uz);YIo=r(IRt,"RemBertModel"),IRt.forEach(t),ZIo=r(yDe," (RemBERT model)"),yDe.forEach(t),KIo=i(x),Y1=n(x,"LI",{});var xDe=s(Y1);Z1e=n(xDe,"STRONG",{});var NRt=s(Z1e);eNo=r(NRt,"resnet"),NRt.forEach(t),oNo=r(xDe," \u2014 "),pz=n(xDe,"A",{href:!0});var qRt=s(pz);rNo=r(qRt,"ResNetModel"),qRt.forEach(t),tNo=r(xDe," (ResNet model)"),xDe.forEach(t),aNo=i(x),Z1=n(x,"LI",{});var $De=s(Z1);K1e=n($De,"STRONG",{});var jRt=s(K1e);nNo=r(jRt,"retribert"),jRt.forEach(t),sNo=r($De," \u2014 "),_z=n($De,"A",{href:!0});var DRt=s(_z);lNo=r(DRt,"RetriBertModel"),DRt.forEach(t),iNo=r($De," (RetriBERT model)"),$De.forEach(t),dNo=i(x),K1=n(x,"LI",{});var kDe=s(K1);e2e=n(kDe,"STRONG",{});var GRt=s(e2e);cNo=r(GRt,"roberta"),GRt.forEach(t),mNo=r(kDe," \u2014 "),bz=n(kDe,"A",{href:!0});var ORt=s(bz);fNo=r(ORt,"RobertaModel"),ORt.forEach(t),gNo=r(kDe," (RoBERTa model)"),kDe.forEach(t),hNo=i(x),e2=n(x,"LI",{});var SDe=s(e2);o2e=n(SDe,"STRONG",{});var VRt=s(o2e);uNo=r(VRt,"roformer"),VRt.forEach(t),pNo=r(SDe," \u2014 "),vz=n(SDe,"A",{href:!0});var XRt=s(vz);_No=r(XRt,"RoFormerModel"),XRt.forEach(t),bNo=r(SDe," (RoFormer model)"),SDe.forEach(t),vNo=i(x),o2=n(x,"LI",{});var RDe=s(o2);r2e=n(RDe,"STRONG",{});var zRt=s(r2e);FNo=r(zRt,"segformer"),zRt.forEach(t),TNo=r(RDe," \u2014 "),Fz=n(RDe,"A",{href:!0});var QRt=s(Fz);MNo=r(QRt,"SegformerModel"),QRt.forEach(t),ENo=r(RDe," (SegFormer model)"),RDe.forEach(t),CNo=i(x),r2=n(x,"LI",{});var PDe=s(r2);t2e=n(PDe,"STRONG",{});var WRt=s(t2e);wNo=r(WRt,"sew"),WRt.forEach(t),ANo=r(PDe," \u2014 "),Tz=n(PDe,"A",{href:!0});var URt=s(Tz);LNo=r(URt,"SEWModel"),URt.forEach(t),yNo=r(PDe," (SEW model)"),PDe.forEach(t),xNo=i(x),t2=n(x,"LI",{});var BDe=s(t2);a2e=n(BDe,"STRONG",{});var HRt=s(a2e);$No=r(HRt,"sew-d"),HRt.forEach(t),kNo=r(BDe," \u2014 "),Mz=n(BDe,"A",{href:!0});var JRt=s(Mz);SNo=r(JRt,"SEWDModel"),JRt.forEach(t),RNo=r(BDe," (SEW-D model)"),BDe.forEach(t),PNo=i(x),a2=n(x,"LI",{});var IDe=s(a2);n2e=n(IDe,"STRONG",{});var YRt=s(n2e);BNo=r(YRt,"speech_to_text"),YRt.forEach(t),INo=r(IDe," \u2014 "),Ez=n(IDe,"A",{href:!0});var ZRt=s(Ez);NNo=r(ZRt,"Speech2TextModel"),ZRt.forEach(t),qNo=r(IDe," (Speech2Text model)"),IDe.forEach(t),jNo=i(x),n2=n(x,"LI",{});var NDe=s(n2);s2e=n(NDe,"STRONG",{});var KRt=s(s2e);DNo=r(KRt,"splinter"),KRt.forEach(t),GNo=r(NDe," \u2014 "),Cz=n(NDe,"A",{href:!0});var ePt=s(Cz);ONo=r(ePt,"SplinterModel"),ePt.forEach(t),VNo=r(NDe," (Splinter model)"),NDe.forEach(t),XNo=i(x),s2=n(x,"LI",{});var qDe=s(s2);l2e=n(qDe,"STRONG",{});var oPt=s(l2e);zNo=r(oPt,"squeezebert"),oPt.forEach(t),QNo=r(qDe," \u2014 "),wz=n(qDe,"A",{href:!0});var rPt=s(wz);WNo=r(rPt,"SqueezeBertModel"),rPt.forEach(t),UNo=r(qDe," (SqueezeBERT model)"),qDe.forEach(t),HNo=i(x),l2=n(x,"LI",{});var jDe=s(l2);i2e=n(jDe,"STRONG",{});var tPt=s(i2e);JNo=r(tPt,"swin"),tPt.forEach(t),YNo=r(jDe," \u2014 "),Az=n(jDe,"A",{href:!0});var aPt=s(Az);ZNo=r(aPt,"SwinModel"),aPt.forEach(t),KNo=r(jDe," (Swin Transformer model)"),jDe.forEach(t),eqo=i(x),i2=n(x,"LI",{});var DDe=s(i2);d2e=n(DDe,"STRONG",{});var nPt=s(d2e);oqo=r(nPt,"swinv2"),nPt.forEach(t),rqo=r(DDe," \u2014 "),Lz=n(DDe,"A",{href:!0});var sPt=s(Lz);tqo=r(sPt,"Swinv2Model"),sPt.forEach(t),aqo=r(DDe," (Swin Transformer V2 model)"),DDe.forEach(t),nqo=i(x),d2=n(x,"LI",{});var GDe=s(d2);c2e=n(GDe,"STRONG",{});var lPt=s(c2e);sqo=r(lPt,"t5"),lPt.forEach(t),lqo=r(GDe," \u2014 "),yz=n(GDe,"A",{href:!0});var iPt=s(yz);iqo=r(iPt,"T5Model"),iPt.forEach(t),dqo=r(GDe," (T5 model)"),GDe.forEach(t),cqo=i(x),c2=n(x,"LI",{});var ODe=s(c2);m2e=n(ODe,"STRONG",{});var dPt=s(m2e);mqo=r(dPt,"tapas"),dPt.forEach(t),fqo=r(ODe," \u2014 "),xz=n(ODe,"A",{href:!0});var cPt=s(xz);gqo=r(cPt,"TapasModel"),cPt.forEach(t),hqo=r(ODe," (TAPAS model)"),ODe.forEach(t),uqo=i(x),m2=n(x,"LI",{});var VDe=s(m2);f2e=n(VDe,"STRONG",{});var mPt=s(f2e);pqo=r(mPt,"time_series_transformer"),mPt.forEach(t),_qo=r(VDe," \u2014 "),$z=n(VDe,"A",{href:!0});var fPt=s($z);bqo=r(fPt,"TimeSeriesTransformerModel"),fPt.forEach(t),vqo=r(VDe," (Time Series Transformer model)"),VDe.forEach(t),Fqo=i(x),f2=n(x,"LI",{});var XDe=s(f2);g2e=n(XDe,"STRONG",{});var gPt=s(g2e);Tqo=r(gPt,"trajectory_transformer"),gPt.forEach(t),Mqo=r(XDe," \u2014 "),kz=n(XDe,"A",{href:!0});var hPt=s(kz);Eqo=r(hPt,"TrajectoryTransformerModel"),hPt.forEach(t),Cqo=r(XDe," (Trajectory Transformer model)"),XDe.forEach(t),wqo=i(x),g2=n(x,"LI",{});var zDe=s(g2);h2e=n(zDe,"STRONG",{});var uPt=s(h2e);Aqo=r(uPt,"transfo-xl"),uPt.forEach(t),Lqo=r(zDe," \u2014 "),Sz=n(zDe,"A",{href:!0});var pPt=s(Sz);yqo=r(pPt,"TransfoXLModel"),pPt.forEach(t),xqo=r(zDe," (Transformer-XL model)"),zDe.forEach(t),$qo=i(x),h2=n(x,"LI",{});var QDe=s(h2);u2e=n(QDe,"STRONG",{});var _Pt=s(u2e);kqo=r(_Pt,"unispeech"),_Pt.forEach(t),Sqo=r(QDe," \u2014 "),Rz=n(QDe,"A",{href:!0});var bPt=s(Rz);Rqo=r(bPt,"UniSpeechModel"),bPt.forEach(t),Pqo=r(QDe," (UniSpeech model)"),QDe.forEach(t),Bqo=i(x),u2=n(x,"LI",{});var WDe=s(u2);p2e=n(WDe,"STRONG",{});var vPt=s(p2e);Iqo=r(vPt,"unispeech-sat"),vPt.forEach(t),Nqo=r(WDe," \u2014 "),Pz=n(WDe,"A",{href:!0});var FPt=s(Pz);qqo=r(FPt,"UniSpeechSatModel"),FPt.forEach(t),jqo=r(WDe," (UniSpeechSat model)"),WDe.forEach(t),Dqo=i(x),p2=n(x,"LI",{});var UDe=s(p2);_2e=n(UDe,"STRONG",{});var TPt=s(_2e);Gqo=r(TPt,"van"),TPt.forEach(t),Oqo=r(UDe," \u2014 "),Bz=n(UDe,"A",{href:!0});var MPt=s(Bz);Vqo=r(MPt,"VanModel"),MPt.forEach(t),Xqo=r(UDe," (VAN model)"),UDe.forEach(t),zqo=i(x),_2=n(x,"LI",{});var HDe=s(_2);b2e=n(HDe,"STRONG",{});var EPt=s(b2e);Qqo=r(EPt,"videomae"),EPt.forEach(t),Wqo=r(HDe," \u2014 "),Iz=n(HDe,"A",{href:!0});var CPt=s(Iz);Uqo=r(CPt,"VideoMAEModel"),CPt.forEach(t),Hqo=r(HDe," (VideoMAE model)"),HDe.forEach(t),Jqo=i(x),b2=n(x,"LI",{});var JDe=s(b2);v2e=n(JDe,"STRONG",{});var wPt=s(v2e);Yqo=r(wPt,"vilt"),wPt.forEach(t),Zqo=r(JDe," \u2014 "),Nz=n(JDe,"A",{href:!0});var APt=s(Nz);Kqo=r(APt,"ViltModel"),APt.forEach(t),ejo=r(JDe," (ViLT model)"),JDe.forEach(t),ojo=i(x),v2=n(x,"LI",{});var YDe=s(v2);F2e=n(YDe,"STRONG",{});var LPt=s(F2e);rjo=r(LPt,"vision-text-dual-encoder"),LPt.forEach(t),tjo=r(YDe," \u2014 "),qz=n(YDe,"A",{href:!0});var yPt=s(qz);ajo=r(yPt,"VisionTextDualEncoderModel"),yPt.forEach(t),njo=r(YDe," (VisionTextDualEncoder model)"),YDe.forEach(t),sjo=i(x),F2=n(x,"LI",{});var ZDe=s(F2);T2e=n(ZDe,"STRONG",{});var xPt=s(T2e);ljo=r(xPt,"visual_bert"),xPt.forEach(t),ijo=r(ZDe," \u2014 "),jz=n(ZDe,"A",{href:!0});var $Pt=s(jz);djo=r($Pt,"VisualBertModel"),$Pt.forEach(t),cjo=r(ZDe," (VisualBERT model)"),ZDe.forEach(t),mjo=i(x),T2=n(x,"LI",{});var KDe=s(T2);M2e=n(KDe,"STRONG",{});var kPt=s(M2e);fjo=r(kPt,"vit"),kPt.forEach(t),gjo=r(KDe," \u2014 "),Dz=n(KDe,"A",{href:!0});var SPt=s(Dz);hjo=r(SPt,"ViTModel"),SPt.forEach(t),ujo=r(KDe," (ViT model)"),KDe.forEach(t),pjo=i(x),M2=n(x,"LI",{});var eGe=s(M2);E2e=n(eGe,"STRONG",{});var RPt=s(E2e);_jo=r(RPt,"vit_mae"),RPt.forEach(t),bjo=r(eGe," \u2014 "),Gz=n(eGe,"A",{href:!0});var PPt=s(Gz);vjo=r(PPt,"ViTMAEModel"),PPt.forEach(t),Fjo=r(eGe," (ViTMAE model)"),eGe.forEach(t),Tjo=i(x),E2=n(x,"LI",{});var oGe=s(E2);C2e=n(oGe,"STRONG",{});var BPt=s(C2e);Mjo=r(BPt,"vit_msn"),BPt.forEach(t),Ejo=r(oGe," \u2014 "),Oz=n(oGe,"A",{href:!0});var IPt=s(Oz);Cjo=r(IPt,"ViTMSNModel"),IPt.forEach(t),wjo=r(oGe," (ViTMSN model)"),oGe.forEach(t),Ajo=i(x),C2=n(x,"LI",{});var rGe=s(C2);w2e=n(rGe,"STRONG",{});var NPt=s(w2e);Ljo=r(NPt,"wav2vec2"),NPt.forEach(t),yjo=r(rGe," \u2014 "),Vz=n(rGe,"A",{href:!0});var qPt=s(Vz);xjo=r(qPt,"Wav2Vec2Model"),qPt.forEach(t),$jo=r(rGe," (Wav2Vec2 model)"),rGe.forEach(t),kjo=i(x),w2=n(x,"LI",{});var tGe=s(w2);A2e=n(tGe,"STRONG",{});var jPt=s(A2e);Sjo=r(jPt,"wav2vec2-conformer"),jPt.forEach(t),Rjo=r(tGe," \u2014 "),Xz=n(tGe,"A",{href:!0});var DPt=s(Xz);Pjo=r(DPt,"Wav2Vec2ConformerModel"),DPt.forEach(t),Bjo=r(tGe," (Wav2Vec2-Conformer model)"),tGe.forEach(t),Ijo=i(x),A2=n(x,"LI",{});var aGe=s(A2);L2e=n(aGe,"STRONG",{});var GPt=s(L2e);Njo=r(GPt,"wavlm"),GPt.forEach(t),qjo=r(aGe," \u2014 "),zz=n(aGe,"A",{href:!0});var OPt=s(zz);jjo=r(OPt,"WavLMModel"),OPt.forEach(t),Djo=r(aGe," (WavLM model)"),aGe.forEach(t),Gjo=i(x),L2=n(x,"LI",{});var nGe=s(L2);y2e=n(nGe,"STRONG",{});var VPt=s(y2e);Ojo=r(VPt,"whisper"),VPt.forEach(t),Vjo=r(nGe," \u2014 "),Qz=n(nGe,"A",{href:!0});var XPt=s(Qz);Xjo=r(XPt,"WhisperModel"),XPt.forEach(t),zjo=r(nGe," (Whisper model)"),nGe.forEach(t),Qjo=i(x),y2=n(x,"LI",{});var sGe=s(y2);x2e=n(sGe,"STRONG",{});var zPt=s(x2e);Wjo=r(zPt,"xclip"),zPt.forEach(t),Ujo=r(sGe," \u2014 "),Wz=n(sGe,"A",{href:!0});var QPt=s(Wz);Hjo=r(QPt,"XCLIPModel"),QPt.forEach(t),Jjo=r(sGe," (X-CLIP model)"),sGe.forEach(t),Yjo=i(x),x2=n(x,"LI",{});var lGe=s(x2);$2e=n(lGe,"STRONG",{});var WPt=s($2e);Zjo=r(WPt,"xglm"),WPt.forEach(t),Kjo=r(lGe," \u2014 "),Uz=n(lGe,"A",{href:!0});var UPt=s(Uz);eDo=r(UPt,"XGLMModel"),UPt.forEach(t),oDo=r(lGe," (XGLM model)"),lGe.forEach(t),rDo=i(x),$2=n(x,"LI",{});var iGe=s($2);k2e=n(iGe,"STRONG",{});var HPt=s(k2e);tDo=r(HPt,"xlm"),HPt.forEach(t),aDo=r(iGe," \u2014 "),Hz=n(iGe,"A",{href:!0});var JPt=s(Hz);nDo=r(JPt,"XLMModel"),JPt.forEach(t),sDo=r(iGe," (XLM model)"),iGe.forEach(t),lDo=i(x),k2=n(x,"LI",{});var dGe=s(k2);S2e=n(dGe,"STRONG",{});var YPt=s(S2e);iDo=r(YPt,"xlm-prophetnet"),YPt.forEach(t),dDo=r(dGe," \u2014 "),Jz=n(dGe,"A",{href:!0});var ZPt=s(Jz);cDo=r(ZPt,"XLMProphetNetModel"),ZPt.forEach(t),mDo=r(dGe," (XLM-ProphetNet model)"),dGe.forEach(t),fDo=i(x),S2=n(x,"LI",{});var cGe=s(S2);R2e=n(cGe,"STRONG",{});var KPt=s(R2e);gDo=r(KPt,"xlm-roberta"),KPt.forEach(t),hDo=r(cGe," \u2014 "),Yz=n(cGe,"A",{href:!0});var eBt=s(Yz);uDo=r(eBt,"XLMRobertaModel"),eBt.forEach(t),pDo=r(cGe," (XLM-RoBERTa model)"),cGe.forEach(t),_Do=i(x),R2=n(x,"LI",{});var mGe=s(R2);P2e=n(mGe,"STRONG",{});var oBt=s(P2e);bDo=r(oBt,"xlm-roberta-xl"),oBt.forEach(t),vDo=r(mGe," \u2014 "),Zz=n(mGe,"A",{href:!0});var rBt=s(Zz);FDo=r(rBt,"XLMRobertaXLModel"),rBt.forEach(t),TDo=r(mGe," (XLM-RoBERTa-XL model)"),mGe.forEach(t),MDo=i(x),P2=n(x,"LI",{});var fGe=s(P2);B2e=n(fGe,"STRONG",{});var tBt=s(B2e);EDo=r(tBt,"xlnet"),tBt.forEach(t),CDo=r(fGe," \u2014 "),Kz=n(fGe,"A",{href:!0});var aBt=s(Kz);wDo=r(aBt,"XLNetModel"),aBt.forEach(t),ADo=r(fGe," (XLNet model)"),fGe.forEach(t),LDo=i(x),B2=n(x,"LI",{});var gGe=s(B2);I2e=n(gGe,"STRONG",{});var nBt=s(I2e);yDo=r(nBt,"yolos"),nBt.forEach(t),xDo=r(gGe," \u2014 "),eQ=n(gGe,"A",{href:!0});var sBt=s(eQ);$Do=r(sBt,"YolosModel"),sBt.forEach(t),kDo=r(gGe," (YOLOS model)"),gGe.forEach(t),SDo=i(x),I2=n(x,"LI",{});var hGe=s(I2);N2e=n(hGe,"STRONG",{});var lBt=s(N2e);RDo=r(lBt,"yoso"),lBt.forEach(t),PDo=r(hGe," \u2014 "),oQ=n(hGe,"A",{href:!0});var iBt=s(oQ);BDo=r(iBt,"YosoModel"),iBt.forEach(t),IDo=r(hGe," (YOSO model)"),hGe.forEach(t),x.forEach(t),NDo=i(Ea),N2=n(Ea,"P",{});var uGe=s(N2);qDo=r(uGe,"The model is set in evaluation mode by default using "),q2e=n(uGe,"CODE",{});var dBt=s(q2e);jDo=r(dBt,"model.eval()"),dBt.forEach(t),DDo=r(uGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j2e=n(uGe,"CODE",{});var cBt=s(j2e);GDo=r(cBt,"model.train()"),cBt.forEach(t),uGe.forEach(t),ODo=i(Ea),T(q2.$$.fragment,Ea),Ea.forEach(t),kl.forEach(t),joo=i(m),Ad=n(m,"H2",{class:!0});var oao=s(Ad);j2=n(oao,"A",{id:!0,class:!0,href:!0});var mBt=s(j2);D2e=n(mBt,"SPAN",{});var fBt=s(D2e);T(l$.$$.fragment,fBt),fBt.forEach(t),mBt.forEach(t),VDo=i(oao),G2e=n(oao,"SPAN",{});var gBt=s(G2e);XDo=r(gBt,"AutoModelForPreTraining"),gBt.forEach(t),oao.forEach(t),Doo=i(m),Io=n(m,"DIV",{class:!0});var Sl=s(Io);T(i$.$$.fragment,Sl),zDo=i(Sl),Ld=n(Sl,"P",{});var Yie=s(Ld);QDo=r(Yie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rQ=n(Yie,"A",{href:!0});var hBt=s(rQ);WDo=r(hBt,"from_pretrained()"),hBt.forEach(t),UDo=r(Yie," class method or the "),tQ=n(Yie,"A",{href:!0});var uBt=s(tQ);HDo=r(uBt,"from_config()"),uBt.forEach(t),JDo=r(Yie,` class
method.`),Yie.forEach(t),YDo=i(Sl),d$=n(Sl,"P",{});var rao=s(d$);ZDo=r(rao,"This class cannot be instantiated directly using "),O2e=n(rao,"CODE",{});var pBt=s(O2e);KDo=r(pBt,"__init__()"),pBt.forEach(t),eGo=r(rao," (throws an error)."),rao.forEach(t),oGo=i(Sl),Ft=n(Sl,"DIV",{class:!0});var Cy=s(Ft);T(c$.$$.fragment,Cy),rGo=i(Cy),V2e=n(Cy,"P",{});var _Bt=s(V2e);tGo=r(_Bt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_Bt.forEach(t),aGo=i(Cy),yd=n(Cy,"P",{});var Zie=s(yd);nGo=r(Zie,`Note:
Loading a model from its configuration file does `),X2e=n(Zie,"STRONG",{});var bBt=s(X2e);sGo=r(bBt,"not"),bBt.forEach(t),lGo=r(Zie,` load the model weights. It only affects the
model\u2019s configuration. Use `),aQ=n(Zie,"A",{href:!0});var vBt=s(aQ);iGo=r(vBt,"from_pretrained()"),vBt.forEach(t),dGo=r(Zie," to load the model weights."),Zie.forEach(t),cGo=i(Cy),T(D2.$$.fragment,Cy),Cy.forEach(t),mGo=i(Sl),eo=n(Sl,"DIV",{class:!0});var Ca=s(eo);T(m$.$$.fragment,Ca),fGo=i(Ca),z2e=n(Ca,"P",{});var FBt=s(z2e);gGo=r(FBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FBt.forEach(t),hGo=i(Ca),on=n(Ca,"P",{});var wy=s(on);uGo=r(wy,"The model class to instantiate is selected based on the "),Q2e=n(wy,"CODE",{});var TBt=s(Q2e);pGo=r(TBt,"model_type"),TBt.forEach(t),_Go=r(wy,` property of the config object (either
passed as an argument or loaded from `),W2e=n(wy,"CODE",{});var MBt=s(W2e);bGo=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),vGo=r(wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=n(wy,"CODE",{});var EBt=s(U2e);FGo=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),TGo=r(wy,":"),wy.forEach(t),MGo=i(Ca),G=n(Ca,"UL",{});var V=s(G);G2=n(V,"LI",{});var pGe=s(G2);H2e=n(pGe,"STRONG",{});var CBt=s(H2e);EGo=r(CBt,"albert"),CBt.forEach(t),CGo=r(pGe," \u2014 "),nQ=n(pGe,"A",{href:!0});var wBt=s(nQ);wGo=r(wBt,"AlbertForPreTraining"),wBt.forEach(t),AGo=r(pGe," (ALBERT model)"),pGe.forEach(t),LGo=i(V),O2=n(V,"LI",{});var _Ge=s(O2);J2e=n(_Ge,"STRONG",{});var ABt=s(J2e);yGo=r(ABt,"bart"),ABt.forEach(t),xGo=r(_Ge," \u2014 "),sQ=n(_Ge,"A",{href:!0});var LBt=s(sQ);$Go=r(LBt,"BartForConditionalGeneration"),LBt.forEach(t),kGo=r(_Ge," (BART model)"),_Ge.forEach(t),SGo=i(V),V2=n(V,"LI",{});var bGe=s(V2);Y2e=n(bGe,"STRONG",{});var yBt=s(Y2e);RGo=r(yBt,"bert"),yBt.forEach(t),PGo=r(bGe," \u2014 "),lQ=n(bGe,"A",{href:!0});var xBt=s(lQ);BGo=r(xBt,"BertForPreTraining"),xBt.forEach(t),IGo=r(bGe," (BERT model)"),bGe.forEach(t),NGo=i(V),X2=n(V,"LI",{});var vGe=s(X2);Z2e=n(vGe,"STRONG",{});var $Bt=s(Z2e);qGo=r($Bt,"big_bird"),$Bt.forEach(t),jGo=r(vGe," \u2014 "),iQ=n(vGe,"A",{href:!0});var kBt=s(iQ);DGo=r(kBt,"BigBirdForPreTraining"),kBt.forEach(t),GGo=r(vGe," (BigBird model)"),vGe.forEach(t),OGo=i(V),z2=n(V,"LI",{});var FGe=s(z2);K2e=n(FGe,"STRONG",{});var SBt=s(K2e);VGo=r(SBt,"bloom"),SBt.forEach(t),XGo=r(FGe," \u2014 "),dQ=n(FGe,"A",{href:!0});var RBt=s(dQ);zGo=r(RBt,"BloomForCausalLM"),RBt.forEach(t),QGo=r(FGe," (BLOOM model)"),FGe.forEach(t),WGo=i(V),Q2=n(V,"LI",{});var TGe=s(Q2);ebe=n(TGe,"STRONG",{});var PBt=s(ebe);UGo=r(PBt,"camembert"),PBt.forEach(t),HGo=r(TGe," \u2014 "),cQ=n(TGe,"A",{href:!0});var BBt=s(cQ);JGo=r(BBt,"CamembertForMaskedLM"),BBt.forEach(t),YGo=r(TGe," (CamemBERT model)"),TGe.forEach(t),ZGo=i(V),W2=n(V,"LI",{});var MGe=s(W2);obe=n(MGe,"STRONG",{});var IBt=s(obe);KGo=r(IBt,"ctrl"),IBt.forEach(t),eOo=r(MGe," \u2014 "),mQ=n(MGe,"A",{href:!0});var NBt=s(mQ);oOo=r(NBt,"CTRLLMHeadModel"),NBt.forEach(t),rOo=r(MGe," (CTRL model)"),MGe.forEach(t),tOo=i(V),U2=n(V,"LI",{});var EGe=s(U2);rbe=n(EGe,"STRONG",{});var qBt=s(rbe);aOo=r(qBt,"data2vec-text"),qBt.forEach(t),nOo=r(EGe," \u2014 "),fQ=n(EGe,"A",{href:!0});var jBt=s(fQ);sOo=r(jBt,"Data2VecTextForMaskedLM"),jBt.forEach(t),lOo=r(EGe," (Data2VecText model)"),EGe.forEach(t),iOo=i(V),H2=n(V,"LI",{});var CGe=s(H2);tbe=n(CGe,"STRONG",{});var DBt=s(tbe);dOo=r(DBt,"deberta"),DBt.forEach(t),cOo=r(CGe," \u2014 "),gQ=n(CGe,"A",{href:!0});var GBt=s(gQ);mOo=r(GBt,"DebertaForMaskedLM"),GBt.forEach(t),fOo=r(CGe," (DeBERTa model)"),CGe.forEach(t),gOo=i(V),J2=n(V,"LI",{});var wGe=s(J2);abe=n(wGe,"STRONG",{});var OBt=s(abe);hOo=r(OBt,"deberta-v2"),OBt.forEach(t),uOo=r(wGe," \u2014 "),hQ=n(wGe,"A",{href:!0});var VBt=s(hQ);pOo=r(VBt,"DebertaV2ForMaskedLM"),VBt.forEach(t),_Oo=r(wGe," (DeBERTa-v2 model)"),wGe.forEach(t),bOo=i(V),Y2=n(V,"LI",{});var AGe=s(Y2);nbe=n(AGe,"STRONG",{});var XBt=s(nbe);vOo=r(XBt,"distilbert"),XBt.forEach(t),FOo=r(AGe," \u2014 "),uQ=n(AGe,"A",{href:!0});var zBt=s(uQ);TOo=r(zBt,"DistilBertForMaskedLM"),zBt.forEach(t),MOo=r(AGe," (DistilBERT model)"),AGe.forEach(t),EOo=i(V),Z2=n(V,"LI",{});var LGe=s(Z2);sbe=n(LGe,"STRONG",{});var QBt=s(sbe);COo=r(QBt,"electra"),QBt.forEach(t),wOo=r(LGe," \u2014 "),pQ=n(LGe,"A",{href:!0});var WBt=s(pQ);AOo=r(WBt,"ElectraForPreTraining"),WBt.forEach(t),LOo=r(LGe," (ELECTRA model)"),LGe.forEach(t),yOo=i(V),K2=n(V,"LI",{});var yGe=s(K2);lbe=n(yGe,"STRONG",{});var UBt=s(lbe);xOo=r(UBt,"ernie"),UBt.forEach(t),$Oo=r(yGe," \u2014 "),_Q=n(yGe,"A",{href:!0});var HBt=s(_Q);kOo=r(HBt,"ErnieForPreTraining"),HBt.forEach(t),SOo=r(yGe," (ERNIE model)"),yGe.forEach(t),ROo=i(V),eb=n(V,"LI",{});var xGe=s(eb);ibe=n(xGe,"STRONG",{});var JBt=s(ibe);POo=r(JBt,"flaubert"),JBt.forEach(t),BOo=r(xGe," \u2014 "),bQ=n(xGe,"A",{href:!0});var YBt=s(bQ);IOo=r(YBt,"FlaubertWithLMHeadModel"),YBt.forEach(t),NOo=r(xGe," (FlauBERT model)"),xGe.forEach(t),qOo=i(V),ob=n(V,"LI",{});var $Ge=s(ob);dbe=n($Ge,"STRONG",{});var ZBt=s(dbe);jOo=r(ZBt,"flava"),ZBt.forEach(t),DOo=r($Ge," \u2014 "),vQ=n($Ge,"A",{href:!0});var KBt=s(vQ);GOo=r(KBt,"FlavaForPreTraining"),KBt.forEach(t),OOo=r($Ge," (FLAVA model)"),$Ge.forEach(t),VOo=i(V),rb=n(V,"LI",{});var kGe=s(rb);cbe=n(kGe,"STRONG",{});var eIt=s(cbe);XOo=r(eIt,"fnet"),eIt.forEach(t),zOo=r(kGe," \u2014 "),FQ=n(kGe,"A",{href:!0});var oIt=s(FQ);QOo=r(oIt,"FNetForPreTraining"),oIt.forEach(t),WOo=r(kGe," (FNet model)"),kGe.forEach(t),UOo=i(V),tb=n(V,"LI",{});var SGe=s(tb);mbe=n(SGe,"STRONG",{});var rIt=s(mbe);HOo=r(rIt,"fsmt"),rIt.forEach(t),JOo=r(SGe," \u2014 "),TQ=n(SGe,"A",{href:!0});var tIt=s(TQ);YOo=r(tIt,"FSMTForConditionalGeneration"),tIt.forEach(t),ZOo=r(SGe," (FairSeq Machine-Translation model)"),SGe.forEach(t),KOo=i(V),ab=n(V,"LI",{});var RGe=s(ab);fbe=n(RGe,"STRONG",{});var aIt=s(fbe);eVo=r(aIt,"funnel"),aIt.forEach(t),oVo=r(RGe," \u2014 "),MQ=n(RGe,"A",{href:!0});var nIt=s(MQ);rVo=r(nIt,"FunnelForPreTraining"),nIt.forEach(t),tVo=r(RGe," (Funnel Transformer model)"),RGe.forEach(t),aVo=i(V),nb=n(V,"LI",{});var PGe=s(nb);gbe=n(PGe,"STRONG",{});var sIt=s(gbe);nVo=r(sIt,"gpt2"),sIt.forEach(t),sVo=r(PGe," \u2014 "),EQ=n(PGe,"A",{href:!0});var lIt=s(EQ);lVo=r(lIt,"GPT2LMHeadModel"),lIt.forEach(t),iVo=r(PGe," (OpenAI GPT-2 model)"),PGe.forEach(t),dVo=i(V),sb=n(V,"LI",{});var BGe=s(sb);hbe=n(BGe,"STRONG",{});var iIt=s(hbe);cVo=r(iIt,"ibert"),iIt.forEach(t),mVo=r(BGe," \u2014 "),CQ=n(BGe,"A",{href:!0});var dIt=s(CQ);fVo=r(dIt,"IBertForMaskedLM"),dIt.forEach(t),gVo=r(BGe," (I-BERT model)"),BGe.forEach(t),hVo=i(V),lb=n(V,"LI",{});var IGe=s(lb);ube=n(IGe,"STRONG",{});var cIt=s(ube);uVo=r(cIt,"layoutlm"),cIt.forEach(t),pVo=r(IGe," \u2014 "),wQ=n(IGe,"A",{href:!0});var mIt=s(wQ);_Vo=r(mIt,"LayoutLMForMaskedLM"),mIt.forEach(t),bVo=r(IGe," (LayoutLM model)"),IGe.forEach(t),vVo=i(V),ib=n(V,"LI",{});var NGe=s(ib);pbe=n(NGe,"STRONG",{});var fIt=s(pbe);FVo=r(fIt,"longformer"),fIt.forEach(t),TVo=r(NGe," \u2014 "),AQ=n(NGe,"A",{href:!0});var gIt=s(AQ);MVo=r(gIt,"LongformerForMaskedLM"),gIt.forEach(t),EVo=r(NGe," (Longformer model)"),NGe.forEach(t),CVo=i(V),db=n(V,"LI",{});var qGe=s(db);_be=n(qGe,"STRONG",{});var hIt=s(_be);wVo=r(hIt,"luke"),hIt.forEach(t),AVo=r(qGe," \u2014 "),LQ=n(qGe,"A",{href:!0});var uIt=s(LQ);LVo=r(uIt,"LukeForMaskedLM"),uIt.forEach(t),yVo=r(qGe," (LUKE model)"),qGe.forEach(t),xVo=i(V),cb=n(V,"LI",{});var jGe=s(cb);bbe=n(jGe,"STRONG",{});var pIt=s(bbe);$Vo=r(pIt,"lxmert"),pIt.forEach(t),kVo=r(jGe," \u2014 "),yQ=n(jGe,"A",{href:!0});var _It=s(yQ);SVo=r(_It,"LxmertForPreTraining"),_It.forEach(t),RVo=r(jGe," (LXMERT model)"),jGe.forEach(t),PVo=i(V),mb=n(V,"LI",{});var DGe=s(mb);vbe=n(DGe,"STRONG",{});var bIt=s(vbe);BVo=r(bIt,"megatron-bert"),bIt.forEach(t),IVo=r(DGe," \u2014 "),xQ=n(DGe,"A",{href:!0});var vIt=s(xQ);NVo=r(vIt,"MegatronBertForPreTraining"),vIt.forEach(t),qVo=r(DGe," (Megatron-BERT model)"),DGe.forEach(t),jVo=i(V),fb=n(V,"LI",{});var GGe=s(fb);Fbe=n(GGe,"STRONG",{});var FIt=s(Fbe);DVo=r(FIt,"mobilebert"),FIt.forEach(t),GVo=r(GGe," \u2014 "),$Q=n(GGe,"A",{href:!0});var TIt=s($Q);OVo=r(TIt,"MobileBertForPreTraining"),TIt.forEach(t),VVo=r(GGe," (MobileBERT model)"),GGe.forEach(t),XVo=i(V),gb=n(V,"LI",{});var OGe=s(gb);Tbe=n(OGe,"STRONG",{});var MIt=s(Tbe);zVo=r(MIt,"mpnet"),MIt.forEach(t),QVo=r(OGe," \u2014 "),kQ=n(OGe,"A",{href:!0});var EIt=s(kQ);WVo=r(EIt,"MPNetForMaskedLM"),EIt.forEach(t),UVo=r(OGe," (MPNet model)"),OGe.forEach(t),HVo=i(V),hb=n(V,"LI",{});var VGe=s(hb);Mbe=n(VGe,"STRONG",{});var CIt=s(Mbe);JVo=r(CIt,"mvp"),CIt.forEach(t),YVo=r(VGe," \u2014 "),SQ=n(VGe,"A",{href:!0});var wIt=s(SQ);ZVo=r(wIt,"MvpForConditionalGeneration"),wIt.forEach(t),KVo=r(VGe," (MVP model)"),VGe.forEach(t),eXo=i(V),ub=n(V,"LI",{});var XGe=s(ub);Ebe=n(XGe,"STRONG",{});var AIt=s(Ebe);oXo=r(AIt,"nezha"),AIt.forEach(t),rXo=r(XGe," \u2014 "),RQ=n(XGe,"A",{href:!0});var LIt=s(RQ);tXo=r(LIt,"NezhaForPreTraining"),LIt.forEach(t),aXo=r(XGe," (Nezha model)"),XGe.forEach(t),nXo=i(V),pb=n(V,"LI",{});var zGe=s(pb);Cbe=n(zGe,"STRONG",{});var yIt=s(Cbe);sXo=r(yIt,"openai-gpt"),yIt.forEach(t),lXo=r(zGe," \u2014 "),PQ=n(zGe,"A",{href:!0});var xIt=s(PQ);iXo=r(xIt,"OpenAIGPTLMHeadModel"),xIt.forEach(t),dXo=r(zGe," (OpenAI GPT model)"),zGe.forEach(t),cXo=i(V),_b=n(V,"LI",{});var QGe=s(_b);wbe=n(QGe,"STRONG",{});var $It=s(wbe);mXo=r($It,"retribert"),$It.forEach(t),fXo=r(QGe," \u2014 "),BQ=n(QGe,"A",{href:!0});var kIt=s(BQ);gXo=r(kIt,"RetriBertModel"),kIt.forEach(t),hXo=r(QGe," (RetriBERT model)"),QGe.forEach(t),uXo=i(V),bb=n(V,"LI",{});var WGe=s(bb);Abe=n(WGe,"STRONG",{});var SIt=s(Abe);pXo=r(SIt,"roberta"),SIt.forEach(t),_Xo=r(WGe," \u2014 "),IQ=n(WGe,"A",{href:!0});var RIt=s(IQ);bXo=r(RIt,"RobertaForMaskedLM"),RIt.forEach(t),vXo=r(WGe," (RoBERTa model)"),WGe.forEach(t),FXo=i(V),vb=n(V,"LI",{});var UGe=s(vb);Lbe=n(UGe,"STRONG",{});var PIt=s(Lbe);TXo=r(PIt,"splinter"),PIt.forEach(t),MXo=r(UGe," \u2014 "),NQ=n(UGe,"A",{href:!0});var BIt=s(NQ);EXo=r(BIt,"SplinterForPreTraining"),BIt.forEach(t),CXo=r(UGe," (Splinter model)"),UGe.forEach(t),wXo=i(V),Fb=n(V,"LI",{});var HGe=s(Fb);ybe=n(HGe,"STRONG",{});var IIt=s(ybe);AXo=r(IIt,"squeezebert"),IIt.forEach(t),LXo=r(HGe," \u2014 "),qQ=n(HGe,"A",{href:!0});var NIt=s(qQ);yXo=r(NIt,"SqueezeBertForMaskedLM"),NIt.forEach(t),xXo=r(HGe," (SqueezeBERT model)"),HGe.forEach(t),$Xo=i(V),Tb=n(V,"LI",{});var JGe=s(Tb);xbe=n(JGe,"STRONG",{});var qIt=s(xbe);kXo=r(qIt,"t5"),qIt.forEach(t),SXo=r(JGe," \u2014 "),jQ=n(JGe,"A",{href:!0});var jIt=s(jQ);RXo=r(jIt,"T5ForConditionalGeneration"),jIt.forEach(t),PXo=r(JGe," (T5 model)"),JGe.forEach(t),BXo=i(V),Mb=n(V,"LI",{});var YGe=s(Mb);$be=n(YGe,"STRONG",{});var DIt=s($be);IXo=r(DIt,"tapas"),DIt.forEach(t),NXo=r(YGe," \u2014 "),DQ=n(YGe,"A",{href:!0});var GIt=s(DQ);qXo=r(GIt,"TapasForMaskedLM"),GIt.forEach(t),jXo=r(YGe," (TAPAS model)"),YGe.forEach(t),DXo=i(V),Eb=n(V,"LI",{});var ZGe=s(Eb);kbe=n(ZGe,"STRONG",{});var OIt=s(kbe);GXo=r(OIt,"transfo-xl"),OIt.forEach(t),OXo=r(ZGe," \u2014 "),GQ=n(ZGe,"A",{href:!0});var VIt=s(GQ);VXo=r(VIt,"TransfoXLLMHeadModel"),VIt.forEach(t),XXo=r(ZGe," (Transformer-XL model)"),ZGe.forEach(t),zXo=i(V),Cb=n(V,"LI",{});var KGe=s(Cb);Sbe=n(KGe,"STRONG",{});var XIt=s(Sbe);QXo=r(XIt,"unispeech"),XIt.forEach(t),WXo=r(KGe," \u2014 "),OQ=n(KGe,"A",{href:!0});var zIt=s(OQ);UXo=r(zIt,"UniSpeechForPreTraining"),zIt.forEach(t),HXo=r(KGe," (UniSpeech model)"),KGe.forEach(t),JXo=i(V),wb=n(V,"LI",{});var eOe=s(wb);Rbe=n(eOe,"STRONG",{});var QIt=s(Rbe);YXo=r(QIt,"unispeech-sat"),QIt.forEach(t),ZXo=r(eOe," \u2014 "),VQ=n(eOe,"A",{href:!0});var WIt=s(VQ);KXo=r(WIt,"UniSpeechSatForPreTraining"),WIt.forEach(t),ezo=r(eOe," (UniSpeechSat model)"),eOe.forEach(t),ozo=i(V),Ab=n(V,"LI",{});var oOe=s(Ab);Pbe=n(oOe,"STRONG",{});var UIt=s(Pbe);rzo=r(UIt,"videomae"),UIt.forEach(t),tzo=r(oOe," \u2014 "),XQ=n(oOe,"A",{href:!0});var HIt=s(XQ);azo=r(HIt,"VideoMAEForPreTraining"),HIt.forEach(t),nzo=r(oOe," (VideoMAE model)"),oOe.forEach(t),szo=i(V),Lb=n(V,"LI",{});var rOe=s(Lb);Bbe=n(rOe,"STRONG",{});var JIt=s(Bbe);lzo=r(JIt,"visual_bert"),JIt.forEach(t),izo=r(rOe," \u2014 "),zQ=n(rOe,"A",{href:!0});var YIt=s(zQ);dzo=r(YIt,"VisualBertForPreTraining"),YIt.forEach(t),czo=r(rOe," (VisualBERT model)"),rOe.forEach(t),mzo=i(V),yb=n(V,"LI",{});var tOe=s(yb);Ibe=n(tOe,"STRONG",{});var ZIt=s(Ibe);fzo=r(ZIt,"vit_mae"),ZIt.forEach(t),gzo=r(tOe," \u2014 "),QQ=n(tOe,"A",{href:!0});var KIt=s(QQ);hzo=r(KIt,"ViTMAEForPreTraining"),KIt.forEach(t),uzo=r(tOe," (ViTMAE model)"),tOe.forEach(t),pzo=i(V),xb=n(V,"LI",{});var aOe=s(xb);Nbe=n(aOe,"STRONG",{});var eNt=s(Nbe);_zo=r(eNt,"wav2vec2"),eNt.forEach(t),bzo=r(aOe," \u2014 "),WQ=n(aOe,"A",{href:!0});var oNt=s(WQ);vzo=r(oNt,"Wav2Vec2ForPreTraining"),oNt.forEach(t),Fzo=r(aOe," (Wav2Vec2 model)"),aOe.forEach(t),Tzo=i(V),$b=n(V,"LI",{});var nOe=s($b);qbe=n(nOe,"STRONG",{});var rNt=s(qbe);Mzo=r(rNt,"wav2vec2-conformer"),rNt.forEach(t),Ezo=r(nOe," \u2014 "),UQ=n(nOe,"A",{href:!0});var tNt=s(UQ);Czo=r(tNt,"Wav2Vec2ConformerForPreTraining"),tNt.forEach(t),wzo=r(nOe," (Wav2Vec2-Conformer model)"),nOe.forEach(t),Azo=i(V),kb=n(V,"LI",{});var sOe=s(kb);jbe=n(sOe,"STRONG",{});var aNt=s(jbe);Lzo=r(aNt,"xlm"),aNt.forEach(t),yzo=r(sOe," \u2014 "),HQ=n(sOe,"A",{href:!0});var nNt=s(HQ);xzo=r(nNt,"XLMWithLMHeadModel"),nNt.forEach(t),$zo=r(sOe," (XLM model)"),sOe.forEach(t),kzo=i(V),Sb=n(V,"LI",{});var lOe=s(Sb);Dbe=n(lOe,"STRONG",{});var sNt=s(Dbe);Szo=r(sNt,"xlm-roberta"),sNt.forEach(t),Rzo=r(lOe," \u2014 "),JQ=n(lOe,"A",{href:!0});var lNt=s(JQ);Pzo=r(lNt,"XLMRobertaForMaskedLM"),lNt.forEach(t),Bzo=r(lOe," (XLM-RoBERTa model)"),lOe.forEach(t),Izo=i(V),Rb=n(V,"LI",{});var iOe=s(Rb);Gbe=n(iOe,"STRONG",{});var iNt=s(Gbe);Nzo=r(iNt,"xlm-roberta-xl"),iNt.forEach(t),qzo=r(iOe," \u2014 "),YQ=n(iOe,"A",{href:!0});var dNt=s(YQ);jzo=r(dNt,"XLMRobertaXLForMaskedLM"),dNt.forEach(t),Dzo=r(iOe," (XLM-RoBERTa-XL model)"),iOe.forEach(t),Gzo=i(V),Pb=n(V,"LI",{});var dOe=s(Pb);Obe=n(dOe,"STRONG",{});var cNt=s(Obe);Ozo=r(cNt,"xlnet"),cNt.forEach(t),Vzo=r(dOe," \u2014 "),ZQ=n(dOe,"A",{href:!0});var mNt=s(ZQ);Xzo=r(mNt,"XLNetLMHeadModel"),mNt.forEach(t),zzo=r(dOe," (XLNet model)"),dOe.forEach(t),V.forEach(t),Qzo=i(Ca),Bb=n(Ca,"P",{});var cOe=s(Bb);Wzo=r(cOe,"The model is set in evaluation mode by default using "),Vbe=n(cOe,"CODE",{});var fNt=s(Vbe);Uzo=r(fNt,"model.eval()"),fNt.forEach(t),Hzo=r(cOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xbe=n(cOe,"CODE",{});var gNt=s(Xbe);Jzo=r(gNt,"model.train()"),gNt.forEach(t),cOe.forEach(t),Yzo=i(Ca),T(Ib.$$.fragment,Ca),Ca.forEach(t),Sl.forEach(t),Goo=i(m),xd=n(m,"H2",{class:!0});var tao=s(xd);Nb=n(tao,"A",{id:!0,class:!0,href:!0});var hNt=s(Nb);zbe=n(hNt,"SPAN",{});var uNt=s(zbe);T(f$.$$.fragment,uNt),uNt.forEach(t),hNt.forEach(t),Zzo=i(tao),Qbe=n(tao,"SPAN",{});var pNt=s(Qbe);Kzo=r(pNt,"AutoModelForCausalLM"),pNt.forEach(t),tao.forEach(t),Ooo=i(m),No=n(m,"DIV",{class:!0});var Rl=s(No);T(g$.$$.fragment,Rl),eQo=i(Rl),$d=n(Rl,"P",{});var Kie=s($d);oQo=r(Kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),KQ=n(Kie,"A",{href:!0});var _Nt=s(KQ);rQo=r(_Nt,"from_pretrained()"),_Nt.forEach(t),tQo=r(Kie," class method or the "),eW=n(Kie,"A",{href:!0});var bNt=s(eW);aQo=r(bNt,"from_config()"),bNt.forEach(t),nQo=r(Kie,` class
method.`),Kie.forEach(t),sQo=i(Rl),h$=n(Rl,"P",{});var aao=s(h$);lQo=r(aao,"This class cannot be instantiated directly using "),Wbe=n(aao,"CODE",{});var vNt=s(Wbe);iQo=r(vNt,"__init__()"),vNt.forEach(t),dQo=r(aao," (throws an error)."),aao.forEach(t),cQo=i(Rl),Tt=n(Rl,"DIV",{class:!0});var Ay=s(Tt);T(u$.$$.fragment,Ay),mQo=i(Ay),Ube=n(Ay,"P",{});var FNt=s(Ube);fQo=r(FNt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),FNt.forEach(t),gQo=i(Ay),kd=n(Ay,"P",{});var ede=s(kd);hQo=r(ede,`Note:
Loading a model from its configuration file does `),Hbe=n(ede,"STRONG",{});var TNt=s(Hbe);uQo=r(TNt,"not"),TNt.forEach(t),pQo=r(ede,` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=n(ede,"A",{href:!0});var MNt=s(oW);_Qo=r(MNt,"from_pretrained()"),MNt.forEach(t),bQo=r(ede," to load the model weights."),ede.forEach(t),vQo=i(Ay),T(qb.$$.fragment,Ay),Ay.forEach(t),FQo=i(Rl),oo=n(Rl,"DIV",{class:!0});var wa=s(oo);T(p$.$$.fragment,wa),TQo=i(wa),Jbe=n(wa,"P",{});var ENt=s(Jbe);MQo=r(ENt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ENt.forEach(t),EQo=i(wa),rn=n(wa,"P",{});var Ly=s(rn);CQo=r(Ly,"The model class to instantiate is selected based on the "),Ybe=n(Ly,"CODE",{});var CNt=s(Ybe);wQo=r(CNt,"model_type"),CNt.forEach(t),AQo=r(Ly,` property of the config object (either
passed as an argument or loaded from `),Zbe=n(Ly,"CODE",{});var wNt=s(Zbe);LQo=r(wNt,"pretrained_model_name_or_path"),wNt.forEach(t),yQo=r(Ly,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kbe=n(Ly,"CODE",{});var ANt=s(Kbe);xQo=r(ANt,"pretrained_model_name_or_path"),ANt.forEach(t),$Qo=r(Ly,":"),Ly.forEach(t),kQo=i(wa),Q=n(wa,"UL",{});var U=s(Q);jb=n(U,"LI",{});var mOe=s(jb);eve=n(mOe,"STRONG",{});var LNt=s(eve);SQo=r(LNt,"bart"),LNt.forEach(t),RQo=r(mOe," \u2014 "),rW=n(mOe,"A",{href:!0});var yNt=s(rW);PQo=r(yNt,"BartForCausalLM"),yNt.forEach(t),BQo=r(mOe," (BART model)"),mOe.forEach(t),IQo=i(U),Db=n(U,"LI",{});var fOe=s(Db);ove=n(fOe,"STRONG",{});var xNt=s(ove);NQo=r(xNt,"bert"),xNt.forEach(t),qQo=r(fOe," \u2014 "),tW=n(fOe,"A",{href:!0});var $Nt=s(tW);jQo=r($Nt,"BertLMHeadModel"),$Nt.forEach(t),DQo=r(fOe," (BERT model)"),fOe.forEach(t),GQo=i(U),Gb=n(U,"LI",{});var gOe=s(Gb);rve=n(gOe,"STRONG",{});var kNt=s(rve);OQo=r(kNt,"bert-generation"),kNt.forEach(t),VQo=r(gOe," \u2014 "),aW=n(gOe,"A",{href:!0});var SNt=s(aW);XQo=r(SNt,"BertGenerationDecoder"),SNt.forEach(t),zQo=r(gOe," (Bert Generation model)"),gOe.forEach(t),QQo=i(U),Ob=n(U,"LI",{});var hOe=s(Ob);tve=n(hOe,"STRONG",{});var RNt=s(tve);WQo=r(RNt,"big_bird"),RNt.forEach(t),UQo=r(hOe," \u2014 "),nW=n(hOe,"A",{href:!0});var PNt=s(nW);HQo=r(PNt,"BigBirdForCausalLM"),PNt.forEach(t),JQo=r(hOe," (BigBird model)"),hOe.forEach(t),YQo=i(U),Vb=n(U,"LI",{});var uOe=s(Vb);ave=n(uOe,"STRONG",{});var BNt=s(ave);ZQo=r(BNt,"bigbird_pegasus"),BNt.forEach(t),KQo=r(uOe," \u2014 "),sW=n(uOe,"A",{href:!0});var INt=s(sW);eWo=r(INt,"BigBirdPegasusForCausalLM"),INt.forEach(t),oWo=r(uOe," (BigBird-Pegasus model)"),uOe.forEach(t),rWo=i(U),Xb=n(U,"LI",{});var pOe=s(Xb);nve=n(pOe,"STRONG",{});var NNt=s(nve);tWo=r(NNt,"blenderbot"),NNt.forEach(t),aWo=r(pOe," \u2014 "),lW=n(pOe,"A",{href:!0});var qNt=s(lW);nWo=r(qNt,"BlenderbotForCausalLM"),qNt.forEach(t),sWo=r(pOe," (Blenderbot model)"),pOe.forEach(t),lWo=i(U),zb=n(U,"LI",{});var _Oe=s(zb);sve=n(_Oe,"STRONG",{});var jNt=s(sve);iWo=r(jNt,"blenderbot-small"),jNt.forEach(t),dWo=r(_Oe," \u2014 "),iW=n(_Oe,"A",{href:!0});var DNt=s(iW);cWo=r(DNt,"BlenderbotSmallForCausalLM"),DNt.forEach(t),mWo=r(_Oe," (BlenderbotSmall model)"),_Oe.forEach(t),fWo=i(U),Qb=n(U,"LI",{});var bOe=s(Qb);lve=n(bOe,"STRONG",{});var GNt=s(lve);gWo=r(GNt,"bloom"),GNt.forEach(t),hWo=r(bOe," \u2014 "),dW=n(bOe,"A",{href:!0});var ONt=s(dW);uWo=r(ONt,"BloomForCausalLM"),ONt.forEach(t),pWo=r(bOe," (BLOOM model)"),bOe.forEach(t),_Wo=i(U),Wb=n(U,"LI",{});var vOe=s(Wb);ive=n(vOe,"STRONG",{});var VNt=s(ive);bWo=r(VNt,"camembert"),VNt.forEach(t),vWo=r(vOe," \u2014 "),cW=n(vOe,"A",{href:!0});var XNt=s(cW);FWo=r(XNt,"CamembertForCausalLM"),XNt.forEach(t),TWo=r(vOe," (CamemBERT model)"),vOe.forEach(t),MWo=i(U),Ub=n(U,"LI",{});var FOe=s(Ub);dve=n(FOe,"STRONG",{});var zNt=s(dve);EWo=r(zNt,"codegen"),zNt.forEach(t),CWo=r(FOe," \u2014 "),mW=n(FOe,"A",{href:!0});var QNt=s(mW);wWo=r(QNt,"CodeGenForCausalLM"),QNt.forEach(t),AWo=r(FOe," (CodeGen model)"),FOe.forEach(t),LWo=i(U),Hb=n(U,"LI",{});var TOe=s(Hb);cve=n(TOe,"STRONG",{});var WNt=s(cve);yWo=r(WNt,"ctrl"),WNt.forEach(t),xWo=r(TOe," \u2014 "),fW=n(TOe,"A",{href:!0});var UNt=s(fW);$Wo=r(UNt,"CTRLLMHeadModel"),UNt.forEach(t),kWo=r(TOe," (CTRL model)"),TOe.forEach(t),SWo=i(U),Jb=n(U,"LI",{});var MOe=s(Jb);mve=n(MOe,"STRONG",{});var HNt=s(mve);RWo=r(HNt,"data2vec-text"),HNt.forEach(t),PWo=r(MOe," \u2014 "),gW=n(MOe,"A",{href:!0});var JNt=s(gW);BWo=r(JNt,"Data2VecTextForCausalLM"),JNt.forEach(t),IWo=r(MOe," (Data2VecText model)"),MOe.forEach(t),NWo=i(U),Yb=n(U,"LI",{});var EOe=s(Yb);fve=n(EOe,"STRONG",{});var YNt=s(fve);qWo=r(YNt,"electra"),YNt.forEach(t),jWo=r(EOe," \u2014 "),hW=n(EOe,"A",{href:!0});var ZNt=s(hW);DWo=r(ZNt,"ElectraForCausalLM"),ZNt.forEach(t),GWo=r(EOe," (ELECTRA model)"),EOe.forEach(t),OWo=i(U),Zb=n(U,"LI",{});var COe=s(Zb);gve=n(COe,"STRONG",{});var KNt=s(gve);VWo=r(KNt,"ernie"),KNt.forEach(t),XWo=r(COe," \u2014 "),uW=n(COe,"A",{href:!0});var eqt=s(uW);zWo=r(eqt,"ErnieForCausalLM"),eqt.forEach(t),QWo=r(COe," (ERNIE model)"),COe.forEach(t),WWo=i(U),Kb=n(U,"LI",{});var wOe=s(Kb);hve=n(wOe,"STRONG",{});var oqt=s(hve);UWo=r(oqt,"gpt2"),oqt.forEach(t),HWo=r(wOe," \u2014 "),pW=n(wOe,"A",{href:!0});var rqt=s(pW);JWo=r(rqt,"GPT2LMHeadModel"),rqt.forEach(t),YWo=r(wOe," (OpenAI GPT-2 model)"),wOe.forEach(t),ZWo=i(U),ev=n(U,"LI",{});var AOe=s(ev);uve=n(AOe,"STRONG",{});var tqt=s(uve);KWo=r(tqt,"gpt_neo"),tqt.forEach(t),eUo=r(AOe," \u2014 "),_W=n(AOe,"A",{href:!0});var aqt=s(_W);oUo=r(aqt,"GPTNeoForCausalLM"),aqt.forEach(t),rUo=r(AOe," (GPT Neo model)"),AOe.forEach(t),tUo=i(U),ov=n(U,"LI",{});var LOe=s(ov);pve=n(LOe,"STRONG",{});var nqt=s(pve);aUo=r(nqt,"gpt_neox"),nqt.forEach(t),nUo=r(LOe," \u2014 "),bW=n(LOe,"A",{href:!0});var sqt=s(bW);sUo=r(sqt,"GPTNeoXForCausalLM"),sqt.forEach(t),lUo=r(LOe," (GPT NeoX model)"),LOe.forEach(t),iUo=i(U),rv=n(U,"LI",{});var yOe=s(rv);_ve=n(yOe,"STRONG",{});var lqt=s(_ve);dUo=r(lqt,"gpt_neox_japanese"),lqt.forEach(t),cUo=r(yOe," \u2014 "),vW=n(yOe,"A",{href:!0});var iqt=s(vW);mUo=r(iqt,"GPTNeoXJapaneseForCausalLM"),iqt.forEach(t),fUo=r(yOe," (GPT NeoX Japanese model)"),yOe.forEach(t),gUo=i(U),tv=n(U,"LI",{});var xOe=s(tv);bve=n(xOe,"STRONG",{});var dqt=s(bve);hUo=r(dqt,"gptj"),dqt.forEach(t),uUo=r(xOe," \u2014 "),FW=n(xOe,"A",{href:!0});var cqt=s(FW);pUo=r(cqt,"GPTJForCausalLM"),cqt.forEach(t),_Uo=r(xOe," (GPT-J model)"),xOe.forEach(t),bUo=i(U),av=n(U,"LI",{});var $Oe=s(av);vve=n($Oe,"STRONG",{});var mqt=s(vve);vUo=r(mqt,"marian"),mqt.forEach(t),FUo=r($Oe," \u2014 "),TW=n($Oe,"A",{href:!0});var fqt=s(TW);TUo=r(fqt,"MarianForCausalLM"),fqt.forEach(t),MUo=r($Oe," (Marian model)"),$Oe.forEach(t),EUo=i(U),nv=n(U,"LI",{});var kOe=s(nv);Fve=n(kOe,"STRONG",{});var gqt=s(Fve);CUo=r(gqt,"mbart"),gqt.forEach(t),wUo=r(kOe," \u2014 "),MW=n(kOe,"A",{href:!0});var hqt=s(MW);AUo=r(hqt,"MBartForCausalLM"),hqt.forEach(t),LUo=r(kOe," (mBART model)"),kOe.forEach(t),yUo=i(U),sv=n(U,"LI",{});var SOe=s(sv);Tve=n(SOe,"STRONG",{});var uqt=s(Tve);xUo=r(uqt,"megatron-bert"),uqt.forEach(t),$Uo=r(SOe," \u2014 "),EW=n(SOe,"A",{href:!0});var pqt=s(EW);kUo=r(pqt,"MegatronBertForCausalLM"),pqt.forEach(t),SUo=r(SOe," (Megatron-BERT model)"),SOe.forEach(t),RUo=i(U),lv=n(U,"LI",{});var ROe=s(lv);Mve=n(ROe,"STRONG",{});var _qt=s(Mve);PUo=r(_qt,"mvp"),_qt.forEach(t),BUo=r(ROe," \u2014 "),CW=n(ROe,"A",{href:!0});var bqt=s(CW);IUo=r(bqt,"MvpForCausalLM"),bqt.forEach(t),NUo=r(ROe," (MVP model)"),ROe.forEach(t),qUo=i(U),iv=n(U,"LI",{});var POe=s(iv);Eve=n(POe,"STRONG",{});var vqt=s(Eve);jUo=r(vqt,"openai-gpt"),vqt.forEach(t),DUo=r(POe," \u2014 "),wW=n(POe,"A",{href:!0});var Fqt=s(wW);GUo=r(Fqt,"OpenAIGPTLMHeadModel"),Fqt.forEach(t),OUo=r(POe," (OpenAI GPT model)"),POe.forEach(t),VUo=i(U),dv=n(U,"LI",{});var BOe=s(dv);Cve=n(BOe,"STRONG",{});var Tqt=s(Cve);XUo=r(Tqt,"opt"),Tqt.forEach(t),zUo=r(BOe," \u2014 "),AW=n(BOe,"A",{href:!0});var Mqt=s(AW);QUo=r(Mqt,"OPTForCausalLM"),Mqt.forEach(t),WUo=r(BOe," (OPT model)"),BOe.forEach(t),UUo=i(U),cv=n(U,"LI",{});var IOe=s(cv);wve=n(IOe,"STRONG",{});var Eqt=s(wve);HUo=r(Eqt,"pegasus"),Eqt.forEach(t),JUo=r(IOe," \u2014 "),LW=n(IOe,"A",{href:!0});var Cqt=s(LW);YUo=r(Cqt,"PegasusForCausalLM"),Cqt.forEach(t),ZUo=r(IOe," (Pegasus model)"),IOe.forEach(t),KUo=i(U),mv=n(U,"LI",{});var NOe=s(mv);Ave=n(NOe,"STRONG",{});var wqt=s(Ave);eHo=r(wqt,"plbart"),wqt.forEach(t),oHo=r(NOe," \u2014 "),yW=n(NOe,"A",{href:!0});var Aqt=s(yW);rHo=r(Aqt,"PLBartForCausalLM"),Aqt.forEach(t),tHo=r(NOe," (PLBart model)"),NOe.forEach(t),aHo=i(U),fv=n(U,"LI",{});var qOe=s(fv);Lve=n(qOe,"STRONG",{});var Lqt=s(Lve);nHo=r(Lqt,"prophetnet"),Lqt.forEach(t),sHo=r(qOe," \u2014 "),xW=n(qOe,"A",{href:!0});var yqt=s(xW);lHo=r(yqt,"ProphetNetForCausalLM"),yqt.forEach(t),iHo=r(qOe," (ProphetNet model)"),qOe.forEach(t),dHo=i(U),gv=n(U,"LI",{});var jOe=s(gv);yve=n(jOe,"STRONG",{});var xqt=s(yve);cHo=r(xqt,"qdqbert"),xqt.forEach(t),mHo=r(jOe," \u2014 "),$W=n(jOe,"A",{href:!0});var $qt=s($W);fHo=r($qt,"QDQBertLMHeadModel"),$qt.forEach(t),gHo=r(jOe," (QDQBert model)"),jOe.forEach(t),hHo=i(U),hv=n(U,"LI",{});var DOe=s(hv);xve=n(DOe,"STRONG",{});var kqt=s(xve);uHo=r(kqt,"reformer"),kqt.forEach(t),pHo=r(DOe," \u2014 "),kW=n(DOe,"A",{href:!0});var Sqt=s(kW);_Ho=r(Sqt,"ReformerModelWithLMHead"),Sqt.forEach(t),bHo=r(DOe," (Reformer model)"),DOe.forEach(t),vHo=i(U),uv=n(U,"LI",{});var GOe=s(uv);$ve=n(GOe,"STRONG",{});var Rqt=s($ve);FHo=r(Rqt,"rembert"),Rqt.forEach(t),THo=r(GOe," \u2014 "),SW=n(GOe,"A",{href:!0});var Pqt=s(SW);MHo=r(Pqt,"RemBertForCausalLM"),Pqt.forEach(t),EHo=r(GOe," (RemBERT model)"),GOe.forEach(t),CHo=i(U),pv=n(U,"LI",{});var OOe=s(pv);kve=n(OOe,"STRONG",{});var Bqt=s(kve);wHo=r(Bqt,"roberta"),Bqt.forEach(t),AHo=r(OOe," \u2014 "),RW=n(OOe,"A",{href:!0});var Iqt=s(RW);LHo=r(Iqt,"RobertaForCausalLM"),Iqt.forEach(t),yHo=r(OOe," (RoBERTa model)"),OOe.forEach(t),xHo=i(U),_v=n(U,"LI",{});var VOe=s(_v);Sve=n(VOe,"STRONG",{});var Nqt=s(Sve);$Ho=r(Nqt,"roformer"),Nqt.forEach(t),kHo=r(VOe," \u2014 "),PW=n(VOe,"A",{href:!0});var qqt=s(PW);SHo=r(qqt,"RoFormerForCausalLM"),qqt.forEach(t),RHo=r(VOe," (RoFormer model)"),VOe.forEach(t),PHo=i(U),bv=n(U,"LI",{});var XOe=s(bv);Rve=n(XOe,"STRONG",{});var jqt=s(Rve);BHo=r(jqt,"speech_to_text_2"),jqt.forEach(t),IHo=r(XOe," \u2014 "),BW=n(XOe,"A",{href:!0});var Dqt=s(BW);NHo=r(Dqt,"Speech2Text2ForCausalLM"),Dqt.forEach(t),qHo=r(XOe," (Speech2Text2 model)"),XOe.forEach(t),jHo=i(U),vv=n(U,"LI",{});var zOe=s(vv);Pve=n(zOe,"STRONG",{});var Gqt=s(Pve);DHo=r(Gqt,"transfo-xl"),Gqt.forEach(t),GHo=r(zOe," \u2014 "),IW=n(zOe,"A",{href:!0});var Oqt=s(IW);OHo=r(Oqt,"TransfoXLLMHeadModel"),Oqt.forEach(t),VHo=r(zOe," (Transformer-XL model)"),zOe.forEach(t),XHo=i(U),Fv=n(U,"LI",{});var QOe=s(Fv);Bve=n(QOe,"STRONG",{});var Vqt=s(Bve);zHo=r(Vqt,"trocr"),Vqt.forEach(t),QHo=r(QOe," \u2014 "),NW=n(QOe,"A",{href:!0});var Xqt=s(NW);WHo=r(Xqt,"TrOCRForCausalLM"),Xqt.forEach(t),UHo=r(QOe," (TrOCR model)"),QOe.forEach(t),HHo=i(U),Tv=n(U,"LI",{});var WOe=s(Tv);Ive=n(WOe,"STRONG",{});var zqt=s(Ive);JHo=r(zqt,"xglm"),zqt.forEach(t),YHo=r(WOe," \u2014 "),qW=n(WOe,"A",{href:!0});var Qqt=s(qW);ZHo=r(Qqt,"XGLMForCausalLM"),Qqt.forEach(t),KHo=r(WOe," (XGLM model)"),WOe.forEach(t),eJo=i(U),Mv=n(U,"LI",{});var UOe=s(Mv);Nve=n(UOe,"STRONG",{});var Wqt=s(Nve);oJo=r(Wqt,"xlm"),Wqt.forEach(t),rJo=r(UOe," \u2014 "),jW=n(UOe,"A",{href:!0});var Uqt=s(jW);tJo=r(Uqt,"XLMWithLMHeadModel"),Uqt.forEach(t),aJo=r(UOe," (XLM model)"),UOe.forEach(t),nJo=i(U),Ev=n(U,"LI",{});var HOe=s(Ev);qve=n(HOe,"STRONG",{});var Hqt=s(qve);sJo=r(Hqt,"xlm-prophetnet"),Hqt.forEach(t),lJo=r(HOe," \u2014 "),DW=n(HOe,"A",{href:!0});var Jqt=s(DW);iJo=r(Jqt,"XLMProphetNetForCausalLM"),Jqt.forEach(t),dJo=r(HOe," (XLM-ProphetNet model)"),HOe.forEach(t),cJo=i(U),Cv=n(U,"LI",{});var JOe=s(Cv);jve=n(JOe,"STRONG",{});var Yqt=s(jve);mJo=r(Yqt,"xlm-roberta"),Yqt.forEach(t),fJo=r(JOe," \u2014 "),GW=n(JOe,"A",{href:!0});var Zqt=s(GW);gJo=r(Zqt,"XLMRobertaForCausalLM"),Zqt.forEach(t),hJo=r(JOe," (XLM-RoBERTa model)"),JOe.forEach(t),uJo=i(U),wv=n(U,"LI",{});var YOe=s(wv);Dve=n(YOe,"STRONG",{});var Kqt=s(Dve);pJo=r(Kqt,"xlm-roberta-xl"),Kqt.forEach(t),_Jo=r(YOe," \u2014 "),OW=n(YOe,"A",{href:!0});var ejt=s(OW);bJo=r(ejt,"XLMRobertaXLForCausalLM"),ejt.forEach(t),vJo=r(YOe," (XLM-RoBERTa-XL model)"),YOe.forEach(t),FJo=i(U),Av=n(U,"LI",{});var ZOe=s(Av);Gve=n(ZOe,"STRONG",{});var ojt=s(Gve);TJo=r(ojt,"xlnet"),ojt.forEach(t),MJo=r(ZOe," \u2014 "),VW=n(ZOe,"A",{href:!0});var rjt=s(VW);EJo=r(rjt,"XLNetLMHeadModel"),rjt.forEach(t),CJo=r(ZOe," (XLNet model)"),ZOe.forEach(t),U.forEach(t),wJo=i(wa),Lv=n(wa,"P",{});var KOe=s(Lv);AJo=r(KOe,"The model is set in evaluation mode by default using "),Ove=n(KOe,"CODE",{});var tjt=s(Ove);LJo=r(tjt,"model.eval()"),tjt.forEach(t),yJo=r(KOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vve=n(KOe,"CODE",{});var ajt=s(Vve);xJo=r(ajt,"model.train()"),ajt.forEach(t),KOe.forEach(t),$Jo=i(wa),T(yv.$$.fragment,wa),wa.forEach(t),Rl.forEach(t),Voo=i(m),Sd=n(m,"H2",{class:!0});var nao=s(Sd);xv=n(nao,"A",{id:!0,class:!0,href:!0});var njt=s(xv);Xve=n(njt,"SPAN",{});var sjt=s(Xve);T(_$.$$.fragment,sjt),sjt.forEach(t),njt.forEach(t),kJo=i(nao),zve=n(nao,"SPAN",{});var ljt=s(zve);SJo=r(ljt,"AutoModelForMaskedLM"),ljt.forEach(t),nao.forEach(t),Xoo=i(m),qo=n(m,"DIV",{class:!0});var Pl=s(qo);T(b$.$$.fragment,Pl),RJo=i(Pl),Rd=n(Pl,"P",{});var ode=s(Rd);PJo=r(ode,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),XW=n(ode,"A",{href:!0});var ijt=s(XW);BJo=r(ijt,"from_pretrained()"),ijt.forEach(t),IJo=r(ode," class method or the "),zW=n(ode,"A",{href:!0});var djt=s(zW);NJo=r(djt,"from_config()"),djt.forEach(t),qJo=r(ode,` class
method.`),ode.forEach(t),jJo=i(Pl),v$=n(Pl,"P",{});var sao=s(v$);DJo=r(sao,"This class cannot be instantiated directly using "),Qve=n(sao,"CODE",{});var cjt=s(Qve);GJo=r(cjt,"__init__()"),cjt.forEach(t),OJo=r(sao," (throws an error)."),sao.forEach(t),VJo=i(Pl),Mt=n(Pl,"DIV",{class:!0});var yy=s(Mt);T(F$.$$.fragment,yy),XJo=i(yy),Wve=n(yy,"P",{});var mjt=s(Wve);zJo=r(mjt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mjt.forEach(t),QJo=i(yy),Pd=n(yy,"P",{});var rde=s(Pd);WJo=r(rde,`Note:
Loading a model from its configuration file does `),Uve=n(rde,"STRONG",{});var fjt=s(Uve);UJo=r(fjt,"not"),fjt.forEach(t),HJo=r(rde,` load the model weights. It only affects the
model\u2019s configuration. Use `),QW=n(rde,"A",{href:!0});var gjt=s(QW);JJo=r(gjt,"from_pretrained()"),gjt.forEach(t),YJo=r(rde," to load the model weights."),rde.forEach(t),ZJo=i(yy),T($v.$$.fragment,yy),yy.forEach(t),KJo=i(Pl),ro=n(Pl,"DIV",{class:!0});var Aa=s(ro);T(T$.$$.fragment,Aa),eYo=i(Aa),Hve=n(Aa,"P",{});var hjt=s(Hve);oYo=r(hjt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hjt.forEach(t),rYo=i(Aa),tn=n(Aa,"P",{});var xy=s(tn);tYo=r(xy,"The model class to instantiate is selected based on the "),Jve=n(xy,"CODE",{});var ujt=s(Jve);aYo=r(ujt,"model_type"),ujt.forEach(t),nYo=r(xy,` property of the config object (either
passed as an argument or loaded from `),Yve=n(xy,"CODE",{});var pjt=s(Yve);sYo=r(pjt,"pretrained_model_name_or_path"),pjt.forEach(t),lYo=r(xy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zve=n(xy,"CODE",{});var _jt=s(Zve);iYo=r(_jt,"pretrained_model_name_or_path"),_jt.forEach(t),dYo=r(xy,":"),xy.forEach(t),cYo=i(Aa),J=n(Aa,"UL",{});var Z=s(J);kv=n(Z,"LI",{});var eVe=s(kv);Kve=n(eVe,"STRONG",{});var bjt=s(Kve);mYo=r(bjt,"albert"),bjt.forEach(t),fYo=r(eVe," \u2014 "),WW=n(eVe,"A",{href:!0});var vjt=s(WW);gYo=r(vjt,"AlbertForMaskedLM"),vjt.forEach(t),hYo=r(eVe," (ALBERT model)"),eVe.forEach(t),uYo=i(Z),Sv=n(Z,"LI",{});var oVe=s(Sv);eFe=n(oVe,"STRONG",{});var Fjt=s(eFe);pYo=r(Fjt,"bart"),Fjt.forEach(t),_Yo=r(oVe," \u2014 "),UW=n(oVe,"A",{href:!0});var Tjt=s(UW);bYo=r(Tjt,"BartForConditionalGeneration"),Tjt.forEach(t),vYo=r(oVe," (BART model)"),oVe.forEach(t),FYo=i(Z),Rv=n(Z,"LI",{});var rVe=s(Rv);oFe=n(rVe,"STRONG",{});var Mjt=s(oFe);TYo=r(Mjt,"bert"),Mjt.forEach(t),MYo=r(rVe," \u2014 "),HW=n(rVe,"A",{href:!0});var Ejt=s(HW);EYo=r(Ejt,"BertForMaskedLM"),Ejt.forEach(t),CYo=r(rVe," (BERT model)"),rVe.forEach(t),wYo=i(Z),Pv=n(Z,"LI",{});var tVe=s(Pv);rFe=n(tVe,"STRONG",{});var Cjt=s(rFe);AYo=r(Cjt,"big_bird"),Cjt.forEach(t),LYo=r(tVe," \u2014 "),JW=n(tVe,"A",{href:!0});var wjt=s(JW);yYo=r(wjt,"BigBirdForMaskedLM"),wjt.forEach(t),xYo=r(tVe," (BigBird model)"),tVe.forEach(t),$Yo=i(Z),Bv=n(Z,"LI",{});var aVe=s(Bv);tFe=n(aVe,"STRONG",{});var Ajt=s(tFe);kYo=r(Ajt,"camembert"),Ajt.forEach(t),SYo=r(aVe," \u2014 "),YW=n(aVe,"A",{href:!0});var Ljt=s(YW);RYo=r(Ljt,"CamembertForMaskedLM"),Ljt.forEach(t),PYo=r(aVe," (CamemBERT model)"),aVe.forEach(t),BYo=i(Z),Iv=n(Z,"LI",{});var nVe=s(Iv);aFe=n(nVe,"STRONG",{});var yjt=s(aFe);IYo=r(yjt,"convbert"),yjt.forEach(t),NYo=r(nVe," \u2014 "),ZW=n(nVe,"A",{href:!0});var xjt=s(ZW);qYo=r(xjt,"ConvBertForMaskedLM"),xjt.forEach(t),jYo=r(nVe," (ConvBERT model)"),nVe.forEach(t),DYo=i(Z),Nv=n(Z,"LI",{});var sVe=s(Nv);nFe=n(sVe,"STRONG",{});var $jt=s(nFe);GYo=r($jt,"data2vec-text"),$jt.forEach(t),OYo=r(sVe," \u2014 "),KW=n(sVe,"A",{href:!0});var kjt=s(KW);VYo=r(kjt,"Data2VecTextForMaskedLM"),kjt.forEach(t),XYo=r(sVe," (Data2VecText model)"),sVe.forEach(t),zYo=i(Z),qv=n(Z,"LI",{});var lVe=s(qv);sFe=n(lVe,"STRONG",{});var Sjt=s(sFe);QYo=r(Sjt,"deberta"),Sjt.forEach(t),WYo=r(lVe," \u2014 "),eU=n(lVe,"A",{href:!0});var Rjt=s(eU);UYo=r(Rjt,"DebertaForMaskedLM"),Rjt.forEach(t),HYo=r(lVe," (DeBERTa model)"),lVe.forEach(t),JYo=i(Z),jv=n(Z,"LI",{});var iVe=s(jv);lFe=n(iVe,"STRONG",{});var Pjt=s(lFe);YYo=r(Pjt,"deberta-v2"),Pjt.forEach(t),ZYo=r(iVe," \u2014 "),oU=n(iVe,"A",{href:!0});var Bjt=s(oU);KYo=r(Bjt,"DebertaV2ForMaskedLM"),Bjt.forEach(t),eZo=r(iVe," (DeBERTa-v2 model)"),iVe.forEach(t),oZo=i(Z),Dv=n(Z,"LI",{});var dVe=s(Dv);iFe=n(dVe,"STRONG",{});var Ijt=s(iFe);rZo=r(Ijt,"distilbert"),Ijt.forEach(t),tZo=r(dVe," \u2014 "),rU=n(dVe,"A",{href:!0});var Njt=s(rU);aZo=r(Njt,"DistilBertForMaskedLM"),Njt.forEach(t),nZo=r(dVe," (DistilBERT model)"),dVe.forEach(t),sZo=i(Z),Gv=n(Z,"LI",{});var cVe=s(Gv);dFe=n(cVe,"STRONG",{});var qjt=s(dFe);lZo=r(qjt,"electra"),qjt.forEach(t),iZo=r(cVe," \u2014 "),tU=n(cVe,"A",{href:!0});var jjt=s(tU);dZo=r(jjt,"ElectraForMaskedLM"),jjt.forEach(t),cZo=r(cVe," (ELECTRA model)"),cVe.forEach(t),mZo=i(Z),Ov=n(Z,"LI",{});var mVe=s(Ov);cFe=n(mVe,"STRONG",{});var Djt=s(cFe);fZo=r(Djt,"ernie"),Djt.forEach(t),gZo=r(mVe," \u2014 "),aU=n(mVe,"A",{href:!0});var Gjt=s(aU);hZo=r(Gjt,"ErnieForMaskedLM"),Gjt.forEach(t),uZo=r(mVe," (ERNIE model)"),mVe.forEach(t),pZo=i(Z),Vv=n(Z,"LI",{});var fVe=s(Vv);mFe=n(fVe,"STRONG",{});var Ojt=s(mFe);_Zo=r(Ojt,"flaubert"),Ojt.forEach(t),bZo=r(fVe," \u2014 "),nU=n(fVe,"A",{href:!0});var Vjt=s(nU);vZo=r(Vjt,"FlaubertWithLMHeadModel"),Vjt.forEach(t),FZo=r(fVe," (FlauBERT model)"),fVe.forEach(t),TZo=i(Z),Xv=n(Z,"LI",{});var gVe=s(Xv);fFe=n(gVe,"STRONG",{});var Xjt=s(fFe);MZo=r(Xjt,"fnet"),Xjt.forEach(t),EZo=r(gVe," \u2014 "),sU=n(gVe,"A",{href:!0});var zjt=s(sU);CZo=r(zjt,"FNetForMaskedLM"),zjt.forEach(t),wZo=r(gVe," (FNet model)"),gVe.forEach(t),AZo=i(Z),zv=n(Z,"LI",{});var hVe=s(zv);gFe=n(hVe,"STRONG",{});var Qjt=s(gFe);LZo=r(Qjt,"funnel"),Qjt.forEach(t),yZo=r(hVe," \u2014 "),lU=n(hVe,"A",{href:!0});var Wjt=s(lU);xZo=r(Wjt,"FunnelForMaskedLM"),Wjt.forEach(t),$Zo=r(hVe," (Funnel Transformer model)"),hVe.forEach(t),kZo=i(Z),Qv=n(Z,"LI",{});var uVe=s(Qv);hFe=n(uVe,"STRONG",{});var Ujt=s(hFe);SZo=r(Ujt,"ibert"),Ujt.forEach(t),RZo=r(uVe," \u2014 "),iU=n(uVe,"A",{href:!0});var Hjt=s(iU);PZo=r(Hjt,"IBertForMaskedLM"),Hjt.forEach(t),BZo=r(uVe," (I-BERT model)"),uVe.forEach(t),IZo=i(Z),Wv=n(Z,"LI",{});var pVe=s(Wv);uFe=n(pVe,"STRONG",{});var Jjt=s(uFe);NZo=r(Jjt,"layoutlm"),Jjt.forEach(t),qZo=r(pVe," \u2014 "),dU=n(pVe,"A",{href:!0});var Yjt=s(dU);jZo=r(Yjt,"LayoutLMForMaskedLM"),Yjt.forEach(t),DZo=r(pVe," (LayoutLM model)"),pVe.forEach(t),GZo=i(Z),Uv=n(Z,"LI",{});var _Ve=s(Uv);pFe=n(_Ve,"STRONG",{});var Zjt=s(pFe);OZo=r(Zjt,"longformer"),Zjt.forEach(t),VZo=r(_Ve," \u2014 "),cU=n(_Ve,"A",{href:!0});var Kjt=s(cU);XZo=r(Kjt,"LongformerForMaskedLM"),Kjt.forEach(t),zZo=r(_Ve," (Longformer model)"),_Ve.forEach(t),QZo=i(Z),Hv=n(Z,"LI",{});var bVe=s(Hv);_Fe=n(bVe,"STRONG",{});var eDt=s(_Fe);WZo=r(eDt,"luke"),eDt.forEach(t),UZo=r(bVe," \u2014 "),mU=n(bVe,"A",{href:!0});var oDt=s(mU);HZo=r(oDt,"LukeForMaskedLM"),oDt.forEach(t),JZo=r(bVe," (LUKE model)"),bVe.forEach(t),YZo=i(Z),Jv=n(Z,"LI",{});var vVe=s(Jv);bFe=n(vVe,"STRONG",{});var rDt=s(bFe);ZZo=r(rDt,"mbart"),rDt.forEach(t),KZo=r(vVe," \u2014 "),fU=n(vVe,"A",{href:!0});var tDt=s(fU);eKo=r(tDt,"MBartForConditionalGeneration"),tDt.forEach(t),oKo=r(vVe," (mBART model)"),vVe.forEach(t),rKo=i(Z),Yv=n(Z,"LI",{});var FVe=s(Yv);vFe=n(FVe,"STRONG",{});var aDt=s(vFe);tKo=r(aDt,"megatron-bert"),aDt.forEach(t),aKo=r(FVe," \u2014 "),gU=n(FVe,"A",{href:!0});var nDt=s(gU);nKo=r(nDt,"MegatronBertForMaskedLM"),nDt.forEach(t),sKo=r(FVe," (Megatron-BERT model)"),FVe.forEach(t),lKo=i(Z),Zv=n(Z,"LI",{});var TVe=s(Zv);FFe=n(TVe,"STRONG",{});var sDt=s(FFe);iKo=r(sDt,"mobilebert"),sDt.forEach(t),dKo=r(TVe," \u2014 "),hU=n(TVe,"A",{href:!0});var lDt=s(hU);cKo=r(lDt,"MobileBertForMaskedLM"),lDt.forEach(t),mKo=r(TVe," (MobileBERT model)"),TVe.forEach(t),fKo=i(Z),Kv=n(Z,"LI",{});var MVe=s(Kv);TFe=n(MVe,"STRONG",{});var iDt=s(TFe);gKo=r(iDt,"mpnet"),iDt.forEach(t),hKo=r(MVe," \u2014 "),uU=n(MVe,"A",{href:!0});var dDt=s(uU);uKo=r(dDt,"MPNetForMaskedLM"),dDt.forEach(t),pKo=r(MVe," (MPNet model)"),MVe.forEach(t),_Ko=i(Z),eF=n(Z,"LI",{});var EVe=s(eF);MFe=n(EVe,"STRONG",{});var cDt=s(MFe);bKo=r(cDt,"mvp"),cDt.forEach(t),vKo=r(EVe," \u2014 "),pU=n(EVe,"A",{href:!0});var mDt=s(pU);FKo=r(mDt,"MvpForConditionalGeneration"),mDt.forEach(t),TKo=r(EVe," (MVP model)"),EVe.forEach(t),MKo=i(Z),oF=n(Z,"LI",{});var CVe=s(oF);EFe=n(CVe,"STRONG",{});var fDt=s(EFe);EKo=r(fDt,"nezha"),fDt.forEach(t),CKo=r(CVe," \u2014 "),_U=n(CVe,"A",{href:!0});var gDt=s(_U);wKo=r(gDt,"NezhaForMaskedLM"),gDt.forEach(t),AKo=r(CVe," (Nezha model)"),CVe.forEach(t),LKo=i(Z),rF=n(Z,"LI",{});var wVe=s(rF);CFe=n(wVe,"STRONG",{});var hDt=s(CFe);yKo=r(hDt,"nystromformer"),hDt.forEach(t),xKo=r(wVe," \u2014 "),bU=n(wVe,"A",{href:!0});var uDt=s(bU);$Ko=r(uDt,"NystromformerForMaskedLM"),uDt.forEach(t),kKo=r(wVe," (Nystr\xF6mformer model)"),wVe.forEach(t),SKo=i(Z),tF=n(Z,"LI",{});var AVe=s(tF);wFe=n(AVe,"STRONG",{});var pDt=s(wFe);RKo=r(pDt,"perceiver"),pDt.forEach(t),PKo=r(AVe," \u2014 "),vU=n(AVe,"A",{href:!0});var _Dt=s(vU);BKo=r(_Dt,"PerceiverForMaskedLM"),_Dt.forEach(t),IKo=r(AVe," (Perceiver model)"),AVe.forEach(t),NKo=i(Z),aF=n(Z,"LI",{});var LVe=s(aF);AFe=n(LVe,"STRONG",{});var bDt=s(AFe);qKo=r(bDt,"qdqbert"),bDt.forEach(t),jKo=r(LVe," \u2014 "),FU=n(LVe,"A",{href:!0});var vDt=s(FU);DKo=r(vDt,"QDQBertForMaskedLM"),vDt.forEach(t),GKo=r(LVe," (QDQBert model)"),LVe.forEach(t),OKo=i(Z),nF=n(Z,"LI",{});var yVe=s(nF);LFe=n(yVe,"STRONG",{});var FDt=s(LFe);VKo=r(FDt,"reformer"),FDt.forEach(t),XKo=r(yVe," \u2014 "),TU=n(yVe,"A",{href:!0});var TDt=s(TU);zKo=r(TDt,"ReformerForMaskedLM"),TDt.forEach(t),QKo=r(yVe," (Reformer model)"),yVe.forEach(t),WKo=i(Z),sF=n(Z,"LI",{});var xVe=s(sF);yFe=n(xVe,"STRONG",{});var MDt=s(yFe);UKo=r(MDt,"rembert"),MDt.forEach(t),HKo=r(xVe," \u2014 "),MU=n(xVe,"A",{href:!0});var EDt=s(MU);JKo=r(EDt,"RemBertForMaskedLM"),EDt.forEach(t),YKo=r(xVe," (RemBERT model)"),xVe.forEach(t),ZKo=i(Z),lF=n(Z,"LI",{});var $Ve=s(lF);xFe=n($Ve,"STRONG",{});var CDt=s(xFe);KKo=r(CDt,"roberta"),CDt.forEach(t),eer=r($Ve," \u2014 "),EU=n($Ve,"A",{href:!0});var wDt=s(EU);oer=r(wDt,"RobertaForMaskedLM"),wDt.forEach(t),rer=r($Ve," (RoBERTa model)"),$Ve.forEach(t),ter=i(Z),iF=n(Z,"LI",{});var kVe=s(iF);$Fe=n(kVe,"STRONG",{});var ADt=s($Fe);aer=r(ADt,"roformer"),ADt.forEach(t),ner=r(kVe," \u2014 "),CU=n(kVe,"A",{href:!0});var LDt=s(CU);ser=r(LDt,"RoFormerForMaskedLM"),LDt.forEach(t),ler=r(kVe," (RoFormer model)"),kVe.forEach(t),ier=i(Z),dF=n(Z,"LI",{});var SVe=s(dF);kFe=n(SVe,"STRONG",{});var yDt=s(kFe);der=r(yDt,"squeezebert"),yDt.forEach(t),cer=r(SVe," \u2014 "),wU=n(SVe,"A",{href:!0});var xDt=s(wU);mer=r(xDt,"SqueezeBertForMaskedLM"),xDt.forEach(t),fer=r(SVe," (SqueezeBERT model)"),SVe.forEach(t),ger=i(Z),cF=n(Z,"LI",{});var RVe=s(cF);SFe=n(RVe,"STRONG",{});var $Dt=s(SFe);her=r($Dt,"tapas"),$Dt.forEach(t),uer=r(RVe," \u2014 "),AU=n(RVe,"A",{href:!0});var kDt=s(AU);per=r(kDt,"TapasForMaskedLM"),kDt.forEach(t),_er=r(RVe," (TAPAS model)"),RVe.forEach(t),ber=i(Z),mF=n(Z,"LI",{});var PVe=s(mF);RFe=n(PVe,"STRONG",{});var SDt=s(RFe);ver=r(SDt,"wav2vec2"),SDt.forEach(t),Fer=r(PVe," \u2014 "),PFe=n(PVe,"CODE",{});var RDt=s(PFe);Ter=r(RDt,"Wav2Vec2ForMaskedLM"),RDt.forEach(t),Mer=r(PVe," (Wav2Vec2 model)"),PVe.forEach(t),Eer=i(Z),fF=n(Z,"LI",{});var BVe=s(fF);BFe=n(BVe,"STRONG",{});var PDt=s(BFe);Cer=r(PDt,"xlm"),PDt.forEach(t),wer=r(BVe," \u2014 "),LU=n(BVe,"A",{href:!0});var BDt=s(LU);Aer=r(BDt,"XLMWithLMHeadModel"),BDt.forEach(t),Ler=r(BVe," (XLM model)"),BVe.forEach(t),yer=i(Z),gF=n(Z,"LI",{});var IVe=s(gF);IFe=n(IVe,"STRONG",{});var IDt=s(IFe);xer=r(IDt,"xlm-roberta"),IDt.forEach(t),$er=r(IVe," \u2014 "),yU=n(IVe,"A",{href:!0});var NDt=s(yU);ker=r(NDt,"XLMRobertaForMaskedLM"),NDt.forEach(t),Ser=r(IVe," (XLM-RoBERTa model)"),IVe.forEach(t),Rer=i(Z),hF=n(Z,"LI",{});var NVe=s(hF);NFe=n(NVe,"STRONG",{});var qDt=s(NFe);Per=r(qDt,"xlm-roberta-xl"),qDt.forEach(t),Ber=r(NVe," \u2014 "),xU=n(NVe,"A",{href:!0});var jDt=s(xU);Ier=r(jDt,"XLMRobertaXLForMaskedLM"),jDt.forEach(t),Ner=r(NVe," (XLM-RoBERTa-XL model)"),NVe.forEach(t),qer=i(Z),uF=n(Z,"LI",{});var qVe=s(uF);qFe=n(qVe,"STRONG",{});var DDt=s(qFe);jer=r(DDt,"yoso"),DDt.forEach(t),Der=r(qVe," \u2014 "),$U=n(qVe,"A",{href:!0});var GDt=s($U);Ger=r(GDt,"YosoForMaskedLM"),GDt.forEach(t),Oer=r(qVe," (YOSO model)"),qVe.forEach(t),Z.forEach(t),Ver=i(Aa),pF=n(Aa,"P",{});var jVe=s(pF);Xer=r(jVe,"The model is set in evaluation mode by default using "),jFe=n(jVe,"CODE",{});var ODt=s(jFe);zer=r(ODt,"model.eval()"),ODt.forEach(t),Qer=r(jVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DFe=n(jVe,"CODE",{});var VDt=s(DFe);Wer=r(VDt,"model.train()"),VDt.forEach(t),jVe.forEach(t),Uer=i(Aa),T(_F.$$.fragment,Aa),Aa.forEach(t),Pl.forEach(t),zoo=i(m),Bd=n(m,"H2",{class:!0});var lao=s(Bd);bF=n(lao,"A",{id:!0,class:!0,href:!0});var XDt=s(bF);GFe=n(XDt,"SPAN",{});var zDt=s(GFe);T(M$.$$.fragment,zDt),zDt.forEach(t),XDt.forEach(t),Her=i(lao),OFe=n(lao,"SPAN",{});var QDt=s(OFe);Jer=r(QDt,"AutoModelForSeq2SeqLM"),QDt.forEach(t),lao.forEach(t),Qoo=i(m),jo=n(m,"DIV",{class:!0});var Bl=s(jo);T(E$.$$.fragment,Bl),Yer=i(Bl),Id=n(Bl,"P",{});var tde=s(Id);Zer=r(tde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kU=n(tde,"A",{href:!0});var WDt=s(kU);Ker=r(WDt,"from_pretrained()"),WDt.forEach(t),eor=r(tde," class method or the "),SU=n(tde,"A",{href:!0});var UDt=s(SU);oor=r(UDt,"from_config()"),UDt.forEach(t),ror=r(tde,` class
method.`),tde.forEach(t),tor=i(Bl),C$=n(Bl,"P",{});var iao=s(C$);aor=r(iao,"This class cannot be instantiated directly using "),VFe=n(iao,"CODE",{});var HDt=s(VFe);nor=r(HDt,"__init__()"),HDt.forEach(t),sor=r(iao," (throws an error)."),iao.forEach(t),lor=i(Bl),Et=n(Bl,"DIV",{class:!0});var $y=s(Et);T(w$.$$.fragment,$y),ior=i($y),XFe=n($y,"P",{});var JDt=s(XFe);dor=r(JDt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),JDt.forEach(t),cor=i($y),Nd=n($y,"P",{});var ade=s(Nd);mor=r(ade,`Note:
Loading a model from its configuration file does `),zFe=n(ade,"STRONG",{});var YDt=s(zFe);gor=r(YDt,"not"),YDt.forEach(t),hor=r(ade,` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=n(ade,"A",{href:!0});var ZDt=s(RU);uor=r(ZDt,"from_pretrained()"),ZDt.forEach(t),por=r(ade," to load the model weights."),ade.forEach(t),_or=i($y),T(vF.$$.fragment,$y),$y.forEach(t),bor=i(Bl),to=n(Bl,"DIV",{class:!0});var La=s(to);T(A$.$$.fragment,La),vor=i(La),QFe=n(La,"P",{});var KDt=s(QFe);For=r(KDt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),KDt.forEach(t),Tor=i(La),an=n(La,"P",{});var ky=s(an);Mor=r(ky,"The model class to instantiate is selected based on the "),WFe=n(ky,"CODE",{});var eGt=s(WFe);Eor=r(eGt,"model_type"),eGt.forEach(t),Cor=r(ky,` property of the config object (either
passed as an argument or loaded from `),UFe=n(ky,"CODE",{});var oGt=s(UFe);wor=r(oGt,"pretrained_model_name_or_path"),oGt.forEach(t),Aor=r(ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HFe=n(ky,"CODE",{});var rGt=s(HFe);Lor=r(rGt,"pretrained_model_name_or_path"),rGt.forEach(t),yor=r(ky,":"),ky.forEach(t),xor=i(La),fe=n(La,"UL",{});var pe=s(fe);FF=n(pe,"LI",{});var DVe=s(FF);JFe=n(DVe,"STRONG",{});var tGt=s(JFe);$or=r(tGt,"bart"),tGt.forEach(t),kor=r(DVe," \u2014 "),PU=n(DVe,"A",{href:!0});var aGt=s(PU);Sor=r(aGt,"BartForConditionalGeneration"),aGt.forEach(t),Ror=r(DVe," (BART model)"),DVe.forEach(t),Por=i(pe),TF=n(pe,"LI",{});var GVe=s(TF);YFe=n(GVe,"STRONG",{});var nGt=s(YFe);Bor=r(nGt,"bigbird_pegasus"),nGt.forEach(t),Ior=r(GVe," \u2014 "),BU=n(GVe,"A",{href:!0});var sGt=s(BU);Nor=r(sGt,"BigBirdPegasusForConditionalGeneration"),sGt.forEach(t),qor=r(GVe," (BigBird-Pegasus model)"),GVe.forEach(t),jor=i(pe),MF=n(pe,"LI",{});var OVe=s(MF);ZFe=n(OVe,"STRONG",{});var lGt=s(ZFe);Dor=r(lGt,"blenderbot"),lGt.forEach(t),Gor=r(OVe," \u2014 "),IU=n(OVe,"A",{href:!0});var iGt=s(IU);Oor=r(iGt,"BlenderbotForConditionalGeneration"),iGt.forEach(t),Vor=r(OVe," (Blenderbot model)"),OVe.forEach(t),Xor=i(pe),EF=n(pe,"LI",{});var VVe=s(EF);KFe=n(VVe,"STRONG",{});var dGt=s(KFe);zor=r(dGt,"blenderbot-small"),dGt.forEach(t),Qor=r(VVe," \u2014 "),NU=n(VVe,"A",{href:!0});var cGt=s(NU);Wor=r(cGt,"BlenderbotSmallForConditionalGeneration"),cGt.forEach(t),Uor=r(VVe," (BlenderbotSmall model)"),VVe.forEach(t),Hor=i(pe),CF=n(pe,"LI",{});var XVe=s(CF);eTe=n(XVe,"STRONG",{});var mGt=s(eTe);Jor=r(mGt,"encoder-decoder"),mGt.forEach(t),Yor=r(XVe," \u2014 "),qU=n(XVe,"A",{href:!0});var fGt=s(qU);Zor=r(fGt,"EncoderDecoderModel"),fGt.forEach(t),Kor=r(XVe," (Encoder decoder model)"),XVe.forEach(t),err=i(pe),wF=n(pe,"LI",{});var zVe=s(wF);oTe=n(zVe,"STRONG",{});var gGt=s(oTe);orr=r(gGt,"fsmt"),gGt.forEach(t),rrr=r(zVe," \u2014 "),jU=n(zVe,"A",{href:!0});var hGt=s(jU);trr=r(hGt,"FSMTForConditionalGeneration"),hGt.forEach(t),arr=r(zVe," (FairSeq Machine-Translation model)"),zVe.forEach(t),nrr=i(pe),AF=n(pe,"LI",{});var QVe=s(AF);rTe=n(QVe,"STRONG",{});var uGt=s(rTe);srr=r(uGt,"led"),uGt.forEach(t),lrr=r(QVe," \u2014 "),DU=n(QVe,"A",{href:!0});var pGt=s(DU);irr=r(pGt,"LEDForConditionalGeneration"),pGt.forEach(t),drr=r(QVe," (LED model)"),QVe.forEach(t),crr=i(pe),LF=n(pe,"LI",{});var WVe=s(LF);tTe=n(WVe,"STRONG",{});var _Gt=s(tTe);mrr=r(_Gt,"longt5"),_Gt.forEach(t),frr=r(WVe," \u2014 "),GU=n(WVe,"A",{href:!0});var bGt=s(GU);grr=r(bGt,"LongT5ForConditionalGeneration"),bGt.forEach(t),hrr=r(WVe," (LongT5 model)"),WVe.forEach(t),urr=i(pe),yF=n(pe,"LI",{});var UVe=s(yF);aTe=n(UVe,"STRONG",{});var vGt=s(aTe);prr=r(vGt,"m2m_100"),vGt.forEach(t),_rr=r(UVe," \u2014 "),OU=n(UVe,"A",{href:!0});var FGt=s(OU);brr=r(FGt,"M2M100ForConditionalGeneration"),FGt.forEach(t),vrr=r(UVe," (M2M100 model)"),UVe.forEach(t),Frr=i(pe),xF=n(pe,"LI",{});var HVe=s(xF);nTe=n(HVe,"STRONG",{});var TGt=s(nTe);Trr=r(TGt,"marian"),TGt.forEach(t),Mrr=r(HVe," \u2014 "),VU=n(HVe,"A",{href:!0});var MGt=s(VU);Err=r(MGt,"MarianMTModel"),MGt.forEach(t),Crr=r(HVe," (Marian model)"),HVe.forEach(t),wrr=i(pe),$F=n(pe,"LI",{});var JVe=s($F);sTe=n(JVe,"STRONG",{});var EGt=s(sTe);Arr=r(EGt,"mbart"),EGt.forEach(t),Lrr=r(JVe," \u2014 "),XU=n(JVe,"A",{href:!0});var CGt=s(XU);yrr=r(CGt,"MBartForConditionalGeneration"),CGt.forEach(t),xrr=r(JVe," (mBART model)"),JVe.forEach(t),$rr=i(pe),kF=n(pe,"LI",{});var YVe=s(kF);lTe=n(YVe,"STRONG",{});var wGt=s(lTe);krr=r(wGt,"mt5"),wGt.forEach(t),Srr=r(YVe," \u2014 "),zU=n(YVe,"A",{href:!0});var AGt=s(zU);Rrr=r(AGt,"MT5ForConditionalGeneration"),AGt.forEach(t),Prr=r(YVe," (MT5 model)"),YVe.forEach(t),Brr=i(pe),SF=n(pe,"LI",{});var ZVe=s(SF);iTe=n(ZVe,"STRONG",{});var LGt=s(iTe);Irr=r(LGt,"mvp"),LGt.forEach(t),Nrr=r(ZVe," \u2014 "),QU=n(ZVe,"A",{href:!0});var yGt=s(QU);qrr=r(yGt,"MvpForConditionalGeneration"),yGt.forEach(t),jrr=r(ZVe," (MVP model)"),ZVe.forEach(t),Drr=i(pe),RF=n(pe,"LI",{});var KVe=s(RF);dTe=n(KVe,"STRONG",{});var xGt=s(dTe);Grr=r(xGt,"nllb"),xGt.forEach(t),Orr=r(KVe," \u2014 "),WU=n(KVe,"A",{href:!0});var $Gt=s(WU);Vrr=r($Gt,"M2M100ForConditionalGeneration"),$Gt.forEach(t),Xrr=r(KVe," (NLLB model)"),KVe.forEach(t),zrr=i(pe),PF=n(pe,"LI",{});var eXe=s(PF);cTe=n(eXe,"STRONG",{});var kGt=s(cTe);Qrr=r(kGt,"pegasus"),kGt.forEach(t),Wrr=r(eXe," \u2014 "),UU=n(eXe,"A",{href:!0});var SGt=s(UU);Urr=r(SGt,"PegasusForConditionalGeneration"),SGt.forEach(t),Hrr=r(eXe," (Pegasus model)"),eXe.forEach(t),Jrr=i(pe),BF=n(pe,"LI",{});var oXe=s(BF);mTe=n(oXe,"STRONG",{});var RGt=s(mTe);Yrr=r(RGt,"pegasus_x"),RGt.forEach(t),Zrr=r(oXe," \u2014 "),HU=n(oXe,"A",{href:!0});var PGt=s(HU);Krr=r(PGt,"PegasusXForConditionalGeneration"),PGt.forEach(t),etr=r(oXe," (PEGASUS-X model)"),oXe.forEach(t),otr=i(pe),IF=n(pe,"LI",{});var rXe=s(IF);fTe=n(rXe,"STRONG",{});var BGt=s(fTe);rtr=r(BGt,"plbart"),BGt.forEach(t),ttr=r(rXe," \u2014 "),JU=n(rXe,"A",{href:!0});var IGt=s(JU);atr=r(IGt,"PLBartForConditionalGeneration"),IGt.forEach(t),ntr=r(rXe," (PLBart model)"),rXe.forEach(t),str=i(pe),NF=n(pe,"LI",{});var tXe=s(NF);gTe=n(tXe,"STRONG",{});var NGt=s(gTe);ltr=r(NGt,"prophetnet"),NGt.forEach(t),itr=r(tXe," \u2014 "),YU=n(tXe,"A",{href:!0});var qGt=s(YU);dtr=r(qGt,"ProphetNetForConditionalGeneration"),qGt.forEach(t),ctr=r(tXe," (ProphetNet model)"),tXe.forEach(t),mtr=i(pe),qF=n(pe,"LI",{});var aXe=s(qF);hTe=n(aXe,"STRONG",{});var jGt=s(hTe);ftr=r(jGt,"t5"),jGt.forEach(t),gtr=r(aXe," \u2014 "),ZU=n(aXe,"A",{href:!0});var DGt=s(ZU);htr=r(DGt,"T5ForConditionalGeneration"),DGt.forEach(t),utr=r(aXe," (T5 model)"),aXe.forEach(t),ptr=i(pe),jF=n(pe,"LI",{});var nXe=s(jF);uTe=n(nXe,"STRONG",{});var GGt=s(uTe);_tr=r(GGt,"xlm-prophetnet"),GGt.forEach(t),btr=r(nXe," \u2014 "),KU=n(nXe,"A",{href:!0});var OGt=s(KU);vtr=r(OGt,"XLMProphetNetForConditionalGeneration"),OGt.forEach(t),Ftr=r(nXe," (XLM-ProphetNet model)"),nXe.forEach(t),pe.forEach(t),Ttr=i(La),DF=n(La,"P",{});var sXe=s(DF);Mtr=r(sXe,"The model is set in evaluation mode by default using "),pTe=n(sXe,"CODE",{});var VGt=s(pTe);Etr=r(VGt,"model.eval()"),VGt.forEach(t),Ctr=r(sXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Te=n(sXe,"CODE",{});var XGt=s(_Te);wtr=r(XGt,"model.train()"),XGt.forEach(t),sXe.forEach(t),Atr=i(La),T(GF.$$.fragment,La),La.forEach(t),Bl.forEach(t),Woo=i(m),qd=n(m,"H2",{class:!0});var dao=s(qd);OF=n(dao,"A",{id:!0,class:!0,href:!0});var zGt=s(OF);bTe=n(zGt,"SPAN",{});var QGt=s(bTe);T(L$.$$.fragment,QGt),QGt.forEach(t),zGt.forEach(t),Ltr=i(dao),vTe=n(dao,"SPAN",{});var WGt=s(vTe);ytr=r(WGt,"AutoModelForSequenceClassification"),WGt.forEach(t),dao.forEach(t),Uoo=i(m),Do=n(m,"DIV",{class:!0});var Il=s(Do);T(y$.$$.fragment,Il),xtr=i(Il),jd=n(Il,"P",{});var nde=s(jd);$tr=r(nde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),eH=n(nde,"A",{href:!0});var UGt=s(eH);ktr=r(UGt,"from_pretrained()"),UGt.forEach(t),Str=r(nde," class method or the "),oH=n(nde,"A",{href:!0});var HGt=s(oH);Rtr=r(HGt,"from_config()"),HGt.forEach(t),Ptr=r(nde,` class
method.`),nde.forEach(t),Btr=i(Il),x$=n(Il,"P",{});var cao=s(x$);Itr=r(cao,"This class cannot be instantiated directly using "),FTe=n(cao,"CODE",{});var JGt=s(FTe);Ntr=r(JGt,"__init__()"),JGt.forEach(t),qtr=r(cao," (throws an error)."),cao.forEach(t),jtr=i(Il),Ct=n(Il,"DIV",{class:!0});var Sy=s(Ct);T($$.$$.fragment,Sy),Dtr=i(Sy),TTe=n(Sy,"P",{});var YGt=s(TTe);Gtr=r(YGt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),YGt.forEach(t),Otr=i(Sy),Dd=n(Sy,"P",{});var sde=s(Dd);Vtr=r(sde,`Note:
Loading a model from its configuration file does `),MTe=n(sde,"STRONG",{});var ZGt=s(MTe);Xtr=r(ZGt,"not"),ZGt.forEach(t),ztr=r(sde,` load the model weights. It only affects the
model\u2019s configuration. Use `),rH=n(sde,"A",{href:!0});var KGt=s(rH);Qtr=r(KGt,"from_pretrained()"),KGt.forEach(t),Wtr=r(sde," to load the model weights."),sde.forEach(t),Utr=i(Sy),T(VF.$$.fragment,Sy),Sy.forEach(t),Htr=i(Il),ao=n(Il,"DIV",{class:!0});var ya=s(ao);T(k$.$$.fragment,ya),Jtr=i(ya),ETe=n(ya,"P",{});var eOt=s(ETe);Ytr=r(eOt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),eOt.forEach(t),Ztr=i(ya),nn=n(ya,"P",{});var Ry=s(nn);Ktr=r(Ry,"The model class to instantiate is selected based on the "),CTe=n(Ry,"CODE",{});var oOt=s(CTe);ear=r(oOt,"model_type"),oOt.forEach(t),oar=r(Ry,` property of the config object (either
passed as an argument or loaded from `),wTe=n(Ry,"CODE",{});var rOt=s(wTe);rar=r(rOt,"pretrained_model_name_or_path"),rOt.forEach(t),tar=r(Ry,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ATe=n(Ry,"CODE",{});var tOt=s(ATe);aar=r(tOt,"pretrained_model_name_or_path"),tOt.forEach(t),nar=r(Ry,":"),Ry.forEach(t),sar=i(ya),j=n(ya,"UL",{});var D=s(j);XF=n(D,"LI",{});var lXe=s(XF);LTe=n(lXe,"STRONG",{});var aOt=s(LTe);lar=r(aOt,"albert"),aOt.forEach(t),iar=r(lXe," \u2014 "),tH=n(lXe,"A",{href:!0});var nOt=s(tH);dar=r(nOt,"AlbertForSequenceClassification"),nOt.forEach(t),car=r(lXe," (ALBERT model)"),lXe.forEach(t),mar=i(D),zF=n(D,"LI",{});var iXe=s(zF);yTe=n(iXe,"STRONG",{});var sOt=s(yTe);far=r(sOt,"bart"),sOt.forEach(t),gar=r(iXe," \u2014 "),aH=n(iXe,"A",{href:!0});var lOt=s(aH);har=r(lOt,"BartForSequenceClassification"),lOt.forEach(t),uar=r(iXe," (BART model)"),iXe.forEach(t),par=i(D),QF=n(D,"LI",{});var dXe=s(QF);xTe=n(dXe,"STRONG",{});var iOt=s(xTe);_ar=r(iOt,"bert"),iOt.forEach(t),bar=r(dXe," \u2014 "),nH=n(dXe,"A",{href:!0});var dOt=s(nH);Far=r(dOt,"BertForSequenceClassification"),dOt.forEach(t),Tar=r(dXe," (BERT model)"),dXe.forEach(t),Mar=i(D),WF=n(D,"LI",{});var cXe=s(WF);$Te=n(cXe,"STRONG",{});var cOt=s($Te);Ear=r(cOt,"big_bird"),cOt.forEach(t),Car=r(cXe," \u2014 "),sH=n(cXe,"A",{href:!0});var mOt=s(sH);war=r(mOt,"BigBirdForSequenceClassification"),mOt.forEach(t),Aar=r(cXe," (BigBird model)"),cXe.forEach(t),Lar=i(D),UF=n(D,"LI",{});var mXe=s(UF);kTe=n(mXe,"STRONG",{});var fOt=s(kTe);yar=r(fOt,"bigbird_pegasus"),fOt.forEach(t),xar=r(mXe," \u2014 "),lH=n(mXe,"A",{href:!0});var gOt=s(lH);$ar=r(gOt,"BigBirdPegasusForSequenceClassification"),gOt.forEach(t),kar=r(mXe," (BigBird-Pegasus model)"),mXe.forEach(t),Sar=i(D),HF=n(D,"LI",{});var fXe=s(HF);STe=n(fXe,"STRONG",{});var hOt=s(STe);Rar=r(hOt,"bloom"),hOt.forEach(t),Par=r(fXe," \u2014 "),iH=n(fXe,"A",{href:!0});var uOt=s(iH);Bar=r(uOt,"BloomForSequenceClassification"),uOt.forEach(t),Iar=r(fXe," (BLOOM model)"),fXe.forEach(t),Nar=i(D),JF=n(D,"LI",{});var gXe=s(JF);RTe=n(gXe,"STRONG",{});var pOt=s(RTe);qar=r(pOt,"camembert"),pOt.forEach(t),jar=r(gXe," \u2014 "),dH=n(gXe,"A",{href:!0});var _Ot=s(dH);Dar=r(_Ot,"CamembertForSequenceClassification"),_Ot.forEach(t),Gar=r(gXe," (CamemBERT model)"),gXe.forEach(t),Oar=i(D),YF=n(D,"LI",{});var hXe=s(YF);PTe=n(hXe,"STRONG",{});var bOt=s(PTe);Var=r(bOt,"canine"),bOt.forEach(t),Xar=r(hXe," \u2014 "),cH=n(hXe,"A",{href:!0});var vOt=s(cH);zar=r(vOt,"CanineForSequenceClassification"),vOt.forEach(t),Qar=r(hXe," (CANINE model)"),hXe.forEach(t),War=i(D),ZF=n(D,"LI",{});var uXe=s(ZF);BTe=n(uXe,"STRONG",{});var FOt=s(BTe);Uar=r(FOt,"convbert"),FOt.forEach(t),Har=r(uXe," \u2014 "),mH=n(uXe,"A",{href:!0});var TOt=s(mH);Jar=r(TOt,"ConvBertForSequenceClassification"),TOt.forEach(t),Yar=r(uXe," (ConvBERT model)"),uXe.forEach(t),Zar=i(D),KF=n(D,"LI",{});var pXe=s(KF);ITe=n(pXe,"STRONG",{});var MOt=s(ITe);Kar=r(MOt,"ctrl"),MOt.forEach(t),enr=r(pXe," \u2014 "),fH=n(pXe,"A",{href:!0});var EOt=s(fH);onr=r(EOt,"CTRLForSequenceClassification"),EOt.forEach(t),rnr=r(pXe," (CTRL model)"),pXe.forEach(t),tnr=i(D),eT=n(D,"LI",{});var _Xe=s(eT);NTe=n(_Xe,"STRONG",{});var COt=s(NTe);anr=r(COt,"data2vec-text"),COt.forEach(t),nnr=r(_Xe," \u2014 "),gH=n(_Xe,"A",{href:!0});var wOt=s(gH);snr=r(wOt,"Data2VecTextForSequenceClassification"),wOt.forEach(t),lnr=r(_Xe," (Data2VecText model)"),_Xe.forEach(t),inr=i(D),oT=n(D,"LI",{});var bXe=s(oT);qTe=n(bXe,"STRONG",{});var AOt=s(qTe);dnr=r(AOt,"deberta"),AOt.forEach(t),cnr=r(bXe," \u2014 "),hH=n(bXe,"A",{href:!0});var LOt=s(hH);mnr=r(LOt,"DebertaForSequenceClassification"),LOt.forEach(t),fnr=r(bXe," (DeBERTa model)"),bXe.forEach(t),gnr=i(D),rT=n(D,"LI",{});var vXe=s(rT);jTe=n(vXe,"STRONG",{});var yOt=s(jTe);hnr=r(yOt,"deberta-v2"),yOt.forEach(t),unr=r(vXe," \u2014 "),uH=n(vXe,"A",{href:!0});var xOt=s(uH);pnr=r(xOt,"DebertaV2ForSequenceClassification"),xOt.forEach(t),_nr=r(vXe," (DeBERTa-v2 model)"),vXe.forEach(t),bnr=i(D),tT=n(D,"LI",{});var FXe=s(tT);DTe=n(FXe,"STRONG",{});var $Ot=s(DTe);vnr=r($Ot,"distilbert"),$Ot.forEach(t),Fnr=r(FXe," \u2014 "),pH=n(FXe,"A",{href:!0});var kOt=s(pH);Tnr=r(kOt,"DistilBertForSequenceClassification"),kOt.forEach(t),Mnr=r(FXe," (DistilBERT model)"),FXe.forEach(t),Enr=i(D),aT=n(D,"LI",{});var TXe=s(aT);GTe=n(TXe,"STRONG",{});var SOt=s(GTe);Cnr=r(SOt,"electra"),SOt.forEach(t),wnr=r(TXe," \u2014 "),_H=n(TXe,"A",{href:!0});var ROt=s(_H);Anr=r(ROt,"ElectraForSequenceClassification"),ROt.forEach(t),Lnr=r(TXe," (ELECTRA model)"),TXe.forEach(t),ynr=i(D),nT=n(D,"LI",{});var MXe=s(nT);OTe=n(MXe,"STRONG",{});var POt=s(OTe);xnr=r(POt,"ernie"),POt.forEach(t),$nr=r(MXe," \u2014 "),bH=n(MXe,"A",{href:!0});var BOt=s(bH);knr=r(BOt,"ErnieForSequenceClassification"),BOt.forEach(t),Snr=r(MXe," (ERNIE model)"),MXe.forEach(t),Rnr=i(D),sT=n(D,"LI",{});var EXe=s(sT);VTe=n(EXe,"STRONG",{});var IOt=s(VTe);Pnr=r(IOt,"esm"),IOt.forEach(t),Bnr=r(EXe," \u2014 "),vH=n(EXe,"A",{href:!0});var NOt=s(vH);Inr=r(NOt,"EsmForSequenceClassification"),NOt.forEach(t),Nnr=r(EXe," (ESM model)"),EXe.forEach(t),qnr=i(D),lT=n(D,"LI",{});var CXe=s(lT);XTe=n(CXe,"STRONG",{});var qOt=s(XTe);jnr=r(qOt,"flaubert"),qOt.forEach(t),Dnr=r(CXe," \u2014 "),FH=n(CXe,"A",{href:!0});var jOt=s(FH);Gnr=r(jOt,"FlaubertForSequenceClassification"),jOt.forEach(t),Onr=r(CXe," (FlauBERT model)"),CXe.forEach(t),Vnr=i(D),iT=n(D,"LI",{});var wXe=s(iT);zTe=n(wXe,"STRONG",{});var DOt=s(zTe);Xnr=r(DOt,"fnet"),DOt.forEach(t),znr=r(wXe," \u2014 "),TH=n(wXe,"A",{href:!0});var GOt=s(TH);Qnr=r(GOt,"FNetForSequenceClassification"),GOt.forEach(t),Wnr=r(wXe," (FNet model)"),wXe.forEach(t),Unr=i(D),dT=n(D,"LI",{});var AXe=s(dT);QTe=n(AXe,"STRONG",{});var OOt=s(QTe);Hnr=r(OOt,"funnel"),OOt.forEach(t),Jnr=r(AXe," \u2014 "),MH=n(AXe,"A",{href:!0});var VOt=s(MH);Ynr=r(VOt,"FunnelForSequenceClassification"),VOt.forEach(t),Znr=r(AXe," (Funnel Transformer model)"),AXe.forEach(t),Knr=i(D),cT=n(D,"LI",{});var LXe=s(cT);WTe=n(LXe,"STRONG",{});var XOt=s(WTe);esr=r(XOt,"gpt2"),XOt.forEach(t),osr=r(LXe," \u2014 "),EH=n(LXe,"A",{href:!0});var zOt=s(EH);rsr=r(zOt,"GPT2ForSequenceClassification"),zOt.forEach(t),tsr=r(LXe," (OpenAI GPT-2 model)"),LXe.forEach(t),asr=i(D),mT=n(D,"LI",{});var yXe=s(mT);UTe=n(yXe,"STRONG",{});var QOt=s(UTe);nsr=r(QOt,"gpt_neo"),QOt.forEach(t),ssr=r(yXe," \u2014 "),CH=n(yXe,"A",{href:!0});var WOt=s(CH);lsr=r(WOt,"GPTNeoForSequenceClassification"),WOt.forEach(t),isr=r(yXe," (GPT Neo model)"),yXe.forEach(t),dsr=i(D),fT=n(D,"LI",{});var xXe=s(fT);HTe=n(xXe,"STRONG",{});var UOt=s(HTe);csr=r(UOt,"gptj"),UOt.forEach(t),msr=r(xXe," \u2014 "),wH=n(xXe,"A",{href:!0});var HOt=s(wH);fsr=r(HOt,"GPTJForSequenceClassification"),HOt.forEach(t),gsr=r(xXe," (GPT-J model)"),xXe.forEach(t),hsr=i(D),gT=n(D,"LI",{});var $Xe=s(gT);JTe=n($Xe,"STRONG",{});var JOt=s(JTe);usr=r(JOt,"ibert"),JOt.forEach(t),psr=r($Xe," \u2014 "),AH=n($Xe,"A",{href:!0});var YOt=s(AH);_sr=r(YOt,"IBertForSequenceClassification"),YOt.forEach(t),bsr=r($Xe," (I-BERT model)"),$Xe.forEach(t),vsr=i(D),hT=n(D,"LI",{});var kXe=s(hT);YTe=n(kXe,"STRONG",{});var ZOt=s(YTe);Fsr=r(ZOt,"layoutlm"),ZOt.forEach(t),Tsr=r(kXe," \u2014 "),LH=n(kXe,"A",{href:!0});var KOt=s(LH);Msr=r(KOt,"LayoutLMForSequenceClassification"),KOt.forEach(t),Esr=r(kXe," (LayoutLM model)"),kXe.forEach(t),Csr=i(D),uT=n(D,"LI",{});var SXe=s(uT);ZTe=n(SXe,"STRONG",{});var eVt=s(ZTe);wsr=r(eVt,"layoutlmv2"),eVt.forEach(t),Asr=r(SXe," \u2014 "),yH=n(SXe,"A",{href:!0});var oVt=s(yH);Lsr=r(oVt,"LayoutLMv2ForSequenceClassification"),oVt.forEach(t),ysr=r(SXe," (LayoutLMv2 model)"),SXe.forEach(t),xsr=i(D),pT=n(D,"LI",{});var RXe=s(pT);KTe=n(RXe,"STRONG",{});var rVt=s(KTe);$sr=r(rVt,"layoutlmv3"),rVt.forEach(t),ksr=r(RXe," \u2014 "),xH=n(RXe,"A",{href:!0});var tVt=s(xH);Ssr=r(tVt,"LayoutLMv3ForSequenceClassification"),tVt.forEach(t),Rsr=r(RXe," (LayoutLMv3 model)"),RXe.forEach(t),Psr=i(D),_T=n(D,"LI",{});var PXe=s(_T);eMe=n(PXe,"STRONG",{});var aVt=s(eMe);Bsr=r(aVt,"led"),aVt.forEach(t),Isr=r(PXe," \u2014 "),$H=n(PXe,"A",{href:!0});var nVt=s($H);Nsr=r(nVt,"LEDForSequenceClassification"),nVt.forEach(t),qsr=r(PXe," (LED model)"),PXe.forEach(t),jsr=i(D),bT=n(D,"LI",{});var BXe=s(bT);oMe=n(BXe,"STRONG",{});var sVt=s(oMe);Dsr=r(sVt,"longformer"),sVt.forEach(t),Gsr=r(BXe," \u2014 "),kH=n(BXe,"A",{href:!0});var lVt=s(kH);Osr=r(lVt,"LongformerForSequenceClassification"),lVt.forEach(t),Vsr=r(BXe," (Longformer model)"),BXe.forEach(t),Xsr=i(D),vT=n(D,"LI",{});var IXe=s(vT);rMe=n(IXe,"STRONG",{});var iVt=s(rMe);zsr=r(iVt,"luke"),iVt.forEach(t),Qsr=r(IXe," \u2014 "),SH=n(IXe,"A",{href:!0});var dVt=s(SH);Wsr=r(dVt,"LukeForSequenceClassification"),dVt.forEach(t),Usr=r(IXe," (LUKE model)"),IXe.forEach(t),Hsr=i(D),FT=n(D,"LI",{});var NXe=s(FT);tMe=n(NXe,"STRONG",{});var cVt=s(tMe);Jsr=r(cVt,"markuplm"),cVt.forEach(t),Ysr=r(NXe," \u2014 "),RH=n(NXe,"A",{href:!0});var mVt=s(RH);Zsr=r(mVt,"MarkupLMForSequenceClassification"),mVt.forEach(t),Ksr=r(NXe," (MarkupLM model)"),NXe.forEach(t),elr=i(D),TT=n(D,"LI",{});var qXe=s(TT);aMe=n(qXe,"STRONG",{});var fVt=s(aMe);olr=r(fVt,"mbart"),fVt.forEach(t),rlr=r(qXe," \u2014 "),PH=n(qXe,"A",{href:!0});var gVt=s(PH);tlr=r(gVt,"MBartForSequenceClassification"),gVt.forEach(t),alr=r(qXe," (mBART model)"),qXe.forEach(t),nlr=i(D),MT=n(D,"LI",{});var jXe=s(MT);nMe=n(jXe,"STRONG",{});var hVt=s(nMe);slr=r(hVt,"megatron-bert"),hVt.forEach(t),llr=r(jXe," \u2014 "),BH=n(jXe,"A",{href:!0});var uVt=s(BH);ilr=r(uVt,"MegatronBertForSequenceClassification"),uVt.forEach(t),dlr=r(jXe," (Megatron-BERT model)"),jXe.forEach(t),clr=i(D),ET=n(D,"LI",{});var DXe=s(ET);sMe=n(DXe,"STRONG",{});var pVt=s(sMe);mlr=r(pVt,"mobilebert"),pVt.forEach(t),flr=r(DXe," \u2014 "),IH=n(DXe,"A",{href:!0});var _Vt=s(IH);glr=r(_Vt,"MobileBertForSequenceClassification"),_Vt.forEach(t),hlr=r(DXe," (MobileBERT model)"),DXe.forEach(t),ulr=i(D),CT=n(D,"LI",{});var GXe=s(CT);lMe=n(GXe,"STRONG",{});var bVt=s(lMe);plr=r(bVt,"mpnet"),bVt.forEach(t),_lr=r(GXe," \u2014 "),NH=n(GXe,"A",{href:!0});var vVt=s(NH);blr=r(vVt,"MPNetForSequenceClassification"),vVt.forEach(t),vlr=r(GXe," (MPNet model)"),GXe.forEach(t),Flr=i(D),wT=n(D,"LI",{});var OXe=s(wT);iMe=n(OXe,"STRONG",{});var FVt=s(iMe);Tlr=r(FVt,"mvp"),FVt.forEach(t),Mlr=r(OXe," \u2014 "),qH=n(OXe,"A",{href:!0});var TVt=s(qH);Elr=r(TVt,"MvpForSequenceClassification"),TVt.forEach(t),Clr=r(OXe," (MVP model)"),OXe.forEach(t),wlr=i(D),AT=n(D,"LI",{});var VXe=s(AT);dMe=n(VXe,"STRONG",{});var MVt=s(dMe);Alr=r(MVt,"nezha"),MVt.forEach(t),Llr=r(VXe," \u2014 "),jH=n(VXe,"A",{href:!0});var EVt=s(jH);ylr=r(EVt,"NezhaForSequenceClassification"),EVt.forEach(t),xlr=r(VXe," (Nezha model)"),VXe.forEach(t),$lr=i(D),LT=n(D,"LI",{});var XXe=s(LT);cMe=n(XXe,"STRONG",{});var CVt=s(cMe);klr=r(CVt,"nystromformer"),CVt.forEach(t),Slr=r(XXe," \u2014 "),DH=n(XXe,"A",{href:!0});var wVt=s(DH);Rlr=r(wVt,"NystromformerForSequenceClassification"),wVt.forEach(t),Plr=r(XXe," (Nystr\xF6mformer model)"),XXe.forEach(t),Blr=i(D),yT=n(D,"LI",{});var zXe=s(yT);mMe=n(zXe,"STRONG",{});var AVt=s(mMe);Ilr=r(AVt,"openai-gpt"),AVt.forEach(t),Nlr=r(zXe," \u2014 "),GH=n(zXe,"A",{href:!0});var LVt=s(GH);qlr=r(LVt,"OpenAIGPTForSequenceClassification"),LVt.forEach(t),jlr=r(zXe," (OpenAI GPT model)"),zXe.forEach(t),Dlr=i(D),xT=n(D,"LI",{});var QXe=s(xT);fMe=n(QXe,"STRONG",{});var yVt=s(fMe);Glr=r(yVt,"opt"),yVt.forEach(t),Olr=r(QXe," \u2014 "),OH=n(QXe,"A",{href:!0});var xVt=s(OH);Vlr=r(xVt,"OPTForSequenceClassification"),xVt.forEach(t),Xlr=r(QXe," (OPT model)"),QXe.forEach(t),zlr=i(D),$T=n(D,"LI",{});var WXe=s($T);gMe=n(WXe,"STRONG",{});var $Vt=s(gMe);Qlr=r($Vt,"perceiver"),$Vt.forEach(t),Wlr=r(WXe," \u2014 "),VH=n(WXe,"A",{href:!0});var kVt=s(VH);Ulr=r(kVt,"PerceiverForSequenceClassification"),kVt.forEach(t),Hlr=r(WXe," (Perceiver model)"),WXe.forEach(t),Jlr=i(D),kT=n(D,"LI",{});var UXe=s(kT);hMe=n(UXe,"STRONG",{});var SVt=s(hMe);Ylr=r(SVt,"plbart"),SVt.forEach(t),Zlr=r(UXe," \u2014 "),XH=n(UXe,"A",{href:!0});var RVt=s(XH);Klr=r(RVt,"PLBartForSequenceClassification"),RVt.forEach(t),eir=r(UXe," (PLBart model)"),UXe.forEach(t),oir=i(D),ST=n(D,"LI",{});var HXe=s(ST);uMe=n(HXe,"STRONG",{});var PVt=s(uMe);rir=r(PVt,"qdqbert"),PVt.forEach(t),tir=r(HXe," \u2014 "),zH=n(HXe,"A",{href:!0});var BVt=s(zH);air=r(BVt,"QDQBertForSequenceClassification"),BVt.forEach(t),nir=r(HXe," (QDQBert model)"),HXe.forEach(t),sir=i(D),RT=n(D,"LI",{});var JXe=s(RT);pMe=n(JXe,"STRONG",{});var IVt=s(pMe);lir=r(IVt,"reformer"),IVt.forEach(t),iir=r(JXe," \u2014 "),QH=n(JXe,"A",{href:!0});var NVt=s(QH);dir=r(NVt,"ReformerForSequenceClassification"),NVt.forEach(t),cir=r(JXe," (Reformer model)"),JXe.forEach(t),mir=i(D),PT=n(D,"LI",{});var YXe=s(PT);_Me=n(YXe,"STRONG",{});var qVt=s(_Me);fir=r(qVt,"rembert"),qVt.forEach(t),gir=r(YXe," \u2014 "),WH=n(YXe,"A",{href:!0});var jVt=s(WH);hir=r(jVt,"RemBertForSequenceClassification"),jVt.forEach(t),uir=r(YXe," (RemBERT model)"),YXe.forEach(t),pir=i(D),BT=n(D,"LI",{});var ZXe=s(BT);bMe=n(ZXe,"STRONG",{});var DVt=s(bMe);_ir=r(DVt,"roberta"),DVt.forEach(t),bir=r(ZXe," \u2014 "),UH=n(ZXe,"A",{href:!0});var GVt=s(UH);vir=r(GVt,"RobertaForSequenceClassification"),GVt.forEach(t),Fir=r(ZXe," (RoBERTa model)"),ZXe.forEach(t),Tir=i(D),IT=n(D,"LI",{});var KXe=s(IT);vMe=n(KXe,"STRONG",{});var OVt=s(vMe);Mir=r(OVt,"roformer"),OVt.forEach(t),Eir=r(KXe," \u2014 "),HH=n(KXe,"A",{href:!0});var VVt=s(HH);Cir=r(VVt,"RoFormerForSequenceClassification"),VVt.forEach(t),wir=r(KXe," (RoFormer model)"),KXe.forEach(t),Air=i(D),NT=n(D,"LI",{});var eze=s(NT);FMe=n(eze,"STRONG",{});var XVt=s(FMe);Lir=r(XVt,"squeezebert"),XVt.forEach(t),yir=r(eze," \u2014 "),JH=n(eze,"A",{href:!0});var zVt=s(JH);xir=r(zVt,"SqueezeBertForSequenceClassification"),zVt.forEach(t),$ir=r(eze," (SqueezeBERT model)"),eze.forEach(t),kir=i(D),qT=n(D,"LI",{});var oze=s(qT);TMe=n(oze,"STRONG",{});var QVt=s(TMe);Sir=r(QVt,"tapas"),QVt.forEach(t),Rir=r(oze," \u2014 "),YH=n(oze,"A",{href:!0});var WVt=s(YH);Pir=r(WVt,"TapasForSequenceClassification"),WVt.forEach(t),Bir=r(oze," (TAPAS model)"),oze.forEach(t),Iir=i(D),jT=n(D,"LI",{});var rze=s(jT);MMe=n(rze,"STRONG",{});var UVt=s(MMe);Nir=r(UVt,"transfo-xl"),UVt.forEach(t),qir=r(rze," \u2014 "),ZH=n(rze,"A",{href:!0});var HVt=s(ZH);jir=r(HVt,"TransfoXLForSequenceClassification"),HVt.forEach(t),Dir=r(rze," (Transformer-XL model)"),rze.forEach(t),Gir=i(D),DT=n(D,"LI",{});var tze=s(DT);EMe=n(tze,"STRONG",{});var JVt=s(EMe);Oir=r(JVt,"xlm"),JVt.forEach(t),Vir=r(tze," \u2014 "),KH=n(tze,"A",{href:!0});var YVt=s(KH);Xir=r(YVt,"XLMForSequenceClassification"),YVt.forEach(t),zir=r(tze," (XLM model)"),tze.forEach(t),Qir=i(D),GT=n(D,"LI",{});var aze=s(GT);CMe=n(aze,"STRONG",{});var ZVt=s(CMe);Wir=r(ZVt,"xlm-roberta"),ZVt.forEach(t),Uir=r(aze," \u2014 "),eJ=n(aze,"A",{href:!0});var KVt=s(eJ);Hir=r(KVt,"XLMRobertaForSequenceClassification"),KVt.forEach(t),Jir=r(aze," (XLM-RoBERTa model)"),aze.forEach(t),Yir=i(D),OT=n(D,"LI",{});var nze=s(OT);wMe=n(nze,"STRONG",{});var eXt=s(wMe);Zir=r(eXt,"xlm-roberta-xl"),eXt.forEach(t),Kir=r(nze," \u2014 "),oJ=n(nze,"A",{href:!0});var oXt=s(oJ);edr=r(oXt,"XLMRobertaXLForSequenceClassification"),oXt.forEach(t),odr=r(nze," (XLM-RoBERTa-XL model)"),nze.forEach(t),rdr=i(D),VT=n(D,"LI",{});var sze=s(VT);AMe=n(sze,"STRONG",{});var rXt=s(AMe);tdr=r(rXt,"xlnet"),rXt.forEach(t),adr=r(sze," \u2014 "),rJ=n(sze,"A",{href:!0});var tXt=s(rJ);ndr=r(tXt,"XLNetForSequenceClassification"),tXt.forEach(t),sdr=r(sze," (XLNet model)"),sze.forEach(t),ldr=i(D),XT=n(D,"LI",{});var lze=s(XT);LMe=n(lze,"STRONG",{});var aXt=s(LMe);idr=r(aXt,"yoso"),aXt.forEach(t),ddr=r(lze," \u2014 "),tJ=n(lze,"A",{href:!0});var nXt=s(tJ);cdr=r(nXt,"YosoForSequenceClassification"),nXt.forEach(t),mdr=r(lze," (YOSO model)"),lze.forEach(t),D.forEach(t),fdr=i(ya),zT=n(ya,"P",{});var ize=s(zT);gdr=r(ize,"The model is set in evaluation mode by default using "),yMe=n(ize,"CODE",{});var sXt=s(yMe);hdr=r(sXt,"model.eval()"),sXt.forEach(t),udr=r(ize,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xMe=n(ize,"CODE",{});var lXt=s(xMe);pdr=r(lXt,"model.train()"),lXt.forEach(t),ize.forEach(t),_dr=i(ya),T(QT.$$.fragment,ya),ya.forEach(t),Il.forEach(t),Hoo=i(m),Gd=n(m,"H2",{class:!0});var mao=s(Gd);WT=n(mao,"A",{id:!0,class:!0,href:!0});var iXt=s(WT);$Me=n(iXt,"SPAN",{});var dXt=s($Me);T(S$.$$.fragment,dXt),dXt.forEach(t),iXt.forEach(t),bdr=i(mao),kMe=n(mao,"SPAN",{});var cXt=s(kMe);vdr=r(cXt,"AutoModelForMultipleChoice"),cXt.forEach(t),mao.forEach(t),Joo=i(m),Go=n(m,"DIV",{class:!0});var Nl=s(Go);T(R$.$$.fragment,Nl),Fdr=i(Nl),Od=n(Nl,"P",{});var lde=s(Od);Tdr=r(lde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),aJ=n(lde,"A",{href:!0});var mXt=s(aJ);Mdr=r(mXt,"from_pretrained()"),mXt.forEach(t),Edr=r(lde," class method or the "),nJ=n(lde,"A",{href:!0});var fXt=s(nJ);Cdr=r(fXt,"from_config()"),fXt.forEach(t),wdr=r(lde,` class
method.`),lde.forEach(t),Adr=i(Nl),P$=n(Nl,"P",{});var fao=s(P$);Ldr=r(fao,"This class cannot be instantiated directly using "),SMe=n(fao,"CODE",{});var gXt=s(SMe);ydr=r(gXt,"__init__()"),gXt.forEach(t),xdr=r(fao," (throws an error)."),fao.forEach(t),$dr=i(Nl),wt=n(Nl,"DIV",{class:!0});var Py=s(wt);T(B$.$$.fragment,Py),kdr=i(Py),RMe=n(Py,"P",{});var hXt=s(RMe);Sdr=r(hXt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),hXt.forEach(t),Rdr=i(Py),Vd=n(Py,"P",{});var ide=s(Vd);Pdr=r(ide,`Note:
Loading a model from its configuration file does `),PMe=n(ide,"STRONG",{});var uXt=s(PMe);Bdr=r(uXt,"not"),uXt.forEach(t),Idr=r(ide,` load the model weights. It only affects the
model\u2019s configuration. Use `),sJ=n(ide,"A",{href:!0});var pXt=s(sJ);Ndr=r(pXt,"from_pretrained()"),pXt.forEach(t),qdr=r(ide," to load the model weights."),ide.forEach(t),jdr=i(Py),T(UT.$$.fragment,Py),Py.forEach(t),Ddr=i(Nl),no=n(Nl,"DIV",{class:!0});var xa=s(no);T(I$.$$.fragment,xa),Gdr=i(xa),BMe=n(xa,"P",{});var _Xt=s(BMe);Odr=r(_Xt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),_Xt.forEach(t),Vdr=i(xa),sn=n(xa,"P",{});var By=s(sn);Xdr=r(By,"The model class to instantiate is selected based on the "),IMe=n(By,"CODE",{});var bXt=s(IMe);zdr=r(bXt,"model_type"),bXt.forEach(t),Qdr=r(By,` property of the config object (either
passed as an argument or loaded from `),NMe=n(By,"CODE",{});var vXt=s(NMe);Wdr=r(vXt,"pretrained_model_name_or_path"),vXt.forEach(t),Udr=r(By,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qMe=n(By,"CODE",{});var FXt=s(qMe);Hdr=r(FXt,"pretrained_model_name_or_path"),FXt.forEach(t),Jdr=r(By,":"),By.forEach(t),Ydr=i(xa),K=n(xa,"UL",{});var ee=s(K);HT=n(ee,"LI",{});var dze=s(HT);jMe=n(dze,"STRONG",{});var TXt=s(jMe);Zdr=r(TXt,"albert"),TXt.forEach(t),Kdr=r(dze," \u2014 "),lJ=n(dze,"A",{href:!0});var MXt=s(lJ);ecr=r(MXt,"AlbertForMultipleChoice"),MXt.forEach(t),ocr=r(dze," (ALBERT model)"),dze.forEach(t),rcr=i(ee),JT=n(ee,"LI",{});var cze=s(JT);DMe=n(cze,"STRONG",{});var EXt=s(DMe);tcr=r(EXt,"bert"),EXt.forEach(t),acr=r(cze," \u2014 "),iJ=n(cze,"A",{href:!0});var CXt=s(iJ);ncr=r(CXt,"BertForMultipleChoice"),CXt.forEach(t),scr=r(cze," (BERT model)"),cze.forEach(t),lcr=i(ee),YT=n(ee,"LI",{});var mze=s(YT);GMe=n(mze,"STRONG",{});var wXt=s(GMe);icr=r(wXt,"big_bird"),wXt.forEach(t),dcr=r(mze," \u2014 "),dJ=n(mze,"A",{href:!0});var AXt=s(dJ);ccr=r(AXt,"BigBirdForMultipleChoice"),AXt.forEach(t),mcr=r(mze," (BigBird model)"),mze.forEach(t),fcr=i(ee),ZT=n(ee,"LI",{});var fze=s(ZT);OMe=n(fze,"STRONG",{});var LXt=s(OMe);gcr=r(LXt,"camembert"),LXt.forEach(t),hcr=r(fze," \u2014 "),cJ=n(fze,"A",{href:!0});var yXt=s(cJ);ucr=r(yXt,"CamembertForMultipleChoice"),yXt.forEach(t),pcr=r(fze," (CamemBERT model)"),fze.forEach(t),_cr=i(ee),KT=n(ee,"LI",{});var gze=s(KT);VMe=n(gze,"STRONG",{});var xXt=s(VMe);bcr=r(xXt,"canine"),xXt.forEach(t),vcr=r(gze," \u2014 "),mJ=n(gze,"A",{href:!0});var $Xt=s(mJ);Fcr=r($Xt,"CanineForMultipleChoice"),$Xt.forEach(t),Tcr=r(gze," (CANINE model)"),gze.forEach(t),Mcr=i(ee),eM=n(ee,"LI",{});var hze=s(eM);XMe=n(hze,"STRONG",{});var kXt=s(XMe);Ecr=r(kXt,"convbert"),kXt.forEach(t),Ccr=r(hze," \u2014 "),fJ=n(hze,"A",{href:!0});var SXt=s(fJ);wcr=r(SXt,"ConvBertForMultipleChoice"),SXt.forEach(t),Acr=r(hze," (ConvBERT model)"),hze.forEach(t),Lcr=i(ee),oM=n(ee,"LI",{});var uze=s(oM);zMe=n(uze,"STRONG",{});var RXt=s(zMe);ycr=r(RXt,"data2vec-text"),RXt.forEach(t),xcr=r(uze," \u2014 "),gJ=n(uze,"A",{href:!0});var PXt=s(gJ);$cr=r(PXt,"Data2VecTextForMultipleChoice"),PXt.forEach(t),kcr=r(uze," (Data2VecText model)"),uze.forEach(t),Scr=i(ee),rM=n(ee,"LI",{});var pze=s(rM);QMe=n(pze,"STRONG",{});var BXt=s(QMe);Rcr=r(BXt,"deberta-v2"),BXt.forEach(t),Pcr=r(pze," \u2014 "),hJ=n(pze,"A",{href:!0});var IXt=s(hJ);Bcr=r(IXt,"DebertaV2ForMultipleChoice"),IXt.forEach(t),Icr=r(pze," (DeBERTa-v2 model)"),pze.forEach(t),Ncr=i(ee),tM=n(ee,"LI",{});var _ze=s(tM);WMe=n(_ze,"STRONG",{});var NXt=s(WMe);qcr=r(NXt,"distilbert"),NXt.forEach(t),jcr=r(_ze," \u2014 "),uJ=n(_ze,"A",{href:!0});var qXt=s(uJ);Dcr=r(qXt,"DistilBertForMultipleChoice"),qXt.forEach(t),Gcr=r(_ze," (DistilBERT model)"),_ze.forEach(t),Ocr=i(ee),aM=n(ee,"LI",{});var bze=s(aM);UMe=n(bze,"STRONG",{});var jXt=s(UMe);Vcr=r(jXt,"electra"),jXt.forEach(t),Xcr=r(bze," \u2014 "),pJ=n(bze,"A",{href:!0});var DXt=s(pJ);zcr=r(DXt,"ElectraForMultipleChoice"),DXt.forEach(t),Qcr=r(bze," (ELECTRA model)"),bze.forEach(t),Wcr=i(ee),nM=n(ee,"LI",{});var vze=s(nM);HMe=n(vze,"STRONG",{});var GXt=s(HMe);Ucr=r(GXt,"ernie"),GXt.forEach(t),Hcr=r(vze," \u2014 "),_J=n(vze,"A",{href:!0});var OXt=s(_J);Jcr=r(OXt,"ErnieForMultipleChoice"),OXt.forEach(t),Ycr=r(vze," (ERNIE model)"),vze.forEach(t),Zcr=i(ee),sM=n(ee,"LI",{});var Fze=s(sM);JMe=n(Fze,"STRONG",{});var VXt=s(JMe);Kcr=r(VXt,"flaubert"),VXt.forEach(t),emr=r(Fze," \u2014 "),bJ=n(Fze,"A",{href:!0});var XXt=s(bJ);omr=r(XXt,"FlaubertForMultipleChoice"),XXt.forEach(t),rmr=r(Fze," (FlauBERT model)"),Fze.forEach(t),tmr=i(ee),lM=n(ee,"LI",{});var Tze=s(lM);YMe=n(Tze,"STRONG",{});var zXt=s(YMe);amr=r(zXt,"fnet"),zXt.forEach(t),nmr=r(Tze," \u2014 "),vJ=n(Tze,"A",{href:!0});var QXt=s(vJ);smr=r(QXt,"FNetForMultipleChoice"),QXt.forEach(t),lmr=r(Tze," (FNet model)"),Tze.forEach(t),imr=i(ee),iM=n(ee,"LI",{});var Mze=s(iM);ZMe=n(Mze,"STRONG",{});var WXt=s(ZMe);dmr=r(WXt,"funnel"),WXt.forEach(t),cmr=r(Mze," \u2014 "),FJ=n(Mze,"A",{href:!0});var UXt=s(FJ);mmr=r(UXt,"FunnelForMultipleChoice"),UXt.forEach(t),fmr=r(Mze," (Funnel Transformer model)"),Mze.forEach(t),gmr=i(ee),dM=n(ee,"LI",{});var Eze=s(dM);KMe=n(Eze,"STRONG",{});var HXt=s(KMe);hmr=r(HXt,"ibert"),HXt.forEach(t),umr=r(Eze," \u2014 "),TJ=n(Eze,"A",{href:!0});var JXt=s(TJ);pmr=r(JXt,"IBertForMultipleChoice"),JXt.forEach(t),_mr=r(Eze," (I-BERT model)"),Eze.forEach(t),bmr=i(ee),cM=n(ee,"LI",{});var Cze=s(cM);eEe=n(Cze,"STRONG",{});var YXt=s(eEe);vmr=r(YXt,"longformer"),YXt.forEach(t),Fmr=r(Cze," \u2014 "),MJ=n(Cze,"A",{href:!0});var ZXt=s(MJ);Tmr=r(ZXt,"LongformerForMultipleChoice"),ZXt.forEach(t),Mmr=r(Cze," (Longformer model)"),Cze.forEach(t),Emr=i(ee),mM=n(ee,"LI",{});var wze=s(mM);oEe=n(wze,"STRONG",{});var KXt=s(oEe);Cmr=r(KXt,"luke"),KXt.forEach(t),wmr=r(wze," \u2014 "),EJ=n(wze,"A",{href:!0});var ezt=s(EJ);Amr=r(ezt,"LukeForMultipleChoice"),ezt.forEach(t),Lmr=r(wze," (LUKE model)"),wze.forEach(t),ymr=i(ee),fM=n(ee,"LI",{});var Aze=s(fM);rEe=n(Aze,"STRONG",{});var ozt=s(rEe);xmr=r(ozt,"megatron-bert"),ozt.forEach(t),$mr=r(Aze," \u2014 "),CJ=n(Aze,"A",{href:!0});var rzt=s(CJ);kmr=r(rzt,"MegatronBertForMultipleChoice"),rzt.forEach(t),Smr=r(Aze," (Megatron-BERT model)"),Aze.forEach(t),Rmr=i(ee),gM=n(ee,"LI",{});var Lze=s(gM);tEe=n(Lze,"STRONG",{});var tzt=s(tEe);Pmr=r(tzt,"mobilebert"),tzt.forEach(t),Bmr=r(Lze," \u2014 "),wJ=n(Lze,"A",{href:!0});var azt=s(wJ);Imr=r(azt,"MobileBertForMultipleChoice"),azt.forEach(t),Nmr=r(Lze," (MobileBERT model)"),Lze.forEach(t),qmr=i(ee),hM=n(ee,"LI",{});var yze=s(hM);aEe=n(yze,"STRONG",{});var nzt=s(aEe);jmr=r(nzt,"mpnet"),nzt.forEach(t),Dmr=r(yze," \u2014 "),AJ=n(yze,"A",{href:!0});var szt=s(AJ);Gmr=r(szt,"MPNetForMultipleChoice"),szt.forEach(t),Omr=r(yze," (MPNet model)"),yze.forEach(t),Vmr=i(ee),uM=n(ee,"LI",{});var xze=s(uM);nEe=n(xze,"STRONG",{});var lzt=s(nEe);Xmr=r(lzt,"nezha"),lzt.forEach(t),zmr=r(xze," \u2014 "),LJ=n(xze,"A",{href:!0});var izt=s(LJ);Qmr=r(izt,"NezhaForMultipleChoice"),izt.forEach(t),Wmr=r(xze," (Nezha model)"),xze.forEach(t),Umr=i(ee),pM=n(ee,"LI",{});var $ze=s(pM);sEe=n($ze,"STRONG",{});var dzt=s(sEe);Hmr=r(dzt,"nystromformer"),dzt.forEach(t),Jmr=r($ze," \u2014 "),yJ=n($ze,"A",{href:!0});var czt=s(yJ);Ymr=r(czt,"NystromformerForMultipleChoice"),czt.forEach(t),Zmr=r($ze," (Nystr\xF6mformer model)"),$ze.forEach(t),Kmr=i(ee),_M=n(ee,"LI",{});var kze=s(_M);lEe=n(kze,"STRONG",{});var mzt=s(lEe);efr=r(mzt,"qdqbert"),mzt.forEach(t),ofr=r(kze," \u2014 "),xJ=n(kze,"A",{href:!0});var fzt=s(xJ);rfr=r(fzt,"QDQBertForMultipleChoice"),fzt.forEach(t),tfr=r(kze," (QDQBert model)"),kze.forEach(t),afr=i(ee),bM=n(ee,"LI",{});var Sze=s(bM);iEe=n(Sze,"STRONG",{});var gzt=s(iEe);nfr=r(gzt,"rembert"),gzt.forEach(t),sfr=r(Sze," \u2014 "),$J=n(Sze,"A",{href:!0});var hzt=s($J);lfr=r(hzt,"RemBertForMultipleChoice"),hzt.forEach(t),ifr=r(Sze," (RemBERT model)"),Sze.forEach(t),dfr=i(ee),vM=n(ee,"LI",{});var Rze=s(vM);dEe=n(Rze,"STRONG",{});var uzt=s(dEe);cfr=r(uzt,"roberta"),uzt.forEach(t),mfr=r(Rze," \u2014 "),kJ=n(Rze,"A",{href:!0});var pzt=s(kJ);ffr=r(pzt,"RobertaForMultipleChoice"),pzt.forEach(t),gfr=r(Rze," (RoBERTa model)"),Rze.forEach(t),hfr=i(ee),FM=n(ee,"LI",{});var Pze=s(FM);cEe=n(Pze,"STRONG",{});var _zt=s(cEe);ufr=r(_zt,"roformer"),_zt.forEach(t),pfr=r(Pze," \u2014 "),SJ=n(Pze,"A",{href:!0});var bzt=s(SJ);_fr=r(bzt,"RoFormerForMultipleChoice"),bzt.forEach(t),bfr=r(Pze," (RoFormer model)"),Pze.forEach(t),vfr=i(ee),TM=n(ee,"LI",{});var Bze=s(TM);mEe=n(Bze,"STRONG",{});var vzt=s(mEe);Ffr=r(vzt,"squeezebert"),vzt.forEach(t),Tfr=r(Bze," \u2014 "),RJ=n(Bze,"A",{href:!0});var Fzt=s(RJ);Mfr=r(Fzt,"SqueezeBertForMultipleChoice"),Fzt.forEach(t),Efr=r(Bze," (SqueezeBERT model)"),Bze.forEach(t),Cfr=i(ee),MM=n(ee,"LI",{});var Ize=s(MM);fEe=n(Ize,"STRONG",{});var Tzt=s(fEe);wfr=r(Tzt,"xlm"),Tzt.forEach(t),Afr=r(Ize," \u2014 "),PJ=n(Ize,"A",{href:!0});var Mzt=s(PJ);Lfr=r(Mzt,"XLMForMultipleChoice"),Mzt.forEach(t),yfr=r(Ize," (XLM model)"),Ize.forEach(t),xfr=i(ee),EM=n(ee,"LI",{});var Nze=s(EM);gEe=n(Nze,"STRONG",{});var Ezt=s(gEe);$fr=r(Ezt,"xlm-roberta"),Ezt.forEach(t),kfr=r(Nze," \u2014 "),BJ=n(Nze,"A",{href:!0});var Czt=s(BJ);Sfr=r(Czt,"XLMRobertaForMultipleChoice"),Czt.forEach(t),Rfr=r(Nze," (XLM-RoBERTa model)"),Nze.forEach(t),Pfr=i(ee),CM=n(ee,"LI",{});var qze=s(CM);hEe=n(qze,"STRONG",{});var wzt=s(hEe);Bfr=r(wzt,"xlm-roberta-xl"),wzt.forEach(t),Ifr=r(qze," \u2014 "),IJ=n(qze,"A",{href:!0});var Azt=s(IJ);Nfr=r(Azt,"XLMRobertaXLForMultipleChoice"),Azt.forEach(t),qfr=r(qze," (XLM-RoBERTa-XL model)"),qze.forEach(t),jfr=i(ee),wM=n(ee,"LI",{});var jze=s(wM);uEe=n(jze,"STRONG",{});var Lzt=s(uEe);Dfr=r(Lzt,"xlnet"),Lzt.forEach(t),Gfr=r(jze," \u2014 "),NJ=n(jze,"A",{href:!0});var yzt=s(NJ);Ofr=r(yzt,"XLNetForMultipleChoice"),yzt.forEach(t),Vfr=r(jze," (XLNet model)"),jze.forEach(t),Xfr=i(ee),AM=n(ee,"LI",{});var Dze=s(AM);pEe=n(Dze,"STRONG",{});var xzt=s(pEe);zfr=r(xzt,"yoso"),xzt.forEach(t),Qfr=r(Dze," \u2014 "),qJ=n(Dze,"A",{href:!0});var $zt=s(qJ);Wfr=r($zt,"YosoForMultipleChoice"),$zt.forEach(t),Ufr=r(Dze," (YOSO model)"),Dze.forEach(t),ee.forEach(t),Hfr=i(xa),LM=n(xa,"P",{});var Gze=s(LM);Jfr=r(Gze,"The model is set in evaluation mode by default using "),_Ee=n(Gze,"CODE",{});var kzt=s(_Ee);Yfr=r(kzt,"model.eval()"),kzt.forEach(t),Zfr=r(Gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bEe=n(Gze,"CODE",{});var Szt=s(bEe);Kfr=r(Szt,"model.train()"),Szt.forEach(t),Gze.forEach(t),egr=i(xa),T(yM.$$.fragment,xa),xa.forEach(t),Nl.forEach(t),Yoo=i(m),Xd=n(m,"H2",{class:!0});var gao=s(Xd);xM=n(gao,"A",{id:!0,class:!0,href:!0});var Rzt=s(xM);vEe=n(Rzt,"SPAN",{});var Pzt=s(vEe);T(N$.$$.fragment,Pzt),Pzt.forEach(t),Rzt.forEach(t),ogr=i(gao),FEe=n(gao,"SPAN",{});var Bzt=s(FEe);rgr=r(Bzt,"AutoModelForNextSentencePrediction"),Bzt.forEach(t),gao.forEach(t),Zoo=i(m),Oo=n(m,"DIV",{class:!0});var ql=s(Oo);T(q$.$$.fragment,ql),tgr=i(ql),zd=n(ql,"P",{});var dde=s(zd);agr=r(dde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),jJ=n(dde,"A",{href:!0});var Izt=s(jJ);ngr=r(Izt,"from_pretrained()"),Izt.forEach(t),sgr=r(dde," class method or the "),DJ=n(dde,"A",{href:!0});var Nzt=s(DJ);lgr=r(Nzt,"from_config()"),Nzt.forEach(t),igr=r(dde,` class
method.`),dde.forEach(t),dgr=i(ql),j$=n(ql,"P",{});var hao=s(j$);cgr=r(hao,"This class cannot be instantiated directly using "),TEe=n(hao,"CODE",{});var qzt=s(TEe);mgr=r(qzt,"__init__()"),qzt.forEach(t),fgr=r(hao," (throws an error)."),hao.forEach(t),ggr=i(ql),At=n(ql,"DIV",{class:!0});var Iy=s(At);T(D$.$$.fragment,Iy),hgr=i(Iy),MEe=n(Iy,"P",{});var jzt=s(MEe);ugr=r(jzt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jzt.forEach(t),pgr=i(Iy),Qd=n(Iy,"P",{});var cde=s(Qd);_gr=r(cde,`Note:
Loading a model from its configuration file does `),EEe=n(cde,"STRONG",{});var Dzt=s(EEe);bgr=r(Dzt,"not"),Dzt.forEach(t),vgr=r(cde,` load the model weights. It only affects the
model\u2019s configuration. Use `),GJ=n(cde,"A",{href:!0});var Gzt=s(GJ);Fgr=r(Gzt,"from_pretrained()"),Gzt.forEach(t),Tgr=r(cde," to load the model weights."),cde.forEach(t),Mgr=i(Iy),T($M.$$.fragment,Iy),Iy.forEach(t),Egr=i(ql),so=n(ql,"DIV",{class:!0});var $a=s(so);T(G$.$$.fragment,$a),Cgr=i($a),CEe=n($a,"P",{});var Ozt=s(CEe);wgr=r(Ozt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Ozt.forEach(t),Agr=i($a),ln=n($a,"P",{});var Ny=s(ln);Lgr=r(Ny,"The model class to instantiate is selected based on the "),wEe=n(Ny,"CODE",{});var Vzt=s(wEe);ygr=r(Vzt,"model_type"),Vzt.forEach(t),xgr=r(Ny,` property of the config object (either
passed as an argument or loaded from `),AEe=n(Ny,"CODE",{});var Xzt=s(AEe);$gr=r(Xzt,"pretrained_model_name_or_path"),Xzt.forEach(t),kgr=r(Ny,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=n(Ny,"CODE",{});var zzt=s(LEe);Sgr=r(zzt,"pretrained_model_name_or_path"),zzt.forEach(t),Rgr=r(Ny,":"),Ny.forEach(t),Pgr=i($a),Ue=n($a,"UL",{});var ft=s(Ue);kM=n(ft,"LI",{});var Oze=s(kM);yEe=n(Oze,"STRONG",{});var Qzt=s(yEe);Bgr=r(Qzt,"bert"),Qzt.forEach(t),Igr=r(Oze," \u2014 "),OJ=n(Oze,"A",{href:!0});var Wzt=s(OJ);Ngr=r(Wzt,"BertForNextSentencePrediction"),Wzt.forEach(t),qgr=r(Oze," (BERT model)"),Oze.forEach(t),jgr=i(ft),SM=n(ft,"LI",{});var Vze=s(SM);xEe=n(Vze,"STRONG",{});var Uzt=s(xEe);Dgr=r(Uzt,"ernie"),Uzt.forEach(t),Ggr=r(Vze," \u2014 "),VJ=n(Vze,"A",{href:!0});var Hzt=s(VJ);Ogr=r(Hzt,"ErnieForNextSentencePrediction"),Hzt.forEach(t),Vgr=r(Vze," (ERNIE model)"),Vze.forEach(t),Xgr=i(ft),RM=n(ft,"LI",{});var Xze=s(RM);$Ee=n(Xze,"STRONG",{});var Jzt=s($Ee);zgr=r(Jzt,"fnet"),Jzt.forEach(t),Qgr=r(Xze," \u2014 "),XJ=n(Xze,"A",{href:!0});var Yzt=s(XJ);Wgr=r(Yzt,"FNetForNextSentencePrediction"),Yzt.forEach(t),Ugr=r(Xze," (FNet model)"),Xze.forEach(t),Hgr=i(ft),PM=n(ft,"LI",{});var zze=s(PM);kEe=n(zze,"STRONG",{});var Zzt=s(kEe);Jgr=r(Zzt,"megatron-bert"),Zzt.forEach(t),Ygr=r(zze," \u2014 "),zJ=n(zze,"A",{href:!0});var Kzt=s(zJ);Zgr=r(Kzt,"MegatronBertForNextSentencePrediction"),Kzt.forEach(t),Kgr=r(zze," (Megatron-BERT model)"),zze.forEach(t),ehr=i(ft),BM=n(ft,"LI",{});var Qze=s(BM);SEe=n(Qze,"STRONG",{});var eQt=s(SEe);ohr=r(eQt,"mobilebert"),eQt.forEach(t),rhr=r(Qze," \u2014 "),QJ=n(Qze,"A",{href:!0});var oQt=s(QJ);thr=r(oQt,"MobileBertForNextSentencePrediction"),oQt.forEach(t),ahr=r(Qze," (MobileBERT model)"),Qze.forEach(t),nhr=i(ft),IM=n(ft,"LI",{});var Wze=s(IM);REe=n(Wze,"STRONG",{});var rQt=s(REe);shr=r(rQt,"nezha"),rQt.forEach(t),lhr=r(Wze," \u2014 "),WJ=n(Wze,"A",{href:!0});var tQt=s(WJ);ihr=r(tQt,"NezhaForNextSentencePrediction"),tQt.forEach(t),dhr=r(Wze," (Nezha model)"),Wze.forEach(t),chr=i(ft),NM=n(ft,"LI",{});var Uze=s(NM);PEe=n(Uze,"STRONG",{});var aQt=s(PEe);mhr=r(aQt,"qdqbert"),aQt.forEach(t),fhr=r(Uze," \u2014 "),UJ=n(Uze,"A",{href:!0});var nQt=s(UJ);ghr=r(nQt,"QDQBertForNextSentencePrediction"),nQt.forEach(t),hhr=r(Uze," (QDQBert model)"),Uze.forEach(t),ft.forEach(t),uhr=i($a),qM=n($a,"P",{});var Hze=s(qM);phr=r(Hze,"The model is set in evaluation mode by default using "),BEe=n(Hze,"CODE",{});var sQt=s(BEe);_hr=r(sQt,"model.eval()"),sQt.forEach(t),bhr=r(Hze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),IEe=n(Hze,"CODE",{});var lQt=s(IEe);vhr=r(lQt,"model.train()"),lQt.forEach(t),Hze.forEach(t),Fhr=i($a),T(jM.$$.fragment,$a),$a.forEach(t),ql.forEach(t),Koo=i(m),Wd=n(m,"H2",{class:!0});var uao=s(Wd);DM=n(uao,"A",{id:!0,class:!0,href:!0});var iQt=s(DM);NEe=n(iQt,"SPAN",{});var dQt=s(NEe);T(O$.$$.fragment,dQt),dQt.forEach(t),iQt.forEach(t),Thr=i(uao),qEe=n(uao,"SPAN",{});var cQt=s(qEe);Mhr=r(cQt,"AutoModelForTokenClassification"),cQt.forEach(t),uao.forEach(t),ero=i(m),Vo=n(m,"DIV",{class:!0});var jl=s(Vo);T(V$.$$.fragment,jl),Ehr=i(jl),Ud=n(jl,"P",{});var mde=s(Ud);Chr=r(mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HJ=n(mde,"A",{href:!0});var mQt=s(HJ);whr=r(mQt,"from_pretrained()"),mQt.forEach(t),Ahr=r(mde," class method or the "),JJ=n(mde,"A",{href:!0});var fQt=s(JJ);Lhr=r(fQt,"from_config()"),fQt.forEach(t),yhr=r(mde,` class
method.`),mde.forEach(t),xhr=i(jl),X$=n(jl,"P",{});var pao=s(X$);$hr=r(pao,"This class cannot be instantiated directly using "),jEe=n(pao,"CODE",{});var gQt=s(jEe);khr=r(gQt,"__init__()"),gQt.forEach(t),Shr=r(pao," (throws an error)."),pao.forEach(t),Rhr=i(jl),Lt=n(jl,"DIV",{class:!0});var qy=s(Lt);T(z$.$$.fragment,qy),Phr=i(qy),DEe=n(qy,"P",{});var hQt=s(DEe);Bhr=r(hQt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),hQt.forEach(t),Ihr=i(qy),Hd=n(qy,"P",{});var fde=s(Hd);Nhr=r(fde,`Note:
Loading a model from its configuration file does `),GEe=n(fde,"STRONG",{});var uQt=s(GEe);qhr=r(uQt,"not"),uQt.forEach(t),jhr=r(fde,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(fde,"A",{href:!0});var pQt=s(YJ);Dhr=r(pQt,"from_pretrained()"),pQt.forEach(t),Ghr=r(fde," to load the model weights."),fde.forEach(t),Ohr=i(qy),T(GM.$$.fragment,qy),qy.forEach(t),Vhr=i(jl),lo=n(jl,"DIV",{class:!0});var ka=s(lo);T(Q$.$$.fragment,ka),Xhr=i(ka),OEe=n(ka,"P",{});var _Qt=s(OEe);zhr=r(_Qt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),_Qt.forEach(t),Qhr=i(ka),dn=n(ka,"P",{});var jy=s(dn);Whr=r(jy,"The model class to instantiate is selected based on the "),VEe=n(jy,"CODE",{});var bQt=s(VEe);Uhr=r(bQt,"model_type"),bQt.forEach(t),Hhr=r(jy,` property of the config object (either
passed as an argument or loaded from `),XEe=n(jy,"CODE",{});var vQt=s(XEe);Jhr=r(vQt,"pretrained_model_name_or_path"),vQt.forEach(t),Yhr=r(jy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zEe=n(jy,"CODE",{});var FQt=s(zEe);Zhr=r(FQt,"pretrained_model_name_or_path"),FQt.forEach(t),Khr=r(jy,":"),jy.forEach(t),eur=i(ka),H=n(ka,"UL",{});var Y=s(H);OM=n(Y,"LI",{});var Jze=s(OM);QEe=n(Jze,"STRONG",{});var TQt=s(QEe);our=r(TQt,"albert"),TQt.forEach(t),rur=r(Jze," \u2014 "),ZJ=n(Jze,"A",{href:!0});var MQt=s(ZJ);tur=r(MQt,"AlbertForTokenClassification"),MQt.forEach(t),aur=r(Jze," (ALBERT model)"),Jze.forEach(t),nur=i(Y),VM=n(Y,"LI",{});var Yze=s(VM);WEe=n(Yze,"STRONG",{});var EQt=s(WEe);sur=r(EQt,"bert"),EQt.forEach(t),lur=r(Yze," \u2014 "),KJ=n(Yze,"A",{href:!0});var CQt=s(KJ);iur=r(CQt,"BertForTokenClassification"),CQt.forEach(t),dur=r(Yze," (BERT model)"),Yze.forEach(t),cur=i(Y),XM=n(Y,"LI",{});var Zze=s(XM);UEe=n(Zze,"STRONG",{});var wQt=s(UEe);mur=r(wQt,"big_bird"),wQt.forEach(t),fur=r(Zze," \u2014 "),eY=n(Zze,"A",{href:!0});var AQt=s(eY);gur=r(AQt,"BigBirdForTokenClassification"),AQt.forEach(t),hur=r(Zze," (BigBird model)"),Zze.forEach(t),uur=i(Y),zM=n(Y,"LI",{});var Kze=s(zM);HEe=n(Kze,"STRONG",{});var LQt=s(HEe);pur=r(LQt,"bloom"),LQt.forEach(t),_ur=r(Kze," \u2014 "),oY=n(Kze,"A",{href:!0});var yQt=s(oY);bur=r(yQt,"BloomForTokenClassification"),yQt.forEach(t),vur=r(Kze," (BLOOM model)"),Kze.forEach(t),Fur=i(Y),QM=n(Y,"LI",{});var eQe=s(QM);JEe=n(eQe,"STRONG",{});var xQt=s(JEe);Tur=r(xQt,"camembert"),xQt.forEach(t),Mur=r(eQe," \u2014 "),rY=n(eQe,"A",{href:!0});var $Qt=s(rY);Eur=r($Qt,"CamembertForTokenClassification"),$Qt.forEach(t),Cur=r(eQe," (CamemBERT model)"),eQe.forEach(t),wur=i(Y),WM=n(Y,"LI",{});var oQe=s(WM);YEe=n(oQe,"STRONG",{});var kQt=s(YEe);Aur=r(kQt,"canine"),kQt.forEach(t),Lur=r(oQe," \u2014 "),tY=n(oQe,"A",{href:!0});var SQt=s(tY);yur=r(SQt,"CanineForTokenClassification"),SQt.forEach(t),xur=r(oQe," (CANINE model)"),oQe.forEach(t),$ur=i(Y),UM=n(Y,"LI",{});var rQe=s(UM);ZEe=n(rQe,"STRONG",{});var RQt=s(ZEe);kur=r(RQt,"convbert"),RQt.forEach(t),Sur=r(rQe," \u2014 "),aY=n(rQe,"A",{href:!0});var PQt=s(aY);Rur=r(PQt,"ConvBertForTokenClassification"),PQt.forEach(t),Pur=r(rQe," (ConvBERT model)"),rQe.forEach(t),Bur=i(Y),HM=n(Y,"LI",{});var tQe=s(HM);KEe=n(tQe,"STRONG",{});var BQt=s(KEe);Iur=r(BQt,"data2vec-text"),BQt.forEach(t),Nur=r(tQe," \u2014 "),nY=n(tQe,"A",{href:!0});var IQt=s(nY);qur=r(IQt,"Data2VecTextForTokenClassification"),IQt.forEach(t),jur=r(tQe," (Data2VecText model)"),tQe.forEach(t),Dur=i(Y),JM=n(Y,"LI",{});var aQe=s(JM);e4e=n(aQe,"STRONG",{});var NQt=s(e4e);Gur=r(NQt,"deberta"),NQt.forEach(t),Our=r(aQe," \u2014 "),sY=n(aQe,"A",{href:!0});var qQt=s(sY);Vur=r(qQt,"DebertaForTokenClassification"),qQt.forEach(t),Xur=r(aQe," (DeBERTa model)"),aQe.forEach(t),zur=i(Y),YM=n(Y,"LI",{});var nQe=s(YM);o4e=n(nQe,"STRONG",{});var jQt=s(o4e);Qur=r(jQt,"deberta-v2"),jQt.forEach(t),Wur=r(nQe," \u2014 "),lY=n(nQe,"A",{href:!0});var DQt=s(lY);Uur=r(DQt,"DebertaV2ForTokenClassification"),DQt.forEach(t),Hur=r(nQe," (DeBERTa-v2 model)"),nQe.forEach(t),Jur=i(Y),ZM=n(Y,"LI",{});var sQe=s(ZM);r4e=n(sQe,"STRONG",{});var GQt=s(r4e);Yur=r(GQt,"distilbert"),GQt.forEach(t),Zur=r(sQe," \u2014 "),iY=n(sQe,"A",{href:!0});var OQt=s(iY);Kur=r(OQt,"DistilBertForTokenClassification"),OQt.forEach(t),epr=r(sQe," (DistilBERT model)"),sQe.forEach(t),opr=i(Y),KM=n(Y,"LI",{});var lQe=s(KM);t4e=n(lQe,"STRONG",{});var VQt=s(t4e);rpr=r(VQt,"electra"),VQt.forEach(t),tpr=r(lQe," \u2014 "),dY=n(lQe,"A",{href:!0});var XQt=s(dY);apr=r(XQt,"ElectraForTokenClassification"),XQt.forEach(t),npr=r(lQe," (ELECTRA model)"),lQe.forEach(t),spr=i(Y),eE=n(Y,"LI",{});var iQe=s(eE);a4e=n(iQe,"STRONG",{});var zQt=s(a4e);lpr=r(zQt,"ernie"),zQt.forEach(t),ipr=r(iQe," \u2014 "),cY=n(iQe,"A",{href:!0});var QQt=s(cY);dpr=r(QQt,"ErnieForTokenClassification"),QQt.forEach(t),cpr=r(iQe," (ERNIE model)"),iQe.forEach(t),mpr=i(Y),oE=n(Y,"LI",{});var dQe=s(oE);n4e=n(dQe,"STRONG",{});var WQt=s(n4e);fpr=r(WQt,"esm"),WQt.forEach(t),gpr=r(dQe," \u2014 "),mY=n(dQe,"A",{href:!0});var UQt=s(mY);hpr=r(UQt,"EsmForTokenClassification"),UQt.forEach(t),upr=r(dQe," (ESM model)"),dQe.forEach(t),ppr=i(Y),rE=n(Y,"LI",{});var cQe=s(rE);s4e=n(cQe,"STRONG",{});var HQt=s(s4e);_pr=r(HQt,"flaubert"),HQt.forEach(t),bpr=r(cQe," \u2014 "),fY=n(cQe,"A",{href:!0});var JQt=s(fY);vpr=r(JQt,"FlaubertForTokenClassification"),JQt.forEach(t),Fpr=r(cQe," (FlauBERT model)"),cQe.forEach(t),Tpr=i(Y),tE=n(Y,"LI",{});var mQe=s(tE);l4e=n(mQe,"STRONG",{});var YQt=s(l4e);Mpr=r(YQt,"fnet"),YQt.forEach(t),Epr=r(mQe," \u2014 "),gY=n(mQe,"A",{href:!0});var ZQt=s(gY);Cpr=r(ZQt,"FNetForTokenClassification"),ZQt.forEach(t),wpr=r(mQe," (FNet model)"),mQe.forEach(t),Apr=i(Y),aE=n(Y,"LI",{});var fQe=s(aE);i4e=n(fQe,"STRONG",{});var KQt=s(i4e);Lpr=r(KQt,"funnel"),KQt.forEach(t),ypr=r(fQe," \u2014 "),hY=n(fQe,"A",{href:!0});var eWt=s(hY);xpr=r(eWt,"FunnelForTokenClassification"),eWt.forEach(t),$pr=r(fQe," (Funnel Transformer model)"),fQe.forEach(t),kpr=i(Y),nE=n(Y,"LI",{});var gQe=s(nE);d4e=n(gQe,"STRONG",{});var oWt=s(d4e);Spr=r(oWt,"gpt2"),oWt.forEach(t),Rpr=r(gQe," \u2014 "),uY=n(gQe,"A",{href:!0});var rWt=s(uY);Ppr=r(rWt,"GPT2ForTokenClassification"),rWt.forEach(t),Bpr=r(gQe," (OpenAI GPT-2 model)"),gQe.forEach(t),Ipr=i(Y),sE=n(Y,"LI",{});var hQe=s(sE);c4e=n(hQe,"STRONG",{});var tWt=s(c4e);Npr=r(tWt,"ibert"),tWt.forEach(t),qpr=r(hQe," \u2014 "),pY=n(hQe,"A",{href:!0});var aWt=s(pY);jpr=r(aWt,"IBertForTokenClassification"),aWt.forEach(t),Dpr=r(hQe," (I-BERT model)"),hQe.forEach(t),Gpr=i(Y),lE=n(Y,"LI",{});var uQe=s(lE);m4e=n(uQe,"STRONG",{});var nWt=s(m4e);Opr=r(nWt,"layoutlm"),nWt.forEach(t),Vpr=r(uQe," \u2014 "),_Y=n(uQe,"A",{href:!0});var sWt=s(_Y);Xpr=r(sWt,"LayoutLMForTokenClassification"),sWt.forEach(t),zpr=r(uQe," (LayoutLM model)"),uQe.forEach(t),Qpr=i(Y),iE=n(Y,"LI",{});var pQe=s(iE);f4e=n(pQe,"STRONG",{});var lWt=s(f4e);Wpr=r(lWt,"layoutlmv2"),lWt.forEach(t),Upr=r(pQe," \u2014 "),bY=n(pQe,"A",{href:!0});var iWt=s(bY);Hpr=r(iWt,"LayoutLMv2ForTokenClassification"),iWt.forEach(t),Jpr=r(pQe," (LayoutLMv2 model)"),pQe.forEach(t),Ypr=i(Y),dE=n(Y,"LI",{});var _Qe=s(dE);g4e=n(_Qe,"STRONG",{});var dWt=s(g4e);Zpr=r(dWt,"layoutlmv3"),dWt.forEach(t),Kpr=r(_Qe," \u2014 "),vY=n(_Qe,"A",{href:!0});var cWt=s(vY);e_r=r(cWt,"LayoutLMv3ForTokenClassification"),cWt.forEach(t),o_r=r(_Qe," (LayoutLMv3 model)"),_Qe.forEach(t),r_r=i(Y),cE=n(Y,"LI",{});var bQe=s(cE);h4e=n(bQe,"STRONG",{});var mWt=s(h4e);t_r=r(mWt,"longformer"),mWt.forEach(t),a_r=r(bQe," \u2014 "),FY=n(bQe,"A",{href:!0});var fWt=s(FY);n_r=r(fWt,"LongformerForTokenClassification"),fWt.forEach(t),s_r=r(bQe," (Longformer model)"),bQe.forEach(t),l_r=i(Y),mE=n(Y,"LI",{});var vQe=s(mE);u4e=n(vQe,"STRONG",{});var gWt=s(u4e);i_r=r(gWt,"luke"),gWt.forEach(t),d_r=r(vQe," \u2014 "),TY=n(vQe,"A",{href:!0});var hWt=s(TY);c_r=r(hWt,"LukeForTokenClassification"),hWt.forEach(t),m_r=r(vQe," (LUKE model)"),vQe.forEach(t),f_r=i(Y),fE=n(Y,"LI",{});var FQe=s(fE);p4e=n(FQe,"STRONG",{});var uWt=s(p4e);g_r=r(uWt,"markuplm"),uWt.forEach(t),h_r=r(FQe," \u2014 "),MY=n(FQe,"A",{href:!0});var pWt=s(MY);u_r=r(pWt,"MarkupLMForTokenClassification"),pWt.forEach(t),p_r=r(FQe," (MarkupLM model)"),FQe.forEach(t),__r=i(Y),gE=n(Y,"LI",{});var TQe=s(gE);_4e=n(TQe,"STRONG",{});var _Wt=s(_4e);b_r=r(_Wt,"megatron-bert"),_Wt.forEach(t),v_r=r(TQe," \u2014 "),EY=n(TQe,"A",{href:!0});var bWt=s(EY);F_r=r(bWt,"MegatronBertForTokenClassification"),bWt.forEach(t),T_r=r(TQe," (Megatron-BERT model)"),TQe.forEach(t),M_r=i(Y),hE=n(Y,"LI",{});var MQe=s(hE);b4e=n(MQe,"STRONG",{});var vWt=s(b4e);E_r=r(vWt,"mobilebert"),vWt.forEach(t),C_r=r(MQe," \u2014 "),CY=n(MQe,"A",{href:!0});var FWt=s(CY);w_r=r(FWt,"MobileBertForTokenClassification"),FWt.forEach(t),A_r=r(MQe," (MobileBERT model)"),MQe.forEach(t),L_r=i(Y),uE=n(Y,"LI",{});var EQe=s(uE);v4e=n(EQe,"STRONG",{});var TWt=s(v4e);y_r=r(TWt,"mpnet"),TWt.forEach(t),x_r=r(EQe," \u2014 "),wY=n(EQe,"A",{href:!0});var MWt=s(wY);$_r=r(MWt,"MPNetForTokenClassification"),MWt.forEach(t),k_r=r(EQe," (MPNet model)"),EQe.forEach(t),S_r=i(Y),pE=n(Y,"LI",{});var CQe=s(pE);F4e=n(CQe,"STRONG",{});var EWt=s(F4e);R_r=r(EWt,"nezha"),EWt.forEach(t),P_r=r(CQe," \u2014 "),AY=n(CQe,"A",{href:!0});var CWt=s(AY);B_r=r(CWt,"NezhaForTokenClassification"),CWt.forEach(t),I_r=r(CQe," (Nezha model)"),CQe.forEach(t),N_r=i(Y),_E=n(Y,"LI",{});var wQe=s(_E);T4e=n(wQe,"STRONG",{});var wWt=s(T4e);q_r=r(wWt,"nystromformer"),wWt.forEach(t),j_r=r(wQe," \u2014 "),LY=n(wQe,"A",{href:!0});var AWt=s(LY);D_r=r(AWt,"NystromformerForTokenClassification"),AWt.forEach(t),G_r=r(wQe," (Nystr\xF6mformer model)"),wQe.forEach(t),O_r=i(Y),bE=n(Y,"LI",{});var AQe=s(bE);M4e=n(AQe,"STRONG",{});var LWt=s(M4e);V_r=r(LWt,"qdqbert"),LWt.forEach(t),X_r=r(AQe," \u2014 "),yY=n(AQe,"A",{href:!0});var yWt=s(yY);z_r=r(yWt,"QDQBertForTokenClassification"),yWt.forEach(t),Q_r=r(AQe," (QDQBert model)"),AQe.forEach(t),W_r=i(Y),vE=n(Y,"LI",{});var LQe=s(vE);E4e=n(LQe,"STRONG",{});var xWt=s(E4e);U_r=r(xWt,"rembert"),xWt.forEach(t),H_r=r(LQe," \u2014 "),xY=n(LQe,"A",{href:!0});var $Wt=s(xY);J_r=r($Wt,"RemBertForTokenClassification"),$Wt.forEach(t),Y_r=r(LQe," (RemBERT model)"),LQe.forEach(t),Z_r=i(Y),FE=n(Y,"LI",{});var yQe=s(FE);C4e=n(yQe,"STRONG",{});var kWt=s(C4e);K_r=r(kWt,"roberta"),kWt.forEach(t),e1r=r(yQe," \u2014 "),$Y=n(yQe,"A",{href:!0});var SWt=s($Y);o1r=r(SWt,"RobertaForTokenClassification"),SWt.forEach(t),r1r=r(yQe," (RoBERTa model)"),yQe.forEach(t),t1r=i(Y),TE=n(Y,"LI",{});var xQe=s(TE);w4e=n(xQe,"STRONG",{});var RWt=s(w4e);a1r=r(RWt,"roformer"),RWt.forEach(t),n1r=r(xQe," \u2014 "),kY=n(xQe,"A",{href:!0});var PWt=s(kY);s1r=r(PWt,"RoFormerForTokenClassification"),PWt.forEach(t),l1r=r(xQe," (RoFormer model)"),xQe.forEach(t),i1r=i(Y),ME=n(Y,"LI",{});var $Qe=s(ME);A4e=n($Qe,"STRONG",{});var BWt=s(A4e);d1r=r(BWt,"squeezebert"),BWt.forEach(t),c1r=r($Qe," \u2014 "),SY=n($Qe,"A",{href:!0});var IWt=s(SY);m1r=r(IWt,"SqueezeBertForTokenClassification"),IWt.forEach(t),f1r=r($Qe," (SqueezeBERT model)"),$Qe.forEach(t),g1r=i(Y),EE=n(Y,"LI",{});var kQe=s(EE);L4e=n(kQe,"STRONG",{});var NWt=s(L4e);h1r=r(NWt,"xlm"),NWt.forEach(t),u1r=r(kQe," \u2014 "),RY=n(kQe,"A",{href:!0});var qWt=s(RY);p1r=r(qWt,"XLMForTokenClassification"),qWt.forEach(t),_1r=r(kQe," (XLM model)"),kQe.forEach(t),b1r=i(Y),CE=n(Y,"LI",{});var SQe=s(CE);y4e=n(SQe,"STRONG",{});var jWt=s(y4e);v1r=r(jWt,"xlm-roberta"),jWt.forEach(t),F1r=r(SQe," \u2014 "),PY=n(SQe,"A",{href:!0});var DWt=s(PY);T1r=r(DWt,"XLMRobertaForTokenClassification"),DWt.forEach(t),M1r=r(SQe," (XLM-RoBERTa model)"),SQe.forEach(t),E1r=i(Y),wE=n(Y,"LI",{});var RQe=s(wE);x4e=n(RQe,"STRONG",{});var GWt=s(x4e);C1r=r(GWt,"xlm-roberta-xl"),GWt.forEach(t),w1r=r(RQe," \u2014 "),BY=n(RQe,"A",{href:!0});var OWt=s(BY);A1r=r(OWt,"XLMRobertaXLForTokenClassification"),OWt.forEach(t),L1r=r(RQe," (XLM-RoBERTa-XL model)"),RQe.forEach(t),y1r=i(Y),AE=n(Y,"LI",{});var PQe=s(AE);$4e=n(PQe,"STRONG",{});var VWt=s($4e);x1r=r(VWt,"xlnet"),VWt.forEach(t),$1r=r(PQe," \u2014 "),IY=n(PQe,"A",{href:!0});var XWt=s(IY);k1r=r(XWt,"XLNetForTokenClassification"),XWt.forEach(t),S1r=r(PQe," (XLNet model)"),PQe.forEach(t),R1r=i(Y),LE=n(Y,"LI",{});var BQe=s(LE);k4e=n(BQe,"STRONG",{});var zWt=s(k4e);P1r=r(zWt,"yoso"),zWt.forEach(t),B1r=r(BQe," \u2014 "),NY=n(BQe,"A",{href:!0});var QWt=s(NY);I1r=r(QWt,"YosoForTokenClassification"),QWt.forEach(t),N1r=r(BQe," (YOSO model)"),BQe.forEach(t),Y.forEach(t),q1r=i(ka),yE=n(ka,"P",{});var IQe=s(yE);j1r=r(IQe,"The model is set in evaluation mode by default using "),S4e=n(IQe,"CODE",{});var WWt=s(S4e);D1r=r(WWt,"model.eval()"),WWt.forEach(t),G1r=r(IQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R4e=n(IQe,"CODE",{});var UWt=s(R4e);O1r=r(UWt,"model.train()"),UWt.forEach(t),IQe.forEach(t),V1r=i(ka),T(xE.$$.fragment,ka),ka.forEach(t),jl.forEach(t),oro=i(m),Jd=n(m,"H2",{class:!0});var _ao=s(Jd);$E=n(_ao,"A",{id:!0,class:!0,href:!0});var HWt=s($E);P4e=n(HWt,"SPAN",{});var JWt=s(P4e);T(W$.$$.fragment,JWt),JWt.forEach(t),HWt.forEach(t),X1r=i(_ao),B4e=n(_ao,"SPAN",{});var YWt=s(B4e);z1r=r(YWt,"AutoModelForQuestionAnswering"),YWt.forEach(t),_ao.forEach(t),rro=i(m),Xo=n(m,"DIV",{class:!0});var Dl=s(Xo);T(U$.$$.fragment,Dl),Q1r=i(Dl),Yd=n(Dl,"P",{});var gde=s(Yd);W1r=r(gde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qY=n(gde,"A",{href:!0});var ZWt=s(qY);U1r=r(ZWt,"from_pretrained()"),ZWt.forEach(t),H1r=r(gde," class method or the "),jY=n(gde,"A",{href:!0});var KWt=s(jY);J1r=r(KWt,"from_config()"),KWt.forEach(t),Y1r=r(gde,` class
method.`),gde.forEach(t),Z1r=i(Dl),H$=n(Dl,"P",{});var bao=s(H$);K1r=r(bao,"This class cannot be instantiated directly using "),I4e=n(bao,"CODE",{});var eUt=s(I4e);e2r=r(eUt,"__init__()"),eUt.forEach(t),o2r=r(bao," (throws an error)."),bao.forEach(t),r2r=i(Dl),yt=n(Dl,"DIV",{class:!0});var Dy=s(yt);T(J$.$$.fragment,Dy),t2r=i(Dy),N4e=n(Dy,"P",{});var oUt=s(N4e);a2r=r(oUt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),oUt.forEach(t),n2r=i(Dy),Zd=n(Dy,"P",{});var hde=s(Zd);s2r=r(hde,`Note:
Loading a model from its configuration file does `),q4e=n(hde,"STRONG",{});var rUt=s(q4e);l2r=r(rUt,"not"),rUt.forEach(t),i2r=r(hde,` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=n(hde,"A",{href:!0});var tUt=s(DY);d2r=r(tUt,"from_pretrained()"),tUt.forEach(t),c2r=r(hde," to load the model weights."),hde.forEach(t),m2r=i(Dy),T(kE.$$.fragment,Dy),Dy.forEach(t),f2r=i(Dl),io=n(Dl,"DIV",{class:!0});var Sa=s(io);T(Y$.$$.fragment,Sa),g2r=i(Sa),j4e=n(Sa,"P",{});var aUt=s(j4e);h2r=r(aUt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),aUt.forEach(t),u2r=i(Sa),cn=n(Sa,"P",{});var Gy=s(cn);p2r=r(Gy,"The model class to instantiate is selected based on the "),D4e=n(Gy,"CODE",{});var nUt=s(D4e);_2r=r(nUt,"model_type"),nUt.forEach(t),b2r=r(Gy,` property of the config object (either
passed as an argument or loaded from `),G4e=n(Gy,"CODE",{});var sUt=s(G4e);v2r=r(sUt,"pretrained_model_name_or_path"),sUt.forEach(t),F2r=r(Gy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O4e=n(Gy,"CODE",{});var lUt=s(O4e);T2r=r(lUt,"pretrained_model_name_or_path"),lUt.forEach(t),M2r=r(Gy,":"),Gy.forEach(t),E2r=i(Sa),O=n(Sa,"UL",{});var X=s(O);SE=n(X,"LI",{});var NQe=s(SE);V4e=n(NQe,"STRONG",{});var iUt=s(V4e);C2r=r(iUt,"albert"),iUt.forEach(t),w2r=r(NQe," \u2014 "),GY=n(NQe,"A",{href:!0});var dUt=s(GY);A2r=r(dUt,"AlbertForQuestionAnswering"),dUt.forEach(t),L2r=r(NQe," (ALBERT model)"),NQe.forEach(t),y2r=i(X),RE=n(X,"LI",{});var qQe=s(RE);X4e=n(qQe,"STRONG",{});var cUt=s(X4e);x2r=r(cUt,"bart"),cUt.forEach(t),$2r=r(qQe," \u2014 "),OY=n(qQe,"A",{href:!0});var mUt=s(OY);k2r=r(mUt,"BartForQuestionAnswering"),mUt.forEach(t),S2r=r(qQe," (BART model)"),qQe.forEach(t),R2r=i(X),PE=n(X,"LI",{});var jQe=s(PE);z4e=n(jQe,"STRONG",{});var fUt=s(z4e);P2r=r(fUt,"bert"),fUt.forEach(t),B2r=r(jQe," \u2014 "),VY=n(jQe,"A",{href:!0});var gUt=s(VY);I2r=r(gUt,"BertForQuestionAnswering"),gUt.forEach(t),N2r=r(jQe," (BERT model)"),jQe.forEach(t),q2r=i(X),BE=n(X,"LI",{});var DQe=s(BE);Q4e=n(DQe,"STRONG",{});var hUt=s(Q4e);j2r=r(hUt,"big_bird"),hUt.forEach(t),D2r=r(DQe," \u2014 "),XY=n(DQe,"A",{href:!0});var uUt=s(XY);G2r=r(uUt,"BigBirdForQuestionAnswering"),uUt.forEach(t),O2r=r(DQe," (BigBird model)"),DQe.forEach(t),V2r=i(X),IE=n(X,"LI",{});var GQe=s(IE);W4e=n(GQe,"STRONG",{});var pUt=s(W4e);X2r=r(pUt,"bigbird_pegasus"),pUt.forEach(t),z2r=r(GQe," \u2014 "),zY=n(GQe,"A",{href:!0});var _Ut=s(zY);Q2r=r(_Ut,"BigBirdPegasusForQuestionAnswering"),_Ut.forEach(t),W2r=r(GQe," (BigBird-Pegasus model)"),GQe.forEach(t),U2r=i(X),NE=n(X,"LI",{});var OQe=s(NE);U4e=n(OQe,"STRONG",{});var bUt=s(U4e);H2r=r(bUt,"bloom"),bUt.forEach(t),J2r=r(OQe," \u2014 "),QY=n(OQe,"A",{href:!0});var vUt=s(QY);Y2r=r(vUt,"BloomForQuestionAnswering"),vUt.forEach(t),Z2r=r(OQe," (BLOOM model)"),OQe.forEach(t),K2r=i(X),qE=n(X,"LI",{});var VQe=s(qE);H4e=n(VQe,"STRONG",{});var FUt=s(H4e);ebr=r(FUt,"camembert"),FUt.forEach(t),obr=r(VQe," \u2014 "),WY=n(VQe,"A",{href:!0});var TUt=s(WY);rbr=r(TUt,"CamembertForQuestionAnswering"),TUt.forEach(t),tbr=r(VQe," (CamemBERT model)"),VQe.forEach(t),abr=i(X),jE=n(X,"LI",{});var XQe=s(jE);J4e=n(XQe,"STRONG",{});var MUt=s(J4e);nbr=r(MUt,"canine"),MUt.forEach(t),sbr=r(XQe," \u2014 "),UY=n(XQe,"A",{href:!0});var EUt=s(UY);lbr=r(EUt,"CanineForQuestionAnswering"),EUt.forEach(t),ibr=r(XQe," (CANINE model)"),XQe.forEach(t),dbr=i(X),DE=n(X,"LI",{});var zQe=s(DE);Y4e=n(zQe,"STRONG",{});var CUt=s(Y4e);cbr=r(CUt,"convbert"),CUt.forEach(t),mbr=r(zQe," \u2014 "),HY=n(zQe,"A",{href:!0});var wUt=s(HY);fbr=r(wUt,"ConvBertForQuestionAnswering"),wUt.forEach(t),gbr=r(zQe," (ConvBERT model)"),zQe.forEach(t),hbr=i(X),GE=n(X,"LI",{});var QQe=s(GE);Z4e=n(QQe,"STRONG",{});var AUt=s(Z4e);ubr=r(AUt,"data2vec-text"),AUt.forEach(t),pbr=r(QQe," \u2014 "),JY=n(QQe,"A",{href:!0});var LUt=s(JY);_br=r(LUt,"Data2VecTextForQuestionAnswering"),LUt.forEach(t),bbr=r(QQe," (Data2VecText model)"),QQe.forEach(t),vbr=i(X),OE=n(X,"LI",{});var WQe=s(OE);K4e=n(WQe,"STRONG",{});var yUt=s(K4e);Fbr=r(yUt,"deberta"),yUt.forEach(t),Tbr=r(WQe," \u2014 "),YY=n(WQe,"A",{href:!0});var xUt=s(YY);Mbr=r(xUt,"DebertaForQuestionAnswering"),xUt.forEach(t),Ebr=r(WQe," (DeBERTa model)"),WQe.forEach(t),Cbr=i(X),VE=n(X,"LI",{});var UQe=s(VE);eCe=n(UQe,"STRONG",{});var $Ut=s(eCe);wbr=r($Ut,"deberta-v2"),$Ut.forEach(t),Abr=r(UQe," \u2014 "),ZY=n(UQe,"A",{href:!0});var kUt=s(ZY);Lbr=r(kUt,"DebertaV2ForQuestionAnswering"),kUt.forEach(t),ybr=r(UQe," (DeBERTa-v2 model)"),UQe.forEach(t),xbr=i(X),XE=n(X,"LI",{});var HQe=s(XE);oCe=n(HQe,"STRONG",{});var SUt=s(oCe);$br=r(SUt,"distilbert"),SUt.forEach(t),kbr=r(HQe," \u2014 "),KY=n(HQe,"A",{href:!0});var RUt=s(KY);Sbr=r(RUt,"DistilBertForQuestionAnswering"),RUt.forEach(t),Rbr=r(HQe," (DistilBERT model)"),HQe.forEach(t),Pbr=i(X),zE=n(X,"LI",{});var JQe=s(zE);rCe=n(JQe,"STRONG",{});var PUt=s(rCe);Bbr=r(PUt,"electra"),PUt.forEach(t),Ibr=r(JQe," \u2014 "),eZ=n(JQe,"A",{href:!0});var BUt=s(eZ);Nbr=r(BUt,"ElectraForQuestionAnswering"),BUt.forEach(t),qbr=r(JQe," (ELECTRA model)"),JQe.forEach(t),jbr=i(X),QE=n(X,"LI",{});var YQe=s(QE);tCe=n(YQe,"STRONG",{});var IUt=s(tCe);Dbr=r(IUt,"ernie"),IUt.forEach(t),Gbr=r(YQe," \u2014 "),oZ=n(YQe,"A",{href:!0});var NUt=s(oZ);Obr=r(NUt,"ErnieForQuestionAnswering"),NUt.forEach(t),Vbr=r(YQe," (ERNIE model)"),YQe.forEach(t),Xbr=i(X),WE=n(X,"LI",{});var ZQe=s(WE);aCe=n(ZQe,"STRONG",{});var qUt=s(aCe);zbr=r(qUt,"flaubert"),qUt.forEach(t),Qbr=r(ZQe," \u2014 "),rZ=n(ZQe,"A",{href:!0});var jUt=s(rZ);Wbr=r(jUt,"FlaubertForQuestionAnsweringSimple"),jUt.forEach(t),Ubr=r(ZQe," (FlauBERT model)"),ZQe.forEach(t),Hbr=i(X),UE=n(X,"LI",{});var KQe=s(UE);nCe=n(KQe,"STRONG",{});var DUt=s(nCe);Jbr=r(DUt,"fnet"),DUt.forEach(t),Ybr=r(KQe," \u2014 "),tZ=n(KQe,"A",{href:!0});var GUt=s(tZ);Zbr=r(GUt,"FNetForQuestionAnswering"),GUt.forEach(t),Kbr=r(KQe," (FNet model)"),KQe.forEach(t),evr=i(X),HE=n(X,"LI",{});var eWe=s(HE);sCe=n(eWe,"STRONG",{});var OUt=s(sCe);ovr=r(OUt,"funnel"),OUt.forEach(t),rvr=r(eWe," \u2014 "),aZ=n(eWe,"A",{href:!0});var VUt=s(aZ);tvr=r(VUt,"FunnelForQuestionAnswering"),VUt.forEach(t),avr=r(eWe," (Funnel Transformer model)"),eWe.forEach(t),nvr=i(X),JE=n(X,"LI",{});var oWe=s(JE);lCe=n(oWe,"STRONG",{});var XUt=s(lCe);svr=r(XUt,"gptj"),XUt.forEach(t),lvr=r(oWe," \u2014 "),nZ=n(oWe,"A",{href:!0});var zUt=s(nZ);ivr=r(zUt,"GPTJForQuestionAnswering"),zUt.forEach(t),dvr=r(oWe," (GPT-J model)"),oWe.forEach(t),cvr=i(X),YE=n(X,"LI",{});var rWe=s(YE);iCe=n(rWe,"STRONG",{});var QUt=s(iCe);mvr=r(QUt,"ibert"),QUt.forEach(t),fvr=r(rWe," \u2014 "),sZ=n(rWe,"A",{href:!0});var WUt=s(sZ);gvr=r(WUt,"IBertForQuestionAnswering"),WUt.forEach(t),hvr=r(rWe," (I-BERT model)"),rWe.forEach(t),uvr=i(X),ZE=n(X,"LI",{});var tWe=s(ZE);dCe=n(tWe,"STRONG",{});var UUt=s(dCe);pvr=r(UUt,"layoutlmv2"),UUt.forEach(t),_vr=r(tWe," \u2014 "),lZ=n(tWe,"A",{href:!0});var HUt=s(lZ);bvr=r(HUt,"LayoutLMv2ForQuestionAnswering"),HUt.forEach(t),vvr=r(tWe," (LayoutLMv2 model)"),tWe.forEach(t),Fvr=i(X),KE=n(X,"LI",{});var aWe=s(KE);cCe=n(aWe,"STRONG",{});var JUt=s(cCe);Tvr=r(JUt,"layoutlmv3"),JUt.forEach(t),Mvr=r(aWe," \u2014 "),iZ=n(aWe,"A",{href:!0});var YUt=s(iZ);Evr=r(YUt,"LayoutLMv3ForQuestionAnswering"),YUt.forEach(t),Cvr=r(aWe," (LayoutLMv3 model)"),aWe.forEach(t),wvr=i(X),e4=n(X,"LI",{});var nWe=s(e4);mCe=n(nWe,"STRONG",{});var ZUt=s(mCe);Avr=r(ZUt,"led"),ZUt.forEach(t),Lvr=r(nWe," \u2014 "),dZ=n(nWe,"A",{href:!0});var KUt=s(dZ);yvr=r(KUt,"LEDForQuestionAnswering"),KUt.forEach(t),xvr=r(nWe," (LED model)"),nWe.forEach(t),$vr=i(X),o4=n(X,"LI",{});var sWe=s(o4);fCe=n(sWe,"STRONG",{});var eHt=s(fCe);kvr=r(eHt,"longformer"),eHt.forEach(t),Svr=r(sWe," \u2014 "),cZ=n(sWe,"A",{href:!0});var oHt=s(cZ);Rvr=r(oHt,"LongformerForQuestionAnswering"),oHt.forEach(t),Pvr=r(sWe," (Longformer model)"),sWe.forEach(t),Bvr=i(X),r4=n(X,"LI",{});var lWe=s(r4);gCe=n(lWe,"STRONG",{});var rHt=s(gCe);Ivr=r(rHt,"luke"),rHt.forEach(t),Nvr=r(lWe," \u2014 "),mZ=n(lWe,"A",{href:!0});var tHt=s(mZ);qvr=r(tHt,"LukeForQuestionAnswering"),tHt.forEach(t),jvr=r(lWe," (LUKE model)"),lWe.forEach(t),Dvr=i(X),t4=n(X,"LI",{});var iWe=s(t4);hCe=n(iWe,"STRONG",{});var aHt=s(hCe);Gvr=r(aHt,"lxmert"),aHt.forEach(t),Ovr=r(iWe," \u2014 "),fZ=n(iWe,"A",{href:!0});var nHt=s(fZ);Vvr=r(nHt,"LxmertForQuestionAnswering"),nHt.forEach(t),Xvr=r(iWe," (LXMERT model)"),iWe.forEach(t),zvr=i(X),a4=n(X,"LI",{});var dWe=s(a4);uCe=n(dWe,"STRONG",{});var sHt=s(uCe);Qvr=r(sHt,"markuplm"),sHt.forEach(t),Wvr=r(dWe," \u2014 "),gZ=n(dWe,"A",{href:!0});var lHt=s(gZ);Uvr=r(lHt,"MarkupLMForQuestionAnswering"),lHt.forEach(t),Hvr=r(dWe," (MarkupLM model)"),dWe.forEach(t),Jvr=i(X),n4=n(X,"LI",{});var cWe=s(n4);pCe=n(cWe,"STRONG",{});var iHt=s(pCe);Yvr=r(iHt,"mbart"),iHt.forEach(t),Zvr=r(cWe," \u2014 "),hZ=n(cWe,"A",{href:!0});var dHt=s(hZ);Kvr=r(dHt,"MBartForQuestionAnswering"),dHt.forEach(t),eFr=r(cWe," (mBART model)"),cWe.forEach(t),oFr=i(X),s4=n(X,"LI",{});var mWe=s(s4);_Ce=n(mWe,"STRONG",{});var cHt=s(_Ce);rFr=r(cHt,"megatron-bert"),cHt.forEach(t),tFr=r(mWe," \u2014 "),uZ=n(mWe,"A",{href:!0});var mHt=s(uZ);aFr=r(mHt,"MegatronBertForQuestionAnswering"),mHt.forEach(t),nFr=r(mWe," (Megatron-BERT model)"),mWe.forEach(t),sFr=i(X),l4=n(X,"LI",{});var fWe=s(l4);bCe=n(fWe,"STRONG",{});var fHt=s(bCe);lFr=r(fHt,"mobilebert"),fHt.forEach(t),iFr=r(fWe," \u2014 "),pZ=n(fWe,"A",{href:!0});var gHt=s(pZ);dFr=r(gHt,"MobileBertForQuestionAnswering"),gHt.forEach(t),cFr=r(fWe," (MobileBERT model)"),fWe.forEach(t),mFr=i(X),i4=n(X,"LI",{});var gWe=s(i4);vCe=n(gWe,"STRONG",{});var hHt=s(vCe);fFr=r(hHt,"mpnet"),hHt.forEach(t),gFr=r(gWe," \u2014 "),_Z=n(gWe,"A",{href:!0});var uHt=s(_Z);hFr=r(uHt,"MPNetForQuestionAnswering"),uHt.forEach(t),uFr=r(gWe," (MPNet model)"),gWe.forEach(t),pFr=i(X),d4=n(X,"LI",{});var hWe=s(d4);FCe=n(hWe,"STRONG",{});var pHt=s(FCe);_Fr=r(pHt,"mvp"),pHt.forEach(t),bFr=r(hWe," \u2014 "),bZ=n(hWe,"A",{href:!0});var _Ht=s(bZ);vFr=r(_Ht,"MvpForQuestionAnswering"),_Ht.forEach(t),FFr=r(hWe," (MVP model)"),hWe.forEach(t),TFr=i(X),c4=n(X,"LI",{});var uWe=s(c4);TCe=n(uWe,"STRONG",{});var bHt=s(TCe);MFr=r(bHt,"nezha"),bHt.forEach(t),EFr=r(uWe," \u2014 "),vZ=n(uWe,"A",{href:!0});var vHt=s(vZ);CFr=r(vHt,"NezhaForQuestionAnswering"),vHt.forEach(t),wFr=r(uWe," (Nezha model)"),uWe.forEach(t),AFr=i(X),m4=n(X,"LI",{});var pWe=s(m4);MCe=n(pWe,"STRONG",{});var FHt=s(MCe);LFr=r(FHt,"nystromformer"),FHt.forEach(t),yFr=r(pWe," \u2014 "),FZ=n(pWe,"A",{href:!0});var THt=s(FZ);xFr=r(THt,"NystromformerForQuestionAnswering"),THt.forEach(t),$Fr=r(pWe," (Nystr\xF6mformer model)"),pWe.forEach(t),kFr=i(X),f4=n(X,"LI",{});var _We=s(f4);ECe=n(_We,"STRONG",{});var MHt=s(ECe);SFr=r(MHt,"opt"),MHt.forEach(t),RFr=r(_We," \u2014 "),TZ=n(_We,"A",{href:!0});var EHt=s(TZ);PFr=r(EHt,"OPTForQuestionAnswering"),EHt.forEach(t),BFr=r(_We," (OPT model)"),_We.forEach(t),IFr=i(X),g4=n(X,"LI",{});var bWe=s(g4);CCe=n(bWe,"STRONG",{});var CHt=s(CCe);NFr=r(CHt,"qdqbert"),CHt.forEach(t),qFr=r(bWe," \u2014 "),MZ=n(bWe,"A",{href:!0});var wHt=s(MZ);jFr=r(wHt,"QDQBertForQuestionAnswering"),wHt.forEach(t),DFr=r(bWe," (QDQBert model)"),bWe.forEach(t),GFr=i(X),h4=n(X,"LI",{});var vWe=s(h4);wCe=n(vWe,"STRONG",{});var AHt=s(wCe);OFr=r(AHt,"reformer"),AHt.forEach(t),VFr=r(vWe," \u2014 "),EZ=n(vWe,"A",{href:!0});var LHt=s(EZ);XFr=r(LHt,"ReformerForQuestionAnswering"),LHt.forEach(t),zFr=r(vWe," (Reformer model)"),vWe.forEach(t),QFr=i(X),u4=n(X,"LI",{});var FWe=s(u4);ACe=n(FWe,"STRONG",{});var yHt=s(ACe);WFr=r(yHt,"rembert"),yHt.forEach(t),UFr=r(FWe," \u2014 "),CZ=n(FWe,"A",{href:!0});var xHt=s(CZ);HFr=r(xHt,"RemBertForQuestionAnswering"),xHt.forEach(t),JFr=r(FWe," (RemBERT model)"),FWe.forEach(t),YFr=i(X),p4=n(X,"LI",{});var TWe=s(p4);LCe=n(TWe,"STRONG",{});var $Ht=s(LCe);ZFr=r($Ht,"roberta"),$Ht.forEach(t),KFr=r(TWe," \u2014 "),wZ=n(TWe,"A",{href:!0});var kHt=s(wZ);eTr=r(kHt,"RobertaForQuestionAnswering"),kHt.forEach(t),oTr=r(TWe," (RoBERTa model)"),TWe.forEach(t),rTr=i(X),_4=n(X,"LI",{});var MWe=s(_4);yCe=n(MWe,"STRONG",{});var SHt=s(yCe);tTr=r(SHt,"roformer"),SHt.forEach(t),aTr=r(MWe," \u2014 "),AZ=n(MWe,"A",{href:!0});var RHt=s(AZ);nTr=r(RHt,"RoFormerForQuestionAnswering"),RHt.forEach(t),sTr=r(MWe," (RoFormer model)"),MWe.forEach(t),lTr=i(X),b4=n(X,"LI",{});var EWe=s(b4);xCe=n(EWe,"STRONG",{});var PHt=s(xCe);iTr=r(PHt,"splinter"),PHt.forEach(t),dTr=r(EWe," \u2014 "),LZ=n(EWe,"A",{href:!0});var BHt=s(LZ);cTr=r(BHt,"SplinterForQuestionAnswering"),BHt.forEach(t),mTr=r(EWe," (Splinter model)"),EWe.forEach(t),fTr=i(X),v4=n(X,"LI",{});var CWe=s(v4);$Ce=n(CWe,"STRONG",{});var IHt=s($Ce);gTr=r(IHt,"squeezebert"),IHt.forEach(t),hTr=r(CWe," \u2014 "),yZ=n(CWe,"A",{href:!0});var NHt=s(yZ);uTr=r(NHt,"SqueezeBertForQuestionAnswering"),NHt.forEach(t),pTr=r(CWe," (SqueezeBERT model)"),CWe.forEach(t),_Tr=i(X),F4=n(X,"LI",{});var wWe=s(F4);kCe=n(wWe,"STRONG",{});var qHt=s(kCe);bTr=r(qHt,"xlm"),qHt.forEach(t),vTr=r(wWe," \u2014 "),xZ=n(wWe,"A",{href:!0});var jHt=s(xZ);FTr=r(jHt,"XLMForQuestionAnsweringSimple"),jHt.forEach(t),TTr=r(wWe," (XLM model)"),wWe.forEach(t),MTr=i(X),T4=n(X,"LI",{});var AWe=s(T4);SCe=n(AWe,"STRONG",{});var DHt=s(SCe);ETr=r(DHt,"xlm-roberta"),DHt.forEach(t),CTr=r(AWe," \u2014 "),$Z=n(AWe,"A",{href:!0});var GHt=s($Z);wTr=r(GHt,"XLMRobertaForQuestionAnswering"),GHt.forEach(t),ATr=r(AWe," (XLM-RoBERTa model)"),AWe.forEach(t),LTr=i(X),M4=n(X,"LI",{});var LWe=s(M4);RCe=n(LWe,"STRONG",{});var OHt=s(RCe);yTr=r(OHt,"xlm-roberta-xl"),OHt.forEach(t),xTr=r(LWe," \u2014 "),kZ=n(LWe,"A",{href:!0});var VHt=s(kZ);$Tr=r(VHt,"XLMRobertaXLForQuestionAnswering"),VHt.forEach(t),kTr=r(LWe," (XLM-RoBERTa-XL model)"),LWe.forEach(t),STr=i(X),E4=n(X,"LI",{});var yWe=s(E4);PCe=n(yWe,"STRONG",{});var XHt=s(PCe);RTr=r(XHt,"xlnet"),XHt.forEach(t),PTr=r(yWe," \u2014 "),SZ=n(yWe,"A",{href:!0});var zHt=s(SZ);BTr=r(zHt,"XLNetForQuestionAnsweringSimple"),zHt.forEach(t),ITr=r(yWe," (XLNet model)"),yWe.forEach(t),NTr=i(X),C4=n(X,"LI",{});var xWe=s(C4);BCe=n(xWe,"STRONG",{});var QHt=s(BCe);qTr=r(QHt,"yoso"),QHt.forEach(t),jTr=r(xWe," \u2014 "),RZ=n(xWe,"A",{href:!0});var WHt=s(RZ);DTr=r(WHt,"YosoForQuestionAnswering"),WHt.forEach(t),GTr=r(xWe," (YOSO model)"),xWe.forEach(t),X.forEach(t),OTr=i(Sa),w4=n(Sa,"P",{});var $We=s(w4);VTr=r($We,"The model is set in evaluation mode by default using "),ICe=n($We,"CODE",{});var UHt=s(ICe);XTr=r(UHt,"model.eval()"),UHt.forEach(t),zTr=r($We,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NCe=n($We,"CODE",{});var HHt=s(NCe);QTr=r(HHt,"model.train()"),HHt.forEach(t),$We.forEach(t),WTr=i(Sa),T(A4.$$.fragment,Sa),Sa.forEach(t),Dl.forEach(t),tro=i(m),Kd=n(m,"H2",{class:!0});var vao=s(Kd);L4=n(vao,"A",{id:!0,class:!0,href:!0});var JHt=s(L4);qCe=n(JHt,"SPAN",{});var YHt=s(qCe);T(Z$.$$.fragment,YHt),YHt.forEach(t),JHt.forEach(t),UTr=i(vao),jCe=n(vao,"SPAN",{});var ZHt=s(jCe);HTr=r(ZHt,"AutoModelForTableQuestionAnswering"),ZHt.forEach(t),vao.forEach(t),aro=i(m),zo=n(m,"DIV",{class:!0});var Gl=s(zo);T(K$.$$.fragment,Gl),JTr=i(Gl),ec=n(Gl,"P",{});var ude=s(ec);YTr=r(ude,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PZ=n(ude,"A",{href:!0});var KHt=s(PZ);ZTr=r(KHt,"from_pretrained()"),KHt.forEach(t),KTr=r(ude," class method or the "),BZ=n(ude,"A",{href:!0});var eJt=s(BZ);eMr=r(eJt,"from_config()"),eJt.forEach(t),oMr=r(ude,` class
method.`),ude.forEach(t),rMr=i(Gl),ek=n(Gl,"P",{});var Fao=s(ek);tMr=r(Fao,"This class cannot be instantiated directly using "),DCe=n(Fao,"CODE",{});var oJt=s(DCe);aMr=r(oJt,"__init__()"),oJt.forEach(t),nMr=r(Fao," (throws an error)."),Fao.forEach(t),sMr=i(Gl),xt=n(Gl,"DIV",{class:!0});var Oy=s(xt);T(ok.$$.fragment,Oy),lMr=i(Oy),GCe=n(Oy,"P",{});var rJt=s(GCe);iMr=r(rJt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),rJt.forEach(t),dMr=i(Oy),oc=n(Oy,"P",{});var pde=s(oc);cMr=r(pde,`Note:
Loading a model from its configuration file does `),OCe=n(pde,"STRONG",{});var tJt=s(OCe);mMr=r(tJt,"not"),tJt.forEach(t),fMr=r(pde,` load the model weights. It only affects the
model\u2019s configuration. Use `),IZ=n(pde,"A",{href:!0});var aJt=s(IZ);gMr=r(aJt,"from_pretrained()"),aJt.forEach(t),hMr=r(pde," to load the model weights."),pde.forEach(t),uMr=i(Oy),T(y4.$$.fragment,Oy),Oy.forEach(t),pMr=i(Gl),co=n(Gl,"DIV",{class:!0});var Ra=s(co);T(rk.$$.fragment,Ra),_Mr=i(Ra),VCe=n(Ra,"P",{});var nJt=s(VCe);bMr=r(nJt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),nJt.forEach(t),vMr=i(Ra),mn=n(Ra,"P",{});var Vy=s(mn);FMr=r(Vy,"The model class to instantiate is selected based on the "),XCe=n(Vy,"CODE",{});var sJt=s(XCe);TMr=r(sJt,"model_type"),sJt.forEach(t),MMr=r(Vy,` property of the config object (either
passed as an argument or loaded from `),zCe=n(Vy,"CODE",{});var lJt=s(zCe);EMr=r(lJt,"pretrained_model_name_or_path"),lJt.forEach(t),CMr=r(Vy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QCe=n(Vy,"CODE",{});var iJt=s(QCe);wMr=r(iJt,"pretrained_model_name_or_path"),iJt.forEach(t),AMr=r(Vy,":"),Vy.forEach(t),LMr=i(Ra),WCe=n(Ra,"UL",{});var dJt=s(WCe);x4=n(dJt,"LI",{});var kWe=s(x4);UCe=n(kWe,"STRONG",{});var cJt=s(UCe);yMr=r(cJt,"tapas"),cJt.forEach(t),xMr=r(kWe," \u2014 "),NZ=n(kWe,"A",{href:!0});var mJt=s(NZ);$Mr=r(mJt,"TapasForQuestionAnswering"),mJt.forEach(t),kMr=r(kWe," (TAPAS model)"),kWe.forEach(t),dJt.forEach(t),SMr=i(Ra),$4=n(Ra,"P",{});var SWe=s($4);RMr=r(SWe,"The model is set in evaluation mode by default using "),HCe=n(SWe,"CODE",{});var fJt=s(HCe);PMr=r(fJt,"model.eval()"),fJt.forEach(t),BMr=r(SWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JCe=n(SWe,"CODE",{});var gJt=s(JCe);IMr=r(gJt,"model.train()"),gJt.forEach(t),SWe.forEach(t),NMr=i(Ra),T(k4.$$.fragment,Ra),Ra.forEach(t),Gl.forEach(t),nro=i(m),rc=n(m,"H2",{class:!0});var Tao=s(rc);S4=n(Tao,"A",{id:!0,class:!0,href:!0});var hJt=s(S4);YCe=n(hJt,"SPAN",{});var uJt=s(YCe);T(tk.$$.fragment,uJt),uJt.forEach(t),hJt.forEach(t),qMr=i(Tao),ZCe=n(Tao,"SPAN",{});var pJt=s(ZCe);jMr=r(pJt,"AutoModelForDocumentQuestionAnswering"),pJt.forEach(t),Tao.forEach(t),sro=i(m),Qo=n(m,"DIV",{class:!0});var Ol=s(Qo);T(ak.$$.fragment,Ol),DMr=i(Ol),tc=n(Ol,"P",{});var _de=s(tc);GMr=r(_de,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),qZ=n(_de,"A",{href:!0});var _Jt=s(qZ);OMr=r(_Jt,"from_pretrained()"),_Jt.forEach(t),VMr=r(_de," class method or the "),jZ=n(_de,"A",{href:!0});var bJt=s(jZ);XMr=r(bJt,"from_config()"),bJt.forEach(t),zMr=r(_de,` class
method.`),_de.forEach(t),QMr=i(Ol),nk=n(Ol,"P",{});var Mao=s(nk);WMr=r(Mao,"This class cannot be instantiated directly using "),KCe=n(Mao,"CODE",{});var vJt=s(KCe);UMr=r(vJt,"__init__()"),vJt.forEach(t),HMr=r(Mao," (throws an error)."),Mao.forEach(t),JMr=i(Ol),$t=n(Ol,"DIV",{class:!0});var Xy=s($t);T(sk.$$.fragment,Xy),YMr=i(Xy),e3e=n(Xy,"P",{});var FJt=s(e3e);ZMr=r(FJt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),FJt.forEach(t),KMr=i(Xy),ac=n(Xy,"P",{});var bde=s(ac);eEr=r(bde,`Note:
Loading a model from its configuration file does `),o3e=n(bde,"STRONG",{});var TJt=s(o3e);oEr=r(TJt,"not"),TJt.forEach(t),rEr=r(bde,` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=n(bde,"A",{href:!0});var MJt=s(DZ);tEr=r(MJt,"from_pretrained()"),MJt.forEach(t),aEr=r(bde," to load the model weights."),bde.forEach(t),nEr=i(Xy),T(R4.$$.fragment,Xy),Xy.forEach(t),sEr=i(Ol),mo=n(Ol,"DIV",{class:!0});var Pa=s(mo);T(lk.$$.fragment,Pa),lEr=i(Pa),r3e=n(Pa,"P",{});var EJt=s(r3e);iEr=r(EJt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),EJt.forEach(t),dEr=i(Pa),fn=n(Pa,"P",{});var zy=s(fn);cEr=r(zy,"The model class to instantiate is selected based on the "),t3e=n(zy,"CODE",{});var CJt=s(t3e);mEr=r(CJt,"model_type"),CJt.forEach(t),fEr=r(zy,` property of the config object (either
passed as an argument or loaded from `),a3e=n(zy,"CODE",{});var wJt=s(a3e);gEr=r(wJt,"pretrained_model_name_or_path"),wJt.forEach(t),hEr=r(zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n3e=n(zy,"CODE",{});var AJt=s(n3e);uEr=r(AJt,"pretrained_model_name_or_path"),AJt.forEach(t),pEr=r(zy,":"),zy.forEach(t),_Er=i(Pa),nc=n(Pa,"UL",{});var vde=s(nc);P4=n(vde,"LI",{});var RWe=s(P4);s3e=n(RWe,"STRONG",{});var LJt=s(s3e);bEr=r(LJt,"layoutlm"),LJt.forEach(t),vEr=r(RWe," \u2014 "),GZ=n(RWe,"A",{href:!0});var yJt=s(GZ);FEr=r(yJt,"LayoutLMForQuestionAnswering"),yJt.forEach(t),TEr=r(RWe," (LayoutLM model)"),RWe.forEach(t),MEr=i(vde),B4=n(vde,"LI",{});var PWe=s(B4);l3e=n(PWe,"STRONG",{});var xJt=s(l3e);EEr=r(xJt,"layoutlmv2"),xJt.forEach(t),CEr=r(PWe," \u2014 "),OZ=n(PWe,"A",{href:!0});var $Jt=s(OZ);wEr=r($Jt,"LayoutLMv2ForQuestionAnswering"),$Jt.forEach(t),AEr=r(PWe," (LayoutLMv2 model)"),PWe.forEach(t),LEr=i(vde),I4=n(vde,"LI",{});var BWe=s(I4);i3e=n(BWe,"STRONG",{});var kJt=s(i3e);yEr=r(kJt,"layoutlmv3"),kJt.forEach(t),xEr=r(BWe," \u2014 "),VZ=n(BWe,"A",{href:!0});var SJt=s(VZ);$Er=r(SJt,"LayoutLMv3ForQuestionAnswering"),SJt.forEach(t),kEr=r(BWe," (LayoutLMv3 model)"),BWe.forEach(t),vde.forEach(t),SEr=i(Pa),N4=n(Pa,"P",{});var IWe=s(N4);REr=r(IWe,"The model is set in evaluation mode by default using "),d3e=n(IWe,"CODE",{});var RJt=s(d3e);PEr=r(RJt,"model.eval()"),RJt.forEach(t),BEr=r(IWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c3e=n(IWe,"CODE",{});var PJt=s(c3e);IEr=r(PJt,"model.train()"),PJt.forEach(t),IWe.forEach(t),NEr=i(Pa),T(q4.$$.fragment,Pa),Pa.forEach(t),Ol.forEach(t),lro=i(m),sc=n(m,"H2",{class:!0});var Eao=s(sc);j4=n(Eao,"A",{id:!0,class:!0,href:!0});var BJt=s(j4);m3e=n(BJt,"SPAN",{});var IJt=s(m3e);T(ik.$$.fragment,IJt),IJt.forEach(t),BJt.forEach(t),qEr=i(Eao),f3e=n(Eao,"SPAN",{});var NJt=s(f3e);jEr=r(NJt,"AutoModelForImageClassification"),NJt.forEach(t),Eao.forEach(t),iro=i(m),Wo=n(m,"DIV",{class:!0});var Vl=s(Wo);T(dk.$$.fragment,Vl),DEr=i(Vl),lc=n(Vl,"P",{});var Fde=s(lc);GEr=r(Fde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),XZ=n(Fde,"A",{href:!0});var qJt=s(XZ);OEr=r(qJt,"from_pretrained()"),qJt.forEach(t),VEr=r(Fde," class method or the "),zZ=n(Fde,"A",{href:!0});var jJt=s(zZ);XEr=r(jJt,"from_config()"),jJt.forEach(t),zEr=r(Fde,` class
method.`),Fde.forEach(t),QEr=i(Vl),ck=n(Vl,"P",{});var Cao=s(ck);WEr=r(Cao,"This class cannot be instantiated directly using "),g3e=n(Cao,"CODE",{});var DJt=s(g3e);UEr=r(DJt,"__init__()"),DJt.forEach(t),HEr=r(Cao," (throws an error)."),Cao.forEach(t),JEr=i(Vl),kt=n(Vl,"DIV",{class:!0});var Qy=s(kt);T(mk.$$.fragment,Qy),YEr=i(Qy),h3e=n(Qy,"P",{});var GJt=s(h3e);ZEr=r(GJt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),GJt.forEach(t),KEr=i(Qy),ic=n(Qy,"P",{});var Tde=s(ic);e4r=r(Tde,`Note:
Loading a model from its configuration file does `),u3e=n(Tde,"STRONG",{});var OJt=s(u3e);o4r=r(OJt,"not"),OJt.forEach(t),r4r=r(Tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),QZ=n(Tde,"A",{href:!0});var VJt=s(QZ);t4r=r(VJt,"from_pretrained()"),VJt.forEach(t),a4r=r(Tde," to load the model weights."),Tde.forEach(t),n4r=i(Qy),T(D4.$$.fragment,Qy),Qy.forEach(t),s4r=i(Vl),fo=n(Vl,"DIV",{class:!0});var Ba=s(fo);T(fk.$$.fragment,Ba),l4r=i(Ba),p3e=n(Ba,"P",{});var XJt=s(p3e);i4r=r(XJt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),XJt.forEach(t),d4r=i(Ba),gn=n(Ba,"P",{});var Wy=s(gn);c4r=r(Wy,"The model class to instantiate is selected based on the "),_3e=n(Wy,"CODE",{});var zJt=s(_3e);m4r=r(zJt,"model_type"),zJt.forEach(t),f4r=r(Wy,` property of the config object (either
passed as an argument or loaded from `),b3e=n(Wy,"CODE",{});var QJt=s(b3e);g4r=r(QJt,"pretrained_model_name_or_path"),QJt.forEach(t),h4r=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v3e=n(Wy,"CODE",{});var WJt=s(v3e);u4r=r(WJt,"pretrained_model_name_or_path"),WJt.forEach(t),p4r=r(Wy,":"),Wy.forEach(t),_4r=i(Ba),be=n(Ba,"UL",{});var Fe=s(be);G4=n(Fe,"LI",{});var NWe=s(G4);F3e=n(NWe,"STRONG",{});var UJt=s(F3e);b4r=r(UJt,"beit"),UJt.forEach(t),v4r=r(NWe," \u2014 "),WZ=n(NWe,"A",{href:!0});var HJt=s(WZ);F4r=r(HJt,"BeitForImageClassification"),HJt.forEach(t),T4r=r(NWe," (BEiT model)"),NWe.forEach(t),M4r=i(Fe),O4=n(Fe,"LI",{});var qWe=s(O4);T3e=n(qWe,"STRONG",{});var JJt=s(T3e);E4r=r(JJt,"convnext"),JJt.forEach(t),C4r=r(qWe," \u2014 "),UZ=n(qWe,"A",{href:!0});var YJt=s(UZ);w4r=r(YJt,"ConvNextForImageClassification"),YJt.forEach(t),A4r=r(qWe," (ConvNeXT model)"),qWe.forEach(t),L4r=i(Fe),V4=n(Fe,"LI",{});var jWe=s(V4);M3e=n(jWe,"STRONG",{});var ZJt=s(M3e);y4r=r(ZJt,"cvt"),ZJt.forEach(t),x4r=r(jWe," \u2014 "),HZ=n(jWe,"A",{href:!0});var KJt=s(HZ);$4r=r(KJt,"CvtForImageClassification"),KJt.forEach(t),k4r=r(jWe," (CvT model)"),jWe.forEach(t),S4r=i(Fe),X4=n(Fe,"LI",{});var DWe=s(X4);E3e=n(DWe,"STRONG",{});var eYt=s(E3e);R4r=r(eYt,"data2vec-vision"),eYt.forEach(t),P4r=r(DWe," \u2014 "),JZ=n(DWe,"A",{href:!0});var oYt=s(JZ);B4r=r(oYt,"Data2VecVisionForImageClassification"),oYt.forEach(t),I4r=r(DWe," (Data2VecVision model)"),DWe.forEach(t),N4r=i(Fe),El=n(Fe,"LI",{});var kI=s(El);C3e=n(kI,"STRONG",{});var rYt=s(C3e);q4r=r(rYt,"deit"),rYt.forEach(t),j4r=r(kI," \u2014 "),YZ=n(kI,"A",{href:!0});var tYt=s(YZ);D4r=r(tYt,"DeiTForImageClassification"),tYt.forEach(t),G4r=r(kI," or "),ZZ=n(kI,"A",{href:!0});var aYt=s(ZZ);O4r=r(aYt,"DeiTForImageClassificationWithTeacher"),aYt.forEach(t),V4r=r(kI," (DeiT model)"),kI.forEach(t),X4r=i(Fe),z4=n(Fe,"LI",{});var GWe=s(z4);w3e=n(GWe,"STRONG",{});var nYt=s(w3e);z4r=r(nYt,"imagegpt"),nYt.forEach(t),Q4r=r(GWe," \u2014 "),KZ=n(GWe,"A",{href:!0});var sYt=s(KZ);W4r=r(sYt,"ImageGPTForImageClassification"),sYt.forEach(t),U4r=r(GWe," (ImageGPT model)"),GWe.forEach(t),H4r=i(Fe),Cl=n(Fe,"LI",{});var SI=s(Cl);A3e=n(SI,"STRONG",{});var lYt=s(A3e);J4r=r(lYt,"levit"),lYt.forEach(t),Y4r=r(SI," \u2014 "),eK=n(SI,"A",{href:!0});var iYt=s(eK);Z4r=r(iYt,"LevitForImageClassification"),iYt.forEach(t),K4r=r(SI," or "),oK=n(SI,"A",{href:!0});var dYt=s(oK);eCr=r(dYt,"LevitForImageClassificationWithTeacher"),dYt.forEach(t),oCr=r(SI," (LeViT model)"),SI.forEach(t),rCr=i(Fe),Q4=n(Fe,"LI",{});var OWe=s(Q4);L3e=n(OWe,"STRONG",{});var cYt=s(L3e);tCr=r(cYt,"mobilevit"),cYt.forEach(t),aCr=r(OWe," \u2014 "),rK=n(OWe,"A",{href:!0});var mYt=s(rK);nCr=r(mYt,"MobileViTForImageClassification"),mYt.forEach(t),sCr=r(OWe," (MobileViT model)"),OWe.forEach(t),lCr=i(Fe),St=n(Fe,"LI",{});var Sf=s(St);y3e=n(Sf,"STRONG",{});var fYt=s(y3e);iCr=r(fYt,"perceiver"),fYt.forEach(t),dCr=r(Sf," \u2014 "),tK=n(Sf,"A",{href:!0});var gYt=s(tK);cCr=r(gYt,"PerceiverForImageClassificationLearned"),gYt.forEach(t),mCr=r(Sf," or "),aK=n(Sf,"A",{href:!0});var hYt=s(aK);fCr=r(hYt,"PerceiverForImageClassificationFourier"),hYt.forEach(t),gCr=r(Sf," or "),nK=n(Sf,"A",{href:!0});var uYt=s(nK);hCr=r(uYt,"PerceiverForImageClassificationConvProcessing"),uYt.forEach(t),uCr=r(Sf," (Perceiver model)"),Sf.forEach(t),pCr=i(Fe),W4=n(Fe,"LI",{});var VWe=s(W4);x3e=n(VWe,"STRONG",{});var pYt=s(x3e);_Cr=r(pYt,"poolformer"),pYt.forEach(t),bCr=r(VWe," \u2014 "),sK=n(VWe,"A",{href:!0});var _Yt=s(sK);vCr=r(_Yt,"PoolFormerForImageClassification"),_Yt.forEach(t),FCr=r(VWe," (PoolFormer model)"),VWe.forEach(t),TCr=i(Fe),U4=n(Fe,"LI",{});var XWe=s(U4);$3e=n(XWe,"STRONG",{});var bYt=s($3e);MCr=r(bYt,"regnet"),bYt.forEach(t),ECr=r(XWe," \u2014 "),lK=n(XWe,"A",{href:!0});var vYt=s(lK);CCr=r(vYt,"RegNetForImageClassification"),vYt.forEach(t),wCr=r(XWe," (RegNet model)"),XWe.forEach(t),ACr=i(Fe),H4=n(Fe,"LI",{});var zWe=s(H4);k3e=n(zWe,"STRONG",{});var FYt=s(k3e);LCr=r(FYt,"resnet"),FYt.forEach(t),yCr=r(zWe," \u2014 "),iK=n(zWe,"A",{href:!0});var TYt=s(iK);xCr=r(TYt,"ResNetForImageClassification"),TYt.forEach(t),$Cr=r(zWe," (ResNet model)"),zWe.forEach(t),kCr=i(Fe),J4=n(Fe,"LI",{});var QWe=s(J4);S3e=n(QWe,"STRONG",{});var MYt=s(S3e);SCr=r(MYt,"segformer"),MYt.forEach(t),RCr=r(QWe," \u2014 "),dK=n(QWe,"A",{href:!0});var EYt=s(dK);PCr=r(EYt,"SegformerForImageClassification"),EYt.forEach(t),BCr=r(QWe," (SegFormer model)"),QWe.forEach(t),ICr=i(Fe),Y4=n(Fe,"LI",{});var WWe=s(Y4);R3e=n(WWe,"STRONG",{});var CYt=s(R3e);NCr=r(CYt,"swin"),CYt.forEach(t),qCr=r(WWe," \u2014 "),cK=n(WWe,"A",{href:!0});var wYt=s(cK);jCr=r(wYt,"SwinForImageClassification"),wYt.forEach(t),DCr=r(WWe," (Swin Transformer model)"),WWe.forEach(t),GCr=i(Fe),Z4=n(Fe,"LI",{});var UWe=s(Z4);P3e=n(UWe,"STRONG",{});var AYt=s(P3e);OCr=r(AYt,"swinv2"),AYt.forEach(t),VCr=r(UWe," \u2014 "),mK=n(UWe,"A",{href:!0});var LYt=s(mK);XCr=r(LYt,"Swinv2ForImageClassification"),LYt.forEach(t),zCr=r(UWe," (Swin Transformer V2 model)"),UWe.forEach(t),QCr=i(Fe),K4=n(Fe,"LI",{});var HWe=s(K4);B3e=n(HWe,"STRONG",{});var yYt=s(B3e);WCr=r(yYt,"van"),yYt.forEach(t),UCr=r(HWe," \u2014 "),fK=n(HWe,"A",{href:!0});var xYt=s(fK);HCr=r(xYt,"VanForImageClassification"),xYt.forEach(t),JCr=r(HWe," (VAN model)"),HWe.forEach(t),YCr=i(Fe),eC=n(Fe,"LI",{});var JWe=s(eC);I3e=n(JWe,"STRONG",{});var $Yt=s(I3e);ZCr=r($Yt,"vit"),$Yt.forEach(t),KCr=r(JWe," \u2014 "),gK=n(JWe,"A",{href:!0});var kYt=s(gK);e3r=r(kYt,"ViTForImageClassification"),kYt.forEach(t),o3r=r(JWe," (ViT model)"),JWe.forEach(t),r3r=i(Fe),oC=n(Fe,"LI",{});var YWe=s(oC);N3e=n(YWe,"STRONG",{});var SYt=s(N3e);t3r=r(SYt,"vit_msn"),SYt.forEach(t),a3r=r(YWe," \u2014 "),hK=n(YWe,"A",{href:!0});var RYt=s(hK);n3r=r(RYt,"ViTMSNForImageClassification"),RYt.forEach(t),s3r=r(YWe," (ViTMSN model)"),YWe.forEach(t),Fe.forEach(t),l3r=i(Ba),rC=n(Ba,"P",{});var ZWe=s(rC);i3r=r(ZWe,"The model is set in evaluation mode by default using "),q3e=n(ZWe,"CODE",{});var PYt=s(q3e);d3r=r(PYt,"model.eval()"),PYt.forEach(t),c3r=r(ZWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j3e=n(ZWe,"CODE",{});var BYt=s(j3e);m3r=r(BYt,"model.train()"),BYt.forEach(t),ZWe.forEach(t),f3r=i(Ba),T(tC.$$.fragment,Ba),Ba.forEach(t),Vl.forEach(t),dro=i(m),dc=n(m,"H2",{class:!0});var wao=s(dc);aC=n(wao,"A",{id:!0,class:!0,href:!0});var IYt=s(aC);D3e=n(IYt,"SPAN",{});var NYt=s(D3e);T(gk.$$.fragment,NYt),NYt.forEach(t),IYt.forEach(t),g3r=i(wao),G3e=n(wao,"SPAN",{});var qYt=s(G3e);h3r=r(qYt,"AutoModelForVideoClassification"),qYt.forEach(t),wao.forEach(t),cro=i(m),Uo=n(m,"DIV",{class:!0});var Xl=s(Uo);T(hk.$$.fragment,Xl),u3r=i(Xl),cc=n(Xl,"P",{});var Mde=s(cc);p3r=r(Mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),uK=n(Mde,"A",{href:!0});var jYt=s(uK);_3r=r(jYt,"from_pretrained()"),jYt.forEach(t),b3r=r(Mde," class method or the "),pK=n(Mde,"A",{href:!0});var DYt=s(pK);v3r=r(DYt,"from_config()"),DYt.forEach(t),F3r=r(Mde,` class
method.`),Mde.forEach(t),T3r=i(Xl),uk=n(Xl,"P",{});var Aao=s(uk);M3r=r(Aao,"This class cannot be instantiated directly using "),O3e=n(Aao,"CODE",{});var GYt=s(O3e);E3r=r(GYt,"__init__()"),GYt.forEach(t),C3r=r(Aao," (throws an error)."),Aao.forEach(t),w3r=i(Xl),Rt=n(Xl,"DIV",{class:!0});var Uy=s(Rt);T(pk.$$.fragment,Uy),A3r=i(Uy),V3e=n(Uy,"P",{});var OYt=s(V3e);L3r=r(OYt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),OYt.forEach(t),y3r=i(Uy),mc=n(Uy,"P",{});var Ede=s(mc);x3r=r(Ede,`Note:
Loading a model from its configuration file does `),X3e=n(Ede,"STRONG",{});var VYt=s(X3e);$3r=r(VYt,"not"),VYt.forEach(t),k3r=r(Ede,` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=n(Ede,"A",{href:!0});var XYt=s(_K);S3r=r(XYt,"from_pretrained()"),XYt.forEach(t),R3r=r(Ede," to load the model weights."),Ede.forEach(t),P3r=i(Uy),T(nC.$$.fragment,Uy),Uy.forEach(t),B3r=i(Xl),go=n(Xl,"DIV",{class:!0});var Ia=s(go);T(_k.$$.fragment,Ia),I3r=i(Ia),z3e=n(Ia,"P",{});var zYt=s(z3e);N3r=r(zYt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),zYt.forEach(t),q3r=i(Ia),hn=n(Ia,"P",{});var Hy=s(hn);j3r=r(Hy,"The model class to instantiate is selected based on the "),Q3e=n(Hy,"CODE",{});var QYt=s(Q3e);D3r=r(QYt,"model_type"),QYt.forEach(t),G3r=r(Hy,` property of the config object (either
passed as an argument or loaded from `),W3e=n(Hy,"CODE",{});var WYt=s(W3e);O3r=r(WYt,"pretrained_model_name_or_path"),WYt.forEach(t),V3r=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U3e=n(Hy,"CODE",{});var UYt=s(U3e);X3r=r(UYt,"pretrained_model_name_or_path"),UYt.forEach(t),z3r=r(Hy,":"),Hy.forEach(t),Q3r=i(Ia),H3e=n(Ia,"UL",{});var HYt=s(H3e);sC=n(HYt,"LI",{});var KWe=s(sC);J3e=n(KWe,"STRONG",{});var JYt=s(J3e);W3r=r(JYt,"videomae"),JYt.forEach(t),U3r=r(KWe," \u2014 "),bK=n(KWe,"A",{href:!0});var YYt=s(bK);H3r=r(YYt,"VideoMAEForVideoClassification"),YYt.forEach(t),J3r=r(KWe," (VideoMAE model)"),KWe.forEach(t),HYt.forEach(t),Y3r=i(Ia),lC=n(Ia,"P",{});var eUe=s(lC);Z3r=r(eUe,"The model is set in evaluation mode by default using "),Y3e=n(eUe,"CODE",{});var ZYt=s(Y3e);K3r=r(ZYt,"model.eval()"),ZYt.forEach(t),e5r=r(eUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z3e=n(eUe,"CODE",{});var KYt=s(Z3e);o5r=r(KYt,"model.train()"),KYt.forEach(t),eUe.forEach(t),r5r=i(Ia),T(iC.$$.fragment,Ia),Ia.forEach(t),Xl.forEach(t),mro=i(m),fc=n(m,"H2",{class:!0});var Lao=s(fc);dC=n(Lao,"A",{id:!0,class:!0,href:!0});var eZt=s(dC);K3e=n(eZt,"SPAN",{});var oZt=s(K3e);T(bk.$$.fragment,oZt),oZt.forEach(t),eZt.forEach(t),t5r=i(Lao),e5e=n(Lao,"SPAN",{});var rZt=s(e5e);a5r=r(rZt,"AutoModelForVision2Seq"),rZt.forEach(t),Lao.forEach(t),fro=i(m),Ho=n(m,"DIV",{class:!0});var zl=s(Ho);T(vk.$$.fragment,zl),n5r=i(zl),gc=n(zl,"P",{});var Cde=s(gc);s5r=r(Cde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vK=n(Cde,"A",{href:!0});var tZt=s(vK);l5r=r(tZt,"from_pretrained()"),tZt.forEach(t),i5r=r(Cde," class method or the "),FK=n(Cde,"A",{href:!0});var aZt=s(FK);d5r=r(aZt,"from_config()"),aZt.forEach(t),c5r=r(Cde,` class
method.`),Cde.forEach(t),m5r=i(zl),Fk=n(zl,"P",{});var yao=s(Fk);f5r=r(yao,"This class cannot be instantiated directly using "),o5e=n(yao,"CODE",{});var nZt=s(o5e);g5r=r(nZt,"__init__()"),nZt.forEach(t),h5r=r(yao," (throws an error)."),yao.forEach(t),u5r=i(zl),Pt=n(zl,"DIV",{class:!0});var Jy=s(Pt);T(Tk.$$.fragment,Jy),p5r=i(Jy),r5e=n(Jy,"P",{});var sZt=s(r5e);_5r=r(sZt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),sZt.forEach(t),b5r=i(Jy),hc=n(Jy,"P",{});var wde=s(hc);v5r=r(wde,`Note:
Loading a model from its configuration file does `),t5e=n(wde,"STRONG",{});var lZt=s(t5e);F5r=r(lZt,"not"),lZt.forEach(t),T5r=r(wde,` load the model weights. It only affects the
model\u2019s configuration. Use `),TK=n(wde,"A",{href:!0});var iZt=s(TK);M5r=r(iZt,"from_pretrained()"),iZt.forEach(t),E5r=r(wde," to load the model weights."),wde.forEach(t),C5r=i(Jy),T(cC.$$.fragment,Jy),Jy.forEach(t),w5r=i(zl),ho=n(zl,"DIV",{class:!0});var Na=s(ho);T(Mk.$$.fragment,Na),A5r=i(Na),a5e=n(Na,"P",{});var dZt=s(a5e);L5r=r(dZt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),dZt.forEach(t),y5r=i(Na),un=n(Na,"P",{});var Yy=s(un);x5r=r(Yy,"The model class to instantiate is selected based on the "),n5e=n(Yy,"CODE",{});var cZt=s(n5e);$5r=r(cZt,"model_type"),cZt.forEach(t),k5r=r(Yy,` property of the config object (either
passed as an argument or loaded from `),s5e=n(Yy,"CODE",{});var mZt=s(s5e);S5r=r(mZt,"pretrained_model_name_or_path"),mZt.forEach(t),R5r=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l5e=n(Yy,"CODE",{});var fZt=s(l5e);P5r=r(fZt,"pretrained_model_name_or_path"),fZt.forEach(t),B5r=r(Yy,":"),Yy.forEach(t),I5r=i(Na),i5e=n(Na,"UL",{});var gZt=s(i5e);mC=n(gZt,"LI",{});var oUe=s(mC);d5e=n(oUe,"STRONG",{});var hZt=s(d5e);N5r=r(hZt,"vision-encoder-decoder"),hZt.forEach(t),q5r=r(oUe," \u2014 "),MK=n(oUe,"A",{href:!0});var uZt=s(MK);j5r=r(uZt,"VisionEncoderDecoderModel"),uZt.forEach(t),D5r=r(oUe," (Vision Encoder decoder model)"),oUe.forEach(t),gZt.forEach(t),G5r=i(Na),fC=n(Na,"P",{});var rUe=s(fC);O5r=r(rUe,"The model is set in evaluation mode by default using "),c5e=n(rUe,"CODE",{});var pZt=s(c5e);V5r=r(pZt,"model.eval()"),pZt.forEach(t),X5r=r(rUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m5e=n(rUe,"CODE",{});var _Zt=s(m5e);z5r=r(_Zt,"model.train()"),_Zt.forEach(t),rUe.forEach(t),Q5r=i(Na),T(gC.$$.fragment,Na),Na.forEach(t),zl.forEach(t),gro=i(m),uc=n(m,"H2",{class:!0});var xao=s(uc);hC=n(xao,"A",{id:!0,class:!0,href:!0});var bZt=s(hC);f5e=n(bZt,"SPAN",{});var vZt=s(f5e);T(Ek.$$.fragment,vZt),vZt.forEach(t),bZt.forEach(t),W5r=i(xao),g5e=n(xao,"SPAN",{});var FZt=s(g5e);U5r=r(FZt,"AutoModelForVisualQuestionAnswering"),FZt.forEach(t),xao.forEach(t),hro=i(m),Jo=n(m,"DIV",{class:!0});var Ql=s(Jo);T(Ck.$$.fragment,Ql),H5r=i(Ql),pc=n(Ql,"P",{});var Ade=s(pc);J5r=r(Ade,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),EK=n(Ade,"A",{href:!0});var TZt=s(EK);Y5r=r(TZt,"from_pretrained()"),TZt.forEach(t),Z5r=r(Ade," class method or the "),CK=n(Ade,"A",{href:!0});var MZt=s(CK);K5r=r(MZt,"from_config()"),MZt.forEach(t),e0r=r(Ade,` class
method.`),Ade.forEach(t),o0r=i(Ql),wk=n(Ql,"P",{});var $ao=s(wk);r0r=r($ao,"This class cannot be instantiated directly using "),h5e=n($ao,"CODE",{});var EZt=s(h5e);t0r=r(EZt,"__init__()"),EZt.forEach(t),a0r=r($ao," (throws an error)."),$ao.forEach(t),n0r=i(Ql),Bt=n(Ql,"DIV",{class:!0});var Zy=s(Bt);T(Ak.$$.fragment,Zy),s0r=i(Zy),u5e=n(Zy,"P",{});var CZt=s(u5e);l0r=r(CZt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),CZt.forEach(t),i0r=i(Zy),_c=n(Zy,"P",{});var Lde=s(_c);d0r=r(Lde,`Note:
Loading a model from its configuration file does `),p5e=n(Lde,"STRONG",{});var wZt=s(p5e);c0r=r(wZt,"not"),wZt.forEach(t),m0r=r(Lde,` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=n(Lde,"A",{href:!0});var AZt=s(wK);f0r=r(AZt,"from_pretrained()"),AZt.forEach(t),g0r=r(Lde," to load the model weights."),Lde.forEach(t),h0r=i(Zy),T(uC.$$.fragment,Zy),Zy.forEach(t),u0r=i(Ql),uo=n(Ql,"DIV",{class:!0});var qa=s(uo);T(Lk.$$.fragment,qa),p0r=i(qa),_5e=n(qa,"P",{});var LZt=s(_5e);_0r=r(LZt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),LZt.forEach(t),b0r=i(qa),pn=n(qa,"P",{});var Ky=s(pn);v0r=r(Ky,"The model class to instantiate is selected based on the "),b5e=n(Ky,"CODE",{});var yZt=s(b5e);F0r=r(yZt,"model_type"),yZt.forEach(t),T0r=r(Ky,` property of the config object (either
passed as an argument or loaded from `),v5e=n(Ky,"CODE",{});var xZt=s(v5e);M0r=r(xZt,"pretrained_model_name_or_path"),xZt.forEach(t),E0r=r(Ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F5e=n(Ky,"CODE",{});var $Zt=s(F5e);C0r=r($Zt,"pretrained_model_name_or_path"),$Zt.forEach(t),w0r=r(Ky,":"),Ky.forEach(t),A0r=i(qa),T5e=n(qa,"UL",{});var kZt=s(T5e);pC=n(kZt,"LI",{});var tUe=s(pC);M5e=n(tUe,"STRONG",{});var SZt=s(M5e);L0r=r(SZt,"vilt"),SZt.forEach(t),y0r=r(tUe," \u2014 "),AK=n(tUe,"A",{href:!0});var RZt=s(AK);x0r=r(RZt,"ViltForQuestionAnswering"),RZt.forEach(t),$0r=r(tUe," (ViLT model)"),tUe.forEach(t),kZt.forEach(t),k0r=i(qa),_C=n(qa,"P",{});var aUe=s(_C);S0r=r(aUe,"The model is set in evaluation mode by default using "),E5e=n(aUe,"CODE",{});var PZt=s(E5e);R0r=r(PZt,"model.eval()"),PZt.forEach(t),P0r=r(aUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C5e=n(aUe,"CODE",{});var BZt=s(C5e);B0r=r(BZt,"model.train()"),BZt.forEach(t),aUe.forEach(t),I0r=i(qa),T(bC.$$.fragment,qa),qa.forEach(t),Ql.forEach(t),uro=i(m),bc=n(m,"H2",{class:!0});var kao=s(bc);vC=n(kao,"A",{id:!0,class:!0,href:!0});var IZt=s(vC);w5e=n(IZt,"SPAN",{});var NZt=s(w5e);T(yk.$$.fragment,NZt),NZt.forEach(t),IZt.forEach(t),N0r=i(kao),A5e=n(kao,"SPAN",{});var qZt=s(A5e);q0r=r(qZt,"AutoModelForAudioClassification"),qZt.forEach(t),kao.forEach(t),pro=i(m),Yo=n(m,"DIV",{class:!0});var Wl=s(Yo);T(xk.$$.fragment,Wl),j0r=i(Wl),vc=n(Wl,"P",{});var yde=s(vc);D0r=r(yde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),LK=n(yde,"A",{href:!0});var jZt=s(LK);G0r=r(jZt,"from_pretrained()"),jZt.forEach(t),O0r=r(yde," class method or the "),yK=n(yde,"A",{href:!0});var DZt=s(yK);V0r=r(DZt,"from_config()"),DZt.forEach(t),X0r=r(yde,` class
method.`),yde.forEach(t),z0r=i(Wl),$k=n(Wl,"P",{});var Sao=s($k);Q0r=r(Sao,"This class cannot be instantiated directly using "),L5e=n(Sao,"CODE",{});var GZt=s(L5e);W0r=r(GZt,"__init__()"),GZt.forEach(t),U0r=r(Sao," (throws an error)."),Sao.forEach(t),H0r=i(Wl),It=n(Wl,"DIV",{class:!0});var e9=s(It);T(kk.$$.fragment,e9),J0r=i(e9),y5e=n(e9,"P",{});var OZt=s(y5e);Y0r=r(OZt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),OZt.forEach(t),Z0r=i(e9),Fc=n(e9,"P",{});var xde=s(Fc);K0r=r(xde,`Note:
Loading a model from its configuration file does `),x5e=n(xde,"STRONG",{});var VZt=s(x5e);ewr=r(VZt,"not"),VZt.forEach(t),owr=r(xde,` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=n(xde,"A",{href:!0});var XZt=s(xK);rwr=r(XZt,"from_pretrained()"),XZt.forEach(t),twr=r(xde," to load the model weights."),xde.forEach(t),awr=i(e9),T(FC.$$.fragment,e9),e9.forEach(t),nwr=i(Wl),po=n(Wl,"DIV",{class:!0});var ja=s(po);T(Sk.$$.fragment,ja),swr=i(ja),$5e=n(ja,"P",{});var zZt=s($5e);lwr=r(zZt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),zZt.forEach(t),iwr=i(ja),_n=n(ja,"P",{});var o9=s(_n);dwr=r(o9,"The model class to instantiate is selected based on the "),k5e=n(o9,"CODE",{});var QZt=s(k5e);cwr=r(QZt,"model_type"),QZt.forEach(t),mwr=r(o9,` property of the config object (either
passed as an argument or loaded from `),S5e=n(o9,"CODE",{});var WZt=s(S5e);fwr=r(WZt,"pretrained_model_name_or_path"),WZt.forEach(t),gwr=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R5e=n(o9,"CODE",{});var UZt=s(R5e);hwr=r(UZt,"pretrained_model_name_or_path"),UZt.forEach(t),uwr=r(o9,":"),o9.forEach(t),pwr=i(ja),Be=n(ja,"UL",{});var We=s(Be);TC=n(We,"LI",{});var nUe=s(TC);P5e=n(nUe,"STRONG",{});var HZt=s(P5e);_wr=r(HZt,"data2vec-audio"),HZt.forEach(t),bwr=r(nUe," \u2014 "),$K=n(nUe,"A",{href:!0});var JZt=s($K);vwr=r(JZt,"Data2VecAudioForSequenceClassification"),JZt.forEach(t),Fwr=r(nUe," (Data2VecAudio model)"),nUe.forEach(t),Twr=i(We),MC=n(We,"LI",{});var sUe=s(MC);B5e=n(sUe,"STRONG",{});var YZt=s(B5e);Mwr=r(YZt,"hubert"),YZt.forEach(t),Ewr=r(sUe," \u2014 "),kK=n(sUe,"A",{href:!0});var ZZt=s(kK);Cwr=r(ZZt,"HubertForSequenceClassification"),ZZt.forEach(t),wwr=r(sUe," (Hubert model)"),sUe.forEach(t),Awr=i(We),EC=n(We,"LI",{});var lUe=s(EC);I5e=n(lUe,"STRONG",{});var KZt=s(I5e);Lwr=r(KZt,"sew"),KZt.forEach(t),ywr=r(lUe," \u2014 "),SK=n(lUe,"A",{href:!0});var eKt=s(SK);xwr=r(eKt,"SEWForSequenceClassification"),eKt.forEach(t),$wr=r(lUe," (SEW model)"),lUe.forEach(t),kwr=i(We),CC=n(We,"LI",{});var iUe=s(CC);N5e=n(iUe,"STRONG",{});var oKt=s(N5e);Swr=r(oKt,"sew-d"),oKt.forEach(t),Rwr=r(iUe," \u2014 "),RK=n(iUe,"A",{href:!0});var rKt=s(RK);Pwr=r(rKt,"SEWDForSequenceClassification"),rKt.forEach(t),Bwr=r(iUe," (SEW-D model)"),iUe.forEach(t),Iwr=i(We),wC=n(We,"LI",{});var dUe=s(wC);q5e=n(dUe,"STRONG",{});var tKt=s(q5e);Nwr=r(tKt,"unispeech"),tKt.forEach(t),qwr=r(dUe," \u2014 "),PK=n(dUe,"A",{href:!0});var aKt=s(PK);jwr=r(aKt,"UniSpeechForSequenceClassification"),aKt.forEach(t),Dwr=r(dUe," (UniSpeech model)"),dUe.forEach(t),Gwr=i(We),AC=n(We,"LI",{});var cUe=s(AC);j5e=n(cUe,"STRONG",{});var nKt=s(j5e);Owr=r(nKt,"unispeech-sat"),nKt.forEach(t),Vwr=r(cUe," \u2014 "),BK=n(cUe,"A",{href:!0});var sKt=s(BK);Xwr=r(sKt,"UniSpeechSatForSequenceClassification"),sKt.forEach(t),zwr=r(cUe," (UniSpeechSat model)"),cUe.forEach(t),Qwr=i(We),LC=n(We,"LI",{});var mUe=s(LC);D5e=n(mUe,"STRONG",{});var lKt=s(D5e);Wwr=r(lKt,"wav2vec2"),lKt.forEach(t),Uwr=r(mUe," \u2014 "),IK=n(mUe,"A",{href:!0});var iKt=s(IK);Hwr=r(iKt,"Wav2Vec2ForSequenceClassification"),iKt.forEach(t),Jwr=r(mUe," (Wav2Vec2 model)"),mUe.forEach(t),Ywr=i(We),yC=n(We,"LI",{});var fUe=s(yC);G5e=n(fUe,"STRONG",{});var dKt=s(G5e);Zwr=r(dKt,"wav2vec2-conformer"),dKt.forEach(t),Kwr=r(fUe," \u2014 "),NK=n(fUe,"A",{href:!0});var cKt=s(NK);eAr=r(cKt,"Wav2Vec2ConformerForSequenceClassification"),cKt.forEach(t),oAr=r(fUe," (Wav2Vec2-Conformer model)"),fUe.forEach(t),rAr=i(We),xC=n(We,"LI",{});var gUe=s(xC);O5e=n(gUe,"STRONG",{});var mKt=s(O5e);tAr=r(mKt,"wavlm"),mKt.forEach(t),aAr=r(gUe," \u2014 "),qK=n(gUe,"A",{href:!0});var fKt=s(qK);nAr=r(fKt,"WavLMForSequenceClassification"),fKt.forEach(t),sAr=r(gUe," (WavLM model)"),gUe.forEach(t),We.forEach(t),lAr=i(ja),$C=n(ja,"P",{});var hUe=s($C);iAr=r(hUe,"The model is set in evaluation mode by default using "),V5e=n(hUe,"CODE",{});var gKt=s(V5e);dAr=r(gKt,"model.eval()"),gKt.forEach(t),cAr=r(hUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X5e=n(hUe,"CODE",{});var hKt=s(X5e);mAr=r(hKt,"model.train()"),hKt.forEach(t),hUe.forEach(t),fAr=i(ja),T(kC.$$.fragment,ja),ja.forEach(t),Wl.forEach(t),_ro=i(m),Tc=n(m,"H2",{class:!0});var Rao=s(Tc);SC=n(Rao,"A",{id:!0,class:!0,href:!0});var uKt=s(SC);z5e=n(uKt,"SPAN",{});var pKt=s(z5e);T(Rk.$$.fragment,pKt),pKt.forEach(t),uKt.forEach(t),gAr=i(Rao),Q5e=n(Rao,"SPAN",{});var _Kt=s(Q5e);hAr=r(_Kt,"AutoModelForAudioFrameClassification"),_Kt.forEach(t),Rao.forEach(t),bro=i(m),Zo=n(m,"DIV",{class:!0});var Ul=s(Zo);T(Pk.$$.fragment,Ul),uAr=i(Ul),Mc=n(Ul,"P",{});var $de=s(Mc);pAr=r($de,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),jK=n($de,"A",{href:!0});var bKt=s(jK);_Ar=r(bKt,"from_pretrained()"),bKt.forEach(t),bAr=r($de," class method or the "),DK=n($de,"A",{href:!0});var vKt=s(DK);vAr=r(vKt,"from_config()"),vKt.forEach(t),FAr=r($de,` class
method.`),$de.forEach(t),TAr=i(Ul),Bk=n(Ul,"P",{});var Pao=s(Bk);MAr=r(Pao,"This class cannot be instantiated directly using "),W5e=n(Pao,"CODE",{});var FKt=s(W5e);EAr=r(FKt,"__init__()"),FKt.forEach(t),CAr=r(Pao," (throws an error)."),Pao.forEach(t),wAr=i(Ul),Nt=n(Ul,"DIV",{class:!0});var r9=s(Nt);T(Ik.$$.fragment,r9),AAr=i(r9),U5e=n(r9,"P",{});var TKt=s(U5e);LAr=r(TKt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),TKt.forEach(t),yAr=i(r9),Ec=n(r9,"P",{});var kde=s(Ec);xAr=r(kde,`Note:
Loading a model from its configuration file does `),H5e=n(kde,"STRONG",{});var MKt=s(H5e);$Ar=r(MKt,"not"),MKt.forEach(t),kAr=r(kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=n(kde,"A",{href:!0});var EKt=s(GK);SAr=r(EKt,"from_pretrained()"),EKt.forEach(t),RAr=r(kde," to load the model weights."),kde.forEach(t),PAr=i(r9),T(RC.$$.fragment,r9),r9.forEach(t),BAr=i(Ul),_o=n(Ul,"DIV",{class:!0});var Da=s(_o);T(Nk.$$.fragment,Da),IAr=i(Da),J5e=n(Da,"P",{});var CKt=s(J5e);NAr=r(CKt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),CKt.forEach(t),qAr=i(Da),bn=n(Da,"P",{});var t9=s(bn);jAr=r(t9,"The model class to instantiate is selected based on the "),Y5e=n(t9,"CODE",{});var wKt=s(Y5e);DAr=r(wKt,"model_type"),wKt.forEach(t),GAr=r(t9,` property of the config object (either
passed as an argument or loaded from `),Z5e=n(t9,"CODE",{});var AKt=s(Z5e);OAr=r(AKt,"pretrained_model_name_or_path"),AKt.forEach(t),VAr=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=n(t9,"CODE",{});var LKt=s(K5e);XAr=r(LKt,"pretrained_model_name_or_path"),LKt.forEach(t),zAr=r(t9,":"),t9.forEach(t),QAr=i(Da),gt=n(Da,"UL",{});var Hl=s(gt);PC=n(Hl,"LI",{});var uUe=s(PC);e0e=n(uUe,"STRONG",{});var yKt=s(e0e);WAr=r(yKt,"data2vec-audio"),yKt.forEach(t),UAr=r(uUe," \u2014 "),OK=n(uUe,"A",{href:!0});var xKt=s(OK);HAr=r(xKt,"Data2VecAudioForAudioFrameClassification"),xKt.forEach(t),JAr=r(uUe," (Data2VecAudio model)"),uUe.forEach(t),YAr=i(Hl),BC=n(Hl,"LI",{});var pUe=s(BC);o0e=n(pUe,"STRONG",{});var $Kt=s(o0e);ZAr=r($Kt,"unispeech-sat"),$Kt.forEach(t),KAr=r(pUe," \u2014 "),VK=n(pUe,"A",{href:!0});var kKt=s(VK);e6r=r(kKt,"UniSpeechSatForAudioFrameClassification"),kKt.forEach(t),o6r=r(pUe," (UniSpeechSat model)"),pUe.forEach(t),r6r=i(Hl),IC=n(Hl,"LI",{});var _Ue=s(IC);r0e=n(_Ue,"STRONG",{});var SKt=s(r0e);t6r=r(SKt,"wav2vec2"),SKt.forEach(t),a6r=r(_Ue," \u2014 "),XK=n(_Ue,"A",{href:!0});var RKt=s(XK);n6r=r(RKt,"Wav2Vec2ForAudioFrameClassification"),RKt.forEach(t),s6r=r(_Ue," (Wav2Vec2 model)"),_Ue.forEach(t),l6r=i(Hl),NC=n(Hl,"LI",{});var bUe=s(NC);t0e=n(bUe,"STRONG",{});var PKt=s(t0e);i6r=r(PKt,"wav2vec2-conformer"),PKt.forEach(t),d6r=r(bUe," \u2014 "),zK=n(bUe,"A",{href:!0});var BKt=s(zK);c6r=r(BKt,"Wav2Vec2ConformerForAudioFrameClassification"),BKt.forEach(t),m6r=r(bUe," (Wav2Vec2-Conformer model)"),bUe.forEach(t),f6r=i(Hl),qC=n(Hl,"LI",{});var vUe=s(qC);a0e=n(vUe,"STRONG",{});var IKt=s(a0e);g6r=r(IKt,"wavlm"),IKt.forEach(t),h6r=r(vUe," \u2014 "),QK=n(vUe,"A",{href:!0});var NKt=s(QK);u6r=r(NKt,"WavLMForAudioFrameClassification"),NKt.forEach(t),p6r=r(vUe," (WavLM model)"),vUe.forEach(t),Hl.forEach(t),_6r=i(Da),jC=n(Da,"P",{});var FUe=s(jC);b6r=r(FUe,"The model is set in evaluation mode by default using "),n0e=n(FUe,"CODE",{});var qKt=s(n0e);v6r=r(qKt,"model.eval()"),qKt.forEach(t),F6r=r(FUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s0e=n(FUe,"CODE",{});var jKt=s(s0e);T6r=r(jKt,"model.train()"),jKt.forEach(t),FUe.forEach(t),M6r=i(Da),T(DC.$$.fragment,Da),Da.forEach(t),Ul.forEach(t),vro=i(m),Cc=n(m,"H2",{class:!0});var Bao=s(Cc);GC=n(Bao,"A",{id:!0,class:!0,href:!0});var DKt=s(GC);l0e=n(DKt,"SPAN",{});var GKt=s(l0e);T(qk.$$.fragment,GKt),GKt.forEach(t),DKt.forEach(t),E6r=i(Bao),i0e=n(Bao,"SPAN",{});var OKt=s(i0e);C6r=r(OKt,"AutoModelForCTC"),OKt.forEach(t),Bao.forEach(t),Fro=i(m),Ko=n(m,"DIV",{class:!0});var Jl=s(Ko);T(jk.$$.fragment,Jl),w6r=i(Jl),wc=n(Jl,"P",{});var Sde=s(wc);A6r=r(Sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),WK=n(Sde,"A",{href:!0});var VKt=s(WK);L6r=r(VKt,"from_pretrained()"),VKt.forEach(t),y6r=r(Sde," class method or the "),UK=n(Sde,"A",{href:!0});var XKt=s(UK);x6r=r(XKt,"from_config()"),XKt.forEach(t),$6r=r(Sde,` class
method.`),Sde.forEach(t),k6r=i(Jl),Dk=n(Jl,"P",{});var Iao=s(Dk);S6r=r(Iao,"This class cannot be instantiated directly using "),d0e=n(Iao,"CODE",{});var zKt=s(d0e);R6r=r(zKt,"__init__()"),zKt.forEach(t),P6r=r(Iao," (throws an error)."),Iao.forEach(t),B6r=i(Jl),qt=n(Jl,"DIV",{class:!0});var a9=s(qt);T(Gk.$$.fragment,a9),I6r=i(a9),c0e=n(a9,"P",{});var QKt=s(c0e);N6r=r(QKt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),QKt.forEach(t),q6r=i(a9),Ac=n(a9,"P",{});var Rde=s(Ac);j6r=r(Rde,`Note:
Loading a model from its configuration file does `),m0e=n(Rde,"STRONG",{});var WKt=s(m0e);D6r=r(WKt,"not"),WKt.forEach(t),G6r=r(Rde,` load the model weights. It only affects the
model\u2019s configuration. Use `),HK=n(Rde,"A",{href:!0});var UKt=s(HK);O6r=r(UKt,"from_pretrained()"),UKt.forEach(t),V6r=r(Rde," to load the model weights."),Rde.forEach(t),X6r=i(a9),T(OC.$$.fragment,a9),a9.forEach(t),z6r=i(Jl),bo=n(Jl,"DIV",{class:!0});var Ga=s(bo);T(Ok.$$.fragment,Ga),Q6r=i(Ga),f0e=n(Ga,"P",{});var HKt=s(f0e);W6r=r(HKt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),HKt.forEach(t),U6r=i(Ga),vn=n(Ga,"P",{});var n9=s(vn);H6r=r(n9,"The model class to instantiate is selected based on the "),g0e=n(n9,"CODE",{});var JKt=s(g0e);J6r=r(JKt,"model_type"),JKt.forEach(t),Y6r=r(n9,` property of the config object (either
passed as an argument or loaded from `),h0e=n(n9,"CODE",{});var YKt=s(h0e);Z6r=r(YKt,"pretrained_model_name_or_path"),YKt.forEach(t),K6r=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u0e=n(n9,"CODE",{});var ZKt=s(u0e);e7r=r(ZKt,"pretrained_model_name_or_path"),ZKt.forEach(t),o7r=r(n9,":"),n9.forEach(t),r7r=i(Ga),Le=n(Ga,"UL",{});var Ie=s(Le);VC=n(Ie,"LI",{});var TUe=s(VC);p0e=n(TUe,"STRONG",{});var KKt=s(p0e);t7r=r(KKt,"data2vec-audio"),KKt.forEach(t),a7r=r(TUe," \u2014 "),JK=n(TUe,"A",{href:!0});var eea=s(JK);n7r=r(eea,"Data2VecAudioForCTC"),eea.forEach(t),s7r=r(TUe," (Data2VecAudio model)"),TUe.forEach(t),l7r=i(Ie),XC=n(Ie,"LI",{});var MUe=s(XC);_0e=n(MUe,"STRONG",{});var oea=s(_0e);i7r=r(oea,"hubert"),oea.forEach(t),d7r=r(MUe," \u2014 "),YK=n(MUe,"A",{href:!0});var rea=s(YK);c7r=r(rea,"HubertForCTC"),rea.forEach(t),m7r=r(MUe," (Hubert model)"),MUe.forEach(t),f7r=i(Ie),zC=n(Ie,"LI",{});var EUe=s(zC);b0e=n(EUe,"STRONG",{});var tea=s(b0e);g7r=r(tea,"mctct"),tea.forEach(t),h7r=r(EUe," \u2014 "),ZK=n(EUe,"A",{href:!0});var aea=s(ZK);u7r=r(aea,"MCTCTForCTC"),aea.forEach(t),p7r=r(EUe," (M-CTC-T model)"),EUe.forEach(t),_7r=i(Ie),QC=n(Ie,"LI",{});var CUe=s(QC);v0e=n(CUe,"STRONG",{});var nea=s(v0e);b7r=r(nea,"sew"),nea.forEach(t),v7r=r(CUe," \u2014 "),KK=n(CUe,"A",{href:!0});var sea=s(KK);F7r=r(sea,"SEWForCTC"),sea.forEach(t),T7r=r(CUe," (SEW model)"),CUe.forEach(t),M7r=i(Ie),WC=n(Ie,"LI",{});var wUe=s(WC);F0e=n(wUe,"STRONG",{});var lea=s(F0e);E7r=r(lea,"sew-d"),lea.forEach(t),C7r=r(wUe," \u2014 "),eee=n(wUe,"A",{href:!0});var iea=s(eee);w7r=r(iea,"SEWDForCTC"),iea.forEach(t),A7r=r(wUe," (SEW-D model)"),wUe.forEach(t),L7r=i(Ie),UC=n(Ie,"LI",{});var AUe=s(UC);T0e=n(AUe,"STRONG",{});var dea=s(T0e);y7r=r(dea,"unispeech"),dea.forEach(t),x7r=r(AUe," \u2014 "),oee=n(AUe,"A",{href:!0});var cea=s(oee);$7r=r(cea,"UniSpeechForCTC"),cea.forEach(t),k7r=r(AUe," (UniSpeech model)"),AUe.forEach(t),S7r=i(Ie),HC=n(Ie,"LI",{});var LUe=s(HC);M0e=n(LUe,"STRONG",{});var mea=s(M0e);R7r=r(mea,"unispeech-sat"),mea.forEach(t),P7r=r(LUe," \u2014 "),ree=n(LUe,"A",{href:!0});var fea=s(ree);B7r=r(fea,"UniSpeechSatForCTC"),fea.forEach(t),I7r=r(LUe," (UniSpeechSat model)"),LUe.forEach(t),N7r=i(Ie),JC=n(Ie,"LI",{});var yUe=s(JC);E0e=n(yUe,"STRONG",{});var gea=s(E0e);q7r=r(gea,"wav2vec2"),gea.forEach(t),j7r=r(yUe," \u2014 "),tee=n(yUe,"A",{href:!0});var hea=s(tee);D7r=r(hea,"Wav2Vec2ForCTC"),hea.forEach(t),G7r=r(yUe," (Wav2Vec2 model)"),yUe.forEach(t),O7r=i(Ie),YC=n(Ie,"LI",{});var xUe=s(YC);C0e=n(xUe,"STRONG",{});var uea=s(C0e);V7r=r(uea,"wav2vec2-conformer"),uea.forEach(t),X7r=r(xUe," \u2014 "),aee=n(xUe,"A",{href:!0});var pea=s(aee);z7r=r(pea,"Wav2Vec2ConformerForCTC"),pea.forEach(t),Q7r=r(xUe," (Wav2Vec2-Conformer model)"),xUe.forEach(t),W7r=i(Ie),ZC=n(Ie,"LI",{});var $Ue=s(ZC);w0e=n($Ue,"STRONG",{});var _ea=s(w0e);U7r=r(_ea,"wavlm"),_ea.forEach(t),H7r=r($Ue," \u2014 "),nee=n($Ue,"A",{href:!0});var bea=s(nee);J7r=r(bea,"WavLMForCTC"),bea.forEach(t),Y7r=r($Ue," (WavLM model)"),$Ue.forEach(t),Ie.forEach(t),Z7r=i(Ga),KC=n(Ga,"P",{});var kUe=s(KC);K7r=r(kUe,"The model is set in evaluation mode by default using "),A0e=n(kUe,"CODE",{});var vea=s(A0e);eLr=r(vea,"model.eval()"),vea.forEach(t),oLr=r(kUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L0e=n(kUe,"CODE",{});var Fea=s(L0e);rLr=r(Fea,"model.train()"),Fea.forEach(t),kUe.forEach(t),tLr=i(Ga),T(e3.$$.fragment,Ga),Ga.forEach(t),Jl.forEach(t),Tro=i(m),Lc=n(m,"H2",{class:!0});var Nao=s(Lc);o3=n(Nao,"A",{id:!0,class:!0,href:!0});var Tea=s(o3);y0e=n(Tea,"SPAN",{});var Mea=s(y0e);T(Vk.$$.fragment,Mea),Mea.forEach(t),Tea.forEach(t),aLr=i(Nao),x0e=n(Nao,"SPAN",{});var Eea=s(x0e);nLr=r(Eea,"AutoModelForSpeechSeq2Seq"),Eea.forEach(t),Nao.forEach(t),Mro=i(m),er=n(m,"DIV",{class:!0});var Yl=s(er);T(Xk.$$.fragment,Yl),sLr=i(Yl),yc=n(Yl,"P",{});var Pde=s(yc);lLr=r(Pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),see=n(Pde,"A",{href:!0});var Cea=s(see);iLr=r(Cea,"from_pretrained()"),Cea.forEach(t),dLr=r(Pde," class method or the "),lee=n(Pde,"A",{href:!0});var wea=s(lee);cLr=r(wea,"from_config()"),wea.forEach(t),mLr=r(Pde,` class
method.`),Pde.forEach(t),fLr=i(Yl),zk=n(Yl,"P",{});var qao=s(zk);gLr=r(qao,"This class cannot be instantiated directly using "),$0e=n(qao,"CODE",{});var Aea=s($0e);hLr=r(Aea,"__init__()"),Aea.forEach(t),uLr=r(qao," (throws an error)."),qao.forEach(t),pLr=i(Yl),jt=n(Yl,"DIV",{class:!0});var s9=s(jt);T(Qk.$$.fragment,s9),_Lr=i(s9),k0e=n(s9,"P",{});var Lea=s(k0e);bLr=r(Lea,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Lea.forEach(t),vLr=i(s9),xc=n(s9,"P",{});var Bde=s(xc);FLr=r(Bde,`Note:
Loading a model from its configuration file does `),S0e=n(Bde,"STRONG",{});var yea=s(S0e);TLr=r(yea,"not"),yea.forEach(t),MLr=r(Bde,` load the model weights. It only affects the
model\u2019s configuration. Use `),iee=n(Bde,"A",{href:!0});var xea=s(iee);ELr=r(xea,"from_pretrained()"),xea.forEach(t),CLr=r(Bde," to load the model weights."),Bde.forEach(t),wLr=i(s9),T(r3.$$.fragment,s9),s9.forEach(t),ALr=i(Yl),vo=n(Yl,"DIV",{class:!0});var Oa=s(vo);T(Wk.$$.fragment,Oa),LLr=i(Oa),R0e=n(Oa,"P",{});var $ea=s(R0e);yLr=r($ea,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$ea.forEach(t),xLr=i(Oa),Fn=n(Oa,"P",{});var l9=s(Fn);$Lr=r(l9,"The model class to instantiate is selected based on the "),P0e=n(l9,"CODE",{});var kea=s(P0e);kLr=r(kea,"model_type"),kea.forEach(t),SLr=r(l9,` property of the config object (either
passed as an argument or loaded from `),B0e=n(l9,"CODE",{});var Sea=s(B0e);RLr=r(Sea,"pretrained_model_name_or_path"),Sea.forEach(t),PLr=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I0e=n(l9,"CODE",{});var Rea=s(I0e);BLr=r(Rea,"pretrained_model_name_or_path"),Rea.forEach(t),ILr=r(l9,":"),l9.forEach(t),NLr=i(Oa),$c=n(Oa,"UL",{});var Ide=s($c);t3=n(Ide,"LI",{});var SUe=s(t3);N0e=n(SUe,"STRONG",{});var Pea=s(N0e);qLr=r(Pea,"speech-encoder-decoder"),Pea.forEach(t),jLr=r(SUe," \u2014 "),dee=n(SUe,"A",{href:!0});var Bea=s(dee);DLr=r(Bea,"SpeechEncoderDecoderModel"),Bea.forEach(t),GLr=r(SUe," (Speech Encoder decoder model)"),SUe.forEach(t),OLr=i(Ide),a3=n(Ide,"LI",{});var RUe=s(a3);q0e=n(RUe,"STRONG",{});var Iea=s(q0e);VLr=r(Iea,"speech_to_text"),Iea.forEach(t),XLr=r(RUe," \u2014 "),cee=n(RUe,"A",{href:!0});var Nea=s(cee);zLr=r(Nea,"Speech2TextForConditionalGeneration"),Nea.forEach(t),QLr=r(RUe," (Speech2Text model)"),RUe.forEach(t),WLr=i(Ide),n3=n(Ide,"LI",{});var PUe=s(n3);j0e=n(PUe,"STRONG",{});var qea=s(j0e);ULr=r(qea,"whisper"),qea.forEach(t),HLr=r(PUe," \u2014 "),mee=n(PUe,"A",{href:!0});var jea=s(mee);JLr=r(jea,"WhisperForConditionalGeneration"),jea.forEach(t),YLr=r(PUe," (Whisper model)"),PUe.forEach(t),Ide.forEach(t),ZLr=i(Oa),s3=n(Oa,"P",{});var BUe=s(s3);KLr=r(BUe,"The model is set in evaluation mode by default using "),D0e=n(BUe,"CODE",{});var Dea=s(D0e);e8r=r(Dea,"model.eval()"),Dea.forEach(t),o8r=r(BUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G0e=n(BUe,"CODE",{});var Gea=s(G0e);r8r=r(Gea,"model.train()"),Gea.forEach(t),BUe.forEach(t),t8r=i(Oa),T(l3.$$.fragment,Oa),Oa.forEach(t),Yl.forEach(t),Ero=i(m),kc=n(m,"H2",{class:!0});var jao=s(kc);i3=n(jao,"A",{id:!0,class:!0,href:!0});var Oea=s(i3);O0e=n(Oea,"SPAN",{});var Vea=s(O0e);T(Uk.$$.fragment,Vea),Vea.forEach(t),Oea.forEach(t),a8r=i(jao),V0e=n(jao,"SPAN",{});var Xea=s(V0e);n8r=r(Xea,"AutoModelForAudioXVector"),Xea.forEach(t),jao.forEach(t),Cro=i(m),or=n(m,"DIV",{class:!0});var Zl=s(or);T(Hk.$$.fragment,Zl),s8r=i(Zl),Sc=n(Zl,"P",{});var Nde=s(Sc);l8r=r(Nde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),fee=n(Nde,"A",{href:!0});var zea=s(fee);i8r=r(zea,"from_pretrained()"),zea.forEach(t),d8r=r(Nde," class method or the "),gee=n(Nde,"A",{href:!0});var Qea=s(gee);c8r=r(Qea,"from_config()"),Qea.forEach(t),m8r=r(Nde,` class
method.`),Nde.forEach(t),f8r=i(Zl),Jk=n(Zl,"P",{});var Dao=s(Jk);g8r=r(Dao,"This class cannot be instantiated directly using "),X0e=n(Dao,"CODE",{});var Wea=s(X0e);h8r=r(Wea,"__init__()"),Wea.forEach(t),u8r=r(Dao," (throws an error)."),Dao.forEach(t),p8r=i(Zl),Dt=n(Zl,"DIV",{class:!0});var i9=s(Dt);T(Yk.$$.fragment,i9),_8r=i(i9),z0e=n(i9,"P",{});var Uea=s(z0e);b8r=r(Uea,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Uea.forEach(t),v8r=i(i9),Rc=n(i9,"P",{});var qde=s(Rc);F8r=r(qde,`Note:
Loading a model from its configuration file does `),Q0e=n(qde,"STRONG",{});var Hea=s(Q0e);T8r=r(Hea,"not"),Hea.forEach(t),M8r=r(qde,` load the model weights. It only affects the
model\u2019s configuration. Use `),hee=n(qde,"A",{href:!0});var Jea=s(hee);E8r=r(Jea,"from_pretrained()"),Jea.forEach(t),C8r=r(qde," to load the model weights."),qde.forEach(t),w8r=i(i9),T(d3.$$.fragment,i9),i9.forEach(t),A8r=i(Zl),Fo=n(Zl,"DIV",{class:!0});var Va=s(Fo);T(Zk.$$.fragment,Va),L8r=i(Va),W0e=n(Va,"P",{});var Yea=s(W0e);y8r=r(Yea,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Yea.forEach(t),x8r=i(Va),Tn=n(Va,"P",{});var d9=s(Tn);$8r=r(d9,"The model class to instantiate is selected based on the "),U0e=n(d9,"CODE",{});var Zea=s(U0e);k8r=r(Zea,"model_type"),Zea.forEach(t),S8r=r(d9,` property of the config object (either
passed as an argument or loaded from `),H0e=n(d9,"CODE",{});var Kea=s(H0e);R8r=r(Kea,"pretrained_model_name_or_path"),Kea.forEach(t),P8r=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J0e=n(d9,"CODE",{});var eoa=s(J0e);B8r=r(eoa,"pretrained_model_name_or_path"),eoa.forEach(t),I8r=r(d9,":"),d9.forEach(t),N8r=i(Va),ht=n(Va,"UL",{});var Kl=s(ht);c3=n(Kl,"LI",{});var IUe=s(c3);Y0e=n(IUe,"STRONG",{});var ooa=s(Y0e);q8r=r(ooa,"data2vec-audio"),ooa.forEach(t),j8r=r(IUe," \u2014 "),uee=n(IUe,"A",{href:!0});var roa=s(uee);D8r=r(roa,"Data2VecAudioForXVector"),roa.forEach(t),G8r=r(IUe," (Data2VecAudio model)"),IUe.forEach(t),O8r=i(Kl),m3=n(Kl,"LI",{});var NUe=s(m3);Z0e=n(NUe,"STRONG",{});var toa=s(Z0e);V8r=r(toa,"unispeech-sat"),toa.forEach(t),X8r=r(NUe," \u2014 "),pee=n(NUe,"A",{href:!0});var aoa=s(pee);z8r=r(aoa,"UniSpeechSatForXVector"),aoa.forEach(t),Q8r=r(NUe," (UniSpeechSat model)"),NUe.forEach(t),W8r=i(Kl),f3=n(Kl,"LI",{});var qUe=s(f3);K0e=n(qUe,"STRONG",{});var noa=s(K0e);U8r=r(noa,"wav2vec2"),noa.forEach(t),H8r=r(qUe," \u2014 "),_ee=n(qUe,"A",{href:!0});var soa=s(_ee);J8r=r(soa,"Wav2Vec2ForXVector"),soa.forEach(t),Y8r=r(qUe," (Wav2Vec2 model)"),qUe.forEach(t),Z8r=i(Kl),g3=n(Kl,"LI",{});var jUe=s(g3);ewe=n(jUe,"STRONG",{});var loa=s(ewe);K8r=r(loa,"wav2vec2-conformer"),loa.forEach(t),eyr=r(jUe," \u2014 "),bee=n(jUe,"A",{href:!0});var ioa=s(bee);oyr=r(ioa,"Wav2Vec2ConformerForXVector"),ioa.forEach(t),ryr=r(jUe," (Wav2Vec2-Conformer model)"),jUe.forEach(t),tyr=i(Kl),h3=n(Kl,"LI",{});var DUe=s(h3);owe=n(DUe,"STRONG",{});var doa=s(owe);ayr=r(doa,"wavlm"),doa.forEach(t),nyr=r(DUe," \u2014 "),vee=n(DUe,"A",{href:!0});var coa=s(vee);syr=r(coa,"WavLMForXVector"),coa.forEach(t),lyr=r(DUe," (WavLM model)"),DUe.forEach(t),Kl.forEach(t),iyr=i(Va),u3=n(Va,"P",{});var GUe=s(u3);dyr=r(GUe,"The model is set in evaluation mode by default using "),rwe=n(GUe,"CODE",{});var moa=s(rwe);cyr=r(moa,"model.eval()"),moa.forEach(t),myr=r(GUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),twe=n(GUe,"CODE",{});var foa=s(twe);fyr=r(foa,"model.train()"),foa.forEach(t),GUe.forEach(t),gyr=i(Va),T(p3.$$.fragment,Va),Va.forEach(t),Zl.forEach(t),wro=i(m),Pc=n(m,"H2",{class:!0});var Gao=s(Pc);_3=n(Gao,"A",{id:!0,class:!0,href:!0});var goa=s(_3);awe=n(goa,"SPAN",{});var hoa=s(awe);T(Kk.$$.fragment,hoa),hoa.forEach(t),goa.forEach(t),hyr=i(Gao),nwe=n(Gao,"SPAN",{});var uoa=s(nwe);uyr=r(uoa,"AutoModelForMaskedImageModeling"),uoa.forEach(t),Gao.forEach(t),Aro=i(m),rr=n(m,"DIV",{class:!0});var ei=s(rr);T(eS.$$.fragment,ei),pyr=i(ei),Bc=n(ei,"P",{});var jde=s(Bc);_yr=r(jde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Fee=n(jde,"A",{href:!0});var poa=s(Fee);byr=r(poa,"from_pretrained()"),poa.forEach(t),vyr=r(jde," class method or the "),Tee=n(jde,"A",{href:!0});var _oa=s(Tee);Fyr=r(_oa,"from_config()"),_oa.forEach(t),Tyr=r(jde,` class
method.`),jde.forEach(t),Myr=i(ei),oS=n(ei,"P",{});var Oao=s(oS);Eyr=r(Oao,"This class cannot be instantiated directly using "),swe=n(Oao,"CODE",{});var boa=s(swe);Cyr=r(boa,"__init__()"),boa.forEach(t),wyr=r(Oao," (throws an error)."),Oao.forEach(t),Ayr=i(ei),Gt=n(ei,"DIV",{class:!0});var c9=s(Gt);T(rS.$$.fragment,c9),Lyr=i(c9),lwe=n(c9,"P",{});var voa=s(lwe);yyr=r(voa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),voa.forEach(t),xyr=i(c9),Ic=n(c9,"P",{});var Dde=s(Ic);$yr=r(Dde,`Note:
Loading a model from its configuration file does `),iwe=n(Dde,"STRONG",{});var Foa=s(iwe);kyr=r(Foa,"not"),Foa.forEach(t),Syr=r(Dde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mee=n(Dde,"A",{href:!0});var Toa=s(Mee);Ryr=r(Toa,"from_pretrained()"),Toa.forEach(t),Pyr=r(Dde," to load the model weights."),Dde.forEach(t),Byr=i(c9),T(b3.$$.fragment,c9),c9.forEach(t),Iyr=i(ei),To=n(ei,"DIV",{class:!0});var Xa=s(To);T(tS.$$.fragment,Xa),Nyr=i(Xa),dwe=n(Xa,"P",{});var Moa=s(dwe);qyr=r(Moa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Moa.forEach(t),jyr=i(Xa),Mn=n(Xa,"P",{});var m9=s(Mn);Dyr=r(m9,"The model class to instantiate is selected based on the "),cwe=n(m9,"CODE",{});var Eoa=s(cwe);Gyr=r(Eoa,"model_type"),Eoa.forEach(t),Oyr=r(m9,` property of the config object (either
passed as an argument or loaded from `),mwe=n(m9,"CODE",{});var Coa=s(mwe);Vyr=r(Coa,"pretrained_model_name_or_path"),Coa.forEach(t),Xyr=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fwe=n(m9,"CODE",{});var woa=s(fwe);zyr=r(woa,"pretrained_model_name_or_path"),woa.forEach(t),Qyr=r(m9,":"),m9.forEach(t),Wyr=i(Xa),En=n(Xa,"UL",{});var f9=s(En);v3=n(f9,"LI",{});var OUe=s(v3);gwe=n(OUe,"STRONG",{});var Aoa=s(gwe);Uyr=r(Aoa,"deit"),Aoa.forEach(t),Hyr=r(OUe," \u2014 "),Eee=n(OUe,"A",{href:!0});var Loa=s(Eee);Jyr=r(Loa,"DeiTForMaskedImageModeling"),Loa.forEach(t),Yyr=r(OUe," (DeiT model)"),OUe.forEach(t),Zyr=i(f9),F3=n(f9,"LI",{});var VUe=s(F3);hwe=n(VUe,"STRONG",{});var yoa=s(hwe);Kyr=r(yoa,"swin"),yoa.forEach(t),e9r=r(VUe," \u2014 "),Cee=n(VUe,"A",{href:!0});var xoa=s(Cee);o9r=r(xoa,"SwinForMaskedImageModeling"),xoa.forEach(t),r9r=r(VUe," (Swin Transformer model)"),VUe.forEach(t),t9r=i(f9),T3=n(f9,"LI",{});var XUe=s(T3);uwe=n(XUe,"STRONG",{});var $oa=s(uwe);a9r=r($oa,"swinv2"),$oa.forEach(t),n9r=r(XUe," \u2014 "),wee=n(XUe,"A",{href:!0});var koa=s(wee);s9r=r(koa,"Swinv2ForMaskedImageModeling"),koa.forEach(t),l9r=r(XUe," (Swin Transformer V2 model)"),XUe.forEach(t),i9r=i(f9),M3=n(f9,"LI",{});var zUe=s(M3);pwe=n(zUe,"STRONG",{});var Soa=s(pwe);d9r=r(Soa,"vit"),Soa.forEach(t),c9r=r(zUe," \u2014 "),Aee=n(zUe,"A",{href:!0});var Roa=s(Aee);m9r=r(Roa,"ViTForMaskedImageModeling"),Roa.forEach(t),f9r=r(zUe," (ViT model)"),zUe.forEach(t),f9.forEach(t),g9r=i(Xa),E3=n(Xa,"P",{});var QUe=s(E3);h9r=r(QUe,"The model is set in evaluation mode by default using "),_we=n(QUe,"CODE",{});var Poa=s(_we);u9r=r(Poa,"model.eval()"),Poa.forEach(t),p9r=r(QUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bwe=n(QUe,"CODE",{});var Boa=s(bwe);_9r=r(Boa,"model.train()"),Boa.forEach(t),QUe.forEach(t),b9r=i(Xa),T(C3.$$.fragment,Xa),Xa.forEach(t),ei.forEach(t),Lro=i(m),Nc=n(m,"H2",{class:!0});var Vao=s(Nc);w3=n(Vao,"A",{id:!0,class:!0,href:!0});var Ioa=s(w3);vwe=n(Ioa,"SPAN",{});var Noa=s(vwe);T(aS.$$.fragment,Noa),Noa.forEach(t),Ioa.forEach(t),v9r=i(Vao),Fwe=n(Vao,"SPAN",{});var qoa=s(Fwe);F9r=r(qoa,"AutoModelForObjectDetection"),qoa.forEach(t),Vao.forEach(t),yro=i(m),tr=n(m,"DIV",{class:!0});var oi=s(tr);T(nS.$$.fragment,oi),T9r=i(oi),qc=n(oi,"P",{});var Gde=s(qc);M9r=r(Gde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Lee=n(Gde,"A",{href:!0});var joa=s(Lee);E9r=r(joa,"from_pretrained()"),joa.forEach(t),C9r=r(Gde," class method or the "),yee=n(Gde,"A",{href:!0});var Doa=s(yee);w9r=r(Doa,"from_config()"),Doa.forEach(t),A9r=r(Gde,` class
method.`),Gde.forEach(t),L9r=i(oi),sS=n(oi,"P",{});var Xao=s(sS);y9r=r(Xao,"This class cannot be instantiated directly using "),Twe=n(Xao,"CODE",{});var Goa=s(Twe);x9r=r(Goa,"__init__()"),Goa.forEach(t),$9r=r(Xao," (throws an error)."),Xao.forEach(t),k9r=i(oi),Ot=n(oi,"DIV",{class:!0});var g9=s(Ot);T(lS.$$.fragment,g9),S9r=i(g9),Mwe=n(g9,"P",{});var Ooa=s(Mwe);R9r=r(Ooa,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Ooa.forEach(t),P9r=i(g9),jc=n(g9,"P",{});var Ode=s(jc);B9r=r(Ode,`Note:
Loading a model from its configuration file does `),Ewe=n(Ode,"STRONG",{});var Voa=s(Ewe);I9r=r(Voa,"not"),Voa.forEach(t),N9r=r(Ode,` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=n(Ode,"A",{href:!0});var Xoa=s(xee);q9r=r(Xoa,"from_pretrained()"),Xoa.forEach(t),j9r=r(Ode," to load the model weights."),Ode.forEach(t),D9r=i(g9),T(A3.$$.fragment,g9),g9.forEach(t),G9r=i(oi),Mo=n(oi,"DIV",{class:!0});var za=s(Mo);T(iS.$$.fragment,za),O9r=i(za),Cwe=n(za,"P",{});var zoa=s(Cwe);V9r=r(zoa,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),zoa.forEach(t),X9r=i(za),Cn=n(za,"P",{});var h9=s(Cn);z9r=r(h9,"The model class to instantiate is selected based on the "),wwe=n(h9,"CODE",{});var Qoa=s(wwe);Q9r=r(Qoa,"model_type"),Qoa.forEach(t),W9r=r(h9,` property of the config object (either
passed as an argument or loaded from `),Awe=n(h9,"CODE",{});var Woa=s(Awe);U9r=r(Woa,"pretrained_model_name_or_path"),Woa.forEach(t),H9r=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lwe=n(h9,"CODE",{});var Uoa=s(Lwe);J9r=r(Uoa,"pretrained_model_name_or_path"),Uoa.forEach(t),Y9r=r(h9,":"),h9.forEach(t),Z9r=i(za),wn=n(za,"UL",{});var u9=s(wn);L3=n(u9,"LI",{});var WUe=s(L3);ywe=n(WUe,"STRONG",{});var Hoa=s(ywe);K9r=r(Hoa,"conditional_detr"),Hoa.forEach(t),exr=r(WUe," \u2014 "),$ee=n(WUe,"A",{href:!0});var Joa=s($ee);oxr=r(Joa,"ConditionalDetrForObjectDetection"),Joa.forEach(t),rxr=r(WUe," (Conditional DETR model)"),WUe.forEach(t),txr=i(u9),y3=n(u9,"LI",{});var UUe=s(y3);xwe=n(UUe,"STRONG",{});var Yoa=s(xwe);axr=r(Yoa,"deformable_detr"),Yoa.forEach(t),nxr=r(UUe," \u2014 "),kee=n(UUe,"A",{href:!0});var Zoa=s(kee);sxr=r(Zoa,"DeformableDetrForObjectDetection"),Zoa.forEach(t),lxr=r(UUe," (Deformable DETR model)"),UUe.forEach(t),ixr=i(u9),x3=n(u9,"LI",{});var HUe=s(x3);$we=n(HUe,"STRONG",{});var Koa=s($we);dxr=r(Koa,"detr"),Koa.forEach(t),cxr=r(HUe," \u2014 "),See=n(HUe,"A",{href:!0});var era=s(See);mxr=r(era,"DetrForObjectDetection"),era.forEach(t),fxr=r(HUe," (DETR model)"),HUe.forEach(t),gxr=i(u9),$3=n(u9,"LI",{});var JUe=s($3);kwe=n(JUe,"STRONG",{});var ora=s(kwe);hxr=r(ora,"yolos"),ora.forEach(t),uxr=r(JUe," \u2014 "),Ree=n(JUe,"A",{href:!0});var rra=s(Ree);pxr=r(rra,"YolosForObjectDetection"),rra.forEach(t),_xr=r(JUe," (YOLOS model)"),JUe.forEach(t),u9.forEach(t),bxr=i(za),k3=n(za,"P",{});var YUe=s(k3);vxr=r(YUe,"The model is set in evaluation mode by default using "),Swe=n(YUe,"CODE",{});var tra=s(Swe);Fxr=r(tra,"model.eval()"),tra.forEach(t),Txr=r(YUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rwe=n(YUe,"CODE",{});var ara=s(Rwe);Mxr=r(ara,"model.train()"),ara.forEach(t),YUe.forEach(t),Exr=i(za),T(S3.$$.fragment,za),za.forEach(t),oi.forEach(t),xro=i(m),Dc=n(m,"H2",{class:!0});var zao=s(Dc);R3=n(zao,"A",{id:!0,class:!0,href:!0});var nra=s(R3);Pwe=n(nra,"SPAN",{});var sra=s(Pwe);T(dS.$$.fragment,sra),sra.forEach(t),nra.forEach(t),Cxr=i(zao),Bwe=n(zao,"SPAN",{});var lra=s(Bwe);wxr=r(lra,"AutoModelForImageSegmentation"),lra.forEach(t),zao.forEach(t),$ro=i(m),ar=n(m,"DIV",{class:!0});var ri=s(ar);T(cS.$$.fragment,ri),Axr=i(ri),Gc=n(ri,"P",{});var Vde=s(Gc);Lxr=r(Vde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Pee=n(Vde,"A",{href:!0});var ira=s(Pee);yxr=r(ira,"from_pretrained()"),ira.forEach(t),xxr=r(Vde," class method or the "),Bee=n(Vde,"A",{href:!0});var dra=s(Bee);$xr=r(dra,"from_config()"),dra.forEach(t),kxr=r(Vde,` class
method.`),Vde.forEach(t),Sxr=i(ri),mS=n(ri,"P",{});var Qao=s(mS);Rxr=r(Qao,"This class cannot be instantiated directly using "),Iwe=n(Qao,"CODE",{});var cra=s(Iwe);Pxr=r(cra,"__init__()"),cra.forEach(t),Bxr=r(Qao," (throws an error)."),Qao.forEach(t),Ixr=i(ri),Vt=n(ri,"DIV",{class:!0});var p9=s(Vt);T(fS.$$.fragment,p9),Nxr=i(p9),Nwe=n(p9,"P",{});var mra=s(Nwe);qxr=r(mra,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),mra.forEach(t),jxr=i(p9),Oc=n(p9,"P",{});var Xde=s(Oc);Dxr=r(Xde,`Note:
Loading a model from its configuration file does `),qwe=n(Xde,"STRONG",{});var fra=s(qwe);Gxr=r(fra,"not"),fra.forEach(t),Oxr=r(Xde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=n(Xde,"A",{href:!0});var gra=s(Iee);Vxr=r(gra,"from_pretrained()"),gra.forEach(t),Xxr=r(Xde," to load the model weights."),Xde.forEach(t),zxr=i(p9),T(P3.$$.fragment,p9),p9.forEach(t),Qxr=i(ri),Eo=n(ri,"DIV",{class:!0});var Qa=s(Eo);T(gS.$$.fragment,Qa),Wxr=i(Qa),jwe=n(Qa,"P",{});var hra=s(jwe);Uxr=r(hra,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),hra.forEach(t),Hxr=i(Qa),An=n(Qa,"P",{});var _9=s(An);Jxr=r(_9,"The model class to instantiate is selected based on the "),Dwe=n(_9,"CODE",{});var ura=s(Dwe);Yxr=r(ura,"model_type"),ura.forEach(t),Zxr=r(_9,` property of the config object (either
passed as an argument or loaded from `),Gwe=n(_9,"CODE",{});var pra=s(Gwe);Kxr=r(pra,"pretrained_model_name_or_path"),pra.forEach(t),e$r=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Owe=n(_9,"CODE",{});var _ra=s(Owe);o$r=r(_ra,"pretrained_model_name_or_path"),_ra.forEach(t),r$r=r(_9,":"),_9.forEach(t),t$r=i(Qa),Vwe=n(Qa,"UL",{});var bra=s(Vwe);B3=n(bra,"LI",{});var ZUe=s(B3);Xwe=n(ZUe,"STRONG",{});var vra=s(Xwe);a$r=r(vra,"detr"),vra.forEach(t),n$r=r(ZUe," \u2014 "),Nee=n(ZUe,"A",{href:!0});var Fra=s(Nee);s$r=r(Fra,"DetrForSegmentation"),Fra.forEach(t),l$r=r(ZUe," (DETR model)"),ZUe.forEach(t),bra.forEach(t),i$r=i(Qa),I3=n(Qa,"P",{});var KUe=s(I3);d$r=r(KUe,"The model is set in evaluation mode by default using "),zwe=n(KUe,"CODE",{});var Tra=s(zwe);c$r=r(Tra,"model.eval()"),Tra.forEach(t),m$r=r(KUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qwe=n(KUe,"CODE",{});var Mra=s(Qwe);f$r=r(Mra,"model.train()"),Mra.forEach(t),KUe.forEach(t),g$r=i(Qa),T(N3.$$.fragment,Qa),Qa.forEach(t),ri.forEach(t),kro=i(m),Vc=n(m,"H2",{class:!0});var Wao=s(Vc);q3=n(Wao,"A",{id:!0,class:!0,href:!0});var Era=s(q3);Wwe=n(Era,"SPAN",{});var Cra=s(Wwe);T(hS.$$.fragment,Cra),Cra.forEach(t),Era.forEach(t),h$r=i(Wao),Uwe=n(Wao,"SPAN",{});var wra=s(Uwe);u$r=r(wra,"AutoModelForSemanticSegmentation"),wra.forEach(t),Wao.forEach(t),Sro=i(m),nr=n(m,"DIV",{class:!0});var ti=s(nr);T(uS.$$.fragment,ti),p$r=i(ti),Xc=n(ti,"P",{});var zde=s(Xc);_$r=r(zde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),qee=n(zde,"A",{href:!0});var Ara=s(qee);b$r=r(Ara,"from_pretrained()"),Ara.forEach(t),v$r=r(zde," class method or the "),jee=n(zde,"A",{href:!0});var Lra=s(jee);F$r=r(Lra,"from_config()"),Lra.forEach(t),T$r=r(zde,` class
method.`),zde.forEach(t),M$r=i(ti),pS=n(ti,"P",{});var Uao=s(pS);E$r=r(Uao,"This class cannot be instantiated directly using "),Hwe=n(Uao,"CODE",{});var yra=s(Hwe);C$r=r(yra,"__init__()"),yra.forEach(t),w$r=r(Uao," (throws an error)."),Uao.forEach(t),A$r=i(ti),Xt=n(ti,"DIV",{class:!0});var b9=s(Xt);T(_S.$$.fragment,b9),L$r=i(b9),Jwe=n(b9,"P",{});var xra=s(Jwe);y$r=r(xra,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),xra.forEach(t),x$r=i(b9),zc=n(b9,"P",{});var Qde=s(zc);$$r=r(Qde,`Note:
Loading a model from its configuration file does `),Ywe=n(Qde,"STRONG",{});var $ra=s(Ywe);k$r=r($ra,"not"),$ra.forEach(t),S$r=r(Qde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dee=n(Qde,"A",{href:!0});var kra=s(Dee);R$r=r(kra,"from_pretrained()"),kra.forEach(t),P$r=r(Qde," to load the model weights."),Qde.forEach(t),B$r=i(b9),T(j3.$$.fragment,b9),b9.forEach(t),I$r=i(ti),Co=n(ti,"DIV",{class:!0});var Wa=s(Co);T(bS.$$.fragment,Wa),N$r=i(Wa),Zwe=n(Wa,"P",{});var Sra=s(Zwe);q$r=r(Sra,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Sra.forEach(t),j$r=i(Wa),Ln=n(Wa,"P",{});var v9=s(Ln);D$r=r(v9,"The model class to instantiate is selected based on the "),Kwe=n(v9,"CODE",{});var Rra=s(Kwe);G$r=r(Rra,"model_type"),Rra.forEach(t),O$r=r(v9,` property of the config object (either
passed as an argument or loaded from `),eAe=n(v9,"CODE",{});var Pra=s(eAe);V$r=r(Pra,"pretrained_model_name_or_path"),Pra.forEach(t),X$r=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oAe=n(v9,"CODE",{});var Bra=s(oAe);z$r=r(Bra,"pretrained_model_name_or_path"),Bra.forEach(t),Q$r=r(v9,":"),v9.forEach(t),W$r=i(Wa),ut=n(Wa,"UL",{});var ai=s(ut);D3=n(ai,"LI",{});var eHe=s(D3);rAe=n(eHe,"STRONG",{});var Ira=s(rAe);U$r=r(Ira,"beit"),Ira.forEach(t),H$r=r(eHe," \u2014 "),Gee=n(eHe,"A",{href:!0});var Nra=s(Gee);J$r=r(Nra,"BeitForSemanticSegmentation"),Nra.forEach(t),Y$r=r(eHe," (BEiT model)"),eHe.forEach(t),Z$r=i(ai),G3=n(ai,"LI",{});var oHe=s(G3);tAe=n(oHe,"STRONG",{});var qra=s(tAe);K$r=r(qra,"data2vec-vision"),qra.forEach(t),ekr=r(oHe," \u2014 "),Oee=n(oHe,"A",{href:!0});var jra=s(Oee);okr=r(jra,"Data2VecVisionForSemanticSegmentation"),jra.forEach(t),rkr=r(oHe," (Data2VecVision model)"),oHe.forEach(t),tkr=i(ai),O3=n(ai,"LI",{});var rHe=s(O3);aAe=n(rHe,"STRONG",{});var Dra=s(aAe);akr=r(Dra,"dpt"),Dra.forEach(t),nkr=r(rHe," \u2014 "),Vee=n(rHe,"A",{href:!0});var Gra=s(Vee);skr=r(Gra,"DPTForSemanticSegmentation"),Gra.forEach(t),lkr=r(rHe," (DPT model)"),rHe.forEach(t),ikr=i(ai),V3=n(ai,"LI",{});var tHe=s(V3);nAe=n(tHe,"STRONG",{});var Ora=s(nAe);dkr=r(Ora,"mobilevit"),Ora.forEach(t),ckr=r(tHe," \u2014 "),Xee=n(tHe,"A",{href:!0});var Vra=s(Xee);mkr=r(Vra,"MobileViTForSemanticSegmentation"),Vra.forEach(t),fkr=r(tHe," (MobileViT model)"),tHe.forEach(t),gkr=i(ai),X3=n(ai,"LI",{});var aHe=s(X3);sAe=n(aHe,"STRONG",{});var Xra=s(sAe);hkr=r(Xra,"segformer"),Xra.forEach(t),ukr=r(aHe," \u2014 "),zee=n(aHe,"A",{href:!0});var zra=s(zee);pkr=r(zra,"SegformerForSemanticSegmentation"),zra.forEach(t),_kr=r(aHe," (SegFormer model)"),aHe.forEach(t),ai.forEach(t),bkr=i(Wa),z3=n(Wa,"P",{});var nHe=s(z3);vkr=r(nHe,"The model is set in evaluation mode by default using "),lAe=n(nHe,"CODE",{});var Qra=s(lAe);Fkr=r(Qra,"model.eval()"),Qra.forEach(t),Tkr=r(nHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iAe=n(nHe,"CODE",{});var Wra=s(iAe);Mkr=r(Wra,"model.train()"),Wra.forEach(t),nHe.forEach(t),Ekr=i(Wa),T(Q3.$$.fragment,Wa),Wa.forEach(t),ti.forEach(t),Rro=i(m),Qc=n(m,"H2",{class:!0});var Hao=s(Qc);W3=n(Hao,"A",{id:!0,class:!0,href:!0});var Ura=s(W3);dAe=n(Ura,"SPAN",{});var Hra=s(dAe);T(vS.$$.fragment,Hra),Hra.forEach(t),Ura.forEach(t),Ckr=i(Hao),cAe=n(Hao,"SPAN",{});var Jra=s(cAe);wkr=r(Jra,"AutoModelForInstanceSegmentation"),Jra.forEach(t),Hao.forEach(t),Pro=i(m),sr=n(m,"DIV",{class:!0});var ni=s(sr);T(FS.$$.fragment,ni),Akr=i(ni),Wc=n(ni,"P",{});var Wde=s(Wc);Lkr=r(Wde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Qee=n(Wde,"A",{href:!0});var Yra=s(Qee);ykr=r(Yra,"from_pretrained()"),Yra.forEach(t),xkr=r(Wde," class method or the "),Wee=n(Wde,"A",{href:!0});var Zra=s(Wee);$kr=r(Zra,"from_config()"),Zra.forEach(t),kkr=r(Wde,` class
method.`),Wde.forEach(t),Skr=i(ni),TS=n(ni,"P",{});var Jao=s(TS);Rkr=r(Jao,"This class cannot be instantiated directly using "),mAe=n(Jao,"CODE",{});var Kra=s(mAe);Pkr=r(Kra,"__init__()"),Kra.forEach(t),Bkr=r(Jao," (throws an error)."),Jao.forEach(t),Ikr=i(ni),zt=n(ni,"DIV",{class:!0});var F9=s(zt);T(MS.$$.fragment,F9),Nkr=i(F9),fAe=n(F9,"P",{});var eta=s(fAe);qkr=r(eta,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),eta.forEach(t),jkr=i(F9),Uc=n(F9,"P",{});var Ude=s(Uc);Dkr=r(Ude,`Note:
Loading a model from its configuration file does `),gAe=n(Ude,"STRONG",{});var ota=s(gAe);Gkr=r(ota,"not"),ota.forEach(t),Okr=r(Ude,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uee=n(Ude,"A",{href:!0});var rta=s(Uee);Vkr=r(rta,"from_pretrained()"),rta.forEach(t),Xkr=r(Ude," to load the model weights."),Ude.forEach(t),zkr=i(F9),T(U3.$$.fragment,F9),F9.forEach(t),Qkr=i(ni),wo=n(ni,"DIV",{class:!0});var Ua=s(wo);T(ES.$$.fragment,Ua),Wkr=i(Ua),hAe=n(Ua,"P",{});var tta=s(hAe);Ukr=r(tta,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),tta.forEach(t),Hkr=i(Ua),yn=n(Ua,"P",{});var T9=s(yn);Jkr=r(T9,"The model class to instantiate is selected based on the "),uAe=n(T9,"CODE",{});var ata=s(uAe);Ykr=r(ata,"model_type"),ata.forEach(t),Zkr=r(T9,` property of the config object (either
passed as an argument or loaded from `),pAe=n(T9,"CODE",{});var nta=s(pAe);Kkr=r(nta,"pretrained_model_name_or_path"),nta.forEach(t),eSr=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ae=n(T9,"CODE",{});var sta=s(_Ae);oSr=r(sta,"pretrained_model_name_or_path"),sta.forEach(t),rSr=r(T9,":"),T9.forEach(t),tSr=i(Ua),bAe=n(Ua,"UL",{});var lta=s(bAe);H3=n(lta,"LI",{});var sHe=s(H3);vAe=n(sHe,"STRONG",{});var ita=s(vAe);aSr=r(ita,"maskformer"),ita.forEach(t),nSr=r(sHe," \u2014 "),Hee=n(sHe,"A",{href:!0});var dta=s(Hee);sSr=r(dta,"MaskFormerForInstanceSegmentation"),dta.forEach(t),lSr=r(sHe," (MaskFormer model)"),sHe.forEach(t),lta.forEach(t),iSr=i(Ua),J3=n(Ua,"P",{});var lHe=s(J3);dSr=r(lHe,"The model is set in evaluation mode by default using "),FAe=n(lHe,"CODE",{});var cta=s(FAe);cSr=r(cta,"model.eval()"),cta.forEach(t),mSr=r(lHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TAe=n(lHe,"CODE",{});var mta=s(TAe);fSr=r(mta,"model.train()"),mta.forEach(t),lHe.forEach(t),gSr=i(Ua),T(Y3.$$.fragment,Ua),Ua.forEach(t),ni.forEach(t),Bro=i(m),Hc=n(m,"H2",{class:!0});var Yao=s(Hc);Z3=n(Yao,"A",{id:!0,class:!0,href:!0});var fta=s(Z3);MAe=n(fta,"SPAN",{});var gta=s(MAe);T(CS.$$.fragment,gta),gta.forEach(t),fta.forEach(t),hSr=i(Yao),EAe=n(Yao,"SPAN",{});var hta=s(EAe);uSr=r(hta,"AutoModelForZeroShotObjectDetection"),hta.forEach(t),Yao.forEach(t),Iro=i(m),lr=n(m,"DIV",{class:!0});var si=s(lr);T(wS.$$.fragment,si),pSr=i(si),Jc=n(si,"P",{});var Hde=s(Jc);_Sr=r(Hde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),Jee=n(Hde,"A",{href:!0});var uta=s(Jee);bSr=r(uta,"from_pretrained()"),uta.forEach(t),vSr=r(Hde," class method or the "),Yee=n(Hde,"A",{href:!0});var pta=s(Yee);FSr=r(pta,"from_config()"),pta.forEach(t),TSr=r(Hde,` class
method.`),Hde.forEach(t),MSr=i(si),AS=n(si,"P",{});var Zao=s(AS);ESr=r(Zao,"This class cannot be instantiated directly using "),CAe=n(Zao,"CODE",{});var _ta=s(CAe);CSr=r(_ta,"__init__()"),_ta.forEach(t),wSr=r(Zao," (throws an error)."),Zao.forEach(t),ASr=i(si),Qt=n(si,"DIV",{class:!0});var M9=s(Qt);T(LS.$$.fragment,M9),LSr=i(M9),wAe=n(M9,"P",{});var bta=s(wAe);ySr=r(bta,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),bta.forEach(t),xSr=i(M9),Yc=n(M9,"P",{});var Jde=s(Yc);$Sr=r(Jde,`Note:
Loading a model from its configuration file does `),AAe=n(Jde,"STRONG",{});var vta=s(AAe);kSr=r(vta,"not"),vta.forEach(t),SSr=r(Jde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zee=n(Jde,"A",{href:!0});var Fta=s(Zee);RSr=r(Fta,"from_pretrained()"),Fta.forEach(t),PSr=r(Jde," to load the model weights."),Jde.forEach(t),BSr=i(M9),T(K3.$$.fragment,M9),M9.forEach(t),ISr=i(si),Ao=n(si,"DIV",{class:!0});var Ha=s(Ao);T(yS.$$.fragment,Ha),NSr=i(Ha),LAe=n(Ha,"P",{});var Tta=s(LAe);qSr=r(Tta,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Tta.forEach(t),jSr=i(Ha),xn=n(Ha,"P",{});var E9=s(xn);DSr=r(E9,"The model class to instantiate is selected based on the "),yAe=n(E9,"CODE",{});var Mta=s(yAe);GSr=r(Mta,"model_type"),Mta.forEach(t),OSr=r(E9,` property of the config object (either
passed as an argument or loaded from `),xAe=n(E9,"CODE",{});var Eta=s(xAe);VSr=r(Eta,"pretrained_model_name_or_path"),Eta.forEach(t),XSr=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=n(E9,"CODE",{});var Cta=s($Ae);zSr=r(Cta,"pretrained_model_name_or_path"),Cta.forEach(t),QSr=r(E9,":"),E9.forEach(t),WSr=i(Ha),kAe=n(Ha,"UL",{});var wta=s(kAe);e5=n(wta,"LI",{});var iHe=s(e5);SAe=n(iHe,"STRONG",{});var Ata=s(SAe);USr=r(Ata,"owlvit"),Ata.forEach(t),HSr=r(iHe," \u2014 "),Kee=n(iHe,"A",{href:!0});var Lta=s(Kee);JSr=r(Lta,"OwlViTForObjectDetection"),Lta.forEach(t),YSr=r(iHe," (OWL-ViT model)"),iHe.forEach(t),wta.forEach(t),ZSr=i(Ha),o5=n(Ha,"P",{});var dHe=s(o5);KSr=r(dHe,"The model is set in evaluation mode by default using "),RAe=n(dHe,"CODE",{});var yta=s(RAe);eRr=r(yta,"model.eval()"),yta.forEach(t),oRr=r(dHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PAe=n(dHe,"CODE",{});var xta=s(PAe);rRr=r(xta,"model.train()"),xta.forEach(t),dHe.forEach(t),tRr=i(Ha),T(r5.$$.fragment,Ha),Ha.forEach(t),si.forEach(t),Nro=i(m),Zc=n(m,"H2",{class:!0});var Kao=s(Zc);t5=n(Kao,"A",{id:!0,class:!0,href:!0});var $ta=s(t5);BAe=n($ta,"SPAN",{});var kta=s(BAe);T(xS.$$.fragment,kta),kta.forEach(t),$ta.forEach(t),aRr=i(Kao),IAe=n(Kao,"SPAN",{});var Sta=s(IAe);nRr=r(Sta,"TFAutoModel"),Sta.forEach(t),Kao.forEach(t),qro=i(m),ir=n(m,"DIV",{class:!0});var li=s(ir);T($S.$$.fragment,li),sRr=i(li),Kc=n(li,"P",{});var Yde=s(Kc);lRr=r(Yde,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),eoe=n(Yde,"A",{href:!0});var Rta=s(eoe);iRr=r(Rta,"from_pretrained()"),Rta.forEach(t),dRr=r(Yde," class method or the "),ooe=n(Yde,"A",{href:!0});var Pta=s(ooe);cRr=r(Pta,"from_config()"),Pta.forEach(t),mRr=r(Yde,` class
method.`),Yde.forEach(t),fRr=i(li),kS=n(li,"P",{});var eno=s(kS);gRr=r(eno,"This class cannot be instantiated directly using "),NAe=n(eno,"CODE",{});var Bta=s(NAe);hRr=r(Bta,"__init__()"),Bta.forEach(t),uRr=r(eno," (throws an error)."),eno.forEach(t),pRr=i(li),Wt=n(li,"DIV",{class:!0});var C9=s(Wt);T(SS.$$.fragment,C9),_Rr=i(C9),qAe=n(C9,"P",{});var Ita=s(qAe);bRr=r(Ita,"Instantiates one of the base model classes of the library from a configuration."),Ita.forEach(t),vRr=i(C9),em=n(C9,"P",{});var Zde=s(em);FRr=r(Zde,`Note:
Loading a model from its configuration file does `),jAe=n(Zde,"STRONG",{});var Nta=s(jAe);TRr=r(Nta,"not"),Nta.forEach(t),MRr=r(Zde,` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=n(Zde,"A",{href:!0});var qta=s(roe);ERr=r(qta,"from_pretrained()"),qta.forEach(t),CRr=r(Zde," to load the model weights."),Zde.forEach(t),wRr=i(C9),T(a5.$$.fragment,C9),C9.forEach(t),ARr=i(li),qr=n(li,"DIV",{class:!0});var ii=s(qr);T(RS.$$.fragment,ii),LRr=i(ii),DAe=n(ii,"P",{});var jta=s(DAe);yRr=r(jta,"Instantiate one of the base model classes of the library from a pretrained model."),jta.forEach(t),xRr=i(ii),$n=n(ii,"P",{});var w9=s($n);$Rr=r(w9,"The model class to instantiate is selected based on the "),GAe=n(w9,"CODE",{});var Dta=s(GAe);kRr=r(Dta,"model_type"),Dta.forEach(t),SRr=r(w9,` property of the config object (either
passed as an argument or loaded from `),OAe=n(w9,"CODE",{});var Gta=s(OAe);RRr=r(Gta,"pretrained_model_name_or_path"),Gta.forEach(t),PRr=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VAe=n(w9,"CODE",{});var Ota=s(VAe);BRr=r(Ota,"pretrained_model_name_or_path"),Ota.forEach(t),IRr=r(w9,":"),w9.forEach(t),NRr=i(ii),P=n(ii,"UL",{});var I=s(P);n5=n(I,"LI",{});var cHe=s(n5);XAe=n(cHe,"STRONG",{});var Vta=s(XAe);qRr=r(Vta,"albert"),Vta.forEach(t),jRr=r(cHe," \u2014 "),toe=n(cHe,"A",{href:!0});var Xta=s(toe);DRr=r(Xta,"TFAlbertModel"),Xta.forEach(t),GRr=r(cHe," (ALBERT model)"),cHe.forEach(t),ORr=i(I),s5=n(I,"LI",{});var mHe=s(s5);zAe=n(mHe,"STRONG",{});var zta=s(zAe);VRr=r(zta,"bart"),zta.forEach(t),XRr=r(mHe," \u2014 "),aoe=n(mHe,"A",{href:!0});var Qta=s(aoe);zRr=r(Qta,"TFBartModel"),Qta.forEach(t),QRr=r(mHe," (BART model)"),mHe.forEach(t),WRr=i(I),l5=n(I,"LI",{});var fHe=s(l5);QAe=n(fHe,"STRONG",{});var Wta=s(QAe);URr=r(Wta,"bert"),Wta.forEach(t),HRr=r(fHe," \u2014 "),noe=n(fHe,"A",{href:!0});var Uta=s(noe);JRr=r(Uta,"TFBertModel"),Uta.forEach(t),YRr=r(fHe," (BERT model)"),fHe.forEach(t),ZRr=i(I),i5=n(I,"LI",{});var gHe=s(i5);WAe=n(gHe,"STRONG",{});var Hta=s(WAe);KRr=r(Hta,"blenderbot"),Hta.forEach(t),ePr=r(gHe," \u2014 "),soe=n(gHe,"A",{href:!0});var Jta=s(soe);oPr=r(Jta,"TFBlenderbotModel"),Jta.forEach(t),rPr=r(gHe," (Blenderbot model)"),gHe.forEach(t),tPr=i(I),d5=n(I,"LI",{});var hHe=s(d5);UAe=n(hHe,"STRONG",{});var Yta=s(UAe);aPr=r(Yta,"blenderbot-small"),Yta.forEach(t),nPr=r(hHe," \u2014 "),loe=n(hHe,"A",{href:!0});var Zta=s(loe);sPr=r(Zta,"TFBlenderbotSmallModel"),Zta.forEach(t),lPr=r(hHe," (BlenderbotSmall model)"),hHe.forEach(t),iPr=i(I),c5=n(I,"LI",{});var uHe=s(c5);HAe=n(uHe,"STRONG",{});var Kta=s(HAe);dPr=r(Kta,"camembert"),Kta.forEach(t),cPr=r(uHe," \u2014 "),ioe=n(uHe,"A",{href:!0});var eaa=s(ioe);mPr=r(eaa,"TFCamembertModel"),eaa.forEach(t),fPr=r(uHe," (CamemBERT model)"),uHe.forEach(t),gPr=i(I),m5=n(I,"LI",{});var pHe=s(m5);JAe=n(pHe,"STRONG",{});var oaa=s(JAe);hPr=r(oaa,"clip"),oaa.forEach(t),uPr=r(pHe," \u2014 "),doe=n(pHe,"A",{href:!0});var raa=s(doe);pPr=r(raa,"TFCLIPModel"),raa.forEach(t),_Pr=r(pHe," (CLIP model)"),pHe.forEach(t),bPr=i(I),f5=n(I,"LI",{});var _He=s(f5);YAe=n(_He,"STRONG",{});var taa=s(YAe);vPr=r(taa,"convbert"),taa.forEach(t),FPr=r(_He," \u2014 "),coe=n(_He,"A",{href:!0});var aaa=s(coe);TPr=r(aaa,"TFConvBertModel"),aaa.forEach(t),MPr=r(_He," (ConvBERT model)"),_He.forEach(t),EPr=i(I),g5=n(I,"LI",{});var bHe=s(g5);ZAe=n(bHe,"STRONG",{});var naa=s(ZAe);CPr=r(naa,"convnext"),naa.forEach(t),wPr=r(bHe," \u2014 "),moe=n(bHe,"A",{href:!0});var saa=s(moe);APr=r(saa,"TFConvNextModel"),saa.forEach(t),LPr=r(bHe," (ConvNeXT model)"),bHe.forEach(t),yPr=i(I),h5=n(I,"LI",{});var vHe=s(h5);KAe=n(vHe,"STRONG",{});var laa=s(KAe);xPr=r(laa,"ctrl"),laa.forEach(t),$Pr=r(vHe," \u2014 "),foe=n(vHe,"A",{href:!0});var iaa=s(foe);kPr=r(iaa,"TFCTRLModel"),iaa.forEach(t),SPr=r(vHe," (CTRL model)"),vHe.forEach(t),RPr=i(I),u5=n(I,"LI",{});var FHe=s(u5);e6e=n(FHe,"STRONG",{});var daa=s(e6e);PPr=r(daa,"cvt"),daa.forEach(t),BPr=r(FHe," \u2014 "),goe=n(FHe,"A",{href:!0});var caa=s(goe);IPr=r(caa,"TFCvtModel"),caa.forEach(t),NPr=r(FHe," (CvT model)"),FHe.forEach(t),qPr=i(I),p5=n(I,"LI",{});var THe=s(p5);o6e=n(THe,"STRONG",{});var maa=s(o6e);jPr=r(maa,"data2vec-vision"),maa.forEach(t),DPr=r(THe," \u2014 "),hoe=n(THe,"A",{href:!0});var faa=s(hoe);GPr=r(faa,"TFData2VecVisionModel"),faa.forEach(t),OPr=r(THe," (Data2VecVision model)"),THe.forEach(t),VPr=i(I),_5=n(I,"LI",{});var MHe=s(_5);r6e=n(MHe,"STRONG",{});var gaa=s(r6e);XPr=r(gaa,"deberta"),gaa.forEach(t),zPr=r(MHe," \u2014 "),uoe=n(MHe,"A",{href:!0});var haa=s(uoe);QPr=r(haa,"TFDebertaModel"),haa.forEach(t),WPr=r(MHe," (DeBERTa model)"),MHe.forEach(t),UPr=i(I),b5=n(I,"LI",{});var EHe=s(b5);t6e=n(EHe,"STRONG",{});var uaa=s(t6e);HPr=r(uaa,"deberta-v2"),uaa.forEach(t),JPr=r(EHe," \u2014 "),poe=n(EHe,"A",{href:!0});var paa=s(poe);YPr=r(paa,"TFDebertaV2Model"),paa.forEach(t),ZPr=r(EHe," (DeBERTa-v2 model)"),EHe.forEach(t),KPr=i(I),v5=n(I,"LI",{});var CHe=s(v5);a6e=n(CHe,"STRONG",{});var _aa=s(a6e);eBr=r(_aa,"deit"),_aa.forEach(t),oBr=r(CHe," \u2014 "),_oe=n(CHe,"A",{href:!0});var baa=s(_oe);rBr=r(baa,"TFDeiTModel"),baa.forEach(t),tBr=r(CHe," (DeiT model)"),CHe.forEach(t),aBr=i(I),F5=n(I,"LI",{});var wHe=s(F5);n6e=n(wHe,"STRONG",{});var vaa=s(n6e);nBr=r(vaa,"distilbert"),vaa.forEach(t),sBr=r(wHe," \u2014 "),boe=n(wHe,"A",{href:!0});var Faa=s(boe);lBr=r(Faa,"TFDistilBertModel"),Faa.forEach(t),iBr=r(wHe," (DistilBERT model)"),wHe.forEach(t),dBr=i(I),T5=n(I,"LI",{});var AHe=s(T5);s6e=n(AHe,"STRONG",{});var Taa=s(s6e);cBr=r(Taa,"dpr"),Taa.forEach(t),mBr=r(AHe," \u2014 "),voe=n(AHe,"A",{href:!0});var Maa=s(voe);fBr=r(Maa,"TFDPRQuestionEncoder"),Maa.forEach(t),gBr=r(AHe," (DPR model)"),AHe.forEach(t),hBr=i(I),M5=n(I,"LI",{});var LHe=s(M5);l6e=n(LHe,"STRONG",{});var Eaa=s(l6e);uBr=r(Eaa,"electra"),Eaa.forEach(t),pBr=r(LHe," \u2014 "),Foe=n(LHe,"A",{href:!0});var Caa=s(Foe);_Br=r(Caa,"TFElectraModel"),Caa.forEach(t),bBr=r(LHe," (ELECTRA model)"),LHe.forEach(t),vBr=i(I),E5=n(I,"LI",{});var yHe=s(E5);i6e=n(yHe,"STRONG",{});var waa=s(i6e);FBr=r(waa,"flaubert"),waa.forEach(t),TBr=r(yHe," \u2014 "),Toe=n(yHe,"A",{href:!0});var Aaa=s(Toe);MBr=r(Aaa,"TFFlaubertModel"),Aaa.forEach(t),EBr=r(yHe," (FlauBERT model)"),yHe.forEach(t),CBr=i(I),wl=n(I,"LI",{});var RI=s(wl);d6e=n(RI,"STRONG",{});var Laa=s(d6e);wBr=r(Laa,"funnel"),Laa.forEach(t),ABr=r(RI," \u2014 "),Moe=n(RI,"A",{href:!0});var yaa=s(Moe);LBr=r(yaa,"TFFunnelModel"),yaa.forEach(t),yBr=r(RI," or "),Eoe=n(RI,"A",{href:!0});var xaa=s(Eoe);xBr=r(xaa,"TFFunnelBaseModel"),xaa.forEach(t),$Br=r(RI," (Funnel Transformer model)"),RI.forEach(t),kBr=i(I),C5=n(I,"LI",{});var xHe=s(C5);c6e=n(xHe,"STRONG",{});var $aa=s(c6e);SBr=r($aa,"gpt2"),$aa.forEach(t),RBr=r(xHe," \u2014 "),Coe=n(xHe,"A",{href:!0});var kaa=s(Coe);PBr=r(kaa,"TFGPT2Model"),kaa.forEach(t),BBr=r(xHe," (OpenAI GPT-2 model)"),xHe.forEach(t),IBr=i(I),w5=n(I,"LI",{});var $He=s(w5);m6e=n($He,"STRONG",{});var Saa=s(m6e);NBr=r(Saa,"gptj"),Saa.forEach(t),qBr=r($He," \u2014 "),woe=n($He,"A",{href:!0});var Raa=s(woe);jBr=r(Raa,"TFGPTJModel"),Raa.forEach(t),DBr=r($He," (GPT-J model)"),$He.forEach(t),GBr=i(I),A5=n(I,"LI",{});var kHe=s(A5);f6e=n(kHe,"STRONG",{});var Paa=s(f6e);OBr=r(Paa,"groupvit"),Paa.forEach(t),VBr=r(kHe," \u2014 "),Aoe=n(kHe,"A",{href:!0});var Baa=s(Aoe);XBr=r(Baa,"TFGroupViTModel"),Baa.forEach(t),zBr=r(kHe," (GroupViT model)"),kHe.forEach(t),QBr=i(I),L5=n(I,"LI",{});var SHe=s(L5);g6e=n(SHe,"STRONG",{});var Iaa=s(g6e);WBr=r(Iaa,"hubert"),Iaa.forEach(t),UBr=r(SHe," \u2014 "),Loe=n(SHe,"A",{href:!0});var Naa=s(Loe);HBr=r(Naa,"TFHubertModel"),Naa.forEach(t),JBr=r(SHe," (Hubert model)"),SHe.forEach(t),YBr=i(I),y5=n(I,"LI",{});var RHe=s(y5);h6e=n(RHe,"STRONG",{});var qaa=s(h6e);ZBr=r(qaa,"layoutlm"),qaa.forEach(t),KBr=r(RHe," \u2014 "),yoe=n(RHe,"A",{href:!0});var jaa=s(yoe);eIr=r(jaa,"TFLayoutLMModel"),jaa.forEach(t),oIr=r(RHe," (LayoutLM model)"),RHe.forEach(t),rIr=i(I),x5=n(I,"LI",{});var PHe=s(x5);u6e=n(PHe,"STRONG",{});var Daa=s(u6e);tIr=r(Daa,"layoutlmv3"),Daa.forEach(t),aIr=r(PHe," \u2014 "),xoe=n(PHe,"A",{href:!0});var Gaa=s(xoe);nIr=r(Gaa,"TFLayoutLMv3Model"),Gaa.forEach(t),sIr=r(PHe," (LayoutLMv3 model)"),PHe.forEach(t),lIr=i(I),$5=n(I,"LI",{});var BHe=s($5);p6e=n(BHe,"STRONG",{});var Oaa=s(p6e);iIr=r(Oaa,"led"),Oaa.forEach(t),dIr=r(BHe," \u2014 "),$oe=n(BHe,"A",{href:!0});var Vaa=s($oe);cIr=r(Vaa,"TFLEDModel"),Vaa.forEach(t),mIr=r(BHe," (LED model)"),BHe.forEach(t),fIr=i(I),k5=n(I,"LI",{});var IHe=s(k5);_6e=n(IHe,"STRONG",{});var Xaa=s(_6e);gIr=r(Xaa,"longformer"),Xaa.forEach(t),hIr=r(IHe," \u2014 "),koe=n(IHe,"A",{href:!0});var zaa=s(koe);uIr=r(zaa,"TFLongformerModel"),zaa.forEach(t),pIr=r(IHe," (Longformer model)"),IHe.forEach(t),_Ir=i(I),S5=n(I,"LI",{});var NHe=s(S5);b6e=n(NHe,"STRONG",{});var Qaa=s(b6e);bIr=r(Qaa,"lxmert"),Qaa.forEach(t),vIr=r(NHe," \u2014 "),Soe=n(NHe,"A",{href:!0});var Waa=s(Soe);FIr=r(Waa,"TFLxmertModel"),Waa.forEach(t),TIr=r(NHe," (LXMERT model)"),NHe.forEach(t),MIr=i(I),R5=n(I,"LI",{});var qHe=s(R5);v6e=n(qHe,"STRONG",{});var Uaa=s(v6e);EIr=r(Uaa,"marian"),Uaa.forEach(t),CIr=r(qHe," \u2014 "),Roe=n(qHe,"A",{href:!0});var Haa=s(Roe);wIr=r(Haa,"TFMarianModel"),Haa.forEach(t),AIr=r(qHe," (Marian model)"),qHe.forEach(t),LIr=i(I),P5=n(I,"LI",{});var jHe=s(P5);F6e=n(jHe,"STRONG",{});var Jaa=s(F6e);yIr=r(Jaa,"mbart"),Jaa.forEach(t),xIr=r(jHe," \u2014 "),Poe=n(jHe,"A",{href:!0});var Yaa=s(Poe);$Ir=r(Yaa,"TFMBartModel"),Yaa.forEach(t),kIr=r(jHe," (mBART model)"),jHe.forEach(t),SIr=i(I),B5=n(I,"LI",{});var DHe=s(B5);T6e=n(DHe,"STRONG",{});var Zaa=s(T6e);RIr=r(Zaa,"mobilebert"),Zaa.forEach(t),PIr=r(DHe," \u2014 "),Boe=n(DHe,"A",{href:!0});var Kaa=s(Boe);BIr=r(Kaa,"TFMobileBertModel"),Kaa.forEach(t),IIr=r(DHe," (MobileBERT model)"),DHe.forEach(t),NIr=i(I),I5=n(I,"LI",{});var GHe=s(I5);M6e=n(GHe,"STRONG",{});var ena=s(M6e);qIr=r(ena,"mobilevit"),ena.forEach(t),jIr=r(GHe," \u2014 "),Ioe=n(GHe,"A",{href:!0});var ona=s(Ioe);DIr=r(ona,"TFMobileViTModel"),ona.forEach(t),GIr=r(GHe," (MobileViT model)"),GHe.forEach(t),OIr=i(I),N5=n(I,"LI",{});var OHe=s(N5);E6e=n(OHe,"STRONG",{});var rna=s(E6e);VIr=r(rna,"mpnet"),rna.forEach(t),XIr=r(OHe," \u2014 "),Noe=n(OHe,"A",{href:!0});var tna=s(Noe);zIr=r(tna,"TFMPNetModel"),tna.forEach(t),QIr=r(OHe," (MPNet model)"),OHe.forEach(t),WIr=i(I),q5=n(I,"LI",{});var VHe=s(q5);C6e=n(VHe,"STRONG",{});var ana=s(C6e);UIr=r(ana,"mt5"),ana.forEach(t),HIr=r(VHe," \u2014 "),qoe=n(VHe,"A",{href:!0});var nna=s(qoe);JIr=r(nna,"TFMT5Model"),nna.forEach(t),YIr=r(VHe," (MT5 model)"),VHe.forEach(t),ZIr=i(I),j5=n(I,"LI",{});var XHe=s(j5);w6e=n(XHe,"STRONG",{});var sna=s(w6e);KIr=r(sna,"openai-gpt"),sna.forEach(t),eNr=r(XHe," \u2014 "),joe=n(XHe,"A",{href:!0});var lna=s(joe);oNr=r(lna,"TFOpenAIGPTModel"),lna.forEach(t),rNr=r(XHe," (OpenAI GPT model)"),XHe.forEach(t),tNr=i(I),D5=n(I,"LI",{});var zHe=s(D5);A6e=n(zHe,"STRONG",{});var ina=s(A6e);aNr=r(ina,"opt"),ina.forEach(t),nNr=r(zHe," \u2014 "),Doe=n(zHe,"A",{href:!0});var dna=s(Doe);sNr=r(dna,"TFOPTModel"),dna.forEach(t),lNr=r(zHe," (OPT model)"),zHe.forEach(t),iNr=i(I),G5=n(I,"LI",{});var QHe=s(G5);L6e=n(QHe,"STRONG",{});var cna=s(L6e);dNr=r(cna,"pegasus"),cna.forEach(t),cNr=r(QHe," \u2014 "),Goe=n(QHe,"A",{href:!0});var mna=s(Goe);mNr=r(mna,"TFPegasusModel"),mna.forEach(t),fNr=r(QHe," (Pegasus model)"),QHe.forEach(t),gNr=i(I),O5=n(I,"LI",{});var WHe=s(O5);y6e=n(WHe,"STRONG",{});var fna=s(y6e);hNr=r(fna,"regnet"),fna.forEach(t),uNr=r(WHe," \u2014 "),Ooe=n(WHe,"A",{href:!0});var gna=s(Ooe);pNr=r(gna,"TFRegNetModel"),gna.forEach(t),_Nr=r(WHe," (RegNet model)"),WHe.forEach(t),bNr=i(I),V5=n(I,"LI",{});var UHe=s(V5);x6e=n(UHe,"STRONG",{});var hna=s(x6e);vNr=r(hna,"rembert"),hna.forEach(t),FNr=r(UHe," \u2014 "),Voe=n(UHe,"A",{href:!0});var una=s(Voe);TNr=r(una,"TFRemBertModel"),una.forEach(t),MNr=r(UHe," (RemBERT model)"),UHe.forEach(t),ENr=i(I),X5=n(I,"LI",{});var HHe=s(X5);$6e=n(HHe,"STRONG",{});var pna=s($6e);CNr=r(pna,"resnet"),pna.forEach(t),wNr=r(HHe," \u2014 "),Xoe=n(HHe,"A",{href:!0});var _na=s(Xoe);ANr=r(_na,"TFResNetModel"),_na.forEach(t),LNr=r(HHe," (ResNet model)"),HHe.forEach(t),yNr=i(I),z5=n(I,"LI",{});var JHe=s(z5);k6e=n(JHe,"STRONG",{});var bna=s(k6e);xNr=r(bna,"roberta"),bna.forEach(t),$Nr=r(JHe," \u2014 "),zoe=n(JHe,"A",{href:!0});var vna=s(zoe);kNr=r(vna,"TFRobertaModel"),vna.forEach(t),SNr=r(JHe," (RoBERTa model)"),JHe.forEach(t),RNr=i(I),Q5=n(I,"LI",{});var YHe=s(Q5);S6e=n(YHe,"STRONG",{});var Fna=s(S6e);PNr=r(Fna,"roformer"),Fna.forEach(t),BNr=r(YHe," \u2014 "),Qoe=n(YHe,"A",{href:!0});var Tna=s(Qoe);INr=r(Tna,"TFRoFormerModel"),Tna.forEach(t),NNr=r(YHe," (RoFormer model)"),YHe.forEach(t),qNr=i(I),W5=n(I,"LI",{});var ZHe=s(W5);R6e=n(ZHe,"STRONG",{});var Mna=s(R6e);jNr=r(Mna,"segformer"),Mna.forEach(t),DNr=r(ZHe," \u2014 "),Woe=n(ZHe,"A",{href:!0});var Ena=s(Woe);GNr=r(Ena,"TFSegformerModel"),Ena.forEach(t),ONr=r(ZHe," (SegFormer model)"),ZHe.forEach(t),VNr=i(I),U5=n(I,"LI",{});var KHe=s(U5);P6e=n(KHe,"STRONG",{});var Cna=s(P6e);XNr=r(Cna,"speech_to_text"),Cna.forEach(t),zNr=r(KHe," \u2014 "),Uoe=n(KHe,"A",{href:!0});var wna=s(Uoe);QNr=r(wna,"TFSpeech2TextModel"),wna.forEach(t),WNr=r(KHe," (Speech2Text model)"),KHe.forEach(t),UNr=i(I),H5=n(I,"LI",{});var eJe=s(H5);B6e=n(eJe,"STRONG",{});var Ana=s(B6e);HNr=r(Ana,"swin"),Ana.forEach(t),JNr=r(eJe," \u2014 "),Hoe=n(eJe,"A",{href:!0});var Lna=s(Hoe);YNr=r(Lna,"TFSwinModel"),Lna.forEach(t),ZNr=r(eJe," (Swin Transformer model)"),eJe.forEach(t),KNr=i(I),J5=n(I,"LI",{});var oJe=s(J5);I6e=n(oJe,"STRONG",{});var yna=s(I6e);eqr=r(yna,"t5"),yna.forEach(t),oqr=r(oJe," \u2014 "),Joe=n(oJe,"A",{href:!0});var xna=s(Joe);rqr=r(xna,"TFT5Model"),xna.forEach(t),tqr=r(oJe," (T5 model)"),oJe.forEach(t),aqr=i(I),Y5=n(I,"LI",{});var rJe=s(Y5);N6e=n(rJe,"STRONG",{});var $na=s(N6e);nqr=r($na,"tapas"),$na.forEach(t),sqr=r(rJe," \u2014 "),Yoe=n(rJe,"A",{href:!0});var kna=s(Yoe);lqr=r(kna,"TFTapasModel"),kna.forEach(t),iqr=r(rJe," (TAPAS model)"),rJe.forEach(t),dqr=i(I),Z5=n(I,"LI",{});var tJe=s(Z5);q6e=n(tJe,"STRONG",{});var Sna=s(q6e);cqr=r(Sna,"transfo-xl"),Sna.forEach(t),mqr=r(tJe," \u2014 "),Zoe=n(tJe,"A",{href:!0});var Rna=s(Zoe);fqr=r(Rna,"TFTransfoXLModel"),Rna.forEach(t),gqr=r(tJe," (Transformer-XL model)"),tJe.forEach(t),hqr=i(I),K5=n(I,"LI",{});var aJe=s(K5);j6e=n(aJe,"STRONG",{});var Pna=s(j6e);uqr=r(Pna,"vit"),Pna.forEach(t),pqr=r(aJe," \u2014 "),Koe=n(aJe,"A",{href:!0});var Bna=s(Koe);_qr=r(Bna,"TFViTModel"),Bna.forEach(t),bqr=r(aJe," (ViT model)"),aJe.forEach(t),vqr=i(I),e0=n(I,"LI",{});var nJe=s(e0);D6e=n(nJe,"STRONG",{});var Ina=s(D6e);Fqr=r(Ina,"vit_mae"),Ina.forEach(t),Tqr=r(nJe," \u2014 "),ere=n(nJe,"A",{href:!0});var Nna=s(ere);Mqr=r(Nna,"TFViTMAEModel"),Nna.forEach(t),Eqr=r(nJe," (ViTMAE model)"),nJe.forEach(t),Cqr=i(I),o0=n(I,"LI",{});var sJe=s(o0);G6e=n(sJe,"STRONG",{});var qna=s(G6e);wqr=r(qna,"wav2vec2"),qna.forEach(t),Aqr=r(sJe," \u2014 "),ore=n(sJe,"A",{href:!0});var jna=s(ore);Lqr=r(jna,"TFWav2Vec2Model"),jna.forEach(t),yqr=r(sJe," (Wav2Vec2 model)"),sJe.forEach(t),xqr=i(I),r0=n(I,"LI",{});var lJe=s(r0);O6e=n(lJe,"STRONG",{});var Dna=s(O6e);$qr=r(Dna,"whisper"),Dna.forEach(t),kqr=r(lJe," \u2014 "),rre=n(lJe,"A",{href:!0});var Gna=s(rre);Sqr=r(Gna,"TFWhisperModel"),Gna.forEach(t),Rqr=r(lJe," (Whisper model)"),lJe.forEach(t),Pqr=i(I),t0=n(I,"LI",{});var iJe=s(t0);V6e=n(iJe,"STRONG",{});var Ona=s(V6e);Bqr=r(Ona,"xglm"),Ona.forEach(t),Iqr=r(iJe," \u2014 "),tre=n(iJe,"A",{href:!0});var Vna=s(tre);Nqr=r(Vna,"TFXGLMModel"),Vna.forEach(t),qqr=r(iJe," (XGLM model)"),iJe.forEach(t),jqr=i(I),a0=n(I,"LI",{});var dJe=s(a0);X6e=n(dJe,"STRONG",{});var Xna=s(X6e);Dqr=r(Xna,"xlm"),Xna.forEach(t),Gqr=r(dJe," \u2014 "),are=n(dJe,"A",{href:!0});var zna=s(are);Oqr=r(zna,"TFXLMModel"),zna.forEach(t),Vqr=r(dJe," (XLM model)"),dJe.forEach(t),Xqr=i(I),n0=n(I,"LI",{});var cJe=s(n0);z6e=n(cJe,"STRONG",{});var Qna=s(z6e);zqr=r(Qna,"xlm-roberta"),Qna.forEach(t),Qqr=r(cJe," \u2014 "),nre=n(cJe,"A",{href:!0});var Wna=s(nre);Wqr=r(Wna,"TFXLMRobertaModel"),Wna.forEach(t),Uqr=r(cJe," (XLM-RoBERTa model)"),cJe.forEach(t),Hqr=i(I),s0=n(I,"LI",{});var mJe=s(s0);Q6e=n(mJe,"STRONG",{});var Una=s(Q6e);Jqr=r(Una,"xlnet"),Una.forEach(t),Yqr=r(mJe," \u2014 "),sre=n(mJe,"A",{href:!0});var Hna=s(sre);Zqr=r(Hna,"TFXLNetModel"),Hna.forEach(t),Kqr=r(mJe," (XLNet model)"),mJe.forEach(t),I.forEach(t),ejr=i(ii),T(l0.$$.fragment,ii),ii.forEach(t),li.forEach(t),jro=i(m),om=n(m,"H2",{class:!0});var ono=s(om);i0=n(ono,"A",{id:!0,class:!0,href:!0});var Jna=s(i0);W6e=n(Jna,"SPAN",{});var Yna=s(W6e);T(PS.$$.fragment,Yna),Yna.forEach(t),Jna.forEach(t),ojr=i(ono),U6e=n(ono,"SPAN",{});var Zna=s(U6e);rjr=r(Zna,"TFAutoModelForPreTraining"),Zna.forEach(t),ono.forEach(t),Dro=i(m),dr=n(m,"DIV",{class:!0});var di=s(dr);T(BS.$$.fragment,di),tjr=i(di),rm=n(di,"P",{});var Kde=s(rm);ajr=r(Kde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),lre=n(Kde,"A",{href:!0});var Kna=s(lre);njr=r(Kna,"from_pretrained()"),Kna.forEach(t),sjr=r(Kde," class method or the "),ire=n(Kde,"A",{href:!0});var esa=s(ire);ljr=r(esa,"from_config()"),esa.forEach(t),ijr=r(Kde,` class
method.`),Kde.forEach(t),djr=i(di),IS=n(di,"P",{});var rno=s(IS);cjr=r(rno,"This class cannot be instantiated directly using "),H6e=n(rno,"CODE",{});var osa=s(H6e);mjr=r(osa,"__init__()"),osa.forEach(t),fjr=r(rno," (throws an error)."),rno.forEach(t),gjr=i(di),Ut=n(di,"DIV",{class:!0});var A9=s(Ut);T(NS.$$.fragment,A9),hjr=i(A9),J6e=n(A9,"P",{});var rsa=s(J6e);ujr=r(rsa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),rsa.forEach(t),pjr=i(A9),tm=n(A9,"P",{});var ece=s(tm);_jr=r(ece,`Note:
Loading a model from its configuration file does `),Y6e=n(ece,"STRONG",{});var tsa=s(Y6e);bjr=r(tsa,"not"),tsa.forEach(t),vjr=r(ece,` load the model weights. It only affects the
model\u2019s configuration. Use `),dre=n(ece,"A",{href:!0});var asa=s(dre);Fjr=r(asa,"from_pretrained()"),asa.forEach(t),Tjr=r(ece," to load the model weights."),ece.forEach(t),Mjr=i(A9),T(d0.$$.fragment,A9),A9.forEach(t),Ejr=i(di),jr=n(di,"DIV",{class:!0});var ci=s(jr);T(qS.$$.fragment,ci),Cjr=i(ci),Z6e=n(ci,"P",{});var nsa=s(Z6e);wjr=r(nsa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nsa.forEach(t),Ajr=i(ci),kn=n(ci,"P",{});var L9=s(kn);Ljr=r(L9,"The model class to instantiate is selected based on the "),K6e=n(L9,"CODE",{});var ssa=s(K6e);yjr=r(ssa,"model_type"),ssa.forEach(t),xjr=r(L9,` property of the config object (either
passed as an argument or loaded from `),e7e=n(L9,"CODE",{});var lsa=s(e7e);$jr=r(lsa,"pretrained_model_name_or_path"),lsa.forEach(t),kjr=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=n(L9,"CODE",{});var isa=s(o7e);Sjr=r(isa,"pretrained_model_name_or_path"),isa.forEach(t),Rjr=r(L9,":"),L9.forEach(t),Pjr=i(ci),le=n(ci,"UL",{});var de=s(le);c0=n(de,"LI",{});var fJe=s(c0);r7e=n(fJe,"STRONG",{});var dsa=s(r7e);Bjr=r(dsa,"albert"),dsa.forEach(t),Ijr=r(fJe," \u2014 "),cre=n(fJe,"A",{href:!0});var csa=s(cre);Njr=r(csa,"TFAlbertForPreTraining"),csa.forEach(t),qjr=r(fJe," (ALBERT model)"),fJe.forEach(t),jjr=i(de),m0=n(de,"LI",{});var gJe=s(m0);t7e=n(gJe,"STRONG",{});var msa=s(t7e);Djr=r(msa,"bart"),msa.forEach(t),Gjr=r(gJe," \u2014 "),mre=n(gJe,"A",{href:!0});var fsa=s(mre);Ojr=r(fsa,"TFBartForConditionalGeneration"),fsa.forEach(t),Vjr=r(gJe," (BART model)"),gJe.forEach(t),Xjr=i(de),f0=n(de,"LI",{});var hJe=s(f0);a7e=n(hJe,"STRONG",{});var gsa=s(a7e);zjr=r(gsa,"bert"),gsa.forEach(t),Qjr=r(hJe," \u2014 "),fre=n(hJe,"A",{href:!0});var hsa=s(fre);Wjr=r(hsa,"TFBertForPreTraining"),hsa.forEach(t),Ujr=r(hJe," (BERT model)"),hJe.forEach(t),Hjr=i(de),g0=n(de,"LI",{});var uJe=s(g0);n7e=n(uJe,"STRONG",{});var usa=s(n7e);Jjr=r(usa,"camembert"),usa.forEach(t),Yjr=r(uJe," \u2014 "),gre=n(uJe,"A",{href:!0});var psa=s(gre);Zjr=r(psa,"TFCamembertForMaskedLM"),psa.forEach(t),Kjr=r(uJe," (CamemBERT model)"),uJe.forEach(t),eDr=i(de),h0=n(de,"LI",{});var pJe=s(h0);s7e=n(pJe,"STRONG",{});var _sa=s(s7e);oDr=r(_sa,"ctrl"),_sa.forEach(t),rDr=r(pJe," \u2014 "),hre=n(pJe,"A",{href:!0});var bsa=s(hre);tDr=r(bsa,"TFCTRLLMHeadModel"),bsa.forEach(t),aDr=r(pJe," (CTRL model)"),pJe.forEach(t),nDr=i(de),u0=n(de,"LI",{});var _Je=s(u0);l7e=n(_Je,"STRONG",{});var vsa=s(l7e);sDr=r(vsa,"distilbert"),vsa.forEach(t),lDr=r(_Je," \u2014 "),ure=n(_Je,"A",{href:!0});var Fsa=s(ure);iDr=r(Fsa,"TFDistilBertForMaskedLM"),Fsa.forEach(t),dDr=r(_Je," (DistilBERT model)"),_Je.forEach(t),cDr=i(de),p0=n(de,"LI",{});var bJe=s(p0);i7e=n(bJe,"STRONG",{});var Tsa=s(i7e);mDr=r(Tsa,"electra"),Tsa.forEach(t),fDr=r(bJe," \u2014 "),pre=n(bJe,"A",{href:!0});var Msa=s(pre);gDr=r(Msa,"TFElectraForPreTraining"),Msa.forEach(t),hDr=r(bJe," (ELECTRA model)"),bJe.forEach(t),uDr=i(de),_0=n(de,"LI",{});var vJe=s(_0);d7e=n(vJe,"STRONG",{});var Esa=s(d7e);pDr=r(Esa,"flaubert"),Esa.forEach(t),_Dr=r(vJe," \u2014 "),_re=n(vJe,"A",{href:!0});var Csa=s(_re);bDr=r(Csa,"TFFlaubertWithLMHeadModel"),Csa.forEach(t),vDr=r(vJe," (FlauBERT model)"),vJe.forEach(t),FDr=i(de),b0=n(de,"LI",{});var FJe=s(b0);c7e=n(FJe,"STRONG",{});var wsa=s(c7e);TDr=r(wsa,"funnel"),wsa.forEach(t),MDr=r(FJe," \u2014 "),bre=n(FJe,"A",{href:!0});var Asa=s(bre);EDr=r(Asa,"TFFunnelForPreTraining"),Asa.forEach(t),CDr=r(FJe," (Funnel Transformer model)"),FJe.forEach(t),wDr=i(de),v0=n(de,"LI",{});var TJe=s(v0);m7e=n(TJe,"STRONG",{});var Lsa=s(m7e);ADr=r(Lsa,"gpt2"),Lsa.forEach(t),LDr=r(TJe," \u2014 "),vre=n(TJe,"A",{href:!0});var ysa=s(vre);yDr=r(ysa,"TFGPT2LMHeadModel"),ysa.forEach(t),xDr=r(TJe," (OpenAI GPT-2 model)"),TJe.forEach(t),$Dr=i(de),F0=n(de,"LI",{});var MJe=s(F0);f7e=n(MJe,"STRONG",{});var xsa=s(f7e);kDr=r(xsa,"layoutlm"),xsa.forEach(t),SDr=r(MJe," \u2014 "),Fre=n(MJe,"A",{href:!0});var $sa=s(Fre);RDr=r($sa,"TFLayoutLMForMaskedLM"),$sa.forEach(t),PDr=r(MJe," (LayoutLM model)"),MJe.forEach(t),BDr=i(de),T0=n(de,"LI",{});var EJe=s(T0);g7e=n(EJe,"STRONG",{});var ksa=s(g7e);IDr=r(ksa,"lxmert"),ksa.forEach(t),NDr=r(EJe," \u2014 "),Tre=n(EJe,"A",{href:!0});var Ssa=s(Tre);qDr=r(Ssa,"TFLxmertForPreTraining"),Ssa.forEach(t),jDr=r(EJe," (LXMERT model)"),EJe.forEach(t),DDr=i(de),M0=n(de,"LI",{});var CJe=s(M0);h7e=n(CJe,"STRONG",{});var Rsa=s(h7e);GDr=r(Rsa,"mobilebert"),Rsa.forEach(t),ODr=r(CJe," \u2014 "),Mre=n(CJe,"A",{href:!0});var Psa=s(Mre);VDr=r(Psa,"TFMobileBertForPreTraining"),Psa.forEach(t),XDr=r(CJe," (MobileBERT model)"),CJe.forEach(t),zDr=i(de),E0=n(de,"LI",{});var wJe=s(E0);u7e=n(wJe,"STRONG",{});var Bsa=s(u7e);QDr=r(Bsa,"mpnet"),Bsa.forEach(t),WDr=r(wJe," \u2014 "),Ere=n(wJe,"A",{href:!0});var Isa=s(Ere);UDr=r(Isa,"TFMPNetForMaskedLM"),Isa.forEach(t),HDr=r(wJe," (MPNet model)"),wJe.forEach(t),JDr=i(de),C0=n(de,"LI",{});var AJe=s(C0);p7e=n(AJe,"STRONG",{});var Nsa=s(p7e);YDr=r(Nsa,"openai-gpt"),Nsa.forEach(t),ZDr=r(AJe," \u2014 "),Cre=n(AJe,"A",{href:!0});var qsa=s(Cre);KDr=r(qsa,"TFOpenAIGPTLMHeadModel"),qsa.forEach(t),eGr=r(AJe," (OpenAI GPT model)"),AJe.forEach(t),oGr=i(de),w0=n(de,"LI",{});var LJe=s(w0);_7e=n(LJe,"STRONG",{});var jsa=s(_7e);rGr=r(jsa,"roberta"),jsa.forEach(t),tGr=r(LJe," \u2014 "),wre=n(LJe,"A",{href:!0});var Dsa=s(wre);aGr=r(Dsa,"TFRobertaForMaskedLM"),Dsa.forEach(t),nGr=r(LJe," (RoBERTa model)"),LJe.forEach(t),sGr=i(de),A0=n(de,"LI",{});var yJe=s(A0);b7e=n(yJe,"STRONG",{});var Gsa=s(b7e);lGr=r(Gsa,"t5"),Gsa.forEach(t),iGr=r(yJe," \u2014 "),Are=n(yJe,"A",{href:!0});var Osa=s(Are);dGr=r(Osa,"TFT5ForConditionalGeneration"),Osa.forEach(t),cGr=r(yJe," (T5 model)"),yJe.forEach(t),mGr=i(de),L0=n(de,"LI",{});var xJe=s(L0);v7e=n(xJe,"STRONG",{});var Vsa=s(v7e);fGr=r(Vsa,"tapas"),Vsa.forEach(t),gGr=r(xJe," \u2014 "),Lre=n(xJe,"A",{href:!0});var Xsa=s(Lre);hGr=r(Xsa,"TFTapasForMaskedLM"),Xsa.forEach(t),uGr=r(xJe," (TAPAS model)"),xJe.forEach(t),pGr=i(de),y0=n(de,"LI",{});var $Je=s(y0);F7e=n($Je,"STRONG",{});var zsa=s(F7e);_Gr=r(zsa,"transfo-xl"),zsa.forEach(t),bGr=r($Je," \u2014 "),yre=n($Je,"A",{href:!0});var Qsa=s(yre);vGr=r(Qsa,"TFTransfoXLLMHeadModel"),Qsa.forEach(t),FGr=r($Je," (Transformer-XL model)"),$Je.forEach(t),TGr=i(de),x0=n(de,"LI",{});var kJe=s(x0);T7e=n(kJe,"STRONG",{});var Wsa=s(T7e);MGr=r(Wsa,"vit_mae"),Wsa.forEach(t),EGr=r(kJe," \u2014 "),xre=n(kJe,"A",{href:!0});var Usa=s(xre);CGr=r(Usa,"TFViTMAEForPreTraining"),Usa.forEach(t),wGr=r(kJe," (ViTMAE model)"),kJe.forEach(t),AGr=i(de),$0=n(de,"LI",{});var SJe=s($0);M7e=n(SJe,"STRONG",{});var Hsa=s(M7e);LGr=r(Hsa,"xlm"),Hsa.forEach(t),yGr=r(SJe," \u2014 "),$re=n(SJe,"A",{href:!0});var Jsa=s($re);xGr=r(Jsa,"TFXLMWithLMHeadModel"),Jsa.forEach(t),$Gr=r(SJe," (XLM model)"),SJe.forEach(t),kGr=i(de),k0=n(de,"LI",{});var RJe=s(k0);E7e=n(RJe,"STRONG",{});var Ysa=s(E7e);SGr=r(Ysa,"xlm-roberta"),Ysa.forEach(t),RGr=r(RJe," \u2014 "),kre=n(RJe,"A",{href:!0});var Zsa=s(kre);PGr=r(Zsa,"TFXLMRobertaForMaskedLM"),Zsa.forEach(t),BGr=r(RJe," (XLM-RoBERTa model)"),RJe.forEach(t),IGr=i(de),S0=n(de,"LI",{});var PJe=s(S0);C7e=n(PJe,"STRONG",{});var Ksa=s(C7e);NGr=r(Ksa,"xlnet"),Ksa.forEach(t),qGr=r(PJe," \u2014 "),Sre=n(PJe,"A",{href:!0});var ela=s(Sre);jGr=r(ela,"TFXLNetLMHeadModel"),ela.forEach(t),DGr=r(PJe," (XLNet model)"),PJe.forEach(t),de.forEach(t),GGr=i(ci),T(R0.$$.fragment,ci),ci.forEach(t),di.forEach(t),Gro=i(m),am=n(m,"H2",{class:!0});var tno=s(am);P0=n(tno,"A",{id:!0,class:!0,href:!0});var ola=s(P0);w7e=n(ola,"SPAN",{});var rla=s(w7e);T(jS.$$.fragment,rla),rla.forEach(t),ola.forEach(t),OGr=i(tno),A7e=n(tno,"SPAN",{});var tla=s(A7e);VGr=r(tla,"TFAutoModelForCausalLM"),tla.forEach(t),tno.forEach(t),Oro=i(m),cr=n(m,"DIV",{class:!0});var mi=s(cr);T(DS.$$.fragment,mi),XGr=i(mi),nm=n(mi,"P",{});var oce=s(nm);zGr=r(oce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Rre=n(oce,"A",{href:!0});var ala=s(Rre);QGr=r(ala,"from_pretrained()"),ala.forEach(t),WGr=r(oce," class method or the "),Pre=n(oce,"A",{href:!0});var nla=s(Pre);UGr=r(nla,"from_config()"),nla.forEach(t),HGr=r(oce,` class
method.`),oce.forEach(t),JGr=i(mi),GS=n(mi,"P",{});var ano=s(GS);YGr=r(ano,"This class cannot be instantiated directly using "),L7e=n(ano,"CODE",{});var sla=s(L7e);ZGr=r(sla,"__init__()"),sla.forEach(t),KGr=r(ano," (throws an error)."),ano.forEach(t),eOr=i(mi),Ht=n(mi,"DIV",{class:!0});var y9=s(Ht);T(OS.$$.fragment,y9),oOr=i(y9),y7e=n(y9,"P",{});var lla=s(y7e);rOr=r(lla,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lla.forEach(t),tOr=i(y9),sm=n(y9,"P",{});var rce=s(sm);aOr=r(rce,`Note:
Loading a model from its configuration file does `),x7e=n(rce,"STRONG",{});var ila=s(x7e);nOr=r(ila,"not"),ila.forEach(t),sOr=r(rce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bre=n(rce,"A",{href:!0});var dla=s(Bre);lOr=r(dla,"from_pretrained()"),dla.forEach(t),iOr=r(rce," to load the model weights."),rce.forEach(t),dOr=i(y9),T(B0.$$.fragment,y9),y9.forEach(t),cOr=i(mi),Dr=n(mi,"DIV",{class:!0});var fi=s(Dr);T(VS.$$.fragment,fi),mOr=i(fi),$7e=n(fi,"P",{});var cla=s($7e);fOr=r(cla,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cla.forEach(t),gOr=i(fi),Sn=n(fi,"P",{});var x9=s(Sn);hOr=r(x9,"The model class to instantiate is selected based on the "),k7e=n(x9,"CODE",{});var mla=s(k7e);uOr=r(mla,"model_type"),mla.forEach(t),pOr=r(x9,` property of the config object (either
passed as an argument or loaded from `),S7e=n(x9,"CODE",{});var fla=s(S7e);_Or=r(fla,"pretrained_model_name_or_path"),fla.forEach(t),bOr=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R7e=n(x9,"CODE",{});var gla=s(R7e);vOr=r(gla,"pretrained_model_name_or_path"),gla.forEach(t),FOr=r(x9,":"),x9.forEach(t),TOr=i(fi),Me=n(fi,"UL",{});var Ce=s(Me);I0=n(Ce,"LI",{});var BJe=s(I0);P7e=n(BJe,"STRONG",{});var hla=s(P7e);MOr=r(hla,"bert"),hla.forEach(t),EOr=r(BJe," \u2014 "),Ire=n(BJe,"A",{href:!0});var ula=s(Ire);COr=r(ula,"TFBertLMHeadModel"),ula.forEach(t),wOr=r(BJe," (BERT model)"),BJe.forEach(t),AOr=i(Ce),N0=n(Ce,"LI",{});var IJe=s(N0);B7e=n(IJe,"STRONG",{});var pla=s(B7e);LOr=r(pla,"camembert"),pla.forEach(t),yOr=r(IJe," \u2014 "),Nre=n(IJe,"A",{href:!0});var _la=s(Nre);xOr=r(_la,"TFCamembertForCausalLM"),_la.forEach(t),$Or=r(IJe," (CamemBERT model)"),IJe.forEach(t),kOr=i(Ce),q0=n(Ce,"LI",{});var NJe=s(q0);I7e=n(NJe,"STRONG",{});var bla=s(I7e);SOr=r(bla,"ctrl"),bla.forEach(t),ROr=r(NJe," \u2014 "),qre=n(NJe,"A",{href:!0});var vla=s(qre);POr=r(vla,"TFCTRLLMHeadModel"),vla.forEach(t),BOr=r(NJe," (CTRL model)"),NJe.forEach(t),IOr=i(Ce),j0=n(Ce,"LI",{});var qJe=s(j0);N7e=n(qJe,"STRONG",{});var Fla=s(N7e);NOr=r(Fla,"gpt2"),Fla.forEach(t),qOr=r(qJe," \u2014 "),jre=n(qJe,"A",{href:!0});var Tla=s(jre);jOr=r(Tla,"TFGPT2LMHeadModel"),Tla.forEach(t),DOr=r(qJe," (OpenAI GPT-2 model)"),qJe.forEach(t),GOr=i(Ce),D0=n(Ce,"LI",{});var jJe=s(D0);q7e=n(jJe,"STRONG",{});var Mla=s(q7e);OOr=r(Mla,"gptj"),Mla.forEach(t),VOr=r(jJe," \u2014 "),Dre=n(jJe,"A",{href:!0});var Ela=s(Dre);XOr=r(Ela,"TFGPTJForCausalLM"),Ela.forEach(t),zOr=r(jJe," (GPT-J model)"),jJe.forEach(t),QOr=i(Ce),G0=n(Ce,"LI",{});var DJe=s(G0);j7e=n(DJe,"STRONG",{});var Cla=s(j7e);WOr=r(Cla,"openai-gpt"),Cla.forEach(t),UOr=r(DJe," \u2014 "),Gre=n(DJe,"A",{href:!0});var wla=s(Gre);HOr=r(wla,"TFOpenAIGPTLMHeadModel"),wla.forEach(t),JOr=r(DJe," (OpenAI GPT model)"),DJe.forEach(t),YOr=i(Ce),O0=n(Ce,"LI",{});var GJe=s(O0);D7e=n(GJe,"STRONG",{});var Ala=s(D7e);ZOr=r(Ala,"opt"),Ala.forEach(t),KOr=r(GJe," \u2014 "),Ore=n(GJe,"A",{href:!0});var Lla=s(Ore);eVr=r(Lla,"TFOPTForCausalLM"),Lla.forEach(t),oVr=r(GJe," (OPT model)"),GJe.forEach(t),rVr=i(Ce),V0=n(Ce,"LI",{});var OJe=s(V0);G7e=n(OJe,"STRONG",{});var yla=s(G7e);tVr=r(yla,"rembert"),yla.forEach(t),aVr=r(OJe," \u2014 "),Vre=n(OJe,"A",{href:!0});var xla=s(Vre);nVr=r(xla,"TFRemBertForCausalLM"),xla.forEach(t),sVr=r(OJe," (RemBERT model)"),OJe.forEach(t),lVr=i(Ce),X0=n(Ce,"LI",{});var VJe=s(X0);O7e=n(VJe,"STRONG",{});var $la=s(O7e);iVr=r($la,"roberta"),$la.forEach(t),dVr=r(VJe," \u2014 "),Xre=n(VJe,"A",{href:!0});var kla=s(Xre);cVr=r(kla,"TFRobertaForCausalLM"),kla.forEach(t),mVr=r(VJe," (RoBERTa model)"),VJe.forEach(t),fVr=i(Ce),z0=n(Ce,"LI",{});var XJe=s(z0);V7e=n(XJe,"STRONG",{});var Sla=s(V7e);gVr=r(Sla,"roformer"),Sla.forEach(t),hVr=r(XJe," \u2014 "),zre=n(XJe,"A",{href:!0});var Rla=s(zre);uVr=r(Rla,"TFRoFormerForCausalLM"),Rla.forEach(t),pVr=r(XJe," (RoFormer model)"),XJe.forEach(t),_Vr=i(Ce),Q0=n(Ce,"LI",{});var zJe=s(Q0);X7e=n(zJe,"STRONG",{});var Pla=s(X7e);bVr=r(Pla,"transfo-xl"),Pla.forEach(t),vVr=r(zJe," \u2014 "),Qre=n(zJe,"A",{href:!0});var Bla=s(Qre);FVr=r(Bla,"TFTransfoXLLMHeadModel"),Bla.forEach(t),TVr=r(zJe," (Transformer-XL model)"),zJe.forEach(t),MVr=i(Ce),W0=n(Ce,"LI",{});var QJe=s(W0);z7e=n(QJe,"STRONG",{});var Ila=s(z7e);EVr=r(Ila,"xglm"),Ila.forEach(t),CVr=r(QJe," \u2014 "),Wre=n(QJe,"A",{href:!0});var Nla=s(Wre);wVr=r(Nla,"TFXGLMForCausalLM"),Nla.forEach(t),AVr=r(QJe," (XGLM model)"),QJe.forEach(t),LVr=i(Ce),U0=n(Ce,"LI",{});var WJe=s(U0);Q7e=n(WJe,"STRONG",{});var qla=s(Q7e);yVr=r(qla,"xlm"),qla.forEach(t),xVr=r(WJe," \u2014 "),Ure=n(WJe,"A",{href:!0});var jla=s(Ure);$Vr=r(jla,"TFXLMWithLMHeadModel"),jla.forEach(t),kVr=r(WJe," (XLM model)"),WJe.forEach(t),SVr=i(Ce),H0=n(Ce,"LI",{});var UJe=s(H0);W7e=n(UJe,"STRONG",{});var Dla=s(W7e);RVr=r(Dla,"xlnet"),Dla.forEach(t),PVr=r(UJe," \u2014 "),Hre=n(UJe,"A",{href:!0});var Gla=s(Hre);BVr=r(Gla,"TFXLNetLMHeadModel"),Gla.forEach(t),IVr=r(UJe," (XLNet model)"),UJe.forEach(t),Ce.forEach(t),NVr=i(fi),T(J0.$$.fragment,fi),fi.forEach(t),mi.forEach(t),Vro=i(m),lm=n(m,"H2",{class:!0});var nno=s(lm);Y0=n(nno,"A",{id:!0,class:!0,href:!0});var Ola=s(Y0);U7e=n(Ola,"SPAN",{});var Vla=s(U7e);T(XS.$$.fragment,Vla),Vla.forEach(t),Ola.forEach(t),qVr=i(nno),H7e=n(nno,"SPAN",{});var Xla=s(H7e);jVr=r(Xla,"TFAutoModelForImageClassification"),Xla.forEach(t),nno.forEach(t),Xro=i(m),mr=n(m,"DIV",{class:!0});var gi=s(mr);T(zS.$$.fragment,gi),DVr=i(gi),im=n(gi,"P",{});var tce=s(im);GVr=r(tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jre=n(tce,"A",{href:!0});var zla=s(Jre);OVr=r(zla,"from_pretrained()"),zla.forEach(t),VVr=r(tce," class method or the "),Yre=n(tce,"A",{href:!0});var Qla=s(Yre);XVr=r(Qla,"from_config()"),Qla.forEach(t),zVr=r(tce,` class
method.`),tce.forEach(t),QVr=i(gi),QS=n(gi,"P",{});var sno=s(QS);WVr=r(sno,"This class cannot be instantiated directly using "),J7e=n(sno,"CODE",{});var Wla=s(J7e);UVr=r(Wla,"__init__()"),Wla.forEach(t),HVr=r(sno," (throws an error)."),sno.forEach(t),JVr=i(gi),Jt=n(gi,"DIV",{class:!0});var $9=s(Jt);T(WS.$$.fragment,$9),YVr=i($9),Y7e=n($9,"P",{});var Ula=s(Y7e);ZVr=r(Ula,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Ula.forEach(t),KVr=i($9),dm=n($9,"P",{});var ace=s(dm);eXr=r(ace,`Note:
Loading a model from its configuration file does `),Z7e=n(ace,"STRONG",{});var Hla=s(Z7e);oXr=r(Hla,"not"),Hla.forEach(t),rXr=r(ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=n(ace,"A",{href:!0});var Jla=s(Zre);tXr=r(Jla,"from_pretrained()"),Jla.forEach(t),aXr=r(ace," to load the model weights."),ace.forEach(t),nXr=i($9),T(Z0.$$.fragment,$9),$9.forEach(t),sXr=i(gi),Gr=n(gi,"DIV",{class:!0});var hi=s(Gr);T(US.$$.fragment,hi),lXr=i(hi),K7e=n(hi,"P",{});var Yla=s(K7e);iXr=r(Yla,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Yla.forEach(t),dXr=i(hi),Rn=n(hi,"P",{});var k9=s(Rn);cXr=r(k9,"The model class to instantiate is selected based on the "),eLe=n(k9,"CODE",{});var Zla=s(eLe);mXr=r(Zla,"model_type"),Zla.forEach(t),fXr=r(k9,` property of the config object (either
passed as an argument or loaded from `),oLe=n(k9,"CODE",{});var Kla=s(oLe);gXr=r(Kla,"pretrained_model_name_or_path"),Kla.forEach(t),hXr=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rLe=n(k9,"CODE",{});var eia=s(rLe);uXr=r(eia,"pretrained_model_name_or_path"),eia.forEach(t),pXr=r(k9,":"),k9.forEach(t),_Xr=i(hi),ye=n(hi,"UL",{});var Ne=s(ye);K0=n(Ne,"LI",{});var HJe=s(K0);tLe=n(HJe,"STRONG",{});var oia=s(tLe);bXr=r(oia,"convnext"),oia.forEach(t),vXr=r(HJe," \u2014 "),Kre=n(HJe,"A",{href:!0});var ria=s(Kre);FXr=r(ria,"TFConvNextForImageClassification"),ria.forEach(t),TXr=r(HJe," (ConvNeXT model)"),HJe.forEach(t),MXr=i(Ne),ew=n(Ne,"LI",{});var JJe=s(ew);aLe=n(JJe,"STRONG",{});var tia=s(aLe);EXr=r(tia,"cvt"),tia.forEach(t),CXr=r(JJe," \u2014 "),ete=n(JJe,"A",{href:!0});var aia=s(ete);wXr=r(aia,"TFCvtForImageClassification"),aia.forEach(t),AXr=r(JJe," (CvT model)"),JJe.forEach(t),LXr=i(Ne),ow=n(Ne,"LI",{});var YJe=s(ow);nLe=n(YJe,"STRONG",{});var nia=s(nLe);yXr=r(nia,"data2vec-vision"),nia.forEach(t),xXr=r(YJe," \u2014 "),ote=n(YJe,"A",{href:!0});var sia=s(ote);$Xr=r(sia,"TFData2VecVisionForImageClassification"),sia.forEach(t),kXr=r(YJe," (Data2VecVision model)"),YJe.forEach(t),SXr=i(Ne),Al=n(Ne,"LI",{});var PI=s(Al);sLe=n(PI,"STRONG",{});var lia=s(sLe);RXr=r(lia,"deit"),lia.forEach(t),PXr=r(PI," \u2014 "),rte=n(PI,"A",{href:!0});var iia=s(rte);BXr=r(iia,"TFDeiTForImageClassification"),iia.forEach(t),IXr=r(PI," or "),tte=n(PI,"A",{href:!0});var dia=s(tte);NXr=r(dia,"TFDeiTForImageClassificationWithTeacher"),dia.forEach(t),qXr=r(PI," (DeiT model)"),PI.forEach(t),jXr=i(Ne),rw=n(Ne,"LI",{});var ZJe=s(rw);lLe=n(ZJe,"STRONG",{});var cia=s(lLe);DXr=r(cia,"mobilevit"),cia.forEach(t),GXr=r(ZJe," \u2014 "),ate=n(ZJe,"A",{href:!0});var mia=s(ate);OXr=r(mia,"TFMobileViTForImageClassification"),mia.forEach(t),VXr=r(ZJe," (MobileViT model)"),ZJe.forEach(t),XXr=i(Ne),tw=n(Ne,"LI",{});var KJe=s(tw);iLe=n(KJe,"STRONG",{});var fia=s(iLe);zXr=r(fia,"regnet"),fia.forEach(t),QXr=r(KJe," \u2014 "),nte=n(KJe,"A",{href:!0});var gia=s(nte);WXr=r(gia,"TFRegNetForImageClassification"),gia.forEach(t),UXr=r(KJe," (RegNet model)"),KJe.forEach(t),HXr=i(Ne),aw=n(Ne,"LI",{});var eYe=s(aw);dLe=n(eYe,"STRONG",{});var hia=s(dLe);JXr=r(hia,"resnet"),hia.forEach(t),YXr=r(eYe," \u2014 "),ste=n(eYe,"A",{href:!0});var uia=s(ste);ZXr=r(uia,"TFResNetForImageClassification"),uia.forEach(t),KXr=r(eYe," (ResNet model)"),eYe.forEach(t),ezr=i(Ne),nw=n(Ne,"LI",{});var oYe=s(nw);cLe=n(oYe,"STRONG",{});var pia=s(cLe);ozr=r(pia,"segformer"),pia.forEach(t),rzr=r(oYe," \u2014 "),lte=n(oYe,"A",{href:!0});var _ia=s(lte);tzr=r(_ia,"TFSegformerForImageClassification"),_ia.forEach(t),azr=r(oYe," (SegFormer model)"),oYe.forEach(t),nzr=i(Ne),sw=n(Ne,"LI",{});var rYe=s(sw);mLe=n(rYe,"STRONG",{});var bia=s(mLe);szr=r(bia,"swin"),bia.forEach(t),lzr=r(rYe," \u2014 "),ite=n(rYe,"A",{href:!0});var via=s(ite);izr=r(via,"TFSwinForImageClassification"),via.forEach(t),dzr=r(rYe," (Swin Transformer model)"),rYe.forEach(t),czr=i(Ne),lw=n(Ne,"LI",{});var tYe=s(lw);fLe=n(tYe,"STRONG",{});var Fia=s(fLe);mzr=r(Fia,"vit"),Fia.forEach(t),fzr=r(tYe," \u2014 "),dte=n(tYe,"A",{href:!0});var Tia=s(dte);gzr=r(Tia,"TFViTForImageClassification"),Tia.forEach(t),hzr=r(tYe," (ViT model)"),tYe.forEach(t),Ne.forEach(t),uzr=i(hi),T(iw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),zro=i(m),cm=n(m,"H2",{class:!0});var lno=s(cm);dw=n(lno,"A",{id:!0,class:!0,href:!0});var Mia=s(dw);gLe=n(Mia,"SPAN",{});var Eia=s(gLe);T(HS.$$.fragment,Eia),Eia.forEach(t),Mia.forEach(t),pzr=i(lno),hLe=n(lno,"SPAN",{});var Cia=s(hLe);_zr=r(Cia,"TFAutoModelForSemanticSegmentation"),Cia.forEach(t),lno.forEach(t),Qro=i(m),fr=n(m,"DIV",{class:!0});var ui=s(fr);T(JS.$$.fragment,ui),bzr=i(ui),mm=n(ui,"P",{});var nce=s(mm);vzr=r(nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),cte=n(nce,"A",{href:!0});var wia=s(cte);Fzr=r(wia,"from_pretrained()"),wia.forEach(t),Tzr=r(nce," class method or the "),mte=n(nce,"A",{href:!0});var Aia=s(mte);Mzr=r(Aia,"from_config()"),Aia.forEach(t),Ezr=r(nce,` class
method.`),nce.forEach(t),Czr=i(ui),YS=n(ui,"P",{});var ino=s(YS);wzr=r(ino,"This class cannot be instantiated directly using "),uLe=n(ino,"CODE",{});var Lia=s(uLe);Azr=r(Lia,"__init__()"),Lia.forEach(t),Lzr=r(ino," (throws an error)."),ino.forEach(t),yzr=i(ui),Yt=n(ui,"DIV",{class:!0});var S9=s(Yt);T(ZS.$$.fragment,S9),xzr=i(S9),pLe=n(S9,"P",{});var yia=s(pLe);$zr=r(yia,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),yia.forEach(t),kzr=i(S9),fm=n(S9,"P",{});var sce=s(fm);Szr=r(sce,`Note:
Loading a model from its configuration file does `),_Le=n(sce,"STRONG",{});var xia=s(_Le);Rzr=r(xia,"not"),xia.forEach(t),Pzr=r(sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),fte=n(sce,"A",{href:!0});var $ia=s(fte);Bzr=r($ia,"from_pretrained()"),$ia.forEach(t),Izr=r(sce," to load the model weights."),sce.forEach(t),Nzr=i(S9),T(cw.$$.fragment,S9),S9.forEach(t),qzr=i(ui),Or=n(ui,"DIV",{class:!0});var pi=s(Or);T(KS.$$.fragment,pi),jzr=i(pi),bLe=n(pi,"P",{});var kia=s(bLe);Dzr=r(kia,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),kia.forEach(t),Gzr=i(pi),Pn=n(pi,"P",{});var R9=s(Pn);Ozr=r(R9,"The model class to instantiate is selected based on the "),vLe=n(R9,"CODE",{});var Sia=s(vLe);Vzr=r(Sia,"model_type"),Sia.forEach(t),Xzr=r(R9,` property of the config object (either
passed as an argument or loaded from `),FLe=n(R9,"CODE",{});var Ria=s(FLe);zzr=r(Ria,"pretrained_model_name_or_path"),Ria.forEach(t),Qzr=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TLe=n(R9,"CODE",{});var Pia=s(TLe);Wzr=r(Pia,"pretrained_model_name_or_path"),Pia.forEach(t),Uzr=r(R9,":"),R9.forEach(t),Hzr=i(pi),gm=n(pi,"UL",{});var lce=s(gm);mw=n(lce,"LI",{});var aYe=s(mw);MLe=n(aYe,"STRONG",{});var Bia=s(MLe);Jzr=r(Bia,"data2vec-vision"),Bia.forEach(t),Yzr=r(aYe," \u2014 "),gte=n(aYe,"A",{href:!0});var Iia=s(gte);Zzr=r(Iia,"TFData2VecVisionForSemanticSegmentation"),Iia.forEach(t),Kzr=r(aYe," (Data2VecVision model)"),aYe.forEach(t),eQr=i(lce),fw=n(lce,"LI",{});var nYe=s(fw);ELe=n(nYe,"STRONG",{});var Nia=s(ELe);oQr=r(Nia,"mobilevit"),Nia.forEach(t),rQr=r(nYe," \u2014 "),hte=n(nYe,"A",{href:!0});var qia=s(hte);tQr=r(qia,"TFMobileViTForSemanticSegmentation"),qia.forEach(t),aQr=r(nYe," (MobileViT model)"),nYe.forEach(t),nQr=i(lce),gw=n(lce,"LI",{});var sYe=s(gw);CLe=n(sYe,"STRONG",{});var jia=s(CLe);sQr=r(jia,"segformer"),jia.forEach(t),lQr=r(sYe," \u2014 "),ute=n(sYe,"A",{href:!0});var Dia=s(ute);iQr=r(Dia,"TFSegformerForSemanticSegmentation"),Dia.forEach(t),dQr=r(sYe," (SegFormer model)"),sYe.forEach(t),lce.forEach(t),cQr=i(pi),T(hw.$$.fragment,pi),pi.forEach(t),ui.forEach(t),Wro=i(m),hm=n(m,"H2",{class:!0});var dno=s(hm);uw=n(dno,"A",{id:!0,class:!0,href:!0});var Gia=s(uw);wLe=n(Gia,"SPAN",{});var Oia=s(wLe);T(eR.$$.fragment,Oia),Oia.forEach(t),Gia.forEach(t),mQr=i(dno),ALe=n(dno,"SPAN",{});var Via=s(ALe);fQr=r(Via,"TFAutoModelForMaskedLM"),Via.forEach(t),dno.forEach(t),Uro=i(m),gr=n(m,"DIV",{class:!0});var _i=s(gr);T(oR.$$.fragment,_i),gQr=i(_i),um=n(_i,"P",{});var ice=s(um);hQr=r(ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pte=n(ice,"A",{href:!0});var Xia=s(pte);uQr=r(Xia,"from_pretrained()"),Xia.forEach(t),pQr=r(ice," class method or the "),_te=n(ice,"A",{href:!0});var zia=s(_te);_Qr=r(zia,"from_config()"),zia.forEach(t),bQr=r(ice,` class
method.`),ice.forEach(t),vQr=i(_i),rR=n(_i,"P",{});var cno=s(rR);FQr=r(cno,"This class cannot be instantiated directly using "),LLe=n(cno,"CODE",{});var Qia=s(LLe);TQr=r(Qia,"__init__()"),Qia.forEach(t),MQr=r(cno," (throws an error)."),cno.forEach(t),EQr=i(_i),Zt=n(_i,"DIV",{class:!0});var P9=s(Zt);T(tR.$$.fragment,P9),CQr=i(P9),yLe=n(P9,"P",{});var Wia=s(yLe);wQr=r(Wia,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Wia.forEach(t),AQr=i(P9),pm=n(P9,"P",{});var dce=s(pm);LQr=r(dce,`Note:
Loading a model from its configuration file does `),xLe=n(dce,"STRONG",{});var Uia=s(xLe);yQr=r(Uia,"not"),Uia.forEach(t),xQr=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=n(dce,"A",{href:!0});var Hia=s(bte);$Qr=r(Hia,"from_pretrained()"),Hia.forEach(t),kQr=r(dce," to load the model weights."),dce.forEach(t),SQr=i(P9),T(pw.$$.fragment,P9),P9.forEach(t),RQr=i(_i),Vr=n(_i,"DIV",{class:!0});var bi=s(Vr);T(aR.$$.fragment,bi),PQr=i(bi),$Le=n(bi,"P",{});var Jia=s($Le);BQr=r(Jia,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Jia.forEach(t),IQr=i(bi),Bn=n(bi,"P",{});var B9=s(Bn);NQr=r(B9,"The model class to instantiate is selected based on the "),kLe=n(B9,"CODE",{});var Yia=s(kLe);qQr=r(Yia,"model_type"),Yia.forEach(t),jQr=r(B9,` property of the config object (either
passed as an argument or loaded from `),SLe=n(B9,"CODE",{});var Zia=s(SLe);DQr=r(Zia,"pretrained_model_name_or_path"),Zia.forEach(t),GQr=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RLe=n(B9,"CODE",{});var Kia=s(RLe);OQr=r(Kia,"pretrained_model_name_or_path"),Kia.forEach(t),VQr=r(B9,":"),B9.forEach(t),XQr=i(bi),ge=n(bi,"UL",{});var _e=s(ge);_w=n(_e,"LI",{});var lYe=s(_w);PLe=n(lYe,"STRONG",{});var eda=s(PLe);zQr=r(eda,"albert"),eda.forEach(t),QQr=r(lYe," \u2014 "),vte=n(lYe,"A",{href:!0});var oda=s(vte);WQr=r(oda,"TFAlbertForMaskedLM"),oda.forEach(t),UQr=r(lYe," (ALBERT model)"),lYe.forEach(t),HQr=i(_e),bw=n(_e,"LI",{});var iYe=s(bw);BLe=n(iYe,"STRONG",{});var rda=s(BLe);JQr=r(rda,"bert"),rda.forEach(t),YQr=r(iYe," \u2014 "),Fte=n(iYe,"A",{href:!0});var tda=s(Fte);ZQr=r(tda,"TFBertForMaskedLM"),tda.forEach(t),KQr=r(iYe," (BERT model)"),iYe.forEach(t),eWr=i(_e),vw=n(_e,"LI",{});var dYe=s(vw);ILe=n(dYe,"STRONG",{});var ada=s(ILe);oWr=r(ada,"camembert"),ada.forEach(t),rWr=r(dYe," \u2014 "),Tte=n(dYe,"A",{href:!0});var nda=s(Tte);tWr=r(nda,"TFCamembertForMaskedLM"),nda.forEach(t),aWr=r(dYe," (CamemBERT model)"),dYe.forEach(t),nWr=i(_e),Fw=n(_e,"LI",{});var cYe=s(Fw);NLe=n(cYe,"STRONG",{});var sda=s(NLe);sWr=r(sda,"convbert"),sda.forEach(t),lWr=r(cYe," \u2014 "),Mte=n(cYe,"A",{href:!0});var lda=s(Mte);iWr=r(lda,"TFConvBertForMaskedLM"),lda.forEach(t),dWr=r(cYe," (ConvBERT model)"),cYe.forEach(t),cWr=i(_e),Tw=n(_e,"LI",{});var mYe=s(Tw);qLe=n(mYe,"STRONG",{});var ida=s(qLe);mWr=r(ida,"deberta"),ida.forEach(t),fWr=r(mYe," \u2014 "),Ete=n(mYe,"A",{href:!0});var dda=s(Ete);gWr=r(dda,"TFDebertaForMaskedLM"),dda.forEach(t),hWr=r(mYe," (DeBERTa model)"),mYe.forEach(t),uWr=i(_e),Mw=n(_e,"LI",{});var fYe=s(Mw);jLe=n(fYe,"STRONG",{});var cda=s(jLe);pWr=r(cda,"deberta-v2"),cda.forEach(t),_Wr=r(fYe," \u2014 "),Cte=n(fYe,"A",{href:!0});var mda=s(Cte);bWr=r(mda,"TFDebertaV2ForMaskedLM"),mda.forEach(t),vWr=r(fYe," (DeBERTa-v2 model)"),fYe.forEach(t),FWr=i(_e),Ew=n(_e,"LI",{});var gYe=s(Ew);DLe=n(gYe,"STRONG",{});var fda=s(DLe);TWr=r(fda,"distilbert"),fda.forEach(t),MWr=r(gYe," \u2014 "),wte=n(gYe,"A",{href:!0});var gda=s(wte);EWr=r(gda,"TFDistilBertForMaskedLM"),gda.forEach(t),CWr=r(gYe," (DistilBERT model)"),gYe.forEach(t),wWr=i(_e),Cw=n(_e,"LI",{});var hYe=s(Cw);GLe=n(hYe,"STRONG",{});var hda=s(GLe);AWr=r(hda,"electra"),hda.forEach(t),LWr=r(hYe," \u2014 "),Ate=n(hYe,"A",{href:!0});var uda=s(Ate);yWr=r(uda,"TFElectraForMaskedLM"),uda.forEach(t),xWr=r(hYe," (ELECTRA model)"),hYe.forEach(t),$Wr=i(_e),ww=n(_e,"LI",{});var uYe=s(ww);OLe=n(uYe,"STRONG",{});var pda=s(OLe);kWr=r(pda,"flaubert"),pda.forEach(t),SWr=r(uYe," \u2014 "),Lte=n(uYe,"A",{href:!0});var _da=s(Lte);RWr=r(_da,"TFFlaubertWithLMHeadModel"),_da.forEach(t),PWr=r(uYe," (FlauBERT model)"),uYe.forEach(t),BWr=i(_e),Aw=n(_e,"LI",{});var pYe=s(Aw);VLe=n(pYe,"STRONG",{});var bda=s(VLe);IWr=r(bda,"funnel"),bda.forEach(t),NWr=r(pYe," \u2014 "),yte=n(pYe,"A",{href:!0});var vda=s(yte);qWr=r(vda,"TFFunnelForMaskedLM"),vda.forEach(t),jWr=r(pYe," (Funnel Transformer model)"),pYe.forEach(t),DWr=i(_e),Lw=n(_e,"LI",{});var _Ye=s(Lw);XLe=n(_Ye,"STRONG",{});var Fda=s(XLe);GWr=r(Fda,"layoutlm"),Fda.forEach(t),OWr=r(_Ye," \u2014 "),xte=n(_Ye,"A",{href:!0});var Tda=s(xte);VWr=r(Tda,"TFLayoutLMForMaskedLM"),Tda.forEach(t),XWr=r(_Ye," (LayoutLM model)"),_Ye.forEach(t),zWr=i(_e),yw=n(_e,"LI",{});var bYe=s(yw);zLe=n(bYe,"STRONG",{});var Mda=s(zLe);QWr=r(Mda,"longformer"),Mda.forEach(t),WWr=r(bYe," \u2014 "),$te=n(bYe,"A",{href:!0});var Eda=s($te);UWr=r(Eda,"TFLongformerForMaskedLM"),Eda.forEach(t),HWr=r(bYe," (Longformer model)"),bYe.forEach(t),JWr=i(_e),xw=n(_e,"LI",{});var vYe=s(xw);QLe=n(vYe,"STRONG",{});var Cda=s(QLe);YWr=r(Cda,"mobilebert"),Cda.forEach(t),ZWr=r(vYe," \u2014 "),kte=n(vYe,"A",{href:!0});var wda=s(kte);KWr=r(wda,"TFMobileBertForMaskedLM"),wda.forEach(t),eUr=r(vYe," (MobileBERT model)"),vYe.forEach(t),oUr=i(_e),$w=n(_e,"LI",{});var FYe=s($w);WLe=n(FYe,"STRONG",{});var Ada=s(WLe);rUr=r(Ada,"mpnet"),Ada.forEach(t),tUr=r(FYe," \u2014 "),Ste=n(FYe,"A",{href:!0});var Lda=s(Ste);aUr=r(Lda,"TFMPNetForMaskedLM"),Lda.forEach(t),nUr=r(FYe," (MPNet model)"),FYe.forEach(t),sUr=i(_e),kw=n(_e,"LI",{});var TYe=s(kw);ULe=n(TYe,"STRONG",{});var yda=s(ULe);lUr=r(yda,"rembert"),yda.forEach(t),iUr=r(TYe," \u2014 "),Rte=n(TYe,"A",{href:!0});var xda=s(Rte);dUr=r(xda,"TFRemBertForMaskedLM"),xda.forEach(t),cUr=r(TYe," (RemBERT model)"),TYe.forEach(t),mUr=i(_e),Sw=n(_e,"LI",{});var MYe=s(Sw);HLe=n(MYe,"STRONG",{});var $da=s(HLe);fUr=r($da,"roberta"),$da.forEach(t),gUr=r(MYe," \u2014 "),Pte=n(MYe,"A",{href:!0});var kda=s(Pte);hUr=r(kda,"TFRobertaForMaskedLM"),kda.forEach(t),uUr=r(MYe," (RoBERTa model)"),MYe.forEach(t),pUr=i(_e),Rw=n(_e,"LI",{});var EYe=s(Rw);JLe=n(EYe,"STRONG",{});var Sda=s(JLe);_Ur=r(Sda,"roformer"),Sda.forEach(t),bUr=r(EYe," \u2014 "),Bte=n(EYe,"A",{href:!0});var Rda=s(Bte);vUr=r(Rda,"TFRoFormerForMaskedLM"),Rda.forEach(t),FUr=r(EYe," (RoFormer model)"),EYe.forEach(t),TUr=i(_e),Pw=n(_e,"LI",{});var CYe=s(Pw);YLe=n(CYe,"STRONG",{});var Pda=s(YLe);MUr=r(Pda,"tapas"),Pda.forEach(t),EUr=r(CYe," \u2014 "),Ite=n(CYe,"A",{href:!0});var Bda=s(Ite);CUr=r(Bda,"TFTapasForMaskedLM"),Bda.forEach(t),wUr=r(CYe," (TAPAS model)"),CYe.forEach(t),AUr=i(_e),Bw=n(_e,"LI",{});var wYe=s(Bw);ZLe=n(wYe,"STRONG",{});var Ida=s(ZLe);LUr=r(Ida,"xlm"),Ida.forEach(t),yUr=r(wYe," \u2014 "),Nte=n(wYe,"A",{href:!0});var Nda=s(Nte);xUr=r(Nda,"TFXLMWithLMHeadModel"),Nda.forEach(t),$Ur=r(wYe," (XLM model)"),wYe.forEach(t),kUr=i(_e),Iw=n(_e,"LI",{});var AYe=s(Iw);KLe=n(AYe,"STRONG",{});var qda=s(KLe);SUr=r(qda,"xlm-roberta"),qda.forEach(t),RUr=r(AYe," \u2014 "),qte=n(AYe,"A",{href:!0});var jda=s(qte);PUr=r(jda,"TFXLMRobertaForMaskedLM"),jda.forEach(t),BUr=r(AYe," (XLM-RoBERTa model)"),AYe.forEach(t),_e.forEach(t),IUr=i(bi),T(Nw.$$.fragment,bi),bi.forEach(t),_i.forEach(t),Hro=i(m),_m=n(m,"H2",{class:!0});var mno=s(_m);qw=n(mno,"A",{id:!0,class:!0,href:!0});var Dda=s(qw);e8e=n(Dda,"SPAN",{});var Gda=s(e8e);T(nR.$$.fragment,Gda),Gda.forEach(t),Dda.forEach(t),NUr=i(mno),o8e=n(mno,"SPAN",{});var Oda=s(o8e);qUr=r(Oda,"TFAutoModelForSeq2SeqLM"),Oda.forEach(t),mno.forEach(t),Jro=i(m),hr=n(m,"DIV",{class:!0});var vi=s(hr);T(sR.$$.fragment,vi),jUr=i(vi),bm=n(vi,"P",{});var cce=s(bm);DUr=r(cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),jte=n(cce,"A",{href:!0});var Vda=s(jte);GUr=r(Vda,"from_pretrained()"),Vda.forEach(t),OUr=r(cce," class method or the "),Dte=n(cce,"A",{href:!0});var Xda=s(Dte);VUr=r(Xda,"from_config()"),Xda.forEach(t),XUr=r(cce,` class
method.`),cce.forEach(t),zUr=i(vi),lR=n(vi,"P",{});var fno=s(lR);QUr=r(fno,"This class cannot be instantiated directly using "),r8e=n(fno,"CODE",{});var zda=s(r8e);WUr=r(zda,"__init__()"),zda.forEach(t),UUr=r(fno," (throws an error)."),fno.forEach(t),HUr=i(vi),Kt=n(vi,"DIV",{class:!0});var I9=s(Kt);T(iR.$$.fragment,I9),JUr=i(I9),t8e=n(I9,"P",{});var Qda=s(t8e);YUr=r(Qda,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qda.forEach(t),ZUr=i(I9),vm=n(I9,"P",{});var mce=s(vm);KUr=r(mce,`Note:
Loading a model from its configuration file does `),a8e=n(mce,"STRONG",{});var Wda=s(a8e);eHr=r(Wda,"not"),Wda.forEach(t),oHr=r(mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(mce,"A",{href:!0});var Uda=s(Gte);rHr=r(Uda,"from_pretrained()"),Uda.forEach(t),tHr=r(mce," to load the model weights."),mce.forEach(t),aHr=i(I9),T(jw.$$.fragment,I9),I9.forEach(t),nHr=i(vi),Xr=n(vi,"DIV",{class:!0});var Fi=s(Xr);T(dR.$$.fragment,Fi),sHr=i(Fi),n8e=n(Fi,"P",{});var Hda=s(n8e);lHr=r(Hda,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Hda.forEach(t),iHr=i(Fi),In=n(Fi,"P",{});var N9=s(In);dHr=r(N9,"The model class to instantiate is selected based on the "),s8e=n(N9,"CODE",{});var Jda=s(s8e);cHr=r(Jda,"model_type"),Jda.forEach(t),mHr=r(N9,` property of the config object (either
passed as an argument or loaded from `),l8e=n(N9,"CODE",{});var Yda=s(l8e);fHr=r(Yda,"pretrained_model_name_or_path"),Yda.forEach(t),gHr=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i8e=n(N9,"CODE",{});var Zda=s(i8e);hHr=r(Zda,"pretrained_model_name_or_path"),Zda.forEach(t),uHr=r(N9,":"),N9.forEach(t),pHr=i(Fi),xe=n(Fi,"UL",{});var qe=s(xe);Dw=n(qe,"LI",{});var LYe=s(Dw);d8e=n(LYe,"STRONG",{});var Kda=s(d8e);_Hr=r(Kda,"bart"),Kda.forEach(t),bHr=r(LYe," \u2014 "),Ote=n(LYe,"A",{href:!0});var eca=s(Ote);vHr=r(eca,"TFBartForConditionalGeneration"),eca.forEach(t),FHr=r(LYe," (BART model)"),LYe.forEach(t),THr=i(qe),Gw=n(qe,"LI",{});var yYe=s(Gw);c8e=n(yYe,"STRONG",{});var oca=s(c8e);MHr=r(oca,"blenderbot"),oca.forEach(t),EHr=r(yYe," \u2014 "),Vte=n(yYe,"A",{href:!0});var rca=s(Vte);CHr=r(rca,"TFBlenderbotForConditionalGeneration"),rca.forEach(t),wHr=r(yYe," (Blenderbot model)"),yYe.forEach(t),AHr=i(qe),Ow=n(qe,"LI",{});var xYe=s(Ow);m8e=n(xYe,"STRONG",{});var tca=s(m8e);LHr=r(tca,"blenderbot-small"),tca.forEach(t),yHr=r(xYe," \u2014 "),Xte=n(xYe,"A",{href:!0});var aca=s(Xte);xHr=r(aca,"TFBlenderbotSmallForConditionalGeneration"),aca.forEach(t),$Hr=r(xYe," (BlenderbotSmall model)"),xYe.forEach(t),kHr=i(qe),Vw=n(qe,"LI",{});var $Ye=s(Vw);f8e=n($Ye,"STRONG",{});var nca=s(f8e);SHr=r(nca,"encoder-decoder"),nca.forEach(t),RHr=r($Ye," \u2014 "),zte=n($Ye,"A",{href:!0});var sca=s(zte);PHr=r(sca,"TFEncoderDecoderModel"),sca.forEach(t),BHr=r($Ye," (Encoder decoder model)"),$Ye.forEach(t),IHr=i(qe),Xw=n(qe,"LI",{});var kYe=s(Xw);g8e=n(kYe,"STRONG",{});var lca=s(g8e);NHr=r(lca,"led"),lca.forEach(t),qHr=r(kYe," \u2014 "),Qte=n(kYe,"A",{href:!0});var ica=s(Qte);jHr=r(ica,"TFLEDForConditionalGeneration"),ica.forEach(t),DHr=r(kYe," (LED model)"),kYe.forEach(t),GHr=i(qe),zw=n(qe,"LI",{});var SYe=s(zw);h8e=n(SYe,"STRONG",{});var dca=s(h8e);OHr=r(dca,"marian"),dca.forEach(t),VHr=r(SYe," \u2014 "),Wte=n(SYe,"A",{href:!0});var cca=s(Wte);XHr=r(cca,"TFMarianMTModel"),cca.forEach(t),zHr=r(SYe," (Marian model)"),SYe.forEach(t),QHr=i(qe),Qw=n(qe,"LI",{});var RYe=s(Qw);u8e=n(RYe,"STRONG",{});var mca=s(u8e);WHr=r(mca,"mbart"),mca.forEach(t),UHr=r(RYe," \u2014 "),Ute=n(RYe,"A",{href:!0});var fca=s(Ute);HHr=r(fca,"TFMBartForConditionalGeneration"),fca.forEach(t),JHr=r(RYe," (mBART model)"),RYe.forEach(t),YHr=i(qe),Ww=n(qe,"LI",{});var PYe=s(Ww);p8e=n(PYe,"STRONG",{});var gca=s(p8e);ZHr=r(gca,"mt5"),gca.forEach(t),KHr=r(PYe," \u2014 "),Hte=n(PYe,"A",{href:!0});var hca=s(Hte);eJr=r(hca,"TFMT5ForConditionalGeneration"),hca.forEach(t),oJr=r(PYe," (MT5 model)"),PYe.forEach(t),rJr=i(qe),Uw=n(qe,"LI",{});var BYe=s(Uw);_8e=n(BYe,"STRONG",{});var uca=s(_8e);tJr=r(uca,"pegasus"),uca.forEach(t),aJr=r(BYe," \u2014 "),Jte=n(BYe,"A",{href:!0});var pca=s(Jte);nJr=r(pca,"TFPegasusForConditionalGeneration"),pca.forEach(t),sJr=r(BYe," (Pegasus model)"),BYe.forEach(t),lJr=i(qe),Hw=n(qe,"LI",{});var IYe=s(Hw);b8e=n(IYe,"STRONG",{});var _ca=s(b8e);iJr=r(_ca,"t5"),_ca.forEach(t),dJr=r(IYe," \u2014 "),Yte=n(IYe,"A",{href:!0});var bca=s(Yte);cJr=r(bca,"TFT5ForConditionalGeneration"),bca.forEach(t),mJr=r(IYe," (T5 model)"),IYe.forEach(t),qe.forEach(t),fJr=i(Fi),T(Jw.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),Yro=i(m),Fm=n(m,"H2",{class:!0});var gno=s(Fm);Yw=n(gno,"A",{id:!0,class:!0,href:!0});var vca=s(Yw);v8e=n(vca,"SPAN",{});var Fca=s(v8e);T(cR.$$.fragment,Fca),Fca.forEach(t),vca.forEach(t),gJr=i(gno),F8e=n(gno,"SPAN",{});var Tca=s(F8e);hJr=r(Tca,"TFAutoModelForSequenceClassification"),Tca.forEach(t),gno.forEach(t),Zro=i(m),ur=n(m,"DIV",{class:!0});var Ti=s(ur);T(mR.$$.fragment,Ti),uJr=i(Ti),Tm=n(Ti,"P",{});var fce=s(Tm);pJr=r(fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Zte=n(fce,"A",{href:!0});var Mca=s(Zte);_Jr=r(Mca,"from_pretrained()"),Mca.forEach(t),bJr=r(fce," class method or the "),Kte=n(fce,"A",{href:!0});var Eca=s(Kte);vJr=r(Eca,"from_config()"),Eca.forEach(t),FJr=r(fce,` class
method.`),fce.forEach(t),TJr=i(Ti),fR=n(Ti,"P",{});var hno=s(fR);MJr=r(hno,"This class cannot be instantiated directly using "),T8e=n(hno,"CODE",{});var Cca=s(T8e);EJr=r(Cca,"__init__()"),Cca.forEach(t),CJr=r(hno," (throws an error)."),hno.forEach(t),wJr=i(Ti),ea=n(Ti,"DIV",{class:!0});var q9=s(ea);T(gR.$$.fragment,q9),AJr=i(q9),M8e=n(q9,"P",{});var wca=s(M8e);LJr=r(wca,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),wca.forEach(t),yJr=i(q9),Mm=n(q9,"P",{});var gce=s(Mm);xJr=r(gce,`Note:
Loading a model from its configuration file does `),E8e=n(gce,"STRONG",{});var Aca=s(E8e);$Jr=r(Aca,"not"),Aca.forEach(t),kJr=r(gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),eae=n(gce,"A",{href:!0});var Lca=s(eae);SJr=r(Lca,"from_pretrained()"),Lca.forEach(t),RJr=r(gce," to load the model weights."),gce.forEach(t),PJr=i(q9),T(Zw.$$.fragment,q9),q9.forEach(t),BJr=i(Ti),zr=n(Ti,"DIV",{class:!0});var Mi=s(zr);T(hR.$$.fragment,Mi),IJr=i(Mi),C8e=n(Mi,"P",{});var yca=s(C8e);NJr=r(yca,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),yca.forEach(t),qJr=i(Mi),Nn=n(Mi,"P",{});var j9=s(Nn);jJr=r(j9,"The model class to instantiate is selected based on the "),w8e=n(j9,"CODE",{});var xca=s(w8e);DJr=r(xca,"model_type"),xca.forEach(t),GJr=r(j9,` property of the config object (either
passed as an argument or loaded from `),A8e=n(j9,"CODE",{});var $ca=s(A8e);OJr=r($ca,"pretrained_model_name_or_path"),$ca.forEach(t),VJr=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L8e=n(j9,"CODE",{});var kca=s(L8e);XJr=r(kca,"pretrained_model_name_or_path"),kca.forEach(t),zJr=r(j9,":"),j9.forEach(t),QJr=i(Mi),re=n(Mi,"UL",{});var ae=s(re);Kw=n(ae,"LI",{});var NYe=s(Kw);y8e=n(NYe,"STRONG",{});var Sca=s(y8e);WJr=r(Sca,"albert"),Sca.forEach(t),UJr=r(NYe," \u2014 "),oae=n(NYe,"A",{href:!0});var Rca=s(oae);HJr=r(Rca,"TFAlbertForSequenceClassification"),Rca.forEach(t),JJr=r(NYe," (ALBERT model)"),NYe.forEach(t),YJr=i(ae),eA=n(ae,"LI",{});var qYe=s(eA);x8e=n(qYe,"STRONG",{});var Pca=s(x8e);ZJr=r(Pca,"bert"),Pca.forEach(t),KJr=r(qYe," \u2014 "),rae=n(qYe,"A",{href:!0});var Bca=s(rae);eYr=r(Bca,"TFBertForSequenceClassification"),Bca.forEach(t),oYr=r(qYe," (BERT model)"),qYe.forEach(t),rYr=i(ae),oA=n(ae,"LI",{});var jYe=s(oA);$8e=n(jYe,"STRONG",{});var Ica=s($8e);tYr=r(Ica,"camembert"),Ica.forEach(t),aYr=r(jYe," \u2014 "),tae=n(jYe,"A",{href:!0});var Nca=s(tae);nYr=r(Nca,"TFCamembertForSequenceClassification"),Nca.forEach(t),sYr=r(jYe," (CamemBERT model)"),jYe.forEach(t),lYr=i(ae),rA=n(ae,"LI",{});var DYe=s(rA);k8e=n(DYe,"STRONG",{});var qca=s(k8e);iYr=r(qca,"convbert"),qca.forEach(t),dYr=r(DYe," \u2014 "),aae=n(DYe,"A",{href:!0});var jca=s(aae);cYr=r(jca,"TFConvBertForSequenceClassification"),jca.forEach(t),mYr=r(DYe," (ConvBERT model)"),DYe.forEach(t),fYr=i(ae),tA=n(ae,"LI",{});var GYe=s(tA);S8e=n(GYe,"STRONG",{});var Dca=s(S8e);gYr=r(Dca,"ctrl"),Dca.forEach(t),hYr=r(GYe," \u2014 "),nae=n(GYe,"A",{href:!0});var Gca=s(nae);uYr=r(Gca,"TFCTRLForSequenceClassification"),Gca.forEach(t),pYr=r(GYe," (CTRL model)"),GYe.forEach(t),_Yr=i(ae),aA=n(ae,"LI",{});var OYe=s(aA);R8e=n(OYe,"STRONG",{});var Oca=s(R8e);bYr=r(Oca,"deberta"),Oca.forEach(t),vYr=r(OYe," \u2014 "),sae=n(OYe,"A",{href:!0});var Vca=s(sae);FYr=r(Vca,"TFDebertaForSequenceClassification"),Vca.forEach(t),TYr=r(OYe," (DeBERTa model)"),OYe.forEach(t),MYr=i(ae),nA=n(ae,"LI",{});var VYe=s(nA);P8e=n(VYe,"STRONG",{});var Xca=s(P8e);EYr=r(Xca,"deberta-v2"),Xca.forEach(t),CYr=r(VYe," \u2014 "),lae=n(VYe,"A",{href:!0});var zca=s(lae);wYr=r(zca,"TFDebertaV2ForSequenceClassification"),zca.forEach(t),AYr=r(VYe," (DeBERTa-v2 model)"),VYe.forEach(t),LYr=i(ae),sA=n(ae,"LI",{});var XYe=s(sA);B8e=n(XYe,"STRONG",{});var Qca=s(B8e);yYr=r(Qca,"distilbert"),Qca.forEach(t),xYr=r(XYe," \u2014 "),iae=n(XYe,"A",{href:!0});var Wca=s(iae);$Yr=r(Wca,"TFDistilBertForSequenceClassification"),Wca.forEach(t),kYr=r(XYe," (DistilBERT model)"),XYe.forEach(t),SYr=i(ae),lA=n(ae,"LI",{});var zYe=s(lA);I8e=n(zYe,"STRONG",{});var Uca=s(I8e);RYr=r(Uca,"electra"),Uca.forEach(t),PYr=r(zYe," \u2014 "),dae=n(zYe,"A",{href:!0});var Hca=s(dae);BYr=r(Hca,"TFElectraForSequenceClassification"),Hca.forEach(t),IYr=r(zYe," (ELECTRA model)"),zYe.forEach(t),NYr=i(ae),iA=n(ae,"LI",{});var QYe=s(iA);N8e=n(QYe,"STRONG",{});var Jca=s(N8e);qYr=r(Jca,"flaubert"),Jca.forEach(t),jYr=r(QYe," \u2014 "),cae=n(QYe,"A",{href:!0});var Yca=s(cae);DYr=r(Yca,"TFFlaubertForSequenceClassification"),Yca.forEach(t),GYr=r(QYe," (FlauBERT model)"),QYe.forEach(t),OYr=i(ae),dA=n(ae,"LI",{});var WYe=s(dA);q8e=n(WYe,"STRONG",{});var Zca=s(q8e);VYr=r(Zca,"funnel"),Zca.forEach(t),XYr=r(WYe," \u2014 "),mae=n(WYe,"A",{href:!0});var Kca=s(mae);zYr=r(Kca,"TFFunnelForSequenceClassification"),Kca.forEach(t),QYr=r(WYe," (Funnel Transformer model)"),WYe.forEach(t),WYr=i(ae),cA=n(ae,"LI",{});var UYe=s(cA);j8e=n(UYe,"STRONG",{});var ema=s(j8e);UYr=r(ema,"gpt2"),ema.forEach(t),HYr=r(UYe," \u2014 "),fae=n(UYe,"A",{href:!0});var oma=s(fae);JYr=r(oma,"TFGPT2ForSequenceClassification"),oma.forEach(t),YYr=r(UYe," (OpenAI GPT-2 model)"),UYe.forEach(t),ZYr=i(ae),mA=n(ae,"LI",{});var HYe=s(mA);D8e=n(HYe,"STRONG",{});var rma=s(D8e);KYr=r(rma,"gptj"),rma.forEach(t),eZr=r(HYe," \u2014 "),gae=n(HYe,"A",{href:!0});var tma=s(gae);oZr=r(tma,"TFGPTJForSequenceClassification"),tma.forEach(t),rZr=r(HYe," (GPT-J model)"),HYe.forEach(t),tZr=i(ae),fA=n(ae,"LI",{});var JYe=s(fA);G8e=n(JYe,"STRONG",{});var ama=s(G8e);aZr=r(ama,"layoutlm"),ama.forEach(t),nZr=r(JYe," \u2014 "),hae=n(JYe,"A",{href:!0});var nma=s(hae);sZr=r(nma,"TFLayoutLMForSequenceClassification"),nma.forEach(t),lZr=r(JYe," (LayoutLM model)"),JYe.forEach(t),iZr=i(ae),gA=n(ae,"LI",{});var YYe=s(gA);O8e=n(YYe,"STRONG",{});var sma=s(O8e);dZr=r(sma,"layoutlmv3"),sma.forEach(t),cZr=r(YYe," \u2014 "),uae=n(YYe,"A",{href:!0});var lma=s(uae);mZr=r(lma,"TFLayoutLMv3ForSequenceClassification"),lma.forEach(t),fZr=r(YYe," (LayoutLMv3 model)"),YYe.forEach(t),gZr=i(ae),hA=n(ae,"LI",{});var ZYe=s(hA);V8e=n(ZYe,"STRONG",{});var ima=s(V8e);hZr=r(ima,"longformer"),ima.forEach(t),uZr=r(ZYe," \u2014 "),pae=n(ZYe,"A",{href:!0});var dma=s(pae);pZr=r(dma,"TFLongformerForSequenceClassification"),dma.forEach(t),_Zr=r(ZYe," (Longformer model)"),ZYe.forEach(t),bZr=i(ae),uA=n(ae,"LI",{});var KYe=s(uA);X8e=n(KYe,"STRONG",{});var cma=s(X8e);vZr=r(cma,"mobilebert"),cma.forEach(t),FZr=r(KYe," \u2014 "),_ae=n(KYe,"A",{href:!0});var mma=s(_ae);TZr=r(mma,"TFMobileBertForSequenceClassification"),mma.forEach(t),MZr=r(KYe," (MobileBERT model)"),KYe.forEach(t),EZr=i(ae),pA=n(ae,"LI",{});var eZe=s(pA);z8e=n(eZe,"STRONG",{});var fma=s(z8e);CZr=r(fma,"mpnet"),fma.forEach(t),wZr=r(eZe," \u2014 "),bae=n(eZe,"A",{href:!0});var gma=s(bae);AZr=r(gma,"TFMPNetForSequenceClassification"),gma.forEach(t),LZr=r(eZe," (MPNet model)"),eZe.forEach(t),yZr=i(ae),_A=n(ae,"LI",{});var oZe=s(_A);Q8e=n(oZe,"STRONG",{});var hma=s(Q8e);xZr=r(hma,"openai-gpt"),hma.forEach(t),$Zr=r(oZe," \u2014 "),vae=n(oZe,"A",{href:!0});var uma=s(vae);kZr=r(uma,"TFOpenAIGPTForSequenceClassification"),uma.forEach(t),SZr=r(oZe," (OpenAI GPT model)"),oZe.forEach(t),RZr=i(ae),bA=n(ae,"LI",{});var rZe=s(bA);W8e=n(rZe,"STRONG",{});var pma=s(W8e);PZr=r(pma,"rembert"),pma.forEach(t),BZr=r(rZe," \u2014 "),Fae=n(rZe,"A",{href:!0});var _ma=s(Fae);IZr=r(_ma,"TFRemBertForSequenceClassification"),_ma.forEach(t),NZr=r(rZe," (RemBERT model)"),rZe.forEach(t),qZr=i(ae),vA=n(ae,"LI",{});var tZe=s(vA);U8e=n(tZe,"STRONG",{});var bma=s(U8e);jZr=r(bma,"roberta"),bma.forEach(t),DZr=r(tZe," \u2014 "),Tae=n(tZe,"A",{href:!0});var vma=s(Tae);GZr=r(vma,"TFRobertaForSequenceClassification"),vma.forEach(t),OZr=r(tZe," (RoBERTa model)"),tZe.forEach(t),VZr=i(ae),FA=n(ae,"LI",{});var aZe=s(FA);H8e=n(aZe,"STRONG",{});var Fma=s(H8e);XZr=r(Fma,"roformer"),Fma.forEach(t),zZr=r(aZe," \u2014 "),Mae=n(aZe,"A",{href:!0});var Tma=s(Mae);QZr=r(Tma,"TFRoFormerForSequenceClassification"),Tma.forEach(t),WZr=r(aZe," (RoFormer model)"),aZe.forEach(t),UZr=i(ae),TA=n(ae,"LI",{});var nZe=s(TA);J8e=n(nZe,"STRONG",{});var Mma=s(J8e);HZr=r(Mma,"tapas"),Mma.forEach(t),JZr=r(nZe," \u2014 "),Eae=n(nZe,"A",{href:!0});var Ema=s(Eae);YZr=r(Ema,"TFTapasForSequenceClassification"),Ema.forEach(t),ZZr=r(nZe," (TAPAS model)"),nZe.forEach(t),KZr=i(ae),MA=n(ae,"LI",{});var sZe=s(MA);Y8e=n(sZe,"STRONG",{});var Cma=s(Y8e);eKr=r(Cma,"transfo-xl"),Cma.forEach(t),oKr=r(sZe," \u2014 "),Cae=n(sZe,"A",{href:!0});var wma=s(Cae);rKr=r(wma,"TFTransfoXLForSequenceClassification"),wma.forEach(t),tKr=r(sZe," (Transformer-XL model)"),sZe.forEach(t),aKr=i(ae),EA=n(ae,"LI",{});var lZe=s(EA);Z8e=n(lZe,"STRONG",{});var Ama=s(Z8e);nKr=r(Ama,"xlm"),Ama.forEach(t),sKr=r(lZe," \u2014 "),wae=n(lZe,"A",{href:!0});var Lma=s(wae);lKr=r(Lma,"TFXLMForSequenceClassification"),Lma.forEach(t),iKr=r(lZe," (XLM model)"),lZe.forEach(t),dKr=i(ae),CA=n(ae,"LI",{});var iZe=s(CA);K8e=n(iZe,"STRONG",{});var yma=s(K8e);cKr=r(yma,"xlm-roberta"),yma.forEach(t),mKr=r(iZe," \u2014 "),Aae=n(iZe,"A",{href:!0});var xma=s(Aae);fKr=r(xma,"TFXLMRobertaForSequenceClassification"),xma.forEach(t),gKr=r(iZe," (XLM-RoBERTa model)"),iZe.forEach(t),hKr=i(ae),wA=n(ae,"LI",{});var dZe=s(wA);eye=n(dZe,"STRONG",{});var $ma=s(eye);uKr=r($ma,"xlnet"),$ma.forEach(t),pKr=r(dZe," \u2014 "),Lae=n(dZe,"A",{href:!0});var kma=s(Lae);_Kr=r(kma,"TFXLNetForSequenceClassification"),kma.forEach(t),bKr=r(dZe," (XLNet model)"),dZe.forEach(t),ae.forEach(t),vKr=i(Mi),T(AA.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),Kro=i(m),Em=n(m,"H2",{class:!0});var uno=s(Em);LA=n(uno,"A",{id:!0,class:!0,href:!0});var Sma=s(LA);oye=n(Sma,"SPAN",{});var Rma=s(oye);T(uR.$$.fragment,Rma),Rma.forEach(t),Sma.forEach(t),FKr=i(uno),rye=n(uno,"SPAN",{});var Pma=s(rye);TKr=r(Pma,"TFAutoModelForMultipleChoice"),Pma.forEach(t),uno.forEach(t),eto=i(m),pr=n(m,"DIV",{class:!0});var Ei=s(pr);T(pR.$$.fragment,Ei),MKr=i(Ei),Cm=n(Ei,"P",{});var hce=s(Cm);EKr=r(hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),yae=n(hce,"A",{href:!0});var Bma=s(yae);CKr=r(Bma,"from_pretrained()"),Bma.forEach(t),wKr=r(hce," class method or the "),xae=n(hce,"A",{href:!0});var Ima=s(xae);AKr=r(Ima,"from_config()"),Ima.forEach(t),LKr=r(hce,` class
method.`),hce.forEach(t),yKr=i(Ei),_R=n(Ei,"P",{});var pno=s(_R);xKr=r(pno,"This class cannot be instantiated directly using "),tye=n(pno,"CODE",{});var Nma=s(tye);$Kr=r(Nma,"__init__()"),Nma.forEach(t),kKr=r(pno," (throws an error)."),pno.forEach(t),SKr=i(Ei),oa=n(Ei,"DIV",{class:!0});var D9=s(oa);T(bR.$$.fragment,D9),RKr=i(D9),aye=n(D9,"P",{});var qma=s(aye);PKr=r(qma,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),qma.forEach(t),BKr=i(D9),wm=n(D9,"P",{});var uce=s(wm);IKr=r(uce,`Note:
Loading a model from its configuration file does `),nye=n(uce,"STRONG",{});var jma=s(nye);NKr=r(jma,"not"),jma.forEach(t),qKr=r(uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ae=n(uce,"A",{href:!0});var Dma=s($ae);jKr=r(Dma,"from_pretrained()"),Dma.forEach(t),DKr=r(uce," to load the model weights."),uce.forEach(t),GKr=i(D9),T(yA.$$.fragment,D9),D9.forEach(t),OKr=i(Ei),Qr=n(Ei,"DIV",{class:!0});var Ci=s(Qr);T(vR.$$.fragment,Ci),VKr=i(Ci),sye=n(Ci,"P",{});var Gma=s(sye);XKr=r(Gma,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Gma.forEach(t),zKr=i(Ci),qn=n(Ci,"P",{});var G9=s(qn);QKr=r(G9,"The model class to instantiate is selected based on the "),lye=n(G9,"CODE",{});var Oma=s(lye);WKr=r(Oma,"model_type"),Oma.forEach(t),UKr=r(G9,` property of the config object (either
passed as an argument or loaded from `),iye=n(G9,"CODE",{});var Vma=s(iye);HKr=r(Vma,"pretrained_model_name_or_path"),Vma.forEach(t),JKr=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dye=n(G9,"CODE",{});var Xma=s(dye);YKr=r(Xma,"pretrained_model_name_or_path"),Xma.forEach(t),ZKr=r(G9,":"),G9.forEach(t),KKr=i(Ci),ve=n(Ci,"UL",{});var Te=s(ve);xA=n(Te,"LI",{});var cZe=s(xA);cye=n(cZe,"STRONG",{});var zma=s(cye);eet=r(zma,"albert"),zma.forEach(t),oet=r(cZe," \u2014 "),kae=n(cZe,"A",{href:!0});var Qma=s(kae);ret=r(Qma,"TFAlbertForMultipleChoice"),Qma.forEach(t),tet=r(cZe," (ALBERT model)"),cZe.forEach(t),aet=i(Te),$A=n(Te,"LI",{});var mZe=s($A);mye=n(mZe,"STRONG",{});var Wma=s(mye);net=r(Wma,"bert"),Wma.forEach(t),set=r(mZe," \u2014 "),Sae=n(mZe,"A",{href:!0});var Uma=s(Sae);iet=r(Uma,"TFBertForMultipleChoice"),Uma.forEach(t),det=r(mZe," (BERT model)"),mZe.forEach(t),cet=i(Te),kA=n(Te,"LI",{});var fZe=s(kA);fye=n(fZe,"STRONG",{});var Hma=s(fye);met=r(Hma,"camembert"),Hma.forEach(t),fet=r(fZe," \u2014 "),Rae=n(fZe,"A",{href:!0});var Jma=s(Rae);get=r(Jma,"TFCamembertForMultipleChoice"),Jma.forEach(t),het=r(fZe," (CamemBERT model)"),fZe.forEach(t),uet=i(Te),SA=n(Te,"LI",{});var gZe=s(SA);gye=n(gZe,"STRONG",{});var Yma=s(gye);pet=r(Yma,"convbert"),Yma.forEach(t),_et=r(gZe," \u2014 "),Pae=n(gZe,"A",{href:!0});var Zma=s(Pae);bet=r(Zma,"TFConvBertForMultipleChoice"),Zma.forEach(t),vet=r(gZe," (ConvBERT model)"),gZe.forEach(t),Fet=i(Te),RA=n(Te,"LI",{});var hZe=s(RA);hye=n(hZe,"STRONG",{});var Kma=s(hye);Tet=r(Kma,"distilbert"),Kma.forEach(t),Met=r(hZe," \u2014 "),Bae=n(hZe,"A",{href:!0});var efa=s(Bae);Eet=r(efa,"TFDistilBertForMultipleChoice"),efa.forEach(t),Cet=r(hZe," (DistilBERT model)"),hZe.forEach(t),wet=i(Te),PA=n(Te,"LI",{});var uZe=s(PA);uye=n(uZe,"STRONG",{});var ofa=s(uye);Aet=r(ofa,"electra"),ofa.forEach(t),Let=r(uZe," \u2014 "),Iae=n(uZe,"A",{href:!0});var rfa=s(Iae);yet=r(rfa,"TFElectraForMultipleChoice"),rfa.forEach(t),xet=r(uZe," (ELECTRA model)"),uZe.forEach(t),$et=i(Te),BA=n(Te,"LI",{});var pZe=s(BA);pye=n(pZe,"STRONG",{});var tfa=s(pye);ket=r(tfa,"flaubert"),tfa.forEach(t),Set=r(pZe," \u2014 "),Nae=n(pZe,"A",{href:!0});var afa=s(Nae);Ret=r(afa,"TFFlaubertForMultipleChoice"),afa.forEach(t),Pet=r(pZe," (FlauBERT model)"),pZe.forEach(t),Bet=i(Te),IA=n(Te,"LI",{});var _Ze=s(IA);_ye=n(_Ze,"STRONG",{});var nfa=s(_ye);Iet=r(nfa,"funnel"),nfa.forEach(t),Net=r(_Ze," \u2014 "),qae=n(_Ze,"A",{href:!0});var sfa=s(qae);qet=r(sfa,"TFFunnelForMultipleChoice"),sfa.forEach(t),jet=r(_Ze," (Funnel Transformer model)"),_Ze.forEach(t),Det=i(Te),NA=n(Te,"LI",{});var bZe=s(NA);bye=n(bZe,"STRONG",{});var lfa=s(bye);Get=r(lfa,"longformer"),lfa.forEach(t),Oet=r(bZe," \u2014 "),jae=n(bZe,"A",{href:!0});var ifa=s(jae);Vet=r(ifa,"TFLongformerForMultipleChoice"),ifa.forEach(t),Xet=r(bZe," (Longformer model)"),bZe.forEach(t),zet=i(Te),qA=n(Te,"LI",{});var vZe=s(qA);vye=n(vZe,"STRONG",{});var dfa=s(vye);Qet=r(dfa,"mobilebert"),dfa.forEach(t),Wet=r(vZe," \u2014 "),Dae=n(vZe,"A",{href:!0});var cfa=s(Dae);Uet=r(cfa,"TFMobileBertForMultipleChoice"),cfa.forEach(t),Het=r(vZe," (MobileBERT model)"),vZe.forEach(t),Jet=i(Te),jA=n(Te,"LI",{});var FZe=s(jA);Fye=n(FZe,"STRONG",{});var mfa=s(Fye);Yet=r(mfa,"mpnet"),mfa.forEach(t),Zet=r(FZe," \u2014 "),Gae=n(FZe,"A",{href:!0});var ffa=s(Gae);Ket=r(ffa,"TFMPNetForMultipleChoice"),ffa.forEach(t),eot=r(FZe," (MPNet model)"),FZe.forEach(t),oot=i(Te),DA=n(Te,"LI",{});var TZe=s(DA);Tye=n(TZe,"STRONG",{});var gfa=s(Tye);rot=r(gfa,"rembert"),gfa.forEach(t),tot=r(TZe," \u2014 "),Oae=n(TZe,"A",{href:!0});var hfa=s(Oae);aot=r(hfa,"TFRemBertForMultipleChoice"),hfa.forEach(t),not=r(TZe," (RemBERT model)"),TZe.forEach(t),sot=i(Te),GA=n(Te,"LI",{});var MZe=s(GA);Mye=n(MZe,"STRONG",{});var ufa=s(Mye);lot=r(ufa,"roberta"),ufa.forEach(t),iot=r(MZe," \u2014 "),Vae=n(MZe,"A",{href:!0});var pfa=s(Vae);dot=r(pfa,"TFRobertaForMultipleChoice"),pfa.forEach(t),cot=r(MZe," (RoBERTa model)"),MZe.forEach(t),mot=i(Te),OA=n(Te,"LI",{});var EZe=s(OA);Eye=n(EZe,"STRONG",{});var _fa=s(Eye);fot=r(_fa,"roformer"),_fa.forEach(t),got=r(EZe," \u2014 "),Xae=n(EZe,"A",{href:!0});var bfa=s(Xae);hot=r(bfa,"TFRoFormerForMultipleChoice"),bfa.forEach(t),uot=r(EZe," (RoFormer model)"),EZe.forEach(t),pot=i(Te),VA=n(Te,"LI",{});var CZe=s(VA);Cye=n(CZe,"STRONG",{});var vfa=s(Cye);_ot=r(vfa,"xlm"),vfa.forEach(t),bot=r(CZe," \u2014 "),zae=n(CZe,"A",{href:!0});var Ffa=s(zae);vot=r(Ffa,"TFXLMForMultipleChoice"),Ffa.forEach(t),Fot=r(CZe," (XLM model)"),CZe.forEach(t),Tot=i(Te),XA=n(Te,"LI",{});var wZe=s(XA);wye=n(wZe,"STRONG",{});var Tfa=s(wye);Mot=r(Tfa,"xlm-roberta"),Tfa.forEach(t),Eot=r(wZe," \u2014 "),Qae=n(wZe,"A",{href:!0});var Mfa=s(Qae);Cot=r(Mfa,"TFXLMRobertaForMultipleChoice"),Mfa.forEach(t),wot=r(wZe," (XLM-RoBERTa model)"),wZe.forEach(t),Aot=i(Te),zA=n(Te,"LI",{});var AZe=s(zA);Aye=n(AZe,"STRONG",{});var Efa=s(Aye);Lot=r(Efa,"xlnet"),Efa.forEach(t),yot=r(AZe," \u2014 "),Wae=n(AZe,"A",{href:!0});var Cfa=s(Wae);xot=r(Cfa,"TFXLNetForMultipleChoice"),Cfa.forEach(t),$ot=r(AZe," (XLNet model)"),AZe.forEach(t),Te.forEach(t),kot=i(Ci),T(QA.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),oto=i(m),Am=n(m,"H2",{class:!0});var _no=s(Am);WA=n(_no,"A",{id:!0,class:!0,href:!0});var wfa=s(WA);Lye=n(wfa,"SPAN",{});var Afa=s(Lye);T(FR.$$.fragment,Afa),Afa.forEach(t),wfa.forEach(t),Sot=i(_no),yye=n(_no,"SPAN",{});var Lfa=s(yye);Rot=r(Lfa,"TFAutoModelForNextSentencePrediction"),Lfa.forEach(t),_no.forEach(t),rto=i(m),_r=n(m,"DIV",{class:!0});var wi=s(_r);T(TR.$$.fragment,wi),Pot=i(wi),Lm=n(wi,"P",{});var pce=s(Lm);Bot=r(pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Uae=n(pce,"A",{href:!0});var yfa=s(Uae);Iot=r(yfa,"from_pretrained()"),yfa.forEach(t),Not=r(pce," class method or the "),Hae=n(pce,"A",{href:!0});var xfa=s(Hae);qot=r(xfa,"from_config()"),xfa.forEach(t),jot=r(pce,` class
method.`),pce.forEach(t),Dot=i(wi),MR=n(wi,"P",{});var bno=s(MR);Got=r(bno,"This class cannot be instantiated directly using "),xye=n(bno,"CODE",{});var $fa=s(xye);Oot=r($fa,"__init__()"),$fa.forEach(t),Vot=r(bno," (throws an error)."),bno.forEach(t),Xot=i(wi),ra=n(wi,"DIV",{class:!0});var O9=s(ra);T(ER.$$.fragment,O9),zot=i(O9),$ye=n(O9,"P",{});var kfa=s($ye);Qot=r(kfa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),kfa.forEach(t),Wot=i(O9),ym=n(O9,"P",{});var _ce=s(ym);Uot=r(_ce,`Note:
Loading a model from its configuration file does `),kye=n(_ce,"STRONG",{});var Sfa=s(kye);Hot=r(Sfa,"not"),Sfa.forEach(t),Jot=r(_ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jae=n(_ce,"A",{href:!0});var Rfa=s(Jae);Yot=r(Rfa,"from_pretrained()"),Rfa.forEach(t),Zot=r(_ce," to load the model weights."),_ce.forEach(t),Kot=i(O9),T(UA.$$.fragment,O9),O9.forEach(t),ert=i(wi),Wr=n(wi,"DIV",{class:!0});var Ai=s(Wr);T(CR.$$.fragment,Ai),ort=i(Ai),Sye=n(Ai,"P",{});var Pfa=s(Sye);rrt=r(Pfa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Pfa.forEach(t),trt=i(Ai),jn=n(Ai,"P",{});var V9=s(jn);art=r(V9,"The model class to instantiate is selected based on the "),Rye=n(V9,"CODE",{});var Bfa=s(Rye);nrt=r(Bfa,"model_type"),Bfa.forEach(t),srt=r(V9,` property of the config object (either
passed as an argument or loaded from `),Pye=n(V9,"CODE",{});var Ifa=s(Pye);lrt=r(Ifa,"pretrained_model_name_or_path"),Ifa.forEach(t),irt=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bye=n(V9,"CODE",{});var Nfa=s(Bye);drt=r(Nfa,"pretrained_model_name_or_path"),Nfa.forEach(t),crt=r(V9,":"),V9.forEach(t),mrt=i(Ai),wR=n(Ai,"UL",{});var vno=s(wR);HA=n(vno,"LI",{});var LZe=s(HA);Iye=n(LZe,"STRONG",{});var qfa=s(Iye);frt=r(qfa,"bert"),qfa.forEach(t),grt=r(LZe," \u2014 "),Yae=n(LZe,"A",{href:!0});var jfa=s(Yae);hrt=r(jfa,"TFBertForNextSentencePrediction"),jfa.forEach(t),urt=r(LZe," (BERT model)"),LZe.forEach(t),prt=i(vno),JA=n(vno,"LI",{});var yZe=s(JA);Nye=n(yZe,"STRONG",{});var Dfa=s(Nye);_rt=r(Dfa,"mobilebert"),Dfa.forEach(t),brt=r(yZe," \u2014 "),Zae=n(yZe,"A",{href:!0});var Gfa=s(Zae);vrt=r(Gfa,"TFMobileBertForNextSentencePrediction"),Gfa.forEach(t),Frt=r(yZe," (MobileBERT model)"),yZe.forEach(t),vno.forEach(t),Trt=i(Ai),T(YA.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),tto=i(m),xm=n(m,"H2",{class:!0});var Fno=s(xm);ZA=n(Fno,"A",{id:!0,class:!0,href:!0});var Ofa=s(ZA);qye=n(Ofa,"SPAN",{});var Vfa=s(qye);T(AR.$$.fragment,Vfa),Vfa.forEach(t),Ofa.forEach(t),Mrt=i(Fno),jye=n(Fno,"SPAN",{});var Xfa=s(jye);Ert=r(Xfa,"TFAutoModelForTableQuestionAnswering"),Xfa.forEach(t),Fno.forEach(t),ato=i(m),br=n(m,"DIV",{class:!0});var Li=s(br);T(LR.$$.fragment,Li),Crt=i(Li),$m=n(Li,"P",{});var bce=s($m);wrt=r(bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Kae=n(bce,"A",{href:!0});var zfa=s(Kae);Art=r(zfa,"from_pretrained()"),zfa.forEach(t),Lrt=r(bce," class method or the "),ene=n(bce,"A",{href:!0});var Qfa=s(ene);yrt=r(Qfa,"from_config()"),Qfa.forEach(t),xrt=r(bce,` class
method.`),bce.forEach(t),$rt=i(Li),yR=n(Li,"P",{});var Tno=s(yR);krt=r(Tno,"This class cannot be instantiated directly using "),Dye=n(Tno,"CODE",{});var Wfa=s(Dye);Srt=r(Wfa,"__init__()"),Wfa.forEach(t),Rrt=r(Tno," (throws an error)."),Tno.forEach(t),Prt=i(Li),ta=n(Li,"DIV",{class:!0});var X9=s(ta);T(xR.$$.fragment,X9),Brt=i(X9),Gye=n(X9,"P",{});var Ufa=s(Gye);Irt=r(Ufa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Ufa.forEach(t),Nrt=i(X9),km=n(X9,"P",{});var vce=s(km);qrt=r(vce,`Note:
Loading a model from its configuration file does `),Oye=n(vce,"STRONG",{});var Hfa=s(Oye);jrt=r(Hfa,"not"),Hfa.forEach(t),Drt=r(vce,` load the model weights. It only affects the
model\u2019s configuration. Use `),one=n(vce,"A",{href:!0});var Jfa=s(one);Grt=r(Jfa,"from_pretrained()"),Jfa.forEach(t),Ort=r(vce," to load the model weights."),vce.forEach(t),Vrt=i(X9),T(KA.$$.fragment,X9),X9.forEach(t),Xrt=i(Li),Ur=n(Li,"DIV",{class:!0});var yi=s(Ur);T($R.$$.fragment,yi),zrt=i(yi),Vye=n(yi,"P",{});var Yfa=s(Vye);Qrt=r(Yfa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Yfa.forEach(t),Wrt=i(yi),Dn=n(yi,"P",{});var z9=s(Dn);Urt=r(z9,"The model class to instantiate is selected based on the "),Xye=n(z9,"CODE",{});var Zfa=s(Xye);Hrt=r(Zfa,"model_type"),Zfa.forEach(t),Jrt=r(z9,` property of the config object (either
passed as an argument or loaded from `),zye=n(z9,"CODE",{});var Kfa=s(zye);Yrt=r(Kfa,"pretrained_model_name_or_path"),Kfa.forEach(t),Zrt=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qye=n(z9,"CODE",{});var ega=s(Qye);Krt=r(ega,"pretrained_model_name_or_path"),ega.forEach(t),ett=r(z9,":"),z9.forEach(t),ott=i(yi),Wye=n(yi,"UL",{});var oga=s(Wye);e6=n(oga,"LI",{});var xZe=s(e6);Uye=n(xZe,"STRONG",{});var rga=s(Uye);rtt=r(rga,"tapas"),rga.forEach(t),ttt=r(xZe," \u2014 "),rne=n(xZe,"A",{href:!0});var tga=s(rne);att=r(tga,"TFTapasForQuestionAnswering"),tga.forEach(t),ntt=r(xZe," (TAPAS model)"),xZe.forEach(t),oga.forEach(t),stt=i(yi),T(o6.$$.fragment,yi),yi.forEach(t),Li.forEach(t),nto=i(m),Sm=n(m,"H2",{class:!0});var Mno=s(Sm);r6=n(Mno,"A",{id:!0,class:!0,href:!0});var aga=s(r6);Hye=n(aga,"SPAN",{});var nga=s(Hye);T(kR.$$.fragment,nga),nga.forEach(t),aga.forEach(t),ltt=i(Mno),Jye=n(Mno,"SPAN",{});var sga=s(Jye);itt=r(sga,"TFAutoModelForDocumentQuestionAnswering"),sga.forEach(t),Mno.forEach(t),sto=i(m),vr=n(m,"DIV",{class:!0});var xi=s(vr);T(SR.$$.fragment,xi),dtt=i(xi),Rm=n(xi,"P",{});var Fce=s(Rm);ctt=r(Fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),tne=n(Fce,"A",{href:!0});var lga=s(tne);mtt=r(lga,"from_pretrained()"),lga.forEach(t),ftt=r(Fce," class method or the "),ane=n(Fce,"A",{href:!0});var iga=s(ane);gtt=r(iga,"from_config()"),iga.forEach(t),htt=r(Fce,` class
method.`),Fce.forEach(t),utt=i(xi),RR=n(xi,"P",{});var Eno=s(RR);ptt=r(Eno,"This class cannot be instantiated directly using "),Yye=n(Eno,"CODE",{});var dga=s(Yye);_tt=r(dga,"__init__()"),dga.forEach(t),btt=r(Eno," (throws an error)."),Eno.forEach(t),vtt=i(xi),aa=n(xi,"DIV",{class:!0});var Q9=s(aa);T(PR.$$.fragment,Q9),Ftt=i(Q9),Zye=n(Q9,"P",{});var cga=s(Zye);Ttt=r(cga,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),cga.forEach(t),Mtt=i(Q9),Pm=n(Q9,"P",{});var Tce=s(Pm);Ett=r(Tce,`Note:
Loading a model from its configuration file does `),Kye=n(Tce,"STRONG",{});var mga=s(Kye);Ctt=r(mga,"not"),mga.forEach(t),wtt=r(Tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),nne=n(Tce,"A",{href:!0});var fga=s(nne);Att=r(fga,"from_pretrained()"),fga.forEach(t),Ltt=r(Tce," to load the model weights."),Tce.forEach(t),ytt=i(Q9),T(t6.$$.fragment,Q9),Q9.forEach(t),xtt=i(xi),Hr=n(xi,"DIV",{class:!0});var $i=s(Hr);T(BR.$$.fragment,$i),$tt=i($i),e9e=n($i,"P",{});var gga=s(e9e);ktt=r(gga,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),gga.forEach(t),Stt=i($i),Gn=n($i,"P",{});var W9=s(Gn);Rtt=r(W9,"The model class to instantiate is selected based on the "),o9e=n(W9,"CODE",{});var hga=s(o9e);Ptt=r(hga,"model_type"),hga.forEach(t),Btt=r(W9,` property of the config object (either
passed as an argument or loaded from `),r9e=n(W9,"CODE",{});var uga=s(r9e);Itt=r(uga,"pretrained_model_name_or_path"),uga.forEach(t),Ntt=r(W9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t9e=n(W9,"CODE",{});var pga=s(t9e);qtt=r(pga,"pretrained_model_name_or_path"),pga.forEach(t),jtt=r(W9,":"),W9.forEach(t),Dtt=i($i),a9e=n($i,"UL",{});var _ga=s(a9e);a6=n(_ga,"LI",{});var $Ze=s(a6);n9e=n($Ze,"STRONG",{});var bga=s(n9e);Gtt=r(bga,"layoutlm"),bga.forEach(t),Ott=r($Ze," \u2014 "),sne=n($Ze,"A",{href:!0});var vga=s(sne);Vtt=r(vga,"TFLayoutLMForQuestionAnswering"),vga.forEach(t),Xtt=r($Ze," (LayoutLM model)"),$Ze.forEach(t),_ga.forEach(t),ztt=i($i),T(n6.$$.fragment,$i),$i.forEach(t),xi.forEach(t),lto=i(m),Bm=n(m,"H2",{class:!0});var Cno=s(Bm);s6=n(Cno,"A",{id:!0,class:!0,href:!0});var Fga=s(s6);s9e=n(Fga,"SPAN",{});var Tga=s(s9e);T(IR.$$.fragment,Tga),Tga.forEach(t),Fga.forEach(t),Qtt=i(Cno),l9e=n(Cno,"SPAN",{});var Mga=s(l9e);Wtt=r(Mga,"TFAutoModelForTokenClassification"),Mga.forEach(t),Cno.forEach(t),ito=i(m),Fr=n(m,"DIV",{class:!0});var ki=s(Fr);T(NR.$$.fragment,ki),Utt=i(ki),Im=n(ki,"P",{});var Mce=s(Im);Htt=r(Mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),lne=n(Mce,"A",{href:!0});var Ega=s(lne);Jtt=r(Ega,"from_pretrained()"),Ega.forEach(t),Ytt=r(Mce," class method or the "),ine=n(Mce,"A",{href:!0});var Cga=s(ine);Ztt=r(Cga,"from_config()"),Cga.forEach(t),Ktt=r(Mce,` class
method.`),Mce.forEach(t),eat=i(ki),qR=n(ki,"P",{});var wno=s(qR);oat=r(wno,"This class cannot be instantiated directly using "),i9e=n(wno,"CODE",{});var wga=s(i9e);rat=r(wga,"__init__()"),wga.forEach(t),tat=r(wno," (throws an error)."),wno.forEach(t),aat=i(ki),na=n(ki,"DIV",{class:!0});var U9=s(na);T(jR.$$.fragment,U9),nat=i(U9),d9e=n(U9,"P",{});var Aga=s(d9e);sat=r(Aga,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aga.forEach(t),lat=i(U9),Nm=n(U9,"P",{});var Ece=s(Nm);iat=r(Ece,`Note:
Loading a model from its configuration file does `),c9e=n(Ece,"STRONG",{});var Lga=s(c9e);dat=r(Lga,"not"),Lga.forEach(t),cat=r(Ece,` load the model weights. It only affects the
model\u2019s configuration. Use `),dne=n(Ece,"A",{href:!0});var yga=s(dne);mat=r(yga,"from_pretrained()"),yga.forEach(t),fat=r(Ece," to load the model weights."),Ece.forEach(t),gat=i(U9),T(l6.$$.fragment,U9),U9.forEach(t),hat=i(ki),Jr=n(ki,"DIV",{class:!0});var Si=s(Jr);T(DR.$$.fragment,Si),uat=i(Si),m9e=n(Si,"P",{});var xga=s(m9e);pat=r(xga,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xga.forEach(t),_at=i(Si),On=n(Si,"P",{});var H9=s(On);bat=r(H9,"The model class to instantiate is selected based on the "),f9e=n(H9,"CODE",{});var $ga=s(f9e);vat=r($ga,"model_type"),$ga.forEach(t),Fat=r(H9,` property of the config object (either
passed as an argument or loaded from `),g9e=n(H9,"CODE",{});var kga=s(g9e);Tat=r(kga,"pretrained_model_name_or_path"),kga.forEach(t),Mat=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h9e=n(H9,"CODE",{});var Sga=s(h9e);Eat=r(Sga,"pretrained_model_name_or_path"),Sga.forEach(t),Cat=r(H9,":"),H9.forEach(t),wat=i(Si),ce=n(Si,"UL",{});var he=s(ce);i6=n(he,"LI",{});var kZe=s(i6);u9e=n(kZe,"STRONG",{});var Rga=s(u9e);Aat=r(Rga,"albert"),Rga.forEach(t),Lat=r(kZe," \u2014 "),cne=n(kZe,"A",{href:!0});var Pga=s(cne);yat=r(Pga,"TFAlbertForTokenClassification"),Pga.forEach(t),xat=r(kZe," (ALBERT model)"),kZe.forEach(t),$at=i(he),d6=n(he,"LI",{});var SZe=s(d6);p9e=n(SZe,"STRONG",{});var Bga=s(p9e);kat=r(Bga,"bert"),Bga.forEach(t),Sat=r(SZe," \u2014 "),mne=n(SZe,"A",{href:!0});var Iga=s(mne);Rat=r(Iga,"TFBertForTokenClassification"),Iga.forEach(t),Pat=r(SZe," (BERT model)"),SZe.forEach(t),Bat=i(he),c6=n(he,"LI",{});var RZe=s(c6);_9e=n(RZe,"STRONG",{});var Nga=s(_9e);Iat=r(Nga,"camembert"),Nga.forEach(t),Nat=r(RZe," \u2014 "),fne=n(RZe,"A",{href:!0});var qga=s(fne);qat=r(qga,"TFCamembertForTokenClassification"),qga.forEach(t),jat=r(RZe," (CamemBERT model)"),RZe.forEach(t),Dat=i(he),m6=n(he,"LI",{});var PZe=s(m6);b9e=n(PZe,"STRONG",{});var jga=s(b9e);Gat=r(jga,"convbert"),jga.forEach(t),Oat=r(PZe," \u2014 "),gne=n(PZe,"A",{href:!0});var Dga=s(gne);Vat=r(Dga,"TFConvBertForTokenClassification"),Dga.forEach(t),Xat=r(PZe," (ConvBERT model)"),PZe.forEach(t),zat=i(he),f6=n(he,"LI",{});var BZe=s(f6);v9e=n(BZe,"STRONG",{});var Gga=s(v9e);Qat=r(Gga,"deberta"),Gga.forEach(t),Wat=r(BZe," \u2014 "),hne=n(BZe,"A",{href:!0});var Oga=s(hne);Uat=r(Oga,"TFDebertaForTokenClassification"),Oga.forEach(t),Hat=r(BZe," (DeBERTa model)"),BZe.forEach(t),Jat=i(he),g6=n(he,"LI",{});var IZe=s(g6);F9e=n(IZe,"STRONG",{});var Vga=s(F9e);Yat=r(Vga,"deberta-v2"),Vga.forEach(t),Zat=r(IZe," \u2014 "),une=n(IZe,"A",{href:!0});var Xga=s(une);Kat=r(Xga,"TFDebertaV2ForTokenClassification"),Xga.forEach(t),ent=r(IZe," (DeBERTa-v2 model)"),IZe.forEach(t),ont=i(he),h6=n(he,"LI",{});var NZe=s(h6);T9e=n(NZe,"STRONG",{});var zga=s(T9e);rnt=r(zga,"distilbert"),zga.forEach(t),tnt=r(NZe," \u2014 "),pne=n(NZe,"A",{href:!0});var Qga=s(pne);ant=r(Qga,"TFDistilBertForTokenClassification"),Qga.forEach(t),nnt=r(NZe," (DistilBERT model)"),NZe.forEach(t),snt=i(he),u6=n(he,"LI",{});var qZe=s(u6);M9e=n(qZe,"STRONG",{});var Wga=s(M9e);lnt=r(Wga,"electra"),Wga.forEach(t),int=r(qZe," \u2014 "),_ne=n(qZe,"A",{href:!0});var Uga=s(_ne);dnt=r(Uga,"TFElectraForTokenClassification"),Uga.forEach(t),cnt=r(qZe," (ELECTRA model)"),qZe.forEach(t),mnt=i(he),p6=n(he,"LI",{});var jZe=s(p6);E9e=n(jZe,"STRONG",{});var Hga=s(E9e);fnt=r(Hga,"flaubert"),Hga.forEach(t),gnt=r(jZe," \u2014 "),bne=n(jZe,"A",{href:!0});var Jga=s(bne);hnt=r(Jga,"TFFlaubertForTokenClassification"),Jga.forEach(t),unt=r(jZe," (FlauBERT model)"),jZe.forEach(t),pnt=i(he),_6=n(he,"LI",{});var DZe=s(_6);C9e=n(DZe,"STRONG",{});var Yga=s(C9e);_nt=r(Yga,"funnel"),Yga.forEach(t),bnt=r(DZe," \u2014 "),vne=n(DZe,"A",{href:!0});var Zga=s(vne);vnt=r(Zga,"TFFunnelForTokenClassification"),Zga.forEach(t),Fnt=r(DZe," (Funnel Transformer model)"),DZe.forEach(t),Tnt=i(he),b6=n(he,"LI",{});var GZe=s(b6);w9e=n(GZe,"STRONG",{});var Kga=s(w9e);Mnt=r(Kga,"layoutlm"),Kga.forEach(t),Ent=r(GZe," \u2014 "),Fne=n(GZe,"A",{href:!0});var eha=s(Fne);Cnt=r(eha,"TFLayoutLMForTokenClassification"),eha.forEach(t),wnt=r(GZe," (LayoutLM model)"),GZe.forEach(t),Ant=i(he),v6=n(he,"LI",{});var OZe=s(v6);A9e=n(OZe,"STRONG",{});var oha=s(A9e);Lnt=r(oha,"layoutlmv3"),oha.forEach(t),ynt=r(OZe," \u2014 "),Tne=n(OZe,"A",{href:!0});var rha=s(Tne);xnt=r(rha,"TFLayoutLMv3ForTokenClassification"),rha.forEach(t),$nt=r(OZe," (LayoutLMv3 model)"),OZe.forEach(t),knt=i(he),F6=n(he,"LI",{});var VZe=s(F6);L9e=n(VZe,"STRONG",{});var tha=s(L9e);Snt=r(tha,"longformer"),tha.forEach(t),Rnt=r(VZe," \u2014 "),Mne=n(VZe,"A",{href:!0});var aha=s(Mne);Pnt=r(aha,"TFLongformerForTokenClassification"),aha.forEach(t),Bnt=r(VZe," (Longformer model)"),VZe.forEach(t),Int=i(he),T6=n(he,"LI",{});var XZe=s(T6);y9e=n(XZe,"STRONG",{});var nha=s(y9e);Nnt=r(nha,"mobilebert"),nha.forEach(t),qnt=r(XZe," \u2014 "),Ene=n(XZe,"A",{href:!0});var sha=s(Ene);jnt=r(sha,"TFMobileBertForTokenClassification"),sha.forEach(t),Dnt=r(XZe," (MobileBERT model)"),XZe.forEach(t),Gnt=i(he),M6=n(he,"LI",{});var zZe=s(M6);x9e=n(zZe,"STRONG",{});var lha=s(x9e);Ont=r(lha,"mpnet"),lha.forEach(t),Vnt=r(zZe," \u2014 "),Cne=n(zZe,"A",{href:!0});var iha=s(Cne);Xnt=r(iha,"TFMPNetForTokenClassification"),iha.forEach(t),znt=r(zZe," (MPNet model)"),zZe.forEach(t),Qnt=i(he),E6=n(he,"LI",{});var QZe=s(E6);$9e=n(QZe,"STRONG",{});var dha=s($9e);Wnt=r(dha,"rembert"),dha.forEach(t),Unt=r(QZe," \u2014 "),wne=n(QZe,"A",{href:!0});var cha=s(wne);Hnt=r(cha,"TFRemBertForTokenClassification"),cha.forEach(t),Jnt=r(QZe," (RemBERT model)"),QZe.forEach(t),Ynt=i(he),C6=n(he,"LI",{});var WZe=s(C6);k9e=n(WZe,"STRONG",{});var mha=s(k9e);Znt=r(mha,"roberta"),mha.forEach(t),Knt=r(WZe," \u2014 "),Ane=n(WZe,"A",{href:!0});var fha=s(Ane);est=r(fha,"TFRobertaForTokenClassification"),fha.forEach(t),ost=r(WZe," (RoBERTa model)"),WZe.forEach(t),rst=i(he),w6=n(he,"LI",{});var UZe=s(w6);S9e=n(UZe,"STRONG",{});var gha=s(S9e);tst=r(gha,"roformer"),gha.forEach(t),ast=r(UZe," \u2014 "),Lne=n(UZe,"A",{href:!0});var hha=s(Lne);nst=r(hha,"TFRoFormerForTokenClassification"),hha.forEach(t),sst=r(UZe," (RoFormer model)"),UZe.forEach(t),lst=i(he),A6=n(he,"LI",{});var HZe=s(A6);R9e=n(HZe,"STRONG",{});var uha=s(R9e);ist=r(uha,"xlm"),uha.forEach(t),dst=r(HZe," \u2014 "),yne=n(HZe,"A",{href:!0});var pha=s(yne);cst=r(pha,"TFXLMForTokenClassification"),pha.forEach(t),mst=r(HZe," (XLM model)"),HZe.forEach(t),fst=i(he),L6=n(he,"LI",{});var JZe=s(L6);P9e=n(JZe,"STRONG",{});var _ha=s(P9e);gst=r(_ha,"xlm-roberta"),_ha.forEach(t),hst=r(JZe," \u2014 "),xne=n(JZe,"A",{href:!0});var bha=s(xne);ust=r(bha,"TFXLMRobertaForTokenClassification"),bha.forEach(t),pst=r(JZe," (XLM-RoBERTa model)"),JZe.forEach(t),_st=i(he),y6=n(he,"LI",{});var YZe=s(y6);B9e=n(YZe,"STRONG",{});var vha=s(B9e);bst=r(vha,"xlnet"),vha.forEach(t),vst=r(YZe," \u2014 "),$ne=n(YZe,"A",{href:!0});var Fha=s($ne);Fst=r(Fha,"TFXLNetForTokenClassification"),Fha.forEach(t),Tst=r(YZe," (XLNet model)"),YZe.forEach(t),he.forEach(t),Mst=i(Si),T(x6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),dto=i(m),qm=n(m,"H2",{class:!0});var Ano=s(qm);$6=n(Ano,"A",{id:!0,class:!0,href:!0});var Tha=s($6);I9e=n(Tha,"SPAN",{});var Mha=s(I9e);T(GR.$$.fragment,Mha),Mha.forEach(t),Tha.forEach(t),Est=i(Ano),N9e=n(Ano,"SPAN",{});var Eha=s(N9e);Cst=r(Eha,"TFAutoModelForQuestionAnswering"),Eha.forEach(t),Ano.forEach(t),cto=i(m),Tr=n(m,"DIV",{class:!0});var Ri=s(Tr);T(OR.$$.fragment,Ri),wst=i(Ri),jm=n(Ri,"P",{});var Cce=s(jm);Ast=r(Cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),kne=n(Cce,"A",{href:!0});var Cha=s(kne);Lst=r(Cha,"from_pretrained()"),Cha.forEach(t),yst=r(Cce," class method or the "),Sne=n(Cce,"A",{href:!0});var wha=s(Sne);xst=r(wha,"from_config()"),wha.forEach(t),$st=r(Cce,` class
method.`),Cce.forEach(t),kst=i(Ri),VR=n(Ri,"P",{});var Lno=s(VR);Sst=r(Lno,"This class cannot be instantiated directly using "),q9e=n(Lno,"CODE",{});var Aha=s(q9e);Rst=r(Aha,"__init__()"),Aha.forEach(t),Pst=r(Lno," (throws an error)."),Lno.forEach(t),Bst=i(Ri),sa=n(Ri,"DIV",{class:!0});var J9=s(sa);T(XR.$$.fragment,J9),Ist=i(J9),j9e=n(J9,"P",{});var Lha=s(j9e);Nst=r(Lha,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Lha.forEach(t),qst=i(J9),Dm=n(J9,"P",{});var wce=s(Dm);jst=r(wce,`Note:
Loading a model from its configuration file does `),D9e=n(wce,"STRONG",{});var yha=s(D9e);Dst=r(yha,"not"),yha.forEach(t),Gst=r(wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rne=n(wce,"A",{href:!0});var xha=s(Rne);Ost=r(xha,"from_pretrained()"),xha.forEach(t),Vst=r(wce," to load the model weights."),wce.forEach(t),Xst=i(J9),T(k6.$$.fragment,J9),J9.forEach(t),zst=i(Ri),Yr=n(Ri,"DIV",{class:!0});var Pi=s(Yr);T(zR.$$.fragment,Pi),Qst=i(Pi),G9e=n(Pi,"P",{});var $ha=s(G9e);Wst=r($ha,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$ha.forEach(t),Ust=i(Pi),Vn=n(Pi,"P",{});var Y9=s(Vn);Hst=r(Y9,"The model class to instantiate is selected based on the "),O9e=n(Y9,"CODE",{});var kha=s(O9e);Jst=r(kha,"model_type"),kha.forEach(t),Yst=r(Y9,` property of the config object (either
passed as an argument or loaded from `),V9e=n(Y9,"CODE",{});var Sha=s(V9e);Zst=r(Sha,"pretrained_model_name_or_path"),Sha.forEach(t),Kst=r(Y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X9e=n(Y9,"CODE",{});var Rha=s(X9e);elt=r(Rha,"pretrained_model_name_or_path"),Rha.forEach(t),olt=r(Y9,":"),Y9.forEach(t),rlt=i(Pi),me=n(Pi,"UL",{});var ue=s(me);S6=n(ue,"LI",{});var ZZe=s(S6);z9e=n(ZZe,"STRONG",{});var Pha=s(z9e);tlt=r(Pha,"albert"),Pha.forEach(t),alt=r(ZZe," \u2014 "),Pne=n(ZZe,"A",{href:!0});var Bha=s(Pne);nlt=r(Bha,"TFAlbertForQuestionAnswering"),Bha.forEach(t),slt=r(ZZe," (ALBERT model)"),ZZe.forEach(t),llt=i(ue),R6=n(ue,"LI",{});var KZe=s(R6);Q9e=n(KZe,"STRONG",{});var Iha=s(Q9e);ilt=r(Iha,"bert"),Iha.forEach(t),dlt=r(KZe," \u2014 "),Bne=n(KZe,"A",{href:!0});var Nha=s(Bne);clt=r(Nha,"TFBertForQuestionAnswering"),Nha.forEach(t),mlt=r(KZe," (BERT model)"),KZe.forEach(t),flt=i(ue),P6=n(ue,"LI",{});var eKe=s(P6);W9e=n(eKe,"STRONG",{});var qha=s(W9e);glt=r(qha,"camembert"),qha.forEach(t),hlt=r(eKe," \u2014 "),Ine=n(eKe,"A",{href:!0});var jha=s(Ine);ult=r(jha,"TFCamembertForQuestionAnswering"),jha.forEach(t),plt=r(eKe," (CamemBERT model)"),eKe.forEach(t),_lt=i(ue),B6=n(ue,"LI",{});var oKe=s(B6);U9e=n(oKe,"STRONG",{});var Dha=s(U9e);blt=r(Dha,"convbert"),Dha.forEach(t),vlt=r(oKe," \u2014 "),Nne=n(oKe,"A",{href:!0});var Gha=s(Nne);Flt=r(Gha,"TFConvBertForQuestionAnswering"),Gha.forEach(t),Tlt=r(oKe," (ConvBERT model)"),oKe.forEach(t),Mlt=i(ue),I6=n(ue,"LI",{});var rKe=s(I6);H9e=n(rKe,"STRONG",{});var Oha=s(H9e);Elt=r(Oha,"deberta"),Oha.forEach(t),Clt=r(rKe," \u2014 "),qne=n(rKe,"A",{href:!0});var Vha=s(qne);wlt=r(Vha,"TFDebertaForQuestionAnswering"),Vha.forEach(t),Alt=r(rKe," (DeBERTa model)"),rKe.forEach(t),Llt=i(ue),N6=n(ue,"LI",{});var tKe=s(N6);J9e=n(tKe,"STRONG",{});var Xha=s(J9e);ylt=r(Xha,"deberta-v2"),Xha.forEach(t),xlt=r(tKe," \u2014 "),jne=n(tKe,"A",{href:!0});var zha=s(jne);$lt=r(zha,"TFDebertaV2ForQuestionAnswering"),zha.forEach(t),klt=r(tKe," (DeBERTa-v2 model)"),tKe.forEach(t),Slt=i(ue),q6=n(ue,"LI",{});var aKe=s(q6);Y9e=n(aKe,"STRONG",{});var Qha=s(Y9e);Rlt=r(Qha,"distilbert"),Qha.forEach(t),Plt=r(aKe," \u2014 "),Dne=n(aKe,"A",{href:!0});var Wha=s(Dne);Blt=r(Wha,"TFDistilBertForQuestionAnswering"),Wha.forEach(t),Ilt=r(aKe," (DistilBERT model)"),aKe.forEach(t),Nlt=i(ue),j6=n(ue,"LI",{});var nKe=s(j6);Z9e=n(nKe,"STRONG",{});var Uha=s(Z9e);qlt=r(Uha,"electra"),Uha.forEach(t),jlt=r(nKe," \u2014 "),Gne=n(nKe,"A",{href:!0});var Hha=s(Gne);Dlt=r(Hha,"TFElectraForQuestionAnswering"),Hha.forEach(t),Glt=r(nKe," (ELECTRA model)"),nKe.forEach(t),Olt=i(ue),D6=n(ue,"LI",{});var sKe=s(D6);K9e=n(sKe,"STRONG",{});var Jha=s(K9e);Vlt=r(Jha,"flaubert"),Jha.forEach(t),Xlt=r(sKe," \u2014 "),One=n(sKe,"A",{href:!0});var Yha=s(One);zlt=r(Yha,"TFFlaubertForQuestionAnsweringSimple"),Yha.forEach(t),Qlt=r(sKe," (FlauBERT model)"),sKe.forEach(t),Wlt=i(ue),G6=n(ue,"LI",{});var lKe=s(G6);exe=n(lKe,"STRONG",{});var Zha=s(exe);Ult=r(Zha,"funnel"),Zha.forEach(t),Hlt=r(lKe," \u2014 "),Vne=n(lKe,"A",{href:!0});var Kha=s(Vne);Jlt=r(Kha,"TFFunnelForQuestionAnswering"),Kha.forEach(t),Ylt=r(lKe," (Funnel Transformer model)"),lKe.forEach(t),Zlt=i(ue),O6=n(ue,"LI",{});var iKe=s(O6);oxe=n(iKe,"STRONG",{});var eua=s(oxe);Klt=r(eua,"gptj"),eua.forEach(t),eit=r(iKe," \u2014 "),Xne=n(iKe,"A",{href:!0});var oua=s(Xne);oit=r(oua,"TFGPTJForQuestionAnswering"),oua.forEach(t),rit=r(iKe," (GPT-J model)"),iKe.forEach(t),tit=i(ue),V6=n(ue,"LI",{});var dKe=s(V6);rxe=n(dKe,"STRONG",{});var rua=s(rxe);ait=r(rua,"layoutlmv3"),rua.forEach(t),nit=r(dKe," \u2014 "),zne=n(dKe,"A",{href:!0});var tua=s(zne);sit=r(tua,"TFLayoutLMv3ForQuestionAnswering"),tua.forEach(t),lit=r(dKe," (LayoutLMv3 model)"),dKe.forEach(t),iit=i(ue),X6=n(ue,"LI",{});var cKe=s(X6);txe=n(cKe,"STRONG",{});var aua=s(txe);dit=r(aua,"longformer"),aua.forEach(t),cit=r(cKe," \u2014 "),Qne=n(cKe,"A",{href:!0});var nua=s(Qne);mit=r(nua,"TFLongformerForQuestionAnswering"),nua.forEach(t),fit=r(cKe," (Longformer model)"),cKe.forEach(t),git=i(ue),z6=n(ue,"LI",{});var mKe=s(z6);axe=n(mKe,"STRONG",{});var sua=s(axe);hit=r(sua,"mobilebert"),sua.forEach(t),uit=r(mKe," \u2014 "),Wne=n(mKe,"A",{href:!0});var lua=s(Wne);pit=r(lua,"TFMobileBertForQuestionAnswering"),lua.forEach(t),_it=r(mKe," (MobileBERT model)"),mKe.forEach(t),bit=i(ue),Q6=n(ue,"LI",{});var fKe=s(Q6);nxe=n(fKe,"STRONG",{});var iua=s(nxe);vit=r(iua,"mpnet"),iua.forEach(t),Fit=r(fKe," \u2014 "),Une=n(fKe,"A",{href:!0});var dua=s(Une);Tit=r(dua,"TFMPNetForQuestionAnswering"),dua.forEach(t),Mit=r(fKe," (MPNet model)"),fKe.forEach(t),Eit=i(ue),W6=n(ue,"LI",{});var gKe=s(W6);sxe=n(gKe,"STRONG",{});var cua=s(sxe);Cit=r(cua,"rembert"),cua.forEach(t),wit=r(gKe," \u2014 "),Hne=n(gKe,"A",{href:!0});var mua=s(Hne);Ait=r(mua,"TFRemBertForQuestionAnswering"),mua.forEach(t),Lit=r(gKe," (RemBERT model)"),gKe.forEach(t),yit=i(ue),U6=n(ue,"LI",{});var hKe=s(U6);lxe=n(hKe,"STRONG",{});var fua=s(lxe);xit=r(fua,"roberta"),fua.forEach(t),$it=r(hKe," \u2014 "),Jne=n(hKe,"A",{href:!0});var gua=s(Jne);kit=r(gua,"TFRobertaForQuestionAnswering"),gua.forEach(t),Sit=r(hKe," (RoBERTa model)"),hKe.forEach(t),Rit=i(ue),H6=n(ue,"LI",{});var uKe=s(H6);ixe=n(uKe,"STRONG",{});var hua=s(ixe);Pit=r(hua,"roformer"),hua.forEach(t),Bit=r(uKe," \u2014 "),Yne=n(uKe,"A",{href:!0});var uua=s(Yne);Iit=r(uua,"TFRoFormerForQuestionAnswering"),uua.forEach(t),Nit=r(uKe," (RoFormer model)"),uKe.forEach(t),qit=i(ue),J6=n(ue,"LI",{});var pKe=s(J6);dxe=n(pKe,"STRONG",{});var pua=s(dxe);jit=r(pua,"xlm"),pua.forEach(t),Dit=r(pKe," \u2014 "),Zne=n(pKe,"A",{href:!0});var _ua=s(Zne);Git=r(_ua,"TFXLMForQuestionAnsweringSimple"),_ua.forEach(t),Oit=r(pKe," (XLM model)"),pKe.forEach(t),Vit=i(ue),Y6=n(ue,"LI",{});var _Ke=s(Y6);cxe=n(_Ke,"STRONG",{});var bua=s(cxe);Xit=r(bua,"xlm-roberta"),bua.forEach(t),zit=r(_Ke," \u2014 "),Kne=n(_Ke,"A",{href:!0});var vua=s(Kne);Qit=r(vua,"TFXLMRobertaForQuestionAnswering"),vua.forEach(t),Wit=r(_Ke," (XLM-RoBERTa model)"),_Ke.forEach(t),Uit=i(ue),Z6=n(ue,"LI",{});var bKe=s(Z6);mxe=n(bKe,"STRONG",{});var Fua=s(mxe);Hit=r(Fua,"xlnet"),Fua.forEach(t),Jit=r(bKe," \u2014 "),ese=n(bKe,"A",{href:!0});var Tua=s(ese);Yit=r(Tua,"TFXLNetForQuestionAnsweringSimple"),Tua.forEach(t),Zit=r(bKe," (XLNet model)"),bKe.forEach(t),ue.forEach(t),Kit=i(Pi),T(K6.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),mto=i(m),Gm=n(m,"H2",{class:!0});var yno=s(Gm);e7=n(yno,"A",{id:!0,class:!0,href:!0});var Mua=s(e7);fxe=n(Mua,"SPAN",{});var Eua=s(fxe);T(QR.$$.fragment,Eua),Eua.forEach(t),Mua.forEach(t),edt=i(yno),gxe=n(yno,"SPAN",{});var Cua=s(gxe);odt=r(Cua,"TFAutoModelForVision2Seq"),Cua.forEach(t),yno.forEach(t),fto=i(m),Mr=n(m,"DIV",{class:!0});var Bi=s(Mr);T(WR.$$.fragment,Bi),rdt=i(Bi),Om=n(Bi,"P",{});var Ace=s(Om);tdt=r(Ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ose=n(Ace,"A",{href:!0});var wua=s(ose);adt=r(wua,"from_pretrained()"),wua.forEach(t),ndt=r(Ace," class method or the "),rse=n(Ace,"A",{href:!0});var Aua=s(rse);sdt=r(Aua,"from_config()"),Aua.forEach(t),ldt=r(Ace,` class
method.`),Ace.forEach(t),idt=i(Bi),UR=n(Bi,"P",{});var xno=s(UR);ddt=r(xno,"This class cannot be instantiated directly using "),hxe=n(xno,"CODE",{});var Lua=s(hxe);cdt=r(Lua,"__init__()"),Lua.forEach(t),mdt=r(xno," (throws an error)."),xno.forEach(t),fdt=i(Bi),la=n(Bi,"DIV",{class:!0});var Z9=s(la);T(HR.$$.fragment,Z9),gdt=i(Z9),uxe=n(Z9,"P",{});var yua=s(uxe);hdt=r(yua,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yua.forEach(t),udt=i(Z9),Vm=n(Z9,"P",{});var Lce=s(Vm);pdt=r(Lce,`Note:
Loading a model from its configuration file does `),pxe=n(Lce,"STRONG",{});var xua=s(pxe);_dt=r(xua,"not"),xua.forEach(t),bdt=r(Lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),tse=n(Lce,"A",{href:!0});var $ua=s(tse);vdt=r($ua,"from_pretrained()"),$ua.forEach(t),Fdt=r(Lce," to load the model weights."),Lce.forEach(t),Tdt=i(Z9),T(o7.$$.fragment,Z9),Z9.forEach(t),Mdt=i(Bi),Zr=n(Bi,"DIV",{class:!0});var Ii=s(Zr);T(JR.$$.fragment,Ii),Edt=i(Ii),_xe=n(Ii,"P",{});var kua=s(_xe);Cdt=r(kua,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kua.forEach(t),wdt=i(Ii),Xn=n(Ii,"P",{});var K9=s(Xn);Adt=r(K9,"The model class to instantiate is selected based on the "),bxe=n(K9,"CODE",{});var Sua=s(bxe);Ldt=r(Sua,"model_type"),Sua.forEach(t),ydt=r(K9,` property of the config object (either
passed as an argument or loaded from `),vxe=n(K9,"CODE",{});var Rua=s(vxe);xdt=r(Rua,"pretrained_model_name_or_path"),Rua.forEach(t),$dt=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fxe=n(K9,"CODE",{});var Pua=s(Fxe);kdt=r(Pua,"pretrained_model_name_or_path"),Pua.forEach(t),Sdt=r(K9,":"),K9.forEach(t),Rdt=i(Ii),Txe=n(Ii,"UL",{});var Bua=s(Txe);r7=n(Bua,"LI",{});var vKe=s(r7);Mxe=n(vKe,"STRONG",{});var Iua=s(Mxe);Pdt=r(Iua,"vision-encoder-decoder"),Iua.forEach(t),Bdt=r(vKe," \u2014 "),ase=n(vKe,"A",{href:!0});var Nua=s(ase);Idt=r(Nua,"TFVisionEncoderDecoderModel"),Nua.forEach(t),Ndt=r(vKe," (Vision Encoder decoder model)"),vKe.forEach(t),Bua.forEach(t),qdt=i(Ii),T(t7.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),gto=i(m),Xm=n(m,"H2",{class:!0});var $no=s(Xm);a7=n($no,"A",{id:!0,class:!0,href:!0});var qua=s(a7);Exe=n(qua,"SPAN",{});var jua=s(Exe);T(YR.$$.fragment,jua),jua.forEach(t),qua.forEach(t),jdt=i($no),Cxe=n($no,"SPAN",{});var Dua=s(Cxe);Ddt=r(Dua,"TFAutoModelForSpeechSeq2Seq"),Dua.forEach(t),$no.forEach(t),hto=i(m),Er=n(m,"DIV",{class:!0});var Ni=s(Er);T(ZR.$$.fragment,Ni),Gdt=i(Ni),zm=n(Ni,"P",{});var yce=s(zm);Odt=r(yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),nse=n(yce,"A",{href:!0});var Gua=s(nse);Vdt=r(Gua,"from_pretrained()"),Gua.forEach(t),Xdt=r(yce," class method or the "),sse=n(yce,"A",{href:!0});var Oua=s(sse);zdt=r(Oua,"from_config()"),Oua.forEach(t),Qdt=r(yce,` class
method.`),yce.forEach(t),Wdt=i(Ni),KR=n(Ni,"P",{});var kno=s(KR);Udt=r(kno,"This class cannot be instantiated directly using "),wxe=n(kno,"CODE",{});var Vua=s(wxe);Hdt=r(Vua,"__init__()"),Vua.forEach(t),Jdt=r(kno," (throws an error)."),kno.forEach(t),Ydt=i(Ni),ia=n(Ni,"DIV",{class:!0});var ex=s(ia);T(eP.$$.fragment,ex),Zdt=i(ex),Axe=n(ex,"P",{});var Xua=s(Axe);Kdt=r(Xua,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Xua.forEach(t),ect=i(ex),Qm=n(ex,"P",{});var xce=s(Qm);oct=r(xce,`Note:
Loading a model from its configuration file does `),Lxe=n(xce,"STRONG",{});var zua=s(Lxe);rct=r(zua,"not"),zua.forEach(t),tct=r(xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=n(xce,"A",{href:!0});var Qua=s(lse);act=r(Qua,"from_pretrained()"),Qua.forEach(t),nct=r(xce," to load the model weights."),xce.forEach(t),sct=i(ex),T(n7.$$.fragment,ex),ex.forEach(t),lct=i(Ni),Kr=n(Ni,"DIV",{class:!0});var qi=s(Kr);T(oP.$$.fragment,qi),ict=i(qi),yxe=n(qi,"P",{});var Wua=s(yxe);dct=r(Wua,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Wua.forEach(t),cct=i(qi),zn=n(qi,"P",{});var ox=s(zn);mct=r(ox,"The model class to instantiate is selected based on the "),xxe=n(ox,"CODE",{});var Uua=s(xxe);fct=r(Uua,"model_type"),Uua.forEach(t),gct=r(ox,` property of the config object (either
passed as an argument or loaded from `),$xe=n(ox,"CODE",{});var Hua=s($xe);hct=r(Hua,"pretrained_model_name_or_path"),Hua.forEach(t),uct=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kxe=n(ox,"CODE",{});var Jua=s(kxe);pct=r(Jua,"pretrained_model_name_or_path"),Jua.forEach(t),_ct=r(ox,":"),ox.forEach(t),bct=i(qi),rP=n(qi,"UL",{});var Sno=s(rP);s7=n(Sno,"LI",{});var FKe=s(s7);Sxe=n(FKe,"STRONG",{});var Yua=s(Sxe);vct=r(Yua,"speech_to_text"),Yua.forEach(t),Fct=r(FKe," \u2014 "),ise=n(FKe,"A",{href:!0});var Zua=s(ise);Tct=r(Zua,"TFSpeech2TextForConditionalGeneration"),Zua.forEach(t),Mct=r(FKe," (Speech2Text model)"),FKe.forEach(t),Ect=i(Sno),l7=n(Sno,"LI",{});var TKe=s(l7);Rxe=n(TKe,"STRONG",{});var Kua=s(Rxe);Cct=r(Kua,"whisper"),Kua.forEach(t),wct=r(TKe," \u2014 "),dse=n(TKe,"A",{href:!0});var epa=s(dse);Act=r(epa,"TFWhisperForConditionalGeneration"),epa.forEach(t),Lct=r(TKe," (Whisper model)"),TKe.forEach(t),Sno.forEach(t),yct=i(qi),T(i7.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),uto=i(m),Wm=n(m,"H2",{class:!0});var Rno=s(Wm);d7=n(Rno,"A",{id:!0,class:!0,href:!0});var opa=s(d7);Pxe=n(opa,"SPAN",{});var rpa=s(Pxe);T(tP.$$.fragment,rpa),rpa.forEach(t),opa.forEach(t),xct=i(Rno),Bxe=n(Rno,"SPAN",{});var tpa=s(Bxe);$ct=r(tpa,"FlaxAutoModel"),tpa.forEach(t),Rno.forEach(t),pto=i(m),Cr=n(m,"DIV",{class:!0});var ji=s(Cr);T(aP.$$.fragment,ji),kct=i(ji),Um=n(ji,"P",{});var $ce=s(Um);Sct=r($ce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),cse=n($ce,"A",{href:!0});var apa=s(cse);Rct=r(apa,"from_pretrained()"),apa.forEach(t),Pct=r($ce," class method or the "),mse=n($ce,"A",{href:!0});var npa=s(mse);Bct=r(npa,"from_config()"),npa.forEach(t),Ict=r($ce,` class
method.`),$ce.forEach(t),Nct=i(ji),nP=n(ji,"P",{});var Pno=s(nP);qct=r(Pno,"This class cannot be instantiated directly using "),Ixe=n(Pno,"CODE",{});var spa=s(Ixe);jct=r(spa,"__init__()"),spa.forEach(t),Dct=r(Pno," (throws an error)."),Pno.forEach(t),Gct=i(ji),da=n(ji,"DIV",{class:!0});var rx=s(da);T(sP.$$.fragment,rx),Oct=i(rx),Nxe=n(rx,"P",{});var lpa=s(Nxe);Vct=r(lpa,"Instantiates one of the base model classes of the library from a configuration."),lpa.forEach(t),Xct=i(rx),Hm=n(rx,"P",{});var kce=s(Hm);zct=r(kce,`Note:
Loading a model from its configuration file does `),qxe=n(kce,"STRONG",{});var ipa=s(qxe);Qct=r(ipa,"not"),ipa.forEach(t),Wct=r(kce,` load the model weights. It only affects the
model\u2019s configuration. Use `),fse=n(kce,"A",{href:!0});var dpa=s(fse);Uct=r(dpa,"from_pretrained()"),dpa.forEach(t),Hct=r(kce," to load the model weights."),kce.forEach(t),Jct=i(rx),T(c7.$$.fragment,rx),rx.forEach(t),Yct=i(ji),et=n(ji,"DIV",{class:!0});var Di=s(et);T(lP.$$.fragment,Di),Zct=i(Di),jxe=n(Di,"P",{});var cpa=s(jxe);Kct=r(cpa,"Instantiate one of the base model classes of the library from a pretrained model."),cpa.forEach(t),emt=i(Di),Qn=n(Di,"P",{});var tx=s(Qn);omt=r(tx,"The model class to instantiate is selected based on the "),Dxe=n(tx,"CODE",{});var mpa=s(Dxe);rmt=r(mpa,"model_type"),mpa.forEach(t),tmt=r(tx,` property of the config object (either
passed as an argument or loaded from `),Gxe=n(tx,"CODE",{});var fpa=s(Gxe);amt=r(fpa,"pretrained_model_name_or_path"),fpa.forEach(t),nmt=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=n(tx,"CODE",{});var gpa=s(Oxe);smt=r(gpa,"pretrained_model_name_or_path"),gpa.forEach(t),lmt=r(tx,":"),tx.forEach(t),imt=i(Di),te=n(Di,"UL",{});var ne=s(te);m7=n(ne,"LI",{});var MKe=s(m7);Vxe=n(MKe,"STRONG",{});var hpa=s(Vxe);dmt=r(hpa,"albert"),hpa.forEach(t),cmt=r(MKe," \u2014 "),gse=n(MKe,"A",{href:!0});var upa=s(gse);mmt=r(upa,"FlaxAlbertModel"),upa.forEach(t),fmt=r(MKe," (ALBERT model)"),MKe.forEach(t),gmt=i(ne),f7=n(ne,"LI",{});var EKe=s(f7);Xxe=n(EKe,"STRONG",{});var ppa=s(Xxe);hmt=r(ppa,"bart"),ppa.forEach(t),umt=r(EKe," \u2014 "),hse=n(EKe,"A",{href:!0});var _pa=s(hse);pmt=r(_pa,"FlaxBartModel"),_pa.forEach(t),_mt=r(EKe," (BART model)"),EKe.forEach(t),bmt=i(ne),g7=n(ne,"LI",{});var CKe=s(g7);zxe=n(CKe,"STRONG",{});var bpa=s(zxe);vmt=r(bpa,"beit"),bpa.forEach(t),Fmt=r(CKe," \u2014 "),use=n(CKe,"A",{href:!0});var vpa=s(use);Tmt=r(vpa,"FlaxBeitModel"),vpa.forEach(t),Mmt=r(CKe," (BEiT model)"),CKe.forEach(t),Emt=i(ne),h7=n(ne,"LI",{});var wKe=s(h7);Qxe=n(wKe,"STRONG",{});var Fpa=s(Qxe);Cmt=r(Fpa,"bert"),Fpa.forEach(t),wmt=r(wKe," \u2014 "),pse=n(wKe,"A",{href:!0});var Tpa=s(pse);Amt=r(Tpa,"FlaxBertModel"),Tpa.forEach(t),Lmt=r(wKe," (BERT model)"),wKe.forEach(t),ymt=i(ne),u7=n(ne,"LI",{});var AKe=s(u7);Wxe=n(AKe,"STRONG",{});var Mpa=s(Wxe);xmt=r(Mpa,"big_bird"),Mpa.forEach(t),$mt=r(AKe," \u2014 "),_se=n(AKe,"A",{href:!0});var Epa=s(_se);kmt=r(Epa,"FlaxBigBirdModel"),Epa.forEach(t),Smt=r(AKe," (BigBird model)"),AKe.forEach(t),Rmt=i(ne),p7=n(ne,"LI",{});var LKe=s(p7);Uxe=n(LKe,"STRONG",{});var Cpa=s(Uxe);Pmt=r(Cpa,"blenderbot"),Cpa.forEach(t),Bmt=r(LKe," \u2014 "),bse=n(LKe,"A",{href:!0});var wpa=s(bse);Imt=r(wpa,"FlaxBlenderbotModel"),wpa.forEach(t),Nmt=r(LKe," (Blenderbot model)"),LKe.forEach(t),qmt=i(ne),_7=n(ne,"LI",{});var yKe=s(_7);Hxe=n(yKe,"STRONG",{});var Apa=s(Hxe);jmt=r(Apa,"blenderbot-small"),Apa.forEach(t),Dmt=r(yKe," \u2014 "),vse=n(yKe,"A",{href:!0});var Lpa=s(vse);Gmt=r(Lpa,"FlaxBlenderbotSmallModel"),Lpa.forEach(t),Omt=r(yKe," (BlenderbotSmall model)"),yKe.forEach(t),Vmt=i(ne),b7=n(ne,"LI",{});var xKe=s(b7);Jxe=n(xKe,"STRONG",{});var ypa=s(Jxe);Xmt=r(ypa,"clip"),ypa.forEach(t),zmt=r(xKe," \u2014 "),Fse=n(xKe,"A",{href:!0});var xpa=s(Fse);Qmt=r(xpa,"FlaxCLIPModel"),xpa.forEach(t),Wmt=r(xKe," (CLIP model)"),xKe.forEach(t),Umt=i(ne),v7=n(ne,"LI",{});var $Ke=s(v7);Yxe=n($Ke,"STRONG",{});var $pa=s(Yxe);Hmt=r($pa,"distilbert"),$pa.forEach(t),Jmt=r($Ke," \u2014 "),Tse=n($Ke,"A",{href:!0});var kpa=s(Tse);Ymt=r(kpa,"FlaxDistilBertModel"),kpa.forEach(t),Zmt=r($Ke," (DistilBERT model)"),$Ke.forEach(t),Kmt=i(ne),F7=n(ne,"LI",{});var kKe=s(F7);Zxe=n(kKe,"STRONG",{});var Spa=s(Zxe);eft=r(Spa,"electra"),Spa.forEach(t),oft=r(kKe," \u2014 "),Mse=n(kKe,"A",{href:!0});var Rpa=s(Mse);rft=r(Rpa,"FlaxElectraModel"),Rpa.forEach(t),tft=r(kKe," (ELECTRA model)"),kKe.forEach(t),aft=i(ne),T7=n(ne,"LI",{});var SKe=s(T7);Kxe=n(SKe,"STRONG",{});var Ppa=s(Kxe);nft=r(Ppa,"gpt2"),Ppa.forEach(t),sft=r(SKe," \u2014 "),Ese=n(SKe,"A",{href:!0});var Bpa=s(Ese);lft=r(Bpa,"FlaxGPT2Model"),Bpa.forEach(t),ift=r(SKe," (OpenAI GPT-2 model)"),SKe.forEach(t),dft=i(ne),M7=n(ne,"LI",{});var RKe=s(M7);e$e=n(RKe,"STRONG",{});var Ipa=s(e$e);cft=r(Ipa,"gpt_neo"),Ipa.forEach(t),mft=r(RKe," \u2014 "),Cse=n(RKe,"A",{href:!0});var Npa=s(Cse);fft=r(Npa,"FlaxGPTNeoModel"),Npa.forEach(t),gft=r(RKe," (GPT Neo model)"),RKe.forEach(t),hft=i(ne),E7=n(ne,"LI",{});var PKe=s(E7);o$e=n(PKe,"STRONG",{});var qpa=s(o$e);uft=r(qpa,"gptj"),qpa.forEach(t),pft=r(PKe," \u2014 "),wse=n(PKe,"A",{href:!0});var jpa=s(wse);_ft=r(jpa,"FlaxGPTJModel"),jpa.forEach(t),bft=r(PKe," (GPT-J model)"),PKe.forEach(t),vft=i(ne),C7=n(ne,"LI",{});var BKe=s(C7);r$e=n(BKe,"STRONG",{});var Dpa=s(r$e);Fft=r(Dpa,"longt5"),Dpa.forEach(t),Tft=r(BKe," \u2014 "),Ase=n(BKe,"A",{href:!0});var Gpa=s(Ase);Mft=r(Gpa,"FlaxLongT5Model"),Gpa.forEach(t),Eft=r(BKe," (LongT5 model)"),BKe.forEach(t),Cft=i(ne),w7=n(ne,"LI",{});var IKe=s(w7);t$e=n(IKe,"STRONG",{});var Opa=s(t$e);wft=r(Opa,"marian"),Opa.forEach(t),Aft=r(IKe," \u2014 "),Lse=n(IKe,"A",{href:!0});var Vpa=s(Lse);Lft=r(Vpa,"FlaxMarianModel"),Vpa.forEach(t),yft=r(IKe," (Marian model)"),IKe.forEach(t),xft=i(ne),A7=n(ne,"LI",{});var NKe=s(A7);a$e=n(NKe,"STRONG",{});var Xpa=s(a$e);$ft=r(Xpa,"mbart"),Xpa.forEach(t),kft=r(NKe," \u2014 "),yse=n(NKe,"A",{href:!0});var zpa=s(yse);Sft=r(zpa,"FlaxMBartModel"),zpa.forEach(t),Rft=r(NKe," (mBART model)"),NKe.forEach(t),Pft=i(ne),L7=n(ne,"LI",{});var qKe=s(L7);n$e=n(qKe,"STRONG",{});var Qpa=s(n$e);Bft=r(Qpa,"mt5"),Qpa.forEach(t),Ift=r(qKe," \u2014 "),xse=n(qKe,"A",{href:!0});var Wpa=s(xse);Nft=r(Wpa,"FlaxMT5Model"),Wpa.forEach(t),qft=r(qKe," (MT5 model)"),qKe.forEach(t),jft=i(ne),y7=n(ne,"LI",{});var jKe=s(y7);s$e=n(jKe,"STRONG",{});var Upa=s(s$e);Dft=r(Upa,"opt"),Upa.forEach(t),Gft=r(jKe," \u2014 "),$se=n(jKe,"A",{href:!0});var Hpa=s($se);Oft=r(Hpa,"FlaxOPTModel"),Hpa.forEach(t),Vft=r(jKe," (OPT model)"),jKe.forEach(t),Xft=i(ne),x7=n(ne,"LI",{});var DKe=s(x7);l$e=n(DKe,"STRONG",{});var Jpa=s(l$e);zft=r(Jpa,"pegasus"),Jpa.forEach(t),Qft=r(DKe," \u2014 "),kse=n(DKe,"A",{href:!0});var Ypa=s(kse);Wft=r(Ypa,"FlaxPegasusModel"),Ypa.forEach(t),Uft=r(DKe," (Pegasus model)"),DKe.forEach(t),Hft=i(ne),$7=n(ne,"LI",{});var GKe=s($7);i$e=n(GKe,"STRONG",{});var Zpa=s(i$e);Jft=r(Zpa,"roberta"),Zpa.forEach(t),Yft=r(GKe," \u2014 "),Sse=n(GKe,"A",{href:!0});var Kpa=s(Sse);Zft=r(Kpa,"FlaxRobertaModel"),Kpa.forEach(t),Kft=r(GKe," (RoBERTa model)"),GKe.forEach(t),egt=i(ne),k7=n(ne,"LI",{});var OKe=s(k7);d$e=n(OKe,"STRONG",{});var e_a=s(d$e);ogt=r(e_a,"roformer"),e_a.forEach(t),rgt=r(OKe," \u2014 "),Rse=n(OKe,"A",{href:!0});var o_a=s(Rse);tgt=r(o_a,"FlaxRoFormerModel"),o_a.forEach(t),agt=r(OKe," (RoFormer model)"),OKe.forEach(t),ngt=i(ne),S7=n(ne,"LI",{});var VKe=s(S7);c$e=n(VKe,"STRONG",{});var r_a=s(c$e);sgt=r(r_a,"t5"),r_a.forEach(t),lgt=r(VKe," \u2014 "),Pse=n(VKe,"A",{href:!0});var t_a=s(Pse);igt=r(t_a,"FlaxT5Model"),t_a.forEach(t),dgt=r(VKe," (T5 model)"),VKe.forEach(t),cgt=i(ne),R7=n(ne,"LI",{});var XKe=s(R7);m$e=n(XKe,"STRONG",{});var a_a=s(m$e);mgt=r(a_a,"vision-text-dual-encoder"),a_a.forEach(t),fgt=r(XKe," \u2014 "),Bse=n(XKe,"A",{href:!0});var n_a=s(Bse);ggt=r(n_a,"FlaxVisionTextDualEncoderModel"),n_a.forEach(t),hgt=r(XKe," (VisionTextDualEncoder model)"),XKe.forEach(t),ugt=i(ne),P7=n(ne,"LI",{});var zKe=s(P7);f$e=n(zKe,"STRONG",{});var s_a=s(f$e);pgt=r(s_a,"vit"),s_a.forEach(t),_gt=r(zKe," \u2014 "),Ise=n(zKe,"A",{href:!0});var l_a=s(Ise);bgt=r(l_a,"FlaxViTModel"),l_a.forEach(t),vgt=r(zKe," (ViT model)"),zKe.forEach(t),Fgt=i(ne),B7=n(ne,"LI",{});var QKe=s(B7);g$e=n(QKe,"STRONG",{});var i_a=s(g$e);Tgt=r(i_a,"wav2vec2"),i_a.forEach(t),Mgt=r(QKe," \u2014 "),Nse=n(QKe,"A",{href:!0});var d_a=s(Nse);Egt=r(d_a,"FlaxWav2Vec2Model"),d_a.forEach(t),Cgt=r(QKe," (Wav2Vec2 model)"),QKe.forEach(t),wgt=i(ne),I7=n(ne,"LI",{});var WKe=s(I7);h$e=n(WKe,"STRONG",{});var c_a=s(h$e);Agt=r(c_a,"xglm"),c_a.forEach(t),Lgt=r(WKe," \u2014 "),qse=n(WKe,"A",{href:!0});var m_a=s(qse);ygt=r(m_a,"FlaxXGLMModel"),m_a.forEach(t),xgt=r(WKe," (XGLM model)"),WKe.forEach(t),$gt=i(ne),N7=n(ne,"LI",{});var UKe=s(N7);u$e=n(UKe,"STRONG",{});var f_a=s(u$e);kgt=r(f_a,"xlm-roberta"),f_a.forEach(t),Sgt=r(UKe," \u2014 "),jse=n(UKe,"A",{href:!0});var g_a=s(jse);Rgt=r(g_a,"FlaxXLMRobertaModel"),g_a.forEach(t),Pgt=r(UKe," (XLM-RoBERTa model)"),UKe.forEach(t),ne.forEach(t),Bgt=i(Di),T(q7.$$.fragment,Di),Di.forEach(t),ji.forEach(t),_to=i(m),Jm=n(m,"H2",{class:!0});var Bno=s(Jm);j7=n(Bno,"A",{id:!0,class:!0,href:!0});var h_a=s(j7);p$e=n(h_a,"SPAN",{});var u_a=s(p$e);T(iP.$$.fragment,u_a),u_a.forEach(t),h_a.forEach(t),Igt=i(Bno),_$e=n(Bno,"SPAN",{});var p_a=s(_$e);Ngt=r(p_a,"FlaxAutoModelForCausalLM"),p_a.forEach(t),Bno.forEach(t),bto=i(m),wr=n(m,"DIV",{class:!0});var Gi=s(wr);T(dP.$$.fragment,Gi),qgt=i(Gi),Ym=n(Gi,"P",{});var Sce=s(Ym);jgt=r(Sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Dse=n(Sce,"A",{href:!0});var __a=s(Dse);Dgt=r(__a,"from_pretrained()"),__a.forEach(t),Ggt=r(Sce," class method or the "),Gse=n(Sce,"A",{href:!0});var b_a=s(Gse);Ogt=r(b_a,"from_config()"),b_a.forEach(t),Vgt=r(Sce,` class
method.`),Sce.forEach(t),Xgt=i(Gi),cP=n(Gi,"P",{});var Ino=s(cP);zgt=r(Ino,"This class cannot be instantiated directly using "),b$e=n(Ino,"CODE",{});var v_a=s(b$e);Qgt=r(v_a,"__init__()"),v_a.forEach(t),Wgt=r(Ino," (throws an error)."),Ino.forEach(t),Ugt=i(Gi),ca=n(Gi,"DIV",{class:!0});var ax=s(ca);T(mP.$$.fragment,ax),Hgt=i(ax),v$e=n(ax,"P",{});var F_a=s(v$e);Jgt=r(F_a,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),F_a.forEach(t),Ygt=i(ax),Zm=n(ax,"P",{});var Rce=s(Zm);Zgt=r(Rce,`Note:
Loading a model from its configuration file does `),F$e=n(Rce,"STRONG",{});var T_a=s(F$e);Kgt=r(T_a,"not"),T_a.forEach(t),eht=r(Rce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ose=n(Rce,"A",{href:!0});var M_a=s(Ose);oht=r(M_a,"from_pretrained()"),M_a.forEach(t),rht=r(Rce," to load the model weights."),Rce.forEach(t),tht=i(ax),T(D7.$$.fragment,ax),ax.forEach(t),aht=i(Gi),ot=n(Gi,"DIV",{class:!0});var Oi=s(ot);T(fP.$$.fragment,Oi),nht=i(Oi),T$e=n(Oi,"P",{});var E_a=s(T$e);sht=r(E_a,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),E_a.forEach(t),lht=i(Oi),Wn=n(Oi,"P",{});var nx=s(Wn);iht=r(nx,"The model class to instantiate is selected based on the "),M$e=n(nx,"CODE",{});var C_a=s(M$e);dht=r(C_a,"model_type"),C_a.forEach(t),cht=r(nx,` property of the config object (either
passed as an argument or loaded from `),E$e=n(nx,"CODE",{});var w_a=s(E$e);mht=r(w_a,"pretrained_model_name_or_path"),w_a.forEach(t),fht=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C$e=n(nx,"CODE",{});var A_a=s(C$e);ght=r(A_a,"pretrained_model_name_or_path"),A_a.forEach(t),hht=r(nx,":"),nx.forEach(t),uht=i(Oi),$e=n(Oi,"UL",{});var je=s($e);G7=n(je,"LI",{});var HKe=s(G7);w$e=n(HKe,"STRONG",{});var L_a=s(w$e);pht=r(L_a,"bart"),L_a.forEach(t),_ht=r(HKe," \u2014 "),Vse=n(HKe,"A",{href:!0});var y_a=s(Vse);bht=r(y_a,"FlaxBartForCausalLM"),y_a.forEach(t),vht=r(HKe," (BART model)"),HKe.forEach(t),Fht=i(je),O7=n(je,"LI",{});var JKe=s(O7);A$e=n(JKe,"STRONG",{});var x_a=s(A$e);Tht=r(x_a,"bert"),x_a.forEach(t),Mht=r(JKe," \u2014 "),Xse=n(JKe,"A",{href:!0});var $_a=s(Xse);Eht=r($_a,"FlaxBertForCausalLM"),$_a.forEach(t),Cht=r(JKe," (BERT model)"),JKe.forEach(t),wht=i(je),V7=n(je,"LI",{});var YKe=s(V7);L$e=n(YKe,"STRONG",{});var k_a=s(L$e);Aht=r(k_a,"big_bird"),k_a.forEach(t),Lht=r(YKe," \u2014 "),zse=n(YKe,"A",{href:!0});var S_a=s(zse);yht=r(S_a,"FlaxBigBirdForCausalLM"),S_a.forEach(t),xht=r(YKe," (BigBird model)"),YKe.forEach(t),$ht=i(je),X7=n(je,"LI",{});var ZKe=s(X7);y$e=n(ZKe,"STRONG",{});var R_a=s(y$e);kht=r(R_a,"electra"),R_a.forEach(t),Sht=r(ZKe," \u2014 "),Qse=n(ZKe,"A",{href:!0});var P_a=s(Qse);Rht=r(P_a,"FlaxElectraForCausalLM"),P_a.forEach(t),Pht=r(ZKe," (ELECTRA model)"),ZKe.forEach(t),Bht=i(je),z7=n(je,"LI",{});var KKe=s(z7);x$e=n(KKe,"STRONG",{});var B_a=s(x$e);Iht=r(B_a,"gpt2"),B_a.forEach(t),Nht=r(KKe," \u2014 "),Wse=n(KKe,"A",{href:!0});var I_a=s(Wse);qht=r(I_a,"FlaxGPT2LMHeadModel"),I_a.forEach(t),jht=r(KKe," (OpenAI GPT-2 model)"),KKe.forEach(t),Dht=i(je),Q7=n(je,"LI",{});var eeo=s(Q7);$$e=n(eeo,"STRONG",{});var N_a=s($$e);Ght=r(N_a,"gpt_neo"),N_a.forEach(t),Oht=r(eeo," \u2014 "),Use=n(eeo,"A",{href:!0});var q_a=s(Use);Vht=r(q_a,"FlaxGPTNeoForCausalLM"),q_a.forEach(t),Xht=r(eeo," (GPT Neo model)"),eeo.forEach(t),zht=i(je),W7=n(je,"LI",{});var oeo=s(W7);k$e=n(oeo,"STRONG",{});var j_a=s(k$e);Qht=r(j_a,"gptj"),j_a.forEach(t),Wht=r(oeo," \u2014 "),Hse=n(oeo,"A",{href:!0});var D_a=s(Hse);Uht=r(D_a,"FlaxGPTJForCausalLM"),D_a.forEach(t),Hht=r(oeo," (GPT-J model)"),oeo.forEach(t),Jht=i(je),U7=n(je,"LI",{});var reo=s(U7);S$e=n(reo,"STRONG",{});var G_a=s(S$e);Yht=r(G_a,"opt"),G_a.forEach(t),Zht=r(reo," \u2014 "),Jse=n(reo,"A",{href:!0});var O_a=s(Jse);Kht=r(O_a,"FlaxOPTForCausalLM"),O_a.forEach(t),eut=r(reo," (OPT model)"),reo.forEach(t),out=i(je),H7=n(je,"LI",{});var teo=s(H7);R$e=n(teo,"STRONG",{});var V_a=s(R$e);rut=r(V_a,"roberta"),V_a.forEach(t),tut=r(teo," \u2014 "),Yse=n(teo,"A",{href:!0});var X_a=s(Yse);aut=r(X_a,"FlaxRobertaForCausalLM"),X_a.forEach(t),nut=r(teo," (RoBERTa model)"),teo.forEach(t),sut=i(je),J7=n(je,"LI",{});var aeo=s(J7);P$e=n(aeo,"STRONG",{});var z_a=s(P$e);lut=r(z_a,"xglm"),z_a.forEach(t),iut=r(aeo," \u2014 "),Zse=n(aeo,"A",{href:!0});var Q_a=s(Zse);dut=r(Q_a,"FlaxXGLMForCausalLM"),Q_a.forEach(t),cut=r(aeo," (XGLM model)"),aeo.forEach(t),je.forEach(t),mut=i(Oi),T(Y7.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),vto=i(m),Km=n(m,"H2",{class:!0});var Nno=s(Km);Z7=n(Nno,"A",{id:!0,class:!0,href:!0});var W_a=s(Z7);B$e=n(W_a,"SPAN",{});var U_a=s(B$e);T(gP.$$.fragment,U_a),U_a.forEach(t),W_a.forEach(t),fut=i(Nno),I$e=n(Nno,"SPAN",{});var H_a=s(I$e);gut=r(H_a,"FlaxAutoModelForPreTraining"),H_a.forEach(t),Nno.forEach(t),Fto=i(m),Ar=n(m,"DIV",{class:!0});var Vi=s(Ar);T(hP.$$.fragment,Vi),hut=i(Vi),ef=n(Vi,"P",{});var Pce=s(ef);uut=r(Pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Kse=n(Pce,"A",{href:!0});var J_a=s(Kse);put=r(J_a,"from_pretrained()"),J_a.forEach(t),_ut=r(Pce," class method or the "),ele=n(Pce,"A",{href:!0});var Y_a=s(ele);but=r(Y_a,"from_config()"),Y_a.forEach(t),vut=r(Pce,` class
method.`),Pce.forEach(t),Fut=i(Vi),uP=n(Vi,"P",{});var qno=s(uP);Tut=r(qno,"This class cannot be instantiated directly using "),N$e=n(qno,"CODE",{});var Z_a=s(N$e);Mut=r(Z_a,"__init__()"),Z_a.forEach(t),Eut=r(qno," (throws an error)."),qno.forEach(t),Cut=i(Vi),ma=n(Vi,"DIV",{class:!0});var sx=s(ma);T(pP.$$.fragment,sx),wut=i(sx),q$e=n(sx,"P",{});var K_a=s(q$e);Aut=r(K_a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),K_a.forEach(t),Lut=i(sx),of=n(sx,"P",{});var Bce=s(of);yut=r(Bce,`Note:
Loading a model from its configuration file does `),j$e=n(Bce,"STRONG",{});var e1a=s(j$e);xut=r(e1a,"not"),e1a.forEach(t),$ut=r(Bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ole=n(Bce,"A",{href:!0});var o1a=s(ole);kut=r(o1a,"from_pretrained()"),o1a.forEach(t),Sut=r(Bce," to load the model weights."),Bce.forEach(t),Rut=i(sx),T(K7.$$.fragment,sx),sx.forEach(t),Put=i(Vi),rt=n(Vi,"DIV",{class:!0});var Xi=s(rt);T(_P.$$.fragment,Xi),But=i(Xi),D$e=n(Xi,"P",{});var r1a=s(D$e);Iut=r(r1a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),r1a.forEach(t),Nut=i(Xi),Un=n(Xi,"P",{});var lx=s(Un);qut=r(lx,"The model class to instantiate is selected based on the "),G$e=n(lx,"CODE",{});var t1a=s(G$e);jut=r(t1a,"model_type"),t1a.forEach(t),Dut=r(lx,` property of the config object (either
passed as an argument or loaded from `),O$e=n(lx,"CODE",{});var a1a=s(O$e);Gut=r(a1a,"pretrained_model_name_or_path"),a1a.forEach(t),Out=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V$e=n(lx,"CODE",{});var n1a=s(V$e);Vut=r(n1a,"pretrained_model_name_or_path"),n1a.forEach(t),Xut=r(lx,":"),lx.forEach(t),zut=i(Xi),Ee=n(Xi,"UL",{});var we=s(Ee);eL=n(we,"LI",{});var neo=s(eL);X$e=n(neo,"STRONG",{});var s1a=s(X$e);Qut=r(s1a,"albert"),s1a.forEach(t),Wut=r(neo," \u2014 "),rle=n(neo,"A",{href:!0});var l1a=s(rle);Uut=r(l1a,"FlaxAlbertForPreTraining"),l1a.forEach(t),Hut=r(neo," (ALBERT model)"),neo.forEach(t),Jut=i(we),oL=n(we,"LI",{});var seo=s(oL);z$e=n(seo,"STRONG",{});var i1a=s(z$e);Yut=r(i1a,"bart"),i1a.forEach(t),Zut=r(seo," \u2014 "),tle=n(seo,"A",{href:!0});var d1a=s(tle);Kut=r(d1a,"FlaxBartForConditionalGeneration"),d1a.forEach(t),ept=r(seo," (BART model)"),seo.forEach(t),opt=i(we),rL=n(we,"LI",{});var leo=s(rL);Q$e=n(leo,"STRONG",{});var c1a=s(Q$e);rpt=r(c1a,"bert"),c1a.forEach(t),tpt=r(leo," \u2014 "),ale=n(leo,"A",{href:!0});var m1a=s(ale);apt=r(m1a,"FlaxBertForPreTraining"),m1a.forEach(t),npt=r(leo," (BERT model)"),leo.forEach(t),spt=i(we),tL=n(we,"LI",{});var ieo=s(tL);W$e=n(ieo,"STRONG",{});var f1a=s(W$e);lpt=r(f1a,"big_bird"),f1a.forEach(t),ipt=r(ieo," \u2014 "),nle=n(ieo,"A",{href:!0});var g1a=s(nle);dpt=r(g1a,"FlaxBigBirdForPreTraining"),g1a.forEach(t),cpt=r(ieo," (BigBird model)"),ieo.forEach(t),mpt=i(we),aL=n(we,"LI",{});var deo=s(aL);U$e=n(deo,"STRONG",{});var h1a=s(U$e);fpt=r(h1a,"electra"),h1a.forEach(t),gpt=r(deo," \u2014 "),sle=n(deo,"A",{href:!0});var u1a=s(sle);hpt=r(u1a,"FlaxElectraForPreTraining"),u1a.forEach(t),upt=r(deo," (ELECTRA model)"),deo.forEach(t),ppt=i(we),nL=n(we,"LI",{});var ceo=s(nL);H$e=n(ceo,"STRONG",{});var p1a=s(H$e);_pt=r(p1a,"longt5"),p1a.forEach(t),bpt=r(ceo," \u2014 "),lle=n(ceo,"A",{href:!0});var _1a=s(lle);vpt=r(_1a,"FlaxLongT5ForConditionalGeneration"),_1a.forEach(t),Fpt=r(ceo," (LongT5 model)"),ceo.forEach(t),Tpt=i(we),sL=n(we,"LI",{});var meo=s(sL);J$e=n(meo,"STRONG",{});var b1a=s(J$e);Mpt=r(b1a,"mbart"),b1a.forEach(t),Ept=r(meo," \u2014 "),ile=n(meo,"A",{href:!0});var v1a=s(ile);Cpt=r(v1a,"FlaxMBartForConditionalGeneration"),v1a.forEach(t),wpt=r(meo," (mBART model)"),meo.forEach(t),Apt=i(we),lL=n(we,"LI",{});var feo=s(lL);Y$e=n(feo,"STRONG",{});var F1a=s(Y$e);Lpt=r(F1a,"mt5"),F1a.forEach(t),ypt=r(feo," \u2014 "),dle=n(feo,"A",{href:!0});var T1a=s(dle);xpt=r(T1a,"FlaxMT5ForConditionalGeneration"),T1a.forEach(t),$pt=r(feo," (MT5 model)"),feo.forEach(t),kpt=i(we),iL=n(we,"LI",{});var geo=s(iL);Z$e=n(geo,"STRONG",{});var M1a=s(Z$e);Spt=r(M1a,"roberta"),M1a.forEach(t),Rpt=r(geo," \u2014 "),cle=n(geo,"A",{href:!0});var E1a=s(cle);Ppt=r(E1a,"FlaxRobertaForMaskedLM"),E1a.forEach(t),Bpt=r(geo," (RoBERTa model)"),geo.forEach(t),Ipt=i(we),dL=n(we,"LI",{});var heo=s(dL);K$e=n(heo,"STRONG",{});var C1a=s(K$e);Npt=r(C1a,"roformer"),C1a.forEach(t),qpt=r(heo," \u2014 "),mle=n(heo,"A",{href:!0});var w1a=s(mle);jpt=r(w1a,"FlaxRoFormerForMaskedLM"),w1a.forEach(t),Dpt=r(heo," (RoFormer model)"),heo.forEach(t),Gpt=i(we),cL=n(we,"LI",{});var ueo=s(cL);eke=n(ueo,"STRONG",{});var A1a=s(eke);Opt=r(A1a,"t5"),A1a.forEach(t),Vpt=r(ueo," \u2014 "),fle=n(ueo,"A",{href:!0});var L1a=s(fle);Xpt=r(L1a,"FlaxT5ForConditionalGeneration"),L1a.forEach(t),zpt=r(ueo," (T5 model)"),ueo.forEach(t),Qpt=i(we),mL=n(we,"LI",{});var peo=s(mL);oke=n(peo,"STRONG",{});var y1a=s(oke);Wpt=r(y1a,"wav2vec2"),y1a.forEach(t),Upt=r(peo," \u2014 "),gle=n(peo,"A",{href:!0});var x1a=s(gle);Hpt=r(x1a,"FlaxWav2Vec2ForPreTraining"),x1a.forEach(t),Jpt=r(peo," (Wav2Vec2 model)"),peo.forEach(t),Ypt=i(we),fL=n(we,"LI",{});var _eo=s(fL);rke=n(_eo,"STRONG",{});var $1a=s(rke);Zpt=r($1a,"xlm-roberta"),$1a.forEach(t),Kpt=r(_eo," \u2014 "),hle=n(_eo,"A",{href:!0});var k1a=s(hle);e_t=r(k1a,"FlaxXLMRobertaForMaskedLM"),k1a.forEach(t),o_t=r(_eo," (XLM-RoBERTa model)"),_eo.forEach(t),we.forEach(t),r_t=i(Xi),T(gL.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),Tto=i(m),rf=n(m,"H2",{class:!0});var jno=s(rf);hL=n(jno,"A",{id:!0,class:!0,href:!0});var S1a=s(hL);tke=n(S1a,"SPAN",{});var R1a=s(tke);T(bP.$$.fragment,R1a),R1a.forEach(t),S1a.forEach(t),t_t=i(jno),ake=n(jno,"SPAN",{});var P1a=s(ake);a_t=r(P1a,"FlaxAutoModelForMaskedLM"),P1a.forEach(t),jno.forEach(t),Mto=i(m),Lr=n(m,"DIV",{class:!0});var zi=s(Lr);T(vP.$$.fragment,zi),n_t=i(zi),tf=n(zi,"P",{});var Ice=s(tf);s_t=r(Ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ule=n(Ice,"A",{href:!0});var B1a=s(ule);l_t=r(B1a,"from_pretrained()"),B1a.forEach(t),i_t=r(Ice," class method or the "),ple=n(Ice,"A",{href:!0});var I1a=s(ple);d_t=r(I1a,"from_config()"),I1a.forEach(t),c_t=r(Ice,` class
method.`),Ice.forEach(t),m_t=i(zi),FP=n(zi,"P",{});var Dno=s(FP);f_t=r(Dno,"This class cannot be instantiated directly using "),nke=n(Dno,"CODE",{});var N1a=s(nke);g_t=r(N1a,"__init__()"),N1a.forEach(t),h_t=r(Dno," (throws an error)."),Dno.forEach(t),u_t=i(zi),fa=n(zi,"DIV",{class:!0});var ix=s(fa);T(TP.$$.fragment,ix),p_t=i(ix),ske=n(ix,"P",{});var q1a=s(ske);__t=r(q1a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),q1a.forEach(t),b_t=i(ix),af=n(ix,"P",{});var Nce=s(af);v_t=r(Nce,`Note:
Loading a model from its configuration file does `),lke=n(Nce,"STRONG",{});var j1a=s(lke);F_t=r(j1a,"not"),j1a.forEach(t),T_t=r(Nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),_le=n(Nce,"A",{href:!0});var D1a=s(_le);M_t=r(D1a,"from_pretrained()"),D1a.forEach(t),E_t=r(Nce," to load the model weights."),Nce.forEach(t),C_t=i(ix),T(uL.$$.fragment,ix),ix.forEach(t),w_t=i(zi),tt=n(zi,"DIV",{class:!0});var Qi=s(tt);T(MP.$$.fragment,Qi),A_t=i(Qi),ike=n(Qi,"P",{});var G1a=s(ike);L_t=r(G1a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),G1a.forEach(t),y_t=i(Qi),Hn=n(Qi,"P",{});var dx=s(Hn);x_t=r(dx,"The model class to instantiate is selected based on the "),dke=n(dx,"CODE",{});var O1a=s(dke);$_t=r(O1a,"model_type"),O1a.forEach(t),k_t=r(dx,` property of the config object (either
passed as an argument or loaded from `),cke=n(dx,"CODE",{});var V1a=s(cke);S_t=r(V1a,"pretrained_model_name_or_path"),V1a.forEach(t),R_t=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mke=n(dx,"CODE",{});var X1a=s(mke);P_t=r(X1a,"pretrained_model_name_or_path"),X1a.forEach(t),B_t=r(dx,":"),dx.forEach(t),I_t=i(Qi),ke=n(Qi,"UL",{});var De=s(ke);pL=n(De,"LI",{});var beo=s(pL);fke=n(beo,"STRONG",{});var z1a=s(fke);N_t=r(z1a,"albert"),z1a.forEach(t),q_t=r(beo," \u2014 "),ble=n(beo,"A",{href:!0});var Q1a=s(ble);j_t=r(Q1a,"FlaxAlbertForMaskedLM"),Q1a.forEach(t),D_t=r(beo," (ALBERT model)"),beo.forEach(t),G_t=i(De),_L=n(De,"LI",{});var veo=s(_L);gke=n(veo,"STRONG",{});var W1a=s(gke);O_t=r(W1a,"bart"),W1a.forEach(t),V_t=r(veo," \u2014 "),vle=n(veo,"A",{href:!0});var U1a=s(vle);X_t=r(U1a,"FlaxBartForConditionalGeneration"),U1a.forEach(t),z_t=r(veo," (BART model)"),veo.forEach(t),Q_t=i(De),bL=n(De,"LI",{});var Feo=s(bL);hke=n(Feo,"STRONG",{});var H1a=s(hke);W_t=r(H1a,"bert"),H1a.forEach(t),U_t=r(Feo," \u2014 "),Fle=n(Feo,"A",{href:!0});var J1a=s(Fle);H_t=r(J1a,"FlaxBertForMaskedLM"),J1a.forEach(t),J_t=r(Feo," (BERT model)"),Feo.forEach(t),Y_t=i(De),vL=n(De,"LI",{});var Teo=s(vL);uke=n(Teo,"STRONG",{});var Y1a=s(uke);Z_t=r(Y1a,"big_bird"),Y1a.forEach(t),K_t=r(Teo," \u2014 "),Tle=n(Teo,"A",{href:!0});var Z1a=s(Tle);e1t=r(Z1a,"FlaxBigBirdForMaskedLM"),Z1a.forEach(t),o1t=r(Teo," (BigBird model)"),Teo.forEach(t),r1t=i(De),FL=n(De,"LI",{});var Meo=s(FL);pke=n(Meo,"STRONG",{});var K1a=s(pke);t1t=r(K1a,"distilbert"),K1a.forEach(t),a1t=r(Meo," \u2014 "),Mle=n(Meo,"A",{href:!0});var e2a=s(Mle);n1t=r(e2a,"FlaxDistilBertForMaskedLM"),e2a.forEach(t),s1t=r(Meo," (DistilBERT model)"),Meo.forEach(t),l1t=i(De),TL=n(De,"LI",{});var Eeo=s(TL);_ke=n(Eeo,"STRONG",{});var o2a=s(_ke);i1t=r(o2a,"electra"),o2a.forEach(t),d1t=r(Eeo," \u2014 "),Ele=n(Eeo,"A",{href:!0});var r2a=s(Ele);c1t=r(r2a,"FlaxElectraForMaskedLM"),r2a.forEach(t),m1t=r(Eeo," (ELECTRA model)"),Eeo.forEach(t),f1t=i(De),ML=n(De,"LI",{});var Ceo=s(ML);bke=n(Ceo,"STRONG",{});var t2a=s(bke);g1t=r(t2a,"mbart"),t2a.forEach(t),h1t=r(Ceo," \u2014 "),Cle=n(Ceo,"A",{href:!0});var a2a=s(Cle);u1t=r(a2a,"FlaxMBartForConditionalGeneration"),a2a.forEach(t),p1t=r(Ceo," (mBART model)"),Ceo.forEach(t),_1t=i(De),EL=n(De,"LI",{});var weo=s(EL);vke=n(weo,"STRONG",{});var n2a=s(vke);b1t=r(n2a,"roberta"),n2a.forEach(t),v1t=r(weo," \u2014 "),wle=n(weo,"A",{href:!0});var s2a=s(wle);F1t=r(s2a,"FlaxRobertaForMaskedLM"),s2a.forEach(t),T1t=r(weo," (RoBERTa model)"),weo.forEach(t),M1t=i(De),CL=n(De,"LI",{});var Aeo=s(CL);Fke=n(Aeo,"STRONG",{});var l2a=s(Fke);E1t=r(l2a,"roformer"),l2a.forEach(t),C1t=r(Aeo," \u2014 "),Ale=n(Aeo,"A",{href:!0});var i2a=s(Ale);w1t=r(i2a,"FlaxRoFormerForMaskedLM"),i2a.forEach(t),A1t=r(Aeo," (RoFormer model)"),Aeo.forEach(t),L1t=i(De),wL=n(De,"LI",{});var Leo=s(wL);Tke=n(Leo,"STRONG",{});var d2a=s(Tke);y1t=r(d2a,"xlm-roberta"),d2a.forEach(t),x1t=r(Leo," \u2014 "),Lle=n(Leo,"A",{href:!0});var c2a=s(Lle);$1t=r(c2a,"FlaxXLMRobertaForMaskedLM"),c2a.forEach(t),k1t=r(Leo," (XLM-RoBERTa model)"),Leo.forEach(t),De.forEach(t),S1t=i(Qi),T(AL.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),Eto=i(m),nf=n(m,"H2",{class:!0});var Gno=s(nf);LL=n(Gno,"A",{id:!0,class:!0,href:!0});var m2a=s(LL);Mke=n(m2a,"SPAN",{});var f2a=s(Mke);T(EP.$$.fragment,f2a),f2a.forEach(t),m2a.forEach(t),R1t=i(Gno),Eke=n(Gno,"SPAN",{});var g2a=s(Eke);P1t=r(g2a,"FlaxAutoModelForSeq2SeqLM"),g2a.forEach(t),Gno.forEach(t),Cto=i(m),yr=n(m,"DIV",{class:!0});var Wi=s(yr);T(CP.$$.fragment,Wi),B1t=i(Wi),sf=n(Wi,"P",{});var qce=s(sf);I1t=r(qce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yle=n(qce,"A",{href:!0});var h2a=s(yle);N1t=r(h2a,"from_pretrained()"),h2a.forEach(t),q1t=r(qce," class method or the "),xle=n(qce,"A",{href:!0});var u2a=s(xle);j1t=r(u2a,"from_config()"),u2a.forEach(t),D1t=r(qce,` class
method.`),qce.forEach(t),G1t=i(Wi),wP=n(Wi,"P",{});var Ono=s(wP);O1t=r(Ono,"This class cannot be instantiated directly using "),Cke=n(Ono,"CODE",{});var p2a=s(Cke);V1t=r(p2a,"__init__()"),p2a.forEach(t),X1t=r(Ono," (throws an error)."),Ono.forEach(t),z1t=i(Wi),ga=n(Wi,"DIV",{class:!0});var cx=s(ga);T(AP.$$.fragment,cx),Q1t=i(cx),wke=n(cx,"P",{});var _2a=s(wke);W1t=r(_2a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_2a.forEach(t),U1t=i(cx),lf=n(cx,"P",{});var jce=s(lf);H1t=r(jce,`Note:
Loading a model from its configuration file does `),Ake=n(jce,"STRONG",{});var b2a=s(Ake);J1t=r(b2a,"not"),b2a.forEach(t),Y1t=r(jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),$le=n(jce,"A",{href:!0});var v2a=s($le);Z1t=r(v2a,"from_pretrained()"),v2a.forEach(t),K1t=r(jce," to load the model weights."),jce.forEach(t),e2t=i(cx),T(yL.$$.fragment,cx),cx.forEach(t),o2t=i(Wi),at=n(Wi,"DIV",{class:!0});var Ui=s(at);T(LP.$$.fragment,Ui),r2t=i(Ui),Lke=n(Ui,"P",{});var F2a=s(Lke);t2t=r(F2a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),F2a.forEach(t),a2t=i(Ui),Jn=n(Ui,"P",{});var mx=s(Jn);n2t=r(mx,"The model class to instantiate is selected based on the "),yke=n(mx,"CODE",{});var T2a=s(yke);s2t=r(T2a,"model_type"),T2a.forEach(t),l2t=r(mx,` property of the config object (either
passed as an argument or loaded from `),xke=n(mx,"CODE",{});var M2a=s(xke);i2t=r(M2a,"pretrained_model_name_or_path"),M2a.forEach(t),d2t=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ke=n(mx,"CODE",{});var E2a=s($ke);c2t=r(E2a,"pretrained_model_name_or_path"),E2a.forEach(t),m2t=r(mx,":"),mx.forEach(t),f2t=i(Ui),Se=n(Ui,"UL",{});var Ge=s(Se);xL=n(Ge,"LI",{});var yeo=s(xL);kke=n(yeo,"STRONG",{});var C2a=s(kke);g2t=r(C2a,"bart"),C2a.forEach(t),h2t=r(yeo," \u2014 "),kle=n(yeo,"A",{href:!0});var w2a=s(kle);u2t=r(w2a,"FlaxBartForConditionalGeneration"),w2a.forEach(t),p2t=r(yeo," (BART model)"),yeo.forEach(t),_2t=i(Ge),$L=n(Ge,"LI",{});var xeo=s($L);Ske=n(xeo,"STRONG",{});var A2a=s(Ske);b2t=r(A2a,"blenderbot"),A2a.forEach(t),v2t=r(xeo," \u2014 "),Sle=n(xeo,"A",{href:!0});var L2a=s(Sle);F2t=r(L2a,"FlaxBlenderbotForConditionalGeneration"),L2a.forEach(t),T2t=r(xeo," (Blenderbot model)"),xeo.forEach(t),M2t=i(Ge),kL=n(Ge,"LI",{});var $eo=s(kL);Rke=n($eo,"STRONG",{});var y2a=s(Rke);E2t=r(y2a,"blenderbot-small"),y2a.forEach(t),C2t=r($eo," \u2014 "),Rle=n($eo,"A",{href:!0});var x2a=s(Rle);w2t=r(x2a,"FlaxBlenderbotSmallForConditionalGeneration"),x2a.forEach(t),A2t=r($eo," (BlenderbotSmall model)"),$eo.forEach(t),L2t=i(Ge),SL=n(Ge,"LI",{});var keo=s(SL);Pke=n(keo,"STRONG",{});var $2a=s(Pke);y2t=r($2a,"encoder-decoder"),$2a.forEach(t),x2t=r(keo," \u2014 "),Ple=n(keo,"A",{href:!0});var k2a=s(Ple);$2t=r(k2a,"FlaxEncoderDecoderModel"),k2a.forEach(t),k2t=r(keo," (Encoder decoder model)"),keo.forEach(t),S2t=i(Ge),RL=n(Ge,"LI",{});var Seo=s(RL);Bke=n(Seo,"STRONG",{});var S2a=s(Bke);R2t=r(S2a,"longt5"),S2a.forEach(t),P2t=r(Seo," \u2014 "),Ble=n(Seo,"A",{href:!0});var R2a=s(Ble);B2t=r(R2a,"FlaxLongT5ForConditionalGeneration"),R2a.forEach(t),I2t=r(Seo," (LongT5 model)"),Seo.forEach(t),N2t=i(Ge),PL=n(Ge,"LI",{});var Reo=s(PL);Ike=n(Reo,"STRONG",{});var P2a=s(Ike);q2t=r(P2a,"marian"),P2a.forEach(t),j2t=r(Reo," \u2014 "),Ile=n(Reo,"A",{href:!0});var B2a=s(Ile);D2t=r(B2a,"FlaxMarianMTModel"),B2a.forEach(t),G2t=r(Reo," (Marian model)"),Reo.forEach(t),O2t=i(Ge),BL=n(Ge,"LI",{});var Peo=s(BL);Nke=n(Peo,"STRONG",{});var I2a=s(Nke);V2t=r(I2a,"mbart"),I2a.forEach(t),X2t=r(Peo," \u2014 "),Nle=n(Peo,"A",{href:!0});var N2a=s(Nle);z2t=r(N2a,"FlaxMBartForConditionalGeneration"),N2a.forEach(t),Q2t=r(Peo," (mBART model)"),Peo.forEach(t),W2t=i(Ge),IL=n(Ge,"LI",{});var Beo=s(IL);qke=n(Beo,"STRONG",{});var q2a=s(qke);U2t=r(q2a,"mt5"),q2a.forEach(t),H2t=r(Beo," \u2014 "),qle=n(Beo,"A",{href:!0});var j2a=s(qle);J2t=r(j2a,"FlaxMT5ForConditionalGeneration"),j2a.forEach(t),Y2t=r(Beo," (MT5 model)"),Beo.forEach(t),Z2t=i(Ge),NL=n(Ge,"LI",{});var Ieo=s(NL);jke=n(Ieo,"STRONG",{});var D2a=s(jke);K2t=r(D2a,"pegasus"),D2a.forEach(t),ebt=r(Ieo," \u2014 "),jle=n(Ieo,"A",{href:!0});var G2a=s(jle);obt=r(G2a,"FlaxPegasusForConditionalGeneration"),G2a.forEach(t),rbt=r(Ieo," (Pegasus model)"),Ieo.forEach(t),tbt=i(Ge),qL=n(Ge,"LI",{});var Neo=s(qL);Dke=n(Neo,"STRONG",{});var O2a=s(Dke);abt=r(O2a,"t5"),O2a.forEach(t),nbt=r(Neo," \u2014 "),Dle=n(Neo,"A",{href:!0});var V2a=s(Dle);sbt=r(V2a,"FlaxT5ForConditionalGeneration"),V2a.forEach(t),lbt=r(Neo," (T5 model)"),Neo.forEach(t),Ge.forEach(t),ibt=i(Ui),T(jL.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),wto=i(m),df=n(m,"H2",{class:!0});var Vno=s(df);DL=n(Vno,"A",{id:!0,class:!0,href:!0});var X2a=s(DL);Gke=n(X2a,"SPAN",{});var z2a=s(Gke);T(yP.$$.fragment,z2a),z2a.forEach(t),X2a.forEach(t),dbt=i(Vno),Oke=n(Vno,"SPAN",{});var Q2a=s(Oke);cbt=r(Q2a,"FlaxAutoModelForSequenceClassification"),Q2a.forEach(t),Vno.forEach(t),Ato=i(m),xr=n(m,"DIV",{class:!0});var Hi=s(xr);T(xP.$$.fragment,Hi),mbt=i(Hi),cf=n(Hi,"P",{});var Dce=s(cf);fbt=r(Dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Gle=n(Dce,"A",{href:!0});var W2a=s(Gle);gbt=r(W2a,"from_pretrained()"),W2a.forEach(t),hbt=r(Dce," class method or the "),Ole=n(Dce,"A",{href:!0});var U2a=s(Ole);ubt=r(U2a,"from_config()"),U2a.forEach(t),pbt=r(Dce,` class
method.`),Dce.forEach(t),_bt=i(Hi),$P=n(Hi,"P",{});var Xno=s($P);bbt=r(Xno,"This class cannot be instantiated directly using "),Vke=n(Xno,"CODE",{});var H2a=s(Vke);vbt=r(H2a,"__init__()"),H2a.forEach(t),Fbt=r(Xno," (throws an error)."),Xno.forEach(t),Tbt=i(Hi),ha=n(Hi,"DIV",{class:!0});var fx=s(ha);T(kP.$$.fragment,fx),Mbt=i(fx),Xke=n(fx,"P",{});var J2a=s(Xke);Ebt=r(J2a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),J2a.forEach(t),Cbt=i(fx),mf=n(fx,"P",{});var Gce=s(mf);wbt=r(Gce,`Note:
Loading a model from its configuration file does `),zke=n(Gce,"STRONG",{});var Y2a=s(zke);Abt=r(Y2a,"not"),Y2a.forEach(t),Lbt=r(Gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vle=n(Gce,"A",{href:!0});var Z2a=s(Vle);ybt=r(Z2a,"from_pretrained()"),Z2a.forEach(t),xbt=r(Gce," to load the model weights."),Gce.forEach(t),$bt=i(fx),T(GL.$$.fragment,fx),fx.forEach(t),kbt=i(Hi),nt=n(Hi,"DIV",{class:!0});var Ji=s(nt);T(SP.$$.fragment,Ji),Sbt=i(Ji),Qke=n(Ji,"P",{});var K2a=s(Qke);Rbt=r(K2a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),K2a.forEach(t),Pbt=i(Ji),Yn=n(Ji,"P",{});var gx=s(Yn);Bbt=r(gx,"The model class to instantiate is selected based on the "),Wke=n(gx,"CODE",{});var eba=s(Wke);Ibt=r(eba,"model_type"),eba.forEach(t),Nbt=r(gx,` property of the config object (either
passed as an argument or loaded from `),Uke=n(gx,"CODE",{});var oba=s(Uke);qbt=r(oba,"pretrained_model_name_or_path"),oba.forEach(t),jbt=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hke=n(gx,"CODE",{});var rba=s(Hke);Dbt=r(rba,"pretrained_model_name_or_path"),rba.forEach(t),Gbt=r(gx,":"),gx.forEach(t),Obt=i(Ji),Re=n(Ji,"UL",{});var Oe=s(Re);OL=n(Oe,"LI",{});var qeo=s(OL);Jke=n(qeo,"STRONG",{});var tba=s(Jke);Vbt=r(tba,"albert"),tba.forEach(t),Xbt=r(qeo," \u2014 "),Xle=n(qeo,"A",{href:!0});var aba=s(Xle);zbt=r(aba,"FlaxAlbertForSequenceClassification"),aba.forEach(t),Qbt=r(qeo," (ALBERT model)"),qeo.forEach(t),Wbt=i(Oe),VL=n(Oe,"LI",{});var jeo=s(VL);Yke=n(jeo,"STRONG",{});var nba=s(Yke);Ubt=r(nba,"bart"),nba.forEach(t),Hbt=r(jeo," \u2014 "),zle=n(jeo,"A",{href:!0});var sba=s(zle);Jbt=r(sba,"FlaxBartForSequenceClassification"),sba.forEach(t),Ybt=r(jeo," (BART model)"),jeo.forEach(t),Zbt=i(Oe),XL=n(Oe,"LI",{});var Deo=s(XL);Zke=n(Deo,"STRONG",{});var lba=s(Zke);Kbt=r(lba,"bert"),lba.forEach(t),evt=r(Deo," \u2014 "),Qle=n(Deo,"A",{href:!0});var iba=s(Qle);ovt=r(iba,"FlaxBertForSequenceClassification"),iba.forEach(t),rvt=r(Deo," (BERT model)"),Deo.forEach(t),tvt=i(Oe),zL=n(Oe,"LI",{});var Geo=s(zL);Kke=n(Geo,"STRONG",{});var dba=s(Kke);avt=r(dba,"big_bird"),dba.forEach(t),nvt=r(Geo," \u2014 "),Wle=n(Geo,"A",{href:!0});var cba=s(Wle);svt=r(cba,"FlaxBigBirdForSequenceClassification"),cba.forEach(t),lvt=r(Geo," (BigBird model)"),Geo.forEach(t),ivt=i(Oe),QL=n(Oe,"LI",{});var Oeo=s(QL);eSe=n(Oeo,"STRONG",{});var mba=s(eSe);dvt=r(mba,"distilbert"),mba.forEach(t),cvt=r(Oeo," \u2014 "),Ule=n(Oeo,"A",{href:!0});var fba=s(Ule);mvt=r(fba,"FlaxDistilBertForSequenceClassification"),fba.forEach(t),fvt=r(Oeo," (DistilBERT model)"),Oeo.forEach(t),gvt=i(Oe),WL=n(Oe,"LI",{});var Veo=s(WL);oSe=n(Veo,"STRONG",{});var gba=s(oSe);hvt=r(gba,"electra"),gba.forEach(t),uvt=r(Veo," \u2014 "),Hle=n(Veo,"A",{href:!0});var hba=s(Hle);pvt=r(hba,"FlaxElectraForSequenceClassification"),hba.forEach(t),_vt=r(Veo," (ELECTRA model)"),Veo.forEach(t),bvt=i(Oe),UL=n(Oe,"LI",{});var Xeo=s(UL);rSe=n(Xeo,"STRONG",{});var uba=s(rSe);vvt=r(uba,"mbart"),uba.forEach(t),Fvt=r(Xeo," \u2014 "),Jle=n(Xeo,"A",{href:!0});var pba=s(Jle);Tvt=r(pba,"FlaxMBartForSequenceClassification"),pba.forEach(t),Mvt=r(Xeo," (mBART model)"),Xeo.forEach(t),Evt=i(Oe),HL=n(Oe,"LI",{});var zeo=s(HL);tSe=n(zeo,"STRONG",{});var _ba=s(tSe);Cvt=r(_ba,"roberta"),_ba.forEach(t),wvt=r(zeo," \u2014 "),Yle=n(zeo,"A",{href:!0});var bba=s(Yle);Avt=r(bba,"FlaxRobertaForSequenceClassification"),bba.forEach(t),Lvt=r(zeo," (RoBERTa model)"),zeo.forEach(t),yvt=i(Oe),JL=n(Oe,"LI",{});var Qeo=s(JL);aSe=n(Qeo,"STRONG",{});var vba=s(aSe);xvt=r(vba,"roformer"),vba.forEach(t),$vt=r(Qeo," \u2014 "),Zle=n(Qeo,"A",{href:!0});var Fba=s(Zle);kvt=r(Fba,"FlaxRoFormerForSequenceClassification"),Fba.forEach(t),Svt=r(Qeo," (RoFormer model)"),Qeo.forEach(t),Rvt=i(Oe),YL=n(Oe,"LI",{});var Weo=s(YL);nSe=n(Weo,"STRONG",{});var Tba=s(nSe);Pvt=r(Tba,"xlm-roberta"),Tba.forEach(t),Bvt=r(Weo," \u2014 "),Kle=n(Weo,"A",{href:!0});var Mba=s(Kle);Ivt=r(Mba,"FlaxXLMRobertaForSequenceClassification"),Mba.forEach(t),Nvt=r(Weo," (XLM-RoBERTa model)"),Weo.forEach(t),Oe.forEach(t),qvt=i(Ji),T(ZL.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Lto=i(m),ff=n(m,"H2",{class:!0});var zno=s(ff);KL=n(zno,"A",{id:!0,class:!0,href:!0});var Eba=s(KL);sSe=n(Eba,"SPAN",{});var Cba=s(sSe);T(RP.$$.fragment,Cba),Cba.forEach(t),Eba.forEach(t),jvt=i(zno),lSe=n(zno,"SPAN",{});var wba=s(lSe);Dvt=r(wba,"FlaxAutoModelForQuestionAnswering"),wba.forEach(t),zno.forEach(t),yto=i(m),$r=n(m,"DIV",{class:!0});var Yi=s($r);T(PP.$$.fragment,Yi),Gvt=i(Yi),gf=n(Yi,"P",{});var Oce=s(gf);Ovt=r(Oce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),eie=n(Oce,"A",{href:!0});var Aba=s(eie);Vvt=r(Aba,"from_pretrained()"),Aba.forEach(t),Xvt=r(Oce," class method or the "),oie=n(Oce,"A",{href:!0});var Lba=s(oie);zvt=r(Lba,"from_config()"),Lba.forEach(t),Qvt=r(Oce,` class
method.`),Oce.forEach(t),Wvt=i(Yi),BP=n(Yi,"P",{});var Qno=s(BP);Uvt=r(Qno,"This class cannot be instantiated directly using "),iSe=n(Qno,"CODE",{});var yba=s(iSe);Hvt=r(yba,"__init__()"),yba.forEach(t),Jvt=r(Qno," (throws an error)."),Qno.forEach(t),Yvt=i(Yi),ua=n(Yi,"DIV",{class:!0});var hx=s(ua);T(IP.$$.fragment,hx),Zvt=i(hx),dSe=n(hx,"P",{});var xba=s(dSe);Kvt=r(xba,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),xba.forEach(t),eFt=i(hx),hf=n(hx,"P",{});var Vce=s(hf);oFt=r(Vce,`Note:
Loading a model from its configuration file does `),cSe=n(Vce,"STRONG",{});var $ba=s(cSe);rFt=r($ba,"not"),$ba.forEach(t),tFt=r(Vce,` load the model weights. It only affects the
model\u2019s configuration. Use `),rie=n(Vce,"A",{href:!0});var kba=s(rie);aFt=r(kba,"from_pretrained()"),kba.forEach(t),nFt=r(Vce," to load the model weights."),Vce.forEach(t),sFt=i(hx),T(e8.$$.fragment,hx),hx.forEach(t),lFt=i(Yi),st=n(Yi,"DIV",{class:!0});var Zi=s(st);T(NP.$$.fragment,Zi),iFt=i(Zi),mSe=n(Zi,"P",{});var Sba=s(mSe);dFt=r(Sba,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Sba.forEach(t),cFt=i(Zi),Zn=n(Zi,"P",{});var ux=s(Zn);mFt=r(ux,"The model class to instantiate is selected based on the "),fSe=n(ux,"CODE",{});var Rba=s(fSe);fFt=r(Rba,"model_type"),Rba.forEach(t),gFt=r(ux,` property of the config object (either
passed as an argument or loaded from `),gSe=n(ux,"CODE",{});var Pba=s(gSe);hFt=r(Pba,"pretrained_model_name_or_path"),Pba.forEach(t),uFt=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hSe=n(ux,"CODE",{});var Bba=s(hSe);pFt=r(Bba,"pretrained_model_name_or_path"),Bba.forEach(t),_Ft=r(ux,":"),ux.forEach(t),bFt=i(Zi),Pe=n(Zi,"UL",{});var Ve=s(Pe);o8=n(Ve,"LI",{});var Ueo=s(o8);uSe=n(Ueo,"STRONG",{});var Iba=s(uSe);vFt=r(Iba,"albert"),Iba.forEach(t),FFt=r(Ueo," \u2014 "),tie=n(Ueo,"A",{href:!0});var Nba=s(tie);TFt=r(Nba,"FlaxAlbertForQuestionAnswering"),Nba.forEach(t),MFt=r(Ueo," (ALBERT model)"),Ueo.forEach(t),EFt=i(Ve),r8=n(Ve,"LI",{});var Heo=s(r8);pSe=n(Heo,"STRONG",{});var qba=s(pSe);CFt=r(qba,"bart"),qba.forEach(t),wFt=r(Heo," \u2014 "),aie=n(Heo,"A",{href:!0});var jba=s(aie);AFt=r(jba,"FlaxBartForQuestionAnswering"),jba.forEach(t),LFt=r(Heo," (BART model)"),Heo.forEach(t),yFt=i(Ve),t8=n(Ve,"LI",{});var Jeo=s(t8);_Se=n(Jeo,"STRONG",{});var Dba=s(_Se);xFt=r(Dba,"bert"),Dba.forEach(t),$Ft=r(Jeo," \u2014 "),nie=n(Jeo,"A",{href:!0});var Gba=s(nie);kFt=r(Gba,"FlaxBertForQuestionAnswering"),Gba.forEach(t),SFt=r(Jeo," (BERT model)"),Jeo.forEach(t),RFt=i(Ve),a8=n(Ve,"LI",{});var Yeo=s(a8);bSe=n(Yeo,"STRONG",{});var Oba=s(bSe);PFt=r(Oba,"big_bird"),Oba.forEach(t),BFt=r(Yeo," \u2014 "),sie=n(Yeo,"A",{href:!0});var Vba=s(sie);IFt=r(Vba,"FlaxBigBirdForQuestionAnswering"),Vba.forEach(t),NFt=r(Yeo," (BigBird model)"),Yeo.forEach(t),qFt=i(Ve),n8=n(Ve,"LI",{});var Zeo=s(n8);vSe=n(Zeo,"STRONG",{});var Xba=s(vSe);jFt=r(Xba,"distilbert"),Xba.forEach(t),DFt=r(Zeo," \u2014 "),lie=n(Zeo,"A",{href:!0});var zba=s(lie);GFt=r(zba,"FlaxDistilBertForQuestionAnswering"),zba.forEach(t),OFt=r(Zeo," (DistilBERT model)"),Zeo.forEach(t),VFt=i(Ve),s8=n(Ve,"LI",{});var Keo=s(s8);FSe=n(Keo,"STRONG",{});var Qba=s(FSe);XFt=r(Qba,"electra"),Qba.forEach(t),zFt=r(Keo," \u2014 "),iie=n(Keo,"A",{href:!0});var Wba=s(iie);QFt=r(Wba,"FlaxElectraForQuestionAnswering"),Wba.forEach(t),WFt=r(Keo," (ELECTRA model)"),Keo.forEach(t),UFt=i(Ve),l8=n(Ve,"LI",{});var eoo=s(l8);TSe=n(eoo,"STRONG",{});var Uba=s(TSe);HFt=r(Uba,"mbart"),Uba.forEach(t),JFt=r(eoo," \u2014 "),die=n(eoo,"A",{href:!0});var Hba=s(die);YFt=r(Hba,"FlaxMBartForQuestionAnswering"),Hba.forEach(t),ZFt=r(eoo," (mBART model)"),eoo.forEach(t),KFt=i(Ve),i8=n(Ve,"LI",{});var ooo=s(i8);MSe=n(ooo,"STRONG",{});var Jba=s(MSe);eTt=r(Jba,"roberta"),Jba.forEach(t),oTt=r(ooo," \u2014 "),cie=n(ooo,"A",{href:!0});var Yba=s(cie);rTt=r(Yba,"FlaxRobertaForQuestionAnswering"),Yba.forEach(t),tTt=r(ooo," (RoBERTa model)"),ooo.forEach(t),aTt=i(Ve),d8=n(Ve,"LI",{});var roo=s(d8);ESe=n(roo,"STRONG",{});var Zba=s(ESe);nTt=r(Zba,"roformer"),Zba.forEach(t),sTt=r(roo," \u2014 "),mie=n(roo,"A",{href:!0});var Kba=s(mie);lTt=r(Kba,"FlaxRoFormerForQuestionAnswering"),Kba.forEach(t),iTt=r(roo," (RoFormer model)"),roo.forEach(t),dTt=i(Ve),c8=n(Ve,"LI",{});var too=s(c8);CSe=n(too,"STRONG",{});var eva=s(CSe);cTt=r(eva,"xlm-roberta"),eva.forEach(t),mTt=r(too," \u2014 "),fie=n(too,"A",{href:!0});var ova=s(fie);fTt=r(ova,"FlaxXLMRobertaForQuestionAnswering"),ova.forEach(t),gTt=r(too," (XLM-RoBERTa model)"),too.forEach(t),Ve.forEach(t),hTt=i(Zi),T(m8.$$.fragment,Zi),Zi.forEach(t),Yi.forEach(t),xto=i(m),uf=n(m,"H2",{class:!0});var Wno=s(uf);f8=n(Wno,"A",{id:!0,class:!0,href:!0});var rva=s(f8);wSe=n(rva,"SPAN",{});var tva=s(wSe);T(qP.$$.fragment,tva),tva.forEach(t),rva.forEach(t),uTt=i(Wno),ASe=n(Wno,"SPAN",{});var ava=s(ASe);pTt=r(ava,"FlaxAutoModelForTokenClassification"),ava.forEach(t),Wno.forEach(t),$to=i(m),kr=n(m,"DIV",{class:!0});var Ki=s(kr);T(jP.$$.fragment,Ki),_Tt=i(Ki),pf=n(Ki,"P",{});var Xce=s(pf);bTt=r(Xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),gie=n(Xce,"A",{href:!0});var nva=s(gie);vTt=r(nva,"from_pretrained()"),nva.forEach(t),FTt=r(Xce," class method or the "),hie=n(Xce,"A",{href:!0});var sva=s(hie);TTt=r(sva,"from_config()"),sva.forEach(t),MTt=r(Xce,` class
method.`),Xce.forEach(t),ETt=i(Ki),DP=n(Ki,"P",{});var Uno=s(DP);CTt=r(Uno,"This class cannot be instantiated directly using "),LSe=n(Uno,"CODE",{});var lva=s(LSe);wTt=r(lva,"__init__()"),lva.forEach(t),ATt=r(Uno," (throws an error)."),Uno.forEach(t),LTt=i(Ki),pa=n(Ki,"DIV",{class:!0});var px=s(pa);T(GP.$$.fragment,px),yTt=i(px),ySe=n(px,"P",{});var iva=s(ySe);xTt=r(iva,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),iva.forEach(t),$Tt=i(px),_f=n(px,"P",{});var zce=s(_f);kTt=r(zce,`Note:
Loading a model from its configuration file does `),xSe=n(zce,"STRONG",{});var dva=s(xSe);STt=r(dva,"not"),dva.forEach(t),RTt=r(zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),uie=n(zce,"A",{href:!0});var cva=s(uie);PTt=r(cva,"from_pretrained()"),cva.forEach(t),BTt=r(zce," to load the model weights."),zce.forEach(t),ITt=i(px),T(g8.$$.fragment,px),px.forEach(t),NTt=i(Ki),lt=n(Ki,"DIV",{class:!0});var ed=s(lt);T(OP.$$.fragment,ed),qTt=i(ed),$Se=n(ed,"P",{});var mva=s($Se);jTt=r(mva,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),mva.forEach(t),DTt=i(ed),Kn=n(ed,"P",{});var _x=s(Kn);GTt=r(_x,"The model class to instantiate is selected based on the "),kSe=n(_x,"CODE",{});var fva=s(kSe);OTt=r(fva,"model_type"),fva.forEach(t),VTt=r(_x,` property of the config object (either
passed as an argument or loaded from `),SSe=n(_x,"CODE",{});var gva=s(SSe);XTt=r(gva,"pretrained_model_name_or_path"),gva.forEach(t),zTt=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RSe=n(_x,"CODE",{});var hva=s(RSe);QTt=r(hva,"pretrained_model_name_or_path"),hva.forEach(t),WTt=r(_x,":"),_x.forEach(t),UTt=i(ed),ze=n(ed,"UL",{});var Lo=s(ze);h8=n(Lo,"LI",{});var aoo=s(h8);PSe=n(aoo,"STRONG",{});var uva=s(PSe);HTt=r(uva,"albert"),uva.forEach(t),JTt=r(aoo," \u2014 "),pie=n(aoo,"A",{href:!0});var pva=s(pie);YTt=r(pva,"FlaxAlbertForTokenClassification"),pva.forEach(t),ZTt=r(aoo," (ALBERT model)"),aoo.forEach(t),KTt=i(Lo),u8=n(Lo,"LI",{});var noo=s(u8);BSe=n(noo,"STRONG",{});var _va=s(BSe);eMt=r(_va,"bert"),_va.forEach(t),oMt=r(noo," \u2014 "),_ie=n(noo,"A",{href:!0});var bva=s(_ie);rMt=r(bva,"FlaxBertForTokenClassification"),bva.forEach(t),tMt=r(noo," (BERT model)"),noo.forEach(t),aMt=i(Lo),p8=n(Lo,"LI",{});var soo=s(p8);ISe=n(soo,"STRONG",{});var vva=s(ISe);nMt=r(vva,"big_bird"),vva.forEach(t),sMt=r(soo," \u2014 "),bie=n(soo,"A",{href:!0});var Fva=s(bie);lMt=r(Fva,"FlaxBigBirdForTokenClassification"),Fva.forEach(t),iMt=r(soo," (BigBird model)"),soo.forEach(t),dMt=i(Lo),_8=n(Lo,"LI",{});var loo=s(_8);NSe=n(loo,"STRONG",{});var Tva=s(NSe);cMt=r(Tva,"distilbert"),Tva.forEach(t),mMt=r(loo," \u2014 "),vie=n(loo,"A",{href:!0});var Mva=s(vie);fMt=r(Mva,"FlaxDistilBertForTokenClassification"),Mva.forEach(t),gMt=r(loo," (DistilBERT model)"),loo.forEach(t),hMt=i(Lo),b8=n(Lo,"LI",{});var ioo=s(b8);qSe=n(ioo,"STRONG",{});var Eva=s(qSe);uMt=r(Eva,"electra"),Eva.forEach(t),pMt=r(ioo," \u2014 "),Fie=n(ioo,"A",{href:!0});var Cva=s(Fie);_Mt=r(Cva,"FlaxElectraForTokenClassification"),Cva.forEach(t),bMt=r(ioo," (ELECTRA model)"),ioo.forEach(t),vMt=i(Lo),v8=n(Lo,"LI",{});var doo=s(v8);jSe=n(doo,"STRONG",{});var wva=s(jSe);FMt=r(wva,"roberta"),wva.forEach(t),TMt=r(doo," \u2014 "),Tie=n(doo,"A",{href:!0});var Ava=s(Tie);MMt=r(Ava,"FlaxRobertaForTokenClassification"),Ava.forEach(t),EMt=r(doo," (RoBERTa model)"),doo.forEach(t),CMt=i(Lo),F8=n(Lo,"LI",{});var coo=s(F8);DSe=n(coo,"STRONG",{});var Lva=s(DSe);wMt=r(Lva,"roformer"),Lva.forEach(t),AMt=r(coo," \u2014 "),Mie=n(coo,"A",{href:!0});var yva=s(Mie);LMt=r(yva,"FlaxRoFormerForTokenClassification"),yva.forEach(t),yMt=r(coo," (RoFormer model)"),coo.forEach(t),xMt=i(Lo),T8=n(Lo,"LI",{});var moo=s(T8);GSe=n(moo,"STRONG",{});var xva=s(GSe);$Mt=r(xva,"xlm-roberta"),xva.forEach(t),kMt=r(moo," \u2014 "),Eie=n(moo,"A",{href:!0});var $va=s(Eie);SMt=r($va,"FlaxXLMRobertaForTokenClassification"),$va.forEach(t),RMt=r(moo," (XLM-RoBERTa model)"),moo.forEach(t),Lo.forEach(t),PMt=i(ed),T(M8.$$.fragment,ed),ed.forEach(t),Ki.forEach(t),kto=i(m),bf=n(m,"H2",{class:!0});var Hno=s(bf);E8=n(Hno,"A",{id:!0,class:!0,href:!0});var kva=s(E8);OSe=n(kva,"SPAN",{});var Sva=s(OSe);T(VP.$$.fragment,Sva),Sva.forEach(t),kva.forEach(t),BMt=i(Hno),VSe=n(Hno,"SPAN",{});var Rva=s(VSe);IMt=r(Rva,"FlaxAutoModelForMultipleChoice"),Rva.forEach(t),Hno.forEach(t),Sto=i(m),Sr=n(m,"DIV",{class:!0});var od=s(Sr);T(XP.$$.fragment,od),NMt=i(od),vf=n(od,"P",{});var Qce=s(vf);qMt=r(Qce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Cie=n(Qce,"A",{href:!0});var Pva=s(Cie);jMt=r(Pva,"from_pretrained()"),Pva.forEach(t),DMt=r(Qce," class method or the "),wie=n(Qce,"A",{href:!0});var Bva=s(wie);GMt=r(Bva,"from_config()"),Bva.forEach(t),OMt=r(Qce,` class
method.`),Qce.forEach(t),VMt=i(od),zP=n(od,"P",{});var Jno=s(zP);XMt=r(Jno,"This class cannot be instantiated directly using "),XSe=n(Jno,"CODE",{});var Iva=s(XSe);zMt=r(Iva,"__init__()"),Iva.forEach(t),QMt=r(Jno," (throws an error)."),Jno.forEach(t),WMt=i(od),_a=n(od,"DIV",{class:!0});var bx=s(_a);T(QP.$$.fragment,bx),UMt=i(bx),zSe=n(bx,"P",{});var Nva=s(zSe);HMt=r(Nva,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Nva.forEach(t),JMt=i(bx),Ff=n(bx,"P",{});var Wce=s(Ff);YMt=r(Wce,`Note:
Loading a model from its configuration file does `),QSe=n(Wce,"STRONG",{});var qva=s(QSe);ZMt=r(qva,"not"),qva.forEach(t),KMt=r(Wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aie=n(Wce,"A",{href:!0});var jva=s(Aie);eEt=r(jva,"from_pretrained()"),jva.forEach(t),oEt=r(Wce," to load the model weights."),Wce.forEach(t),rEt=i(bx),T(C8.$$.fragment,bx),bx.forEach(t),tEt=i(od),it=n(od,"DIV",{class:!0});var rd=s(it);T(WP.$$.fragment,rd),aEt=i(rd),WSe=n(rd,"P",{});var Dva=s(WSe);nEt=r(Dva,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Dva.forEach(t),sEt=i(rd),es=n(rd,"P",{});var vx=s(es);lEt=r(vx,"The model class to instantiate is selected based on the "),USe=n(vx,"CODE",{});var Gva=s(USe);iEt=r(Gva,"model_type"),Gva.forEach(t),dEt=r(vx,` property of the config object (either
passed as an argument or loaded from `),HSe=n(vx,"CODE",{});var Ova=s(HSe);cEt=r(Ova,"pretrained_model_name_or_path"),Ova.forEach(t),mEt=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=n(vx,"CODE",{});var Vva=s(JSe);fEt=r(Vva,"pretrained_model_name_or_path"),Vva.forEach(t),gEt=r(vx,":"),vx.forEach(t),hEt=i(rd),Qe=n(rd,"UL",{});var yo=s(Qe);w8=n(yo,"LI",{});var foo=s(w8);YSe=n(foo,"STRONG",{});var Xva=s(YSe);uEt=r(Xva,"albert"),Xva.forEach(t),pEt=r(foo," \u2014 "),Lie=n(foo,"A",{href:!0});var zva=s(Lie);_Et=r(zva,"FlaxAlbertForMultipleChoice"),zva.forEach(t),bEt=r(foo," (ALBERT model)"),foo.forEach(t),vEt=i(yo),A8=n(yo,"LI",{});var goo=s(A8);ZSe=n(goo,"STRONG",{});var Qva=s(ZSe);FEt=r(Qva,"bert"),Qva.forEach(t),TEt=r(goo," \u2014 "),yie=n(goo,"A",{href:!0});var Wva=s(yie);MEt=r(Wva,"FlaxBertForMultipleChoice"),Wva.forEach(t),EEt=r(goo," (BERT model)"),goo.forEach(t),CEt=i(yo),L8=n(yo,"LI",{});var hoo=s(L8);KSe=n(hoo,"STRONG",{});var Uva=s(KSe);wEt=r(Uva,"big_bird"),Uva.forEach(t),AEt=r(hoo," \u2014 "),xie=n(hoo,"A",{href:!0});var Hva=s(xie);LEt=r(Hva,"FlaxBigBirdForMultipleChoice"),Hva.forEach(t),yEt=r(hoo," (BigBird model)"),hoo.forEach(t),xEt=i(yo),y8=n(yo,"LI",{});var uoo=s(y8);eRe=n(uoo,"STRONG",{});var Jva=s(eRe);$Et=r(Jva,"distilbert"),Jva.forEach(t),kEt=r(uoo," \u2014 "),$ie=n(uoo,"A",{href:!0});var Yva=s($ie);SEt=r(Yva,"FlaxDistilBertForMultipleChoice"),Yva.forEach(t),REt=r(uoo," (DistilBERT model)"),uoo.forEach(t),PEt=i(yo),x8=n(yo,"LI",{});var poo=s(x8);oRe=n(poo,"STRONG",{});var Zva=s(oRe);BEt=r(Zva,"electra"),Zva.forEach(t),IEt=r(poo," \u2014 "),kie=n(poo,"A",{href:!0});var Kva=s(kie);NEt=r(Kva,"FlaxElectraForMultipleChoice"),Kva.forEach(t),qEt=r(poo," (ELECTRA model)"),poo.forEach(t),jEt=i(yo),$8=n(yo,"LI",{});var _oo=s($8);rRe=n(_oo,"STRONG",{});var eFa=s(rRe);DEt=r(eFa,"roberta"),eFa.forEach(t),GEt=r(_oo," \u2014 "),Sie=n(_oo,"A",{href:!0});var oFa=s(Sie);OEt=r(oFa,"FlaxRobertaForMultipleChoice"),oFa.forEach(t),VEt=r(_oo," (RoBERTa model)"),_oo.forEach(t),XEt=i(yo),k8=n(yo,"LI",{});var boo=s(k8);tRe=n(boo,"STRONG",{});var rFa=s(tRe);zEt=r(rFa,"roformer"),rFa.forEach(t),QEt=r(boo," \u2014 "),Rie=n(boo,"A",{href:!0});var tFa=s(Rie);WEt=r(tFa,"FlaxRoFormerForMultipleChoice"),tFa.forEach(t),UEt=r(boo," (RoFormer model)"),boo.forEach(t),HEt=i(yo),S8=n(yo,"LI",{});var voo=s(S8);aRe=n(voo,"STRONG",{});var aFa=s(aRe);JEt=r(aFa,"xlm-roberta"),aFa.forEach(t),YEt=r(voo," \u2014 "),Pie=n(voo,"A",{href:!0});var nFa=s(Pie);ZEt=r(nFa,"FlaxXLMRobertaForMultipleChoice"),nFa.forEach(t),KEt=r(voo," (XLM-RoBERTa model)"),voo.forEach(t),yo.forEach(t),e4t=i(rd),T(R8.$$.fragment,rd),rd.forEach(t),od.forEach(t),Rto=i(m),Tf=n(m,"H2",{class:!0});var Yno=s(Tf);P8=n(Yno,"A",{id:!0,class:!0,href:!0});var sFa=s(P8);nRe=n(sFa,"SPAN",{});var lFa=s(nRe);T(UP.$$.fragment,lFa),lFa.forEach(t),sFa.forEach(t),o4t=i(Yno),sRe=n(Yno,"SPAN",{});var iFa=s(sRe);r4t=r(iFa,"FlaxAutoModelForNextSentencePrediction"),iFa.forEach(t),Yno.forEach(t),Pto=i(m),Rr=n(m,"DIV",{class:!0});var td=s(Rr);T(HP.$$.fragment,td),t4t=i(td),Mf=n(td,"P",{});var Uce=s(Mf);a4t=r(Uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Bie=n(Uce,"A",{href:!0});var dFa=s(Bie);n4t=r(dFa,"from_pretrained()"),dFa.forEach(t),s4t=r(Uce," class method or the "),Iie=n(Uce,"A",{href:!0});var cFa=s(Iie);l4t=r(cFa,"from_config()"),cFa.forEach(t),i4t=r(Uce,` class
method.`),Uce.forEach(t),d4t=i(td),JP=n(td,"P",{});var Zno=s(JP);c4t=r(Zno,"This class cannot be instantiated directly using "),lRe=n(Zno,"CODE",{});var mFa=s(lRe);m4t=r(mFa,"__init__()"),mFa.forEach(t),f4t=r(Zno," (throws an error)."),Zno.forEach(t),g4t=i(td),ba=n(td,"DIV",{class:!0});var Fx=s(ba);T(YP.$$.fragment,Fx),h4t=i(Fx),iRe=n(Fx,"P",{});var fFa=s(iRe);u4t=r(fFa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fFa.forEach(t),p4t=i(Fx),Ef=n(Fx,"P",{});var Hce=s(Ef);_4t=r(Hce,`Note:
Loading a model from its configuration file does `),dRe=n(Hce,"STRONG",{});var gFa=s(dRe);b4t=r(gFa,"not"),gFa.forEach(t),v4t=r(Hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=n(Hce,"A",{href:!0});var hFa=s(Nie);F4t=r(hFa,"from_pretrained()"),hFa.forEach(t),T4t=r(Hce," to load the model weights."),Hce.forEach(t),M4t=i(Fx),T(B8.$$.fragment,Fx),Fx.forEach(t),E4t=i(td),dt=n(td,"DIV",{class:!0});var ad=s(dt);T(ZP.$$.fragment,ad),C4t=i(ad),cRe=n(ad,"P",{});var uFa=s(cRe);w4t=r(uFa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),uFa.forEach(t),A4t=i(ad),os=n(ad,"P",{});var Tx=s(os);L4t=r(Tx,"The model class to instantiate is selected based on the "),mRe=n(Tx,"CODE",{});var pFa=s(mRe);y4t=r(pFa,"model_type"),pFa.forEach(t),x4t=r(Tx,` property of the config object (either
passed as an argument or loaded from `),fRe=n(Tx,"CODE",{});var _Fa=s(fRe);$4t=r(_Fa,"pretrained_model_name_or_path"),_Fa.forEach(t),k4t=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gRe=n(Tx,"CODE",{});var bFa=s(gRe);S4t=r(bFa,"pretrained_model_name_or_path"),bFa.forEach(t),R4t=r(Tx,":"),Tx.forEach(t),P4t=i(ad),hRe=n(ad,"UL",{});var vFa=s(hRe);I8=n(vFa,"LI",{});var Foo=s(I8);uRe=n(Foo,"STRONG",{});var FFa=s(uRe);B4t=r(FFa,"bert"),FFa.forEach(t),I4t=r(Foo," \u2014 "),qie=n(Foo,"A",{href:!0});var TFa=s(qie);N4t=r(TFa,"FlaxBertForNextSentencePrediction"),TFa.forEach(t),q4t=r(Foo," (BERT model)"),Foo.forEach(t),vFa.forEach(t),j4t=i(ad),T(N8.$$.fragment,ad),ad.forEach(t),td.forEach(t),Bto=i(m),Cf=n(m,"H2",{class:!0});var Kno=s(Cf);q8=n(Kno,"A",{id:!0,class:!0,href:!0});var MFa=s(q8);pRe=n(MFa,"SPAN",{});var EFa=s(pRe);T(KP.$$.fragment,EFa),EFa.forEach(t),MFa.forEach(t),D4t=i(Kno),_Re=n(Kno,"SPAN",{});var CFa=s(_Re);G4t=r(CFa,"FlaxAutoModelForImageClassification"),CFa.forEach(t),Kno.forEach(t),Ito=i(m),Pr=n(m,"DIV",{class:!0});var nd=s(Pr);T(eB.$$.fragment,nd),O4t=i(nd),wf=n(nd,"P",{});var Jce=s(wf);V4t=r(Jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jie=n(Jce,"A",{href:!0});var wFa=s(jie);X4t=r(wFa,"from_pretrained()"),wFa.forEach(t),z4t=r(Jce," class method or the "),Die=n(Jce,"A",{href:!0});var AFa=s(Die);Q4t=r(AFa,"from_config()"),AFa.forEach(t),W4t=r(Jce,` class
method.`),Jce.forEach(t),U4t=i(nd),oB=n(nd,"P",{});var eso=s(oB);H4t=r(eso,"This class cannot be instantiated directly using "),bRe=n(eso,"CODE",{});var LFa=s(bRe);J4t=r(LFa,"__init__()"),LFa.forEach(t),Y4t=r(eso," (throws an error)."),eso.forEach(t),Z4t=i(nd),va=n(nd,"DIV",{class:!0});var Mx=s(va);T(rB.$$.fragment,Mx),K4t=i(Mx),vRe=n(Mx,"P",{});var yFa=s(vRe);eCt=r(yFa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),yFa.forEach(t),oCt=i(Mx),Af=n(Mx,"P",{});var Yce=s(Af);rCt=r(Yce,`Note:
Loading a model from its configuration file does `),FRe=n(Yce,"STRONG",{});var xFa=s(FRe);tCt=r(xFa,"not"),xFa.forEach(t),aCt=r(Yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gie=n(Yce,"A",{href:!0});var $Fa=s(Gie);nCt=r($Fa,"from_pretrained()"),$Fa.forEach(t),sCt=r(Yce," to load the model weights."),Yce.forEach(t),lCt=i(Mx),T(j8.$$.fragment,Mx),Mx.forEach(t),iCt=i(nd),ct=n(nd,"DIV",{class:!0});var sd=s(ct);T(tB.$$.fragment,sd),dCt=i(sd),TRe=n(sd,"P",{});var kFa=s(TRe);cCt=r(kFa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),kFa.forEach(t),mCt=i(sd),rs=n(sd,"P",{});var Ex=s(rs);fCt=r(Ex,"The model class to instantiate is selected based on the "),MRe=n(Ex,"CODE",{});var SFa=s(MRe);gCt=r(SFa,"model_type"),SFa.forEach(t),hCt=r(Ex,` property of the config object (either
passed as an argument or loaded from `),ERe=n(Ex,"CODE",{});var RFa=s(ERe);uCt=r(RFa,"pretrained_model_name_or_path"),RFa.forEach(t),pCt=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CRe=n(Ex,"CODE",{});var PFa=s(CRe);_Ct=r(PFa,"pretrained_model_name_or_path"),PFa.forEach(t),bCt=r(Ex,":"),Ex.forEach(t),vCt=i(sd),aB=n(sd,"UL",{});var oso=s(aB);D8=n(oso,"LI",{});var Too=s(D8);wRe=n(Too,"STRONG",{});var BFa=s(wRe);FCt=r(BFa,"beit"),BFa.forEach(t),TCt=r(Too," \u2014 "),Oie=n(Too,"A",{href:!0});var IFa=s(Oie);MCt=r(IFa,"FlaxBeitForImageClassification"),IFa.forEach(t),ECt=r(Too," (BEiT model)"),Too.forEach(t),CCt=i(oso),G8=n(oso,"LI",{});var Moo=s(G8);ARe=n(Moo,"STRONG",{});var NFa=s(ARe);wCt=r(NFa,"vit"),NFa.forEach(t),ACt=r(Moo," \u2014 "),Vie=n(Moo,"A",{href:!0});var qFa=s(Vie);LCt=r(qFa,"FlaxViTForImageClassification"),qFa.forEach(t),yCt=r(Moo," (ViT model)"),Moo.forEach(t),oso.forEach(t),xCt=i(sd),T(O8.$$.fragment,sd),sd.forEach(t),nd.forEach(t),Nto=i(m),Lf=n(m,"H2",{class:!0});var rso=s(Lf);V8=n(rso,"A",{id:!0,class:!0,href:!0});var jFa=s(V8);LRe=n(jFa,"SPAN",{});var DFa=s(LRe);T(nB.$$.fragment,DFa),DFa.forEach(t),jFa.forEach(t),$Ct=i(rso),yRe=n(rso,"SPAN",{});var GFa=s(yRe);kCt=r(GFa,"FlaxAutoModelForVision2Seq"),GFa.forEach(t),rso.forEach(t),qto=i(m),Br=n(m,"DIV",{class:!0});var ld=s(Br);T(sB.$$.fragment,ld),SCt=i(ld),yf=n(ld,"P",{});var Zce=s(yf);RCt=r(Zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Xie=n(Zce,"A",{href:!0});var OFa=s(Xie);PCt=r(OFa,"from_pretrained()"),OFa.forEach(t),BCt=r(Zce," class method or the "),zie=n(Zce,"A",{href:!0});var VFa=s(zie);ICt=r(VFa,"from_config()"),VFa.forEach(t),NCt=r(Zce,` class
method.`),Zce.forEach(t),qCt=i(ld),lB=n(ld,"P",{});var tso=s(lB);jCt=r(tso,"This class cannot be instantiated directly using "),xRe=n(tso,"CODE",{});var XFa=s(xRe);DCt=r(XFa,"__init__()"),XFa.forEach(t),GCt=r(tso," (throws an error)."),tso.forEach(t),OCt=i(ld),Fa=n(ld,"DIV",{class:!0});var Cx=s(Fa);T(iB.$$.fragment,Cx),VCt=i(Cx),$Re=n(Cx,"P",{});var zFa=s($Re);XCt=r(zFa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zFa.forEach(t),zCt=i(Cx),xf=n(Cx,"P",{});var Kce=s(xf);QCt=r(Kce,`Note:
Loading a model from its configuration file does `),kRe=n(Kce,"STRONG",{});var QFa=s(kRe);WCt=r(QFa,"not"),QFa.forEach(t),UCt=r(Kce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qie=n(Kce,"A",{href:!0});var WFa=s(Qie);HCt=r(WFa,"from_pretrained()"),WFa.forEach(t),JCt=r(Kce," to load the model weights."),Kce.forEach(t),YCt=i(Cx),T(X8.$$.fragment,Cx),Cx.forEach(t),ZCt=i(ld),mt=n(ld,"DIV",{class:!0});var id=s(mt);T(dB.$$.fragment,id),KCt=i(id),SRe=n(id,"P",{});var UFa=s(SRe);e3t=r(UFa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),UFa.forEach(t),o3t=i(id),ts=n(id,"P",{});var wx=s(ts);r3t=r(wx,"The model class to instantiate is selected based on the "),RRe=n(wx,"CODE",{});var HFa=s(RRe);t3t=r(HFa,"model_type"),HFa.forEach(t),a3t=r(wx,` property of the config object (either
passed as an argument or loaded from `),PRe=n(wx,"CODE",{});var JFa=s(PRe);n3t=r(JFa,"pretrained_model_name_or_path"),JFa.forEach(t),s3t=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BRe=n(wx,"CODE",{});var YFa=s(BRe);l3t=r(YFa,"pretrained_model_name_or_path"),YFa.forEach(t),i3t=r(wx,":"),wx.forEach(t),d3t=i(id),IRe=n(id,"UL",{});var ZFa=s(IRe);z8=n(ZFa,"LI",{});var Eoo=s(z8);NRe=n(Eoo,"STRONG",{});var KFa=s(NRe);c3t=r(KFa,"vision-encoder-decoder"),KFa.forEach(t),m3t=r(Eoo," \u2014 "),Wie=n(Eoo,"A",{href:!0});var eTa=s(Wie);f3t=r(eTa,"FlaxVisionEncoderDecoderModel"),eTa.forEach(t),g3t=r(Eoo," (Vision Encoder decoder model)"),Eoo.forEach(t),ZFa.forEach(t),h3t=i(id),T(Q8.$$.fragment,id),id.forEach(t),ld.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(pEa)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(ns,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(ls,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(is,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(ud,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(Nf,"id","extending-the-auto-classes"),c(Nf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nf,"href","#extending-the-auto-classes"),c(pd,"class","relative group"),c(jf,"id","transformers.AutoConfig"),c(jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jf,"href","#transformers.AutoConfig"),c(_d,"class","relative group"),c(GI,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(OI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(VI,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(XI,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(zI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(QI,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(WI,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(UI,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(HI,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(JI,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(YI,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(ZI,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c(KI,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(eN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(oN,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),c(rN,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),c(tN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(aN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(nN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(sN,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(lN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(iN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(dN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(cN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c(mN,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(fN,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(gN,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(hN,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(uN,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(pN,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c(_N,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),c(bN,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(vN,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(FN,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(TN,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(MN,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),c(EN,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),c(CN,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(wN,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(AN,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(LN,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(yN,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(xN,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c($N,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(kN,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(SN,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(RN,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),c(PN,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c(BN,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),c(IN,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(NN,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(qN,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(jN,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(DN,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(GN,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(ON,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(VN,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(XN,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c(zN,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(QN,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(WN,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(UN,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(HN,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(JN,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),c(YN,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(ZN,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(KN,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(eq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(oq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(rq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(tq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(aq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(nq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),c(sq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(lq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(iq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(dq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(cq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),c(mq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(fq,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(gq,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(hq,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(uq,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(pq,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(_q,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(bq,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(vq,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(Fq,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(Tq,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c(Mq,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(Eq,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(Cq,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(wq,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(Aq,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(Lq,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(yq,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(xq,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c($q,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(kq,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(Sq,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(Rq,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(Pq,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(Bq,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(Iq,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),c(Nq,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(qq,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(jq,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),c(Dq,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(Gq,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(Oq,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(Vq,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(Xq,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(zq,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(Qq,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),c(Wq,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(Uq,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(Hq,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(Jq,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(Yq,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c(Zq,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(Kq,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),c(ej,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(oj,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(rj,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(tj,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),c(aj,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),c(nj,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(sj,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(lj,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(ij,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(dj,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(cj,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(mj,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(fj,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gu,"id","transformers.AutoTokenizer"),c(gu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gu,"href","#transformers.AutoTokenizer"),c(vd,"class","relative group"),c(gj,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(hj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(uj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(pj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(_j,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(bj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(vj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(Fj,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(Tj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Mj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Ej,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(Cj,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(wj,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(Aj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(Lj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(yj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(xj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c($j,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(kj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(Sj,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(Rj,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(Pj,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(Bj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(Ij,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(Nj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(qj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(jj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Dj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Gj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(Oj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(Vj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(Xj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(zj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(Qj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(Wj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Uj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Hj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(Jj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(Yj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(Zj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(Kj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(eD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(oD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(rD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(tD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(aD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(nD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(sD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(lD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(iD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(dD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(cD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(mD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(fD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(gD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(hD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(uD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(pD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(_D,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(bD,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),c(vD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(FD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(TD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(MD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(ED,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(CD,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(wD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(AD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(LD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(yD,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(xD,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c($D,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(kD,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(SD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(RD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(PD,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(BD,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(ID,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(ND,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(qD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(jD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(DD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(GD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(OD,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(VD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(XD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(zD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(QD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(WD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(UD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(HD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(JD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(YD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(ZD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(KD,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(eG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(oG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(rG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(tG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(aG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(nG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(sG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),c(lG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(iG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(dG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(cG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),c(mG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(fG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(gG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(hG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(uG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(pG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(_G,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(bG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(vG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(FG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(TG,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(MG,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(EG,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(CG,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(wG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(AG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(LG,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(yG,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(xG,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c($G,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(kG,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(SG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(RG,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(PG,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(BG,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(IG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(NG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(jG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(DG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(GG,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(OG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(VG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(XG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(zG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(QG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(WG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(UG,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(HG,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c(JG,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(YG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(ZG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(KG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(eO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(oO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(rO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(tO,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(aO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),c(nO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(sO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(lO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(iO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(dO,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(cO,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(mO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(fO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(gO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(hO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(uO,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(pO,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(_O,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(bO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ju,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yu,"id","transformers.AutoFeatureExtractor"),c(Yu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yu,"href","#transformers.AutoFeatureExtractor"),c(Fd,"class","relative group"),c(vO,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(FO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(TO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(MO,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),c(EO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(CO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(wO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(AO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(LO,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),c(yO,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(xO,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c($O,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(kO,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(SO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(RO,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(PO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(BO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IO,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(NO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(qO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(jO,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(DO,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(GO,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(OO,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(VO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(XO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(zO,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(QO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(WO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(UO,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(HO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(JO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(YO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(ZO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(KO,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(eV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(oV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(rV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(tV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(aV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(nV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(sV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),c(lV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(iV,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xp,"id","transformers.AutoProcessor"),c(Xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xp,"href","#transformers.AutoProcessor"),c(Td,"class","relative group"),c(dV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(cV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(mV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),c(fV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),c(gV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(hV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(uV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(pV,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(_V,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),c(bV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(vV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(FV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(TV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(MV,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(EV,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(CV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(wV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(AV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(LV,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(yV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(xV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c($V,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(kV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),c(SV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(__,"id","transformers.AutoModel"),c(__,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(__,"href","#transformers.AutoModel"),c(Ed,"class","relative group"),c(RV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BV,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(NV,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(qV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(jV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(DV,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(GV,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(OV,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(VV,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(XV,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(zV,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(QV,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(WV,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(UV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(HV,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),c(JV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),c(YV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c(ZV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(KV,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(eX,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(oX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(rX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(tX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(aX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(nX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(sX,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(lX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),c(iX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(dX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(cX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c(mX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),c(fX,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(gX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(hX,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(uX,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),c(pX,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),c(_X,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(bX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(vX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(FX,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(TX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(MX,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(EX,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c(CX,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(wX,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(AX,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(LX,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),c(yX,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(xX,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),c($X,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(kX,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(SX,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(RX,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(PX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(BX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(IX,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(NX,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(qX,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(jX,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(DX,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(GX,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(OX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(VX,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(XX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),c(zX,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(QX,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(WX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(UX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(HX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(JX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),c(YX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(ZX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(KX,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),c(ez,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c(oz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(rz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(tz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(az,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(nz,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),c(sz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(lz,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),c(iz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(dz,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(cz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(mz,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(fz,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(gz,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(hz,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(uz,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(pz,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(_z,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(bz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(vz,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(Fz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(Tz,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c(Mz,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(Ez,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Cz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(wz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Az,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(Lz,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),c(yz,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(xz,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c($z,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),c(kz,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(Sz,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Rz,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Pz,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Bz,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(Iz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),c(Nz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(qz,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(jz,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Dz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(Gz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Oz,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),c(Vz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Xz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(zz,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(Qz,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),c(Wz,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),c(Uz,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c(Hz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(Jz,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Yz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Zz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Kz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(eQ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(oQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j2,"id","transformers.AutoModelForPreTraining"),c(j2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j2,"href","#transformers.AutoModelForPreTraining"),c(Ad,"class","relative group"),c(rQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(sQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(lQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(iQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(dQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(cQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(mQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(fQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(gQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(hQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(uQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(pQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(_Q,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(bQ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(vQ,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(FQ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(TQ,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(MQ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(EQ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(CQ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(wQ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(AQ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(LQ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(yQ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($Q,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(RQ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(PQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(BQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(IQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(NQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(qQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(jQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(DQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(GQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(OQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(VQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(XQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(zQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(QQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(WQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(UQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(HQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(JQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(YQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(ZQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nb,"id","transformers.AutoModelForCausalLM"),c(Nb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nb,"href","#transformers.AutoModelForCausalLM"),c(xd,"class","relative group"),c(KQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(tW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c(aW,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(nW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(sW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(lW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(iW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(dW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(cW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(mW,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(fW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(gW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(hW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(uW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(pW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(_W,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(bW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(vW,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),c(FW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(TW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(MW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(EW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(CW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),c(wW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(AW,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(LW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(yW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(xW,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c($W,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(kW,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(SW,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(RW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(PW,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(BW,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(IW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(NW,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(qW,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(jW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(DW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(GW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(OW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(VW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xv,"id","transformers.AutoModelForMaskedLM"),c(xv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xv,"href","#transformers.AutoModelForMaskedLM"),c(Sd,"class","relative group"),c(XW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(UW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(HW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(JW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(YW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(ZW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(KW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(eU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(oU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(rU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(tU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(aU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(nU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(sU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(lU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(iU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(dU,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(cU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(mU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(fU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(gU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(hU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(uU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(pU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(_U,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(bU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(vU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(FU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(TU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(MU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(EU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(CU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(wU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(AU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(LU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(yU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(xU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c($U,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bF,"id","transformers.AutoModelForSeq2SeqLM"),c(bF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bF,"href","#transformers.AutoModelForSeq2SeqLM"),c(Bd,"class","relative group"),c(kU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(BU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(IU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(NU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(qU,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(jU,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(DU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(GU,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(OU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(VU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c(XU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(zU,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(QU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(WU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(UU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(HU,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(JU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(YU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(ZU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(KU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OF,"id","transformers.AutoModelForSequenceClassification"),c(OF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OF,"href","#transformers.AutoModelForSequenceClassification"),c(qd,"class","relative group"),c(eH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(aH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c(nH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(sH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(lH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(iH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(dH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(cH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(mH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(fH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(gH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(hH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(uH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(pH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(_H,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(bH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(vH,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),c(FH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(TH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(MH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(EH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(CH,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(wH,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(AH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(LH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(yH,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(xH,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c($H,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(kH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(SH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(RH,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),c(PH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(BH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(IH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(NH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(qH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(jH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(DH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(GH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(OH,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(VH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(XH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(zH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(QH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(WH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(UH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(HH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(JH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(YH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(ZH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(KH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(eJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(oJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(rJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(tJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WT,"id","transformers.AutoModelForMultipleChoice"),c(WT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WT,"href","#transformers.AutoModelForMultipleChoice"),c(Gd,"class","relative group"),c(aJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(iJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(dJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(cJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(mJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(fJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(gJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(hJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(uJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(pJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(_J,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(bJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(vJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(FJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(TJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(MJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(EJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(CJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(wJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(AJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(LJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(yJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(xJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c($J,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(kJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(SJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(RJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(PJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(BJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(IJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(NJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(qJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xM,"id","transformers.AutoModelForNextSentencePrediction"),c(xM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xM,"href","#transformers.AutoModelForNextSentencePrediction"),c(Xd,"class","relative group"),c(jJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(VJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(XJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(zJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(QJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(WJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(UJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DM,"id","transformers.AutoModelForTokenClassification"),c(DM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DM,"href","#transformers.AutoModelForTokenClassification"),c(Wd,"class","relative group"),c(HJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(KJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(eY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(oY,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(rY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(tY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(aY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(nY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(sY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(lY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(iY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(dY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(cY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(mY,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),c(fY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(gY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(hY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(uY,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(pY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(_Y,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(bY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(vY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(FY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(TY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),c(MY,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),c(EY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(CY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(wY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(AY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(LY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(yY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(xY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c($Y,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(kY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(SY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(RY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(PY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(BY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(IY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(NY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($E,"id","transformers.AutoModelForQuestionAnswering"),c($E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($E,"href","#transformers.AutoModelForQuestionAnswering"),c(Jd,"class","relative group"),c(qY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(OY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(VY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(XY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(zY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(QY,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),c(WY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(UY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(HY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(JY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(YY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(ZY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(KY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(eZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(oZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(rZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(tZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(aZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(nZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(sZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(lZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(iZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(dZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(cZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(mZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(fZ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(gZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),c(hZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(uZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(pZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(_Z,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(bZ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(vZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(FZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(TZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),c(MZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(EZ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(CZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(wZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(AZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(LZ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(yZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(xZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c($Z,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(kZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(SZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(RZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L4,"id","transformers.AutoModelForTableQuestionAnswering"),c(L4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L4,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Kd,"class","relative group"),c(PZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NZ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S4,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(S4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S4,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(rc,"class","relative group"),c(qZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(OZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(VZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j4,"id","transformers.AutoModelForImageClassification"),c(j4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j4,"href","#transformers.AutoModelForImageClassification"),c(sc,"class","relative group"),c(XZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WZ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(UZ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(HZ,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(JZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(YZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(ZZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(KZ,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(eK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(oK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(rK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(tK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(aK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(nK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(sK,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(lK,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(iK,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(dK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(cK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(mK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(fK,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(gK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(hK,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aC,"id","transformers.AutoModelForVideoClassification"),c(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aC,"href","#transformers.AutoModelForVideoClassification"),c(dc,"class","relative group"),c(uK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bK,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dC,"id","transformers.AutoModelForVision2Seq"),c(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dC,"href","#transformers.AutoModelForVision2Seq"),c(fc,"class","relative group"),c(vK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MK,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hC,"id","transformers.AutoModelForVisualQuestionAnswering"),c(hC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hC,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(uc,"class","relative group"),c(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AK,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vC,"id","transformers.AutoModelForAudioClassification"),c(vC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vC,"href","#transformers.AutoModelForAudioClassification"),c(bc,"class","relative group"),c(LK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($K,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(kK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(SK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(RK,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(PK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(BK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(IK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(NK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(qK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SC,"id","transformers.AutoModelForAudioFrameClassification"),c(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SC,"href","#transformers.AutoModelForAudioFrameClassification"),c(Tc,"class","relative group"),c(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(VK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(XK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(zK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(QK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GC,"id","transformers.AutoModelForCTC"),c(GC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GC,"href","#transformers.AutoModelForCTC"),c(Cc,"class","relative group"),c(WK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(YK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(ZK,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(KK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(eee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(oee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(ree,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(tee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(aee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(nee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o3,"id","transformers.AutoModelForSpeechSeq2Seq"),c(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o3,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Lc,"class","relative group"),c(see,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dee,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(cee,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(mee,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i3,"id","transformers.AutoModelForAudioXVector"),c(i3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i3,"href","#transformers.AutoModelForAudioXVector"),c(kc,"class","relative group"),c(fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(pee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(_ee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(bee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(vee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_3,"id","transformers.AutoModelForMaskedImageModeling"),c(_3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_3,"href","#transformers.AutoModelForMaskedImageModeling"),c(Pc,"class","relative group"),c(Fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(Cee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(wee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(Aee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w3,"id","transformers.AutoModelForObjectDetection"),c(w3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w3,"href","#transformers.AutoModelForObjectDetection"),c(Nc,"class","relative group"),c(Lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($ee,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),c(kee,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),c(See,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Ree,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R3,"id","transformers.AutoModelForImageSegmentation"),c(R3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R3,"href","#transformers.AutoModelForImageSegmentation"),c(Dc,"class","relative group"),c(Pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nee,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q3,"id","transformers.AutoModelForSemanticSegmentation"),c(q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q3,"href","#transformers.AutoModelForSemanticSegmentation"),c(Vc,"class","relative group"),c(qee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gee,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(Oee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(Vee,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(Xee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(zee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W3,"id","transformers.AutoModelForInstanceSegmentation"),c(W3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W3,"href","#transformers.AutoModelForInstanceSegmentation"),c(Qc,"class","relative group"),c(Qee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hee,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z3,"id","transformers.AutoModelForZeroShotObjectDetection"),c(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z3,"href","#transformers.AutoModelForZeroShotObjectDetection"),c(Hc,"class","relative group"),c(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kee,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t5,"id","transformers.TFAutoModel"),c(t5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t5,"href","#transformers.TFAutoModel"),c(Zc,"class","relative group"),c(eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(toe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(aoe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(noe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(soe,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(loe,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(ioe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(doe,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(coe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(moe,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(foe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(goe,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),c(hoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(uoe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(poe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(_oe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),c(boe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(voe,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(Foe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(Toe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(Moe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(Eoe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(Coe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(woe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(Aoe,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),c(Loe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(yoe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(xoe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c($oe,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(koe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c(Soe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Roe,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(Poe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(Boe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(Ioe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(Noe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(qoe,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(joe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Doe,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c(Goe,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(Ooe,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),c(Voe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(Xoe,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),c(zoe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(Qoe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(Woe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),c(Uoe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(Hoe,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(Joe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(Yoe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(Zoe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(Koe,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(ere,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(ore,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(rre,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),c(tre,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),c(are,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(nre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(sre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i0,"id","transformers.TFAutoModelForPreTraining"),c(i0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i0,"href","#transformers.TFAutoModelForPreTraining"),c(om,"class","relative group"),c(lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(mre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(fre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(gre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(ure,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(pre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(_re,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(bre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(vre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Fre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Tre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(Mre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(Ere,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Cre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(wre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Are,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Lre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(yre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(xre,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c($re,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(kre,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P0,"id","transformers.TFAutoModelForCausalLM"),c(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P0,"href","#transformers.TFAutoModelForCausalLM"),c(am,"class","relative group"),c(Rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ire,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(Nre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(qre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(jre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Dre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Gre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Ore,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Vre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Xre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(zre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(Qre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Wre,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Ure,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Hre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y0,"id","transformers.TFAutoModelForImageClassification"),c(Y0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y0,"href","#transformers.TFAutoModelForImageClassification"),c(lm,"class","relative group"),c(Jre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(ete,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),c(ote,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(rte,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(tte,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(ate,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(nte,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(ste,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(lte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(ite,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(dte,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dw,"id","transformers.TFAutoModelForSemanticSegmentation"),c(dw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dw,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(cm,"class","relative group"),c(cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(hte,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(ute,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uw,"id","transformers.TFAutoModelForMaskedLM"),c(uw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uw,"href","#transformers.TFAutoModelForMaskedLM"),c(hm,"class","relative group"),c(pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(Fte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(Tte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(Mte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(Ete,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(Cte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(wte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(Ate,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(Lte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(yte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(xte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c($te,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(kte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(Ste,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Rte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Pte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Bte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(Ite,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Nte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(qte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qw,"id","transformers.TFAutoModelForSeq2SeqLM"),c(qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qw,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(_m,"class","relative group"),c(jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ote,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Vte,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Xte,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(zte,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(Qte,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(Wte,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(Ute,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Hte,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Jte,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Yte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yw,"id","transformers.TFAutoModelForSequenceClassification"),c(Yw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yw,"href","#transformers.TFAutoModelForSequenceClassification"),c(Fm,"class","relative group"),c(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(rae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(tae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(aae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(nae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(sae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(lae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(iae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(dae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(cae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(mae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(fae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(gae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(hae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(uae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(pae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(_ae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(bae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(vae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(Fae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(Tae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(Mae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(Eae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(Cae,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(wae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(Aae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(Lae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LA,"id","transformers.TFAutoModelForMultipleChoice"),c(LA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LA,"href","#transformers.TFAutoModelForMultipleChoice"),c(Em,"class","relative group"),c(yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(Sae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Rae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Pae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Bae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(Iae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(Nae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(qae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(jae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(Dae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Gae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Oae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Vae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Xae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(zae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(Qae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(Wae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WA,"id","transformers.TFAutoModelForNextSentencePrediction"),c(WA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WA,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Am,"class","relative group"),c(Uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Zae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZA,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(ZA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZA,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(xm,"class","relative group"),c(Kae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(one,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Sm,"class","relative group"),c(tne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ane,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s6,"id","transformers.TFAutoModelForTokenClassification"),c(s6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s6,"href","#transformers.TFAutoModelForTokenClassification"),c(Bm,"class","relative group"),c(lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ine,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(mne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(fne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(gne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(hne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(une,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(pne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(_ne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(bne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(vne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(Fne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Tne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(Mne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Ene,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Cne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(wne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(Ane,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Lne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(yne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(xne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c($ne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($6,"id","transformers.TFAutoModelForQuestionAnswering"),c($6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($6,"href","#transformers.TFAutoModelForQuestionAnswering"),c(qm,"class","relative group"),c(kne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Sne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Bne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Ine,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Nne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(qne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(jne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Dne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Gne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(One,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Vne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Xne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(zne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(Qne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(Wne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Une,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(Hne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(Jne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Yne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Zne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(Kne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(ese,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e7,"id","transformers.TFAutoModelForVision2Seq"),c(e7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e7,"href","#transformers.TFAutoModelForVision2Seq"),c(Gm,"class","relative group"),c(ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ase,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(a7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Xm,"class","relative group"),c(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ise,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(dse,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d7,"id","transformers.FlaxAutoModel"),c(d7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d7,"href","#transformers.FlaxAutoModel"),c(Wm,"class","relative group"),c(cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(hse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(use,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(pse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(_se,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(bse,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(vse,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(Fse,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(Tse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Mse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(Ese,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Cse,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(wse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Ase,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(Lse,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(yse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(xse,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c($se,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(kse,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Sse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Rse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Pse,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(Bse,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Ise,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(Nse,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(qse,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(jse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j7,"id","transformers.FlaxAutoModelForCausalLM"),c(j7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j7,"href","#transformers.FlaxAutoModelForCausalLM"),c(Jm,"class","relative group"),c(Dse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Xse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(zse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Qse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(Wse,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(Use,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Hse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Jse,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(Yse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Zse,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z7,"id","transformers.FlaxAutoModelForPreTraining"),c(Z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z7,"href","#transformers.FlaxAutoModelForPreTraining"),c(Km,"class","relative group"),c(Kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(tle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ale,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(nle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(sle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(lle,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(ile,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(dle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(cle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(mle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(fle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(gle,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(hle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hL,"id","transformers.FlaxAutoModelForMaskedLM"),c(hL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hL,"href","#transformers.FlaxAutoModelForMaskedLM"),c(rf,"class","relative group"),c(ule,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ble,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(vle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Fle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Tle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Mle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Ele,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Cle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(wle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Ale,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Lle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(LL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(nf,"class","relative group"),c(yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Sle,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Rle,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Ple,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Ble,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Ile,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Nle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(qle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(jle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Dle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DL,"id","transformers.FlaxAutoModelForSequenceClassification"),c(DL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DL,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(df,"class","relative group"),c(Gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(zle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Qle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Wle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Ule,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Hle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Jle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Yle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Zle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Kle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KL,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(KL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(ff,"class","relative group"),c(eie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(aie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(nie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(sie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(lie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(iie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(die,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(cie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(mie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(fie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f8,"id","transformers.FlaxAutoModelForTokenClassification"),c(f8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f8,"href","#transformers.FlaxAutoModelForTokenClassification"),c(uf,"class","relative group"),c(gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(_ie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(bie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(vie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Fie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Tie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Mie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Eie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E8,"id","transformers.FlaxAutoModelForMultipleChoice"),c(E8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E8,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(bf,"class","relative group"),c(Cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(yie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(xie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c($ie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(kie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Sie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Rie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Pie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P8,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(P8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P8,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Tf,"class","relative group"),c(Bie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q8,"id","transformers.FlaxAutoModelForImageClassification"),c(q8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q8,"href","#transformers.FlaxAutoModelForImageClassification"),c(Cf,"class","relative group"),c(jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oie,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Vie,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V8,"id","transformers.FlaxAutoModelForVision2Seq"),c(V8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V8,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Lf,"class","relative group"),c(Xie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wie,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,xo),e(xo,dd),b(m,Rf,_),b(m,bt,_),e(bt,cd),e(bt,md),e(md,Ax),e(bt,Pf),b(m,Xe,_),b(m,He,_),e(He,fd),e(He,ns),e(ns,Lx),e(He,ss),e(He,ls),e(ls,yx),e(He,gd),e(He,is),e(is,xx),e(He,hd),b(m,Bf,_),M(Ja,m,_),b(m,Je,_),b(m,Ae,_),e(Ae,BI),e(Ae,ud),e(ud,II),e(Ae,NI),b(m,$o,_),b(m,Ya,_),e(Ya,qI),e(Ya,If),e(If,jI),e(Ya,aso),b(m,Coo,_),b(m,pd,_),e(pd,Nf),e(Nf,eme),M($x,eme,null),e(pd,nso),e(pd,ome),e(ome,sso),b(m,woo,_),b(m,ds,_),e(ds,lso),e(ds,rme),e(rme,iso),e(ds,dso),e(ds,tme),e(tme,cso),e(ds,mso),b(m,Aoo,_),M(kx,m,_),b(m,Loo,_),b(m,DI,_),e(DI,fso),b(m,yoo,_),M(qf,m,_),b(m,xoo,_),b(m,_d,_),e(_d,jf),e(jf,ame),M(Sx,ame,null),e(_d,gso),e(_d,nme),e(nme,hso),b(m,$oo,_),b(m,ko,_),M(Rx,ko,null),e(ko,uso),e(ko,Px),e(Px,pso),e(Px,GI),e(GI,_so),e(Px,bso),e(ko,vso),e(ko,Bx),e(Bx,Fso),e(Bx,sme),e(sme,Tso),e(Bx,Mso),e(ko,Eso),e(ko,Ir),M(Ix,Ir,null),e(Ir,Cso),e(Ir,lme),e(lme,wso),e(Ir,Aso),e(Ir,bd),e(bd,Lso),e(bd,ime),e(ime,yso),e(bd,xso),e(bd,dme),e(dme,$so),e(bd,kso),e(Ir,Sso),e(Ir,A),e(A,Df),e(Df,cme),e(cme,Rso),e(Df,Pso),e(Df,OI),e(OI,Bso),e(Df,Iso),e(A,Nso),e(A,Gf),e(Gf,mme),e(mme,qso),e(Gf,jso),e(Gf,VI),e(VI,Dso),e(Gf,Gso),e(A,Oso),e(A,Of),e(Of,fme),e(fme,Vso),e(Of,Xso),e(Of,XI),e(XI,zso),e(Of,Qso),e(A,Wso),e(A,Vf),e(Vf,gme),e(gme,Uso),e(Vf,Hso),e(Vf,zI),e(zI,Jso),e(Vf,Yso),e(A,Zso),e(A,Xf),e(Xf,hme),e(hme,Kso),e(Xf,elo),e(Xf,QI),e(QI,olo),e(Xf,rlo),e(A,tlo),e(A,zf),e(zf,ume),e(ume,alo),e(zf,nlo),e(zf,WI),e(WI,slo),e(zf,llo),e(A,ilo),e(A,Qf),e(Qf,pme),e(pme,dlo),e(Qf,clo),e(Qf,UI),e(UI,mlo),e(Qf,flo),e(A,glo),e(A,Wf),e(Wf,_me),e(_me,hlo),e(Wf,ulo),e(Wf,HI),e(HI,plo),e(Wf,_lo),e(A,blo),e(A,Uf),e(Uf,bme),e(bme,vlo),e(Uf,Flo),e(Uf,JI),e(JI,Tlo),e(Uf,Mlo),e(A,Elo),e(A,Hf),e(Hf,vme),e(vme,Clo),e(Hf,wlo),e(Hf,YI),e(YI,Alo),e(Hf,Llo),e(A,ylo),e(A,Jf),e(Jf,Fme),e(Fme,xlo),e(Jf,$lo),e(Jf,ZI),e(ZI,klo),e(Jf,Slo),e(A,Rlo),e(A,Yf),e(Yf,Tme),e(Tme,Plo),e(Yf,Blo),e(Yf,KI),e(KI,Ilo),e(Yf,Nlo),e(A,qlo),e(A,Zf),e(Zf,Mme),e(Mme,jlo),e(Zf,Dlo),e(Zf,eN),e(eN,Glo),e(Zf,Olo),e(A,Vlo),e(A,Kf),e(Kf,Eme),e(Eme,Xlo),e(Kf,zlo),e(Kf,oN),e(oN,Qlo),e(Kf,Wlo),e(A,Ulo),e(A,eg),e(eg,Cme),e(Cme,Hlo),e(eg,Jlo),e(eg,rN),e(rN,Ylo),e(eg,Zlo),e(A,Klo),e(A,og),e(og,wme),e(wme,eio),e(og,oio),e(og,tN),e(tN,rio),e(og,tio),e(A,aio),e(A,rg),e(rg,Ame),e(Ame,nio),e(rg,sio),e(rg,aN),e(aN,lio),e(rg,iio),e(A,dio),e(A,tg),e(tg,Lme),e(Lme,cio),e(tg,mio),e(tg,nN),e(nN,fio),e(tg,gio),e(A,hio),e(A,ag),e(ag,yme),e(yme,uio),e(ag,pio),e(ag,sN),e(sN,_io),e(ag,bio),e(A,vio),e(A,ng),e(ng,xme),e(xme,Fio),e(ng,Tio),e(ng,lN),e(lN,Mio),e(ng,Eio),e(A,Cio),e(A,sg),e(sg,$me),e($me,wio),e(sg,Aio),e(sg,iN),e(iN,Lio),e(sg,yio),e(A,xio),e(A,lg),e(lg,kme),e(kme,$io),e(lg,kio),e(lg,dN),e(dN,Sio),e(lg,Rio),e(A,Pio),e(A,ig),e(ig,Sme),e(Sme,Bio),e(ig,Iio),e(ig,cN),e(cN,Nio),e(ig,qio),e(A,jio),e(A,dg),e(dg,Rme),e(Rme,Dio),e(dg,Gio),e(dg,mN),e(mN,Oio),e(dg,Vio),e(A,Xio),e(A,cg),e(cg,Pme),e(Pme,zio),e(cg,Qio),e(cg,fN),e(fN,Wio),e(cg,Uio),e(A,Hio),e(A,mg),e(mg,Bme),e(Bme,Jio),e(mg,Yio),e(mg,gN),e(gN,Zio),e(mg,Kio),e(A,edo),e(A,fg),e(fg,Ime),e(Ime,odo),e(fg,rdo),e(fg,hN),e(hN,tdo),e(fg,ado),e(A,ndo),e(A,gg),e(gg,Nme),e(Nme,sdo),e(gg,ldo),e(gg,uN),e(uN,ido),e(gg,ddo),e(A,cdo),e(A,hg),e(hg,qme),e(qme,mdo),e(hg,fdo),e(hg,pN),e(pN,gdo),e(hg,hdo),e(A,udo),e(A,ug),e(ug,jme),e(jme,pdo),e(ug,_do),e(ug,_N),e(_N,bdo),e(ug,vdo),e(A,Fdo),e(A,pg),e(pg,Dme),e(Dme,Tdo),e(pg,Mdo),e(pg,bN),e(bN,Edo),e(pg,Cdo),e(A,wdo),e(A,_g),e(_g,Gme),e(Gme,Ado),e(_g,Ldo),e(_g,vN),e(vN,ydo),e(_g,xdo),e(A,$do),e(A,bg),e(bg,Ome),e(Ome,kdo),e(bg,Sdo),e(bg,FN),e(FN,Rdo),e(bg,Pdo),e(A,Bdo),e(A,vg),e(vg,Vme),e(Vme,Ido),e(vg,Ndo),e(vg,TN),e(TN,qdo),e(vg,jdo),e(A,Ddo),e(A,Fg),e(Fg,Xme),e(Xme,Gdo),e(Fg,Odo),e(Fg,MN),e(MN,Vdo),e(Fg,Xdo),e(A,zdo),e(A,Tg),e(Tg,zme),e(zme,Qdo),e(Tg,Wdo),e(Tg,EN),e(EN,Udo),e(Tg,Hdo),e(A,Jdo),e(A,Mg),e(Mg,Qme),e(Qme,Ydo),e(Mg,Zdo),e(Mg,CN),e(CN,Kdo),e(Mg,eco),e(A,oco),e(A,Eg),e(Eg,Wme),e(Wme,rco),e(Eg,tco),e(Eg,wN),e(wN,aco),e(Eg,nco),e(A,sco),e(A,Cg),e(Cg,Ume),e(Ume,lco),e(Cg,ico),e(Cg,AN),e(AN,dco),e(Cg,cco),e(A,mco),e(A,wg),e(wg,Hme),e(Hme,fco),e(wg,gco),e(wg,LN),e(LN,hco),e(wg,uco),e(A,pco),e(A,Ag),e(Ag,Jme),e(Jme,_co),e(Ag,bco),e(Ag,yN),e(yN,vco),e(Ag,Fco),e(A,Tco),e(A,Lg),e(Lg,Yme),e(Yme,Mco),e(Lg,Eco),e(Lg,xN),e(xN,Cco),e(Lg,wco),e(A,Aco),e(A,yg),e(yg,Zme),e(Zme,Lco),e(yg,yco),e(yg,$N),e($N,xco),e(yg,$co),e(A,kco),e(A,xg),e(xg,Kme),e(Kme,Sco),e(xg,Rco),e(xg,kN),e(kN,Pco),e(xg,Bco),e(A,Ico),e(A,$g),e($g,efe),e(efe,Nco),e($g,qco),e($g,SN),e(SN,jco),e($g,Dco),e(A,Gco),e(A,kg),e(kg,ofe),e(ofe,Oco),e(kg,Vco),e(kg,RN),e(RN,Xco),e(kg,zco),e(A,Qco),e(A,Sg),e(Sg,rfe),e(rfe,Wco),e(Sg,Uco),e(Sg,PN),e(PN,Hco),e(Sg,Jco),e(A,Yco),e(A,Rg),e(Rg,tfe),e(tfe,Zco),e(Rg,Kco),e(Rg,BN),e(BN,emo),e(Rg,omo),e(A,rmo),e(A,Pg),e(Pg,afe),e(afe,tmo),e(Pg,amo),e(Pg,IN),e(IN,nmo),e(Pg,smo),e(A,lmo),e(A,Bg),e(Bg,nfe),e(nfe,imo),e(Bg,dmo),e(Bg,NN),e(NN,cmo),e(Bg,mmo),e(A,fmo),e(A,Ig),e(Ig,sfe),e(sfe,gmo),e(Ig,hmo),e(Ig,qN),e(qN,umo),e(Ig,pmo),e(A,_mo),e(A,Ng),e(Ng,lfe),e(lfe,bmo),e(Ng,vmo),e(Ng,jN),e(jN,Fmo),e(Ng,Tmo),e(A,Mmo),e(A,qg),e(qg,ife),e(ife,Emo),e(qg,Cmo),e(qg,DN),e(DN,wmo),e(qg,Amo),e(A,Lmo),e(A,jg),e(jg,dfe),e(dfe,ymo),e(jg,xmo),e(jg,GN),e(GN,$mo),e(jg,kmo),e(A,Smo),e(A,Dg),e(Dg,cfe),e(cfe,Rmo),e(Dg,Pmo),e(Dg,ON),e(ON,Bmo),e(Dg,Imo),e(A,Nmo),e(A,Gg),e(Gg,mfe),e(mfe,qmo),e(Gg,jmo),e(Gg,VN),e(VN,Dmo),e(Gg,Gmo),e(A,Omo),e(A,Og),e(Og,ffe),e(ffe,Vmo),e(Og,Xmo),e(Og,XN),e(XN,zmo),e(Og,Qmo),e(A,Wmo),e(A,Vg),e(Vg,gfe),e(gfe,Umo),e(Vg,Hmo),e(Vg,zN),e(zN,Jmo),e(Vg,Ymo),e(A,Zmo),e(A,Xg),e(Xg,hfe),e(hfe,Kmo),e(Xg,efo),e(Xg,QN),e(QN,ofo),e(Xg,rfo),e(A,tfo),e(A,zg),e(zg,ufe),e(ufe,afo),e(zg,nfo),e(zg,WN),e(WN,sfo),e(zg,lfo),e(A,ifo),e(A,Qg),e(Qg,pfe),e(pfe,dfo),e(Qg,cfo),e(Qg,UN),e(UN,mfo),e(Qg,ffo),e(A,gfo),e(A,Wg),e(Wg,_fe),e(_fe,hfo),e(Wg,ufo),e(Wg,HN),e(HN,pfo),e(Wg,_fo),e(A,bfo),e(A,Ug),e(Ug,bfe),e(bfe,vfo),e(Ug,Ffo),e(Ug,JN),e(JN,Tfo),e(Ug,Mfo),e(A,Efo),e(A,Hg),e(Hg,vfe),e(vfe,Cfo),e(Hg,wfo),e(Hg,YN),e(YN,Afo),e(Hg,Lfo),e(A,yfo),e(A,Jg),e(Jg,Ffe),e(Ffe,xfo),e(Jg,$fo),e(Jg,ZN),e(ZN,kfo),e(Jg,Sfo),e(A,Rfo),e(A,Yg),e(Yg,Tfe),e(Tfe,Pfo),e(Yg,Bfo),e(Yg,KN),e(KN,Ifo),e(Yg,Nfo),e(A,qfo),e(A,Zg),e(Zg,Mfe),e(Mfe,jfo),e(Zg,Dfo),e(Zg,eq),e(eq,Gfo),e(Zg,Ofo),e(A,Vfo),e(A,Kg),e(Kg,Efe),e(Efe,Xfo),e(Kg,zfo),e(Kg,oq),e(oq,Qfo),e(Kg,Wfo),e(A,Ufo),e(A,eh),e(eh,Cfe),e(Cfe,Hfo),e(eh,Jfo),e(eh,rq),e(rq,Yfo),e(eh,Zfo),e(A,Kfo),e(A,oh),e(oh,wfe),e(wfe,ego),e(oh,ogo),e(oh,tq),e(tq,rgo),e(oh,tgo),e(A,ago),e(A,rh),e(rh,Afe),e(Afe,ngo),e(rh,sgo),e(rh,aq),e(aq,lgo),e(rh,igo),e(A,dgo),e(A,th),e(th,Lfe),e(Lfe,cgo),e(th,mgo),e(th,nq),e(nq,fgo),e(th,ggo),e(A,hgo),e(A,ah),e(ah,yfe),e(yfe,ugo),e(ah,pgo),e(ah,sq),e(sq,_go),e(ah,bgo),e(A,vgo),e(A,nh),e(nh,xfe),e(xfe,Fgo),e(nh,Tgo),e(nh,lq),e(lq,Mgo),e(nh,Ego),e(A,Cgo),e(A,sh),e(sh,$fe),e($fe,wgo),e(sh,Ago),e(sh,iq),e(iq,Lgo),e(sh,ygo),e(A,xgo),e(A,lh),e(lh,kfe),e(kfe,$go),e(lh,kgo),e(lh,dq),e(dq,Sgo),e(lh,Rgo),e(A,Pgo),e(A,ih),e(ih,Sfe),e(Sfe,Bgo),e(ih,Igo),e(ih,cq),e(cq,Ngo),e(ih,qgo),e(A,jgo),e(A,dh),e(dh,Rfe),e(Rfe,Dgo),e(dh,Ggo),e(dh,mq),e(mq,Ogo),e(dh,Vgo),e(A,Xgo),e(A,ch),e(ch,Pfe),e(Pfe,zgo),e(ch,Qgo),e(ch,fq),e(fq,Wgo),e(ch,Ugo),e(A,Hgo),e(A,mh),e(mh,Bfe),e(Bfe,Jgo),e(mh,Ygo),e(mh,gq),e(gq,Zgo),e(mh,Kgo),e(A,eho),e(A,fh),e(fh,Ife),e(Ife,oho),e(fh,rho),e(fh,hq),e(hq,tho),e(fh,aho),e(A,nho),e(A,gh),e(gh,Nfe),e(Nfe,sho),e(gh,lho),e(gh,uq),e(uq,iho),e(gh,dho),e(A,cho),e(A,hh),e(hh,qfe),e(qfe,mho),e(hh,fho),e(hh,pq),e(pq,gho),e(hh,hho),e(A,uho),e(A,uh),e(uh,jfe),e(jfe,pho),e(uh,_ho),e(uh,_q),e(_q,bho),e(uh,vho),e(A,Fho),e(A,ph),e(ph,Dfe),e(Dfe,Tho),e(ph,Mho),e(ph,bq),e(bq,Eho),e(ph,Cho),e(A,who),e(A,_h),e(_h,Gfe),e(Gfe,Aho),e(_h,Lho),e(_h,vq),e(vq,yho),e(_h,xho),e(A,$ho),e(A,bh),e(bh,Ofe),e(Ofe,kho),e(bh,Sho),e(bh,Fq),e(Fq,Rho),e(bh,Pho),e(A,Bho),e(A,vh),e(vh,Vfe),e(Vfe,Iho),e(vh,Nho),e(vh,Tq),e(Tq,qho),e(vh,jho),e(A,Dho),e(A,Fh),e(Fh,Xfe),e(Xfe,Gho),e(Fh,Oho),e(Fh,Mq),e(Mq,Vho),e(Fh,Xho),e(A,zho),e(A,Th),e(Th,zfe),e(zfe,Qho),e(Th,Who),e(Th,Eq),e(Eq,Uho),e(Th,Hho),e(A,Jho),e(A,Mh),e(Mh,Qfe),e(Qfe,Yho),e(Mh,Zho),e(Mh,Cq),e(Cq,Kho),e(Mh,euo),e(A,ouo),e(A,Eh),e(Eh,Wfe),e(Wfe,ruo),e(Eh,tuo),e(Eh,wq),e(wq,auo),e(Eh,nuo),e(A,suo),e(A,Ch),e(Ch,Ufe),e(Ufe,luo),e(Ch,iuo),e(Ch,Aq),e(Aq,duo),e(Ch,cuo),e(A,muo),e(A,wh),e(wh,Hfe),e(Hfe,fuo),e(wh,guo),e(wh,Lq),e(Lq,huo),e(wh,uuo),e(A,puo),e(A,Ah),e(Ah,Jfe),e(Jfe,_uo),e(Ah,buo),e(Ah,yq),e(yq,vuo),e(Ah,Fuo),e(A,Tuo),e(A,Lh),e(Lh,Yfe),e(Yfe,Muo),e(Lh,Euo),e(Lh,xq),e(xq,Cuo),e(Lh,wuo),e(A,Auo),e(A,yh),e(yh,Zfe),e(Zfe,Luo),e(yh,yuo),e(yh,$q),e($q,xuo),e(yh,$uo),e(A,kuo),e(A,xh),e(xh,Kfe),e(Kfe,Suo),e(xh,Ruo),e(xh,kq),e(kq,Puo),e(xh,Buo),e(A,Iuo),e(A,$h),e($h,ege),e(ege,Nuo),e($h,quo),e($h,Sq),e(Sq,juo),e($h,Duo),e(A,Guo),e(A,kh),e(kh,oge),e(oge,Ouo),e(kh,Vuo),e(kh,Rq),e(Rq,Xuo),e(kh,zuo),e(A,Quo),e(A,Sh),e(Sh,rge),e(rge,Wuo),e(Sh,Uuo),e(Sh,Pq),e(Pq,Huo),e(Sh,Juo),e(A,Yuo),e(A,Rh),e(Rh,tge),e(tge,Zuo),e(Rh,Kuo),e(Rh,Bq),e(Bq,epo),e(Rh,opo),e(A,rpo),e(A,Ph),e(Ph,age),e(age,tpo),e(Ph,apo),e(Ph,Iq),e(Iq,npo),e(Ph,spo),e(A,lpo),e(A,Bh),e(Bh,nge),e(nge,ipo),e(Bh,dpo),e(Bh,Nq),e(Nq,cpo),e(Bh,mpo),e(A,fpo),e(A,Ih),e(Ih,sge),e(sge,gpo),e(Ih,hpo),e(Ih,qq),e(qq,upo),e(Ih,ppo),e(A,_po),e(A,Nh),e(Nh,lge),e(lge,bpo),e(Nh,vpo),e(Nh,jq),e(jq,Fpo),e(Nh,Tpo),e(A,Mpo),e(A,qh),e(qh,ige),e(ige,Epo),e(qh,Cpo),e(qh,Dq),e(Dq,wpo),e(qh,Apo),e(A,Lpo),e(A,jh),e(jh,dge),e(dge,ypo),e(jh,xpo),e(jh,Gq),e(Gq,$po),e(jh,kpo),e(A,Spo),e(A,Dh),e(Dh,cge),e(cge,Rpo),e(Dh,Ppo),e(Dh,Oq),e(Oq,Bpo),e(Dh,Ipo),e(A,Npo),e(A,Gh),e(Gh,mge),e(mge,qpo),e(Gh,jpo),e(Gh,Vq),e(Vq,Dpo),e(Gh,Gpo),e(A,Opo),e(A,Oh),e(Oh,fge),e(fge,Vpo),e(Oh,Xpo),e(Oh,Xq),e(Xq,zpo),e(Oh,Qpo),e(A,Wpo),e(A,Vh),e(Vh,gge),e(gge,Upo),e(Vh,Hpo),e(Vh,zq),e(zq,Jpo),e(Vh,Ypo),e(A,Zpo),e(A,Xh),e(Xh,hge),e(hge,Kpo),e(Xh,e_o),e(Xh,Qq),e(Qq,o_o),e(Xh,r_o),e(A,t_o),e(A,zh),e(zh,uge),e(uge,a_o),e(zh,n_o),e(zh,Wq),e(Wq,s_o),e(zh,l_o),e(A,i_o),e(A,Qh),e(Qh,pge),e(pge,d_o),e(Qh,c_o),e(Qh,Uq),e(Uq,m_o),e(Qh,f_o),e(A,g_o),e(A,Wh),e(Wh,_ge),e(_ge,h_o),e(Wh,u_o),e(Wh,Hq),e(Hq,p_o),e(Wh,__o),e(A,b_o),e(A,Uh),e(Uh,bge),e(bge,v_o),e(Uh,F_o),e(Uh,Jq),e(Jq,T_o),e(Uh,M_o),e(A,E_o),e(A,Hh),e(Hh,vge),e(vge,C_o),e(Hh,w_o),e(Hh,Yq),e(Yq,A_o),e(Hh,L_o),e(A,y_o),e(A,Jh),e(Jh,Fge),e(Fge,x_o),e(Jh,$_o),e(Jh,Zq),e(Zq,k_o),e(Jh,S_o),e(A,R_o),e(A,Yh),e(Yh,Tge),e(Tge,P_o),e(Yh,B_o),e(Yh,Kq),e(Kq,I_o),e(Yh,N_o),e(A,q_o),e(A,Zh),e(Zh,Mge),e(Mge,j_o),e(Zh,D_o),e(Zh,ej),e(ej,G_o),e(Zh,O_o),e(A,V_o),e(A,Kh),e(Kh,Ege),e(Ege,X_o),e(Kh,z_o),e(Kh,oj),e(oj,Q_o),e(Kh,W_o),e(A,U_o),e(A,eu),e(eu,Cge),e(Cge,H_o),e(eu,J_o),e(eu,rj),e(rj,Y_o),e(eu,Z_o),e(A,K_o),e(A,ou),e(ou,wge),e(wge,e1o),e(ou,o1o),e(ou,tj),e(tj,r1o),e(ou,t1o),e(A,a1o),e(A,ru),e(ru,Age),e(Age,n1o),e(ru,s1o),e(ru,aj),e(aj,l1o),e(ru,i1o),e(A,d1o),e(A,tu),e(tu,Lge),e(Lge,c1o),e(tu,m1o),e(tu,nj),e(nj,f1o),e(tu,g1o),e(A,h1o),e(A,au),e(au,yge),e(yge,u1o),e(au,p1o),e(au,sj),e(sj,_1o),e(au,b1o),e(A,v1o),e(A,nu),e(nu,xge),e(xge,F1o),e(nu,T1o),e(nu,lj),e(lj,M1o),e(nu,E1o),e(A,C1o),e(A,su),e(su,$ge),e($ge,w1o),e(su,A1o),e(su,ij),e(ij,L1o),e(su,y1o),e(A,x1o),e(A,lu),e(lu,kge),e(kge,$1o),e(lu,k1o),e(lu,dj),e(dj,S1o),e(lu,R1o),e(A,P1o),e(A,iu),e(iu,Sge),e(Sge,B1o),e(iu,I1o),e(iu,cj),e(cj,N1o),e(iu,q1o),e(A,j1o),e(A,du),e(du,Rge),e(Rge,D1o),e(du,G1o),e(du,mj),e(mj,O1o),e(du,V1o),e(A,X1o),e(A,cu),e(cu,Pge),e(Pge,z1o),e(cu,Q1o),e(cu,fj),e(fj,W1o),e(cu,U1o),e(Ir,H1o),M(mu,Ir,null),e(ko,J1o),e(ko,fu),M(Nx,fu,null),e(fu,Y1o),e(fu,Bge),e(Bge,Z1o),b(m,koo,_),b(m,vd,_),e(vd,gu),e(gu,Ige),M(qx,Ige,null),e(vd,K1o),e(vd,Nge),e(Nge,e2o),b(m,Soo,_),b(m,So,_),M(jx,So,null),e(So,o2o),e(So,Dx),e(Dx,r2o),e(Dx,gj),e(gj,t2o),e(Dx,a2o),e(So,n2o),e(So,Gx),e(Gx,s2o),e(Gx,qge),e(qge,l2o),e(Gx,i2o),e(So,d2o),e(So,Nr),M(Ox,Nr,null),e(Nr,c2o),e(Nr,jge),e(jge,m2o),e(Nr,f2o),e(Nr,Za),e(Za,g2o),e(Za,Dge),e(Dge,h2o),e(Za,u2o),e(Za,Gge),e(Gge,p2o),e(Za,_2o),e(Za,Oge),e(Oge,b2o),e(Za,v2o),e(Nr,F2o),e(Nr,k),e(k,cs),e(cs,Vge),e(Vge,T2o),e(cs,M2o),e(cs,hj),e(hj,E2o),e(cs,C2o),e(cs,uj),e(uj,w2o),e(cs,A2o),e(k,L2o),e(k,ms),e(ms,Xge),e(Xge,y2o),e(ms,x2o),e(ms,pj),e(pj,$2o),e(ms,k2o),e(ms,_j),e(_j,S2o),e(ms,R2o),e(k,P2o),e(k,fs),e(fs,zge),e(zge,B2o),e(fs,I2o),e(fs,bj),e(bj,N2o),e(fs,q2o),e(fs,vj),e(vj,j2o),e(fs,D2o),e(k,G2o),e(k,hu),e(hu,Qge),e(Qge,O2o),e(hu,V2o),e(hu,Fj),e(Fj,X2o),e(hu,z2o),e(k,Q2o),e(k,gs),e(gs,Wge),e(Wge,W2o),e(gs,U2o),e(gs,Tj),e(Tj,H2o),e(gs,J2o),e(gs,Mj),e(Mj,Y2o),e(gs,Z2o),e(k,K2o),e(k,uu),e(uu,Uge),e(Uge,ebo),e(uu,obo),e(uu,Ej),e(Ej,rbo),e(uu,tbo),e(k,abo),e(k,pu),e(pu,Hge),e(Hge,nbo),e(pu,sbo),e(pu,Cj),e(Cj,lbo),e(pu,ibo),e(k,dbo),e(k,_u),e(_u,Jge),e(Jge,cbo),e(_u,mbo),e(_u,wj),e(wj,fbo),e(_u,gbo),e(k,hbo),e(k,hs),e(hs,Yge),e(Yge,ubo),e(hs,pbo),e(hs,Aj),e(Aj,_bo),e(hs,bbo),e(hs,Lj),e(Lj,vbo),e(hs,Fbo),e(k,Tbo),e(k,us),e(us,Zge),e(Zge,Mbo),e(us,Ebo),e(us,yj),e(yj,Cbo),e(us,wbo),e(us,xj),e(xj,Abo),e(us,Lbo),e(k,ybo),e(k,ps),e(ps,Kge),e(Kge,xbo),e(ps,$bo),e(ps,$j),e($j,kbo),e(ps,Sbo),e(ps,kj),e(kj,Rbo),e(ps,Pbo),e(k,Bbo),e(k,bu),e(bu,ehe),e(ehe,Ibo),e(bu,Nbo),e(bu,Sj),e(Sj,qbo),e(bu,jbo),e(k,Dbo),e(k,vu),e(vu,ohe),e(ohe,Gbo),e(vu,Obo),e(vu,Rj),e(Rj,Vbo),e(vu,Xbo),e(k,zbo),e(k,Fu),e(Fu,rhe),e(rhe,Qbo),e(Fu,Wbo),e(Fu,Pj),e(Pj,Ubo),e(Fu,Hbo),e(k,Jbo),e(k,_s),e(_s,the),e(the,Ybo),e(_s,Zbo),e(_s,Bj),e(Bj,Kbo),e(_s,evo),e(_s,Ij),e(Ij,ovo),e(_s,rvo),e(k,tvo),e(k,Tu),e(Tu,ahe),e(ahe,avo),e(Tu,nvo),e(Tu,Nj),e(Nj,svo),e(Tu,lvo),e(k,ivo),e(k,bs),e(bs,nhe),e(nhe,dvo),e(bs,cvo),e(bs,qj),e(qj,mvo),e(bs,fvo),e(bs,jj),e(jj,gvo),e(bs,hvo),e(k,uvo),e(k,vs),e(vs,she),e(she,pvo),e(vs,_vo),e(vs,Dj),e(Dj,bvo),e(vs,vvo),e(vs,Gj),e(Gj,Fvo),e(vs,Tvo),e(k,Mvo),e(k,Fs),e(Fs,lhe),e(lhe,Evo),e(Fs,Cvo),e(Fs,Oj),e(Oj,wvo),e(Fs,Avo),e(Fs,Vj),e(Vj,Lvo),e(Fs,yvo),e(k,xvo),e(k,Ts),e(Ts,ihe),e(ihe,$vo),e(Ts,kvo),e(Ts,Xj),e(Xj,Svo),e(Ts,Rvo),e(Ts,zj),e(zj,Pvo),e(Ts,Bvo),e(k,Ivo),e(k,Mu),e(Mu,dhe),e(dhe,Nvo),e(Mu,qvo),e(Mu,Qj),e(Qj,jvo),e(Mu,Dvo),e(k,Gvo),e(k,Ms),e(Ms,che),e(che,Ovo),e(Ms,Vvo),e(Ms,Wj),e(Wj,Xvo),e(Ms,zvo),e(Ms,Uj),e(Uj,Qvo),e(Ms,Wvo),e(k,Uvo),e(k,Es),e(Es,mhe),e(mhe,Hvo),e(Es,Jvo),e(Es,Hj),e(Hj,Yvo),e(Es,Zvo),e(Es,Jj),e(Jj,Kvo),e(Es,eFo),e(k,oFo),e(k,Cs),e(Cs,fhe),e(fhe,rFo),e(Cs,tFo),e(Cs,Yj),e(Yj,aFo),e(Cs,nFo),e(Cs,Zj),e(Zj,sFo),e(Cs,lFo),e(k,iFo),e(k,ws),e(ws,ghe),e(ghe,dFo),e(ws,cFo),e(ws,Kj),e(Kj,mFo),e(ws,fFo),e(ws,eD),e(eD,gFo),e(ws,hFo),e(k,uFo),e(k,As),e(As,hhe),e(hhe,pFo),e(As,_Fo),e(As,oD),e(oD,bFo),e(As,vFo),e(As,rD),e(rD,FFo),e(As,TFo),e(k,MFo),e(k,Ls),e(Ls,uhe),e(uhe,EFo),e(Ls,CFo),e(Ls,tD),e(tD,wFo),e(Ls,AFo),e(Ls,aD),e(aD,LFo),e(Ls,yFo),e(k,xFo),e(k,ys),e(ys,phe),e(phe,$Fo),e(ys,kFo),e(ys,nD),e(nD,SFo),e(ys,RFo),e(ys,sD),e(sD,PFo),e(ys,BFo),e(k,IFo),e(k,Eu),e(Eu,_he),e(_he,NFo),e(Eu,qFo),e(Eu,lD),e(lD,jFo),e(Eu,DFo),e(k,GFo),e(k,xs),e(xs,bhe),e(bhe,OFo),e(xs,VFo),e(xs,iD),e(iD,XFo),e(xs,zFo),e(xs,dD),e(dD,QFo),e(xs,WFo),e(k,UFo),e(k,Cu),e(Cu,vhe),e(vhe,HFo),e(Cu,JFo),e(Cu,cD),e(cD,YFo),e(Cu,ZFo),e(k,KFo),e(k,$s),e($s,Fhe),e(Fhe,eTo),e($s,oTo),e($s,mD),e(mD,rTo),e($s,tTo),e($s,fD),e(fD,aTo),e($s,nTo),e(k,sTo),e(k,ks),e(ks,The),e(The,lTo),e(ks,iTo),e(ks,gD),e(gD,dTo),e(ks,cTo),e(ks,hD),e(hD,mTo),e(ks,fTo),e(k,gTo),e(k,Ss),e(Ss,Mhe),e(Mhe,hTo),e(Ss,uTo),e(Ss,uD),e(uD,pTo),e(Ss,_To),e(Ss,pD),e(pD,bTo),e(Ss,vTo),e(k,FTo),e(k,wu),e(wu,Ehe),e(Ehe,TTo),e(wu,MTo),e(wu,_D),e(_D,ETo),e(wu,CTo),e(k,wTo),e(k,Au),e(Au,Che),e(Che,ATo),e(Au,LTo),e(Au,bD),e(bD,yTo),e(Au,xTo),e(k,$To),e(k,Rs),e(Rs,whe),e(whe,kTo),e(Rs,STo),e(Rs,vD),e(vD,RTo),e(Rs,PTo),e(Rs,FD),e(FD,BTo),e(Rs,ITo),e(k,NTo),e(k,Ps),e(Ps,Ahe),e(Ahe,qTo),e(Ps,jTo),e(Ps,TD),e(TD,DTo),e(Ps,GTo),e(Ps,MD),e(MD,OTo),e(Ps,VTo),e(k,XTo),e(k,Bs),e(Bs,Lhe),e(Lhe,zTo),e(Bs,QTo),e(Bs,ED),e(ED,WTo),e(Bs,UTo),e(Bs,CD),e(CD,HTo),e(Bs,JTo),e(k,YTo),e(k,Lu),e(Lu,yhe),e(yhe,ZTo),e(Lu,KTo),e(Lu,wD),e(wD,eMo),e(Lu,oMo),e(k,rMo),e(k,Is),e(Is,xhe),e(xhe,tMo),e(Is,aMo),e(Is,AD),e(AD,nMo),e(Is,sMo),e(Is,LD),e(LD,lMo),e(Is,iMo),e(k,dMo),e(k,Ns),e(Ns,$he),e($he,cMo),e(Ns,mMo),e(Ns,yD),e(yD,fMo),e(Ns,gMo),e(Ns,xD),e(xD,hMo),e(Ns,uMo),e(k,pMo),e(k,qs),e(qs,khe),e(khe,_Mo),e(qs,bMo),e(qs,$D),e($D,vMo),e(qs,FMo),e(qs,kD),e(kD,TMo),e(qs,MMo),e(k,EMo),e(k,js),e(js,She),e(She,CMo),e(js,wMo),e(js,SD),e(SD,AMo),e(js,LMo),e(js,RD),e(RD,yMo),e(js,xMo),e(k,$Mo),e(k,Ds),e(Ds,Rhe),e(Rhe,kMo),e(Ds,SMo),e(Ds,PD),e(PD,RMo),e(Ds,PMo),e(Ds,BD),e(BD,BMo),e(Ds,IMo),e(k,NMo),e(k,Gs),e(Gs,Phe),e(Phe,qMo),e(Gs,jMo),e(Gs,ID),e(ID,DMo),e(Gs,GMo),e(Gs,ND),e(ND,OMo),e(Gs,VMo),e(k,XMo),e(k,Os),e(Os,Bhe),e(Bhe,zMo),e(Os,QMo),e(Os,qD),e(qD,WMo),e(Os,UMo),e(Os,jD),e(jD,HMo),e(Os,JMo),e(k,YMo),e(k,Vs),e(Vs,Ihe),e(Ihe,ZMo),e(Vs,KMo),e(Vs,DD),e(DD,eEo),e(Vs,oEo),e(Vs,GD),e(GD,rEo),e(Vs,tEo),e(k,aEo),e(k,yu),e(yu,Nhe),e(Nhe,nEo),e(yu,sEo),e(yu,OD),e(OD,lEo),e(yu,iEo),e(k,dEo),e(k,Xs),e(Xs,qhe),e(qhe,cEo),e(Xs,mEo),e(Xs,VD),e(VD,fEo),e(Xs,gEo),e(Xs,XD),e(XD,hEo),e(Xs,uEo),e(k,pEo),e(k,xu),e(xu,jhe),e(jhe,_Eo),e(xu,bEo),e(xu,zD),e(zD,vEo),e(xu,FEo),e(k,TEo),e(k,$u),e($u,Dhe),e(Dhe,MEo),e($u,EEo),e($u,QD),e(QD,CEo),e($u,wEo),e(k,AEo),e(k,zs),e(zs,Ghe),e(Ghe,LEo),e(zs,yEo),e(zs,WD),e(WD,xEo),e(zs,$Eo),e(zs,UD),e(UD,kEo),e(zs,SEo),e(k,REo),e(k,Qs),e(Qs,Ohe),e(Ohe,PEo),e(Qs,BEo),e(Qs,HD),e(HD,IEo),e(Qs,NEo),e(Qs,JD),e(JD,qEo),e(Qs,jEo),e(k,DEo),e(k,Ws),e(Ws,Vhe),e(Vhe,GEo),e(Ws,OEo),e(Ws,YD),e(YD,VEo),e(Ws,XEo),e(Ws,ZD),e(ZD,zEo),e(Ws,QEo),e(k,WEo),e(k,ku),e(ku,Xhe),e(Xhe,UEo),e(ku,HEo),e(ku,KD),e(KD,JEo),e(ku,YEo),e(k,ZEo),e(k,Us),e(Us,zhe),e(zhe,KEo),e(Us,e4o),e(Us,eG),e(eG,o4o),e(Us,r4o),e(Us,oG),e(oG,t4o),e(Us,a4o),e(k,n4o),e(k,Hs),e(Hs,Qhe),e(Qhe,s4o),e(Hs,l4o),e(Hs,rG),e(rG,i4o),e(Hs,d4o),e(Hs,tG),e(tG,c4o),e(Hs,m4o),e(k,f4o),e(k,Js),e(Js,Whe),e(Whe,g4o),e(Js,h4o),e(Js,aG),e(aG,u4o),e(Js,p4o),e(Js,nG),e(nG,_4o),e(Js,b4o),e(k,v4o),e(k,Ys),e(Ys,Uhe),e(Uhe,F4o),e(Ys,T4o),e(Ys,sG),e(sG,M4o),e(Ys,E4o),e(Ys,lG),e(lG,C4o),e(Ys,w4o),e(k,A4o),e(k,Zs),e(Zs,Hhe),e(Hhe,L4o),e(Zs,y4o),e(Zs,iG),e(iG,x4o),e(Zs,$4o),e(Zs,dG),e(dG,k4o),e(Zs,S4o),e(k,R4o),e(k,Ks),e(Ks,Jhe),e(Jhe,P4o),e(Ks,B4o),e(Ks,cG),e(cG,I4o),e(Ks,N4o),e(Ks,mG),e(mG,q4o),e(Ks,j4o),e(k,D4o),e(k,el),e(el,Yhe),e(Yhe,G4o),e(el,O4o),e(el,fG),e(fG,V4o),e(el,X4o),e(el,gG),e(gG,z4o),e(el,Q4o),e(k,W4o),e(k,ol),e(ol,Zhe),e(Zhe,U4o),e(ol,H4o),e(ol,hG),e(hG,J4o),e(ol,Y4o),e(ol,uG),e(uG,Z4o),e(ol,K4o),e(k,eCo),e(k,Su),e(Su,Khe),e(Khe,oCo),e(Su,rCo),e(Su,pG),e(pG,tCo),e(Su,aCo),e(k,nCo),e(k,rl),e(rl,eue),e(eue,sCo),e(rl,lCo),e(rl,_G),e(_G,iCo),e(rl,dCo),e(rl,bG),e(bG,cCo),e(rl,mCo),e(k,fCo),e(k,tl),e(tl,oue),e(oue,gCo),e(tl,hCo),e(tl,vG),e(vG,uCo),e(tl,pCo),e(tl,FG),e(FG,_Co),e(tl,bCo),e(k,vCo),e(k,Ru),e(Ru,rue),e(rue,FCo),e(Ru,TCo),e(Ru,TG),e(TG,MCo),e(Ru,ECo),e(k,CCo),e(k,Pu),e(Pu,tue),e(tue,wCo),e(Pu,ACo),e(Pu,MG),e(MG,LCo),e(Pu,yCo),e(k,xCo),e(k,Bu),e(Bu,aue),e(aue,$Co),e(Bu,kCo),e(Bu,EG),e(EG,SCo),e(Bu,RCo),e(k,PCo),e(k,Iu),e(Iu,nue),e(nue,BCo),e(Iu,ICo),e(Iu,CG),e(CG,NCo),e(Iu,qCo),e(k,jCo),e(k,al),e(al,sue),e(sue,DCo),e(al,GCo),e(al,wG),e(wG,OCo),e(al,VCo),e(al,AG),e(AG,XCo),e(al,zCo),e(k,QCo),e(k,Nu),e(Nu,lue),e(lue,WCo),e(Nu,UCo),e(Nu,LG),e(LG,HCo),e(Nu,JCo),e(k,YCo),e(k,nl),e(nl,iue),e(iue,ZCo),e(nl,KCo),e(nl,yG),e(yG,e3o),e(nl,o3o),e(nl,xG),e(xG,r3o),e(nl,t3o),e(k,a3o),e(k,sl),e(sl,due),e(due,n3o),e(sl,s3o),e(sl,$G),e($G,l3o),e(sl,i3o),e(sl,kG),e(kG,d3o),e(sl,c3o),e(k,m3o),e(k,ll),e(ll,cue),e(cue,f3o),e(ll,g3o),e(ll,SG),e(SG,h3o),e(ll,u3o),e(ll,RG),e(RG,p3o),e(ll,_3o),e(k,b3o),e(k,il),e(il,mue),e(mue,v3o),e(il,F3o),e(il,PG),e(PG,T3o),e(il,M3o),e(il,BG),e(BG,E3o),e(il,C3o),e(k,w3o),e(k,dl),e(dl,fue),e(fue,A3o),e(dl,L3o),e(dl,IG),e(IG,y3o),e(dl,x3o),e(dl,NG),e(NG,$3o),e(dl,k3o),e(k,S3o),e(k,cl),e(cl,gue),e(gue,R3o),e(cl,P3o),e(cl,qG),e(qG,B3o),e(cl,I3o),e(cl,jG),e(jG,N3o),e(cl,q3o),e(k,j3o),e(k,qu),e(qu,hue),e(hue,D3o),e(qu,G3o),e(qu,DG),e(DG,O3o),e(qu,V3o),e(k,X3o),e(k,ju),e(ju,uue),e(uue,z3o),e(ju,Q3o),e(ju,GG),e(GG,W3o),e(ju,U3o),e(k,H3o),e(k,ml),e(ml,pue),e(pue,J3o),e(ml,Y3o),e(ml,OG),e(OG,Z3o),e(ml,K3o),e(ml,VG),e(VG,e5o),e(ml,o5o),e(k,r5o),e(k,fl),e(fl,_ue),e(_ue,t5o),e(fl,a5o),e(fl,XG),e(XG,n5o),e(fl,s5o),e(fl,zG),e(zG,l5o),e(fl,i5o),e(k,d5o),e(k,gl),e(gl,bue),e(bue,c5o),e(gl,m5o),e(gl,QG),e(QG,f5o),e(gl,g5o),e(gl,WG),e(WG,h5o),e(gl,u5o),e(k,p5o),e(k,Du),e(Du,vue),e(vue,_5o),e(Du,b5o),e(Du,UG),e(UG,v5o),e(Du,F5o),e(k,T5o),e(k,Gu),e(Gu,Fue),e(Fue,M5o),e(Gu,E5o),e(Gu,HG),e(HG,C5o),e(Gu,w5o),e(k,A5o),e(k,Ou),e(Ou,Tue),e(Tue,L5o),e(Ou,y5o),e(Ou,JG),e(JG,x5o),e(Ou,$5o),e(k,k5o),e(k,hl),e(hl,Mue),e(Mue,S5o),e(hl,R5o),e(hl,YG),e(YG,P5o),e(hl,B5o),e(hl,ZG),e(ZG,I5o),e(hl,N5o),e(k,q5o),e(k,ul),e(ul,Eue),e(Eue,j5o),e(ul,D5o),e(ul,KG),e(KG,G5o),e(ul,O5o),e(ul,eO),e(eO,V5o),e(ul,X5o),e(k,z5o),e(k,Vu),e(Vu,Cue),e(Cue,Q5o),e(Vu,W5o),e(Vu,oO),e(oO,U5o),e(Vu,H5o),e(k,J5o),e(k,Xu),e(Xu,wue),e(wue,Y5o),e(Xu,Z5o),e(Xu,rO),e(rO,K5o),e(Xu,e0o),e(k,o0o),e(k,zu),e(zu,Aue),e(Aue,r0o),e(zu,t0o),e(zu,tO),e(tO,a0o),e(zu,n0o),e(k,s0o),e(k,Qu),e(Qu,Lue),e(Lue,l0o),e(Qu,i0o),e(Qu,aO),e(aO,d0o),e(Qu,c0o),e(k,m0o),e(k,pl),e(pl,yue),e(yue,f0o),e(pl,g0o),e(pl,nO),e(nO,h0o),e(pl,u0o),e(pl,sO),e(sO,p0o),e(pl,_0o),e(k,b0o),e(k,_l),e(_l,xue),e(xue,v0o),e(_l,F0o),e(_l,lO),e(lO,T0o),e(_l,M0o),e(_l,iO),e(iO,E0o),e(_l,C0o),e(k,w0o),e(k,Wu),e(Wu,$ue),e($ue,A0o),e(Wu,L0o),e(Wu,dO),e(dO,y0o),e(Wu,x0o),e(k,$0o),e(k,Uu),e(Uu,kue),e(kue,k0o),e(Uu,S0o),e(Uu,cO),e(cO,R0o),e(Uu,P0o),e(k,B0o),e(k,bl),e(bl,Sue),e(Sue,I0o),e(bl,N0o),e(bl,mO),e(mO,q0o),e(bl,j0o),e(bl,fO),e(fO,D0o),e(bl,G0o),e(k,O0o),e(k,vl),e(vl,Rue),e(Rue,V0o),e(vl,X0o),e(vl,gO),e(gO,z0o),e(vl,Q0o),e(vl,hO),e(hO,W0o),e(vl,U0o),e(k,H0o),e(k,Fl),e(Fl,Pue),e(Pue,J0o),e(Fl,Y0o),e(Fl,uO),e(uO,Z0o),e(Fl,K0o),e(Fl,pO),e(pO,ewo),e(Fl,owo),e(k,rwo),e(k,Tl),e(Tl,Bue),e(Bue,two),e(Tl,awo),e(Tl,_O),e(_O,nwo),e(Tl,swo),e(Tl,bO),e(bO,lwo),e(Tl,iwo),e(Nr,dwo),M(Hu,Nr,null),e(So,cwo),e(So,Ju),M(Vx,Ju,null),e(Ju,mwo),e(Ju,Iue),e(Iue,fwo),b(m,Roo,_),b(m,Fd,_),e(Fd,Yu),e(Yu,Nue),M(Xx,Nue,null),e(Fd,gwo),e(Fd,que),e(que,hwo),b(m,Poo,_),b(m,Ro,_),M(zx,Ro,null),e(Ro,uwo),e(Ro,Qx),e(Qx,pwo),e(Qx,vO),e(vO,_wo),e(Qx,bwo),e(Ro,vwo),e(Ro,Wx),e(Wx,Fwo),e(Wx,jue),e(jue,Two),e(Wx,Mwo),e(Ro,Ewo),e(Ro,Ye),M(Ux,Ye,null),e(Ye,Cwo),e(Ye,Due),e(Due,wwo),e(Ye,Awo),e(Ye,Ka),e(Ka,Lwo),e(Ka,Gue),e(Gue,ywo),e(Ka,xwo),e(Ka,Oue),e(Oue,$wo),e(Ka,kwo),e(Ka,Vue),e(Vue,Swo),e(Ka,Rwo),e(Ye,Pwo),e(Ye,z),e(z,Zu),e(Zu,Xue),e(Xue,Bwo),e(Zu,Iwo),e(Zu,FO),e(FO,Nwo),e(Zu,qwo),e(z,jwo),e(z,Ku),e(Ku,zue),e(zue,Dwo),e(Ku,Gwo),e(Ku,TO),e(TO,Owo),e(Ku,Vwo),e(z,Xwo),e(z,ep),e(ep,Que),e(Que,zwo),e(ep,Qwo),e(ep,MO),e(MO,Wwo),e(ep,Uwo),e(z,Hwo),e(z,op),e(op,Wue),e(Wue,Jwo),e(op,Ywo),e(op,EO),e(EO,Zwo),e(op,Kwo),e(z,eAo),e(z,rp),e(rp,Uue),e(Uue,oAo),e(rp,rAo),e(rp,CO),e(CO,tAo),e(rp,aAo),e(z,nAo),e(z,tp),e(tp,Hue),e(Hue,sAo),e(tp,lAo),e(tp,wO),e(wO,iAo),e(tp,dAo),e(z,cAo),e(z,ap),e(ap,Jue),e(Jue,mAo),e(ap,fAo),e(ap,AO),e(AO,gAo),e(ap,hAo),e(z,uAo),e(z,np),e(np,Yue),e(Yue,pAo),e(np,_Ao),e(np,LO),e(LO,bAo),e(np,vAo),e(z,FAo),e(z,sp),e(sp,Zue),e(Zue,TAo),e(sp,MAo),e(sp,yO),e(yO,EAo),e(sp,CAo),e(z,wAo),e(z,lp),e(lp,Kue),e(Kue,AAo),e(lp,LAo),e(lp,xO),e(xO,yAo),e(lp,xAo),e(z,$Ao),e(z,ip),e(ip,epe),e(epe,kAo),e(ip,SAo),e(ip,$O),e($O,RAo),e(ip,PAo),e(z,BAo),e(z,dp),e(dp,ope),e(ope,IAo),e(dp,NAo),e(dp,kO),e(kO,qAo),e(dp,jAo),e(z,DAo),e(z,cp),e(cp,rpe),e(rpe,GAo),e(cp,OAo),e(cp,SO),e(SO,VAo),e(cp,XAo),e(z,zAo),e(z,mp),e(mp,tpe),e(tpe,QAo),e(mp,WAo),e(mp,RO),e(RO,UAo),e(mp,HAo),e(z,JAo),e(z,fp),e(fp,ape),e(ape,YAo),e(fp,ZAo),e(fp,PO),e(PO,KAo),e(fp,e6o),e(z,o6o),e(z,gp),e(gp,npe),e(npe,r6o),e(gp,t6o),e(gp,BO),e(BO,a6o),e(gp,n6o),e(z,s6o),e(z,hp),e(hp,spe),e(spe,l6o),e(hp,i6o),e(hp,IO),e(IO,d6o),e(hp,c6o),e(z,m6o),e(z,up),e(up,lpe),e(lpe,f6o),e(up,g6o),e(up,NO),e(NO,h6o),e(up,u6o),e(z,p6o),e(z,pp),e(pp,ipe),e(ipe,_6o),e(pp,b6o),e(pp,qO),e(qO,v6o),e(pp,F6o),e(z,T6o),e(z,_p),e(_p,dpe),e(dpe,M6o),e(_p,E6o),e(_p,jO),e(jO,C6o),e(_p,w6o),e(z,A6o),e(z,bp),e(bp,cpe),e(cpe,L6o),e(bp,y6o),e(bp,DO),e(DO,x6o),e(bp,$6o),e(z,k6o),e(z,vp),e(vp,mpe),e(mpe,S6o),e(vp,R6o),e(vp,GO),e(GO,P6o),e(vp,B6o),e(z,I6o),e(z,Fp),e(Fp,fpe),e(fpe,N6o),e(Fp,q6o),e(Fp,OO),e(OO,j6o),e(Fp,D6o),e(z,G6o),e(z,Tp),e(Tp,gpe),e(gpe,O6o),e(Tp,V6o),e(Tp,VO),e(VO,X6o),e(Tp,z6o),e(z,Q6o),e(z,Mp),e(Mp,hpe),e(hpe,W6o),e(Mp,U6o),e(Mp,XO),e(XO,H6o),e(Mp,J6o),e(z,Y6o),e(z,Ep),e(Ep,upe),e(upe,Z6o),e(Ep,K6o),e(Ep,zO),e(zO,e7o),e(Ep,o7o),e(z,r7o),e(z,Cp),e(Cp,ppe),e(ppe,t7o),e(Cp,a7o),e(Cp,QO),e(QO,n7o),e(Cp,s7o),e(z,l7o),e(z,wp),e(wp,_pe),e(_pe,i7o),e(wp,d7o),e(wp,WO),e(WO,c7o),e(wp,m7o),e(z,f7o),e(z,Ap),e(Ap,bpe),e(bpe,g7o),e(Ap,h7o),e(Ap,UO),e(UO,u7o),e(Ap,p7o),e(z,_7o),e(z,Lp),e(Lp,vpe),e(vpe,b7o),e(Lp,v7o),e(Lp,HO),e(HO,F7o),e(Lp,T7o),e(z,M7o),e(z,yp),e(yp,Fpe),e(Fpe,E7o),e(yp,C7o),e(yp,JO),e(JO,w7o),e(yp,A7o),e(z,L7o),e(z,xp),e(xp,Tpe),e(Tpe,y7o),e(xp,x7o),e(xp,YO),e(YO,$7o),e(xp,k7o),e(z,S7o),e(z,$p),e($p,Mpe),e(Mpe,R7o),e($p,P7o),e($p,ZO),e(ZO,B7o),e($p,I7o),e(z,N7o),e(z,kp),e(kp,Epe),e(Epe,q7o),e(kp,j7o),e(kp,KO),e(KO,D7o),e(kp,G7o),e(z,O7o),e(z,Sp),e(Sp,Cpe),e(Cpe,V7o),e(Sp,X7o),e(Sp,eV),e(eV,z7o),e(Sp,Q7o),e(z,W7o),e(z,Rp),e(Rp,wpe),e(wpe,U7o),e(Rp,H7o),e(Rp,oV),e(oV,J7o),e(Rp,Y7o),e(z,Z7o),e(z,Pp),e(Pp,Ape),e(Ape,K7o),e(Pp,eLo),e(Pp,rV),e(rV,oLo),e(Pp,rLo),e(z,tLo),e(z,Bp),e(Bp,Lpe),e(Lpe,aLo),e(Bp,nLo),e(Bp,tV),e(tV,sLo),e(Bp,lLo),e(z,iLo),e(z,Ip),e(Ip,ype),e(ype,dLo),e(Ip,cLo),e(Ip,aV),e(aV,mLo),e(Ip,fLo),e(z,gLo),e(z,Np),e(Np,xpe),e(xpe,hLo),e(Np,uLo),e(Np,nV),e(nV,pLo),e(Np,_Lo),e(z,bLo),e(z,qp),e(qp,$pe),e($pe,vLo),e(qp,FLo),e(qp,sV),e(sV,TLo),e(qp,MLo),e(z,ELo),e(z,jp),e(jp,kpe),e(kpe,CLo),e(jp,wLo),e(jp,lV),e(lV,ALo),e(jp,LLo),e(z,yLo),e(z,Dp),e(Dp,Spe),e(Spe,xLo),e(Dp,$Lo),e(Dp,iV),e(iV,kLo),e(Dp,SLo),e(Ye,RLo),M(Gp,Ye,null),e(Ye,PLo),M(Op,Ye,null),e(Ro,BLo),e(Ro,Vp),M(Hx,Vp,null),e(Vp,ILo),e(Vp,Rpe),e(Rpe,NLo),b(m,Boo,_),b(m,Td,_),e(Td,Xp),e(Xp,Ppe),M(Jx,Ppe,null),e(Td,qLo),e(Td,Bpe),e(Bpe,jLo),b(m,Ioo,_),b(m,Po,_),M(Yx,Po,null),e(Po,DLo),e(Po,Zx),e(Zx,GLo),e(Zx,dV),e(dV,OLo),e(Zx,VLo),e(Po,XLo),e(Po,Kx),e(Kx,zLo),e(Kx,Ipe),e(Ipe,QLo),e(Kx,WLo),e(Po,ULo),e(Po,Ze),M(e$,Ze,null),e(Ze,HLo),e(Ze,Npe),e(Npe,JLo),e(Ze,YLo),e(Ze,Md),e(Md,ZLo),e(Md,qpe),e(qpe,KLo),e(Md,e8o),e(Md,jpe),e(jpe,o8o),e(Md,r8o),e(Ze,t8o),e(Ze,se),e(se,zp),e(zp,Dpe),e(Dpe,a8o),e(zp,n8o),e(zp,cV),e(cV,s8o),e(zp,l8o),e(se,i8o),e(se,Qp),e(Qp,Gpe),e(Gpe,d8o),e(Qp,c8o),e(Qp,mV),e(mV,m8o),e(Qp,f8o),e(se,g8o),e(se,Wp),e(Wp,Ope),e(Ope,h8o),e(Wp,u8o),e(Wp,fV),e(fV,p8o),e(Wp,_8o),e(se,b8o),e(se,Up),e(Up,Vpe),e(Vpe,v8o),e(Up,F8o),e(Up,gV),e(gV,T8o),e(Up,M8o),e(se,E8o),e(se,Hp),e(Hp,Xpe),e(Xpe,C8o),e(Hp,w8o),e(Hp,hV),e(hV,A8o),e(Hp,L8o),e(se,y8o),e(se,Jp),e(Jp,zpe),e(zpe,x8o),e(Jp,$8o),e(Jp,uV),e(uV,k8o),e(Jp,S8o),e(se,R8o),e(se,Yp),e(Yp,Qpe),e(Qpe,P8o),e(Yp,B8o),e(Yp,pV),e(pV,I8o),e(Yp,N8o),e(se,q8o),e(se,Zp),e(Zp,Wpe),e(Wpe,j8o),e(Zp,D8o),e(Zp,_V),e(_V,G8o),e(Zp,O8o),e(se,V8o),e(se,Kp),e(Kp,Upe),e(Upe,X8o),e(Kp,z8o),e(Kp,bV),e(bV,Q8o),e(Kp,W8o),e(se,U8o),e(se,e_),e(e_,Hpe),e(Hpe,H8o),e(e_,J8o),e(e_,vV),e(vV,Y8o),e(e_,Z8o),e(se,K8o),e(se,o_),e(o_,Jpe),e(Jpe,eyo),e(o_,oyo),e(o_,FV),e(FV,ryo),e(o_,tyo),e(se,ayo),e(se,r_),e(r_,Ype),e(Ype,nyo),e(r_,syo),e(r_,TV),e(TV,lyo),e(r_,iyo),e(se,dyo),e(se,t_),e(t_,Zpe),e(Zpe,cyo),e(t_,myo),e(t_,MV),e(MV,fyo),e(t_,gyo),e(se,hyo),e(se,a_),e(a_,Kpe),e(Kpe,uyo),e(a_,pyo),e(a_,EV),e(EV,_yo),e(a_,byo),e(se,vyo),e(se,n_),e(n_,e_e),e(e_e,Fyo),e(n_,Tyo),e(n_,CV),e(CV,Myo),e(n_,Eyo),e(se,Cyo),e(se,s_),e(s_,o_e),e(o_e,wyo),e(s_,Ayo),e(s_,wV),e(wV,Lyo),e(s_,yyo),e(se,xyo),e(se,l_),e(l_,r_e),e(r_e,$yo),e(l_,kyo),e(l_,AV),e(AV,Syo),e(l_,Ryo),e(se,Pyo),e(se,i_),e(i_,t_e),e(t_e,Byo),e(i_,Iyo),e(i_,LV),e(LV,Nyo),e(i_,qyo),e(se,jyo),e(se,d_),e(d_,a_e),e(a_e,Dyo),e(d_,Gyo),e(d_,yV),e(yV,Oyo),e(d_,Vyo),e(se,Xyo),e(se,c_),e(c_,n_e),e(n_e,zyo),e(c_,Qyo),e(c_,xV),e(xV,Wyo),e(c_,Uyo),e(se,Hyo),e(se,m_),e(m_,s_e),e(s_e,Jyo),e(m_,Yyo),e(m_,$V),e($V,Zyo),e(m_,Kyo),e(se,e9o),e(se,f_),e(f_,l_e),e(l_e,o9o),e(f_,r9o),e(f_,kV),e(kV,t9o),e(f_,a9o),e(se,n9o),e(se,g_),e(g_,i_e),e(i_e,s9o),e(g_,l9o),e(g_,SV),e(SV,i9o),e(g_,d9o),e(Ze,c9o),M(h_,Ze,null),e(Ze,m9o),M(u_,Ze,null),e(Po,f9o),e(Po,p_),M(o$,p_,null),e(p_,g9o),e(p_,d_e),e(d_e,h9o),b(m,Noo,_),b(m,Ed,_),e(Ed,__),e(__,c_e),M(r$,c_e,null),e(Ed,u9o),e(Ed,m_e),e(m_e,p9o),b(m,qoo,_),b(m,Bo,_),M(t$,Bo,null),e(Bo,_9o),e(Bo,Cd),e(Cd,b9o),e(Cd,RV),e(RV,v9o),e(Cd,F9o),e(Cd,PV),e(PV,T9o),e(Cd,M9o),e(Bo,E9o),e(Bo,a$),e(a$,C9o),e(a$,f_e),e(f_e,w9o),e(a$,A9o),e(Bo,L9o),e(Bo,vt),M(n$,vt,null),e(vt,y9o),e(vt,g_e),e(g_e,x9o),e(vt,$9o),e(vt,wd),e(wd,k9o),e(wd,h_e),e(h_e,S9o),e(wd,R9o),e(wd,BV),e(BV,P9o),e(wd,B9o),e(vt,I9o),M(b_,vt,null),e(Bo,N9o),e(Bo,Ke),M(s$,Ke,null),e(Ke,q9o),e(Ke,u_e),e(u_e,j9o),e(Ke,D9o),e(Ke,en),e(en,G9o),e(en,p_e),e(p_e,O9o),e(en,V9o),e(en,__e),e(__e,X9o),e(en,z9o),e(en,b_e),e(b_e,Q9o),e(en,W9o),e(Ke,U9o),e(Ke,y),e(y,v_),e(v_,v_e),e(v_e,H9o),e(v_,J9o),e(v_,IV),e(IV,Y9o),e(v_,Z9o),e(y,K9o),e(y,F_),e(F_,F_e),e(F_e,exo),e(F_,oxo),e(F_,NV),e(NV,rxo),e(F_,txo),e(y,axo),e(y,T_),e(T_,T_e),e(T_e,nxo),e(T_,sxo),e(T_,qV),e(qV,lxo),e(T_,ixo),e(y,dxo),e(y,M_),e(M_,M_e),e(M_e,cxo),e(M_,mxo),e(M_,jV),e(jV,fxo),e(M_,gxo),e(y,hxo),e(y,E_),e(E_,E_e),e(E_e,uxo),e(E_,pxo),e(E_,DV),e(DV,_xo),e(E_,bxo),e(y,vxo),e(y,C_),e(C_,C_e),e(C_e,Fxo),e(C_,Txo),e(C_,GV),e(GV,Mxo),e(C_,Exo),e(y,Cxo),e(y,w_),e(w_,w_e),e(w_e,wxo),e(w_,Axo),e(w_,OV),e(OV,Lxo),e(w_,yxo),e(y,xxo),e(y,A_),e(A_,A_e),e(A_e,$xo),e(A_,kxo),e(A_,VV),e(VV,Sxo),e(A_,Rxo),e(y,Pxo),e(y,L_),e(L_,L_e),e(L_e,Bxo),e(L_,Ixo),e(L_,XV),e(XV,Nxo),e(L_,qxo),e(y,jxo),e(y,y_),e(y_,y_e),e(y_e,Dxo),e(y_,Gxo),e(y_,zV),e(zV,Oxo),e(y_,Vxo),e(y,Xxo),e(y,x_),e(x_,x_e),e(x_e,zxo),e(x_,Qxo),e(x_,QV),e(QV,Wxo),e(x_,Uxo),e(y,Hxo),e(y,$_),e($_,$_e),e($_e,Jxo),e($_,Yxo),e($_,WV),e(WV,Zxo),e($_,Kxo),e(y,e$o),e(y,k_),e(k_,k_e),e(k_e,o$o),e(k_,r$o),e(k_,UV),e(UV,t$o),e(k_,a$o),e(y,n$o),e(y,S_),e(S_,S_e),e(S_e,s$o),e(S_,l$o),e(S_,HV),e(HV,i$o),e(S_,d$o),e(y,c$o),e(y,R_),e(R_,R_e),e(R_e,m$o),e(R_,f$o),e(R_,JV),e(JV,g$o),e(R_,h$o),e(y,u$o),e(y,P_),e(P_,P_e),e(P_e,p$o),e(P_,_$o),e(P_,YV),e(YV,b$o),e(P_,v$o),e(y,F$o),e(y,B_),e(B_,B_e),e(B_e,T$o),e(B_,M$o),e(B_,ZV),e(ZV,E$o),e(B_,C$o),e(y,w$o),e(y,I_),e(I_,I_e),e(I_e,A$o),e(I_,L$o),e(I_,KV),e(KV,y$o),e(I_,x$o),e(y,$$o),e(y,N_),e(N_,N_e),e(N_e,k$o),e(N_,S$o),e(N_,eX),e(eX,R$o),e(N_,P$o),e(y,B$o),e(y,q_),e(q_,q_e),e(q_e,I$o),e(q_,N$o),e(q_,oX),e(oX,q$o),e(q_,j$o),e(y,D$o),e(y,j_),e(j_,j_e),e(j_e,G$o),e(j_,O$o),e(j_,rX),e(rX,V$o),e(j_,X$o),e(y,z$o),e(y,D_),e(D_,D_e),e(D_e,Q$o),e(D_,W$o),e(D_,tX),e(tX,U$o),e(D_,H$o),e(y,J$o),e(y,G_),e(G_,G_e),e(G_e,Y$o),e(G_,Z$o),e(G_,aX),e(aX,K$o),e(G_,eko),e(y,oko),e(y,O_),e(O_,O_e),e(O_e,rko),e(O_,tko),e(O_,nX),e(nX,ako),e(O_,nko),e(y,sko),e(y,V_),e(V_,V_e),e(V_e,lko),e(V_,iko),e(V_,sX),e(sX,dko),e(V_,cko),e(y,mko),e(y,X_),e(X_,X_e),e(X_e,fko),e(X_,gko),e(X_,lX),e(lX,hko),e(X_,uko),e(y,pko),e(y,z_),e(z_,z_e),e(z_e,_ko),e(z_,bko),e(z_,iX),e(iX,vko),e(z_,Fko),e(y,Tko),e(y,Q_),e(Q_,Q_e),e(Q_e,Mko),e(Q_,Eko),e(Q_,dX),e(dX,Cko),e(Q_,wko),e(y,Ako),e(y,W_),e(W_,W_e),e(W_e,Lko),e(W_,yko),e(W_,cX),e(cX,xko),e(W_,$ko),e(y,kko),e(y,U_),e(U_,U_e),e(U_e,Sko),e(U_,Rko),e(U_,mX),e(mX,Pko),e(U_,Bko),e(y,Iko),e(y,H_),e(H_,H_e),e(H_e,Nko),e(H_,qko),e(H_,fX),e(fX,jko),e(H_,Dko),e(y,Gko),e(y,J_),e(J_,J_e),e(J_e,Oko),e(J_,Vko),e(J_,gX),e(gX,Xko),e(J_,zko),e(y,Qko),e(y,Y_),e(Y_,Y_e),e(Y_e,Wko),e(Y_,Uko),e(Y_,hX),e(hX,Hko),e(Y_,Jko),e(y,Yko),e(y,Z_),e(Z_,Z_e),e(Z_e,Zko),e(Z_,Kko),e(Z_,uX),e(uX,eSo),e(Z_,oSo),e(y,rSo),e(y,K_),e(K_,K_e),e(K_e,tSo),e(K_,aSo),e(K_,pX),e(pX,nSo),e(K_,sSo),e(y,lSo),e(y,e1),e(e1,e1e),e(e1e,iSo),e(e1,dSo),e(e1,_X),e(_X,cSo),e(e1,mSo),e(y,fSo),e(y,o1),e(o1,o1e),e(o1e,gSo),e(o1,hSo),e(o1,bX),e(bX,uSo),e(o1,pSo),e(y,_So),e(y,r1),e(r1,r1e),e(r1e,bSo),e(r1,vSo),e(r1,vX),e(vX,FSo),e(r1,TSo),e(y,MSo),e(y,t1),e(t1,t1e),e(t1e,ESo),e(t1,CSo),e(t1,FX),e(FX,wSo),e(t1,ASo),e(y,LSo),e(y,Ml),e(Ml,a1e),e(a1e,ySo),e(Ml,xSo),e(Ml,TX),e(TX,$So),e(Ml,kSo),e(Ml,MX),e(MX,SSo),e(Ml,RSo),e(y,PSo),e(y,a1),e(a1,n1e),e(n1e,BSo),e(a1,ISo),e(a1,EX),e(EX,NSo),e(a1,qSo),e(y,jSo),e(y,n1),e(n1,s1e),e(s1e,DSo),e(n1,GSo),e(n1,CX),e(CX,OSo),e(n1,VSo),e(y,XSo),e(y,s1),e(s1,l1e),e(l1e,zSo),e(s1,QSo),e(s1,wX),e(wX,WSo),e(s1,USo),e(y,HSo),e(y,l1),e(l1,i1e),e(i1e,JSo),e(l1,YSo),e(l1,AX),e(AX,ZSo),e(l1,KSo),e(y,eRo),e(y,i1),e(i1,d1e),e(d1e,oRo),e(i1,rRo),e(i1,LX),e(LX,tRo),e(i1,aRo),e(y,nRo),e(y,d1),e(d1,c1e),e(c1e,sRo),e(d1,lRo),e(d1,yX),e(yX,iRo),e(d1,dRo),e(y,cRo),e(y,c1),e(c1,m1e),e(m1e,mRo),e(c1,fRo),e(c1,xX),e(xX,gRo),e(c1,hRo),e(y,uRo),e(y,m1),e(m1,f1e),e(f1e,pRo),e(m1,_Ro),e(m1,$X),e($X,bRo),e(m1,vRo),e(y,FRo),e(y,f1),e(f1,g1e),e(g1e,TRo),e(f1,MRo),e(f1,kX),e(kX,ERo),e(f1,CRo),e(y,wRo),e(y,g1),e(g1,h1e),e(h1e,ARo),e(g1,LRo),e(g1,SX),e(SX,yRo),e(g1,xRo),e(y,$Ro),e(y,h1),e(h1,u1e),e(u1e,kRo),e(h1,SRo),e(h1,RX),e(RX,RRo),e(h1,PRo),e(y,BRo),e(y,u1),e(u1,p1e),e(p1e,IRo),e(u1,NRo),e(u1,PX),e(PX,qRo),e(u1,jRo),e(y,DRo),e(y,p1),e(p1,_1e),e(_1e,GRo),e(p1,ORo),e(p1,BX),e(BX,VRo),e(p1,XRo),e(y,zRo),e(y,_1),e(_1,b1e),e(b1e,QRo),e(_1,WRo),e(_1,IX),e(IX,URo),e(_1,HRo),e(y,JRo),e(y,b1),e(b1,v1e),e(v1e,YRo),e(b1,ZRo),e(b1,NX),e(NX,KRo),e(b1,ePo),e(y,oPo),e(y,v1),e(v1,F1e),e(F1e,rPo),e(v1,tPo),e(v1,qX),e(qX,aPo),e(v1,nPo),e(y,sPo),e(y,F1),e(F1,T1e),e(T1e,lPo),e(F1,iPo),e(F1,jX),e(jX,dPo),e(F1,cPo),e(y,mPo),e(y,T1),e(T1,M1e),e(M1e,fPo),e(T1,gPo),e(T1,DX),e(DX,hPo),e(T1,uPo),e(y,pPo),e(y,M1),e(M1,E1e),e(E1e,_Po),e(M1,bPo),e(M1,GX),e(GX,vPo),e(M1,FPo),e(y,TPo),e(y,E1),e(E1,C1e),e(C1e,MPo),e(E1,EPo),e(E1,OX),e(OX,CPo),e(E1,wPo),e(y,APo),e(y,C1),e(C1,w1e),e(w1e,LPo),e(C1,yPo),e(C1,VX),e(VX,xPo),e(C1,$Po),e(y,kPo),e(y,w1),e(w1,A1e),e(A1e,SPo),e(w1,RPo),e(w1,XX),e(XX,PPo),e(w1,BPo),e(y,IPo),e(y,A1),e(A1,L1e),e(L1e,NPo),e(A1,qPo),e(A1,zX),e(zX,jPo),e(A1,DPo),e(y,GPo),e(y,L1),e(L1,y1e),e(y1e,OPo),e(L1,VPo),e(L1,QX),e(QX,XPo),e(L1,zPo),e(y,QPo),e(y,y1),e(y1,x1e),e(x1e,WPo),e(y1,UPo),e(y1,WX),e(WX,HPo),e(y1,JPo),e(y,YPo),e(y,x1),e(x1,$1e),e($1e,ZPo),e(x1,KPo),e(x1,UX),e(UX,eBo),e(x1,oBo),e(y,rBo),e(y,$1),e($1,k1e),e(k1e,tBo),e($1,aBo),e($1,HX),e(HX,nBo),e($1,sBo),e(y,lBo),e(y,k1),e(k1,S1e),e(S1e,iBo),e(k1,dBo),e(k1,JX),e(JX,cBo),e(k1,mBo),e(y,fBo),e(y,S1),e(S1,R1e),e(R1e,gBo),e(S1,hBo),e(S1,YX),e(YX,uBo),e(S1,pBo),e(y,_Bo),e(y,R1),e(R1,P1e),e(P1e,bBo),e(R1,vBo),e(R1,ZX),e(ZX,FBo),e(R1,TBo),e(y,MBo),e(y,P1),e(P1,B1e),e(B1e,EBo),e(P1,CBo),e(P1,KX),e(KX,wBo),e(P1,ABo),e(y,LBo),e(y,B1),e(B1,I1e),e(I1e,yBo),e(B1,xBo),e(B1,ez),e(ez,$Bo),e(B1,kBo),e(y,SBo),e(y,I1),e(I1,N1e),e(N1e,RBo),e(I1,PBo),e(I1,oz),e(oz,BBo),e(I1,IBo),e(y,NBo),e(y,N1),e(N1,q1e),e(q1e,qBo),e(N1,jBo),e(N1,rz),e(rz,DBo),e(N1,GBo),e(y,OBo),e(y,q1),e(q1,j1e),e(j1e,VBo),e(q1,XBo),e(q1,tz),e(tz,zBo),e(q1,QBo),e(y,WBo),e(y,j1),e(j1,D1e),e(D1e,UBo),e(j1,HBo),e(j1,az),e(az,JBo),e(j1,YBo),e(y,ZBo),e(y,D1),e(D1,G1e),e(G1e,KBo),e(D1,eIo),e(D1,nz),e(nz,oIo),e(D1,rIo),e(y,tIo),e(y,G1),e(G1,O1e),e(O1e,aIo),e(G1,nIo),e(G1,sz),e(sz,sIo),e(G1,lIo),e(y,iIo),e(y,O1),e(O1,V1e),e(V1e,dIo),e(O1,cIo),e(O1,lz),e(lz,mIo),e(O1,fIo),e(y,gIo),e(y,V1),e(V1,X1e),e(X1e,hIo),e(V1,uIo),e(V1,iz),e(iz,pIo),e(V1,_Io),e(y,bIo),e(y,X1),e(X1,z1e),e(z1e,vIo),e(X1,FIo),e(X1,dz),e(dz,TIo),e(X1,MIo),e(y,EIo),e(y,z1),e(z1,Q1e),e(Q1e,CIo),e(z1,wIo),e(z1,cz),e(cz,AIo),e(z1,LIo),e(y,yIo),e(y,Q1),e(Q1,W1e),e(W1e,xIo),e(Q1,$Io),e(Q1,mz),e(mz,kIo),e(Q1,SIo),e(y,RIo),e(y,W1),e(W1,U1e),e(U1e,PIo),e(W1,BIo),e(W1,fz),e(fz,IIo),e(W1,NIo),e(y,qIo),e(y,U1),e(U1,H1e),e(H1e,jIo),e(U1,DIo),e(U1,gz),e(gz,GIo),e(U1,OIo),e(y,VIo),e(y,H1),e(H1,J1e),e(J1e,XIo),e(H1,zIo),e(H1,hz),e(hz,QIo),e(H1,WIo),e(y,UIo),e(y,J1),e(J1,Y1e),e(Y1e,HIo),e(J1,JIo),e(J1,uz),e(uz,YIo),e(J1,ZIo),e(y,KIo),e(y,Y1),e(Y1,Z1e),e(Z1e,eNo),e(Y1,oNo),e(Y1,pz),e(pz,rNo),e(Y1,tNo),e(y,aNo),e(y,Z1),e(Z1,K1e),e(K1e,nNo),e(Z1,sNo),e(Z1,_z),e(_z,lNo),e(Z1,iNo),e(y,dNo),e(y,K1),e(K1,e2e),e(e2e,cNo),e(K1,mNo),e(K1,bz),e(bz,fNo),e(K1,gNo),e(y,hNo),e(y,e2),e(e2,o2e),e(o2e,uNo),e(e2,pNo),e(e2,vz),e(vz,_No),e(e2,bNo),e(y,vNo),e(y,o2),e(o2,r2e),e(r2e,FNo),e(o2,TNo),e(o2,Fz),e(Fz,MNo),e(o2,ENo),e(y,CNo),e(y,r2),e(r2,t2e),e(t2e,wNo),e(r2,ANo),e(r2,Tz),e(Tz,LNo),e(r2,yNo),e(y,xNo),e(y,t2),e(t2,a2e),e(a2e,$No),e(t2,kNo),e(t2,Mz),e(Mz,SNo),e(t2,RNo),e(y,PNo),e(y,a2),e(a2,n2e),e(n2e,BNo),e(a2,INo),e(a2,Ez),e(Ez,NNo),e(a2,qNo),e(y,jNo),e(y,n2),e(n2,s2e),e(s2e,DNo),e(n2,GNo),e(n2,Cz),e(Cz,ONo),e(n2,VNo),e(y,XNo),e(y,s2),e(s2,l2e),e(l2e,zNo),e(s2,QNo),e(s2,wz),e(wz,WNo),e(s2,UNo),e(y,HNo),e(y,l2),e(l2,i2e),e(i2e,JNo),e(l2,YNo),e(l2,Az),e(Az,ZNo),e(l2,KNo),e(y,eqo),e(y,i2),e(i2,d2e),e(d2e,oqo),e(i2,rqo),e(i2,Lz),e(Lz,tqo),e(i2,aqo),e(y,nqo),e(y,d2),e(d2,c2e),e(c2e,sqo),e(d2,lqo),e(d2,yz),e(yz,iqo),e(d2,dqo),e(y,cqo),e(y,c2),e(c2,m2e),e(m2e,mqo),e(c2,fqo),e(c2,xz),e(xz,gqo),e(c2,hqo),e(y,uqo),e(y,m2),e(m2,f2e),e(f2e,pqo),e(m2,_qo),e(m2,$z),e($z,bqo),e(m2,vqo),e(y,Fqo),e(y,f2),e(f2,g2e),e(g2e,Tqo),e(f2,Mqo),e(f2,kz),e(kz,Eqo),e(f2,Cqo),e(y,wqo),e(y,g2),e(g2,h2e),e(h2e,Aqo),e(g2,Lqo),e(g2,Sz),e(Sz,yqo),e(g2,xqo),e(y,$qo),e(y,h2),e(h2,u2e),e(u2e,kqo),e(h2,Sqo),e(h2,Rz),e(Rz,Rqo),e(h2,Pqo),e(y,Bqo),e(y,u2),e(u2,p2e),e(p2e,Iqo),e(u2,Nqo),e(u2,Pz),e(Pz,qqo),e(u2,jqo),e(y,Dqo),e(y,p2),e(p2,_2e),e(_2e,Gqo),e(p2,Oqo),e(p2,Bz),e(Bz,Vqo),e(p2,Xqo),e(y,zqo),e(y,_2),e(_2,b2e),e(b2e,Qqo),e(_2,Wqo),e(_2,Iz),e(Iz,Uqo),e(_2,Hqo),e(y,Jqo),e(y,b2),e(b2,v2e),e(v2e,Yqo),e(b2,Zqo),e(b2,Nz),e(Nz,Kqo),e(b2,ejo),e(y,ojo),e(y,v2),e(v2,F2e),e(F2e,rjo),e(v2,tjo),e(v2,qz),e(qz,ajo),e(v2,njo),e(y,sjo),e(y,F2),e(F2,T2e),e(T2e,ljo),e(F2,ijo),e(F2,jz),e(jz,djo),e(F2,cjo),e(y,mjo),e(y,T2),e(T2,M2e),e(M2e,fjo),e(T2,gjo),e(T2,Dz),e(Dz,hjo),e(T2,ujo),e(y,pjo),e(y,M2),e(M2,E2e),e(E2e,_jo),e(M2,bjo),e(M2,Gz),e(Gz,vjo),e(M2,Fjo),e(y,Tjo),e(y,E2),e(E2,C2e),e(C2e,Mjo),e(E2,Ejo),e(E2,Oz),e(Oz,Cjo),e(E2,wjo),e(y,Ajo),e(y,C2),e(C2,w2e),e(w2e,Ljo),e(C2,yjo),e(C2,Vz),e(Vz,xjo),e(C2,$jo),e(y,kjo),e(y,w2),e(w2,A2e),e(A2e,Sjo),e(w2,Rjo),e(w2,Xz),e(Xz,Pjo),e(w2,Bjo),e(y,Ijo),e(y,A2),e(A2,L2e),e(L2e,Njo),e(A2,qjo),e(A2,zz),e(zz,jjo),e(A2,Djo),e(y,Gjo),e(y,L2),e(L2,y2e),e(y2e,Ojo),e(L2,Vjo),e(L2,Qz),e(Qz,Xjo),e(L2,zjo),e(y,Qjo),e(y,y2),e(y2,x2e),e(x2e,Wjo),e(y2,Ujo),e(y2,Wz),e(Wz,Hjo),e(y2,Jjo),e(y,Yjo),e(y,x2),e(x2,$2e),e($2e,Zjo),e(x2,Kjo),e(x2,Uz),e(Uz,eDo),e(x2,oDo),e(y,rDo),e(y,$2),e($2,k2e),e(k2e,tDo),e($2,aDo),e($2,Hz),e(Hz,nDo),e($2,sDo),e(y,lDo),e(y,k2),e(k2,S2e),e(S2e,iDo),e(k2,dDo),e(k2,Jz),e(Jz,cDo),e(k2,mDo),e(y,fDo),e(y,S2),e(S2,R2e),e(R2e,gDo),e(S2,hDo),e(S2,Yz),e(Yz,uDo),e(S2,pDo),e(y,_Do),e(y,R2),e(R2,P2e),e(P2e,bDo),e(R2,vDo),e(R2,Zz),e(Zz,FDo),e(R2,TDo),e(y,MDo),e(y,P2),e(P2,B2e),e(B2e,EDo),e(P2,CDo),e(P2,Kz),e(Kz,wDo),e(P2,ADo),e(y,LDo),e(y,B2),e(B2,I2e),e(I2e,yDo),e(B2,xDo),e(B2,eQ),e(eQ,$Do),e(B2,kDo),e(y,SDo),e(y,I2),e(I2,N2e),e(N2e,RDo),e(I2,PDo),e(I2,oQ),e(oQ,BDo),e(I2,IDo),e(Ke,NDo),e(Ke,N2),e(N2,qDo),e(N2,q2e),e(q2e,jDo),e(N2,DDo),e(N2,j2e),e(j2e,GDo),e(Ke,ODo),M(q2,Ke,null),b(m,joo,_),b(m,Ad,_),e(Ad,j2),e(j2,D2e),M(l$,D2e,null),e(Ad,VDo),e(Ad,G2e),e(G2e,XDo),b(m,Doo,_),b(m,Io,_),M(i$,Io,null),e(Io,zDo),e(Io,Ld),e(Ld,QDo),e(Ld,rQ),e(rQ,WDo),e(Ld,UDo),e(Ld,tQ),e(tQ,HDo),e(Ld,JDo),e(Io,YDo),e(Io,d$),e(d$,ZDo),e(d$,O2e),e(O2e,KDo),e(d$,eGo),e(Io,oGo),e(Io,Ft),M(c$,Ft,null),e(Ft,rGo),e(Ft,V2e),e(V2e,tGo),e(Ft,aGo),e(Ft,yd),e(yd,nGo),e(yd,X2e),e(X2e,sGo),e(yd,lGo),e(yd,aQ),e(aQ,iGo),e(yd,dGo),e(Ft,cGo),M(D2,Ft,null),e(Io,mGo),e(Io,eo),M(m$,eo,null),e(eo,fGo),e(eo,z2e),e(z2e,gGo),e(eo,hGo),e(eo,on),e(on,uGo),e(on,Q2e),e(Q2e,pGo),e(on,_Go),e(on,W2e),e(W2e,bGo),e(on,vGo),e(on,U2e),e(U2e,FGo),e(on,TGo),e(eo,MGo),e(eo,G),e(G,G2),e(G2,H2e),e(H2e,EGo),e(G2,CGo),e(G2,nQ),e(nQ,wGo),e(G2,AGo),e(G,LGo),e(G,O2),e(O2,J2e),e(J2e,yGo),e(O2,xGo),e(O2,sQ),e(sQ,$Go),e(O2,kGo),e(G,SGo),e(G,V2),e(V2,Y2e),e(Y2e,RGo),e(V2,PGo),e(V2,lQ),e(lQ,BGo),e(V2,IGo),e(G,NGo),e(G,X2),e(X2,Z2e),e(Z2e,qGo),e(X2,jGo),e(X2,iQ),e(iQ,DGo),e(X2,GGo),e(G,OGo),e(G,z2),e(z2,K2e),e(K2e,VGo),e(z2,XGo),e(z2,dQ),e(dQ,zGo),e(z2,QGo),e(G,WGo),e(G,Q2),e(Q2,ebe),e(ebe,UGo),e(Q2,HGo),e(Q2,cQ),e(cQ,JGo),e(Q2,YGo),e(G,ZGo),e(G,W2),e(W2,obe),e(obe,KGo),e(W2,eOo),e(W2,mQ),e(mQ,oOo),e(W2,rOo),e(G,tOo),e(G,U2),e(U2,rbe),e(rbe,aOo),e(U2,nOo),e(U2,fQ),e(fQ,sOo),e(U2,lOo),e(G,iOo),e(G,H2),e(H2,tbe),e(tbe,dOo),e(H2,cOo),e(H2,gQ),e(gQ,mOo),e(H2,fOo),e(G,gOo),e(G,J2),e(J2,abe),e(abe,hOo),e(J2,uOo),e(J2,hQ),e(hQ,pOo),e(J2,_Oo),e(G,bOo),e(G,Y2),e(Y2,nbe),e(nbe,vOo),e(Y2,FOo),e(Y2,uQ),e(uQ,TOo),e(Y2,MOo),e(G,EOo),e(G,Z2),e(Z2,sbe),e(sbe,COo),e(Z2,wOo),e(Z2,pQ),e(pQ,AOo),e(Z2,LOo),e(G,yOo),e(G,K2),e(K2,lbe),e(lbe,xOo),e(K2,$Oo),e(K2,_Q),e(_Q,kOo),e(K2,SOo),e(G,ROo),e(G,eb),e(eb,ibe),e(ibe,POo),e(eb,BOo),e(eb,bQ),e(bQ,IOo),e(eb,NOo),e(G,qOo),e(G,ob),e(ob,dbe),e(dbe,jOo),e(ob,DOo),e(ob,vQ),e(vQ,GOo),e(ob,OOo),e(G,VOo),e(G,rb),e(rb,cbe),e(cbe,XOo),e(rb,zOo),e(rb,FQ),e(FQ,QOo),e(rb,WOo),e(G,UOo),e(G,tb),e(tb,mbe),e(mbe,HOo),e(tb,JOo),e(tb,TQ),e(TQ,YOo),e(tb,ZOo),e(G,KOo),e(G,ab),e(ab,fbe),e(fbe,eVo),e(ab,oVo),e(ab,MQ),e(MQ,rVo),e(ab,tVo),e(G,aVo),e(G,nb),e(nb,gbe),e(gbe,nVo),e(nb,sVo),e(nb,EQ),e(EQ,lVo),e(nb,iVo),e(G,dVo),e(G,sb),e(sb,hbe),e(hbe,cVo),e(sb,mVo),e(sb,CQ),e(CQ,fVo),e(sb,gVo),e(G,hVo),e(G,lb),e(lb,ube),e(ube,uVo),e(lb,pVo),e(lb,wQ),e(wQ,_Vo),e(lb,bVo),e(G,vVo),e(G,ib),e(ib,pbe),e(pbe,FVo),e(ib,TVo),e(ib,AQ),e(AQ,MVo),e(ib,EVo),e(G,CVo),e(G,db),e(db,_be),e(_be,wVo),e(db,AVo),e(db,LQ),e(LQ,LVo),e(db,yVo),e(G,xVo),e(G,cb),e(cb,bbe),e(bbe,$Vo),e(cb,kVo),e(cb,yQ),e(yQ,SVo),e(cb,RVo),e(G,PVo),e(G,mb),e(mb,vbe),e(vbe,BVo),e(mb,IVo),e(mb,xQ),e(xQ,NVo),e(mb,qVo),e(G,jVo),e(G,fb),e(fb,Fbe),e(Fbe,DVo),e(fb,GVo),e(fb,$Q),e($Q,OVo),e(fb,VVo),e(G,XVo),e(G,gb),e(gb,Tbe),e(Tbe,zVo),e(gb,QVo),e(gb,kQ),e(kQ,WVo),e(gb,UVo),e(G,HVo),e(G,hb),e(hb,Mbe),e(Mbe,JVo),e(hb,YVo),e(hb,SQ),e(SQ,ZVo),e(hb,KVo),e(G,eXo),e(G,ub),e(ub,Ebe),e(Ebe,oXo),e(ub,rXo),e(ub,RQ),e(RQ,tXo),e(ub,aXo),e(G,nXo),e(G,pb),e(pb,Cbe),e(Cbe,sXo),e(pb,lXo),e(pb,PQ),e(PQ,iXo),e(pb,dXo),e(G,cXo),e(G,_b),e(_b,wbe),e(wbe,mXo),e(_b,fXo),e(_b,BQ),e(BQ,gXo),e(_b,hXo),e(G,uXo),e(G,bb),e(bb,Abe),e(Abe,pXo),e(bb,_Xo),e(bb,IQ),e(IQ,bXo),e(bb,vXo),e(G,FXo),e(G,vb),e(vb,Lbe),e(Lbe,TXo),e(vb,MXo),e(vb,NQ),e(NQ,EXo),e(vb,CXo),e(G,wXo),e(G,Fb),e(Fb,ybe),e(ybe,AXo),e(Fb,LXo),e(Fb,qQ),e(qQ,yXo),e(Fb,xXo),e(G,$Xo),e(G,Tb),e(Tb,xbe),e(xbe,kXo),e(Tb,SXo),e(Tb,jQ),e(jQ,RXo),e(Tb,PXo),e(G,BXo),e(G,Mb),e(Mb,$be),e($be,IXo),e(Mb,NXo),e(Mb,DQ),e(DQ,qXo),e(Mb,jXo),e(G,DXo),e(G,Eb),e(Eb,kbe),e(kbe,GXo),e(Eb,OXo),e(Eb,GQ),e(GQ,VXo),e(Eb,XXo),e(G,zXo),e(G,Cb),e(Cb,Sbe),e(Sbe,QXo),e(Cb,WXo),e(Cb,OQ),e(OQ,UXo),e(Cb,HXo),e(G,JXo),e(G,wb),e(wb,Rbe),e(Rbe,YXo),e(wb,ZXo),e(wb,VQ),e(VQ,KXo),e(wb,ezo),e(G,ozo),e(G,Ab),e(Ab,Pbe),e(Pbe,rzo),e(Ab,tzo),e(Ab,XQ),e(XQ,azo),e(Ab,nzo),e(G,szo),e(G,Lb),e(Lb,Bbe),e(Bbe,lzo),e(Lb,izo),e(Lb,zQ),e(zQ,dzo),e(Lb,czo),e(G,mzo),e(G,yb),e(yb,Ibe),e(Ibe,fzo),e(yb,gzo),e(yb,QQ),e(QQ,hzo),e(yb,uzo),e(G,pzo),e(G,xb),e(xb,Nbe),e(Nbe,_zo),e(xb,bzo),e(xb,WQ),e(WQ,vzo),e(xb,Fzo),e(G,Tzo),e(G,$b),e($b,qbe),e(qbe,Mzo),e($b,Ezo),e($b,UQ),e(UQ,Czo),e($b,wzo),e(G,Azo),e(G,kb),e(kb,jbe),e(jbe,Lzo),e(kb,yzo),e(kb,HQ),e(HQ,xzo),e(kb,$zo),e(G,kzo),e(G,Sb),e(Sb,Dbe),e(Dbe,Szo),e(Sb,Rzo),e(Sb,JQ),e(JQ,Pzo),e(Sb,Bzo),e(G,Izo),e(G,Rb),e(Rb,Gbe),e(Gbe,Nzo),e(Rb,qzo),e(Rb,YQ),e(YQ,jzo),e(Rb,Dzo),e(G,Gzo),e(G,Pb),e(Pb,Obe),e(Obe,Ozo),e(Pb,Vzo),e(Pb,ZQ),e(ZQ,Xzo),e(Pb,zzo),e(eo,Qzo),e(eo,Bb),e(Bb,Wzo),e(Bb,Vbe),e(Vbe,Uzo),e(Bb,Hzo),e(Bb,Xbe),e(Xbe,Jzo),e(eo,Yzo),M(Ib,eo,null),b(m,Goo,_),b(m,xd,_),e(xd,Nb),e(Nb,zbe),M(f$,zbe,null),e(xd,Zzo),e(xd,Qbe),e(Qbe,Kzo),b(m,Ooo,_),b(m,No,_),M(g$,No,null),e(No,eQo),e(No,$d),e($d,oQo),e($d,KQ),e(KQ,rQo),e($d,tQo),e($d,eW),e(eW,aQo),e($d,nQo),e(No,sQo),e(No,h$),e(h$,lQo),e(h$,Wbe),e(Wbe,iQo),e(h$,dQo),e(No,cQo),e(No,Tt),M(u$,Tt,null),e(Tt,mQo),e(Tt,Ube),e(Ube,fQo),e(Tt,gQo),e(Tt,kd),e(kd,hQo),e(kd,Hbe),e(Hbe,uQo),e(kd,pQo),e(kd,oW),e(oW,_Qo),e(kd,bQo),e(Tt,vQo),M(qb,Tt,null),e(No,FQo),e(No,oo),M(p$,oo,null),e(oo,TQo),e(oo,Jbe),e(Jbe,MQo),e(oo,EQo),e(oo,rn),e(rn,CQo),e(rn,Ybe),e(Ybe,wQo),e(rn,AQo),e(rn,Zbe),e(Zbe,LQo),e(rn,yQo),e(rn,Kbe),e(Kbe,xQo),e(rn,$Qo),e(oo,kQo),e(oo,Q),e(Q,jb),e(jb,eve),e(eve,SQo),e(jb,RQo),e(jb,rW),e(rW,PQo),e(jb,BQo),e(Q,IQo),e(Q,Db),e(Db,ove),e(ove,NQo),e(Db,qQo),e(Db,tW),e(tW,jQo),e(Db,DQo),e(Q,GQo),e(Q,Gb),e(Gb,rve),e(rve,OQo),e(Gb,VQo),e(Gb,aW),e(aW,XQo),e(Gb,zQo),e(Q,QQo),e(Q,Ob),e(Ob,tve),e(tve,WQo),e(Ob,UQo),e(Ob,nW),e(nW,HQo),e(Ob,JQo),e(Q,YQo),e(Q,Vb),e(Vb,ave),e(ave,ZQo),e(Vb,KQo),e(Vb,sW),e(sW,eWo),e(Vb,oWo),e(Q,rWo),e(Q,Xb),e(Xb,nve),e(nve,tWo),e(Xb,aWo),e(Xb,lW),e(lW,nWo),e(Xb,sWo),e(Q,lWo),e(Q,zb),e(zb,sve),e(sve,iWo),e(zb,dWo),e(zb,iW),e(iW,cWo),e(zb,mWo),e(Q,fWo),e(Q,Qb),e(Qb,lve),e(lve,gWo),e(Qb,hWo),e(Qb,dW),e(dW,uWo),e(Qb,pWo),e(Q,_Wo),e(Q,Wb),e(Wb,ive),e(ive,bWo),e(Wb,vWo),e(Wb,cW),e(cW,FWo),e(Wb,TWo),e(Q,MWo),e(Q,Ub),e(Ub,dve),e(dve,EWo),e(Ub,CWo),e(Ub,mW),e(mW,wWo),e(Ub,AWo),e(Q,LWo),e(Q,Hb),e(Hb,cve),e(cve,yWo),e(Hb,xWo),e(Hb,fW),e(fW,$Wo),e(Hb,kWo),e(Q,SWo),e(Q,Jb),e(Jb,mve),e(mve,RWo),e(Jb,PWo),e(Jb,gW),e(gW,BWo),e(Jb,IWo),e(Q,NWo),e(Q,Yb),e(Yb,fve),e(fve,qWo),e(Yb,jWo),e(Yb,hW),e(hW,DWo),e(Yb,GWo),e(Q,OWo),e(Q,Zb),e(Zb,gve),e(gve,VWo),e(Zb,XWo),e(Zb,uW),e(uW,zWo),e(Zb,QWo),e(Q,WWo),e(Q,Kb),e(Kb,hve),e(hve,UWo),e(Kb,HWo),e(Kb,pW),e(pW,JWo),e(Kb,YWo),e(Q,ZWo),e(Q,ev),e(ev,uve),e(uve,KWo),e(ev,eUo),e(ev,_W),e(_W,oUo),e(ev,rUo),e(Q,tUo),e(Q,ov),e(ov,pve),e(pve,aUo),e(ov,nUo),e(ov,bW),e(bW,sUo),e(ov,lUo),e(Q,iUo),e(Q,rv),e(rv,_ve),e(_ve,dUo),e(rv,cUo),e(rv,vW),e(vW,mUo),e(rv,fUo),e(Q,gUo),e(Q,tv),e(tv,bve),e(bve,hUo),e(tv,uUo),e(tv,FW),e(FW,pUo),e(tv,_Uo),e(Q,bUo),e(Q,av),e(av,vve),e(vve,vUo),e(av,FUo),e(av,TW),e(TW,TUo),e(av,MUo),e(Q,EUo),e(Q,nv),e(nv,Fve),e(Fve,CUo),e(nv,wUo),e(nv,MW),e(MW,AUo),e(nv,LUo),e(Q,yUo),e(Q,sv),e(sv,Tve),e(Tve,xUo),e(sv,$Uo),e(sv,EW),e(EW,kUo),e(sv,SUo),e(Q,RUo),e(Q,lv),e(lv,Mve),e(Mve,PUo),e(lv,BUo),e(lv,CW),e(CW,IUo),e(lv,NUo),e(Q,qUo),e(Q,iv),e(iv,Eve),e(Eve,jUo),e(iv,DUo),e(iv,wW),e(wW,GUo),e(iv,OUo),e(Q,VUo),e(Q,dv),e(dv,Cve),e(Cve,XUo),e(dv,zUo),e(dv,AW),e(AW,QUo),e(dv,WUo),e(Q,UUo),e(Q,cv),e(cv,wve),e(wve,HUo),e(cv,JUo),e(cv,LW),e(LW,YUo),e(cv,ZUo),e(Q,KUo),e(Q,mv),e(mv,Ave),e(Ave,eHo),e(mv,oHo),e(mv,yW),e(yW,rHo),e(mv,tHo),e(Q,aHo),e(Q,fv),e(fv,Lve),e(Lve,nHo),e(fv,sHo),e(fv,xW),e(xW,lHo),e(fv,iHo),e(Q,dHo),e(Q,gv),e(gv,yve),e(yve,cHo),e(gv,mHo),e(gv,$W),e($W,fHo),e(gv,gHo),e(Q,hHo),e(Q,hv),e(hv,xve),e(xve,uHo),e(hv,pHo),e(hv,kW),e(kW,_Ho),e(hv,bHo),e(Q,vHo),e(Q,uv),e(uv,$ve),e($ve,FHo),e(uv,THo),e(uv,SW),e(SW,MHo),e(uv,EHo),e(Q,CHo),e(Q,pv),e(pv,kve),e(kve,wHo),e(pv,AHo),e(pv,RW),e(RW,LHo),e(pv,yHo),e(Q,xHo),e(Q,_v),e(_v,Sve),e(Sve,$Ho),e(_v,kHo),e(_v,PW),e(PW,SHo),e(_v,RHo),e(Q,PHo),e(Q,bv),e(bv,Rve),e(Rve,BHo),e(bv,IHo),e(bv,BW),e(BW,NHo),e(bv,qHo),e(Q,jHo),e(Q,vv),e(vv,Pve),e(Pve,DHo),e(vv,GHo),e(vv,IW),e(IW,OHo),e(vv,VHo),e(Q,XHo),e(Q,Fv),e(Fv,Bve),e(Bve,zHo),e(Fv,QHo),e(Fv,NW),e(NW,WHo),e(Fv,UHo),e(Q,HHo),e(Q,Tv),e(Tv,Ive),e(Ive,JHo),e(Tv,YHo),e(Tv,qW),e(qW,ZHo),e(Tv,KHo),e(Q,eJo),e(Q,Mv),e(Mv,Nve),e(Nve,oJo),e(Mv,rJo),e(Mv,jW),e(jW,tJo),e(Mv,aJo),e(Q,nJo),e(Q,Ev),e(Ev,qve),e(qve,sJo),e(Ev,lJo),e(Ev,DW),e(DW,iJo),e(Ev,dJo),e(Q,cJo),e(Q,Cv),e(Cv,jve),e(jve,mJo),e(Cv,fJo),e(Cv,GW),e(GW,gJo),e(Cv,hJo),e(Q,uJo),e(Q,wv),e(wv,Dve),e(Dve,pJo),e(wv,_Jo),e(wv,OW),e(OW,bJo),e(wv,vJo),e(Q,FJo),e(Q,Av),e(Av,Gve),e(Gve,TJo),e(Av,MJo),e(Av,VW),e(VW,EJo),e(Av,CJo),e(oo,wJo),e(oo,Lv),e(Lv,AJo),e(Lv,Ove),e(Ove,LJo),e(Lv,yJo),e(Lv,Vve),e(Vve,xJo),e(oo,$Jo),M(yv,oo,null),b(m,Voo,_),b(m,Sd,_),e(Sd,xv),e(xv,Xve),M(_$,Xve,null),e(Sd,kJo),e(Sd,zve),e(zve,SJo),b(m,Xoo,_),b(m,qo,_),M(b$,qo,null),e(qo,RJo),e(qo,Rd),e(Rd,PJo),e(Rd,XW),e(XW,BJo),e(Rd,IJo),e(Rd,zW),e(zW,NJo),e(Rd,qJo),e(qo,jJo),e(qo,v$),e(v$,DJo),e(v$,Qve),e(Qve,GJo),e(v$,OJo),e(qo,VJo),e(qo,Mt),M(F$,Mt,null),e(Mt,XJo),e(Mt,Wve),e(Wve,zJo),e(Mt,QJo),e(Mt,Pd),e(Pd,WJo),e(Pd,Uve),e(Uve,UJo),e(Pd,HJo),e(Pd,QW),e(QW,JJo),e(Pd,YJo),e(Mt,ZJo),M($v,Mt,null),e(qo,KJo),e(qo,ro),M(T$,ro,null),e(ro,eYo),e(ro,Hve),e(Hve,oYo),e(ro,rYo),e(ro,tn),e(tn,tYo),e(tn,Jve),e(Jve,aYo),e(tn,nYo),e(tn,Yve),e(Yve,sYo),e(tn,lYo),e(tn,Zve),e(Zve,iYo),e(tn,dYo),e(ro,cYo),e(ro,J),e(J,kv),e(kv,Kve),e(Kve,mYo),e(kv,fYo),e(kv,WW),e(WW,gYo),e(kv,hYo),e(J,uYo),e(J,Sv),e(Sv,eFe),e(eFe,pYo),e(Sv,_Yo),e(Sv,UW),e(UW,bYo),e(Sv,vYo),e(J,FYo),e(J,Rv),e(Rv,oFe),e(oFe,TYo),e(Rv,MYo),e(Rv,HW),e(HW,EYo),e(Rv,CYo),e(J,wYo),e(J,Pv),e(Pv,rFe),e(rFe,AYo),e(Pv,LYo),e(Pv,JW),e(JW,yYo),e(Pv,xYo),e(J,$Yo),e(J,Bv),e(Bv,tFe),e(tFe,kYo),e(Bv,SYo),e(Bv,YW),e(YW,RYo),e(Bv,PYo),e(J,BYo),e(J,Iv),e(Iv,aFe),e(aFe,IYo),e(Iv,NYo),e(Iv,ZW),e(ZW,qYo),e(Iv,jYo),e(J,DYo),e(J,Nv),e(Nv,nFe),e(nFe,GYo),e(Nv,OYo),e(Nv,KW),e(KW,VYo),e(Nv,XYo),e(J,zYo),e(J,qv),e(qv,sFe),e(sFe,QYo),e(qv,WYo),e(qv,eU),e(eU,UYo),e(qv,HYo),e(J,JYo),e(J,jv),e(jv,lFe),e(lFe,YYo),e(jv,ZYo),e(jv,oU),e(oU,KYo),e(jv,eZo),e(J,oZo),e(J,Dv),e(Dv,iFe),e(iFe,rZo),e(Dv,tZo),e(Dv,rU),e(rU,aZo),e(Dv,nZo),e(J,sZo),e(J,Gv),e(Gv,dFe),e(dFe,lZo),e(Gv,iZo),e(Gv,tU),e(tU,dZo),e(Gv,cZo),e(J,mZo),e(J,Ov),e(Ov,cFe),e(cFe,fZo),e(Ov,gZo),e(Ov,aU),e(aU,hZo),e(Ov,uZo),e(J,pZo),e(J,Vv),e(Vv,mFe),e(mFe,_Zo),e(Vv,bZo),e(Vv,nU),e(nU,vZo),e(Vv,FZo),e(J,TZo),e(J,Xv),e(Xv,fFe),e(fFe,MZo),e(Xv,EZo),e(Xv,sU),e(sU,CZo),e(Xv,wZo),e(J,AZo),e(J,zv),e(zv,gFe),e(gFe,LZo),e(zv,yZo),e(zv,lU),e(lU,xZo),e(zv,$Zo),e(J,kZo),e(J,Qv),e(Qv,hFe),e(hFe,SZo),e(Qv,RZo),e(Qv,iU),e(iU,PZo),e(Qv,BZo),e(J,IZo),e(J,Wv),e(Wv,uFe),e(uFe,NZo),e(Wv,qZo),e(Wv,dU),e(dU,jZo),e(Wv,DZo),e(J,GZo),e(J,Uv),e(Uv,pFe),e(pFe,OZo),e(Uv,VZo),e(Uv,cU),e(cU,XZo),e(Uv,zZo),e(J,QZo),e(J,Hv),e(Hv,_Fe),e(_Fe,WZo),e(Hv,UZo),e(Hv,mU),e(mU,HZo),e(Hv,JZo),e(J,YZo),e(J,Jv),e(Jv,bFe),e(bFe,ZZo),e(Jv,KZo),e(Jv,fU),e(fU,eKo),e(Jv,oKo),e(J,rKo),e(J,Yv),e(Yv,vFe),e(vFe,tKo),e(Yv,aKo),e(Yv,gU),e(gU,nKo),e(Yv,sKo),e(J,lKo),e(J,Zv),e(Zv,FFe),e(FFe,iKo),e(Zv,dKo),e(Zv,hU),e(hU,cKo),e(Zv,mKo),e(J,fKo),e(J,Kv),e(Kv,TFe),e(TFe,gKo),e(Kv,hKo),e(Kv,uU),e(uU,uKo),e(Kv,pKo),e(J,_Ko),e(J,eF),e(eF,MFe),e(MFe,bKo),e(eF,vKo),e(eF,pU),e(pU,FKo),e(eF,TKo),e(J,MKo),e(J,oF),e(oF,EFe),e(EFe,EKo),e(oF,CKo),e(oF,_U),e(_U,wKo),e(oF,AKo),e(J,LKo),e(J,rF),e(rF,CFe),e(CFe,yKo),e(rF,xKo),e(rF,bU),e(bU,$Ko),e(rF,kKo),e(J,SKo),e(J,tF),e(tF,wFe),e(wFe,RKo),e(tF,PKo),e(tF,vU),e(vU,BKo),e(tF,IKo),e(J,NKo),e(J,aF),e(aF,AFe),e(AFe,qKo),e(aF,jKo),e(aF,FU),e(FU,DKo),e(aF,GKo),e(J,OKo),e(J,nF),e(nF,LFe),e(LFe,VKo),e(nF,XKo),e(nF,TU),e(TU,zKo),e(nF,QKo),e(J,WKo),e(J,sF),e(sF,yFe),e(yFe,UKo),e(sF,HKo),e(sF,MU),e(MU,JKo),e(sF,YKo),e(J,ZKo),e(J,lF),e(lF,xFe),e(xFe,KKo),e(lF,eer),e(lF,EU),e(EU,oer),e(lF,rer),e(J,ter),e(J,iF),e(iF,$Fe),e($Fe,aer),e(iF,ner),e(iF,CU),e(CU,ser),e(iF,ler),e(J,ier),e(J,dF),e(dF,kFe),e(kFe,der),e(dF,cer),e(dF,wU),e(wU,mer),e(dF,fer),e(J,ger),e(J,cF),e(cF,SFe),e(SFe,her),e(cF,uer),e(cF,AU),e(AU,per),e(cF,_er),e(J,ber),e(J,mF),e(mF,RFe),e(RFe,ver),e(mF,Fer),e(mF,PFe),e(PFe,Ter),e(mF,Mer),e(J,Eer),e(J,fF),e(fF,BFe),e(BFe,Cer),e(fF,wer),e(fF,LU),e(LU,Aer),e(fF,Ler),e(J,yer),e(J,gF),e(gF,IFe),e(IFe,xer),e(gF,$er),e(gF,yU),e(yU,ker),e(gF,Ser),e(J,Rer),e(J,hF),e(hF,NFe),e(NFe,Per),e(hF,Ber),e(hF,xU),e(xU,Ier),e(hF,Ner),e(J,qer),e(J,uF),e(uF,qFe),e(qFe,jer),e(uF,Der),e(uF,$U),e($U,Ger),e(uF,Oer),e(ro,Ver),e(ro,pF),e(pF,Xer),e(pF,jFe),e(jFe,zer),e(pF,Qer),e(pF,DFe),e(DFe,Wer),e(ro,Uer),M(_F,ro,null),b(m,zoo,_),b(m,Bd,_),e(Bd,bF),e(bF,GFe),M(M$,GFe,null),e(Bd,Her),e(Bd,OFe),e(OFe,Jer),b(m,Qoo,_),b(m,jo,_),M(E$,jo,null),e(jo,Yer),e(jo,Id),e(Id,Zer),e(Id,kU),e(kU,Ker),e(Id,eor),e(Id,SU),e(SU,oor),e(Id,ror),e(jo,tor),e(jo,C$),e(C$,aor),e(C$,VFe),e(VFe,nor),e(C$,sor),e(jo,lor),e(jo,Et),M(w$,Et,null),e(Et,ior),e(Et,XFe),e(XFe,dor),e(Et,cor),e(Et,Nd),e(Nd,mor),e(Nd,zFe),e(zFe,gor),e(Nd,hor),e(Nd,RU),e(RU,uor),e(Nd,por),e(Et,_or),M(vF,Et,null),e(jo,bor),e(jo,to),M(A$,to,null),e(to,vor),e(to,QFe),e(QFe,For),e(to,Tor),e(to,an),e(an,Mor),e(an,WFe),e(WFe,Eor),e(an,Cor),e(an,UFe),e(UFe,wor),e(an,Aor),e(an,HFe),e(HFe,Lor),e(an,yor),e(to,xor),e(to,fe),e(fe,FF),e(FF,JFe),e(JFe,$or),e(FF,kor),e(FF,PU),e(PU,Sor),e(FF,Ror),e(fe,Por),e(fe,TF),e(TF,YFe),e(YFe,Bor),e(TF,Ior),e(TF,BU),e(BU,Nor),e(TF,qor),e(fe,jor),e(fe,MF),e(MF,ZFe),e(ZFe,Dor),e(MF,Gor),e(MF,IU),e(IU,Oor),e(MF,Vor),e(fe,Xor),e(fe,EF),e(EF,KFe),e(KFe,zor),e(EF,Qor),e(EF,NU),e(NU,Wor),e(EF,Uor),e(fe,Hor),e(fe,CF),e(CF,eTe),e(eTe,Jor),e(CF,Yor),e(CF,qU),e(qU,Zor),e(CF,Kor),e(fe,err),e(fe,wF),e(wF,oTe),e(oTe,orr),e(wF,rrr),e(wF,jU),e(jU,trr),e(wF,arr),e(fe,nrr),e(fe,AF),e(AF,rTe),e(rTe,srr),e(AF,lrr),e(AF,DU),e(DU,irr),e(AF,drr),e(fe,crr),e(fe,LF),e(LF,tTe),e(tTe,mrr),e(LF,frr),e(LF,GU),e(GU,grr),e(LF,hrr),e(fe,urr),e(fe,yF),e(yF,aTe),e(aTe,prr),e(yF,_rr),e(yF,OU),e(OU,brr),e(yF,vrr),e(fe,Frr),e(fe,xF),e(xF,nTe),e(nTe,Trr),e(xF,Mrr),e(xF,VU),e(VU,Err),e(xF,Crr),e(fe,wrr),e(fe,$F),e($F,sTe),e(sTe,Arr),e($F,Lrr),e($F,XU),e(XU,yrr),e($F,xrr),e(fe,$rr),e(fe,kF),e(kF,lTe),e(lTe,krr),e(kF,Srr),e(kF,zU),e(zU,Rrr),e(kF,Prr),e(fe,Brr),e(fe,SF),e(SF,iTe),e(iTe,Irr),e(SF,Nrr),e(SF,QU),e(QU,qrr),e(SF,jrr),e(fe,Drr),e(fe,RF),e(RF,dTe),e(dTe,Grr),e(RF,Orr),e(RF,WU),e(WU,Vrr),e(RF,Xrr),e(fe,zrr),e(fe,PF),e(PF,cTe),e(cTe,Qrr),e(PF,Wrr),e(PF,UU),e(UU,Urr),e(PF,Hrr),e(fe,Jrr),e(fe,BF),e(BF,mTe),e(mTe,Yrr),e(BF,Zrr),e(BF,HU),e(HU,Krr),e(BF,etr),e(fe,otr),e(fe,IF),e(IF,fTe),e(fTe,rtr),e(IF,ttr),e(IF,JU),e(JU,atr),e(IF,ntr),e(fe,str),e(fe,NF),e(NF,gTe),e(gTe,ltr),e(NF,itr),e(NF,YU),e(YU,dtr),e(NF,ctr),e(fe,mtr),e(fe,qF),e(qF,hTe),e(hTe,ftr),e(qF,gtr),e(qF,ZU),e(ZU,htr),e(qF,utr),e(fe,ptr),e(fe,jF),e(jF,uTe),e(uTe,_tr),e(jF,btr),e(jF,KU),e(KU,vtr),e(jF,Ftr),e(to,Ttr),e(to,DF),e(DF,Mtr),e(DF,pTe),e(pTe,Etr),e(DF,Ctr),e(DF,_Te),e(_Te,wtr),e(to,Atr),M(GF,to,null),b(m,Woo,_),b(m,qd,_),e(qd,OF),e(OF,bTe),M(L$,bTe,null),e(qd,Ltr),e(qd,vTe),e(vTe,ytr),b(m,Uoo,_),b(m,Do,_),M(y$,Do,null),e(Do,xtr),e(Do,jd),e(jd,$tr),e(jd,eH),e(eH,ktr),e(jd,Str),e(jd,oH),e(oH,Rtr),e(jd,Ptr),e(Do,Btr),e(Do,x$),e(x$,Itr),e(x$,FTe),e(FTe,Ntr),e(x$,qtr),e(Do,jtr),e(Do,Ct),M($$,Ct,null),e(Ct,Dtr),e(Ct,TTe),e(TTe,Gtr),e(Ct,Otr),e(Ct,Dd),e(Dd,Vtr),e(Dd,MTe),e(MTe,Xtr),e(Dd,ztr),e(Dd,rH),e(rH,Qtr),e(Dd,Wtr),e(Ct,Utr),M(VF,Ct,null),e(Do,Htr),e(Do,ao),M(k$,ao,null),e(ao,Jtr),e(ao,ETe),e(ETe,Ytr),e(ao,Ztr),e(ao,nn),e(nn,Ktr),e(nn,CTe),e(CTe,ear),e(nn,oar),e(nn,wTe),e(wTe,rar),e(nn,tar),e(nn,ATe),e(ATe,aar),e(nn,nar),e(ao,sar),e(ao,j),e(j,XF),e(XF,LTe),e(LTe,lar),e(XF,iar),e(XF,tH),e(tH,dar),e(XF,car),e(j,mar),e(j,zF),e(zF,yTe),e(yTe,far),e(zF,gar),e(zF,aH),e(aH,har),e(zF,uar),e(j,par),e(j,QF),e(QF,xTe),e(xTe,_ar),e(QF,bar),e(QF,nH),e(nH,Far),e(QF,Tar),e(j,Mar),e(j,WF),e(WF,$Te),e($Te,Ear),e(WF,Car),e(WF,sH),e(sH,war),e(WF,Aar),e(j,Lar),e(j,UF),e(UF,kTe),e(kTe,yar),e(UF,xar),e(UF,lH),e(lH,$ar),e(UF,kar),e(j,Sar),e(j,HF),e(HF,STe),e(STe,Rar),e(HF,Par),e(HF,iH),e(iH,Bar),e(HF,Iar),e(j,Nar),e(j,JF),e(JF,RTe),e(RTe,qar),e(JF,jar),e(JF,dH),e(dH,Dar),e(JF,Gar),e(j,Oar),e(j,YF),e(YF,PTe),e(PTe,Var),e(YF,Xar),e(YF,cH),e(cH,zar),e(YF,Qar),e(j,War),e(j,ZF),e(ZF,BTe),e(BTe,Uar),e(ZF,Har),e(ZF,mH),e(mH,Jar),e(ZF,Yar),e(j,Zar),e(j,KF),e(KF,ITe),e(ITe,Kar),e(KF,enr),e(KF,fH),e(fH,onr),e(KF,rnr),e(j,tnr),e(j,eT),e(eT,NTe),e(NTe,anr),e(eT,nnr),e(eT,gH),e(gH,snr),e(eT,lnr),e(j,inr),e(j,oT),e(oT,qTe),e(qTe,dnr),e(oT,cnr),e(oT,hH),e(hH,mnr),e(oT,fnr),e(j,gnr),e(j,rT),e(rT,jTe),e(jTe,hnr),e(rT,unr),e(rT,uH),e(uH,pnr),e(rT,_nr),e(j,bnr),e(j,tT),e(tT,DTe),e(DTe,vnr),e(tT,Fnr),e(tT,pH),e(pH,Tnr),e(tT,Mnr),e(j,Enr),e(j,aT),e(aT,GTe),e(GTe,Cnr),e(aT,wnr),e(aT,_H),e(_H,Anr),e(aT,Lnr),e(j,ynr),e(j,nT),e(nT,OTe),e(OTe,xnr),e(nT,$nr),e(nT,bH),e(bH,knr),e(nT,Snr),e(j,Rnr),e(j,sT),e(sT,VTe),e(VTe,Pnr),e(sT,Bnr),e(sT,vH),e(vH,Inr),e(sT,Nnr),e(j,qnr),e(j,lT),e(lT,XTe),e(XTe,jnr),e(lT,Dnr),e(lT,FH),e(FH,Gnr),e(lT,Onr),e(j,Vnr),e(j,iT),e(iT,zTe),e(zTe,Xnr),e(iT,znr),e(iT,TH),e(TH,Qnr),e(iT,Wnr),e(j,Unr),e(j,dT),e(dT,QTe),e(QTe,Hnr),e(dT,Jnr),e(dT,MH),e(MH,Ynr),e(dT,Znr),e(j,Knr),e(j,cT),e(cT,WTe),e(WTe,esr),e(cT,osr),e(cT,EH),e(EH,rsr),e(cT,tsr),e(j,asr),e(j,mT),e(mT,UTe),e(UTe,nsr),e(mT,ssr),e(mT,CH),e(CH,lsr),e(mT,isr),e(j,dsr),e(j,fT),e(fT,HTe),e(HTe,csr),e(fT,msr),e(fT,wH),e(wH,fsr),e(fT,gsr),e(j,hsr),e(j,gT),e(gT,JTe),e(JTe,usr),e(gT,psr),e(gT,AH),e(AH,_sr),e(gT,bsr),e(j,vsr),e(j,hT),e(hT,YTe),e(YTe,Fsr),e(hT,Tsr),e(hT,LH),e(LH,Msr),e(hT,Esr),e(j,Csr),e(j,uT),e(uT,ZTe),e(ZTe,wsr),e(uT,Asr),e(uT,yH),e(yH,Lsr),e(uT,ysr),e(j,xsr),e(j,pT),e(pT,KTe),e(KTe,$sr),e(pT,ksr),e(pT,xH),e(xH,Ssr),e(pT,Rsr),e(j,Psr),e(j,_T),e(_T,eMe),e(eMe,Bsr),e(_T,Isr),e(_T,$H),e($H,Nsr),e(_T,qsr),e(j,jsr),e(j,bT),e(bT,oMe),e(oMe,Dsr),e(bT,Gsr),e(bT,kH),e(kH,Osr),e(bT,Vsr),e(j,Xsr),e(j,vT),e(vT,rMe),e(rMe,zsr),e(vT,Qsr),e(vT,SH),e(SH,Wsr),e(vT,Usr),e(j,Hsr),e(j,FT),e(FT,tMe),e(tMe,Jsr),e(FT,Ysr),e(FT,RH),e(RH,Zsr),e(FT,Ksr),e(j,elr),e(j,TT),e(TT,aMe),e(aMe,olr),e(TT,rlr),e(TT,PH),e(PH,tlr),e(TT,alr),e(j,nlr),e(j,MT),e(MT,nMe),e(nMe,slr),e(MT,llr),e(MT,BH),e(BH,ilr),e(MT,dlr),e(j,clr),e(j,ET),e(ET,sMe),e(sMe,mlr),e(ET,flr),e(ET,IH),e(IH,glr),e(ET,hlr),e(j,ulr),e(j,CT),e(CT,lMe),e(lMe,plr),e(CT,_lr),e(CT,NH),e(NH,blr),e(CT,vlr),e(j,Flr),e(j,wT),e(wT,iMe),e(iMe,Tlr),e(wT,Mlr),e(wT,qH),e(qH,Elr),e(wT,Clr),e(j,wlr),e(j,AT),e(AT,dMe),e(dMe,Alr),e(AT,Llr),e(AT,jH),e(jH,ylr),e(AT,xlr),e(j,$lr),e(j,LT),e(LT,cMe),e(cMe,klr),e(LT,Slr),e(LT,DH),e(DH,Rlr),e(LT,Plr),e(j,Blr),e(j,yT),e(yT,mMe),e(mMe,Ilr),e(yT,Nlr),e(yT,GH),e(GH,qlr),e(yT,jlr),e(j,Dlr),e(j,xT),e(xT,fMe),e(fMe,Glr),e(xT,Olr),e(xT,OH),e(OH,Vlr),e(xT,Xlr),e(j,zlr),e(j,$T),e($T,gMe),e(gMe,Qlr),e($T,Wlr),e($T,VH),e(VH,Ulr),e($T,Hlr),e(j,Jlr),e(j,kT),e(kT,hMe),e(hMe,Ylr),e(kT,Zlr),e(kT,XH),e(XH,Klr),e(kT,eir),e(j,oir),e(j,ST),e(ST,uMe),e(uMe,rir),e(ST,tir),e(ST,zH),e(zH,air),e(ST,nir),e(j,sir),e(j,RT),e(RT,pMe),e(pMe,lir),e(RT,iir),e(RT,QH),e(QH,dir),e(RT,cir),e(j,mir),e(j,PT),e(PT,_Me),e(_Me,fir),e(PT,gir),e(PT,WH),e(WH,hir),e(PT,uir),e(j,pir),e(j,BT),e(BT,bMe),e(bMe,_ir),e(BT,bir),e(BT,UH),e(UH,vir),e(BT,Fir),e(j,Tir),e(j,IT),e(IT,vMe),e(vMe,Mir),e(IT,Eir),e(IT,HH),e(HH,Cir),e(IT,wir),e(j,Air),e(j,NT),e(NT,FMe),e(FMe,Lir),e(NT,yir),e(NT,JH),e(JH,xir),e(NT,$ir),e(j,kir),e(j,qT),e(qT,TMe),e(TMe,Sir),e(qT,Rir),e(qT,YH),e(YH,Pir),e(qT,Bir),e(j,Iir),e(j,jT),e(jT,MMe),e(MMe,Nir),e(jT,qir),e(jT,ZH),e(ZH,jir),e(jT,Dir),e(j,Gir),e(j,DT),e(DT,EMe),e(EMe,Oir),e(DT,Vir),e(DT,KH),e(KH,Xir),e(DT,zir),e(j,Qir),e(j,GT),e(GT,CMe),e(CMe,Wir),e(GT,Uir),e(GT,eJ),e(eJ,Hir),e(GT,Jir),e(j,Yir),e(j,OT),e(OT,wMe),e(wMe,Zir),e(OT,Kir),e(OT,oJ),e(oJ,edr),e(OT,odr),e(j,rdr),e(j,VT),e(VT,AMe),e(AMe,tdr),e(VT,adr),e(VT,rJ),e(rJ,ndr),e(VT,sdr),e(j,ldr),e(j,XT),e(XT,LMe),e(LMe,idr),e(XT,ddr),e(XT,tJ),e(tJ,cdr),e(XT,mdr),e(ao,fdr),e(ao,zT),e(zT,gdr),e(zT,yMe),e(yMe,hdr),e(zT,udr),e(zT,xMe),e(xMe,pdr),e(ao,_dr),M(QT,ao,null),b(m,Hoo,_),b(m,Gd,_),e(Gd,WT),e(WT,$Me),M(S$,$Me,null),e(Gd,bdr),e(Gd,kMe),e(kMe,vdr),b(m,Joo,_),b(m,Go,_),M(R$,Go,null),e(Go,Fdr),e(Go,Od),e(Od,Tdr),e(Od,aJ),e(aJ,Mdr),e(Od,Edr),e(Od,nJ),e(nJ,Cdr),e(Od,wdr),e(Go,Adr),e(Go,P$),e(P$,Ldr),e(P$,SMe),e(SMe,ydr),e(P$,xdr),e(Go,$dr),e(Go,wt),M(B$,wt,null),e(wt,kdr),e(wt,RMe),e(RMe,Sdr),e(wt,Rdr),e(wt,Vd),e(Vd,Pdr),e(Vd,PMe),e(PMe,Bdr),e(Vd,Idr),e(Vd,sJ),e(sJ,Ndr),e(Vd,qdr),e(wt,jdr),M(UT,wt,null),e(Go,Ddr),e(Go,no),M(I$,no,null),e(no,Gdr),e(no,BMe),e(BMe,Odr),e(no,Vdr),e(no,sn),e(sn,Xdr),e(sn,IMe),e(IMe,zdr),e(sn,Qdr),e(sn,NMe),e(NMe,Wdr),e(sn,Udr),e(sn,qMe),e(qMe,Hdr),e(sn,Jdr),e(no,Ydr),e(no,K),e(K,HT),e(HT,jMe),e(jMe,Zdr),e(HT,Kdr),e(HT,lJ),e(lJ,ecr),e(HT,ocr),e(K,rcr),e(K,JT),e(JT,DMe),e(DMe,tcr),e(JT,acr),e(JT,iJ),e(iJ,ncr),e(JT,scr),e(K,lcr),e(K,YT),e(YT,GMe),e(GMe,icr),e(YT,dcr),e(YT,dJ),e(dJ,ccr),e(YT,mcr),e(K,fcr),e(K,ZT),e(ZT,OMe),e(OMe,gcr),e(ZT,hcr),e(ZT,cJ),e(cJ,ucr),e(ZT,pcr),e(K,_cr),e(K,KT),e(KT,VMe),e(VMe,bcr),e(KT,vcr),e(KT,mJ),e(mJ,Fcr),e(KT,Tcr),e(K,Mcr),e(K,eM),e(eM,XMe),e(XMe,Ecr),e(eM,Ccr),e(eM,fJ),e(fJ,wcr),e(eM,Acr),e(K,Lcr),e(K,oM),e(oM,zMe),e(zMe,ycr),e(oM,xcr),e(oM,gJ),e(gJ,$cr),e(oM,kcr),e(K,Scr),e(K,rM),e(rM,QMe),e(QMe,Rcr),e(rM,Pcr),e(rM,hJ),e(hJ,Bcr),e(rM,Icr),e(K,Ncr),e(K,tM),e(tM,WMe),e(WMe,qcr),e(tM,jcr),e(tM,uJ),e(uJ,Dcr),e(tM,Gcr),e(K,Ocr),e(K,aM),e(aM,UMe),e(UMe,Vcr),e(aM,Xcr),e(aM,pJ),e(pJ,zcr),e(aM,Qcr),e(K,Wcr),e(K,nM),e(nM,HMe),e(HMe,Ucr),e(nM,Hcr),e(nM,_J),e(_J,Jcr),e(nM,Ycr),e(K,Zcr),e(K,sM),e(sM,JMe),e(JMe,Kcr),e(sM,emr),e(sM,bJ),e(bJ,omr),e(sM,rmr),e(K,tmr),e(K,lM),e(lM,YMe),e(YMe,amr),e(lM,nmr),e(lM,vJ),e(vJ,smr),e(lM,lmr),e(K,imr),e(K,iM),e(iM,ZMe),e(ZMe,dmr),e(iM,cmr),e(iM,FJ),e(FJ,mmr),e(iM,fmr),e(K,gmr),e(K,dM),e(dM,KMe),e(KMe,hmr),e(dM,umr),e(dM,TJ),e(TJ,pmr),e(dM,_mr),e(K,bmr),e(K,cM),e(cM,eEe),e(eEe,vmr),e(cM,Fmr),e(cM,MJ),e(MJ,Tmr),e(cM,Mmr),e(K,Emr),e(K,mM),e(mM,oEe),e(oEe,Cmr),e(mM,wmr),e(mM,EJ),e(EJ,Amr),e(mM,Lmr),e(K,ymr),e(K,fM),e(fM,rEe),e(rEe,xmr),e(fM,$mr),e(fM,CJ),e(CJ,kmr),e(fM,Smr),e(K,Rmr),e(K,gM),e(gM,tEe),e(tEe,Pmr),e(gM,Bmr),e(gM,wJ),e(wJ,Imr),e(gM,Nmr),e(K,qmr),e(K,hM),e(hM,aEe),e(aEe,jmr),e(hM,Dmr),e(hM,AJ),e(AJ,Gmr),e(hM,Omr),e(K,Vmr),e(K,uM),e(uM,nEe),e(nEe,Xmr),e(uM,zmr),e(uM,LJ),e(LJ,Qmr),e(uM,Wmr),e(K,Umr),e(K,pM),e(pM,sEe),e(sEe,Hmr),e(pM,Jmr),e(pM,yJ),e(yJ,Ymr),e(pM,Zmr),e(K,Kmr),e(K,_M),e(_M,lEe),e(lEe,efr),e(_M,ofr),e(_M,xJ),e(xJ,rfr),e(_M,tfr),e(K,afr),e(K,bM),e(bM,iEe),e(iEe,nfr),e(bM,sfr),e(bM,$J),e($J,lfr),e(bM,ifr),e(K,dfr),e(K,vM),e(vM,dEe),e(dEe,cfr),e(vM,mfr),e(vM,kJ),e(kJ,ffr),e(vM,gfr),e(K,hfr),e(K,FM),e(FM,cEe),e(cEe,ufr),e(FM,pfr),e(FM,SJ),e(SJ,_fr),e(FM,bfr),e(K,vfr),e(K,TM),e(TM,mEe),e(mEe,Ffr),e(TM,Tfr),e(TM,RJ),e(RJ,Mfr),e(TM,Efr),e(K,Cfr),e(K,MM),e(MM,fEe),e(fEe,wfr),e(MM,Afr),e(MM,PJ),e(PJ,Lfr),e(MM,yfr),e(K,xfr),e(K,EM),e(EM,gEe),e(gEe,$fr),e(EM,kfr),e(EM,BJ),e(BJ,Sfr),e(EM,Rfr),e(K,Pfr),e(K,CM),e(CM,hEe),e(hEe,Bfr),e(CM,Ifr),e(CM,IJ),e(IJ,Nfr),e(CM,qfr),e(K,jfr),e(K,wM),e(wM,uEe),e(uEe,Dfr),e(wM,Gfr),e(wM,NJ),e(NJ,Ofr),e(wM,Vfr),e(K,Xfr),e(K,AM),e(AM,pEe),e(pEe,zfr),e(AM,Qfr),e(AM,qJ),e(qJ,Wfr),e(AM,Ufr),e(no,Hfr),e(no,LM),e(LM,Jfr),e(LM,_Ee),e(_Ee,Yfr),e(LM,Zfr),e(LM,bEe),e(bEe,Kfr),e(no,egr),M(yM,no,null),b(m,Yoo,_),b(m,Xd,_),e(Xd,xM),e(xM,vEe),M(N$,vEe,null),e(Xd,ogr),e(Xd,FEe),e(FEe,rgr),b(m,Zoo,_),b(m,Oo,_),M(q$,Oo,null),e(Oo,tgr),e(Oo,zd),e(zd,agr),e(zd,jJ),e(jJ,ngr),e(zd,sgr),e(zd,DJ),e(DJ,lgr),e(zd,igr),e(Oo,dgr),e(Oo,j$),e(j$,cgr),e(j$,TEe),e(TEe,mgr),e(j$,fgr),e(Oo,ggr),e(Oo,At),M(D$,At,null),e(At,hgr),e(At,MEe),e(MEe,ugr),e(At,pgr),e(At,Qd),e(Qd,_gr),e(Qd,EEe),e(EEe,bgr),e(Qd,vgr),e(Qd,GJ),e(GJ,Fgr),e(Qd,Tgr),e(At,Mgr),M($M,At,null),e(Oo,Egr),e(Oo,so),M(G$,so,null),e(so,Cgr),e(so,CEe),e(CEe,wgr),e(so,Agr),e(so,ln),e(ln,Lgr),e(ln,wEe),e(wEe,ygr),e(ln,xgr),e(ln,AEe),e(AEe,$gr),e(ln,kgr),e(ln,LEe),e(LEe,Sgr),e(ln,Rgr),e(so,Pgr),e(so,Ue),e(Ue,kM),e(kM,yEe),e(yEe,Bgr),e(kM,Igr),e(kM,OJ),e(OJ,Ngr),e(kM,qgr),e(Ue,jgr),e(Ue,SM),e(SM,xEe),e(xEe,Dgr),e(SM,Ggr),e(SM,VJ),e(VJ,Ogr),e(SM,Vgr),e(Ue,Xgr),e(Ue,RM),e(RM,$Ee),e($Ee,zgr),e(RM,Qgr),e(RM,XJ),e(XJ,Wgr),e(RM,Ugr),e(Ue,Hgr),e(Ue,PM),e(PM,kEe),e(kEe,Jgr),e(PM,Ygr),e(PM,zJ),e(zJ,Zgr),e(PM,Kgr),e(Ue,ehr),e(Ue,BM),e(BM,SEe),e(SEe,ohr),e(BM,rhr),e(BM,QJ),e(QJ,thr),e(BM,ahr),e(Ue,nhr),e(Ue,IM),e(IM,REe),e(REe,shr),e(IM,lhr),e(IM,WJ),e(WJ,ihr),e(IM,dhr),e(Ue,chr),e(Ue,NM),e(NM,PEe),e(PEe,mhr),e(NM,fhr),e(NM,UJ),e(UJ,ghr),e(NM,hhr),e(so,uhr),e(so,qM),e(qM,phr),e(qM,BEe),e(BEe,_hr),e(qM,bhr),e(qM,IEe),e(IEe,vhr),e(so,Fhr),M(jM,so,null),b(m,Koo,_),b(m,Wd,_),e(Wd,DM),e(DM,NEe),M(O$,NEe,null),e(Wd,Thr),e(Wd,qEe),e(qEe,Mhr),b(m,ero,_),b(m,Vo,_),M(V$,Vo,null),e(Vo,Ehr),e(Vo,Ud),e(Ud,Chr),e(Ud,HJ),e(HJ,whr),e(Ud,Ahr),e(Ud,JJ),e(JJ,Lhr),e(Ud,yhr),e(Vo,xhr),e(Vo,X$),e(X$,$hr),e(X$,jEe),e(jEe,khr),e(X$,Shr),e(Vo,Rhr),e(Vo,Lt),M(z$,Lt,null),e(Lt,Phr),e(Lt,DEe),e(DEe,Bhr),e(Lt,Ihr),e(Lt,Hd),e(Hd,Nhr),e(Hd,GEe),e(GEe,qhr),e(Hd,jhr),e(Hd,YJ),e(YJ,Dhr),e(Hd,Ghr),e(Lt,Ohr),M(GM,Lt,null),e(Vo,Vhr),e(Vo,lo),M(Q$,lo,null),e(lo,Xhr),e(lo,OEe),e(OEe,zhr),e(lo,Qhr),e(lo,dn),e(dn,Whr),e(dn,VEe),e(VEe,Uhr),e(dn,Hhr),e(dn,XEe),e(XEe,Jhr),e(dn,Yhr),e(dn,zEe),e(zEe,Zhr),e(dn,Khr),e(lo,eur),e(lo,H),e(H,OM),e(OM,QEe),e(QEe,our),e(OM,rur),e(OM,ZJ),e(ZJ,tur),e(OM,aur),e(H,nur),e(H,VM),e(VM,WEe),e(WEe,sur),e(VM,lur),e(VM,KJ),e(KJ,iur),e(VM,dur),e(H,cur),e(H,XM),e(XM,UEe),e(UEe,mur),e(XM,fur),e(XM,eY),e(eY,gur),e(XM,hur),e(H,uur),e(H,zM),e(zM,HEe),e(HEe,pur),e(zM,_ur),e(zM,oY),e(oY,bur),e(zM,vur),e(H,Fur),e(H,QM),e(QM,JEe),e(JEe,Tur),e(QM,Mur),e(QM,rY),e(rY,Eur),e(QM,Cur),e(H,wur),e(H,WM),e(WM,YEe),e(YEe,Aur),e(WM,Lur),e(WM,tY),e(tY,yur),e(WM,xur),e(H,$ur),e(H,UM),e(UM,ZEe),e(ZEe,kur),e(UM,Sur),e(UM,aY),e(aY,Rur),e(UM,Pur),e(H,Bur),e(H,HM),e(HM,KEe),e(KEe,Iur),e(HM,Nur),e(HM,nY),e(nY,qur),e(HM,jur),e(H,Dur),e(H,JM),e(JM,e4e),e(e4e,Gur),e(JM,Our),e(JM,sY),e(sY,Vur),e(JM,Xur),e(H,zur),e(H,YM),e(YM,o4e),e(o4e,Qur),e(YM,Wur),e(YM,lY),e(lY,Uur),e(YM,Hur),e(H,Jur),e(H,ZM),e(ZM,r4e),e(r4e,Yur),e(ZM,Zur),e(ZM,iY),e(iY,Kur),e(ZM,epr),e(H,opr),e(H,KM),e(KM,t4e),e(t4e,rpr),e(KM,tpr),e(KM,dY),e(dY,apr),e(KM,npr),e(H,spr),e(H,eE),e(eE,a4e),e(a4e,lpr),e(eE,ipr),e(eE,cY),e(cY,dpr),e(eE,cpr),e(H,mpr),e(H,oE),e(oE,n4e),e(n4e,fpr),e(oE,gpr),e(oE,mY),e(mY,hpr),e(oE,upr),e(H,ppr),e(H,rE),e(rE,s4e),e(s4e,_pr),e(rE,bpr),e(rE,fY),e(fY,vpr),e(rE,Fpr),e(H,Tpr),e(H,tE),e(tE,l4e),e(l4e,Mpr),e(tE,Epr),e(tE,gY),e(gY,Cpr),e(tE,wpr),e(H,Apr),e(H,aE),e(aE,i4e),e(i4e,Lpr),e(aE,ypr),e(aE,hY),e(hY,xpr),e(aE,$pr),e(H,kpr),e(H,nE),e(nE,d4e),e(d4e,Spr),e(nE,Rpr),e(nE,uY),e(uY,Ppr),e(nE,Bpr),e(H,Ipr),e(H,sE),e(sE,c4e),e(c4e,Npr),e(sE,qpr),e(sE,pY),e(pY,jpr),e(sE,Dpr),e(H,Gpr),e(H,lE),e(lE,m4e),e(m4e,Opr),e(lE,Vpr),e(lE,_Y),e(_Y,Xpr),e(lE,zpr),e(H,Qpr),e(H,iE),e(iE,f4e),e(f4e,Wpr),e(iE,Upr),e(iE,bY),e(bY,Hpr),e(iE,Jpr),e(H,Ypr),e(H,dE),e(dE,g4e),e(g4e,Zpr),e(dE,Kpr),e(dE,vY),e(vY,e_r),e(dE,o_r),e(H,r_r),e(H,cE),e(cE,h4e),e(h4e,t_r),e(cE,a_r),e(cE,FY),e(FY,n_r),e(cE,s_r),e(H,l_r),e(H,mE),e(mE,u4e),e(u4e,i_r),e(mE,d_r),e(mE,TY),e(TY,c_r),e(mE,m_r),e(H,f_r),e(H,fE),e(fE,p4e),e(p4e,g_r),e(fE,h_r),e(fE,MY),e(MY,u_r),e(fE,p_r),e(H,__r),e(H,gE),e(gE,_4e),e(_4e,b_r),e(gE,v_r),e(gE,EY),e(EY,F_r),e(gE,T_r),e(H,M_r),e(H,hE),e(hE,b4e),e(b4e,E_r),e(hE,C_r),e(hE,CY),e(CY,w_r),e(hE,A_r),e(H,L_r),e(H,uE),e(uE,v4e),e(v4e,y_r),e(uE,x_r),e(uE,wY),e(wY,$_r),e(uE,k_r),e(H,S_r),e(H,pE),e(pE,F4e),e(F4e,R_r),e(pE,P_r),e(pE,AY),e(AY,B_r),e(pE,I_r),e(H,N_r),e(H,_E),e(_E,T4e),e(T4e,q_r),e(_E,j_r),e(_E,LY),e(LY,D_r),e(_E,G_r),e(H,O_r),e(H,bE),e(bE,M4e),e(M4e,V_r),e(bE,X_r),e(bE,yY),e(yY,z_r),e(bE,Q_r),e(H,W_r),e(H,vE),e(vE,E4e),e(E4e,U_r),e(vE,H_r),e(vE,xY),e(xY,J_r),e(vE,Y_r),e(H,Z_r),e(H,FE),e(FE,C4e),e(C4e,K_r),e(FE,e1r),e(FE,$Y),e($Y,o1r),e(FE,r1r),e(H,t1r),e(H,TE),e(TE,w4e),e(w4e,a1r),e(TE,n1r),e(TE,kY),e(kY,s1r),e(TE,l1r),e(H,i1r),e(H,ME),e(ME,A4e),e(A4e,d1r),e(ME,c1r),e(ME,SY),e(SY,m1r),e(ME,f1r),e(H,g1r),e(H,EE),e(EE,L4e),e(L4e,h1r),e(EE,u1r),e(EE,RY),e(RY,p1r),e(EE,_1r),e(H,b1r),e(H,CE),e(CE,y4e),e(y4e,v1r),e(CE,F1r),e(CE,PY),e(PY,T1r),e(CE,M1r),e(H,E1r),e(H,wE),e(wE,x4e),e(x4e,C1r),e(wE,w1r),e(wE,BY),e(BY,A1r),e(wE,L1r),e(H,y1r),e(H,AE),e(AE,$4e),e($4e,x1r),e(AE,$1r),e(AE,IY),e(IY,k1r),e(AE,S1r),e(H,R1r),e(H,LE),e(LE,k4e),e(k4e,P1r),e(LE,B1r),e(LE,NY),e(NY,I1r),e(LE,N1r),e(lo,q1r),e(lo,yE),e(yE,j1r),e(yE,S4e),e(S4e,D1r),e(yE,G1r),e(yE,R4e),e(R4e,O1r),e(lo,V1r),M(xE,lo,null),b(m,oro,_),b(m,Jd,_),e(Jd,$E),e($E,P4e),M(W$,P4e,null),e(Jd,X1r),e(Jd,B4e),e(B4e,z1r),b(m,rro,_),b(m,Xo,_),M(U$,Xo,null),e(Xo,Q1r),e(Xo,Yd),e(Yd,W1r),e(Yd,qY),e(qY,U1r),e(Yd,H1r),e(Yd,jY),e(jY,J1r),e(Yd,Y1r),e(Xo,Z1r),e(Xo,H$),e(H$,K1r),e(H$,I4e),e(I4e,e2r),e(H$,o2r),e(Xo,r2r),e(Xo,yt),M(J$,yt,null),e(yt,t2r),e(yt,N4e),e(N4e,a2r),e(yt,n2r),e(yt,Zd),e(Zd,s2r),e(Zd,q4e),e(q4e,l2r),e(Zd,i2r),e(Zd,DY),e(DY,d2r),e(Zd,c2r),e(yt,m2r),M(kE,yt,null),e(Xo,f2r),e(Xo,io),M(Y$,io,null),e(io,g2r),e(io,j4e),e(j4e,h2r),e(io,u2r),e(io,cn),e(cn,p2r),e(cn,D4e),e(D4e,_2r),e(cn,b2r),e(cn,G4e),e(G4e,v2r),e(cn,F2r),e(cn,O4e),e(O4e,T2r),e(cn,M2r),e(io,E2r),e(io,O),e(O,SE),e(SE,V4e),e(V4e,C2r),e(SE,w2r),e(SE,GY),e(GY,A2r),e(SE,L2r),e(O,y2r),e(O,RE),e(RE,X4e),e(X4e,x2r),e(RE,$2r),e(RE,OY),e(OY,k2r),e(RE,S2r),e(O,R2r),e(O,PE),e(PE,z4e),e(z4e,P2r),e(PE,B2r),e(PE,VY),e(VY,I2r),e(PE,N2r),e(O,q2r),e(O,BE),e(BE,Q4e),e(Q4e,j2r),e(BE,D2r),e(BE,XY),e(XY,G2r),e(BE,O2r),e(O,V2r),e(O,IE),e(IE,W4e),e(W4e,X2r),e(IE,z2r),e(IE,zY),e(zY,Q2r),e(IE,W2r),e(O,U2r),e(O,NE),e(NE,U4e),e(U4e,H2r),e(NE,J2r),e(NE,QY),e(QY,Y2r),e(NE,Z2r),e(O,K2r),e(O,qE),e(qE,H4e),e(H4e,ebr),e(qE,obr),e(qE,WY),e(WY,rbr),e(qE,tbr),e(O,abr),e(O,jE),e(jE,J4e),e(J4e,nbr),e(jE,sbr),e(jE,UY),e(UY,lbr),e(jE,ibr),e(O,dbr),e(O,DE),e(DE,Y4e),e(Y4e,cbr),e(DE,mbr),e(DE,HY),e(HY,fbr),e(DE,gbr),e(O,hbr),e(O,GE),e(GE,Z4e),e(Z4e,ubr),e(GE,pbr),e(GE,JY),e(JY,_br),e(GE,bbr),e(O,vbr),e(O,OE),e(OE,K4e),e(K4e,Fbr),e(OE,Tbr),e(OE,YY),e(YY,Mbr),e(OE,Ebr),e(O,Cbr),e(O,VE),e(VE,eCe),e(eCe,wbr),e(VE,Abr),e(VE,ZY),e(ZY,Lbr),e(VE,ybr),e(O,xbr),e(O,XE),e(XE,oCe),e(oCe,$br),e(XE,kbr),e(XE,KY),e(KY,Sbr),e(XE,Rbr),e(O,Pbr),e(O,zE),e(zE,rCe),e(rCe,Bbr),e(zE,Ibr),e(zE,eZ),e(eZ,Nbr),e(zE,qbr),e(O,jbr),e(O,QE),e(QE,tCe),e(tCe,Dbr),e(QE,Gbr),e(QE,oZ),e(oZ,Obr),e(QE,Vbr),e(O,Xbr),e(O,WE),e(WE,aCe),e(aCe,zbr),e(WE,Qbr),e(WE,rZ),e(rZ,Wbr),e(WE,Ubr),e(O,Hbr),e(O,UE),e(UE,nCe),e(nCe,Jbr),e(UE,Ybr),e(UE,tZ),e(tZ,Zbr),e(UE,Kbr),e(O,evr),e(O,HE),e(HE,sCe),e(sCe,ovr),e(HE,rvr),e(HE,aZ),e(aZ,tvr),e(HE,avr),e(O,nvr),e(O,JE),e(JE,lCe),e(lCe,svr),e(JE,lvr),e(JE,nZ),e(nZ,ivr),e(JE,dvr),e(O,cvr),e(O,YE),e(YE,iCe),e(iCe,mvr),e(YE,fvr),e(YE,sZ),e(sZ,gvr),e(YE,hvr),e(O,uvr),e(O,ZE),e(ZE,dCe),e(dCe,pvr),e(ZE,_vr),e(ZE,lZ),e(lZ,bvr),e(ZE,vvr),e(O,Fvr),e(O,KE),e(KE,cCe),e(cCe,Tvr),e(KE,Mvr),e(KE,iZ),e(iZ,Evr),e(KE,Cvr),e(O,wvr),e(O,e4),e(e4,mCe),e(mCe,Avr),e(e4,Lvr),e(e4,dZ),e(dZ,yvr),e(e4,xvr),e(O,$vr),e(O,o4),e(o4,fCe),e(fCe,kvr),e(o4,Svr),e(o4,cZ),e(cZ,Rvr),e(o4,Pvr),e(O,Bvr),e(O,r4),e(r4,gCe),e(gCe,Ivr),e(r4,Nvr),e(r4,mZ),e(mZ,qvr),e(r4,jvr),e(O,Dvr),e(O,t4),e(t4,hCe),e(hCe,Gvr),e(t4,Ovr),e(t4,fZ),e(fZ,Vvr),e(t4,Xvr),e(O,zvr),e(O,a4),e(a4,uCe),e(uCe,Qvr),e(a4,Wvr),e(a4,gZ),e(gZ,Uvr),e(a4,Hvr),e(O,Jvr),e(O,n4),e(n4,pCe),e(pCe,Yvr),e(n4,Zvr),e(n4,hZ),e(hZ,Kvr),e(n4,eFr),e(O,oFr),e(O,s4),e(s4,_Ce),e(_Ce,rFr),e(s4,tFr),e(s4,uZ),e(uZ,aFr),e(s4,nFr),e(O,sFr),e(O,l4),e(l4,bCe),e(bCe,lFr),e(l4,iFr),e(l4,pZ),e(pZ,dFr),e(l4,cFr),e(O,mFr),e(O,i4),e(i4,vCe),e(vCe,fFr),e(i4,gFr),e(i4,_Z),e(_Z,hFr),e(i4,uFr),e(O,pFr),e(O,d4),e(d4,FCe),e(FCe,_Fr),e(d4,bFr),e(d4,bZ),e(bZ,vFr),e(d4,FFr),e(O,TFr),e(O,c4),e(c4,TCe),e(TCe,MFr),e(c4,EFr),e(c4,vZ),e(vZ,CFr),e(c4,wFr),e(O,AFr),e(O,m4),e(m4,MCe),e(MCe,LFr),e(m4,yFr),e(m4,FZ),e(FZ,xFr),e(m4,$Fr),e(O,kFr),e(O,f4),e(f4,ECe),e(ECe,SFr),e(f4,RFr),e(f4,TZ),e(TZ,PFr),e(f4,BFr),e(O,IFr),e(O,g4),e(g4,CCe),e(CCe,NFr),e(g4,qFr),e(g4,MZ),e(MZ,jFr),e(g4,DFr),e(O,GFr),e(O,h4),e(h4,wCe),e(wCe,OFr),e(h4,VFr),e(h4,EZ),e(EZ,XFr),e(h4,zFr),e(O,QFr),e(O,u4),e(u4,ACe),e(ACe,WFr),e(u4,UFr),e(u4,CZ),e(CZ,HFr),e(u4,JFr),e(O,YFr),e(O,p4),e(p4,LCe),e(LCe,ZFr),e(p4,KFr),e(p4,wZ),e(wZ,eTr),e(p4,oTr),e(O,rTr),e(O,_4),e(_4,yCe),e(yCe,tTr),e(_4,aTr),e(_4,AZ),e(AZ,nTr),e(_4,sTr),e(O,lTr),e(O,b4),e(b4,xCe),e(xCe,iTr),e(b4,dTr),e(b4,LZ),e(LZ,cTr),e(b4,mTr),e(O,fTr),e(O,v4),e(v4,$Ce),e($Ce,gTr),e(v4,hTr),e(v4,yZ),e(yZ,uTr),e(v4,pTr),e(O,_Tr),e(O,F4),e(F4,kCe),e(kCe,bTr),e(F4,vTr),e(F4,xZ),e(xZ,FTr),e(F4,TTr),e(O,MTr),e(O,T4),e(T4,SCe),e(SCe,ETr),e(T4,CTr),e(T4,$Z),e($Z,wTr),e(T4,ATr),e(O,LTr),e(O,M4),e(M4,RCe),e(RCe,yTr),e(M4,xTr),e(M4,kZ),e(kZ,$Tr),e(M4,kTr),e(O,STr),e(O,E4),e(E4,PCe),e(PCe,RTr),e(E4,PTr),e(E4,SZ),e(SZ,BTr),e(E4,ITr),e(O,NTr),e(O,C4),e(C4,BCe),e(BCe,qTr),e(C4,jTr),e(C4,RZ),e(RZ,DTr),e(C4,GTr),e(io,OTr),e(io,w4),e(w4,VTr),e(w4,ICe),e(ICe,XTr),e(w4,zTr),e(w4,NCe),e(NCe,QTr),e(io,WTr),M(A4,io,null),b(m,tro,_),b(m,Kd,_),e(Kd,L4),e(L4,qCe),M(Z$,qCe,null),e(Kd,UTr),e(Kd,jCe),e(jCe,HTr),b(m,aro,_),b(m,zo,_),M(K$,zo,null),e(zo,JTr),e(zo,ec),e(ec,YTr),e(ec,PZ),e(PZ,ZTr),e(ec,KTr),e(ec,BZ),e(BZ,eMr),e(ec,oMr),e(zo,rMr),e(zo,ek),e(ek,tMr),e(ek,DCe),e(DCe,aMr),e(ek,nMr),e(zo,sMr),e(zo,xt),M(ok,xt,null),e(xt,lMr),e(xt,GCe),e(GCe,iMr),e(xt,dMr),e(xt,oc),e(oc,cMr),e(oc,OCe),e(OCe,mMr),e(oc,fMr),e(oc,IZ),e(IZ,gMr),e(oc,hMr),e(xt,uMr),M(y4,xt,null),e(zo,pMr),e(zo,co),M(rk,co,null),e(co,_Mr),e(co,VCe),e(VCe,bMr),e(co,vMr),e(co,mn),e(mn,FMr),e(mn,XCe),e(XCe,TMr),e(mn,MMr),e(mn,zCe),e(zCe,EMr),e(mn,CMr),e(mn,QCe),e(QCe,wMr),e(mn,AMr),e(co,LMr),e(co,WCe),e(WCe,x4),e(x4,UCe),e(UCe,yMr),e(x4,xMr),e(x4,NZ),e(NZ,$Mr),e(x4,kMr),e(co,SMr),e(co,$4),e($4,RMr),e($4,HCe),e(HCe,PMr),e($4,BMr),e($4,JCe),e(JCe,IMr),e(co,NMr),M(k4,co,null),b(m,nro,_),b(m,rc,_),e(rc,S4),e(S4,YCe),M(tk,YCe,null),e(rc,qMr),e(rc,ZCe),e(ZCe,jMr),b(m,sro,_),b(m,Qo,_),M(ak,Qo,null),e(Qo,DMr),e(Qo,tc),e(tc,GMr),e(tc,qZ),e(qZ,OMr),e(tc,VMr),e(tc,jZ),e(jZ,XMr),e(tc,zMr),e(Qo,QMr),e(Qo,nk),e(nk,WMr),e(nk,KCe),e(KCe,UMr),e(nk,HMr),e(Qo,JMr),e(Qo,$t),M(sk,$t,null),e($t,YMr),e($t,e3e),e(e3e,ZMr),e($t,KMr),e($t,ac),e(ac,eEr),e(ac,o3e),e(o3e,oEr),e(ac,rEr),e(ac,DZ),e(DZ,tEr),e(ac,aEr),e($t,nEr),M(R4,$t,null),e(Qo,sEr),e(Qo,mo),M(lk,mo,null),e(mo,lEr),e(mo,r3e),e(r3e,iEr),e(mo,dEr),e(mo,fn),e(fn,cEr),e(fn,t3e),e(t3e,mEr),e(fn,fEr),e(fn,a3e),e(a3e,gEr),e(fn,hEr),e(fn,n3e),e(n3e,uEr),e(fn,pEr),e(mo,_Er),e(mo,nc),e(nc,P4),e(P4,s3e),e(s3e,bEr),e(P4,vEr),e(P4,GZ),e(GZ,FEr),e(P4,TEr),e(nc,MEr),e(nc,B4),e(B4,l3e),e(l3e,EEr),e(B4,CEr),e(B4,OZ),e(OZ,wEr),e(B4,AEr),e(nc,LEr),e(nc,I4),e(I4,i3e),e(i3e,yEr),e(I4,xEr),e(I4,VZ),e(VZ,$Er),e(I4,kEr),e(mo,SEr),e(mo,N4),e(N4,REr),e(N4,d3e),e(d3e,PEr),e(N4,BEr),e(N4,c3e),e(c3e,IEr),e(mo,NEr),M(q4,mo,null),b(m,lro,_),b(m,sc,_),e(sc,j4),e(j4,m3e),M(ik,m3e,null),e(sc,qEr),e(sc,f3e),e(f3e,jEr),b(m,iro,_),b(m,Wo,_),M(dk,Wo,null),e(Wo,DEr),e(Wo,lc),e(lc,GEr),e(lc,XZ),e(XZ,OEr),e(lc,VEr),e(lc,zZ),e(zZ,XEr),e(lc,zEr),e(Wo,QEr),e(Wo,ck),e(ck,WEr),e(ck,g3e),e(g3e,UEr),e(ck,HEr),e(Wo,JEr),e(Wo,kt),M(mk,kt,null),e(kt,YEr),e(kt,h3e),e(h3e,ZEr),e(kt,KEr),e(kt,ic),e(ic,e4r),e(ic,u3e),e(u3e,o4r),e(ic,r4r),e(ic,QZ),e(QZ,t4r),e(ic,a4r),e(kt,n4r),M(D4,kt,null),e(Wo,s4r),e(Wo,fo),M(fk,fo,null),e(fo,l4r),e(fo,p3e),e(p3e,i4r),e(fo,d4r),e(fo,gn),e(gn,c4r),e(gn,_3e),e(_3e,m4r),e(gn,f4r),e(gn,b3e),e(b3e,g4r),e(gn,h4r),e(gn,v3e),e(v3e,u4r),e(gn,p4r),e(fo,_4r),e(fo,be),e(be,G4),e(G4,F3e),e(F3e,b4r),e(G4,v4r),e(G4,WZ),e(WZ,F4r),e(G4,T4r),e(be,M4r),e(be,O4),e(O4,T3e),e(T3e,E4r),e(O4,C4r),e(O4,UZ),e(UZ,w4r),e(O4,A4r),e(be,L4r),e(be,V4),e(V4,M3e),e(M3e,y4r),e(V4,x4r),e(V4,HZ),e(HZ,$4r),e(V4,k4r),e(be,S4r),e(be,X4),e(X4,E3e),e(E3e,R4r),e(X4,P4r),e(X4,JZ),e(JZ,B4r),e(X4,I4r),e(be,N4r),e(be,El),e(El,C3e),e(C3e,q4r),e(El,j4r),e(El,YZ),e(YZ,D4r),e(El,G4r),e(El,ZZ),e(ZZ,O4r),e(El,V4r),e(be,X4r),e(be,z4),e(z4,w3e),e(w3e,z4r),e(z4,Q4r),e(z4,KZ),e(KZ,W4r),e(z4,U4r),e(be,H4r),e(be,Cl),e(Cl,A3e),e(A3e,J4r),e(Cl,Y4r),e(Cl,eK),e(eK,Z4r),e(Cl,K4r),e(Cl,oK),e(oK,eCr),e(Cl,oCr),e(be,rCr),e(be,Q4),e(Q4,L3e),e(L3e,tCr),e(Q4,aCr),e(Q4,rK),e(rK,nCr),e(Q4,sCr),e(be,lCr),e(be,St),e(St,y3e),e(y3e,iCr),e(St,dCr),e(St,tK),e(tK,cCr),e(St,mCr),e(St,aK),e(aK,fCr),e(St,gCr),e(St,nK),e(nK,hCr),e(St,uCr),e(be,pCr),e(be,W4),e(W4,x3e),e(x3e,_Cr),e(W4,bCr),e(W4,sK),e(sK,vCr),e(W4,FCr),e(be,TCr),e(be,U4),e(U4,$3e),e($3e,MCr),e(U4,ECr),e(U4,lK),e(lK,CCr),e(U4,wCr),e(be,ACr),e(be,H4),e(H4,k3e),e(k3e,LCr),e(H4,yCr),e(H4,iK),e(iK,xCr),e(H4,$Cr),e(be,kCr),e(be,J4),e(J4,S3e),e(S3e,SCr),e(J4,RCr),e(J4,dK),e(dK,PCr),e(J4,BCr),e(be,ICr),e(be,Y4),e(Y4,R3e),e(R3e,NCr),e(Y4,qCr),e(Y4,cK),e(cK,jCr),e(Y4,DCr),e(be,GCr),e(be,Z4),e(Z4,P3e),e(P3e,OCr),e(Z4,VCr),e(Z4,mK),e(mK,XCr),e(Z4,zCr),e(be,QCr),e(be,K4),e(K4,B3e),e(B3e,WCr),e(K4,UCr),e(K4,fK),e(fK,HCr),e(K4,JCr),e(be,YCr),e(be,eC),e(eC,I3e),e(I3e,ZCr),e(eC,KCr),e(eC,gK),e(gK,e3r),e(eC,o3r),e(be,r3r),e(be,oC),e(oC,N3e),e(N3e,t3r),e(oC,a3r),e(oC,hK),e(hK,n3r),e(oC,s3r),e(fo,l3r),e(fo,rC),e(rC,i3r),e(rC,q3e),e(q3e,d3r),e(rC,c3r),e(rC,j3e),e(j3e,m3r),e(fo,f3r),M(tC,fo,null),b(m,dro,_),b(m,dc,_),e(dc,aC),e(aC,D3e),M(gk,D3e,null),e(dc,g3r),e(dc,G3e),e(G3e,h3r),b(m,cro,_),b(m,Uo,_),M(hk,Uo,null),e(Uo,u3r),e(Uo,cc),e(cc,p3r),e(cc,uK),e(uK,_3r),e(cc,b3r),e(cc,pK),e(pK,v3r),e(cc,F3r),e(Uo,T3r),e(Uo,uk),e(uk,M3r),e(uk,O3e),e(O3e,E3r),e(uk,C3r),e(Uo,w3r),e(Uo,Rt),M(pk,Rt,null),e(Rt,A3r),e(Rt,V3e),e(V3e,L3r),e(Rt,y3r),e(Rt,mc),e(mc,x3r),e(mc,X3e),e(X3e,$3r),e(mc,k3r),e(mc,_K),e(_K,S3r),e(mc,R3r),e(Rt,P3r),M(nC,Rt,null),e(Uo,B3r),e(Uo,go),M(_k,go,null),e(go,I3r),e(go,z3e),e(z3e,N3r),e(go,q3r),e(go,hn),e(hn,j3r),e(hn,Q3e),e(Q3e,D3r),e(hn,G3r),e(hn,W3e),e(W3e,O3r),e(hn,V3r),e(hn,U3e),e(U3e,X3r),e(hn,z3r),e(go,Q3r),e(go,H3e),e(H3e,sC),e(sC,J3e),e(J3e,W3r),e(sC,U3r),e(sC,bK),e(bK,H3r),e(sC,J3r),e(go,Y3r),e(go,lC),e(lC,Z3r),e(lC,Y3e),e(Y3e,K3r),e(lC,e5r),e(lC,Z3e),e(Z3e,o5r),e(go,r5r),M(iC,go,null),b(m,mro,_),b(m,fc,_),e(fc,dC),e(dC,K3e),M(bk,K3e,null),e(fc,t5r),e(fc,e5e),e(e5e,a5r),b(m,fro,_),b(m,Ho,_),M(vk,Ho,null),e(Ho,n5r),e(Ho,gc),e(gc,s5r),e(gc,vK),e(vK,l5r),e(gc,i5r),e(gc,FK),e(FK,d5r),e(gc,c5r),e(Ho,m5r),e(Ho,Fk),e(Fk,f5r),e(Fk,o5e),e(o5e,g5r),e(Fk,h5r),e(Ho,u5r),e(Ho,Pt),M(Tk,Pt,null),e(Pt,p5r),e(Pt,r5e),e(r5e,_5r),e(Pt,b5r),e(Pt,hc),e(hc,v5r),e(hc,t5e),e(t5e,F5r),e(hc,T5r),e(hc,TK),e(TK,M5r),e(hc,E5r),e(Pt,C5r),M(cC,Pt,null),e(Ho,w5r),e(Ho,ho),M(Mk,ho,null),e(ho,A5r),e(ho,a5e),e(a5e,L5r),e(ho,y5r),e(ho,un),e(un,x5r),e(un,n5e),e(n5e,$5r),e(un,k5r),e(un,s5e),e(s5e,S5r),e(un,R5r),e(un,l5e),e(l5e,P5r),e(un,B5r),e(ho,I5r),e(ho,i5e),e(i5e,mC),e(mC,d5e),e(d5e,N5r),e(mC,q5r),e(mC,MK),e(MK,j5r),e(mC,D5r),e(ho,G5r),e(ho,fC),e(fC,O5r),e(fC,c5e),e(c5e,V5r),e(fC,X5r),e(fC,m5e),e(m5e,z5r),e(ho,Q5r),M(gC,ho,null),b(m,gro,_),b(m,uc,_),e(uc,hC),e(hC,f5e),M(Ek,f5e,null),e(uc,W5r),e(uc,g5e),e(g5e,U5r),b(m,hro,_),b(m,Jo,_),M(Ck,Jo,null),e(Jo,H5r),e(Jo,pc),e(pc,J5r),e(pc,EK),e(EK,Y5r),e(pc,Z5r),e(pc,CK),e(CK,K5r),e(pc,e0r),e(Jo,o0r),e(Jo,wk),e(wk,r0r),e(wk,h5e),e(h5e,t0r),e(wk,a0r),e(Jo,n0r),e(Jo,Bt),M(Ak,Bt,null),e(Bt,s0r),e(Bt,u5e),e(u5e,l0r),e(Bt,i0r),e(Bt,_c),e(_c,d0r),e(_c,p5e),e(p5e,c0r),e(_c,m0r),e(_c,wK),e(wK,f0r),e(_c,g0r),e(Bt,h0r),M(uC,Bt,null),e(Jo,u0r),e(Jo,uo),M(Lk,uo,null),e(uo,p0r),e(uo,_5e),e(_5e,_0r),e(uo,b0r),e(uo,pn),e(pn,v0r),e(pn,b5e),e(b5e,F0r),e(pn,T0r),e(pn,v5e),e(v5e,M0r),e(pn,E0r),e(pn,F5e),e(F5e,C0r),e(pn,w0r),e(uo,A0r),e(uo,T5e),e(T5e,pC),e(pC,M5e),e(M5e,L0r),e(pC,y0r),e(pC,AK),e(AK,x0r),e(pC,$0r),e(uo,k0r),e(uo,_C),e(_C,S0r),e(_C,E5e),e(E5e,R0r),e(_C,P0r),e(_C,C5e),e(C5e,B0r),e(uo,I0r),M(bC,uo,null),b(m,uro,_),b(m,bc,_),e(bc,vC),e(vC,w5e),M(yk,w5e,null),e(bc,N0r),e(bc,A5e),e(A5e,q0r),b(m,pro,_),b(m,Yo,_),M(xk,Yo,null),e(Yo,j0r),e(Yo,vc),e(vc,D0r),e(vc,LK),e(LK,G0r),e(vc,O0r),e(vc,yK),e(yK,V0r),e(vc,X0r),e(Yo,z0r),e(Yo,$k),e($k,Q0r),e($k,L5e),e(L5e,W0r),e($k,U0r),e(Yo,H0r),e(Yo,It),M(kk,It,null),e(It,J0r),e(It,y5e),e(y5e,Y0r),e(It,Z0r),e(It,Fc),e(Fc,K0r),e(Fc,x5e),e(x5e,ewr),e(Fc,owr),e(Fc,xK),e(xK,rwr),e(Fc,twr),e(It,awr),M(FC,It,null),e(Yo,nwr),e(Yo,po),M(Sk,po,null),e(po,swr),e(po,$5e),e($5e,lwr),e(po,iwr),e(po,_n),e(_n,dwr),e(_n,k5e),e(k5e,cwr),e(_n,mwr),e(_n,S5e),e(S5e,fwr),e(_n,gwr),e(_n,R5e),e(R5e,hwr),e(_n,uwr),e(po,pwr),e(po,Be),e(Be,TC),e(TC,P5e),e(P5e,_wr),e(TC,bwr),e(TC,$K),e($K,vwr),e(TC,Fwr),e(Be,Twr),e(Be,MC),e(MC,B5e),e(B5e,Mwr),e(MC,Ewr),e(MC,kK),e(kK,Cwr),e(MC,wwr),e(Be,Awr),e(Be,EC),e(EC,I5e),e(I5e,Lwr),e(EC,ywr),e(EC,SK),e(SK,xwr),e(EC,$wr),e(Be,kwr),e(Be,CC),e(CC,N5e),e(N5e,Swr),e(CC,Rwr),e(CC,RK),e(RK,Pwr),e(CC,Bwr),e(Be,Iwr),e(Be,wC),e(wC,q5e),e(q5e,Nwr),e(wC,qwr),e(wC,PK),e(PK,jwr),e(wC,Dwr),e(Be,Gwr),e(Be,AC),e(AC,j5e),e(j5e,Owr),e(AC,Vwr),e(AC,BK),e(BK,Xwr),e(AC,zwr),e(Be,Qwr),e(Be,LC),e(LC,D5e),e(D5e,Wwr),e(LC,Uwr),e(LC,IK),e(IK,Hwr),e(LC,Jwr),e(Be,Ywr),e(Be,yC),e(yC,G5e),e(G5e,Zwr),e(yC,Kwr),e(yC,NK),e(NK,eAr),e(yC,oAr),e(Be,rAr),e(Be,xC),e(xC,O5e),e(O5e,tAr),e(xC,aAr),e(xC,qK),e(qK,nAr),e(xC,sAr),e(po,lAr),e(po,$C),e($C,iAr),e($C,V5e),e(V5e,dAr),e($C,cAr),e($C,X5e),e(X5e,mAr),e(po,fAr),M(kC,po,null),b(m,_ro,_),b(m,Tc,_),e(Tc,SC),e(SC,z5e),M(Rk,z5e,null),e(Tc,gAr),e(Tc,Q5e),e(Q5e,hAr),b(m,bro,_),b(m,Zo,_),M(Pk,Zo,null),e(Zo,uAr),e(Zo,Mc),e(Mc,pAr),e(Mc,jK),e(jK,_Ar),e(Mc,bAr),e(Mc,DK),e(DK,vAr),e(Mc,FAr),e(Zo,TAr),e(Zo,Bk),e(Bk,MAr),e(Bk,W5e),e(W5e,EAr),e(Bk,CAr),e(Zo,wAr),e(Zo,Nt),M(Ik,Nt,null),e(Nt,AAr),e(Nt,U5e),e(U5e,LAr),e(Nt,yAr),e(Nt,Ec),e(Ec,xAr),e(Ec,H5e),e(H5e,$Ar),e(Ec,kAr),e(Ec,GK),e(GK,SAr),e(Ec,RAr),e(Nt,PAr),M(RC,Nt,null),e(Zo,BAr),e(Zo,_o),M(Nk,_o,null),e(_o,IAr),e(_o,J5e),e(J5e,NAr),e(_o,qAr),e(_o,bn),e(bn,jAr),e(bn,Y5e),e(Y5e,DAr),e(bn,GAr),e(bn,Z5e),e(Z5e,OAr),e(bn,VAr),e(bn,K5e),e(K5e,XAr),e(bn,zAr),e(_o,QAr),e(_o,gt),e(gt,PC),e(PC,e0e),e(e0e,WAr),e(PC,UAr),e(PC,OK),e(OK,HAr),e(PC,JAr),e(gt,YAr),e(gt,BC),e(BC,o0e),e(o0e,ZAr),e(BC,KAr),e(BC,VK),e(VK,e6r),e(BC,o6r),e(gt,r6r),e(gt,IC),e(IC,r0e),e(r0e,t6r),e(IC,a6r),e(IC,XK),e(XK,n6r),e(IC,s6r),e(gt,l6r),e(gt,NC),e(NC,t0e),e(t0e,i6r),e(NC,d6r),e(NC,zK),e(zK,c6r),e(NC,m6r),e(gt,f6r),e(gt,qC),e(qC,a0e),e(a0e,g6r),e(qC,h6r),e(qC,QK),e(QK,u6r),e(qC,p6r),e(_o,_6r),e(_o,jC),e(jC,b6r),e(jC,n0e),e(n0e,v6r),e(jC,F6r),e(jC,s0e),e(s0e,T6r),e(_o,M6r),M(DC,_o,null),b(m,vro,_),b(m,Cc,_),e(Cc,GC),e(GC,l0e),M(qk,l0e,null),e(Cc,E6r),e(Cc,i0e),e(i0e,C6r),b(m,Fro,_),b(m,Ko,_),M(jk,Ko,null),e(Ko,w6r),e(Ko,wc),e(wc,A6r),e(wc,WK),e(WK,L6r),e(wc,y6r),e(wc,UK),e(UK,x6r),e(wc,$6r),e(Ko,k6r),e(Ko,Dk),e(Dk,S6r),e(Dk,d0e),e(d0e,R6r),e(Dk,P6r),e(Ko,B6r),e(Ko,qt),M(Gk,qt,null),e(qt,I6r),e(qt,c0e),e(c0e,N6r),e(qt,q6r),e(qt,Ac),e(Ac,j6r),e(Ac,m0e),e(m0e,D6r),e(Ac,G6r),e(Ac,HK),e(HK,O6r),e(Ac,V6r),e(qt,X6r),M(OC,qt,null),e(Ko,z6r),e(Ko,bo),M(Ok,bo,null),e(bo,Q6r),e(bo,f0e),e(f0e,W6r),e(bo,U6r),e(bo,vn),e(vn,H6r),e(vn,g0e),e(g0e,J6r),e(vn,Y6r),e(vn,h0e),e(h0e,Z6r),e(vn,K6r),e(vn,u0e),e(u0e,e7r),e(vn,o7r),e(bo,r7r),e(bo,Le),e(Le,VC),e(VC,p0e),e(p0e,t7r),e(VC,a7r),e(VC,JK),e(JK,n7r),e(VC,s7r),e(Le,l7r),e(Le,XC),e(XC,_0e),e(_0e,i7r),e(XC,d7r),e(XC,YK),e(YK,c7r),e(XC,m7r),e(Le,f7r),e(Le,zC),e(zC,b0e),e(b0e,g7r),e(zC,h7r),e(zC,ZK),e(ZK,u7r),e(zC,p7r),e(Le,_7r),e(Le,QC),e(QC,v0e),e(v0e,b7r),e(QC,v7r),e(QC,KK),e(KK,F7r),e(QC,T7r),e(Le,M7r),e(Le,WC),e(WC,F0e),e(F0e,E7r),e(WC,C7r),e(WC,eee),e(eee,w7r),e(WC,A7r),e(Le,L7r),e(Le,UC),e(UC,T0e),e(T0e,y7r),e(UC,x7r),e(UC,oee),e(oee,$7r),e(UC,k7r),e(Le,S7r),e(Le,HC),e(HC,M0e),e(M0e,R7r),e(HC,P7r),e(HC,ree),e(ree,B7r),e(HC,I7r),e(Le,N7r),e(Le,JC),e(JC,E0e),e(E0e,q7r),e(JC,j7r),e(JC,tee),e(tee,D7r),e(JC,G7r),e(Le,O7r),e(Le,YC),e(YC,C0e),e(C0e,V7r),e(YC,X7r),e(YC,aee),e(aee,z7r),e(YC,Q7r),e(Le,W7r),e(Le,ZC),e(ZC,w0e),e(w0e,U7r),e(ZC,H7r),e(ZC,nee),e(nee,J7r),e(ZC,Y7r),e(bo,Z7r),e(bo,KC),e(KC,K7r),e(KC,A0e),e(A0e,eLr),e(KC,oLr),e(KC,L0e),e(L0e,rLr),e(bo,tLr),M(e3,bo,null),b(m,Tro,_),b(m,Lc,_),e(Lc,o3),e(o3,y0e),M(Vk,y0e,null),e(Lc,aLr),e(Lc,x0e),e(x0e,nLr),b(m,Mro,_),b(m,er,_),M(Xk,er,null),e(er,sLr),e(er,yc),e(yc,lLr),e(yc,see),e(see,iLr),e(yc,dLr),e(yc,lee),e(lee,cLr),e(yc,mLr),e(er,fLr),e(er,zk),e(zk,gLr),e(zk,$0e),e($0e,hLr),e(zk,uLr),e(er,pLr),e(er,jt),M(Qk,jt,null),e(jt,_Lr),e(jt,k0e),e(k0e,bLr),e(jt,vLr),e(jt,xc),e(xc,FLr),e(xc,S0e),e(S0e,TLr),e(xc,MLr),e(xc,iee),e(iee,ELr),e(xc,CLr),e(jt,wLr),M(r3,jt,null),e(er,ALr),e(er,vo),M(Wk,vo,null),e(vo,LLr),e(vo,R0e),e(R0e,yLr),e(vo,xLr),e(vo,Fn),e(Fn,$Lr),e(Fn,P0e),e(P0e,kLr),e(Fn,SLr),e(Fn,B0e),e(B0e,RLr),e(Fn,PLr),e(Fn,I0e),e(I0e,BLr),e(Fn,ILr),e(vo,NLr),e(vo,$c),e($c,t3),e(t3,N0e),e(N0e,qLr),e(t3,jLr),e(t3,dee),e(dee,DLr),e(t3,GLr),e($c,OLr),e($c,a3),e(a3,q0e),e(q0e,VLr),e(a3,XLr),e(a3,cee),e(cee,zLr),e(a3,QLr),e($c,WLr),e($c,n3),e(n3,j0e),e(j0e,ULr),e(n3,HLr),e(n3,mee),e(mee,JLr),e(n3,YLr),e(vo,ZLr),e(vo,s3),e(s3,KLr),e(s3,D0e),e(D0e,e8r),e(s3,o8r),e(s3,G0e),e(G0e,r8r),e(vo,t8r),M(l3,vo,null),b(m,Ero,_),b(m,kc,_),e(kc,i3),e(i3,O0e),M(Uk,O0e,null),e(kc,a8r),e(kc,V0e),e(V0e,n8r),b(m,Cro,_),b(m,or,_),M(Hk,or,null),e(or,s8r),e(or,Sc),e(Sc,l8r),e(Sc,fee),e(fee,i8r),e(Sc,d8r),e(Sc,gee),e(gee,c8r),e(Sc,m8r),e(or,f8r),e(or,Jk),e(Jk,g8r),e(Jk,X0e),e(X0e,h8r),e(Jk,u8r),e(or,p8r),e(or,Dt),M(Yk,Dt,null),e(Dt,_8r),e(Dt,z0e),e(z0e,b8r),e(Dt,v8r),e(Dt,Rc),e(Rc,F8r),e(Rc,Q0e),e(Q0e,T8r),e(Rc,M8r),e(Rc,hee),e(hee,E8r),e(Rc,C8r),e(Dt,w8r),M(d3,Dt,null),e(or,A8r),e(or,Fo),M(Zk,Fo,null),e(Fo,L8r),e(Fo,W0e),e(W0e,y8r),e(Fo,x8r),e(Fo,Tn),e(Tn,$8r),e(Tn,U0e),e(U0e,k8r),e(Tn,S8r),e(Tn,H0e),e(H0e,R8r),e(Tn,P8r),e(Tn,J0e),e(J0e,B8r),e(Tn,I8r),e(Fo,N8r),e(Fo,ht),e(ht,c3),e(c3,Y0e),e(Y0e,q8r),e(c3,j8r),e(c3,uee),e(uee,D8r),e(c3,G8r),e(ht,O8r),e(ht,m3),e(m3,Z0e),e(Z0e,V8r),e(m3,X8r),e(m3,pee),e(pee,z8r),e(m3,Q8r),e(ht,W8r),e(ht,f3),e(f3,K0e),e(K0e,U8r),e(f3,H8r),e(f3,_ee),e(_ee,J8r),e(f3,Y8r),e(ht,Z8r),e(ht,g3),e(g3,ewe),e(ewe,K8r),e(g3,eyr),e(g3,bee),e(bee,oyr),e(g3,ryr),e(ht,tyr),e(ht,h3),e(h3,owe),e(owe,ayr),e(h3,nyr),e(h3,vee),e(vee,syr),e(h3,lyr),e(Fo,iyr),e(Fo,u3),e(u3,dyr),e(u3,rwe),e(rwe,cyr),e(u3,myr),e(u3,twe),e(twe,fyr),e(Fo,gyr),M(p3,Fo,null),b(m,wro,_),b(m,Pc,_),e(Pc,_3),e(_3,awe),M(Kk,awe,null),e(Pc,hyr),e(Pc,nwe),e(nwe,uyr),b(m,Aro,_),b(m,rr,_),M(eS,rr,null),e(rr,pyr),e(rr,Bc),e(Bc,_yr),e(Bc,Fee),e(Fee,byr),e(Bc,vyr),e(Bc,Tee),e(Tee,Fyr),e(Bc,Tyr),e(rr,Myr),e(rr,oS),e(oS,Eyr),e(oS,swe),e(swe,Cyr),e(oS,wyr),e(rr,Ayr),e(rr,Gt),M(rS,Gt,null),e(Gt,Lyr),e(Gt,lwe),e(lwe,yyr),e(Gt,xyr),e(Gt,Ic),e(Ic,$yr),e(Ic,iwe),e(iwe,kyr),e(Ic,Syr),e(Ic,Mee),e(Mee,Ryr),e(Ic,Pyr),e(Gt,Byr),M(b3,Gt,null),e(rr,Iyr),e(rr,To),M(tS,To,null),e(To,Nyr),e(To,dwe),e(dwe,qyr),e(To,jyr),e(To,Mn),e(Mn,Dyr),e(Mn,cwe),e(cwe,Gyr),e(Mn,Oyr),e(Mn,mwe),e(mwe,Vyr),e(Mn,Xyr),e(Mn,fwe),e(fwe,zyr),e(Mn,Qyr),e(To,Wyr),e(To,En),e(En,v3),e(v3,gwe),e(gwe,Uyr),e(v3,Hyr),e(v3,Eee),e(Eee,Jyr),e(v3,Yyr),e(En,Zyr),e(En,F3),e(F3,hwe),e(hwe,Kyr),e(F3,e9r),e(F3,Cee),e(Cee,o9r),e(F3,r9r),e(En,t9r),e(En,T3),e(T3,uwe),e(uwe,a9r),e(T3,n9r),e(T3,wee),e(wee,s9r),e(T3,l9r),e(En,i9r),e(En,M3),e(M3,pwe),e(pwe,d9r),e(M3,c9r),e(M3,Aee),e(Aee,m9r),e(M3,f9r),e(To,g9r),e(To,E3),e(E3,h9r),e(E3,_we),e(_we,u9r),e(E3,p9r),e(E3,bwe),e(bwe,_9r),e(To,b9r),M(C3,To,null),b(m,Lro,_),b(m,Nc,_),e(Nc,w3),e(w3,vwe),M(aS,vwe,null),e(Nc,v9r),e(Nc,Fwe),e(Fwe,F9r),b(m,yro,_),b(m,tr,_),M(nS,tr,null),e(tr,T9r),e(tr,qc),e(qc,M9r),e(qc,Lee),e(Lee,E9r),e(qc,C9r),e(qc,yee),e(yee,w9r),e(qc,A9r),e(tr,L9r),e(tr,sS),e(sS,y9r),e(sS,Twe),e(Twe,x9r),e(sS,$9r),e(tr,k9r),e(tr,Ot),M(lS,Ot,null),e(Ot,S9r),e(Ot,Mwe),e(Mwe,R9r),e(Ot,P9r),e(Ot,jc),e(jc,B9r),e(jc,Ewe),e(Ewe,I9r),e(jc,N9r),e(jc,xee),e(xee,q9r),e(jc,j9r),e(Ot,D9r),M(A3,Ot,null),e(tr,G9r),e(tr,Mo),M(iS,Mo,null),e(Mo,O9r),e(Mo,Cwe),e(Cwe,V9r),e(Mo,X9r),e(Mo,Cn),e(Cn,z9r),e(Cn,wwe),e(wwe,Q9r),e(Cn,W9r),e(Cn,Awe),e(Awe,U9r),e(Cn,H9r),e(Cn,Lwe),e(Lwe,J9r),e(Cn,Y9r),e(Mo,Z9r),e(Mo,wn),e(wn,L3),e(L3,ywe),e(ywe,K9r),e(L3,exr),e(L3,$ee),e($ee,oxr),e(L3,rxr),e(wn,txr),e(wn,y3),e(y3,xwe),e(xwe,axr),e(y3,nxr),e(y3,kee),e(kee,sxr),e(y3,lxr),e(wn,ixr),e(wn,x3),e(x3,$we),e($we,dxr),e(x3,cxr),e(x3,See),e(See,mxr),e(x3,fxr),e(wn,gxr),e(wn,$3),e($3,kwe),e(kwe,hxr),e($3,uxr),e($3,Ree),e(Ree,pxr),e($3,_xr),e(Mo,bxr),e(Mo,k3),e(k3,vxr),e(k3,Swe),e(Swe,Fxr),e(k3,Txr),e(k3,Rwe),e(Rwe,Mxr),e(Mo,Exr),M(S3,Mo,null),b(m,xro,_),b(m,Dc,_),e(Dc,R3),e(R3,Pwe),M(dS,Pwe,null),e(Dc,Cxr),e(Dc,Bwe),e(Bwe,wxr),b(m,$ro,_),b(m,ar,_),M(cS,ar,null),e(ar,Axr),e(ar,Gc),e(Gc,Lxr),e(Gc,Pee),e(Pee,yxr),e(Gc,xxr),e(Gc,Bee),e(Bee,$xr),e(Gc,kxr),e(ar,Sxr),e(ar,mS),e(mS,Rxr),e(mS,Iwe),e(Iwe,Pxr),e(mS,Bxr),e(ar,Ixr),e(ar,Vt),M(fS,Vt,null),e(Vt,Nxr),e(Vt,Nwe),e(Nwe,qxr),e(Vt,jxr),e(Vt,Oc),e(Oc,Dxr),e(Oc,qwe),e(qwe,Gxr),e(Oc,Oxr),e(Oc,Iee),e(Iee,Vxr),e(Oc,Xxr),e(Vt,zxr),M(P3,Vt,null),e(ar,Qxr),e(ar,Eo),M(gS,Eo,null),e(Eo,Wxr),e(Eo,jwe),e(jwe,Uxr),e(Eo,Hxr),e(Eo,An),e(An,Jxr),e(An,Dwe),e(Dwe,Yxr),e(An,Zxr),e(An,Gwe),e(Gwe,Kxr),e(An,e$r),e(An,Owe),e(Owe,o$r),e(An,r$r),e(Eo,t$r),e(Eo,Vwe),e(Vwe,B3),e(B3,Xwe),e(Xwe,a$r),e(B3,n$r),e(B3,Nee),e(Nee,s$r),e(B3,l$r),e(Eo,i$r),e(Eo,I3),e(I3,d$r),e(I3,zwe),e(zwe,c$r),e(I3,m$r),e(I3,Qwe),e(Qwe,f$r),e(Eo,g$r),M(N3,Eo,null),b(m,kro,_),b(m,Vc,_),e(Vc,q3),e(q3,Wwe),M(hS,Wwe,null),e(Vc,h$r),e(Vc,Uwe),e(Uwe,u$r),b(m,Sro,_),b(m,nr,_),M(uS,nr,null),e(nr,p$r),e(nr,Xc),e(Xc,_$r),e(Xc,qee),e(qee,b$r),e(Xc,v$r),e(Xc,jee),e(jee,F$r),e(Xc,T$r),e(nr,M$r),e(nr,pS),e(pS,E$r),e(pS,Hwe),e(Hwe,C$r),e(pS,w$r),e(nr,A$r),e(nr,Xt),M(_S,Xt,null),e(Xt,L$r),e(Xt,Jwe),e(Jwe,y$r),e(Xt,x$r),e(Xt,zc),e(zc,$$r),e(zc,Ywe),e(Ywe,k$r),e(zc,S$r),e(zc,Dee),e(Dee,R$r),e(zc,P$r),e(Xt,B$r),M(j3,Xt,null),e(nr,I$r),e(nr,Co),M(bS,Co,null),e(Co,N$r),e(Co,Zwe),e(Zwe,q$r),e(Co,j$r),e(Co,Ln),e(Ln,D$r),e(Ln,Kwe),e(Kwe,G$r),e(Ln,O$r),e(Ln,eAe),e(eAe,V$r),e(Ln,X$r),e(Ln,oAe),e(oAe,z$r),e(Ln,Q$r),e(Co,W$r),e(Co,ut),e(ut,D3),e(D3,rAe),e(rAe,U$r),e(D3,H$r),e(D3,Gee),e(Gee,J$r),e(D3,Y$r),e(ut,Z$r),e(ut,G3),e(G3,tAe),e(tAe,K$r),e(G3,ekr),e(G3,Oee),e(Oee,okr),e(G3,rkr),e(ut,tkr),e(ut,O3),e(O3,aAe),e(aAe,akr),e(O3,nkr),e(O3,Vee),e(Vee,skr),e(O3,lkr),e(ut,ikr),e(ut,V3),e(V3,nAe),e(nAe,dkr),e(V3,ckr),e(V3,Xee),e(Xee,mkr),e(V3,fkr),e(ut,gkr),e(ut,X3),e(X3,sAe),e(sAe,hkr),e(X3,ukr),e(X3,zee),e(zee,pkr),e(X3,_kr),e(Co,bkr),e(Co,z3),e(z3,vkr),e(z3,lAe),e(lAe,Fkr),e(z3,Tkr),e(z3,iAe),e(iAe,Mkr),e(Co,Ekr),M(Q3,Co,null),b(m,Rro,_),b(m,Qc,_),e(Qc,W3),e(W3,dAe),M(vS,dAe,null),e(Qc,Ckr),e(Qc,cAe),e(cAe,wkr),b(m,Pro,_),b(m,sr,_),M(FS,sr,null),e(sr,Akr),e(sr,Wc),e(Wc,Lkr),e(Wc,Qee),e(Qee,ykr),e(Wc,xkr),e(Wc,Wee),e(Wee,$kr),e(Wc,kkr),e(sr,Skr),e(sr,TS),e(TS,Rkr),e(TS,mAe),e(mAe,Pkr),e(TS,Bkr),e(sr,Ikr),e(sr,zt),M(MS,zt,null),e(zt,Nkr),e(zt,fAe),e(fAe,qkr),e(zt,jkr),e(zt,Uc),e(Uc,Dkr),e(Uc,gAe),e(gAe,Gkr),e(Uc,Okr),e(Uc,Uee),e(Uee,Vkr),e(Uc,Xkr),e(zt,zkr),M(U3,zt,null),e(sr,Qkr),e(sr,wo),M(ES,wo,null),e(wo,Wkr),e(wo,hAe),e(hAe,Ukr),e(wo,Hkr),e(wo,yn),e(yn,Jkr),e(yn,uAe),e(uAe,Ykr),e(yn,Zkr),e(yn,pAe),e(pAe,Kkr),e(yn,eSr),e(yn,_Ae),e(_Ae,oSr),e(yn,rSr),e(wo,tSr),e(wo,bAe),e(bAe,H3),e(H3,vAe),e(vAe,aSr),e(H3,nSr),e(H3,Hee),e(Hee,sSr),e(H3,lSr),e(wo,iSr),e(wo,J3),e(J3,dSr),e(J3,FAe),e(FAe,cSr),e(J3,mSr),e(J3,TAe),e(TAe,fSr),e(wo,gSr),M(Y3,wo,null),b(m,Bro,_),b(m,Hc,_),e(Hc,Z3),e(Z3,MAe),M(CS,MAe,null),e(Hc,hSr),e(Hc,EAe),e(EAe,uSr),b(m,Iro,_),b(m,lr,_),M(wS,lr,null),e(lr,pSr),e(lr,Jc),e(Jc,_Sr),e(Jc,Jee),e(Jee,bSr),e(Jc,vSr),e(Jc,Yee),e(Yee,FSr),e(Jc,TSr),e(lr,MSr),e(lr,AS),e(AS,ESr),e(AS,CAe),e(CAe,CSr),e(AS,wSr),e(lr,ASr),e(lr,Qt),M(LS,Qt,null),e(Qt,LSr),e(Qt,wAe),e(wAe,ySr),e(Qt,xSr),e(Qt,Yc),e(Yc,$Sr),e(Yc,AAe),e(AAe,kSr),e(Yc,SSr),e(Yc,Zee),e(Zee,RSr),e(Yc,PSr),e(Qt,BSr),M(K3,Qt,null),e(lr,ISr),e(lr,Ao),M(yS,Ao,null),e(Ao,NSr),e(Ao,LAe),e(LAe,qSr),e(Ao,jSr),e(Ao,xn),e(xn,DSr),e(xn,yAe),e(yAe,GSr),e(xn,OSr),e(xn,xAe),e(xAe,VSr),e(xn,XSr),e(xn,$Ae),e($Ae,zSr),e(xn,QSr),e(Ao,WSr),e(Ao,kAe),e(kAe,e5),e(e5,SAe),e(SAe,USr),e(e5,HSr),e(e5,Kee),e(Kee,JSr),e(e5,YSr),e(Ao,ZSr),e(Ao,o5),e(o5,KSr),e(o5,RAe),e(RAe,eRr),e(o5,oRr),e(o5,PAe),e(PAe,rRr),e(Ao,tRr),M(r5,Ao,null),b(m,Nro,_),b(m,Zc,_),e(Zc,t5),e(t5,BAe),M(xS,BAe,null),e(Zc,aRr),e(Zc,IAe),e(IAe,nRr),b(m,qro,_),b(m,ir,_),M($S,ir,null),e(ir,sRr),e(ir,Kc),e(Kc,lRr),e(Kc,eoe),e(eoe,iRr),e(Kc,dRr),e(Kc,ooe),e(ooe,cRr),e(Kc,mRr),e(ir,fRr),e(ir,kS),e(kS,gRr),e(kS,NAe),e(NAe,hRr),e(kS,uRr),e(ir,pRr),e(ir,Wt),M(SS,Wt,null),e(Wt,_Rr),e(Wt,qAe),e(qAe,bRr),e(Wt,vRr),e(Wt,em),e(em,FRr),e(em,jAe),e(jAe,TRr),e(em,MRr),e(em,roe),e(roe,ERr),e(em,CRr),e(Wt,wRr),M(a5,Wt,null),e(ir,ARr),e(ir,qr),M(RS,qr,null),e(qr,LRr),e(qr,DAe),e(DAe,yRr),e(qr,xRr),e(qr,$n),e($n,$Rr),e($n,GAe),e(GAe,kRr),e($n,SRr),e($n,OAe),e(OAe,RRr),e($n,PRr),e($n,VAe),e(VAe,BRr),e($n,IRr),e(qr,NRr),e(qr,P),e(P,n5),e(n5,XAe),e(XAe,qRr),e(n5,jRr),e(n5,toe),e(toe,DRr),e(n5,GRr),e(P,ORr),e(P,s5),e(s5,zAe),e(zAe,VRr),e(s5,XRr),e(s5,aoe),e(aoe,zRr),e(s5,QRr),e(P,WRr),e(P,l5),e(l5,QAe),e(QAe,URr),e(l5,HRr),e(l5,noe),e(noe,JRr),e(l5,YRr),e(P,ZRr),e(P,i5),e(i5,WAe),e(WAe,KRr),e(i5,ePr),e(i5,soe),e(soe,oPr),e(i5,rPr),e(P,tPr),e(P,d5),e(d5,UAe),e(UAe,aPr),e(d5,nPr),e(d5,loe),e(loe,sPr),e(d5,lPr),e(P,iPr),e(P,c5),e(c5,HAe),e(HAe,dPr),e(c5,cPr),e(c5,ioe),e(ioe,mPr),e(c5,fPr),e(P,gPr),e(P,m5),e(m5,JAe),e(JAe,hPr),e(m5,uPr),e(m5,doe),e(doe,pPr),e(m5,_Pr),e(P,bPr),e(P,f5),e(f5,YAe),e(YAe,vPr),e(f5,FPr),e(f5,coe),e(coe,TPr),e(f5,MPr),e(P,EPr),e(P,g5),e(g5,ZAe),e(ZAe,CPr),e(g5,wPr),e(g5,moe),e(moe,APr),e(g5,LPr),e(P,yPr),e(P,h5),e(h5,KAe),e(KAe,xPr),e(h5,$Pr),e(h5,foe),e(foe,kPr),e(h5,SPr),e(P,RPr),e(P,u5),e(u5,e6e),e(e6e,PPr),e(u5,BPr),e(u5,goe),e(goe,IPr),e(u5,NPr),e(P,qPr),e(P,p5),e(p5,o6e),e(o6e,jPr),e(p5,DPr),e(p5,hoe),e(hoe,GPr),e(p5,OPr),e(P,VPr),e(P,_5),e(_5,r6e),e(r6e,XPr),e(_5,zPr),e(_5,uoe),e(uoe,QPr),e(_5,WPr),e(P,UPr),e(P,b5),e(b5,t6e),e(t6e,HPr),e(b5,JPr),e(b5,poe),e(poe,YPr),e(b5,ZPr),e(P,KPr),e(P,v5),e(v5,a6e),e(a6e,eBr),e(v5,oBr),e(v5,_oe),e(_oe,rBr),e(v5,tBr),e(P,aBr),e(P,F5),e(F5,n6e),e(n6e,nBr),e(F5,sBr),e(F5,boe),e(boe,lBr),e(F5,iBr),e(P,dBr),e(P,T5),e(T5,s6e),e(s6e,cBr),e(T5,mBr),e(T5,voe),e(voe,fBr),e(T5,gBr),e(P,hBr),e(P,M5),e(M5,l6e),e(l6e,uBr),e(M5,pBr),e(M5,Foe),e(Foe,_Br),e(M5,bBr),e(P,vBr),e(P,E5),e(E5,i6e),e(i6e,FBr),e(E5,TBr),e(E5,Toe),e(Toe,MBr),e(E5,EBr),e(P,CBr),e(P,wl),e(wl,d6e),e(d6e,wBr),e(wl,ABr),e(wl,Moe),e(Moe,LBr),e(wl,yBr),e(wl,Eoe),e(Eoe,xBr),e(wl,$Br),e(P,kBr),e(P,C5),e(C5,c6e),e(c6e,SBr),e(C5,RBr),e(C5,Coe),e(Coe,PBr),e(C5,BBr),e(P,IBr),e(P,w5),e(w5,m6e),e(m6e,NBr),e(w5,qBr),e(w5,woe),e(woe,jBr),e(w5,DBr),e(P,GBr),e(P,A5),e(A5,f6e),e(f6e,OBr),e(A5,VBr),e(A5,Aoe),e(Aoe,XBr),e(A5,zBr),e(P,QBr),e(P,L5),e(L5,g6e),e(g6e,WBr),e(L5,UBr),e(L5,Loe),e(Loe,HBr),e(L5,JBr),e(P,YBr),e(P,y5),e(y5,h6e),e(h6e,ZBr),e(y5,KBr),e(y5,yoe),e(yoe,eIr),e(y5,oIr),e(P,rIr),e(P,x5),e(x5,u6e),e(u6e,tIr),e(x5,aIr),e(x5,xoe),e(xoe,nIr),e(x5,sIr),e(P,lIr),e(P,$5),e($5,p6e),e(p6e,iIr),e($5,dIr),e($5,$oe),e($oe,cIr),e($5,mIr),e(P,fIr),e(P,k5),e(k5,_6e),e(_6e,gIr),e(k5,hIr),e(k5,koe),e(koe,uIr),e(k5,pIr),e(P,_Ir),e(P,S5),e(S5,b6e),e(b6e,bIr),e(S5,vIr),e(S5,Soe),e(Soe,FIr),e(S5,TIr),e(P,MIr),e(P,R5),e(R5,v6e),e(v6e,EIr),e(R5,CIr),e(R5,Roe),e(Roe,wIr),e(R5,AIr),e(P,LIr),e(P,P5),e(P5,F6e),e(F6e,yIr),e(P5,xIr),e(P5,Poe),e(Poe,$Ir),e(P5,kIr),e(P,SIr),e(P,B5),e(B5,T6e),e(T6e,RIr),e(B5,PIr),e(B5,Boe),e(Boe,BIr),e(B5,IIr),e(P,NIr),e(P,I5),e(I5,M6e),e(M6e,qIr),e(I5,jIr),e(I5,Ioe),e(Ioe,DIr),e(I5,GIr),e(P,OIr),e(P,N5),e(N5,E6e),e(E6e,VIr),e(N5,XIr),e(N5,Noe),e(Noe,zIr),e(N5,QIr),e(P,WIr),e(P,q5),e(q5,C6e),e(C6e,UIr),e(q5,HIr),e(q5,qoe),e(qoe,JIr),e(q5,YIr),e(P,ZIr),e(P,j5),e(j5,w6e),e(w6e,KIr),e(j5,eNr),e(j5,joe),e(joe,oNr),e(j5,rNr),e(P,tNr),e(P,D5),e(D5,A6e),e(A6e,aNr),e(D5,nNr),e(D5,Doe),e(Doe,sNr),e(D5,lNr),e(P,iNr),e(P,G5),e(G5,L6e),e(L6e,dNr),e(G5,cNr),e(G5,Goe),e(Goe,mNr),e(G5,fNr),e(P,gNr),e(P,O5),e(O5,y6e),e(y6e,hNr),e(O5,uNr),e(O5,Ooe),e(Ooe,pNr),e(O5,_Nr),e(P,bNr),e(P,V5),e(V5,x6e),e(x6e,vNr),e(V5,FNr),e(V5,Voe),e(Voe,TNr),e(V5,MNr),e(P,ENr),e(P,X5),e(X5,$6e),e($6e,CNr),e(X5,wNr),e(X5,Xoe),e(Xoe,ANr),e(X5,LNr),e(P,yNr),e(P,z5),e(z5,k6e),e(k6e,xNr),e(z5,$Nr),e(z5,zoe),e(zoe,kNr),e(z5,SNr),e(P,RNr),e(P,Q5),e(Q5,S6e),e(S6e,PNr),e(Q5,BNr),e(Q5,Qoe),e(Qoe,INr),e(Q5,NNr),e(P,qNr),e(P,W5),e(W5,R6e),e(R6e,jNr),e(W5,DNr),e(W5,Woe),e(Woe,GNr),e(W5,ONr),e(P,VNr),e(P,U5),e(U5,P6e),e(P6e,XNr),e(U5,zNr),e(U5,Uoe),e(Uoe,QNr),e(U5,WNr),e(P,UNr),e(P,H5),e(H5,B6e),e(B6e,HNr),e(H5,JNr),e(H5,Hoe),e(Hoe,YNr),e(H5,ZNr),e(P,KNr),e(P,J5),e(J5,I6e),e(I6e,eqr),e(J5,oqr),e(J5,Joe),e(Joe,rqr),e(J5,tqr),e(P,aqr),e(P,Y5),e(Y5,N6e),e(N6e,nqr),e(Y5,sqr),e(Y5,Yoe),e(Yoe,lqr),e(Y5,iqr),e(P,dqr),e(P,Z5),e(Z5,q6e),e(q6e,cqr),e(Z5,mqr),e(Z5,Zoe),e(Zoe,fqr),e(Z5,gqr),e(P,hqr),e(P,K5),e(K5,j6e),e(j6e,uqr),e(K5,pqr),e(K5,Koe),e(Koe,_qr),e(K5,bqr),e(P,vqr),e(P,e0),e(e0,D6e),e(D6e,Fqr),e(e0,Tqr),e(e0,ere),e(ere,Mqr),e(e0,Eqr),e(P,Cqr),e(P,o0),e(o0,G6e),e(G6e,wqr),e(o0,Aqr),e(o0,ore),e(ore,Lqr),e(o0,yqr),e(P,xqr),e(P,r0),e(r0,O6e),e(O6e,$qr),e(r0,kqr),e(r0,rre),e(rre,Sqr),e(r0,Rqr),e(P,Pqr),e(P,t0),e(t0,V6e),e(V6e,Bqr),e(t0,Iqr),e(t0,tre),e(tre,Nqr),e(t0,qqr),e(P,jqr),e(P,a0),e(a0,X6e),e(X6e,Dqr),e(a0,Gqr),e(a0,are),e(are,Oqr),e(a0,Vqr),e(P,Xqr),e(P,n0),e(n0,z6e),e(z6e,zqr),e(n0,Qqr),e(n0,nre),e(nre,Wqr),e(n0,Uqr),e(P,Hqr),e(P,s0),e(s0,Q6e),e(Q6e,Jqr),e(s0,Yqr),e(s0,sre),e(sre,Zqr),e(s0,Kqr),e(qr,ejr),M(l0,qr,null),b(m,jro,_),b(m,om,_),e(om,i0),e(i0,W6e),M(PS,W6e,null),e(om,ojr),e(om,U6e),e(U6e,rjr),b(m,Dro,_),b(m,dr,_),M(BS,dr,null),e(dr,tjr),e(dr,rm),e(rm,ajr),e(rm,lre),e(lre,njr),e(rm,sjr),e(rm,ire),e(ire,ljr),e(rm,ijr),e(dr,djr),e(dr,IS),e(IS,cjr),e(IS,H6e),e(H6e,mjr),e(IS,fjr),e(dr,gjr),e(dr,Ut),M(NS,Ut,null),e(Ut,hjr),e(Ut,J6e),e(J6e,ujr),e(Ut,pjr),e(Ut,tm),e(tm,_jr),e(tm,Y6e),e(Y6e,bjr),e(tm,vjr),e(tm,dre),e(dre,Fjr),e(tm,Tjr),e(Ut,Mjr),M(d0,Ut,null),e(dr,Ejr),e(dr,jr),M(qS,jr,null),e(jr,Cjr),e(jr,Z6e),e(Z6e,wjr),e(jr,Ajr),e(jr,kn),e(kn,Ljr),e(kn,K6e),e(K6e,yjr),e(kn,xjr),e(kn,e7e),e(e7e,$jr),e(kn,kjr),e(kn,o7e),e(o7e,Sjr),e(kn,Rjr),e(jr,Pjr),e(jr,le),e(le,c0),e(c0,r7e),e(r7e,Bjr),e(c0,Ijr),e(c0,cre),e(cre,Njr),e(c0,qjr),e(le,jjr),e(le,m0),e(m0,t7e),e(t7e,Djr),e(m0,Gjr),e(m0,mre),e(mre,Ojr),e(m0,Vjr),e(le,Xjr),e(le,f0),e(f0,a7e),e(a7e,zjr),e(f0,Qjr),e(f0,fre),e(fre,Wjr),e(f0,Ujr),e(le,Hjr),e(le,g0),e(g0,n7e),e(n7e,Jjr),e(g0,Yjr),e(g0,gre),e(gre,Zjr),e(g0,Kjr),e(le,eDr),e(le,h0),e(h0,s7e),e(s7e,oDr),e(h0,rDr),e(h0,hre),e(hre,tDr),e(h0,aDr),e(le,nDr),e(le,u0),e(u0,l7e),e(l7e,sDr),e(u0,lDr),e(u0,ure),e(ure,iDr),e(u0,dDr),e(le,cDr),e(le,p0),e(p0,i7e),e(i7e,mDr),e(p0,fDr),e(p0,pre),e(pre,gDr),e(p0,hDr),e(le,uDr),e(le,_0),e(_0,d7e),e(d7e,pDr),e(_0,_Dr),e(_0,_re),e(_re,bDr),e(_0,vDr),e(le,FDr),e(le,b0),e(b0,c7e),e(c7e,TDr),e(b0,MDr),e(b0,bre),e(bre,EDr),e(b0,CDr),e(le,wDr),e(le,v0),e(v0,m7e),e(m7e,ADr),e(v0,LDr),e(v0,vre),e(vre,yDr),e(v0,xDr),e(le,$Dr),e(le,F0),e(F0,f7e),e(f7e,kDr),e(F0,SDr),e(F0,Fre),e(Fre,RDr),e(F0,PDr),e(le,BDr),e(le,T0),e(T0,g7e),e(g7e,IDr),e(T0,NDr),e(T0,Tre),e(Tre,qDr),e(T0,jDr),e(le,DDr),e(le,M0),e(M0,h7e),e(h7e,GDr),e(M0,ODr),e(M0,Mre),e(Mre,VDr),e(M0,XDr),e(le,zDr),e(le,E0),e(E0,u7e),e(u7e,QDr),e(E0,WDr),e(E0,Ere),e(Ere,UDr),e(E0,HDr),e(le,JDr),e(le,C0),e(C0,p7e),e(p7e,YDr),e(C0,ZDr),e(C0,Cre),e(Cre,KDr),e(C0,eGr),e(le,oGr),e(le,w0),e(w0,_7e),e(_7e,rGr),e(w0,tGr),e(w0,wre),e(wre,aGr),e(w0,nGr),e(le,sGr),e(le,A0),e(A0,b7e),e(b7e,lGr),e(A0,iGr),e(A0,Are),e(Are,dGr),e(A0,cGr),e(le,mGr),e(le,L0),e(L0,v7e),e(v7e,fGr),e(L0,gGr),e(L0,Lre),e(Lre,hGr),e(L0,uGr),e(le,pGr),e(le,y0),e(y0,F7e),e(F7e,_Gr),e(y0,bGr),e(y0,yre),e(yre,vGr),e(y0,FGr),e(le,TGr),e(le,x0),e(x0,T7e),e(T7e,MGr),e(x0,EGr),e(x0,xre),e(xre,CGr),e(x0,wGr),e(le,AGr),e(le,$0),e($0,M7e),e(M7e,LGr),e($0,yGr),e($0,$re),e($re,xGr),e($0,$Gr),e(le,kGr),e(le,k0),e(k0,E7e),e(E7e,SGr),e(k0,RGr),e(k0,kre),e(kre,PGr),e(k0,BGr),e(le,IGr),e(le,S0),e(S0,C7e),e(C7e,NGr),e(S0,qGr),e(S0,Sre),e(Sre,jGr),e(S0,DGr),e(jr,GGr),M(R0,jr,null),b(m,Gro,_),b(m,am,_),e(am,P0),e(P0,w7e),M(jS,w7e,null),e(am,OGr),e(am,A7e),e(A7e,VGr),b(m,Oro,_),b(m,cr,_),M(DS,cr,null),e(cr,XGr),e(cr,nm),e(nm,zGr),e(nm,Rre),e(Rre,QGr),e(nm,WGr),e(nm,Pre),e(Pre,UGr),e(nm,HGr),e(cr,JGr),e(cr,GS),e(GS,YGr),e(GS,L7e),e(L7e,ZGr),e(GS,KGr),e(cr,eOr),e(cr,Ht),M(OS,Ht,null),e(Ht,oOr),e(Ht,y7e),e(y7e,rOr),e(Ht,tOr),e(Ht,sm),e(sm,aOr),e(sm,x7e),e(x7e,nOr),e(sm,sOr),e(sm,Bre),e(Bre,lOr),e(sm,iOr),e(Ht,dOr),M(B0,Ht,null),e(cr,cOr),e(cr,Dr),M(VS,Dr,null),e(Dr,mOr),e(Dr,$7e),e($7e,fOr),e(Dr,gOr),e(Dr,Sn),e(Sn,hOr),e(Sn,k7e),e(k7e,uOr),e(Sn,pOr),e(Sn,S7e),e(S7e,_Or),e(Sn,bOr),e(Sn,R7e),e(R7e,vOr),e(Sn,FOr),e(Dr,TOr),e(Dr,Me),e(Me,I0),e(I0,P7e),e(P7e,MOr),e(I0,EOr),e(I0,Ire),e(Ire,COr),e(I0,wOr),e(Me,AOr),e(Me,N0),e(N0,B7e),e(B7e,LOr),e(N0,yOr),e(N0,Nre),e(Nre,xOr),e(N0,$Or),e(Me,kOr),e(Me,q0),e(q0,I7e),e(I7e,SOr),e(q0,ROr),e(q0,qre),e(qre,POr),e(q0,BOr),e(Me,IOr),e(Me,j0),e(j0,N7e),e(N7e,NOr),e(j0,qOr),e(j0,jre),e(jre,jOr),e(j0,DOr),e(Me,GOr),e(Me,D0),e(D0,q7e),e(q7e,OOr),e(D0,VOr),e(D0,Dre),e(Dre,XOr),e(D0,zOr),e(Me,QOr),e(Me,G0),e(G0,j7e),e(j7e,WOr),e(G0,UOr),e(G0,Gre),e(Gre,HOr),e(G0,JOr),e(Me,YOr),e(Me,O0),e(O0,D7e),e(D7e,ZOr),e(O0,KOr),e(O0,Ore),e(Ore,eVr),e(O0,oVr),e(Me,rVr),e(Me,V0),e(V0,G7e),e(G7e,tVr),e(V0,aVr),e(V0,Vre),e(Vre,nVr),e(V0,sVr),e(Me,lVr),e(Me,X0),e(X0,O7e),e(O7e,iVr),e(X0,dVr),e(X0,Xre),e(Xre,cVr),e(X0,mVr),e(Me,fVr),e(Me,z0),e(z0,V7e),e(V7e,gVr),e(z0,hVr),e(z0,zre),e(zre,uVr),e(z0,pVr),e(Me,_Vr),e(Me,Q0),e(Q0,X7e),e(X7e,bVr),e(Q0,vVr),e(Q0,Qre),e(Qre,FVr),e(Q0,TVr),e(Me,MVr),e(Me,W0),e(W0,z7e),e(z7e,EVr),e(W0,CVr),e(W0,Wre),e(Wre,wVr),e(W0,AVr),e(Me,LVr),e(Me,U0),e(U0,Q7e),e(Q7e,yVr),e(U0,xVr),e(U0,Ure),e(Ure,$Vr),e(U0,kVr),e(Me,SVr),e(Me,H0),e(H0,W7e),e(W7e,RVr),e(H0,PVr),e(H0,Hre),e(Hre,BVr),e(H0,IVr),e(Dr,NVr),M(J0,Dr,null),b(m,Vro,_),b(m,lm,_),e(lm,Y0),e(Y0,U7e),M(XS,U7e,null),e(lm,qVr),e(lm,H7e),e(H7e,jVr),b(m,Xro,_),b(m,mr,_),M(zS,mr,null),e(mr,DVr),e(mr,im),e(im,GVr),e(im,Jre),e(Jre,OVr),e(im,VVr),e(im,Yre),e(Yre,XVr),e(im,zVr),e(mr,QVr),e(mr,QS),e(QS,WVr),e(QS,J7e),e(J7e,UVr),e(QS,HVr),e(mr,JVr),e(mr,Jt),M(WS,Jt,null),e(Jt,YVr),e(Jt,Y7e),e(Y7e,ZVr),e(Jt,KVr),e(Jt,dm),e(dm,eXr),e(dm,Z7e),e(Z7e,oXr),e(dm,rXr),e(dm,Zre),e(Zre,tXr),e(dm,aXr),e(Jt,nXr),M(Z0,Jt,null),e(mr,sXr),e(mr,Gr),M(US,Gr,null),e(Gr,lXr),e(Gr,K7e),e(K7e,iXr),e(Gr,dXr),e(Gr,Rn),e(Rn,cXr),e(Rn,eLe),e(eLe,mXr),e(Rn,fXr),e(Rn,oLe),e(oLe,gXr),e(Rn,hXr),e(Rn,rLe),e(rLe,uXr),e(Rn,pXr),e(Gr,_Xr),e(Gr,ye),e(ye,K0),e(K0,tLe),e(tLe,bXr),e(K0,vXr),e(K0,Kre),e(Kre,FXr),e(K0,TXr),e(ye,MXr),e(ye,ew),e(ew,aLe),e(aLe,EXr),e(ew,CXr),e(ew,ete),e(ete,wXr),e(ew,AXr),e(ye,LXr),e(ye,ow),e(ow,nLe),e(nLe,yXr),e(ow,xXr),e(ow,ote),e(ote,$Xr),e(ow,kXr),e(ye,SXr),e(ye,Al),e(Al,sLe),e(sLe,RXr),e(Al,PXr),e(Al,rte),e(rte,BXr),e(Al,IXr),e(Al,tte),e(tte,NXr),e(Al,qXr),e(ye,jXr),e(ye,rw),e(rw,lLe),e(lLe,DXr),e(rw,GXr),e(rw,ate),e(ate,OXr),e(rw,VXr),e(ye,XXr),e(ye,tw),e(tw,iLe),e(iLe,zXr),e(tw,QXr),e(tw,nte),e(nte,WXr),e(tw,UXr),e(ye,HXr),e(ye,aw),e(aw,dLe),e(dLe,JXr),e(aw,YXr),e(aw,ste),e(ste,ZXr),e(aw,KXr),e(ye,ezr),e(ye,nw),e(nw,cLe),e(cLe,ozr),e(nw,rzr),e(nw,lte),e(lte,tzr),e(nw,azr),e(ye,nzr),e(ye,sw),e(sw,mLe),e(mLe,szr),e(sw,lzr),e(sw,ite),e(ite,izr),e(sw,dzr),e(ye,czr),e(ye,lw),e(lw,fLe),e(fLe,mzr),e(lw,fzr),e(lw,dte),e(dte,gzr),e(lw,hzr),e(Gr,uzr),M(iw,Gr,null),b(m,zro,_),b(m,cm,_),e(cm,dw),e(dw,gLe),M(HS,gLe,null),e(cm,pzr),e(cm,hLe),e(hLe,_zr),b(m,Qro,_),b(m,fr,_),M(JS,fr,null),e(fr,bzr),e(fr,mm),e(mm,vzr),e(mm,cte),e(cte,Fzr),e(mm,Tzr),e(mm,mte),e(mte,Mzr),e(mm,Ezr),e(fr,Czr),e(fr,YS),e(YS,wzr),e(YS,uLe),e(uLe,Azr),e(YS,Lzr),e(fr,yzr),e(fr,Yt),M(ZS,Yt,null),e(Yt,xzr),e(Yt,pLe),e(pLe,$zr),e(Yt,kzr),e(Yt,fm),e(fm,Szr),e(fm,_Le),e(_Le,Rzr),e(fm,Pzr),e(fm,fte),e(fte,Bzr),e(fm,Izr),e(Yt,Nzr),M(cw,Yt,null),e(fr,qzr),e(fr,Or),M(KS,Or,null),e(Or,jzr),e(Or,bLe),e(bLe,Dzr),e(Or,Gzr),e(Or,Pn),e(Pn,Ozr),e(Pn,vLe),e(vLe,Vzr),e(Pn,Xzr),e(Pn,FLe),e(FLe,zzr),e(Pn,Qzr),e(Pn,TLe),e(TLe,Wzr),e(Pn,Uzr),e(Or,Hzr),e(Or,gm),e(gm,mw),e(mw,MLe),e(MLe,Jzr),e(mw,Yzr),e(mw,gte),e(gte,Zzr),e(mw,Kzr),e(gm,eQr),e(gm,fw),e(fw,ELe),e(ELe,oQr),e(fw,rQr),e(fw,hte),e(hte,tQr),e(fw,aQr),e(gm,nQr),e(gm,gw),e(gw,CLe),e(CLe,sQr),e(gw,lQr),e(gw,ute),e(ute,iQr),e(gw,dQr),e(Or,cQr),M(hw,Or,null),b(m,Wro,_),b(m,hm,_),e(hm,uw),e(uw,wLe),M(eR,wLe,null),e(hm,mQr),e(hm,ALe),e(ALe,fQr),b(m,Uro,_),b(m,gr,_),M(oR,gr,null),e(gr,gQr),e(gr,um),e(um,hQr),e(um,pte),e(pte,uQr),e(um,pQr),e(um,_te),e(_te,_Qr),e(um,bQr),e(gr,vQr),e(gr,rR),e(rR,FQr),e(rR,LLe),e(LLe,TQr),e(rR,MQr),e(gr,EQr),e(gr,Zt),M(tR,Zt,null),e(Zt,CQr),e(Zt,yLe),e(yLe,wQr),e(Zt,AQr),e(Zt,pm),e(pm,LQr),e(pm,xLe),e(xLe,yQr),e(pm,xQr),e(pm,bte),e(bte,$Qr),e(pm,kQr),e(Zt,SQr),M(pw,Zt,null),e(gr,RQr),e(gr,Vr),M(aR,Vr,null),e(Vr,PQr),e(Vr,$Le),e($Le,BQr),e(Vr,IQr),e(Vr,Bn),e(Bn,NQr),e(Bn,kLe),e(kLe,qQr),e(Bn,jQr),e(Bn,SLe),e(SLe,DQr),e(Bn,GQr),e(Bn,RLe),e(RLe,OQr),e(Bn,VQr),e(Vr,XQr),e(Vr,ge),e(ge,_w),e(_w,PLe),e(PLe,zQr),e(_w,QQr),e(_w,vte),e(vte,WQr),e(_w,UQr),e(ge,HQr),e(ge,bw),e(bw,BLe),e(BLe,JQr),e(bw,YQr),e(bw,Fte),e(Fte,ZQr),e(bw,KQr),e(ge,eWr),e(ge,vw),e(vw,ILe),e(ILe,oWr),e(vw,rWr),e(vw,Tte),e(Tte,tWr),e(vw,aWr),e(ge,nWr),e(ge,Fw),e(Fw,NLe),e(NLe,sWr),e(Fw,lWr),e(Fw,Mte),e(Mte,iWr),e(Fw,dWr),e(ge,cWr),e(ge,Tw),e(Tw,qLe),e(qLe,mWr),e(Tw,fWr),e(Tw,Ete),e(Ete,gWr),e(Tw,hWr),e(ge,uWr),e(ge,Mw),e(Mw,jLe),e(jLe,pWr),e(Mw,_Wr),e(Mw,Cte),e(Cte,bWr),e(Mw,vWr),e(ge,FWr),e(ge,Ew),e(Ew,DLe),e(DLe,TWr),e(Ew,MWr),e(Ew,wte),e(wte,EWr),e(Ew,CWr),e(ge,wWr),e(ge,Cw),e(Cw,GLe),e(GLe,AWr),e(Cw,LWr),e(Cw,Ate),e(Ate,yWr),e(Cw,xWr),e(ge,$Wr),e(ge,ww),e(ww,OLe),e(OLe,kWr),e(ww,SWr),e(ww,Lte),e(Lte,RWr),e(ww,PWr),e(ge,BWr),e(ge,Aw),e(Aw,VLe),e(VLe,IWr),e(Aw,NWr),e(Aw,yte),e(yte,qWr),e(Aw,jWr),e(ge,DWr),e(ge,Lw),e(Lw,XLe),e(XLe,GWr),e(Lw,OWr),e(Lw,xte),e(xte,VWr),e(Lw,XWr),e(ge,zWr),e(ge,yw),e(yw,zLe),e(zLe,QWr),e(yw,WWr),e(yw,$te),e($te,UWr),e(yw,HWr),e(ge,JWr),e(ge,xw),e(xw,QLe),e(QLe,YWr),e(xw,ZWr),e(xw,kte),e(kte,KWr),e(xw,eUr),e(ge,oUr),e(ge,$w),e($w,WLe),e(WLe,rUr),e($w,tUr),e($w,Ste),e(Ste,aUr),e($w,nUr),e(ge,sUr),e(ge,kw),e(kw,ULe),e(ULe,lUr),e(kw,iUr),e(kw,Rte),e(Rte,dUr),e(kw,cUr),e(ge,mUr),e(ge,Sw),e(Sw,HLe),e(HLe,fUr),e(Sw,gUr),e(Sw,Pte),e(Pte,hUr),e(Sw,uUr),e(ge,pUr),e(ge,Rw),e(Rw,JLe),e(JLe,_Ur),e(Rw,bUr),e(Rw,Bte),e(Bte,vUr),e(Rw,FUr),e(ge,TUr),e(ge,Pw),e(Pw,YLe),e(YLe,MUr),e(Pw,EUr),e(Pw,Ite),e(Ite,CUr),e(Pw,wUr),e(ge,AUr),e(ge,Bw),e(Bw,ZLe),e(ZLe,LUr),e(Bw,yUr),e(Bw,Nte),e(Nte,xUr),e(Bw,$Ur),e(ge,kUr),e(ge,Iw),e(Iw,KLe),e(KLe,SUr),e(Iw,RUr),e(Iw,qte),e(qte,PUr),e(Iw,BUr),e(Vr,IUr),M(Nw,Vr,null),b(m,Hro,_),b(m,_m,_),e(_m,qw),e(qw,e8e),M(nR,e8e,null),e(_m,NUr),e(_m,o8e),e(o8e,qUr),b(m,Jro,_),b(m,hr,_),M(sR,hr,null),e(hr,jUr),e(hr,bm),e(bm,DUr),e(bm,jte),e(jte,GUr),e(bm,OUr),e(bm,Dte),e(Dte,VUr),e(bm,XUr),e(hr,zUr),e(hr,lR),e(lR,QUr),e(lR,r8e),e(r8e,WUr),e(lR,UUr),e(hr,HUr),e(hr,Kt),M(iR,Kt,null),e(Kt,JUr),e(Kt,t8e),e(t8e,YUr),e(Kt,ZUr),e(Kt,vm),e(vm,KUr),e(vm,a8e),e(a8e,eHr),e(vm,oHr),e(vm,Gte),e(Gte,rHr),e(vm,tHr),e(Kt,aHr),M(jw,Kt,null),e(hr,nHr),e(hr,Xr),M(dR,Xr,null),e(Xr,sHr),e(Xr,n8e),e(n8e,lHr),e(Xr,iHr),e(Xr,In),e(In,dHr),e(In,s8e),e(s8e,cHr),e(In,mHr),e(In,l8e),e(l8e,fHr),e(In,gHr),e(In,i8e),e(i8e,hHr),e(In,uHr),e(Xr,pHr),e(Xr,xe),e(xe,Dw),e(Dw,d8e),e(d8e,_Hr),e(Dw,bHr),e(Dw,Ote),e(Ote,vHr),e(Dw,FHr),e(xe,THr),e(xe,Gw),e(Gw,c8e),e(c8e,MHr),e(Gw,EHr),e(Gw,Vte),e(Vte,CHr),e(Gw,wHr),e(xe,AHr),e(xe,Ow),e(Ow,m8e),e(m8e,LHr),e(Ow,yHr),e(Ow,Xte),e(Xte,xHr),e(Ow,$Hr),e(xe,kHr),e(xe,Vw),e(Vw,f8e),e(f8e,SHr),e(Vw,RHr),e(Vw,zte),e(zte,PHr),e(Vw,BHr),e(xe,IHr),e(xe,Xw),e(Xw,g8e),e(g8e,NHr),e(Xw,qHr),e(Xw,Qte),e(Qte,jHr),e(Xw,DHr),e(xe,GHr),e(xe,zw),e(zw,h8e),e(h8e,OHr),e(zw,VHr),e(zw,Wte),e(Wte,XHr),e(zw,zHr),e(xe,QHr),e(xe,Qw),e(Qw,u8e),e(u8e,WHr),e(Qw,UHr),e(Qw,Ute),e(Ute,HHr),e(Qw,JHr),e(xe,YHr),e(xe,Ww),e(Ww,p8e),e(p8e,ZHr),e(Ww,KHr),e(Ww,Hte),e(Hte,eJr),e(Ww,oJr),e(xe,rJr),e(xe,Uw),e(Uw,_8e),e(_8e,tJr),e(Uw,aJr),e(Uw,Jte),e(Jte,nJr),e(Uw,sJr),e(xe,lJr),e(xe,Hw),e(Hw,b8e),e(b8e,iJr),e(Hw,dJr),e(Hw,Yte),e(Yte,cJr),e(Hw,mJr),e(Xr,fJr),M(Jw,Xr,null),b(m,Yro,_),b(m,Fm,_),e(Fm,Yw),e(Yw,v8e),M(cR,v8e,null),e(Fm,gJr),e(Fm,F8e),e(F8e,hJr),b(m,Zro,_),b(m,ur,_),M(mR,ur,null),e(ur,uJr),e(ur,Tm),e(Tm,pJr),e(Tm,Zte),e(Zte,_Jr),e(Tm,bJr),e(Tm,Kte),e(Kte,vJr),e(Tm,FJr),e(ur,TJr),e(ur,fR),e(fR,MJr),e(fR,T8e),e(T8e,EJr),e(fR,CJr),e(ur,wJr),e(ur,ea),M(gR,ea,null),e(ea,AJr),e(ea,M8e),e(M8e,LJr),e(ea,yJr),e(ea,Mm),e(Mm,xJr),e(Mm,E8e),e(E8e,$Jr),e(Mm,kJr),e(Mm,eae),e(eae,SJr),e(Mm,RJr),e(ea,PJr),M(Zw,ea,null),e(ur,BJr),e(ur,zr),M(hR,zr,null),e(zr,IJr),e(zr,C8e),e(C8e,NJr),e(zr,qJr),e(zr,Nn),e(Nn,jJr),e(Nn,w8e),e(w8e,DJr),e(Nn,GJr),e(Nn,A8e),e(A8e,OJr),e(Nn,VJr),e(Nn,L8e),e(L8e,XJr),e(Nn,zJr),e(zr,QJr),e(zr,re),e(re,Kw),e(Kw,y8e),e(y8e,WJr),e(Kw,UJr),e(Kw,oae),e(oae,HJr),e(Kw,JJr),e(re,YJr),e(re,eA),e(eA,x8e),e(x8e,ZJr),e(eA,KJr),e(eA,rae),e(rae,eYr),e(eA,oYr),e(re,rYr),e(re,oA),e(oA,$8e),e($8e,tYr),e(oA,aYr),e(oA,tae),e(tae,nYr),e(oA,sYr),e(re,lYr),e(re,rA),e(rA,k8e),e(k8e,iYr),e(rA,dYr),e(rA,aae),e(aae,cYr),e(rA,mYr),e(re,fYr),e(re,tA),e(tA,S8e),e(S8e,gYr),e(tA,hYr),e(tA,nae),e(nae,uYr),e(tA,pYr),e(re,_Yr),e(re,aA),e(aA,R8e),e(R8e,bYr),e(aA,vYr),e(aA,sae),e(sae,FYr),e(aA,TYr),e(re,MYr),e(re,nA),e(nA,P8e),e(P8e,EYr),e(nA,CYr),e(nA,lae),e(lae,wYr),e(nA,AYr),e(re,LYr),e(re,sA),e(sA,B8e),e(B8e,yYr),e(sA,xYr),e(sA,iae),e(iae,$Yr),e(sA,kYr),e(re,SYr),e(re,lA),e(lA,I8e),e(I8e,RYr),e(lA,PYr),e(lA,dae),e(dae,BYr),e(lA,IYr),e(re,NYr),e(re,iA),e(iA,N8e),e(N8e,qYr),e(iA,jYr),e(iA,cae),e(cae,DYr),e(iA,GYr),e(re,OYr),e(re,dA),e(dA,q8e),e(q8e,VYr),e(dA,XYr),e(dA,mae),e(mae,zYr),e(dA,QYr),e(re,WYr),e(re,cA),e(cA,j8e),e(j8e,UYr),e(cA,HYr),e(cA,fae),e(fae,JYr),e(cA,YYr),e(re,ZYr),e(re,mA),e(mA,D8e),e(D8e,KYr),e(mA,eZr),e(mA,gae),e(gae,oZr),e(mA,rZr),e(re,tZr),e(re,fA),e(fA,G8e),e(G8e,aZr),e(fA,nZr),e(fA,hae),e(hae,sZr),e(fA,lZr),e(re,iZr),e(re,gA),e(gA,O8e),e(O8e,dZr),e(gA,cZr),e(gA,uae),e(uae,mZr),e(gA,fZr),e(re,gZr),e(re,hA),e(hA,V8e),e(V8e,hZr),e(hA,uZr),e(hA,pae),e(pae,pZr),e(hA,_Zr),e(re,bZr),e(re,uA),e(uA,X8e),e(X8e,vZr),e(uA,FZr),e(uA,_ae),e(_ae,TZr),e(uA,MZr),e(re,EZr),e(re,pA),e(pA,z8e),e(z8e,CZr),e(pA,wZr),e(pA,bae),e(bae,AZr),e(pA,LZr),e(re,yZr),e(re,_A),e(_A,Q8e),e(Q8e,xZr),e(_A,$Zr),e(_A,vae),e(vae,kZr),e(_A,SZr),e(re,RZr),e(re,bA),e(bA,W8e),e(W8e,PZr),e(bA,BZr),e(bA,Fae),e(Fae,IZr),e(bA,NZr),e(re,qZr),e(re,vA),e(vA,U8e),e(U8e,jZr),e(vA,DZr),e(vA,Tae),e(Tae,GZr),e(vA,OZr),e(re,VZr),e(re,FA),e(FA,H8e),e(H8e,XZr),e(FA,zZr),e(FA,Mae),e(Mae,QZr),e(FA,WZr),e(re,UZr),e(re,TA),e(TA,J8e),e(J8e,HZr),e(TA,JZr),e(TA,Eae),e(Eae,YZr),e(TA,ZZr),e(re,KZr),e(re,MA),e(MA,Y8e),e(Y8e,eKr),e(MA,oKr),e(MA,Cae),e(Cae,rKr),e(MA,tKr),e(re,aKr),e(re,EA),e(EA,Z8e),e(Z8e,nKr),e(EA,sKr),e(EA,wae),e(wae,lKr),e(EA,iKr),e(re,dKr),e(re,CA),e(CA,K8e),e(K8e,cKr),e(CA,mKr),e(CA,Aae),e(Aae,fKr),e(CA,gKr),e(re,hKr),e(re,wA),e(wA,eye),e(eye,uKr),e(wA,pKr),e(wA,Lae),e(Lae,_Kr),e(wA,bKr),e(zr,vKr),M(AA,zr,null),b(m,Kro,_),b(m,Em,_),e(Em,LA),e(LA,oye),M(uR,oye,null),e(Em,FKr),e(Em,rye),e(rye,TKr),b(m,eto,_),b(m,pr,_),M(pR,pr,null),e(pr,MKr),e(pr,Cm),e(Cm,EKr),e(Cm,yae),e(yae,CKr),e(Cm,wKr),e(Cm,xae),e(xae,AKr),e(Cm,LKr),e(pr,yKr),e(pr,_R),e(_R,xKr),e(_R,tye),e(tye,$Kr),e(_R,kKr),e(pr,SKr),e(pr,oa),M(bR,oa,null),e(oa,RKr),e(oa,aye),e(aye,PKr),e(oa,BKr),e(oa,wm),e(wm,IKr),e(wm,nye),e(nye,NKr),e(wm,qKr),e(wm,$ae),e($ae,jKr),e(wm,DKr),e(oa,GKr),M(yA,oa,null),e(pr,OKr),e(pr,Qr),M(vR,Qr,null),e(Qr,VKr),e(Qr,sye),e(sye,XKr),e(Qr,zKr),e(Qr,qn),e(qn,QKr),e(qn,lye),e(lye,WKr),e(qn,UKr),e(qn,iye),e(iye,HKr),e(qn,JKr),e(qn,dye),e(dye,YKr),e(qn,ZKr),e(Qr,KKr),e(Qr,ve),e(ve,xA),e(xA,cye),e(cye,eet),e(xA,oet),e(xA,kae),e(kae,ret),e(xA,tet),e(ve,aet),e(ve,$A),e($A,mye),e(mye,net),e($A,set),e($A,Sae),e(Sae,iet),e($A,det),e(ve,cet),e(ve,kA),e(kA,fye),e(fye,met),e(kA,fet),e(kA,Rae),e(Rae,get),e(kA,het),e(ve,uet),e(ve,SA),e(SA,gye),e(gye,pet),e(SA,_et),e(SA,Pae),e(Pae,bet),e(SA,vet),e(ve,Fet),e(ve,RA),e(RA,hye),e(hye,Tet),e(RA,Met),e(RA,Bae),e(Bae,Eet),e(RA,Cet),e(ve,wet),e(ve,PA),e(PA,uye),e(uye,Aet),e(PA,Let),e(PA,Iae),e(Iae,yet),e(PA,xet),e(ve,$et),e(ve,BA),e(BA,pye),e(pye,ket),e(BA,Set),e(BA,Nae),e(Nae,Ret),e(BA,Pet),e(ve,Bet),e(ve,IA),e(IA,_ye),e(_ye,Iet),e(IA,Net),e(IA,qae),e(qae,qet),e(IA,jet),e(ve,Det),e(ve,NA),e(NA,bye),e(bye,Get),e(NA,Oet),e(NA,jae),e(jae,Vet),e(NA,Xet),e(ve,zet),e(ve,qA),e(qA,vye),e(vye,Qet),e(qA,Wet),e(qA,Dae),e(Dae,Uet),e(qA,Het),e(ve,Jet),e(ve,jA),e(jA,Fye),e(Fye,Yet),e(jA,Zet),e(jA,Gae),e(Gae,Ket),e(jA,eot),e(ve,oot),e(ve,DA),e(DA,Tye),e(Tye,rot),e(DA,tot),e(DA,Oae),e(Oae,aot),e(DA,not),e(ve,sot),e(ve,GA),e(GA,Mye),e(Mye,lot),e(GA,iot),e(GA,Vae),e(Vae,dot),e(GA,cot),e(ve,mot),e(ve,OA),e(OA,Eye),e(Eye,fot),e(OA,got),e(OA,Xae),e(Xae,hot),e(OA,uot),e(ve,pot),e(ve,VA),e(VA,Cye),e(Cye,_ot),e(VA,bot),e(VA,zae),e(zae,vot),e(VA,Fot),e(ve,Tot),e(ve,XA),e(XA,wye),e(wye,Mot),e(XA,Eot),e(XA,Qae),e(Qae,Cot),e(XA,wot),e(ve,Aot),e(ve,zA),e(zA,Aye),e(Aye,Lot),e(zA,yot),e(zA,Wae),e(Wae,xot),e(zA,$ot),e(Qr,kot),M(QA,Qr,null),b(m,oto,_),b(m,Am,_),e(Am,WA),e(WA,Lye),M(FR,Lye,null),e(Am,Sot),e(Am,yye),e(yye,Rot),b(m,rto,_),b(m,_r,_),M(TR,_r,null),e(_r,Pot),e(_r,Lm),e(Lm,Bot),e(Lm,Uae),e(Uae,Iot),e(Lm,Not),e(Lm,Hae),e(Hae,qot),e(Lm,jot),e(_r,Dot),e(_r,MR),e(MR,Got),e(MR,xye),e(xye,Oot),e(MR,Vot),e(_r,Xot),e(_r,ra),M(ER,ra,null),e(ra,zot),e(ra,$ye),e($ye,Qot),e(ra,Wot),e(ra,ym),e(ym,Uot),e(ym,kye),e(kye,Hot),e(ym,Jot),e(ym,Jae),e(Jae,Yot),e(ym,Zot),e(ra,Kot),M(UA,ra,null),e(_r,ert),e(_r,Wr),M(CR,Wr,null),e(Wr,ort),e(Wr,Sye),e(Sye,rrt),e(Wr,trt),e(Wr,jn),e(jn,art),e(jn,Rye),e(Rye,nrt),e(jn,srt),e(jn,Pye),e(Pye,lrt),e(jn,irt),e(jn,Bye),e(Bye,drt),e(jn,crt),e(Wr,mrt),e(Wr,wR),e(wR,HA),e(HA,Iye),e(Iye,frt),e(HA,grt),e(HA,Yae),e(Yae,hrt),e(HA,urt),e(wR,prt),e(wR,JA),e(JA,Nye),e(Nye,_rt),e(JA,brt),e(JA,Zae),e(Zae,vrt),e(JA,Frt),e(Wr,Trt),M(YA,Wr,null),b(m,tto,_),b(m,xm,_),e(xm,ZA),e(ZA,qye),M(AR,qye,null),e(xm,Mrt),e(xm,jye),e(jye,Ert),b(m,ato,_),b(m,br,_),M(LR,br,null),e(br,Crt),e(br,$m),e($m,wrt),e($m,Kae),e(Kae,Art),e($m,Lrt),e($m,ene),e(ene,yrt),e($m,xrt),e(br,$rt),e(br,yR),e(yR,krt),e(yR,Dye),e(Dye,Srt),e(yR,Rrt),e(br,Prt),e(br,ta),M(xR,ta,null),e(ta,Brt),e(ta,Gye),e(Gye,Irt),e(ta,Nrt),e(ta,km),e(km,qrt),e(km,Oye),e(Oye,jrt),e(km,Drt),e(km,one),e(one,Grt),e(km,Ort),e(ta,Vrt),M(KA,ta,null),e(br,Xrt),e(br,Ur),M($R,Ur,null),e(Ur,zrt),e(Ur,Vye),e(Vye,Qrt),e(Ur,Wrt),e(Ur,Dn),e(Dn,Urt),e(Dn,Xye),e(Xye,Hrt),e(Dn,Jrt),e(Dn,zye),e(zye,Yrt),e(Dn,Zrt),e(Dn,Qye),e(Qye,Krt),e(Dn,ett),e(Ur,ott),e(Ur,Wye),e(Wye,e6),e(e6,Uye),e(Uye,rtt),e(e6,ttt),e(e6,rne),e(rne,att),e(e6,ntt),e(Ur,stt),M(o6,Ur,null),b(m,nto,_),b(m,Sm,_),e(Sm,r6),e(r6,Hye),M(kR,Hye,null),e(Sm,ltt),e(Sm,Jye),e(Jye,itt),b(m,sto,_),b(m,vr,_),M(SR,vr,null),e(vr,dtt),e(vr,Rm),e(Rm,ctt),e(Rm,tne),e(tne,mtt),e(Rm,ftt),e(Rm,ane),e(ane,gtt),e(Rm,htt),e(vr,utt),e(vr,RR),e(RR,ptt),e(RR,Yye),e(Yye,_tt),e(RR,btt),e(vr,vtt),e(vr,aa),M(PR,aa,null),e(aa,Ftt),e(aa,Zye),e(Zye,Ttt),e(aa,Mtt),e(aa,Pm),e(Pm,Ett),e(Pm,Kye),e(Kye,Ctt),e(Pm,wtt),e(Pm,nne),e(nne,Att),e(Pm,Ltt),e(aa,ytt),M(t6,aa,null),e(vr,xtt),e(vr,Hr),M(BR,Hr,null),e(Hr,$tt),e(Hr,e9e),e(e9e,ktt),e(Hr,Stt),e(Hr,Gn),e(Gn,Rtt),e(Gn,o9e),e(o9e,Ptt),e(Gn,Btt),e(Gn,r9e),e(r9e,Itt),e(Gn,Ntt),e(Gn,t9e),e(t9e,qtt),e(Gn,jtt),e(Hr,Dtt),e(Hr,a9e),e(a9e,a6),e(a6,n9e),e(n9e,Gtt),e(a6,Ott),e(a6,sne),e(sne,Vtt),e(a6,Xtt),e(Hr,ztt),M(n6,Hr,null),b(m,lto,_),b(m,Bm,_),e(Bm,s6),e(s6,s9e),M(IR,s9e,null),e(Bm,Qtt),e(Bm,l9e),e(l9e,Wtt),b(m,ito,_),b(m,Fr,_),M(NR,Fr,null),e(Fr,Utt),e(Fr,Im),e(Im,Htt),e(Im,lne),e(lne,Jtt),e(Im,Ytt),e(Im,ine),e(ine,Ztt),e(Im,Ktt),e(Fr,eat),e(Fr,qR),e(qR,oat),e(qR,i9e),e(i9e,rat),e(qR,tat),e(Fr,aat),e(Fr,na),M(jR,na,null),e(na,nat),e(na,d9e),e(d9e,sat),e(na,lat),e(na,Nm),e(Nm,iat),e(Nm,c9e),e(c9e,dat),e(Nm,cat),e(Nm,dne),e(dne,mat),e(Nm,fat),e(na,gat),M(l6,na,null),e(Fr,hat),e(Fr,Jr),M(DR,Jr,null),e(Jr,uat),e(Jr,m9e),e(m9e,pat),e(Jr,_at),e(Jr,On),e(On,bat),e(On,f9e),e(f9e,vat),e(On,Fat),e(On,g9e),e(g9e,Tat),e(On,Mat),e(On,h9e),e(h9e,Eat),e(On,Cat),e(Jr,wat),e(Jr,ce),e(ce,i6),e(i6,u9e),e(u9e,Aat),e(i6,Lat),e(i6,cne),e(cne,yat),e(i6,xat),e(ce,$at),e(ce,d6),e(d6,p9e),e(p9e,kat),e(d6,Sat),e(d6,mne),e(mne,Rat),e(d6,Pat),e(ce,Bat),e(ce,c6),e(c6,_9e),e(_9e,Iat),e(c6,Nat),e(c6,fne),e(fne,qat),e(c6,jat),e(ce,Dat),e(ce,m6),e(m6,b9e),e(b9e,Gat),e(m6,Oat),e(m6,gne),e(gne,Vat),e(m6,Xat),e(ce,zat),e(ce,f6),e(f6,v9e),e(v9e,Qat),e(f6,Wat),e(f6,hne),e(hne,Uat),e(f6,Hat),e(ce,Jat),e(ce,g6),e(g6,F9e),e(F9e,Yat),e(g6,Zat),e(g6,une),e(une,Kat),e(g6,ent),e(ce,ont),e(ce,h6),e(h6,T9e),e(T9e,rnt),e(h6,tnt),e(h6,pne),e(pne,ant),e(h6,nnt),e(ce,snt),e(ce,u6),e(u6,M9e),e(M9e,lnt),e(u6,int),e(u6,_ne),e(_ne,dnt),e(u6,cnt),e(ce,mnt),e(ce,p6),e(p6,E9e),e(E9e,fnt),e(p6,gnt),e(p6,bne),e(bne,hnt),e(p6,unt),e(ce,pnt),e(ce,_6),e(_6,C9e),e(C9e,_nt),e(_6,bnt),e(_6,vne),e(vne,vnt),e(_6,Fnt),e(ce,Tnt),e(ce,b6),e(b6,w9e),e(w9e,Mnt),e(b6,Ent),e(b6,Fne),e(Fne,Cnt),e(b6,wnt),e(ce,Ant),e(ce,v6),e(v6,A9e),e(A9e,Lnt),e(v6,ynt),e(v6,Tne),e(Tne,xnt),e(v6,$nt),e(ce,knt),e(ce,F6),e(F6,L9e),e(L9e,Snt),e(F6,Rnt),e(F6,Mne),e(Mne,Pnt),e(F6,Bnt),e(ce,Int),e(ce,T6),e(T6,y9e),e(y9e,Nnt),e(T6,qnt),e(T6,Ene),e(Ene,jnt),e(T6,Dnt),e(ce,Gnt),e(ce,M6),e(M6,x9e),e(x9e,Ont),e(M6,Vnt),e(M6,Cne),e(Cne,Xnt),e(M6,znt),e(ce,Qnt),e(ce,E6),e(E6,$9e),e($9e,Wnt),e(E6,Unt),e(E6,wne),e(wne,Hnt),e(E6,Jnt),e(ce,Ynt),e(ce,C6),e(C6,k9e),e(k9e,Znt),e(C6,Knt),e(C6,Ane),e(Ane,est),e(C6,ost),e(ce,rst),e(ce,w6),e(w6,S9e),e(S9e,tst),e(w6,ast),e(w6,Lne),e(Lne,nst),e(w6,sst),e(ce,lst),e(ce,A6),e(A6,R9e),e(R9e,ist),e(A6,dst),e(A6,yne),e(yne,cst),e(A6,mst),e(ce,fst),e(ce,L6),e(L6,P9e),e(P9e,gst),e(L6,hst),e(L6,xne),e(xne,ust),e(L6,pst),e(ce,_st),e(ce,y6),e(y6,B9e),e(B9e,bst),e(y6,vst),e(y6,$ne),e($ne,Fst),e(y6,Tst),e(Jr,Mst),M(x6,Jr,null),b(m,dto,_),b(m,qm,_),e(qm,$6),e($6,I9e),M(GR,I9e,null),e(qm,Est),e(qm,N9e),e(N9e,Cst),b(m,cto,_),b(m,Tr,_),M(OR,Tr,null),e(Tr,wst),e(Tr,jm),e(jm,Ast),e(jm,kne),e(kne,Lst),e(jm,yst),e(jm,Sne),e(Sne,xst),e(jm,$st),e(Tr,kst),e(Tr,VR),e(VR,Sst),e(VR,q9e),e(q9e,Rst),e(VR,Pst),e(Tr,Bst),e(Tr,sa),M(XR,sa,null),e(sa,Ist),e(sa,j9e),e(j9e,Nst),e(sa,qst),e(sa,Dm),e(Dm,jst),e(Dm,D9e),e(D9e,Dst),e(Dm,Gst),e(Dm,Rne),e(Rne,Ost),e(Dm,Vst),e(sa,Xst),M(k6,sa,null),e(Tr,zst),e(Tr,Yr),M(zR,Yr,null),e(Yr,Qst),e(Yr,G9e),e(G9e,Wst),e(Yr,Ust),e(Yr,Vn),e(Vn,Hst),e(Vn,O9e),e(O9e,Jst),e(Vn,Yst),e(Vn,V9e),e(V9e,Zst),e(Vn,Kst),e(Vn,X9e),e(X9e,elt),e(Vn,olt),e(Yr,rlt),e(Yr,me),e(me,S6),e(S6,z9e),e(z9e,tlt),e(S6,alt),e(S6,Pne),e(Pne,nlt),e(S6,slt),e(me,llt),e(me,R6),e(R6,Q9e),e(Q9e,ilt),e(R6,dlt),e(R6,Bne),e(Bne,clt),e(R6,mlt),e(me,flt),e(me,P6),e(P6,W9e),e(W9e,glt),e(P6,hlt),e(P6,Ine),e(Ine,ult),e(P6,plt),e(me,_lt),e(me,B6),e(B6,U9e),e(U9e,blt),e(B6,vlt),e(B6,Nne),e(Nne,Flt),e(B6,Tlt),e(me,Mlt),e(me,I6),e(I6,H9e),e(H9e,Elt),e(I6,Clt),e(I6,qne),e(qne,wlt),e(I6,Alt),e(me,Llt),e(me,N6),e(N6,J9e),e(J9e,ylt),e(N6,xlt),e(N6,jne),e(jne,$lt),e(N6,klt),e(me,Slt),e(me,q6),e(q6,Y9e),e(Y9e,Rlt),e(q6,Plt),e(q6,Dne),e(Dne,Blt),e(q6,Ilt),e(me,Nlt),e(me,j6),e(j6,Z9e),e(Z9e,qlt),e(j6,jlt),e(j6,Gne),e(Gne,Dlt),e(j6,Glt),e(me,Olt),e(me,D6),e(D6,K9e),e(K9e,Vlt),e(D6,Xlt),e(D6,One),e(One,zlt),e(D6,Qlt),e(me,Wlt),e(me,G6),e(G6,exe),e(exe,Ult),e(G6,Hlt),e(G6,Vne),e(Vne,Jlt),e(G6,Ylt),e(me,Zlt),e(me,O6),e(O6,oxe),e(oxe,Klt),e(O6,eit),e(O6,Xne),e(Xne,oit),e(O6,rit),e(me,tit),e(me,V6),e(V6,rxe),e(rxe,ait),e(V6,nit),e(V6,zne),e(zne,sit),e(V6,lit),e(me,iit),e(me,X6),e(X6,txe),e(txe,dit),e(X6,cit),e(X6,Qne),e(Qne,mit),e(X6,fit),e(me,git),e(me,z6),e(z6,axe),e(axe,hit),e(z6,uit),e(z6,Wne),e(Wne,pit),e(z6,_it),e(me,bit),e(me,Q6),e(Q6,nxe),e(nxe,vit),e(Q6,Fit),e(Q6,Une),e(Une,Tit),e(Q6,Mit),e(me,Eit),e(me,W6),e(W6,sxe),e(sxe,Cit),e(W6,wit),e(W6,Hne),e(Hne,Ait),e(W6,Lit),e(me,yit),e(me,U6),e(U6,lxe),e(lxe,xit),e(U6,$it),e(U6,Jne),e(Jne,kit),e(U6,Sit),e(me,Rit),e(me,H6),e(H6,ixe),e(ixe,Pit),e(H6,Bit),e(H6,Yne),e(Yne,Iit),e(H6,Nit),e(me,qit),e(me,J6),e(J6,dxe),e(dxe,jit),e(J6,Dit),e(J6,Zne),e(Zne,Git),e(J6,Oit),e(me,Vit),e(me,Y6),e(Y6,cxe),e(cxe,Xit),e(Y6,zit),e(Y6,Kne),e(Kne,Qit),e(Y6,Wit),e(me,Uit),e(me,Z6),e(Z6,mxe),e(mxe,Hit),e(Z6,Jit),e(Z6,ese),e(ese,Yit),e(Z6,Zit),e(Yr,Kit),M(K6,Yr,null),b(m,mto,_),b(m,Gm,_),e(Gm,e7),e(e7,fxe),M(QR,fxe,null),e(Gm,edt),e(Gm,gxe),e(gxe,odt),b(m,fto,_),b(m,Mr,_),M(WR,Mr,null),e(Mr,rdt),e(Mr,Om),e(Om,tdt),e(Om,ose),e(ose,adt),e(Om,ndt),e(Om,rse),e(rse,sdt),e(Om,ldt),e(Mr,idt),e(Mr,UR),e(UR,ddt),e(UR,hxe),e(hxe,cdt),e(UR,mdt),e(Mr,fdt),e(Mr,la),M(HR,la,null),e(la,gdt),e(la,uxe),e(uxe,hdt),e(la,udt),e(la,Vm),e(Vm,pdt),e(Vm,pxe),e(pxe,_dt),e(Vm,bdt),e(Vm,tse),e(tse,vdt),e(Vm,Fdt),e(la,Tdt),M(o7,la,null),e(Mr,Mdt),e(Mr,Zr),M(JR,Zr,null),e(Zr,Edt),e(Zr,_xe),e(_xe,Cdt),e(Zr,wdt),e(Zr,Xn),e(Xn,Adt),e(Xn,bxe),e(bxe,Ldt),e(Xn,ydt),e(Xn,vxe),e(vxe,xdt),e(Xn,$dt),e(Xn,Fxe),e(Fxe,kdt),e(Xn,Sdt),e(Zr,Rdt),e(Zr,Txe),e(Txe,r7),e(r7,Mxe),e(Mxe,Pdt),e(r7,Bdt),e(r7,ase),e(ase,Idt),e(r7,Ndt),e(Zr,qdt),M(t7,Zr,null),b(m,gto,_),b(m,Xm,_),e(Xm,a7),e(a7,Exe),M(YR,Exe,null),e(Xm,jdt),e(Xm,Cxe),e(Cxe,Ddt),b(m,hto,_),b(m,Er,_),M(ZR,Er,null),e(Er,Gdt),e(Er,zm),e(zm,Odt),e(zm,nse),e(nse,Vdt),e(zm,Xdt),e(zm,sse),e(sse,zdt),e(zm,Qdt),e(Er,Wdt),e(Er,KR),e(KR,Udt),e(KR,wxe),e(wxe,Hdt),e(KR,Jdt),e(Er,Ydt),e(Er,ia),M(eP,ia,null),e(ia,Zdt),e(ia,Axe),e(Axe,Kdt),e(ia,ect),e(ia,Qm),e(Qm,oct),e(Qm,Lxe),e(Lxe,rct),e(Qm,tct),e(Qm,lse),e(lse,act),e(Qm,nct),e(ia,sct),M(n7,ia,null),e(Er,lct),e(Er,Kr),M(oP,Kr,null),e(Kr,ict),e(Kr,yxe),e(yxe,dct),e(Kr,cct),e(Kr,zn),e(zn,mct),e(zn,xxe),e(xxe,fct),e(zn,gct),e(zn,$xe),e($xe,hct),e(zn,uct),e(zn,kxe),e(kxe,pct),e(zn,_ct),e(Kr,bct),e(Kr,rP),e(rP,s7),e(s7,Sxe),e(Sxe,vct),e(s7,Fct),e(s7,ise),e(ise,Tct),e(s7,Mct),e(rP,Ect),e(rP,l7),e(l7,Rxe),e(Rxe,Cct),e(l7,wct),e(l7,dse),e(dse,Act),e(l7,Lct),e(Kr,yct),M(i7,Kr,null),b(m,uto,_),b(m,Wm,_),e(Wm,d7),e(d7,Pxe),M(tP,Pxe,null),e(Wm,xct),e(Wm,Bxe),e(Bxe,$ct),b(m,pto,_),b(m,Cr,_),M(aP,Cr,null),e(Cr,kct),e(Cr,Um),e(Um,Sct),e(Um,cse),e(cse,Rct),e(Um,Pct),e(Um,mse),e(mse,Bct),e(Um,Ict),e(Cr,Nct),e(Cr,nP),e(nP,qct),e(nP,Ixe),e(Ixe,jct),e(nP,Dct),e(Cr,Gct),e(Cr,da),M(sP,da,null),e(da,Oct),e(da,Nxe),e(Nxe,Vct),e(da,Xct),e(da,Hm),e(Hm,zct),e(Hm,qxe),e(qxe,Qct),e(Hm,Wct),e(Hm,fse),e(fse,Uct),e(Hm,Hct),e(da,Jct),M(c7,da,null),e(Cr,Yct),e(Cr,et),M(lP,et,null),e(et,Zct),e(et,jxe),e(jxe,Kct),e(et,emt),e(et,Qn),e(Qn,omt),e(Qn,Dxe),e(Dxe,rmt),e(Qn,tmt),e(Qn,Gxe),e(Gxe,amt),e(Qn,nmt),e(Qn,Oxe),e(Oxe,smt),e(Qn,lmt),e(et,imt),e(et,te),e(te,m7),e(m7,Vxe),e(Vxe,dmt),e(m7,cmt),e(m7,gse),e(gse,mmt),e(m7,fmt),e(te,gmt),e(te,f7),e(f7,Xxe),e(Xxe,hmt),e(f7,umt),e(f7,hse),e(hse,pmt),e(f7,_mt),e(te,bmt),e(te,g7),e(g7,zxe),e(zxe,vmt),e(g7,Fmt),e(g7,use),e(use,Tmt),e(g7,Mmt),e(te,Emt),e(te,h7),e(h7,Qxe),e(Qxe,Cmt),e(h7,wmt),e(h7,pse),e(pse,Amt),e(h7,Lmt),e(te,ymt),e(te,u7),e(u7,Wxe),e(Wxe,xmt),e(u7,$mt),e(u7,_se),e(_se,kmt),e(u7,Smt),e(te,Rmt),e(te,p7),e(p7,Uxe),e(Uxe,Pmt),e(p7,Bmt),e(p7,bse),e(bse,Imt),e(p7,Nmt),e(te,qmt),e(te,_7),e(_7,Hxe),e(Hxe,jmt),e(_7,Dmt),e(_7,vse),e(vse,Gmt),e(_7,Omt),e(te,Vmt),e(te,b7),e(b7,Jxe),e(Jxe,Xmt),e(b7,zmt),e(b7,Fse),e(Fse,Qmt),e(b7,Wmt),e(te,Umt),e(te,v7),e(v7,Yxe),e(Yxe,Hmt),e(v7,Jmt),e(v7,Tse),e(Tse,Ymt),e(v7,Zmt),e(te,Kmt),e(te,F7),e(F7,Zxe),e(Zxe,eft),e(F7,oft),e(F7,Mse),e(Mse,rft),e(F7,tft),e(te,aft),e(te,T7),e(T7,Kxe),e(Kxe,nft),e(T7,sft),e(T7,Ese),e(Ese,lft),e(T7,ift),e(te,dft),e(te,M7),e(M7,e$e),e(e$e,cft),e(M7,mft),e(M7,Cse),e(Cse,fft),e(M7,gft),e(te,hft),e(te,E7),e(E7,o$e),e(o$e,uft),e(E7,pft),e(E7,wse),e(wse,_ft),e(E7,bft),e(te,vft),e(te,C7),e(C7,r$e),e(r$e,Fft),e(C7,Tft),e(C7,Ase),e(Ase,Mft),e(C7,Eft),e(te,Cft),e(te,w7),e(w7,t$e),e(t$e,wft),e(w7,Aft),e(w7,Lse),e(Lse,Lft),e(w7,yft),e(te,xft),e(te,A7),e(A7,a$e),e(a$e,$ft),e(A7,kft),e(A7,yse),e(yse,Sft),e(A7,Rft),e(te,Pft),e(te,L7),e(L7,n$e),e(n$e,Bft),e(L7,Ift),e(L7,xse),e(xse,Nft),e(L7,qft),e(te,jft),e(te,y7),e(y7,s$e),e(s$e,Dft),e(y7,Gft),e(y7,$se),e($se,Oft),e(y7,Vft),e(te,Xft),e(te,x7),e(x7,l$e),e(l$e,zft),e(x7,Qft),e(x7,kse),e(kse,Wft),e(x7,Uft),e(te,Hft),e(te,$7),e($7,i$e),e(i$e,Jft),e($7,Yft),e($7,Sse),e(Sse,Zft),e($7,Kft),e(te,egt),e(te,k7),e(k7,d$e),e(d$e,ogt),e(k7,rgt),e(k7,Rse),e(Rse,tgt),e(k7,agt),e(te,ngt),e(te,S7),e(S7,c$e),e(c$e,sgt),e(S7,lgt),e(S7,Pse),e(Pse,igt),e(S7,dgt),e(te,cgt),e(te,R7),e(R7,m$e),e(m$e,mgt),e(R7,fgt),e(R7,Bse),e(Bse,ggt),e(R7,hgt),e(te,ugt),e(te,P7),e(P7,f$e),e(f$e,pgt),e(P7,_gt),e(P7,Ise),e(Ise,bgt),e(P7,vgt),e(te,Fgt),e(te,B7),e(B7,g$e),e(g$e,Tgt),e(B7,Mgt),e(B7,Nse),e(Nse,Egt),e(B7,Cgt),e(te,wgt),e(te,I7),e(I7,h$e),e(h$e,Agt),e(I7,Lgt),e(I7,qse),e(qse,ygt),e(I7,xgt),e(te,$gt),e(te,N7),e(N7,u$e),e(u$e,kgt),e(N7,Sgt),e(N7,jse),e(jse,Rgt),e(N7,Pgt),e(et,Bgt),M(q7,et,null),b(m,_to,_),b(m,Jm,_),e(Jm,j7),e(j7,p$e),M(iP,p$e,null),e(Jm,Igt),e(Jm,_$e),e(_$e,Ngt),b(m,bto,_),b(m,wr,_),M(dP,wr,null),e(wr,qgt),e(wr,Ym),e(Ym,jgt),e(Ym,Dse),e(Dse,Dgt),e(Ym,Ggt),e(Ym,Gse),e(Gse,Ogt),e(Ym,Vgt),e(wr,Xgt),e(wr,cP),e(cP,zgt),e(cP,b$e),e(b$e,Qgt),e(cP,Wgt),e(wr,Ugt),e(wr,ca),M(mP,ca,null),e(ca,Hgt),e(ca,v$e),e(v$e,Jgt),e(ca,Ygt),e(ca,Zm),e(Zm,Zgt),e(Zm,F$e),e(F$e,Kgt),e(Zm,eht),e(Zm,Ose),e(Ose,oht),e(Zm,rht),e(ca,tht),M(D7,ca,null),e(wr,aht),e(wr,ot),M(fP,ot,null),e(ot,nht),e(ot,T$e),e(T$e,sht),e(ot,lht),e(ot,Wn),e(Wn,iht),e(Wn,M$e),e(M$e,dht),e(Wn,cht),e(Wn,E$e),e(E$e,mht),e(Wn,fht),e(Wn,C$e),e(C$e,ght),e(Wn,hht),e(ot,uht),e(ot,$e),e($e,G7),e(G7,w$e),e(w$e,pht),e(G7,_ht),e(G7,Vse),e(Vse,bht),e(G7,vht),e($e,Fht),e($e,O7),e(O7,A$e),e(A$e,Tht),e(O7,Mht),e(O7,Xse),e(Xse,Eht),e(O7,Cht),e($e,wht),e($e,V7),e(V7,L$e),e(L$e,Aht),e(V7,Lht),e(V7,zse),e(zse,yht),e(V7,xht),e($e,$ht),e($e,X7),e(X7,y$e),e(y$e,kht),e(X7,Sht),e(X7,Qse),e(Qse,Rht),e(X7,Pht),e($e,Bht),e($e,z7),e(z7,x$e),e(x$e,Iht),e(z7,Nht),e(z7,Wse),e(Wse,qht),e(z7,jht),e($e,Dht),e($e,Q7),e(Q7,$$e),e($$e,Ght),e(Q7,Oht),e(Q7,Use),e(Use,Vht),e(Q7,Xht),e($e,zht),e($e,W7),e(W7,k$e),e(k$e,Qht),e(W7,Wht),e(W7,Hse),e(Hse,Uht),e(W7,Hht),e($e,Jht),e($e,U7),e(U7,S$e),e(S$e,Yht),e(U7,Zht),e(U7,Jse),e(Jse,Kht),e(U7,eut),e($e,out),e($e,H7),e(H7,R$e),e(R$e,rut),e(H7,tut),e(H7,Yse),e(Yse,aut),e(H7,nut),e($e,sut),e($e,J7),e(J7,P$e),e(P$e,lut),e(J7,iut),e(J7,Zse),e(Zse,dut),e(J7,cut),e(ot,mut),M(Y7,ot,null),b(m,vto,_),b(m,Km,_),e(Km,Z7),e(Z7,B$e),M(gP,B$e,null),e(Km,fut),e(Km,I$e),e(I$e,gut),b(m,Fto,_),b(m,Ar,_),M(hP,Ar,null),e(Ar,hut),e(Ar,ef),e(ef,uut),e(ef,Kse),e(Kse,put),e(ef,_ut),e(ef,ele),e(ele,but),e(ef,vut),e(Ar,Fut),e(Ar,uP),e(uP,Tut),e(uP,N$e),e(N$e,Mut),e(uP,Eut),e(Ar,Cut),e(Ar,ma),M(pP,ma,null),e(ma,wut),e(ma,q$e),e(q$e,Aut),e(ma,Lut),e(ma,of),e(of,yut),e(of,j$e),e(j$e,xut),e(of,$ut),e(of,ole),e(ole,kut),e(of,Sut),e(ma,Rut),M(K7,ma,null),e(Ar,Put),e(Ar,rt),M(_P,rt,null),e(rt,But),e(rt,D$e),e(D$e,Iut),e(rt,Nut),e(rt,Un),e(Un,qut),e(Un,G$e),e(G$e,jut),e(Un,Dut),e(Un,O$e),e(O$e,Gut),e(Un,Out),e(Un,V$e),e(V$e,Vut),e(Un,Xut),e(rt,zut),e(rt,Ee),e(Ee,eL),e(eL,X$e),e(X$e,Qut),e(eL,Wut),e(eL,rle),e(rle,Uut),e(eL,Hut),e(Ee,Jut),e(Ee,oL),e(oL,z$e),e(z$e,Yut),e(oL,Zut),e(oL,tle),e(tle,Kut),e(oL,ept),e(Ee,opt),e(Ee,rL),e(rL,Q$e),e(Q$e,rpt),e(rL,tpt),e(rL,ale),e(ale,apt),e(rL,npt),e(Ee,spt),e(Ee,tL),e(tL,W$e),e(W$e,lpt),e(tL,ipt),e(tL,nle),e(nle,dpt),e(tL,cpt),e(Ee,mpt),e(Ee,aL),e(aL,U$e),e(U$e,fpt),e(aL,gpt),e(aL,sle),e(sle,hpt),e(aL,upt),e(Ee,ppt),e(Ee,nL),e(nL,H$e),e(H$e,_pt),e(nL,bpt),e(nL,lle),e(lle,vpt),e(nL,Fpt),e(Ee,Tpt),e(Ee,sL),e(sL,J$e),e(J$e,Mpt),e(sL,Ept),e(sL,ile),e(ile,Cpt),e(sL,wpt),e(Ee,Apt),e(Ee,lL),e(lL,Y$e),e(Y$e,Lpt),e(lL,ypt),e(lL,dle),e(dle,xpt),e(lL,$pt),e(Ee,kpt),e(Ee,iL),e(iL,Z$e),e(Z$e,Spt),e(iL,Rpt),e(iL,cle),e(cle,Ppt),e(iL,Bpt),e(Ee,Ipt),e(Ee,dL),e(dL,K$e),e(K$e,Npt),e(dL,qpt),e(dL,mle),e(mle,jpt),e(dL,Dpt),e(Ee,Gpt),e(Ee,cL),e(cL,eke),e(eke,Opt),e(cL,Vpt),e(cL,fle),e(fle,Xpt),e(cL,zpt),e(Ee,Qpt),e(Ee,mL),e(mL,oke),e(oke,Wpt),e(mL,Upt),e(mL,gle),e(gle,Hpt),e(mL,Jpt),e(Ee,Ypt),e(Ee,fL),e(fL,rke),e(rke,Zpt),e(fL,Kpt),e(fL,hle),e(hle,e_t),e(fL,o_t),e(rt,r_t),M(gL,rt,null),b(m,Tto,_),b(m,rf,_),e(rf,hL),e(hL,tke),M(bP,tke,null),e(rf,t_t),e(rf,ake),e(ake,a_t),b(m,Mto,_),b(m,Lr,_),M(vP,Lr,null),e(Lr,n_t),e(Lr,tf),e(tf,s_t),e(tf,ule),e(ule,l_t),e(tf,i_t),e(tf,ple),e(ple,d_t),e(tf,c_t),e(Lr,m_t),e(Lr,FP),e(FP,f_t),e(FP,nke),e(nke,g_t),e(FP,h_t),e(Lr,u_t),e(Lr,fa),M(TP,fa,null),e(fa,p_t),e(fa,ske),e(ske,__t),e(fa,b_t),e(fa,af),e(af,v_t),e(af,lke),e(lke,F_t),e(af,T_t),e(af,_le),e(_le,M_t),e(af,E_t),e(fa,C_t),M(uL,fa,null),e(Lr,w_t),e(Lr,tt),M(MP,tt,null),e(tt,A_t),e(tt,ike),e(ike,L_t),e(tt,y_t),e(tt,Hn),e(Hn,x_t),e(Hn,dke),e(dke,$_t),e(Hn,k_t),e(Hn,cke),e(cke,S_t),e(Hn,R_t),e(Hn,mke),e(mke,P_t),e(Hn,B_t),e(tt,I_t),e(tt,ke),e(ke,pL),e(pL,fke),e(fke,N_t),e(pL,q_t),e(pL,ble),e(ble,j_t),e(pL,D_t),e(ke,G_t),e(ke,_L),e(_L,gke),e(gke,O_t),e(_L,V_t),e(_L,vle),e(vle,X_t),e(_L,z_t),e(ke,Q_t),e(ke,bL),e(bL,hke),e(hke,W_t),e(bL,U_t),e(bL,Fle),e(Fle,H_t),e(bL,J_t),e(ke,Y_t),e(ke,vL),e(vL,uke),e(uke,Z_t),e(vL,K_t),e(vL,Tle),e(Tle,e1t),e(vL,o1t),e(ke,r1t),e(ke,FL),e(FL,pke),e(pke,t1t),e(FL,a1t),e(FL,Mle),e(Mle,n1t),e(FL,s1t),e(ke,l1t),e(ke,TL),e(TL,_ke),e(_ke,i1t),e(TL,d1t),e(TL,Ele),e(Ele,c1t),e(TL,m1t),e(ke,f1t),e(ke,ML),e(ML,bke),e(bke,g1t),e(ML,h1t),e(ML,Cle),e(Cle,u1t),e(ML,p1t),e(ke,_1t),e(ke,EL),e(EL,vke),e(vke,b1t),e(EL,v1t),e(EL,wle),e(wle,F1t),e(EL,T1t),e(ke,M1t),e(ke,CL),e(CL,Fke),e(Fke,E1t),e(CL,C1t),e(CL,Ale),e(Ale,w1t),e(CL,A1t),e(ke,L1t),e(ke,wL),e(wL,Tke),e(Tke,y1t),e(wL,x1t),e(wL,Lle),e(Lle,$1t),e(wL,k1t),e(tt,S1t),M(AL,tt,null),b(m,Eto,_),b(m,nf,_),e(nf,LL),e(LL,Mke),M(EP,Mke,null),e(nf,R1t),e(nf,Eke),e(Eke,P1t),b(m,Cto,_),b(m,yr,_),M(CP,yr,null),e(yr,B1t),e(yr,sf),e(sf,I1t),e(sf,yle),e(yle,N1t),e(sf,q1t),e(sf,xle),e(xle,j1t),e(sf,D1t),e(yr,G1t),e(yr,wP),e(wP,O1t),e(wP,Cke),e(Cke,V1t),e(wP,X1t),e(yr,z1t),e(yr,ga),M(AP,ga,null),e(ga,Q1t),e(ga,wke),e(wke,W1t),e(ga,U1t),e(ga,lf),e(lf,H1t),e(lf,Ake),e(Ake,J1t),e(lf,Y1t),e(lf,$le),e($le,Z1t),e(lf,K1t),e(ga,e2t),M(yL,ga,null),e(yr,o2t),e(yr,at),M(LP,at,null),e(at,r2t),e(at,Lke),e(Lke,t2t),e(at,a2t),e(at,Jn),e(Jn,n2t),e(Jn,yke),e(yke,s2t),e(Jn,l2t),e(Jn,xke),e(xke,i2t),e(Jn,d2t),e(Jn,$ke),e($ke,c2t),e(Jn,m2t),e(at,f2t),e(at,Se),e(Se,xL),e(xL,kke),e(kke,g2t),e(xL,h2t),e(xL,kle),e(kle,u2t),e(xL,p2t),e(Se,_2t),e(Se,$L),e($L,Ske),e(Ske,b2t),e($L,v2t),e($L,Sle),e(Sle,F2t),e($L,T2t),e(Se,M2t),e(Se,kL),e(kL,Rke),e(Rke,E2t),e(kL,C2t),e(kL,Rle),e(Rle,w2t),e(kL,A2t),e(Se,L2t),e(Se,SL),e(SL,Pke),e(Pke,y2t),e(SL,x2t),e(SL,Ple),e(Ple,$2t),e(SL,k2t),e(Se,S2t),e(Se,RL),e(RL,Bke),e(Bke,R2t),e(RL,P2t),e(RL,Ble),e(Ble,B2t),e(RL,I2t),e(Se,N2t),e(Se,PL),e(PL,Ike),e(Ike,q2t),e(PL,j2t),e(PL,Ile),e(Ile,D2t),e(PL,G2t),e(Se,O2t),e(Se,BL),e(BL,Nke),e(Nke,V2t),e(BL,X2t),e(BL,Nle),e(Nle,z2t),e(BL,Q2t),e(Se,W2t),e(Se,IL),e(IL,qke),e(qke,U2t),e(IL,H2t),e(IL,qle),e(qle,J2t),e(IL,Y2t),e(Se,Z2t),e(Se,NL),e(NL,jke),e(jke,K2t),e(NL,ebt),e(NL,jle),e(jle,obt),e(NL,rbt),e(Se,tbt),e(Se,qL),e(qL,Dke),e(Dke,abt),e(qL,nbt),e(qL,Dle),e(Dle,sbt),e(qL,lbt),e(at,ibt),M(jL,at,null),b(m,wto,_),b(m,df,_),e(df,DL),e(DL,Gke),M(yP,Gke,null),e(df,dbt),e(df,Oke),e(Oke,cbt),b(m,Ato,_),b(m,xr,_),M(xP,xr,null),e(xr,mbt),e(xr,cf),e(cf,fbt),e(cf,Gle),e(Gle,gbt),e(cf,hbt),e(cf,Ole),e(Ole,ubt),e(cf,pbt),e(xr,_bt),e(xr,$P),e($P,bbt),e($P,Vke),e(Vke,vbt),e($P,Fbt),e(xr,Tbt),e(xr,ha),M(kP,ha,null),e(ha,Mbt),e(ha,Xke),e(Xke,Ebt),e(ha,Cbt),e(ha,mf),e(mf,wbt),e(mf,zke),e(zke,Abt),e(mf,Lbt),e(mf,Vle),e(Vle,ybt),e(mf,xbt),e(ha,$bt),M(GL,ha,null),e(xr,kbt),e(xr,nt),M(SP,nt,null),e(nt,Sbt),e(nt,Qke),e(Qke,Rbt),e(nt,Pbt),e(nt,Yn),e(Yn,Bbt),e(Yn,Wke),e(Wke,Ibt),e(Yn,Nbt),e(Yn,Uke),e(Uke,qbt),e(Yn,jbt),e(Yn,Hke),e(Hke,Dbt),e(Yn,Gbt),e(nt,Obt),e(nt,Re),e(Re,OL),e(OL,Jke),e(Jke,Vbt),e(OL,Xbt),e(OL,Xle),e(Xle,zbt),e(OL,Qbt),e(Re,Wbt),e(Re,VL),e(VL,Yke),e(Yke,Ubt),e(VL,Hbt),e(VL,zle),e(zle,Jbt),e(VL,Ybt),e(Re,Zbt),e(Re,XL),e(XL,Zke),e(Zke,Kbt),e(XL,evt),e(XL,Qle),e(Qle,ovt),e(XL,rvt),e(Re,tvt),e(Re,zL),e(zL,Kke),e(Kke,avt),e(zL,nvt),e(zL,Wle),e(Wle,svt),e(zL,lvt),e(Re,ivt),e(Re,QL),e(QL,eSe),e(eSe,dvt),e(QL,cvt),e(QL,Ule),e(Ule,mvt),e(QL,fvt),e(Re,gvt),e(Re,WL),e(WL,oSe),e(oSe,hvt),e(WL,uvt),e(WL,Hle),e(Hle,pvt),e(WL,_vt),e(Re,bvt),e(Re,UL),e(UL,rSe),e(rSe,vvt),e(UL,Fvt),e(UL,Jle),e(Jle,Tvt),e(UL,Mvt),e(Re,Evt),e(Re,HL),e(HL,tSe),e(tSe,Cvt),e(HL,wvt),e(HL,Yle),e(Yle,Avt),e(HL,Lvt),e(Re,yvt),e(Re,JL),e(JL,aSe),e(aSe,xvt),e(JL,$vt),e(JL,Zle),e(Zle,kvt),e(JL,Svt),e(Re,Rvt),e(Re,YL),e(YL,nSe),e(nSe,Pvt),e(YL,Bvt),e(YL,Kle),e(Kle,Ivt),e(YL,Nvt),e(nt,qvt),M(ZL,nt,null),b(m,Lto,_),b(m,ff,_),e(ff,KL),e(KL,sSe),M(RP,sSe,null),e(ff,jvt),e(ff,lSe),e(lSe,Dvt),b(m,yto,_),b(m,$r,_),M(PP,$r,null),e($r,Gvt),e($r,gf),e(gf,Ovt),e(gf,eie),e(eie,Vvt),e(gf,Xvt),e(gf,oie),e(oie,zvt),e(gf,Qvt),e($r,Wvt),e($r,BP),e(BP,Uvt),e(BP,iSe),e(iSe,Hvt),e(BP,Jvt),e($r,Yvt),e($r,ua),M(IP,ua,null),e(ua,Zvt),e(ua,dSe),e(dSe,Kvt),e(ua,eFt),e(ua,hf),e(hf,oFt),e(hf,cSe),e(cSe,rFt),e(hf,tFt),e(hf,rie),e(rie,aFt),e(hf,nFt),e(ua,sFt),M(e8,ua,null),e($r,lFt),e($r,st),M(NP,st,null),e(st,iFt),e(st,mSe),e(mSe,dFt),e(st,cFt),e(st,Zn),e(Zn,mFt),e(Zn,fSe),e(fSe,fFt),e(Zn,gFt),e(Zn,gSe),e(gSe,hFt),e(Zn,uFt),e(Zn,hSe),e(hSe,pFt),e(Zn,_Ft),e(st,bFt),e(st,Pe),e(Pe,o8),e(o8,uSe),e(uSe,vFt),e(o8,FFt),e(o8,tie),e(tie,TFt),e(o8,MFt),e(Pe,EFt),e(Pe,r8),e(r8,pSe),e(pSe,CFt),e(r8,wFt),e(r8,aie),e(aie,AFt),e(r8,LFt),e(Pe,yFt),e(Pe,t8),e(t8,_Se),e(_Se,xFt),e(t8,$Ft),e(t8,nie),e(nie,kFt),e(t8,SFt),e(Pe,RFt),e(Pe,a8),e(a8,bSe),e(bSe,PFt),e(a8,BFt),e(a8,sie),e(sie,IFt),e(a8,NFt),e(Pe,qFt),e(Pe,n8),e(n8,vSe),e(vSe,jFt),e(n8,DFt),e(n8,lie),e(lie,GFt),e(n8,OFt),e(Pe,VFt),e(Pe,s8),e(s8,FSe),e(FSe,XFt),e(s8,zFt),e(s8,iie),e(iie,QFt),e(s8,WFt),e(Pe,UFt),e(Pe,l8),e(l8,TSe),e(TSe,HFt),e(l8,JFt),e(l8,die),e(die,YFt),e(l8,ZFt),e(Pe,KFt),e(Pe,i8),e(i8,MSe),e(MSe,eTt),e(i8,oTt),e(i8,cie),e(cie,rTt),e(i8,tTt),e(Pe,aTt),e(Pe,d8),e(d8,ESe),e(ESe,nTt),e(d8,sTt),e(d8,mie),e(mie,lTt),e(d8,iTt),e(Pe,dTt),e(Pe,c8),e(c8,CSe),e(CSe,cTt),e(c8,mTt),e(c8,fie),e(fie,fTt),e(c8,gTt),e(st,hTt),M(m8,st,null),b(m,xto,_),b(m,uf,_),e(uf,f8),e(f8,wSe),M(qP,wSe,null),e(uf,uTt),e(uf,ASe),e(ASe,pTt),b(m,$to,_),b(m,kr,_),M(jP,kr,null),e(kr,_Tt),e(kr,pf),e(pf,bTt),e(pf,gie),e(gie,vTt),e(pf,FTt),e(pf,hie),e(hie,TTt),e(pf,MTt),e(kr,ETt),e(kr,DP),e(DP,CTt),e(DP,LSe),e(LSe,wTt),e(DP,ATt),e(kr,LTt),e(kr,pa),M(GP,pa,null),e(pa,yTt),e(pa,ySe),e(ySe,xTt),e(pa,$Tt),e(pa,_f),e(_f,kTt),e(_f,xSe),e(xSe,STt),e(_f,RTt),e(_f,uie),e(uie,PTt),e(_f,BTt),e(pa,ITt),M(g8,pa,null),e(kr,NTt),e(kr,lt),M(OP,lt,null),e(lt,qTt),e(lt,$Se),e($Se,jTt),e(lt,DTt),e(lt,Kn),e(Kn,GTt),e(Kn,kSe),e(kSe,OTt),e(Kn,VTt),e(Kn,SSe),e(SSe,XTt),e(Kn,zTt),e(Kn,RSe),e(RSe,QTt),e(Kn,WTt),e(lt,UTt),e(lt,ze),e(ze,h8),e(h8,PSe),e(PSe,HTt),e(h8,JTt),e(h8,pie),e(pie,YTt),e(h8,ZTt),e(ze,KTt),e(ze,u8),e(u8,BSe),e(BSe,eMt),e(u8,oMt),e(u8,_ie),e(_ie,rMt),e(u8,tMt),e(ze,aMt),e(ze,p8),e(p8,ISe),e(ISe,nMt),e(p8,sMt),e(p8,bie),e(bie,lMt),e(p8,iMt),e(ze,dMt),e(ze,_8),e(_8,NSe),e(NSe,cMt),e(_8,mMt),e(_8,vie),e(vie,fMt),e(_8,gMt),e(ze,hMt),e(ze,b8),e(b8,qSe),e(qSe,uMt),e(b8,pMt),e(b8,Fie),e(Fie,_Mt),e(b8,bMt),e(ze,vMt),e(ze,v8),e(v8,jSe),e(jSe,FMt),e(v8,TMt),e(v8,Tie),e(Tie,MMt),e(v8,EMt),e(ze,CMt),e(ze,F8),e(F8,DSe),e(DSe,wMt),e(F8,AMt),e(F8,Mie),e(Mie,LMt),e(F8,yMt),e(ze,xMt),e(ze,T8),e(T8,GSe),e(GSe,$Mt),e(T8,kMt),e(T8,Eie),e(Eie,SMt),e(T8,RMt),e(lt,PMt),M(M8,lt,null),b(m,kto,_),b(m,bf,_),e(bf,E8),e(E8,OSe),M(VP,OSe,null),e(bf,BMt),e(bf,VSe),e(VSe,IMt),b(m,Sto,_),b(m,Sr,_),M(XP,Sr,null),e(Sr,NMt),e(Sr,vf),e(vf,qMt),e(vf,Cie),e(Cie,jMt),e(vf,DMt),e(vf,wie),e(wie,GMt),e(vf,OMt),e(Sr,VMt),e(Sr,zP),e(zP,XMt),e(zP,XSe),e(XSe,zMt),e(zP,QMt),e(Sr,WMt),e(Sr,_a),M(QP,_a,null),e(_a,UMt),e(_a,zSe),e(zSe,HMt),e(_a,JMt),e(_a,Ff),e(Ff,YMt),e(Ff,QSe),e(QSe,ZMt),e(Ff,KMt),e(Ff,Aie),e(Aie,eEt),e(Ff,oEt),e(_a,rEt),M(C8,_a,null),e(Sr,tEt),e(Sr,it),M(WP,it,null),e(it,aEt),e(it,WSe),e(WSe,nEt),e(it,sEt),e(it,es),e(es,lEt),e(es,USe),e(USe,iEt),e(es,dEt),e(es,HSe),e(HSe,cEt),e(es,mEt),e(es,JSe),e(JSe,fEt),e(es,gEt),e(it,hEt),e(it,Qe),e(Qe,w8),e(w8,YSe),e(YSe,uEt),e(w8,pEt),e(w8,Lie),e(Lie,_Et),e(w8,bEt),e(Qe,vEt),e(Qe,A8),e(A8,ZSe),e(ZSe,FEt),e(A8,TEt),e(A8,yie),e(yie,MEt),e(A8,EEt),e(Qe,CEt),e(Qe,L8),e(L8,KSe),e(KSe,wEt),e(L8,AEt),e(L8,xie),e(xie,LEt),e(L8,yEt),e(Qe,xEt),e(Qe,y8),e(y8,eRe),e(eRe,$Et),e(y8,kEt),e(y8,$ie),e($ie,SEt),e(y8,REt),e(Qe,PEt),e(Qe,x8),e(x8,oRe),e(oRe,BEt),e(x8,IEt),e(x8,kie),e(kie,NEt),e(x8,qEt),e(Qe,jEt),e(Qe,$8),e($8,rRe),e(rRe,DEt),e($8,GEt),e($8,Sie),e(Sie,OEt),e($8,VEt),e(Qe,XEt),e(Qe,k8),e(k8,tRe),e(tRe,zEt),e(k8,QEt),e(k8,Rie),e(Rie,WEt),e(k8,UEt),e(Qe,HEt),e(Qe,S8),e(S8,aRe),e(aRe,JEt),e(S8,YEt),e(S8,Pie),e(Pie,ZEt),e(S8,KEt),e(it,e4t),M(R8,it,null),b(m,Rto,_),b(m,Tf,_),e(Tf,P8),e(P8,nRe),M(UP,nRe,null),e(Tf,o4t),e(Tf,sRe),e(sRe,r4t),b(m,Pto,_),b(m,Rr,_),M(HP,Rr,null),e(Rr,t4t),e(Rr,Mf),e(Mf,a4t),e(Mf,Bie),e(Bie,n4t),e(Mf,s4t),e(Mf,Iie),e(Iie,l4t),e(Mf,i4t),e(Rr,d4t),e(Rr,JP),e(JP,c4t),e(JP,lRe),e(lRe,m4t),e(JP,f4t),e(Rr,g4t),e(Rr,ba),M(YP,ba,null),e(ba,h4t),e(ba,iRe),e(iRe,u4t),e(ba,p4t),e(ba,Ef),e(Ef,_4t),e(Ef,dRe),e(dRe,b4t),e(Ef,v4t),e(Ef,Nie),e(Nie,F4t),e(Ef,T4t),e(ba,M4t),M(B8,ba,null),e(Rr,E4t),e(Rr,dt),M(ZP,dt,null),e(dt,C4t),e(dt,cRe),e(cRe,w4t),e(dt,A4t),e(dt,os),e(os,L4t),e(os,mRe),e(mRe,y4t),e(os,x4t),e(os,fRe),e(fRe,$4t),e(os,k4t),e(os,gRe),e(gRe,S4t),e(os,R4t),e(dt,P4t),e(dt,hRe),e(hRe,I8),e(I8,uRe),e(uRe,B4t),e(I8,I4t),e(I8,qie),e(qie,N4t),e(I8,q4t),e(dt,j4t),M(N8,dt,null),b(m,Bto,_),b(m,Cf,_),e(Cf,q8),e(q8,pRe),M(KP,pRe,null),e(Cf,D4t),e(Cf,_Re),e(_Re,G4t),b(m,Ito,_),b(m,Pr,_),M(eB,Pr,null),e(Pr,O4t),e(Pr,wf),e(wf,V4t),e(wf,jie),e(jie,X4t),e(wf,z4t),e(wf,Die),e(Die,Q4t),e(wf,W4t),e(Pr,U4t),e(Pr,oB),e(oB,H4t),e(oB,bRe),e(bRe,J4t),e(oB,Y4t),e(Pr,Z4t),e(Pr,va),M(rB,va,null),e(va,K4t),e(va,vRe),e(vRe,eCt),e(va,oCt),e(va,Af),e(Af,rCt),e(Af,FRe),e(FRe,tCt),e(Af,aCt),e(Af,Gie),e(Gie,nCt),e(Af,sCt),e(va,lCt),M(j8,va,null),e(Pr,iCt),e(Pr,ct),M(tB,ct,null),e(ct,dCt),e(ct,TRe),e(TRe,cCt),e(ct,mCt),e(ct,rs),e(rs,fCt),e(rs,MRe),e(MRe,gCt),e(rs,hCt),e(rs,ERe),e(ERe,uCt),e(rs,pCt),e(rs,CRe),e(CRe,_Ct),e(rs,bCt),e(ct,vCt),e(ct,aB),e(aB,D8),e(D8,wRe),e(wRe,FCt),e(D8,TCt),e(D8,Oie),e(Oie,MCt),e(D8,ECt),e(aB,CCt),e(aB,G8),e(G8,ARe),e(ARe,wCt),e(G8,ACt),e(G8,Vie),e(Vie,LCt),e(G8,yCt),e(ct,xCt),M(O8,ct,null),b(m,Nto,_),b(m,Lf,_),e(Lf,V8),e(V8,LRe),M(nB,LRe,null),e(Lf,$Ct),e(Lf,yRe),e(yRe,kCt),b(m,qto,_),b(m,Br,_),M(sB,Br,null),e(Br,SCt),e(Br,yf),e(yf,RCt),e(yf,Xie),e(Xie,PCt),e(yf,BCt),e(yf,zie),e(zie,ICt),e(yf,NCt),e(Br,qCt),e(Br,lB),e(lB,jCt),e(lB,xRe),e(xRe,DCt),e(lB,GCt),e(Br,OCt),e(Br,Fa),M(iB,Fa,null),e(Fa,VCt),e(Fa,$Re),e($Re,XCt),e(Fa,zCt),e(Fa,xf),e(xf,QCt),e(xf,kRe),e(kRe,WCt),e(xf,UCt),e(xf,Qie),e(Qie,HCt),e(xf,JCt),e(Fa,YCt),M(X8,Fa,null),e(Br,ZCt),e(Br,mt),M(dB,mt,null),e(mt,KCt),e(mt,SRe),e(SRe,e3t),e(mt,o3t),e(mt,ts),e(ts,r3t),e(ts,RRe),e(RRe,t3t),e(ts,a3t),e(ts,PRe),e(PRe,n3t),e(ts,s3t),e(ts,BRe),e(BRe,l3t),e(ts,i3t),e(mt,d3t),e(mt,IRe),e(IRe,z8),e(z8,NRe),e(NRe,c3t),e(z8,m3t),e(z8,Wie),e(Wie,f3t),e(z8,g3t),e(mt,h3t),M(Q8,mt,null),jto=!0},p(m,[_]){const cB={};_&2&&(cB.$$scope={dirty:_,ctx:m}),qf.$set(cB);const qRe={};_&2&&(qRe.$$scope={dirty:_,ctx:m}),mu.$set(qRe);const jRe={};_&2&&(jRe.$$scope={dirty:_,ctx:m}),Hu.$set(jRe);const DRe={};_&2&&(DRe.$$scope={dirty:_,ctx:m}),Gp.$set(DRe);const mB={};_&2&&(mB.$$scope={dirty:_,ctx:m}),Op.$set(mB);const GRe={};_&2&&(GRe.$$scope={dirty:_,ctx:m}),h_.$set(GRe);const as={};_&2&&(as.$$scope={dirty:_,ctx:m}),u_.$set(as);const ORe={};_&2&&(ORe.$$scope={dirty:_,ctx:m}),b_.$set(ORe);const VRe={};_&2&&(VRe.$$scope={dirty:_,ctx:m}),q2.$set(VRe);const XRe={};_&2&&(XRe.$$scope={dirty:_,ctx:m}),D2.$set(XRe);const fB={};_&2&&(fB.$$scope={dirty:_,ctx:m}),Ib.$set(fB);const zRe={};_&2&&(zRe.$$scope={dirty:_,ctx:m}),qb.$set(zRe);const gB={};_&2&&(gB.$$scope={dirty:_,ctx:m}),yv.$set(gB);const QRe={};_&2&&(QRe.$$scope={dirty:_,ctx:m}),$v.$set(QRe);const hB={};_&2&&(hB.$$scope={dirty:_,ctx:m}),_F.$set(hB);const WRe={};_&2&&(WRe.$$scope={dirty:_,ctx:m}),vF.$set(WRe);const URe={};_&2&&(URe.$$scope={dirty:_,ctx:m}),GF.$set(URe);const HRe={};_&2&&(HRe.$$scope={dirty:_,ctx:m}),VF.$set(HRe);const $f={};_&2&&($f.$$scope={dirty:_,ctx:m}),QT.$set($f);const JRe={};_&2&&(JRe.$$scope={dirty:_,ctx:m}),UT.$set(JRe);const YRe={};_&2&&(YRe.$$scope={dirty:_,ctx:m}),yM.$set(YRe);const ZRe={};_&2&&(ZRe.$$scope={dirty:_,ctx:m}),$M.$set(ZRe);const uB={};_&2&&(uB.$$scope={dirty:_,ctx:m}),jM.$set(uB);const KRe={};_&2&&(KRe.$$scope={dirty:_,ctx:m}),GM.$set(KRe);const ePe={};_&2&&(ePe.$$scope={dirty:_,ctx:m}),xE.$set(ePe);const oPe={};_&2&&(oPe.$$scope={dirty:_,ctx:m}),kE.$set(oPe);const pt={};_&2&&(pt.$$scope={dirty:_,ctx:m}),A4.$set(pt);const pB={};_&2&&(pB.$$scope={dirty:_,ctx:m}),y4.$set(pB);const rPe={};_&2&&(rPe.$$scope={dirty:_,ctx:m}),k4.$set(rPe);const _B={};_&2&&(_B.$$scope={dirty:_,ctx:m}),R4.$set(_B);const tPe={};_&2&&(tPe.$$scope={dirty:_,ctx:m}),q4.$set(tPe);const _t={};_&2&&(_t.$$scope={dirty:_,ctx:m}),D4.$set(_t);const aPe={};_&2&&(aPe.$$scope={dirty:_,ctx:m}),tC.$set(aPe);const kf={};_&2&&(kf.$$scope={dirty:_,ctx:m}),nC.$set(kf);const nPe={};_&2&&(nPe.$$scope={dirty:_,ctx:m}),iC.$set(nPe);const sPe={};_&2&&(sPe.$$scope={dirty:_,ctx:m}),cC.$set(sPe);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),gC.$set(L);const W8={};_&2&&(W8.$$scope={dirty:_,ctx:m}),uC.$set(W8);const lPe={};_&2&&(lPe.$$scope={dirty:_,ctx:m}),bC.$set(lPe);const iPe={};_&2&&(iPe.$$scope={dirty:_,ctx:m}),FC.$set(iPe);const U8={};_&2&&(U8.$$scope={dirty:_,ctx:m}),kC.$set(U8);const dPe={};_&2&&(dPe.$$scope={dirty:_,ctx:m}),RC.$set(dPe);const cPe={};_&2&&(cPe.$$scope={dirty:_,ctx:m}),DC.$set(cPe);const H8={};_&2&&(H8.$$scope={dirty:_,ctx:m}),OC.$set(H8);const mPe={};_&2&&(mPe.$$scope={dirty:_,ctx:m}),e3.$set(mPe);const fPe={};_&2&&(fPe.$$scope={dirty:_,ctx:m}),r3.$set(fPe);const J8={};_&2&&(J8.$$scope={dirty:_,ctx:m}),l3.$set(J8);const gPe={};_&2&&(gPe.$$scope={dirty:_,ctx:m}),d3.$set(gPe);const hPe={};_&2&&(hPe.$$scope={dirty:_,ctx:m}),p3.$set(hPe);const Y8={};_&2&&(Y8.$$scope={dirty:_,ctx:m}),b3.$set(Y8);const uPe={};_&2&&(uPe.$$scope={dirty:_,ctx:m}),C3.$set(uPe);const pPe={};_&2&&(pPe.$$scope={dirty:_,ctx:m}),A3.$set(pPe);const Z8={};_&2&&(Z8.$$scope={dirty:_,ctx:m}),S3.$set(Z8);const _Pe={};_&2&&(_Pe.$$scope={dirty:_,ctx:m}),P3.$set(_Pe);const bPe={};_&2&&(bPe.$$scope={dirty:_,ctx:m}),N3.$set(bPe);const K8={};_&2&&(K8.$$scope={dirty:_,ctx:m}),j3.$set(K8);const vPe={};_&2&&(vPe.$$scope={dirty:_,ctx:m}),Q3.$set(vPe);const FPe={};_&2&&(FPe.$$scope={dirty:_,ctx:m}),U3.$set(FPe);const ey={};_&2&&(ey.$$scope={dirty:_,ctx:m}),Y3.$set(ey);const TPe={};_&2&&(TPe.$$scope={dirty:_,ctx:m}),K3.$set(TPe);const MPe={};_&2&&(MPe.$$scope={dirty:_,ctx:m}),r5.$set(MPe);const oy={};_&2&&(oy.$$scope={dirty:_,ctx:m}),a5.$set(oy);const EPe={};_&2&&(EPe.$$scope={dirty:_,ctx:m}),l0.$set(EPe);const CPe={};_&2&&(CPe.$$scope={dirty:_,ctx:m}),d0.$set(CPe);const ry={};_&2&&(ry.$$scope={dirty:_,ctx:m}),R0.$set(ry);const wPe={};_&2&&(wPe.$$scope={dirty:_,ctx:m}),B0.$set(wPe);const APe={};_&2&&(APe.$$scope={dirty:_,ctx:m}),J0.$set(APe);const ty={};_&2&&(ty.$$scope={dirty:_,ctx:m}),Z0.$set(ty);const LPe={};_&2&&(LPe.$$scope={dirty:_,ctx:m}),iw.$set(LPe);const yPe={};_&2&&(yPe.$$scope={dirty:_,ctx:m}),cw.$set(yPe);const ay={};_&2&&(ay.$$scope={dirty:_,ctx:m}),hw.$set(ay);const xPe={};_&2&&(xPe.$$scope={dirty:_,ctx:m}),pw.$set(xPe);const $Pe={};_&2&&($Pe.$$scope={dirty:_,ctx:m}),Nw.$set($Pe);const ny={};_&2&&(ny.$$scope={dirty:_,ctx:m}),jw.$set(ny);const kPe={};_&2&&(kPe.$$scope={dirty:_,ctx:m}),Jw.$set(kPe);const SPe={};_&2&&(SPe.$$scope={dirty:_,ctx:m}),Zw.$set(SPe);const sy={};_&2&&(sy.$$scope={dirty:_,ctx:m}),AA.$set(sy);const RPe={};_&2&&(RPe.$$scope={dirty:_,ctx:m}),yA.$set(RPe);const PPe={};_&2&&(PPe.$$scope={dirty:_,ctx:m}),QA.$set(PPe);const ly={};_&2&&(ly.$$scope={dirty:_,ctx:m}),UA.$set(ly);const BPe={};_&2&&(BPe.$$scope={dirty:_,ctx:m}),YA.$set(BPe);const IPe={};_&2&&(IPe.$$scope={dirty:_,ctx:m}),KA.$set(IPe);const iy={};_&2&&(iy.$$scope={dirty:_,ctx:m}),o6.$set(iy);const NPe={};_&2&&(NPe.$$scope={dirty:_,ctx:m}),t6.$set(NPe);const qPe={};_&2&&(qPe.$$scope={dirty:_,ctx:m}),n6.$set(qPe);const dy={};_&2&&(dy.$$scope={dirty:_,ctx:m}),l6.$set(dy);const jPe={};_&2&&(jPe.$$scope={dirty:_,ctx:m}),x6.$set(jPe);const DPe={};_&2&&(DPe.$$scope={dirty:_,ctx:m}),k6.$set(DPe);const cy={};_&2&&(cy.$$scope={dirty:_,ctx:m}),K6.$set(cy);const GPe={};_&2&&(GPe.$$scope={dirty:_,ctx:m}),o7.$set(GPe);const OPe={};_&2&&(OPe.$$scope={dirty:_,ctx:m}),t7.$set(OPe);const my={};_&2&&(my.$$scope={dirty:_,ctx:m}),n7.$set(my);const VPe={};_&2&&(VPe.$$scope={dirty:_,ctx:m}),i7.$set(VPe);const XPe={};_&2&&(XPe.$$scope={dirty:_,ctx:m}),c7.$set(XPe);const fy={};_&2&&(fy.$$scope={dirty:_,ctx:m}),q7.$set(fy);const zPe={};_&2&&(zPe.$$scope={dirty:_,ctx:m}),D7.$set(zPe);const QPe={};_&2&&(QPe.$$scope={dirty:_,ctx:m}),Y7.$set(QPe);const gy={};_&2&&(gy.$$scope={dirty:_,ctx:m}),K7.$set(gy);const WPe={};_&2&&(WPe.$$scope={dirty:_,ctx:m}),gL.$set(WPe);const UPe={};_&2&&(UPe.$$scope={dirty:_,ctx:m}),uL.$set(UPe);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:m}),AL.$set(hy);const HPe={};_&2&&(HPe.$$scope={dirty:_,ctx:m}),yL.$set(HPe);const JPe={};_&2&&(JPe.$$scope={dirty:_,ctx:m}),jL.$set(JPe);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:m}),GL.$set(uy);const YPe={};_&2&&(YPe.$$scope={dirty:_,ctx:m}),ZL.$set(YPe);const ZPe={};_&2&&(ZPe.$$scope={dirty:_,ctx:m}),e8.$set(ZPe);const py={};_&2&&(py.$$scope={dirty:_,ctx:m}),m8.$set(py);const KPe={};_&2&&(KPe.$$scope={dirty:_,ctx:m}),g8.$set(KPe);const eBe={};_&2&&(eBe.$$scope={dirty:_,ctx:m}),M8.$set(eBe);const _y={};_&2&&(_y.$$scope={dirty:_,ctx:m}),C8.$set(_y);const oBe={};_&2&&(oBe.$$scope={dirty:_,ctx:m}),R8.$set(oBe);const rBe={};_&2&&(rBe.$$scope={dirty:_,ctx:m}),B8.$set(rBe);const by={};_&2&&(by.$$scope={dirty:_,ctx:m}),N8.$set(by);const tBe={};_&2&&(tBe.$$scope={dirty:_,ctx:m}),j8.$set(tBe);const aBe={};_&2&&(aBe.$$scope={dirty:_,ctx:m}),O8.$set(aBe);const vy={};_&2&&(vy.$$scope={dirty:_,ctx:m}),X8.$set(vy);const nBe={};_&2&&(nBe.$$scope={dirty:_,ctx:m}),Q8.$set(nBe)},i(m){jto||(E(d.$$.fragment,m),E(Ja.$$.fragment,m),E($x.$$.fragment,m),E(kx.$$.fragment,m),E(qf.$$.fragment,m),E(Sx.$$.fragment,m),E(Rx.$$.fragment,m),E(Ix.$$.fragment,m),E(mu.$$.fragment,m),E(Nx.$$.fragment,m),E(qx.$$.fragment,m),E(jx.$$.fragment,m),E(Ox.$$.fragment,m),E(Hu.$$.fragment,m),E(Vx.$$.fragment,m),E(Xx.$$.fragment,m),E(zx.$$.fragment,m),E(Ux.$$.fragment,m),E(Gp.$$.fragment,m),E(Op.$$.fragment,m),E(Hx.$$.fragment,m),E(Jx.$$.fragment,m),E(Yx.$$.fragment,m),E(e$.$$.fragment,m),E(h_.$$.fragment,m),E(u_.$$.fragment,m),E(o$.$$.fragment,m),E(r$.$$.fragment,m),E(t$.$$.fragment,m),E(n$.$$.fragment,m),E(b_.$$.fragment,m),E(s$.$$.fragment,m),E(q2.$$.fragment,m),E(l$.$$.fragment,m),E(i$.$$.fragment,m),E(c$.$$.fragment,m),E(D2.$$.fragment,m),E(m$.$$.fragment,m),E(Ib.$$.fragment,m),E(f$.$$.fragment,m),E(g$.$$.fragment,m),E(u$.$$.fragment,m),E(qb.$$.fragment,m),E(p$.$$.fragment,m),E(yv.$$.fragment,m),E(_$.$$.fragment,m),E(b$.$$.fragment,m),E(F$.$$.fragment,m),E($v.$$.fragment,m),E(T$.$$.fragment,m),E(_F.$$.fragment,m),E(M$.$$.fragment,m),E(E$.$$.fragment,m),E(w$.$$.fragment,m),E(vF.$$.fragment,m),E(A$.$$.fragment,m),E(GF.$$.fragment,m),E(L$.$$.fragment,m),E(y$.$$.fragment,m),E($$.$$.fragment,m),E(VF.$$.fragment,m),E(k$.$$.fragment,m),E(QT.$$.fragment,m),E(S$.$$.fragment,m),E(R$.$$.fragment,m),E(B$.$$.fragment,m),E(UT.$$.fragment,m),E(I$.$$.fragment,m),E(yM.$$.fragment,m),E(N$.$$.fragment,m),E(q$.$$.fragment,m),E(D$.$$.fragment,m),E($M.$$.fragment,m),E(G$.$$.fragment,m),E(jM.$$.fragment,m),E(O$.$$.fragment,m),E(V$.$$.fragment,m),E(z$.$$.fragment,m),E(GM.$$.fragment,m),E(Q$.$$.fragment,m),E(xE.$$.fragment,m),E(W$.$$.fragment,m),E(U$.$$.fragment,m),E(J$.$$.fragment,m),E(kE.$$.fragment,m),E(Y$.$$.fragment,m),E(A4.$$.fragment,m),E(Z$.$$.fragment,m),E(K$.$$.fragment,m),E(ok.$$.fragment,m),E(y4.$$.fragment,m),E(rk.$$.fragment,m),E(k4.$$.fragment,m),E(tk.$$.fragment,m),E(ak.$$.fragment,m),E(sk.$$.fragment,m),E(R4.$$.fragment,m),E(lk.$$.fragment,m),E(q4.$$.fragment,m),E(ik.$$.fragment,m),E(dk.$$.fragment,m),E(mk.$$.fragment,m),E(D4.$$.fragment,m),E(fk.$$.fragment,m),E(tC.$$.fragment,m),E(gk.$$.fragment,m),E(hk.$$.fragment,m),E(pk.$$.fragment,m),E(nC.$$.fragment,m),E(_k.$$.fragment,m),E(iC.$$.fragment,m),E(bk.$$.fragment,m),E(vk.$$.fragment,m),E(Tk.$$.fragment,m),E(cC.$$.fragment,m),E(Mk.$$.fragment,m),E(gC.$$.fragment,m),E(Ek.$$.fragment,m),E(Ck.$$.fragment,m),E(Ak.$$.fragment,m),E(uC.$$.fragment,m),E(Lk.$$.fragment,m),E(bC.$$.fragment,m),E(yk.$$.fragment,m),E(xk.$$.fragment,m),E(kk.$$.fragment,m),E(FC.$$.fragment,m),E(Sk.$$.fragment,m),E(kC.$$.fragment,m),E(Rk.$$.fragment,m),E(Pk.$$.fragment,m),E(Ik.$$.fragment,m),E(RC.$$.fragment,m),E(Nk.$$.fragment,m),E(DC.$$.fragment,m),E(qk.$$.fragment,m),E(jk.$$.fragment,m),E(Gk.$$.fragment,m),E(OC.$$.fragment,m),E(Ok.$$.fragment,m),E(e3.$$.fragment,m),E(Vk.$$.fragment,m),E(Xk.$$.fragment,m),E(Qk.$$.fragment,m),E(r3.$$.fragment,m),E(Wk.$$.fragment,m),E(l3.$$.fragment,m),E(Uk.$$.fragment,m),E(Hk.$$.fragment,m),E(Yk.$$.fragment,m),E(d3.$$.fragment,m),E(Zk.$$.fragment,m),E(p3.$$.fragment,m),E(Kk.$$.fragment,m),E(eS.$$.fragment,m),E(rS.$$.fragment,m),E(b3.$$.fragment,m),E(tS.$$.fragment,m),E(C3.$$.fragment,m),E(aS.$$.fragment,m),E(nS.$$.fragment,m),E(lS.$$.fragment,m),E(A3.$$.fragment,m),E(iS.$$.fragment,m),E(S3.$$.fragment,m),E(dS.$$.fragment,m),E(cS.$$.fragment,m),E(fS.$$.fragment,m),E(P3.$$.fragment,m),E(gS.$$.fragment,m),E(N3.$$.fragment,m),E(hS.$$.fragment,m),E(uS.$$.fragment,m),E(_S.$$.fragment,m),E(j3.$$.fragment,m),E(bS.$$.fragment,m),E(Q3.$$.fragment,m),E(vS.$$.fragment,m),E(FS.$$.fragment,m),E(MS.$$.fragment,m),E(U3.$$.fragment,m),E(ES.$$.fragment,m),E(Y3.$$.fragment,m),E(CS.$$.fragment,m),E(wS.$$.fragment,m),E(LS.$$.fragment,m),E(K3.$$.fragment,m),E(yS.$$.fragment,m),E(r5.$$.fragment,m),E(xS.$$.fragment,m),E($S.$$.fragment,m),E(SS.$$.fragment,m),E(a5.$$.fragment,m),E(RS.$$.fragment,m),E(l0.$$.fragment,m),E(PS.$$.fragment,m),E(BS.$$.fragment,m),E(NS.$$.fragment,m),E(d0.$$.fragment,m),E(qS.$$.fragment,m),E(R0.$$.fragment,m),E(jS.$$.fragment,m),E(DS.$$.fragment,m),E(OS.$$.fragment,m),E(B0.$$.fragment,m),E(VS.$$.fragment,m),E(J0.$$.fragment,m),E(XS.$$.fragment,m),E(zS.$$.fragment,m),E(WS.$$.fragment,m),E(Z0.$$.fragment,m),E(US.$$.fragment,m),E(iw.$$.fragment,m),E(HS.$$.fragment,m),E(JS.$$.fragment,m),E(ZS.$$.fragment,m),E(cw.$$.fragment,m),E(KS.$$.fragment,m),E(hw.$$.fragment,m),E(eR.$$.fragment,m),E(oR.$$.fragment,m),E(tR.$$.fragment,m),E(pw.$$.fragment,m),E(aR.$$.fragment,m),E(Nw.$$.fragment,m),E(nR.$$.fragment,m),E(sR.$$.fragment,m),E(iR.$$.fragment,m),E(jw.$$.fragment,m),E(dR.$$.fragment,m),E(Jw.$$.fragment,m),E(cR.$$.fragment,m),E(mR.$$.fragment,m),E(gR.$$.fragment,m),E(Zw.$$.fragment,m),E(hR.$$.fragment,m),E(AA.$$.fragment,m),E(uR.$$.fragment,m),E(pR.$$.fragment,m),E(bR.$$.fragment,m),E(yA.$$.fragment,m),E(vR.$$.fragment,m),E(QA.$$.fragment,m),E(FR.$$.fragment,m),E(TR.$$.fragment,m),E(ER.$$.fragment,m),E(UA.$$.fragment,m),E(CR.$$.fragment,m),E(YA.$$.fragment,m),E(AR.$$.fragment,m),E(LR.$$.fragment,m),E(xR.$$.fragment,m),E(KA.$$.fragment,m),E($R.$$.fragment,m),E(o6.$$.fragment,m),E(kR.$$.fragment,m),E(SR.$$.fragment,m),E(PR.$$.fragment,m),E(t6.$$.fragment,m),E(BR.$$.fragment,m),E(n6.$$.fragment,m),E(IR.$$.fragment,m),E(NR.$$.fragment,m),E(jR.$$.fragment,m),E(l6.$$.fragment,m),E(DR.$$.fragment,m),E(x6.$$.fragment,m),E(GR.$$.fragment,m),E(OR.$$.fragment,m),E(XR.$$.fragment,m),E(k6.$$.fragment,m),E(zR.$$.fragment,m),E(K6.$$.fragment,m),E(QR.$$.fragment,m),E(WR.$$.fragment,m),E(HR.$$.fragment,m),E(o7.$$.fragment,m),E(JR.$$.fragment,m),E(t7.$$.fragment,m),E(YR.$$.fragment,m),E(ZR.$$.fragment,m),E(eP.$$.fragment,m),E(n7.$$.fragment,m),E(oP.$$.fragment,m),E(i7.$$.fragment,m),E(tP.$$.fragment,m),E(aP.$$.fragment,m),E(sP.$$.fragment,m),E(c7.$$.fragment,m),E(lP.$$.fragment,m),E(q7.$$.fragment,m),E(iP.$$.fragment,m),E(dP.$$.fragment,m),E(mP.$$.fragment,m),E(D7.$$.fragment,m),E(fP.$$.fragment,m),E(Y7.$$.fragment,m),E(gP.$$.fragment,m),E(hP.$$.fragment,m),E(pP.$$.fragment,m),E(K7.$$.fragment,m),E(_P.$$.fragment,m),E(gL.$$.fragment,m),E(bP.$$.fragment,m),E(vP.$$.fragment,m),E(TP.$$.fragment,m),E(uL.$$.fragment,m),E(MP.$$.fragment,m),E(AL.$$.fragment,m),E(EP.$$.fragment,m),E(CP.$$.fragment,m),E(AP.$$.fragment,m),E(yL.$$.fragment,m),E(LP.$$.fragment,m),E(jL.$$.fragment,m),E(yP.$$.fragment,m),E(xP.$$.fragment,m),E(kP.$$.fragment,m),E(GL.$$.fragment,m),E(SP.$$.fragment,m),E(ZL.$$.fragment,m),E(RP.$$.fragment,m),E(PP.$$.fragment,m),E(IP.$$.fragment,m),E(e8.$$.fragment,m),E(NP.$$.fragment,m),E(m8.$$.fragment,m),E(qP.$$.fragment,m),E(jP.$$.fragment,m),E(GP.$$.fragment,m),E(g8.$$.fragment,m),E(OP.$$.fragment,m),E(M8.$$.fragment,m),E(VP.$$.fragment,m),E(XP.$$.fragment,m),E(QP.$$.fragment,m),E(C8.$$.fragment,m),E(WP.$$.fragment,m),E(R8.$$.fragment,m),E(UP.$$.fragment,m),E(HP.$$.fragment,m),E(YP.$$.fragment,m),E(B8.$$.fragment,m),E(ZP.$$.fragment,m),E(N8.$$.fragment,m),E(KP.$$.fragment,m),E(eB.$$.fragment,m),E(rB.$$.fragment,m),E(j8.$$.fragment,m),E(tB.$$.fragment,m),E(O8.$$.fragment,m),E(nB.$$.fragment,m),E(sB.$$.fragment,m),E(iB.$$.fragment,m),E(X8.$$.fragment,m),E(dB.$$.fragment,m),E(Q8.$$.fragment,m),jto=!0)},o(m){C(d.$$.fragment,m),C(Ja.$$.fragment,m),C($x.$$.fragment,m),C(kx.$$.fragment,m),C(qf.$$.fragment,m),C(Sx.$$.fragment,m),C(Rx.$$.fragment,m),C(Ix.$$.fragment,m),C(mu.$$.fragment,m),C(Nx.$$.fragment,m),C(qx.$$.fragment,m),C(jx.$$.fragment,m),C(Ox.$$.fragment,m),C(Hu.$$.fragment,m),C(Vx.$$.fragment,m),C(Xx.$$.fragment,m),C(zx.$$.fragment,m),C(Ux.$$.fragment,m),C(Gp.$$.fragment,m),C(Op.$$.fragment,m),C(Hx.$$.fragment,m),C(Jx.$$.fragment,m),C(Yx.$$.fragment,m),C(e$.$$.fragment,m),C(h_.$$.fragment,m),C(u_.$$.fragment,m),C(o$.$$.fragment,m),C(r$.$$.fragment,m),C(t$.$$.fragment,m),C(n$.$$.fragment,m),C(b_.$$.fragment,m),C(s$.$$.fragment,m),C(q2.$$.fragment,m),C(l$.$$.fragment,m),C(i$.$$.fragment,m),C(c$.$$.fragment,m),C(D2.$$.fragment,m),C(m$.$$.fragment,m),C(Ib.$$.fragment,m),C(f$.$$.fragment,m),C(g$.$$.fragment,m),C(u$.$$.fragment,m),C(qb.$$.fragment,m),C(p$.$$.fragment,m),C(yv.$$.fragment,m),C(_$.$$.fragment,m),C(b$.$$.fragment,m),C(F$.$$.fragment,m),C($v.$$.fragment,m),C(T$.$$.fragment,m),C(_F.$$.fragment,m),C(M$.$$.fragment,m),C(E$.$$.fragment,m),C(w$.$$.fragment,m),C(vF.$$.fragment,m),C(A$.$$.fragment,m),C(GF.$$.fragment,m),C(L$.$$.fragment,m),C(y$.$$.fragment,m),C($$.$$.fragment,m),C(VF.$$.fragment,m),C(k$.$$.fragment,m),C(QT.$$.fragment,m),C(S$.$$.fragment,m),C(R$.$$.fragment,m),C(B$.$$.fragment,m),C(UT.$$.fragment,m),C(I$.$$.fragment,m),C(yM.$$.fragment,m),C(N$.$$.fragment,m),C(q$.$$.fragment,m),C(D$.$$.fragment,m),C($M.$$.fragment,m),C(G$.$$.fragment,m),C(jM.$$.fragment,m),C(O$.$$.fragment,m),C(V$.$$.fragment,m),C(z$.$$.fragment,m),C(GM.$$.fragment,m),C(Q$.$$.fragment,m),C(xE.$$.fragment,m),C(W$.$$.fragment,m),C(U$.$$.fragment,m),C(J$.$$.fragment,m),C(kE.$$.fragment,m),C(Y$.$$.fragment,m),C(A4.$$.fragment,m),C(Z$.$$.fragment,m),C(K$.$$.fragment,m),C(ok.$$.fragment,m),C(y4.$$.fragment,m),C(rk.$$.fragment,m),C(k4.$$.fragment,m),C(tk.$$.fragment,m),C(ak.$$.fragment,m),C(sk.$$.fragment,m),C(R4.$$.fragment,m),C(lk.$$.fragment,m),C(q4.$$.fragment,m),C(ik.$$.fragment,m),C(dk.$$.fragment,m),C(mk.$$.fragment,m),C(D4.$$.fragment,m),C(fk.$$.fragment,m),C(tC.$$.fragment,m),C(gk.$$.fragment,m),C(hk.$$.fragment,m),C(pk.$$.fragment,m),C(nC.$$.fragment,m),C(_k.$$.fragment,m),C(iC.$$.fragment,m),C(bk.$$.fragment,m),C(vk.$$.fragment,m),C(Tk.$$.fragment,m),C(cC.$$.fragment,m),C(Mk.$$.fragment,m),C(gC.$$.fragment,m),C(Ek.$$.fragment,m),C(Ck.$$.fragment,m),C(Ak.$$.fragment,m),C(uC.$$.fragment,m),C(Lk.$$.fragment,m),C(bC.$$.fragment,m),C(yk.$$.fragment,m),C(xk.$$.fragment,m),C(kk.$$.fragment,m),C(FC.$$.fragment,m),C(Sk.$$.fragment,m),C(kC.$$.fragment,m),C(Rk.$$.fragment,m),C(Pk.$$.fragment,m),C(Ik.$$.fragment,m),C(RC.$$.fragment,m),C(Nk.$$.fragment,m),C(DC.$$.fragment,m),C(qk.$$.fragment,m),C(jk.$$.fragment,m),C(Gk.$$.fragment,m),C(OC.$$.fragment,m),C(Ok.$$.fragment,m),C(e3.$$.fragment,m),C(Vk.$$.fragment,m),C(Xk.$$.fragment,m),C(Qk.$$.fragment,m),C(r3.$$.fragment,m),C(Wk.$$.fragment,m),C(l3.$$.fragment,m),C(Uk.$$.fragment,m),C(Hk.$$.fragment,m),C(Yk.$$.fragment,m),C(d3.$$.fragment,m),C(Zk.$$.fragment,m),C(p3.$$.fragment,m),C(Kk.$$.fragment,m),C(eS.$$.fragment,m),C(rS.$$.fragment,m),C(b3.$$.fragment,m),C(tS.$$.fragment,m),C(C3.$$.fragment,m),C(aS.$$.fragment,m),C(nS.$$.fragment,m),C(lS.$$.fragment,m),C(A3.$$.fragment,m),C(iS.$$.fragment,m),C(S3.$$.fragment,m),C(dS.$$.fragment,m),C(cS.$$.fragment,m),C(fS.$$.fragment,m),C(P3.$$.fragment,m),C(gS.$$.fragment,m),C(N3.$$.fragment,m),C(hS.$$.fragment,m),C(uS.$$.fragment,m),C(_S.$$.fragment,m),C(j3.$$.fragment,m),C(bS.$$.fragment,m),C(Q3.$$.fragment,m),C(vS.$$.fragment,m),C(FS.$$.fragment,m),C(MS.$$.fragment,m),C(U3.$$.fragment,m),C(ES.$$.fragment,m),C(Y3.$$.fragment,m),C(CS.$$.fragment,m),C(wS.$$.fragment,m),C(LS.$$.fragment,m),C(K3.$$.fragment,m),C(yS.$$.fragment,m),C(r5.$$.fragment,m),C(xS.$$.fragment,m),C($S.$$.fragment,m),C(SS.$$.fragment,m),C(a5.$$.fragment,m),C(RS.$$.fragment,m),C(l0.$$.fragment,m),C(PS.$$.fragment,m),C(BS.$$.fragment,m),C(NS.$$.fragment,m),C(d0.$$.fragment,m),C(qS.$$.fragment,m),C(R0.$$.fragment,m),C(jS.$$.fragment,m),C(DS.$$.fragment,m),C(OS.$$.fragment,m),C(B0.$$.fragment,m),C(VS.$$.fragment,m),C(J0.$$.fragment,m),C(XS.$$.fragment,m),C(zS.$$.fragment,m),C(WS.$$.fragment,m),C(Z0.$$.fragment,m),C(US.$$.fragment,m),C(iw.$$.fragment,m),C(HS.$$.fragment,m),C(JS.$$.fragment,m),C(ZS.$$.fragment,m),C(cw.$$.fragment,m),C(KS.$$.fragment,m),C(hw.$$.fragment,m),C(eR.$$.fragment,m),C(oR.$$.fragment,m),C(tR.$$.fragment,m),C(pw.$$.fragment,m),C(aR.$$.fragment,m),C(Nw.$$.fragment,m),C(nR.$$.fragment,m),C(sR.$$.fragment,m),C(iR.$$.fragment,m),C(jw.$$.fragment,m),C(dR.$$.fragment,m),C(Jw.$$.fragment,m),C(cR.$$.fragment,m),C(mR.$$.fragment,m),C(gR.$$.fragment,m),C(Zw.$$.fragment,m),C(hR.$$.fragment,m),C(AA.$$.fragment,m),C(uR.$$.fragment,m),C(pR.$$.fragment,m),C(bR.$$.fragment,m),C(yA.$$.fragment,m),C(vR.$$.fragment,m),C(QA.$$.fragment,m),C(FR.$$.fragment,m),C(TR.$$.fragment,m),C(ER.$$.fragment,m),C(UA.$$.fragment,m),C(CR.$$.fragment,m),C(YA.$$.fragment,m),C(AR.$$.fragment,m),C(LR.$$.fragment,m),C(xR.$$.fragment,m),C(KA.$$.fragment,m),C($R.$$.fragment,m),C(o6.$$.fragment,m),C(kR.$$.fragment,m),C(SR.$$.fragment,m),C(PR.$$.fragment,m),C(t6.$$.fragment,m),C(BR.$$.fragment,m),C(n6.$$.fragment,m),C(IR.$$.fragment,m),C(NR.$$.fragment,m),C(jR.$$.fragment,m),C(l6.$$.fragment,m),C(DR.$$.fragment,m),C(x6.$$.fragment,m),C(GR.$$.fragment,m),C(OR.$$.fragment,m),C(XR.$$.fragment,m),C(k6.$$.fragment,m),C(zR.$$.fragment,m),C(K6.$$.fragment,m),C(QR.$$.fragment,m),C(WR.$$.fragment,m),C(HR.$$.fragment,m),C(o7.$$.fragment,m),C(JR.$$.fragment,m),C(t7.$$.fragment,m),C(YR.$$.fragment,m),C(ZR.$$.fragment,m),C(eP.$$.fragment,m),C(n7.$$.fragment,m),C(oP.$$.fragment,m),C(i7.$$.fragment,m),C(tP.$$.fragment,m),C(aP.$$.fragment,m),C(sP.$$.fragment,m),C(c7.$$.fragment,m),C(lP.$$.fragment,m),C(q7.$$.fragment,m),C(iP.$$.fragment,m),C(dP.$$.fragment,m),C(mP.$$.fragment,m),C(D7.$$.fragment,m),C(fP.$$.fragment,m),C(Y7.$$.fragment,m),C(gP.$$.fragment,m),C(hP.$$.fragment,m),C(pP.$$.fragment,m),C(K7.$$.fragment,m),C(_P.$$.fragment,m),C(gL.$$.fragment,m),C(bP.$$.fragment,m),C(vP.$$.fragment,m),C(TP.$$.fragment,m),C(uL.$$.fragment,m),C(MP.$$.fragment,m),C(AL.$$.fragment,m),C(EP.$$.fragment,m),C(CP.$$.fragment,m),C(AP.$$.fragment,m),C(yL.$$.fragment,m),C(LP.$$.fragment,m),C(jL.$$.fragment,m),C(yP.$$.fragment,m),C(xP.$$.fragment,m),C(kP.$$.fragment,m),C(GL.$$.fragment,m),C(SP.$$.fragment,m),C(ZL.$$.fragment,m),C(RP.$$.fragment,m),C(PP.$$.fragment,m),C(IP.$$.fragment,m),C(e8.$$.fragment,m),C(NP.$$.fragment,m),C(m8.$$.fragment,m),C(qP.$$.fragment,m),C(jP.$$.fragment,m),C(GP.$$.fragment,m),C(g8.$$.fragment,m),C(OP.$$.fragment,m),C(M8.$$.fragment,m),C(VP.$$.fragment,m),C(XP.$$.fragment,m),C(QP.$$.fragment,m),C(C8.$$.fragment,m),C(WP.$$.fragment,m),C(R8.$$.fragment,m),C(UP.$$.fragment,m),C(HP.$$.fragment,m),C(YP.$$.fragment,m),C(B8.$$.fragment,m),C(ZP.$$.fragment,m),C(N8.$$.fragment,m),C(KP.$$.fragment,m),C(eB.$$.fragment,m),C(rB.$$.fragment,m),C(j8.$$.fragment,m),C(tB.$$.fragment,m),C(O8.$$.fragment,m),C(nB.$$.fragment,m),C(sB.$$.fragment,m),C(iB.$$.fragment,m),C(X8.$$.fragment,m),C(dB.$$.fragment,m),C(Q8.$$.fragment,m),jto=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Rf),m&&t(bt),m&&t(Xe),m&&t(He),m&&t(Bf),w(Ja,m),m&&t(Je),m&&t(Ae),m&&t($o),m&&t(Ya),m&&t(Coo),m&&t(pd),w($x),m&&t(woo),m&&t(ds),m&&t(Aoo),w(kx,m),m&&t(Loo),m&&t(DI),m&&t(yoo),w(qf,m),m&&t(xoo),m&&t(_d),w(Sx),m&&t($oo),m&&t(ko),w(Rx),w(Ix),w(mu),w(Nx),m&&t(koo),m&&t(vd),w(qx),m&&t(Soo),m&&t(So),w(jx),w(Ox),w(Hu),w(Vx),m&&t(Roo),m&&t(Fd),w(Xx),m&&t(Poo),m&&t(Ro),w(zx),w(Ux),w(Gp),w(Op),w(Hx),m&&t(Boo),m&&t(Td),w(Jx),m&&t(Ioo),m&&t(Po),w(Yx),w(e$),w(h_),w(u_),w(o$),m&&t(Noo),m&&t(Ed),w(r$),m&&t(qoo),m&&t(Bo),w(t$),w(n$),w(b_),w(s$),w(q2),m&&t(joo),m&&t(Ad),w(l$),m&&t(Doo),m&&t(Io),w(i$),w(c$),w(D2),w(m$),w(Ib),m&&t(Goo),m&&t(xd),w(f$),m&&t(Ooo),m&&t(No),w(g$),w(u$),w(qb),w(p$),w(yv),m&&t(Voo),m&&t(Sd),w(_$),m&&t(Xoo),m&&t(qo),w(b$),w(F$),w($v),w(T$),w(_F),m&&t(zoo),m&&t(Bd),w(M$),m&&t(Qoo),m&&t(jo),w(E$),w(w$),w(vF),w(A$),w(GF),m&&t(Woo),m&&t(qd),w(L$),m&&t(Uoo),m&&t(Do),w(y$),w($$),w(VF),w(k$),w(QT),m&&t(Hoo),m&&t(Gd),w(S$),m&&t(Joo),m&&t(Go),w(R$),w(B$),w(UT),w(I$),w(yM),m&&t(Yoo),m&&t(Xd),w(N$),m&&t(Zoo),m&&t(Oo),w(q$),w(D$),w($M),w(G$),w(jM),m&&t(Koo),m&&t(Wd),w(O$),m&&t(ero),m&&t(Vo),w(V$),w(z$),w(GM),w(Q$),w(xE),m&&t(oro),m&&t(Jd),w(W$),m&&t(rro),m&&t(Xo),w(U$),w(J$),w(kE),w(Y$),w(A4),m&&t(tro),m&&t(Kd),w(Z$),m&&t(aro),m&&t(zo),w(K$),w(ok),w(y4),w(rk),w(k4),m&&t(nro),m&&t(rc),w(tk),m&&t(sro),m&&t(Qo),w(ak),w(sk),w(R4),w(lk),w(q4),m&&t(lro),m&&t(sc),w(ik),m&&t(iro),m&&t(Wo),w(dk),w(mk),w(D4),w(fk),w(tC),m&&t(dro),m&&t(dc),w(gk),m&&t(cro),m&&t(Uo),w(hk),w(pk),w(nC),w(_k),w(iC),m&&t(mro),m&&t(fc),w(bk),m&&t(fro),m&&t(Ho),w(vk),w(Tk),w(cC),w(Mk),w(gC),m&&t(gro),m&&t(uc),w(Ek),m&&t(hro),m&&t(Jo),w(Ck),w(Ak),w(uC),w(Lk),w(bC),m&&t(uro),m&&t(bc),w(yk),m&&t(pro),m&&t(Yo),w(xk),w(kk),w(FC),w(Sk),w(kC),m&&t(_ro),m&&t(Tc),w(Rk),m&&t(bro),m&&t(Zo),w(Pk),w(Ik),w(RC),w(Nk),w(DC),m&&t(vro),m&&t(Cc),w(qk),m&&t(Fro),m&&t(Ko),w(jk),w(Gk),w(OC),w(Ok),w(e3),m&&t(Tro),m&&t(Lc),w(Vk),m&&t(Mro),m&&t(er),w(Xk),w(Qk),w(r3),w(Wk),w(l3),m&&t(Ero),m&&t(kc),w(Uk),m&&t(Cro),m&&t(or),w(Hk),w(Yk),w(d3),w(Zk),w(p3),m&&t(wro),m&&t(Pc),w(Kk),m&&t(Aro),m&&t(rr),w(eS),w(rS),w(b3),w(tS),w(C3),m&&t(Lro),m&&t(Nc),w(aS),m&&t(yro),m&&t(tr),w(nS),w(lS),w(A3),w(iS),w(S3),m&&t(xro),m&&t(Dc),w(dS),m&&t($ro),m&&t(ar),w(cS),w(fS),w(P3),w(gS),w(N3),m&&t(kro),m&&t(Vc),w(hS),m&&t(Sro),m&&t(nr),w(uS),w(_S),w(j3),w(bS),w(Q3),m&&t(Rro),m&&t(Qc),w(vS),m&&t(Pro),m&&t(sr),w(FS),w(MS),w(U3),w(ES),w(Y3),m&&t(Bro),m&&t(Hc),w(CS),m&&t(Iro),m&&t(lr),w(wS),w(LS),w(K3),w(yS),w(r5),m&&t(Nro),m&&t(Zc),w(xS),m&&t(qro),m&&t(ir),w($S),w(SS),w(a5),w(RS),w(l0),m&&t(jro),m&&t(om),w(PS),m&&t(Dro),m&&t(dr),w(BS),w(NS),w(d0),w(qS),w(R0),m&&t(Gro),m&&t(am),w(jS),m&&t(Oro),m&&t(cr),w(DS),w(OS),w(B0),w(VS),w(J0),m&&t(Vro),m&&t(lm),w(XS),m&&t(Xro),m&&t(mr),w(zS),w(WS),w(Z0),w(US),w(iw),m&&t(zro),m&&t(cm),w(HS),m&&t(Qro),m&&t(fr),w(JS),w(ZS),w(cw),w(KS),w(hw),m&&t(Wro),m&&t(hm),w(eR),m&&t(Uro),m&&t(gr),w(oR),w(tR),w(pw),w(aR),w(Nw),m&&t(Hro),m&&t(_m),w(nR),m&&t(Jro),m&&t(hr),w(sR),w(iR),w(jw),w(dR),w(Jw),m&&t(Yro),m&&t(Fm),w(cR),m&&t(Zro),m&&t(ur),w(mR),w(gR),w(Zw),w(hR),w(AA),m&&t(Kro),m&&t(Em),w(uR),m&&t(eto),m&&t(pr),w(pR),w(bR),w(yA),w(vR),w(QA),m&&t(oto),m&&t(Am),w(FR),m&&t(rto),m&&t(_r),w(TR),w(ER),w(UA),w(CR),w(YA),m&&t(tto),m&&t(xm),w(AR),m&&t(ato),m&&t(br),w(LR),w(xR),w(KA),w($R),w(o6),m&&t(nto),m&&t(Sm),w(kR),m&&t(sto),m&&t(vr),w(SR),w(PR),w(t6),w(BR),w(n6),m&&t(lto),m&&t(Bm),w(IR),m&&t(ito),m&&t(Fr),w(NR),w(jR),w(l6),w(DR),w(x6),m&&t(dto),m&&t(qm),w(GR),m&&t(cto),m&&t(Tr),w(OR),w(XR),w(k6),w(zR),w(K6),m&&t(mto),m&&t(Gm),w(QR),m&&t(fto),m&&t(Mr),w(WR),w(HR),w(o7),w(JR),w(t7),m&&t(gto),m&&t(Xm),w(YR),m&&t(hto),m&&t(Er),w(ZR),w(eP),w(n7),w(oP),w(i7),m&&t(uto),m&&t(Wm),w(tP),m&&t(pto),m&&t(Cr),w(aP),w(sP),w(c7),w(lP),w(q7),m&&t(_to),m&&t(Jm),w(iP),m&&t(bto),m&&t(wr),w(dP),w(mP),w(D7),w(fP),w(Y7),m&&t(vto),m&&t(Km),w(gP),m&&t(Fto),m&&t(Ar),w(hP),w(pP),w(K7),w(_P),w(gL),m&&t(Tto),m&&t(rf),w(bP),m&&t(Mto),m&&t(Lr),w(vP),w(TP),w(uL),w(MP),w(AL),m&&t(Eto),m&&t(nf),w(EP),m&&t(Cto),m&&t(yr),w(CP),w(AP),w(yL),w(LP),w(jL),m&&t(wto),m&&t(df),w(yP),m&&t(Ato),m&&t(xr),w(xP),w(kP),w(GL),w(SP),w(ZL),m&&t(Lto),m&&t(ff),w(RP),m&&t(yto),m&&t($r),w(PP),w(IP),w(e8),w(NP),w(m8),m&&t(xto),m&&t(uf),w(qP),m&&t($to),m&&t(kr),w(jP),w(GP),w(g8),w(OP),w(M8),m&&t(kto),m&&t(bf),w(VP),m&&t(Sto),m&&t(Sr),w(XP),w(QP),w(C8),w(WP),w(R8),m&&t(Rto),m&&t(Tf),w(UP),m&&t(Pto),m&&t(Rr),w(HP),w(YP),w(B8),w(ZP),w(N8),m&&t(Bto),m&&t(Cf),w(KP),m&&t(Ito),m&&t(Pr),w(eB),w(rB),w(j8),w(tB),w(O8),m&&t(Nto),m&&t(Lf),w(nB),m&&t(qto),m&&t(Br),w(sB),w(iB),w(X8),w(dB),w(Q8)}}}const pEa={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function _Ea($){return nTa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class CEa extends oTa{constructor(g){super();rTa(this,g,_Ea,uEa,tTa,{})}}export{CEa as default,pEa as metadata};
