import{S as y4a,i as x4a,s as $4a,e as a,k as l,w as F,t as o,M as k4a,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as S4a,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as mwt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as I}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function R4a($){let g,v,u,f,p,d,h,$o,pd,Vf,Ft,_d,bd,Jx,Xf,Xe,He,vd,cs,Yx,ms,fs,Zx,Fd,gs,Kx,Td,zf,en;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),pd=a("code"),Vf=o("model_type"),Ft=o(" attribute is set to the same key you use when registering the config (here "),_d=a("code"),bd=o('"new-model"'),Jx=o(")."),Xf=l(),Xe=a("p"),He=o("Likewise, if your "),vd=a("code"),cs=o("NewModel"),Yx=o(" is a subclass of "),ms=a("a"),fs=o("PreTrainedModel"),Zx=o(`, make sure its
`),Fd=a("code"),gs=o("config_class"),Kx=o(` attribute is set to the same class you use when registering the model (here
`),Td=a("code"),zf=o("NewModelConfig"),en=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var fN=s(u);f=r(fN,"NewModelConfig"),fN.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Md=s(d);h=r(Md,"~transformer.PretrainedConfig"),Md.forEach(t),$o=r(Ae,`, make sure its
`),pd=n(Ae,"CODE",{});var gN=s(pd);Vf=r(gN,"model_type"),gN.forEach(t),Ft=r(Ae," attribute is set to the same key you use when registering the config (here "),_d=n(Ae,"CODE",{});var hN=s(_d);bd=r(hN,'"new-model"'),hN.forEach(t),Jx=r(Ae,")."),Ae.forEach(t),Xf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),vd=n(ko,"CODE",{});var on=s(vd);cs=r(on,"NewModel"),on.forEach(t),Yx=r(ko," is a subclass of "),ms=n(ko,"A",{href:!0});var uN=s(ms);fs=r(uN,"PreTrainedModel"),uN.forEach(t),Zx=r(ko,`, make sure its
`),Fd=n(ko,"CODE",{});var Qf=s(Fd);gs=r(Qf,"config_class"),Qf.forEach(t),Kx=r(ko,` attribute is set to the same class you use when registering the model (here
`),Td=n(ko,"CODE",{});var pN=s(Td);zf=r(pN,"NewModelConfig"),pN.forEach(t),en=r(ko,")."),ko.forEach(t),this.h()},h(){c(ms,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,pd),e(pd,Vf),e(g,Ft),e(g,_d),e(_d,bd),e(g,Jx),b(Je,Xf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,vd),e(vd,cs),e(Xe,Yx),e(Xe,ms),e(ms,fs),e(Xe,Zx),e(Xe,Fd),e(Fd,gs),e(Xe,Kx),e(Xe,Td),e(Td,zf),e(Xe,en)},d(Je){Je&&t(g),Je&&t(Xf),Je&&t(Xe)}}}function P4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I4a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function N4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q4a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function j4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K4a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _Ca($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function FCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function TCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function MCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ECa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function CCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ACa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function LCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $Ca($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function SCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function RCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function PCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function BCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ICa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function NCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function DCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function GCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function OCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function VCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function XCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function zCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function QCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function WCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function UCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function HCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function JCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function YCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ZCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function KCa($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V3a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X3a($){let g,v,u,f,p,d,h,$o,pd,Vf,Ft,_d,bd,Jx,Xf,Xe,He,vd,cs,Yx,ms,fs,Zx,Fd,gs,Kx,Td,zf,en,Je,Ae,fN,Md,gN,hN,ko,on,uN,Qf,pN,Llo,Oro,Ed,Wf,zme,e$,ylo,Qme,xlo,Vro,hs,$lo,Wme,klo,Slo,Ume,Rlo,Plo,Xro,o$,zro,_N,Blo,Qro,Uf,Wro,Cd,Hf,Hme,r$,Ilo,Jme,Nlo,Uro,So,t$,qlo,a$,jlo,bN,Dlo,Glo,Olo,n$,Vlo,Yme,Xlo,zlo,Qlo,qr,s$,Wlo,Zme,Ulo,Hlo,wd,Jlo,Kme,Ylo,Zlo,efe,Klo,eio,oio,A,Jf,ofe,rio,tio,vN,aio,nio,sio,Yf,rfe,lio,iio,FN,dio,cio,mio,Zf,tfe,fio,gio,TN,hio,uio,pio,Kf,afe,_io,bio,MN,vio,Fio,Tio,eg,nfe,Mio,Eio,EN,Cio,wio,Aio,og,sfe,Lio,yio,CN,xio,$io,kio,rg,lfe,Sio,Rio,wN,Pio,Bio,Iio,tg,ife,Nio,qio,AN,jio,Dio,Gio,ag,dfe,Oio,Vio,LN,Xio,zio,Qio,ng,cfe,Wio,Uio,yN,Hio,Jio,Yio,sg,mfe,Zio,Kio,xN,edo,odo,rdo,lg,ffe,tdo,ado,$N,ndo,sdo,ldo,ig,gfe,ido,ddo,kN,cdo,mdo,fdo,dg,hfe,gdo,hdo,SN,udo,pdo,_do,cg,ufe,bdo,vdo,RN,Fdo,Tdo,Mdo,mg,pfe,Edo,Cdo,PN,wdo,Ado,Ldo,fg,_fe,ydo,xdo,BN,$do,kdo,Sdo,gg,bfe,Rdo,Pdo,IN,Bdo,Ido,Ndo,hg,vfe,qdo,jdo,NN,Ddo,Gdo,Odo,ug,Ffe,Vdo,Xdo,qN,zdo,Qdo,Wdo,pg,Tfe,Udo,Hdo,jN,Jdo,Ydo,Zdo,_g,Mfe,Kdo,eco,DN,oco,rco,tco,bg,Efe,aco,nco,GN,sco,lco,ico,vg,Cfe,dco,cco,ON,mco,fco,gco,Fg,wfe,hco,uco,VN,pco,_co,bco,Tg,Afe,vco,Fco,XN,Tco,Mco,Eco,Mg,Lfe,Cco,wco,zN,Aco,Lco,yco,Eg,yfe,xco,$co,QN,kco,Sco,Rco,Cg,xfe,Pco,Bco,WN,Ico,Nco,qco,wg,$fe,jco,Dco,UN,Gco,Oco,Vco,Ag,kfe,Xco,zco,HN,Qco,Wco,Uco,Lg,Sfe,Hco,Jco,JN,Yco,Zco,Kco,yg,Rfe,emo,omo,YN,rmo,tmo,amo,xg,Pfe,nmo,smo,ZN,lmo,imo,dmo,$g,Bfe,cmo,mmo,KN,fmo,gmo,hmo,kg,Ife,umo,pmo,eq,_mo,bmo,vmo,Sg,Nfe,Fmo,Tmo,oq,Mmo,Emo,Cmo,Rg,qfe,wmo,Amo,rq,Lmo,ymo,xmo,Pg,jfe,$mo,kmo,tq,Smo,Rmo,Pmo,Bg,Dfe,Bmo,Imo,aq,Nmo,qmo,jmo,Ig,Gfe,Dmo,Gmo,nq,Omo,Vmo,Xmo,Ng,Ofe,zmo,Qmo,sq,Wmo,Umo,Hmo,qg,Vfe,Jmo,Ymo,lq,Zmo,Kmo,efo,jg,Xfe,ofo,rfo,iq,tfo,afo,nfo,Dg,zfe,sfo,lfo,dq,ifo,dfo,cfo,Gg,Qfe,mfo,ffo,cq,gfo,hfo,ufo,Og,Wfe,pfo,_fo,mq,bfo,vfo,Ffo,Vg,Ufe,Tfo,Mfo,fq,Efo,Cfo,wfo,Xg,Hfe,Afo,Lfo,gq,yfo,xfo,$fo,zg,Jfe,kfo,Sfo,hq,Rfo,Pfo,Bfo,Qg,Yfe,Ifo,Nfo,uq,qfo,jfo,Dfo,Wg,Zfe,Gfo,Ofo,pq,Vfo,Xfo,zfo,Ug,Kfe,Qfo,Wfo,_q,Ufo,Hfo,Jfo,Hg,ege,Yfo,Zfo,bq,Kfo,ego,ogo,Jg,oge,rgo,tgo,vq,ago,ngo,sgo,Yg,rge,lgo,igo,Fq,dgo,cgo,mgo,Zg,tge,fgo,ggo,Tq,hgo,ugo,pgo,Kg,age,_go,bgo,Mq,vgo,Fgo,Tgo,eh,nge,Mgo,Ego,Eq,Cgo,wgo,Ago,oh,sge,Lgo,ygo,Cq,xgo,$go,kgo,rh,lge,Sgo,Rgo,wq,Pgo,Bgo,Igo,th,ige,Ngo,qgo,Aq,jgo,Dgo,Ggo,ah,dge,Ogo,Vgo,Lq,Xgo,zgo,Qgo,nh,cge,Wgo,Ugo,yq,Hgo,Jgo,Ygo,sh,mge,Zgo,Kgo,xq,eho,oho,rho,lh,fge,tho,aho,$q,nho,sho,lho,ih,gge,iho,dho,kq,cho,mho,fho,dh,hge,gho,hho,Sq,uho,pho,_ho,ch,uge,bho,vho,Rq,Fho,Tho,Mho,mh,pge,Eho,Cho,Pq,who,Aho,Lho,fh,_ge,yho,xho,Bq,$ho,kho,Sho,gh,bge,Rho,Pho,Iq,Bho,Iho,Nho,hh,vge,qho,jho,Nq,Dho,Gho,Oho,uh,Fge,Vho,Xho,qq,zho,Qho,Who,ph,Tge,Uho,Hho,jq,Jho,Yho,Zho,_h,Mge,Kho,euo,Dq,ouo,ruo,tuo,bh,Ege,auo,nuo,Gq,suo,luo,iuo,vh,Cge,duo,cuo,Oq,muo,fuo,guo,Fh,wge,huo,uuo,Vq,puo,_uo,buo,Th,Age,vuo,Fuo,Xq,Tuo,Muo,Euo,Mh,Lge,Cuo,wuo,zq,Auo,Luo,yuo,Eh,yge,xuo,$uo,Qq,kuo,Suo,Ruo,Ch,xge,Puo,Buo,Wq,Iuo,Nuo,quo,wh,$ge,juo,Duo,Uq,Guo,Ouo,Vuo,Ah,kge,Xuo,zuo,Hq,Quo,Wuo,Uuo,Lh,Sge,Huo,Juo,Jq,Yuo,Zuo,Kuo,yh,Rge,epo,opo,Yq,rpo,tpo,apo,xh,Pge,npo,spo,Zq,lpo,ipo,dpo,$h,Bge,cpo,mpo,Kq,fpo,gpo,hpo,kh,Ige,upo,ppo,ej,_po,bpo,vpo,Sh,Nge,Fpo,Tpo,oj,Mpo,Epo,Cpo,Rh,qge,wpo,Apo,rj,Lpo,ypo,xpo,Ph,jge,$po,kpo,tj,Spo,Rpo,Ppo,Bh,Dge,Bpo,Ipo,aj,Npo,qpo,jpo,Ih,Gge,Dpo,Gpo,nj,Opo,Vpo,Xpo,Nh,Oge,zpo,Qpo,sj,Wpo,Upo,Hpo,qh,Vge,Jpo,Ypo,lj,Zpo,Kpo,e_o,jh,Xge,o_o,r_o,ij,t_o,a_o,n_o,Dh,zge,s_o,l_o,dj,i_o,d_o,c_o,Gh,Qge,m_o,f_o,cj,g_o,h_o,u_o,Oh,Wge,p_o,__o,mj,b_o,v_o,F_o,Vh,Uge,T_o,M_o,fj,E_o,C_o,w_o,Xh,Hge,A_o,L_o,gj,y_o,x_o,$_o,zh,Jge,k_o,S_o,hj,R_o,P_o,B_o,Qh,Yge,I_o,N_o,uj,q_o,j_o,D_o,Wh,Zge,G_o,O_o,pj,V_o,X_o,z_o,Uh,Kge,Q_o,W_o,_j,U_o,H_o,J_o,Hh,ehe,Y_o,Z_o,bj,K_o,e1o,o1o,Jh,ohe,r1o,t1o,vj,a1o,n1o,s1o,Yh,rhe,l1o,i1o,Fj,d1o,c1o,m1o,Zh,the,f1o,g1o,Tj,h1o,u1o,p1o,Kh,ahe,_1o,b1o,Mj,v1o,F1o,T1o,eu,nhe,M1o,E1o,Ej,C1o,w1o,A1o,ou,she,L1o,y1o,Cj,x1o,$1o,k1o,ru,lhe,S1o,R1o,wj,P1o,B1o,I1o,tu,ihe,N1o,q1o,Aj,j1o,D1o,G1o,au,dhe,O1o,V1o,Lj,X1o,z1o,Q1o,nu,che,W1o,U1o,yj,H1o,J1o,Y1o,su,mhe,Z1o,K1o,xj,e2o,o2o,r2o,lu,fhe,t2o,a2o,$j,n2o,s2o,l2o,iu,ghe,i2o,d2o,kj,c2o,m2o,f2o,du,hhe,g2o,h2o,Sj,u2o,p2o,_2o,cu,uhe,b2o,v2o,Rj,F2o,T2o,M2o,mu,phe,E2o,C2o,Pj,w2o,A2o,L2o,fu,_he,y2o,x2o,Bj,$2o,k2o,S2o,gu,bhe,R2o,P2o,Ij,B2o,I2o,N2o,hu,vhe,q2o,j2o,Nj,D2o,G2o,O2o,uu,Fhe,V2o,X2o,qj,z2o,Q2o,W2o,pu,The,U2o,H2o,jj,J2o,Y2o,Z2o,_u,Mhe,K2o,ebo,Dj,obo,rbo,tbo,bu,Ehe,abo,nbo,Gj,sbo,lbo,ibo,vu,Che,dbo,cbo,Oj,mbo,fbo,gbo,Fu,whe,hbo,ubo,Vj,pbo,_bo,bbo,Tu,Ahe,vbo,Fbo,Xj,Tbo,Mbo,Ebo,Mu,Cbo,Eu,l$,wbo,Lhe,Abo,Hro,Ad,Cu,yhe,i$,Lbo,xhe,ybo,Jro,Ro,d$,xbo,c$,$bo,zj,kbo,Sbo,Rbo,m$,Pbo,$he,Bbo,Ibo,Nbo,jr,f$,qbo,khe,jbo,Dbo,rn,Gbo,She,Obo,Vbo,Rhe,Xbo,zbo,Phe,Qbo,Wbo,Ubo,k,us,Bhe,Hbo,Jbo,Qj,Ybo,Zbo,Wj,Kbo,evo,ovo,ps,Ihe,rvo,tvo,Uj,avo,nvo,Hj,svo,lvo,ivo,_s,Nhe,dvo,cvo,Jj,mvo,fvo,Yj,gvo,hvo,uvo,wu,qhe,pvo,_vo,Zj,bvo,vvo,Fvo,bs,jhe,Tvo,Mvo,Kj,Evo,Cvo,eD,wvo,Avo,Lvo,Au,Dhe,yvo,xvo,oD,$vo,kvo,Svo,Lu,Ghe,Rvo,Pvo,rD,Bvo,Ivo,Nvo,yu,Ohe,qvo,jvo,tD,Dvo,Gvo,Ovo,vs,Vhe,Vvo,Xvo,aD,zvo,Qvo,nD,Wvo,Uvo,Hvo,Fs,Xhe,Jvo,Yvo,sD,Zvo,Kvo,lD,eFo,oFo,rFo,Ts,zhe,tFo,aFo,iD,nFo,sFo,dD,lFo,iFo,dFo,xu,Qhe,cFo,mFo,cD,fFo,gFo,hFo,$u,Whe,uFo,pFo,mD,_Fo,bFo,vFo,ku,Uhe,FFo,TFo,fD,MFo,EFo,CFo,Ms,Hhe,wFo,AFo,gD,LFo,yFo,hD,xFo,$Fo,kFo,Su,Jhe,SFo,RFo,uD,PFo,BFo,IFo,Es,Yhe,NFo,qFo,pD,jFo,DFo,_D,GFo,OFo,VFo,Cs,Zhe,XFo,zFo,bD,QFo,WFo,vD,UFo,HFo,JFo,ws,Khe,YFo,ZFo,FD,KFo,eTo,TD,oTo,rTo,tTo,As,eue,aTo,nTo,MD,sTo,lTo,ED,iTo,dTo,cTo,Ru,oue,mTo,fTo,CD,gTo,hTo,uTo,Ls,rue,pTo,_To,wD,bTo,vTo,AD,FTo,TTo,MTo,ys,tue,ETo,CTo,LD,wTo,ATo,yD,LTo,yTo,xTo,xs,aue,$To,kTo,xD,STo,RTo,$D,PTo,BTo,ITo,$s,nue,NTo,qTo,kD,jTo,DTo,SD,GTo,OTo,VTo,ks,sue,XTo,zTo,RD,QTo,WTo,PD,UTo,HTo,JTo,Ss,lue,YTo,ZTo,BD,KTo,eMo,ID,oMo,rMo,tMo,Rs,iue,aMo,nMo,ND,sMo,lMo,qD,iMo,dMo,cMo,Pu,due,mMo,fMo,jD,gMo,hMo,uMo,Ps,cue,pMo,_Mo,DD,bMo,vMo,GD,FMo,TMo,MMo,Bu,mue,EMo,CMo,OD,wMo,AMo,LMo,Bs,fue,yMo,xMo,VD,$Mo,kMo,XD,SMo,RMo,PMo,Is,gue,BMo,IMo,zD,NMo,qMo,QD,jMo,DMo,GMo,Ns,hue,OMo,VMo,WD,XMo,zMo,UD,QMo,WMo,UMo,Iu,uue,HMo,JMo,HD,YMo,ZMo,KMo,Nu,pue,eEo,oEo,JD,rEo,tEo,aEo,qs,_ue,nEo,sEo,YD,lEo,iEo,ZD,dEo,cEo,mEo,js,bue,fEo,gEo,KD,hEo,uEo,eG,pEo,_Eo,bEo,Ds,vue,vEo,FEo,oG,TEo,MEo,rG,EEo,CEo,wEo,qu,Fue,AEo,LEo,tG,yEo,xEo,$Eo,Gs,Tue,kEo,SEo,aG,REo,PEo,nG,BEo,IEo,NEo,Os,Mue,qEo,jEo,sG,DEo,GEo,lG,OEo,VEo,XEo,Vs,Eue,zEo,QEo,iG,WEo,UEo,dG,HEo,JEo,YEo,Xs,Cue,ZEo,KEo,cG,e4o,o4o,mG,r4o,t4o,a4o,zs,wue,n4o,s4o,fG,l4o,i4o,gG,d4o,c4o,m4o,Qs,Aue,f4o,g4o,hG,h4o,u4o,uG,p4o,_4o,b4o,Ws,Lue,v4o,F4o,pG,T4o,M4o,_G,E4o,C4o,w4o,Us,yue,A4o,L4o,bG,y4o,x4o,vG,$4o,k4o,S4o,Hs,xue,R4o,P4o,FG,B4o,I4o,TG,N4o,q4o,j4o,ju,$ue,D4o,G4o,MG,O4o,V4o,X4o,Js,kue,z4o,Q4o,EG,W4o,U4o,CG,H4o,J4o,Y4o,Du,Sue,Z4o,K4o,wG,eCo,oCo,rCo,Gu,Rue,tCo,aCo,AG,nCo,sCo,lCo,Ys,Pue,iCo,dCo,LG,cCo,mCo,yG,fCo,gCo,hCo,Zs,Bue,uCo,pCo,xG,_Co,bCo,$G,vCo,FCo,TCo,Ks,Iue,MCo,ECo,kG,CCo,wCo,SG,ACo,LCo,yCo,Ou,Nue,xCo,$Co,RG,kCo,SCo,RCo,el,que,PCo,BCo,PG,ICo,NCo,BG,qCo,jCo,DCo,ol,jue,GCo,OCo,IG,VCo,XCo,NG,zCo,QCo,WCo,rl,Due,UCo,HCo,qG,JCo,YCo,jG,ZCo,KCo,e3o,tl,Gue,o3o,r3o,DG,t3o,a3o,GG,n3o,s3o,l3o,al,Oue,i3o,d3o,OG,c3o,m3o,VG,f3o,g3o,h3o,nl,Vue,u3o,p3o,XG,_3o,b3o,zG,v3o,F3o,T3o,sl,Xue,M3o,E3o,QG,C3o,w3o,WG,A3o,L3o,y3o,ll,zue,x3o,$3o,UG,k3o,S3o,HG,R3o,P3o,B3o,Vu,Que,I3o,N3o,JG,q3o,j3o,D3o,il,Wue,G3o,O3o,YG,V3o,X3o,ZG,z3o,Q3o,W3o,dl,Uue,U3o,H3o,KG,J3o,Y3o,eO,Z3o,K3o,e5o,Xu,Hue,o5o,r5o,oO,t5o,a5o,n5o,zu,Jue,s5o,l5o,rO,i5o,d5o,c5o,Qu,Yue,m5o,f5o,tO,g5o,h5o,u5o,Wu,Zue,p5o,_5o,aO,b5o,v5o,F5o,cl,Kue,T5o,M5o,nO,E5o,C5o,sO,w5o,A5o,L5o,Uu,epe,y5o,x5o,lO,$5o,k5o,S5o,ml,ope,R5o,P5o,iO,B5o,I5o,dO,N5o,q5o,j5o,fl,rpe,D5o,G5o,cO,O5o,V5o,mO,X5o,z5o,Q5o,gl,tpe,W5o,U5o,fO,H5o,J5o,gO,Y5o,Z5o,K5o,hl,ape,e0o,o0o,hO,r0o,t0o,uO,a0o,n0o,s0o,ul,npe,l0o,i0o,pO,d0o,c0o,_O,m0o,f0o,g0o,pl,spe,h0o,u0o,bO,p0o,_0o,vO,b0o,v0o,F0o,Hu,lpe,T0o,M0o,FO,E0o,C0o,w0o,Ju,ipe,A0o,L0o,TO,y0o,x0o,$0o,_l,dpe,k0o,S0o,MO,R0o,P0o,EO,B0o,I0o,N0o,bl,cpe,q0o,j0o,CO,D0o,G0o,wO,O0o,V0o,X0o,vl,mpe,z0o,Q0o,AO,W0o,U0o,LO,H0o,J0o,Y0o,Yu,fpe,Z0o,K0o,yO,ewo,owo,rwo,Zu,gpe,two,awo,xO,nwo,swo,lwo,Ku,hpe,iwo,dwo,$O,cwo,mwo,fwo,Fl,upe,gwo,hwo,kO,uwo,pwo,SO,_wo,bwo,vwo,Tl,ppe,Fwo,Two,RO,Mwo,Ewo,PO,Cwo,wwo,Awo,ep,_pe,Lwo,ywo,BO,xwo,$wo,kwo,op,bpe,Swo,Rwo,IO,Pwo,Bwo,Iwo,rp,vpe,Nwo,qwo,NO,jwo,Dwo,Gwo,tp,Fpe,Owo,Vwo,qO,Xwo,zwo,Qwo,Ml,Tpe,Wwo,Uwo,jO,Hwo,Jwo,DO,Ywo,Zwo,Kwo,El,Mpe,eAo,oAo,GO,rAo,tAo,OO,aAo,nAo,sAo,ap,Epe,lAo,iAo,VO,dAo,cAo,mAo,np,Cpe,fAo,gAo,XO,hAo,uAo,pAo,Cl,wpe,_Ao,bAo,zO,vAo,FAo,QO,TAo,MAo,EAo,wl,Ape,CAo,wAo,WO,AAo,LAo,UO,yAo,xAo,$Ao,Al,Lpe,kAo,SAo,HO,RAo,PAo,JO,BAo,IAo,NAo,Ll,ype,qAo,jAo,YO,DAo,GAo,ZO,OAo,VAo,XAo,sp,zAo,lp,g$,QAo,xpe,WAo,Yro,Ld,ip,$pe,h$,UAo,kpe,HAo,Zro,Po,u$,JAo,p$,YAo,KO,ZAo,KAo,e6o,_$,o6o,Spe,r6o,t6o,a6o,Ye,b$,n6o,Rpe,s6o,l6o,tn,i6o,Ppe,d6o,c6o,Bpe,m6o,f6o,Ipe,g6o,h6o,u6o,z,dp,Npe,p6o,_6o,eV,b6o,v6o,F6o,cp,qpe,T6o,M6o,oV,E6o,C6o,w6o,mp,jpe,A6o,L6o,rV,y6o,x6o,$6o,fp,Dpe,k6o,S6o,tV,R6o,P6o,B6o,gp,Gpe,I6o,N6o,aV,q6o,j6o,D6o,hp,Ope,G6o,O6o,nV,V6o,X6o,z6o,up,Vpe,Q6o,W6o,sV,U6o,H6o,J6o,pp,Xpe,Y6o,Z6o,lV,K6o,e7o,o7o,_p,zpe,r7o,t7o,iV,a7o,n7o,s7o,bp,Qpe,l7o,i7o,dV,d7o,c7o,m7o,vp,Wpe,f7o,g7o,cV,h7o,u7o,p7o,Fp,Upe,_7o,b7o,mV,v7o,F7o,T7o,Tp,Hpe,M7o,E7o,fV,C7o,w7o,A7o,Mp,Jpe,L7o,y7o,gV,x7o,$7o,k7o,Ep,Ype,S7o,R7o,hV,P7o,B7o,I7o,Cp,Zpe,N7o,q7o,uV,j7o,D7o,G7o,wp,Kpe,O7o,V7o,pV,X7o,z7o,Q7o,Ap,e_e,W7o,U7o,_V,H7o,J7o,Y7o,Lp,o_e,Z7o,K7o,bV,eLo,oLo,rLo,yp,r_e,tLo,aLo,vV,nLo,sLo,lLo,xp,t_e,iLo,dLo,FV,cLo,mLo,fLo,$p,a_e,gLo,hLo,TV,uLo,pLo,_Lo,kp,n_e,bLo,vLo,MV,FLo,TLo,MLo,Sp,s_e,ELo,CLo,EV,wLo,ALo,LLo,Rp,l_e,yLo,xLo,CV,$Lo,kLo,SLo,Pp,i_e,RLo,PLo,wV,BLo,ILo,NLo,Bp,d_e,qLo,jLo,AV,DLo,GLo,OLo,Ip,c_e,VLo,XLo,LV,zLo,QLo,WLo,Np,m_e,ULo,HLo,yV,JLo,YLo,ZLo,qp,f_e,KLo,e8o,xV,o8o,r8o,t8o,jp,g_e,a8o,n8o,$V,s8o,l8o,i8o,Dp,h_e,d8o,c8o,kV,m8o,f8o,g8o,Gp,u_e,h8o,u8o,SV,p8o,_8o,b8o,Op,p_e,v8o,F8o,RV,T8o,M8o,E8o,Vp,__e,C8o,w8o,PV,A8o,L8o,y8o,Xp,b_e,x8o,$8o,BV,k8o,S8o,R8o,zp,v_e,P8o,B8o,IV,I8o,N8o,q8o,Qp,F_e,j8o,D8o,NV,G8o,O8o,V8o,Wp,T_e,X8o,z8o,qV,Q8o,W8o,U8o,Up,M_e,H8o,J8o,jV,Y8o,Z8o,K8o,Hp,E_e,eyo,oyo,DV,ryo,tyo,ayo,Jp,C_e,nyo,syo,GV,lyo,iyo,dyo,Yp,w_e,cyo,myo,OV,fyo,gyo,hyo,Zp,uyo,Kp,pyo,e_,v$,_yo,A_e,byo,Kro,yd,o_,L_e,F$,vyo,y_e,Fyo,eto,Bo,T$,Tyo,M$,Myo,VV,Eyo,Cyo,wyo,E$,Ayo,x_e,Lyo,yyo,xyo,Ze,C$,$yo,$_e,kyo,Syo,xd,Ryo,k_e,Pyo,Byo,S_e,Iyo,Nyo,qyo,se,r_,R_e,jyo,Dyo,XV,Gyo,Oyo,Vyo,t_,P_e,Xyo,zyo,zV,Qyo,Wyo,Uyo,a_,B_e,Hyo,Jyo,QV,Yyo,Zyo,Kyo,n_,I_e,e9o,o9o,WV,r9o,t9o,a9o,s_,N_e,n9o,s9o,UV,l9o,i9o,d9o,l_,q_e,c9o,m9o,HV,f9o,g9o,h9o,i_,j_e,u9o,p9o,JV,_9o,b9o,v9o,d_,D_e,F9o,T9o,YV,M9o,E9o,C9o,c_,G_e,w9o,A9o,ZV,L9o,y9o,x9o,m_,O_e,$9o,k9o,KV,S9o,R9o,P9o,f_,V_e,B9o,I9o,eX,N9o,q9o,j9o,g_,X_e,D9o,G9o,oX,O9o,V9o,X9o,h_,z_e,z9o,Q9o,rX,W9o,U9o,H9o,u_,Q_e,J9o,Y9o,tX,Z9o,K9o,exo,p_,W_e,oxo,rxo,aX,txo,axo,nxo,__,U_e,sxo,lxo,nX,ixo,dxo,cxo,b_,H_e,mxo,fxo,sX,gxo,hxo,uxo,v_,J_e,pxo,_xo,lX,bxo,vxo,Fxo,F_,Y_e,Txo,Mxo,iX,Exo,Cxo,wxo,T_,Z_e,Axo,Lxo,dX,yxo,xxo,$xo,M_,K_e,kxo,Sxo,cX,Rxo,Pxo,Bxo,E_,e1e,Ixo,Nxo,mX,qxo,jxo,Dxo,C_,o1e,Gxo,Oxo,fX,Vxo,Xxo,zxo,w_,Qxo,A_,Wxo,L_,w$,Uxo,r1e,Hxo,oto,$d,y_,t1e,A$,Jxo,a1e,Yxo,rto,Io,L$,Zxo,kd,Kxo,gX,e$o,o$o,hX,r$o,t$o,a$o,y$,n$o,n1e,s$o,l$o,i$o,Tt,x$,d$o,s1e,c$o,m$o,Sd,f$o,l1e,g$o,h$o,uX,u$o,p$o,_$o,x_,b$o,Ke,$$,v$o,i1e,F$o,T$o,an,M$o,d1e,E$o,C$o,c1e,w$o,A$o,m1e,L$o,y$o,x$o,y,$_,f1e,$$o,k$o,pX,S$o,R$o,P$o,k_,g1e,B$o,I$o,_X,N$o,q$o,j$o,S_,h1e,D$o,G$o,bX,O$o,V$o,X$o,R_,u1e,z$o,Q$o,vX,W$o,U$o,H$o,P_,p1e,J$o,Y$o,FX,Z$o,K$o,eko,B_,_1e,oko,rko,TX,tko,ako,nko,I_,b1e,sko,lko,MX,iko,dko,cko,N_,v1e,mko,fko,EX,gko,hko,uko,q_,F1e,pko,_ko,CX,bko,vko,Fko,j_,T1e,Tko,Mko,wX,Eko,Cko,wko,D_,M1e,Ako,Lko,AX,yko,xko,$ko,G_,E1e,kko,Sko,LX,Rko,Pko,Bko,O_,C1e,Iko,Nko,yX,qko,jko,Dko,V_,w1e,Gko,Oko,xX,Vko,Xko,zko,X_,A1e,Qko,Wko,$X,Uko,Hko,Jko,z_,L1e,Yko,Zko,kX,Kko,eSo,oSo,Q_,y1e,rSo,tSo,SX,aSo,nSo,sSo,W_,x1e,lSo,iSo,RX,dSo,cSo,mSo,U_,$1e,fSo,gSo,PX,hSo,uSo,pSo,H_,k1e,_So,bSo,BX,vSo,FSo,TSo,J_,S1e,MSo,ESo,IX,CSo,wSo,ASo,Y_,R1e,LSo,ySo,NX,xSo,$So,kSo,Z_,P1e,SSo,RSo,qX,PSo,BSo,ISo,K_,B1e,NSo,qSo,jX,jSo,DSo,GSo,e1,I1e,OSo,VSo,DX,XSo,zSo,QSo,o1,N1e,WSo,USo,GX,HSo,JSo,YSo,r1,q1e,ZSo,KSo,OX,eRo,oRo,rRo,t1,j1e,tRo,aRo,VX,nRo,sRo,lRo,a1,D1e,iRo,dRo,XX,cRo,mRo,fRo,n1,G1e,gRo,hRo,zX,uRo,pRo,_Ro,s1,O1e,bRo,vRo,QX,FRo,TRo,MRo,l1,V1e,ERo,CRo,WX,wRo,ARo,LRo,i1,X1e,yRo,xRo,UX,$Ro,kRo,SRo,d1,z1e,RRo,PRo,HX,BRo,IRo,NRo,c1,Q1e,qRo,jRo,JX,DRo,GRo,ORo,m1,W1e,VRo,XRo,YX,zRo,QRo,WRo,f1,U1e,URo,HRo,ZX,JRo,YRo,ZRo,g1,H1e,KRo,ePo,KX,oPo,rPo,tPo,h1,J1e,aPo,nPo,ez,sPo,lPo,iPo,yl,Y1e,dPo,cPo,oz,mPo,fPo,rz,gPo,hPo,uPo,u1,Z1e,pPo,_Po,tz,bPo,vPo,FPo,p1,K1e,TPo,MPo,az,EPo,CPo,wPo,_1,e2e,APo,LPo,nz,yPo,xPo,$Po,b1,o2e,kPo,SPo,sz,RPo,PPo,BPo,v1,r2e,IPo,NPo,lz,qPo,jPo,DPo,F1,t2e,GPo,OPo,iz,VPo,XPo,zPo,T1,a2e,QPo,WPo,dz,UPo,HPo,JPo,M1,n2e,YPo,ZPo,cz,KPo,eBo,oBo,E1,s2e,rBo,tBo,mz,aBo,nBo,sBo,C1,l2e,lBo,iBo,fz,dBo,cBo,mBo,w1,i2e,fBo,gBo,gz,hBo,uBo,pBo,A1,d2e,_Bo,bBo,hz,vBo,FBo,TBo,L1,c2e,MBo,EBo,uz,CBo,wBo,ABo,y1,m2e,LBo,yBo,pz,xBo,$Bo,kBo,x1,f2e,SBo,RBo,_z,PBo,BBo,IBo,$1,g2e,NBo,qBo,bz,jBo,DBo,GBo,k1,h2e,OBo,VBo,vz,XBo,zBo,QBo,S1,u2e,WBo,UBo,Fz,HBo,JBo,YBo,R1,p2e,ZBo,KBo,Tz,eIo,oIo,rIo,P1,_2e,tIo,aIo,Mz,nIo,sIo,lIo,B1,b2e,iIo,dIo,Ez,cIo,mIo,fIo,I1,v2e,gIo,hIo,Cz,uIo,pIo,_Io,N1,F2e,bIo,vIo,wz,FIo,TIo,MIo,q1,T2e,EIo,CIo,Az,wIo,AIo,LIo,j1,M2e,yIo,xIo,Lz,$Io,kIo,SIo,D1,E2e,RIo,PIo,yz,BIo,IIo,NIo,G1,C2e,qIo,jIo,xz,DIo,GIo,OIo,O1,w2e,VIo,XIo,$z,zIo,QIo,WIo,V1,A2e,UIo,HIo,kz,JIo,YIo,ZIo,X1,L2e,KIo,eNo,Sz,oNo,rNo,tNo,z1,y2e,aNo,nNo,Rz,sNo,lNo,iNo,Q1,x2e,dNo,cNo,Pz,mNo,fNo,gNo,W1,$2e,hNo,uNo,Bz,pNo,_No,bNo,U1,k2e,vNo,FNo,Iz,TNo,MNo,ENo,H1,S2e,CNo,wNo,Nz,ANo,LNo,yNo,J1,R2e,xNo,$No,qz,kNo,SNo,RNo,Y1,P2e,PNo,BNo,jz,INo,NNo,qNo,Z1,B2e,jNo,DNo,Dz,GNo,ONo,VNo,K1,I2e,XNo,zNo,Gz,QNo,WNo,UNo,e2,N2e,HNo,JNo,Oz,YNo,ZNo,KNo,o2,q2e,eqo,oqo,Vz,rqo,tqo,aqo,r2,j2e,nqo,sqo,Xz,lqo,iqo,dqo,t2,D2e,cqo,mqo,zz,fqo,gqo,hqo,a2,G2e,uqo,pqo,Qz,_qo,bqo,vqo,n2,O2e,Fqo,Tqo,Wz,Mqo,Eqo,Cqo,s2,V2e,wqo,Aqo,Uz,Lqo,yqo,xqo,l2,X2e,$qo,kqo,Hz,Sqo,Rqo,Pqo,i2,z2e,Bqo,Iqo,Jz,Nqo,qqo,jqo,d2,Q2e,Dqo,Gqo,Yz,Oqo,Vqo,Xqo,c2,W2e,zqo,Qqo,Zz,Wqo,Uqo,Hqo,m2,U2e,Jqo,Yqo,Kz,Zqo,Kqo,ejo,f2,H2e,ojo,rjo,eQ,tjo,ajo,njo,g2,J2e,sjo,ljo,oQ,ijo,djo,cjo,h2,Y2e,mjo,fjo,rQ,gjo,hjo,ujo,u2,Z2e,pjo,_jo,tQ,bjo,vjo,Fjo,p2,K2e,Tjo,Mjo,aQ,Ejo,Cjo,wjo,_2,ebe,Ajo,Ljo,nQ,yjo,xjo,$jo,b2,obe,kjo,Sjo,sQ,Rjo,Pjo,Bjo,v2,rbe,Ijo,Njo,lQ,qjo,jjo,Djo,F2,tbe,Gjo,Ojo,iQ,Vjo,Xjo,zjo,T2,abe,Qjo,Wjo,dQ,Ujo,Hjo,Jjo,M2,nbe,Yjo,Zjo,cQ,Kjo,eDo,oDo,E2,sbe,rDo,tDo,mQ,aDo,nDo,sDo,C2,lbe,lDo,iDo,fQ,dDo,cDo,mDo,w2,ibe,fDo,gDo,gQ,hDo,uDo,pDo,A2,dbe,_Do,bDo,hQ,vDo,FDo,TDo,L2,cbe,MDo,EDo,uQ,CDo,wDo,ADo,y2,mbe,LDo,yDo,pQ,xDo,$Do,kDo,x2,fbe,SDo,RDo,_Q,PDo,BDo,IDo,$2,gbe,NDo,qDo,bQ,jDo,DDo,GDo,k2,hbe,ODo,VDo,vQ,XDo,zDo,QDo,S2,ube,WDo,UDo,FQ,HDo,JDo,YDo,R2,pbe,ZDo,KDo,TQ,eGo,oGo,rGo,P2,_be,tGo,aGo,MQ,nGo,sGo,lGo,B2,bbe,iGo,dGo,EQ,cGo,mGo,fGo,I2,vbe,gGo,hGo,CQ,uGo,pGo,_Go,N2,Fbe,bGo,vGo,wQ,FGo,TGo,MGo,q2,Tbe,EGo,CGo,AQ,wGo,AGo,LGo,j2,Mbe,yGo,xGo,LQ,$Go,kGo,SGo,D2,Ebe,RGo,PGo,yQ,BGo,IGo,NGo,G2,Cbe,qGo,jGo,xQ,DGo,GGo,OGo,O2,wbe,VGo,XGo,$Q,zGo,QGo,WGo,V2,Abe,UGo,HGo,kQ,JGo,YGo,ZGo,X2,Lbe,KGo,eOo,SQ,oOo,rOo,tOo,z2,ybe,aOo,nOo,RQ,sOo,lOo,iOo,Q2,xbe,dOo,cOo,PQ,mOo,fOo,gOo,W2,$be,hOo,uOo,BQ,pOo,_Oo,bOo,U2,kbe,vOo,FOo,IQ,TOo,MOo,EOo,H2,COo,Sbe,wOo,AOo,Rbe,LOo,yOo,J2,tto,Rd,Y2,Pbe,k$,xOo,Bbe,$Oo,ato,No,S$,kOo,Pd,SOo,NQ,ROo,POo,qQ,BOo,IOo,NOo,R$,qOo,Ibe,jOo,DOo,GOo,Mt,P$,OOo,Nbe,VOo,XOo,Bd,zOo,qbe,QOo,WOo,jQ,UOo,HOo,JOo,Z2,YOo,eo,B$,ZOo,jbe,KOo,eVo,nn,oVo,Dbe,rVo,tVo,Gbe,aVo,nVo,Obe,sVo,lVo,iVo,G,K2,Vbe,dVo,cVo,DQ,mVo,fVo,gVo,eb,Xbe,hVo,uVo,GQ,pVo,_Vo,bVo,ob,zbe,vVo,FVo,OQ,TVo,MVo,EVo,rb,Qbe,CVo,wVo,VQ,AVo,LVo,yVo,tb,Wbe,xVo,$Vo,XQ,kVo,SVo,RVo,ab,Ube,PVo,BVo,zQ,IVo,NVo,qVo,nb,Hbe,jVo,DVo,QQ,GVo,OVo,VVo,sb,Jbe,XVo,zVo,WQ,QVo,WVo,UVo,lb,Ybe,HVo,JVo,UQ,YVo,ZVo,KVo,ib,Zbe,eXo,oXo,HQ,rXo,tXo,aXo,db,Kbe,nXo,sXo,JQ,lXo,iXo,dXo,cb,eve,cXo,mXo,YQ,fXo,gXo,hXo,mb,ove,uXo,pXo,ZQ,_Xo,bXo,vXo,fb,rve,FXo,TXo,KQ,MXo,EXo,CXo,gb,tve,wXo,AXo,eW,LXo,yXo,xXo,hb,ave,$Xo,kXo,oW,SXo,RXo,PXo,ub,nve,BXo,IXo,rW,NXo,qXo,jXo,pb,sve,DXo,GXo,tW,OXo,VXo,XXo,_b,lve,zXo,QXo,aW,WXo,UXo,HXo,bb,ive,JXo,YXo,nW,ZXo,KXo,ezo,vb,dve,ozo,rzo,sW,tzo,azo,nzo,Fb,cve,szo,lzo,lW,izo,dzo,czo,Tb,mve,mzo,fzo,iW,gzo,hzo,uzo,Mb,fve,pzo,_zo,dW,bzo,vzo,Fzo,Eb,gve,Tzo,Mzo,cW,Ezo,Czo,wzo,Cb,hve,Azo,Lzo,mW,yzo,xzo,$zo,wb,uve,kzo,Szo,fW,Rzo,Pzo,Bzo,Ab,pve,Izo,Nzo,gW,qzo,jzo,Dzo,Lb,_ve,Gzo,Ozo,hW,Vzo,Xzo,zzo,yb,bve,Qzo,Wzo,uW,Uzo,Hzo,Jzo,xb,vve,Yzo,Zzo,pW,Kzo,eQo,oQo,$b,Fve,rQo,tQo,_W,aQo,nQo,sQo,kb,Tve,lQo,iQo,bW,dQo,cQo,mQo,Sb,Mve,fQo,gQo,vW,hQo,uQo,pQo,Rb,Eve,_Qo,bQo,FW,vQo,FQo,TQo,Pb,Cve,MQo,EQo,TW,CQo,wQo,AQo,Bb,wve,LQo,yQo,MW,xQo,$Qo,kQo,Ib,Ave,SQo,RQo,EW,PQo,BQo,IQo,Nb,Lve,NQo,qQo,CW,jQo,DQo,GQo,qb,yve,OQo,VQo,wW,XQo,zQo,QQo,jb,xve,WQo,UQo,AW,HQo,JQo,YQo,Db,$ve,ZQo,KQo,LW,eWo,oWo,rWo,Gb,kve,tWo,aWo,yW,nWo,sWo,lWo,Ob,Sve,iWo,dWo,xW,cWo,mWo,fWo,Vb,Rve,gWo,hWo,$W,uWo,pWo,_Wo,Xb,Pve,bWo,vWo,kW,FWo,TWo,MWo,zb,Bve,EWo,CWo,SW,wWo,AWo,LWo,Qb,Ive,yWo,xWo,RW,$Wo,kWo,SWo,Wb,RWo,Nve,PWo,BWo,qve,IWo,NWo,Ub,nto,Id,Hb,jve,I$,qWo,Dve,jWo,sto,qo,N$,DWo,Nd,GWo,PW,OWo,VWo,BW,XWo,zWo,QWo,q$,WWo,Gve,UWo,HWo,JWo,Et,j$,YWo,Ove,ZWo,KWo,qd,eUo,Vve,oUo,rUo,IW,tUo,aUo,nUo,Jb,sUo,oo,D$,lUo,Xve,iUo,dUo,sn,cUo,zve,mUo,fUo,Qve,gUo,hUo,Wve,uUo,pUo,_Uo,Q,Yb,Uve,bUo,vUo,NW,FUo,TUo,MUo,Zb,Hve,EUo,CUo,qW,wUo,AUo,LUo,Kb,Jve,yUo,xUo,jW,$Uo,kUo,SUo,ev,Yve,RUo,PUo,DW,BUo,IUo,NUo,ov,Zve,qUo,jUo,GW,DUo,GUo,OUo,rv,Kve,VUo,XUo,OW,zUo,QUo,WUo,tv,eFe,UUo,HUo,VW,JUo,YUo,ZUo,av,oFe,KUo,eHo,XW,oHo,rHo,tHo,nv,rFe,aHo,nHo,zW,sHo,lHo,iHo,sv,tFe,dHo,cHo,QW,mHo,fHo,gHo,lv,aFe,hHo,uHo,WW,pHo,_Ho,bHo,iv,nFe,vHo,FHo,UW,THo,MHo,EHo,dv,sFe,CHo,wHo,HW,AHo,LHo,yHo,cv,lFe,xHo,$Ho,JW,kHo,SHo,RHo,mv,iFe,PHo,BHo,YW,IHo,NHo,qHo,fv,dFe,jHo,DHo,ZW,GHo,OHo,VHo,gv,cFe,XHo,zHo,KW,QHo,WHo,UHo,hv,mFe,HHo,JHo,eU,YHo,ZHo,KHo,uv,fFe,eJo,oJo,oU,rJo,tJo,aJo,pv,gFe,nJo,sJo,rU,lJo,iJo,dJo,_v,hFe,cJo,mJo,tU,fJo,gJo,hJo,bv,uFe,uJo,pJo,aU,_Jo,bJo,vJo,vv,pFe,FJo,TJo,nU,MJo,EJo,CJo,Fv,_Fe,wJo,AJo,sU,LJo,yJo,xJo,Tv,bFe,$Jo,kJo,lU,SJo,RJo,PJo,Mv,vFe,BJo,IJo,iU,NJo,qJo,jJo,Ev,FFe,DJo,GJo,dU,OJo,VJo,XJo,Cv,TFe,zJo,QJo,cU,WJo,UJo,HJo,wv,MFe,JJo,YJo,mU,ZJo,KJo,eYo,Av,EFe,oYo,rYo,fU,tYo,aYo,nYo,Lv,CFe,sYo,lYo,gU,iYo,dYo,cYo,yv,wFe,mYo,fYo,hU,gYo,hYo,uYo,xv,AFe,pYo,_Yo,uU,bYo,vYo,FYo,$v,LFe,TYo,MYo,pU,EYo,CYo,wYo,kv,yFe,AYo,LYo,_U,yYo,xYo,$Yo,Sv,xFe,kYo,SYo,bU,RYo,PYo,BYo,Rv,$Fe,IYo,NYo,vU,qYo,jYo,DYo,Pv,kFe,GYo,OYo,FU,VYo,XYo,zYo,Bv,SFe,QYo,WYo,TU,UYo,HYo,JYo,Iv,RFe,YYo,ZYo,MU,KYo,eZo,oZo,Nv,PFe,rZo,tZo,EU,aZo,nZo,sZo,qv,BFe,lZo,iZo,CU,dZo,cZo,mZo,jv,fZo,IFe,gZo,hZo,NFe,uZo,pZo,Dv,lto,jd,Gv,qFe,G$,_Zo,jFe,bZo,ito,jo,O$,vZo,Dd,FZo,wU,TZo,MZo,AU,EZo,CZo,wZo,V$,AZo,DFe,LZo,yZo,xZo,Ct,X$,$Zo,GFe,kZo,SZo,Gd,RZo,OFe,PZo,BZo,LU,IZo,NZo,qZo,Ov,jZo,ro,z$,DZo,VFe,GZo,OZo,ln,VZo,XFe,XZo,zZo,zFe,QZo,WZo,QFe,UZo,HZo,JZo,Q$,Vv,WFe,YZo,ZZo,yU,KZo,eKo,oKo,Xv,UFe,rKo,tKo,xU,aKo,nKo,sKo,zv,lKo,HFe,iKo,dKo,JFe,cKo,mKo,Qv,dto,Od,Wv,YFe,W$,fKo,ZFe,gKo,cto,Do,U$,hKo,Vd,uKo,$U,pKo,_Ko,kU,bKo,vKo,FKo,H$,TKo,KFe,MKo,EKo,CKo,wt,J$,wKo,eTe,AKo,LKo,Xd,yKo,oTe,xKo,$Ko,SU,kKo,SKo,RKo,Uv,PKo,to,Y$,BKo,rTe,IKo,NKo,dn,qKo,tTe,jKo,DKo,aTe,GKo,OKo,nTe,VKo,XKo,zKo,Y,Hv,sTe,QKo,WKo,RU,UKo,HKo,JKo,Jv,lTe,YKo,ZKo,PU,KKo,eer,oer,Yv,iTe,rer,ter,BU,aer,ner,ser,Zv,dTe,ler,ier,IU,der,cer,mer,Kv,cTe,fer,ger,NU,her,uer,per,eF,mTe,_er,ber,qU,ver,Fer,Ter,oF,fTe,Mer,Eer,jU,Cer,wer,Aer,rF,gTe,Ler,yer,DU,xer,$er,ker,tF,hTe,Ser,Rer,GU,Per,Ber,Ier,aF,uTe,Ner,qer,OU,jer,Der,Ger,nF,pTe,Oer,Ver,VU,Xer,zer,Qer,sF,_Te,Wer,Uer,XU,Her,Jer,Yer,lF,bTe,Zer,Ker,zU,eor,oor,ror,iF,vTe,tor,aor,QU,nor,sor,lor,dF,FTe,ior,dor,WU,cor,mor,gor,cF,TTe,hor,uor,UU,por,_or,bor,mF,MTe,vor,For,HU,Tor,Mor,Eor,fF,ETe,Cor,wor,JU,Aor,Lor,yor,gF,CTe,xor,$or,YU,kor,Sor,Ror,hF,wTe,Por,Bor,ZU,Ior,Nor,qor,uF,ATe,jor,Dor,KU,Gor,Oor,Vor,pF,LTe,Xor,zor,eH,Qor,Wor,Uor,_F,yTe,Hor,Jor,oH,Yor,Zor,Kor,bF,xTe,err,orr,rH,rrr,trr,arr,vF,$Te,nrr,srr,tH,lrr,irr,drr,FF,kTe,crr,mrr,aH,frr,grr,hrr,TF,STe,urr,prr,nH,_rr,brr,vrr,MF,RTe,Frr,Trr,sH,Mrr,Err,Crr,EF,PTe,wrr,Arr,lH,Lrr,yrr,xrr,CF,BTe,$rr,krr,iH,Srr,Rrr,Prr,wF,ITe,Brr,Irr,dH,Nrr,qrr,jrr,AF,NTe,Drr,Grr,cH,Orr,Vrr,Xrr,LF,qTe,zrr,Qrr,mH,Wrr,Urr,Hrr,yF,jTe,Jrr,Yrr,fH,Zrr,Krr,etr,xF,DTe,otr,rtr,GTe,ttr,atr,ntr,$F,OTe,str,ltr,gH,itr,dtr,ctr,kF,VTe,mtr,ftr,hH,gtr,htr,utr,SF,XTe,ptr,_tr,uH,btr,vtr,Ftr,RF,zTe,Ttr,Mtr,pH,Etr,Ctr,wtr,PF,Atr,QTe,Ltr,ytr,WTe,xtr,$tr,BF,mto,zd,IF,UTe,Z$,ktr,HTe,Str,fto,Go,K$,Rtr,Qd,Ptr,_H,Btr,Itr,bH,Ntr,qtr,jtr,ek,Dtr,JTe,Gtr,Otr,Vtr,At,ok,Xtr,YTe,ztr,Qtr,Wd,Wtr,ZTe,Utr,Htr,vH,Jtr,Ytr,Ztr,NF,Ktr,ao,rk,ear,KTe,oar,rar,cn,tar,eMe,aar,nar,oMe,sar,lar,rMe,iar,dar,car,fe,qF,tMe,mar,far,FH,gar,har,uar,jF,aMe,par,_ar,TH,bar,Far,Tar,DF,nMe,Mar,Ear,MH,Car,war,Aar,GF,sMe,Lar,yar,EH,xar,$ar,kar,OF,lMe,Sar,Rar,CH,Par,Bar,Iar,VF,iMe,Nar,qar,wH,jar,Dar,Gar,XF,dMe,Oar,Var,AH,Xar,zar,Qar,zF,cMe,War,Uar,LH,Har,Jar,Yar,QF,mMe,Zar,Kar,yH,enr,onr,rnr,WF,fMe,tnr,anr,xH,nnr,snr,lnr,UF,gMe,inr,dnr,$H,cnr,mnr,fnr,HF,hMe,gnr,hnr,kH,unr,pnr,_nr,JF,uMe,bnr,vnr,SH,Fnr,Tnr,Mnr,YF,pMe,Enr,Cnr,RH,wnr,Anr,Lnr,ZF,_Me,ynr,xnr,PH,$nr,knr,Snr,KF,bMe,Rnr,Pnr,BH,Bnr,Inr,Nnr,eT,vMe,qnr,jnr,IH,Dnr,Gnr,Onr,oT,FMe,Vnr,Xnr,NH,znr,Qnr,Wnr,rT,TMe,Unr,Hnr,qH,Jnr,Ynr,Znr,tT,MMe,Knr,esr,jH,osr,rsr,tsr,aT,asr,EMe,nsr,ssr,CMe,lsr,isr,nT,gto,Ud,sT,wMe,tk,dsr,AMe,csr,hto,Oo,ak,msr,Hd,fsr,DH,gsr,hsr,GH,usr,psr,_sr,nk,bsr,LMe,vsr,Fsr,Tsr,Lt,sk,Msr,yMe,Esr,Csr,Jd,wsr,xMe,Asr,Lsr,OH,ysr,xsr,$sr,lT,ksr,no,lk,Ssr,$Me,Rsr,Psr,mn,Bsr,kMe,Isr,Nsr,SMe,qsr,jsr,RMe,Dsr,Gsr,Osr,q,iT,PMe,Vsr,Xsr,VH,zsr,Qsr,Wsr,dT,BMe,Usr,Hsr,XH,Jsr,Ysr,Zsr,cT,IMe,Ksr,elr,zH,olr,rlr,tlr,mT,NMe,alr,nlr,QH,slr,llr,ilr,fT,qMe,dlr,clr,WH,mlr,flr,glr,gT,jMe,hlr,ulr,UH,plr,_lr,blr,hT,DMe,vlr,Flr,HH,Tlr,Mlr,Elr,uT,GMe,Clr,wlr,JH,Alr,Llr,ylr,pT,OMe,xlr,$lr,YH,klr,Slr,Rlr,_T,VMe,Plr,Blr,ZH,Ilr,Nlr,qlr,bT,XMe,jlr,Dlr,KH,Glr,Olr,Vlr,vT,zMe,Xlr,zlr,eJ,Qlr,Wlr,Ulr,FT,QMe,Hlr,Jlr,oJ,Ylr,Zlr,Klr,TT,WMe,eir,oir,rJ,rir,tir,air,MT,UMe,nir,sir,tJ,lir,iir,dir,ET,HMe,cir,mir,aJ,fir,gir,hir,CT,JMe,uir,pir,nJ,_ir,bir,vir,wT,YMe,Fir,Tir,sJ,Mir,Eir,Cir,AT,ZMe,wir,Air,lJ,Lir,yir,xir,LT,KMe,$ir,kir,iJ,Sir,Rir,Pir,yT,eEe,Bir,Iir,dJ,Nir,qir,jir,xT,oEe,Dir,Gir,cJ,Oir,Vir,Xir,$T,rEe,zir,Qir,mJ,Wir,Uir,Hir,kT,tEe,Jir,Yir,fJ,Zir,Kir,edr,ST,aEe,odr,rdr,gJ,tdr,adr,ndr,RT,nEe,sdr,ldr,hJ,idr,ddr,cdr,PT,sEe,mdr,fdr,uJ,gdr,hdr,udr,BT,lEe,pdr,_dr,pJ,bdr,vdr,Fdr,IT,iEe,Tdr,Mdr,_J,Edr,Cdr,wdr,NT,dEe,Adr,Ldr,bJ,ydr,xdr,$dr,qT,cEe,kdr,Sdr,vJ,Rdr,Pdr,Bdr,jT,mEe,Idr,Ndr,FJ,qdr,jdr,Ddr,DT,fEe,Gdr,Odr,TJ,Vdr,Xdr,zdr,GT,gEe,Qdr,Wdr,MJ,Udr,Hdr,Jdr,OT,hEe,Ydr,Zdr,EJ,Kdr,ecr,ocr,VT,uEe,rcr,tcr,CJ,acr,ncr,scr,XT,pEe,lcr,icr,wJ,dcr,ccr,mcr,zT,_Ee,fcr,gcr,AJ,hcr,ucr,pcr,QT,bEe,_cr,bcr,LJ,vcr,Fcr,Tcr,WT,vEe,Mcr,Ecr,yJ,Ccr,wcr,Acr,UT,FEe,Lcr,ycr,xJ,xcr,$cr,kcr,HT,TEe,Scr,Rcr,$J,Pcr,Bcr,Icr,JT,MEe,Ncr,qcr,kJ,jcr,Dcr,Gcr,YT,EEe,Ocr,Vcr,SJ,Xcr,zcr,Qcr,ZT,CEe,Wcr,Ucr,RJ,Hcr,Jcr,Ycr,KT,wEe,Zcr,Kcr,PJ,emr,omr,rmr,eM,AEe,tmr,amr,BJ,nmr,smr,lmr,oM,LEe,imr,dmr,IJ,cmr,mmr,fmr,rM,yEe,gmr,hmr,NJ,umr,pmr,_mr,tM,xEe,bmr,vmr,qJ,Fmr,Tmr,Mmr,aM,$Ee,Emr,Cmr,jJ,wmr,Amr,Lmr,nM,kEe,ymr,xmr,DJ,$mr,kmr,Smr,sM,SEe,Rmr,Pmr,GJ,Bmr,Imr,Nmr,lM,REe,qmr,jmr,OJ,Dmr,Gmr,Omr,iM,PEe,Vmr,Xmr,VJ,zmr,Qmr,Wmr,dM,BEe,Umr,Hmr,XJ,Jmr,Ymr,Zmr,cM,Kmr,IEe,efr,ofr,NEe,rfr,tfr,mM,uto,Yd,fM,qEe,ik,afr,jEe,nfr,pto,Vo,dk,sfr,Zd,lfr,zJ,ifr,dfr,QJ,cfr,mfr,ffr,ck,gfr,DEe,hfr,ufr,pfr,yt,mk,_fr,GEe,bfr,vfr,Kd,Ffr,OEe,Tfr,Mfr,WJ,Efr,Cfr,wfr,gM,Afr,so,fk,Lfr,VEe,yfr,xfr,fn,$fr,XEe,kfr,Sfr,zEe,Rfr,Pfr,QEe,Bfr,Ifr,Nfr,K,hM,WEe,qfr,jfr,UJ,Dfr,Gfr,Ofr,uM,UEe,Vfr,Xfr,HJ,zfr,Qfr,Wfr,pM,HEe,Ufr,Hfr,JJ,Jfr,Yfr,Zfr,_M,JEe,Kfr,egr,YJ,ogr,rgr,tgr,bM,YEe,agr,ngr,ZJ,sgr,lgr,igr,vM,ZEe,dgr,cgr,KJ,mgr,fgr,ggr,FM,KEe,hgr,ugr,eY,pgr,_gr,bgr,TM,e4e,vgr,Fgr,oY,Tgr,Mgr,Egr,MM,o4e,Cgr,wgr,rY,Agr,Lgr,ygr,EM,r4e,xgr,$gr,tY,kgr,Sgr,Rgr,CM,t4e,Pgr,Bgr,aY,Igr,Ngr,qgr,wM,a4e,jgr,Dgr,nY,Ggr,Ogr,Vgr,AM,n4e,Xgr,zgr,sY,Qgr,Wgr,Ugr,LM,s4e,Hgr,Jgr,lY,Ygr,Zgr,Kgr,yM,l4e,ehr,ohr,iY,rhr,thr,ahr,xM,i4e,nhr,shr,dY,lhr,ihr,dhr,$M,d4e,chr,mhr,cY,fhr,ghr,hhr,kM,c4e,uhr,phr,mY,_hr,bhr,vhr,SM,m4e,Fhr,Thr,fY,Mhr,Ehr,Chr,RM,f4e,whr,Ahr,gY,Lhr,yhr,xhr,PM,g4e,$hr,khr,hY,Shr,Rhr,Phr,BM,h4e,Bhr,Ihr,uY,Nhr,qhr,jhr,IM,u4e,Dhr,Ghr,pY,Ohr,Vhr,Xhr,NM,p4e,zhr,Qhr,_Y,Whr,Uhr,Hhr,qM,_4e,Jhr,Yhr,bY,Zhr,Khr,eur,jM,b4e,our,rur,vY,tur,aur,nur,DM,v4e,sur,lur,FY,iur,dur,cur,GM,F4e,mur,fur,TY,gur,hur,uur,OM,T4e,pur,_ur,MY,bur,vur,Fur,VM,M4e,Tur,Mur,EY,Eur,Cur,wur,XM,E4e,Aur,Lur,CY,yur,xur,$ur,zM,C4e,kur,Sur,wY,Rur,Pur,Bur,QM,Iur,w4e,Nur,qur,A4e,jur,Dur,WM,_to,ec,UM,L4e,gk,Gur,y4e,Our,bto,Xo,hk,Vur,oc,Xur,AY,zur,Qur,LY,Wur,Uur,Hur,uk,Jur,x4e,Yur,Zur,Kur,xt,pk,epr,$4e,opr,rpr,rc,tpr,k4e,apr,npr,yY,spr,lpr,ipr,HM,dpr,lo,_k,cpr,S4e,mpr,fpr,gn,gpr,R4e,hpr,upr,P4e,ppr,_pr,B4e,bpr,vpr,Fpr,Ue,JM,I4e,Tpr,Mpr,xY,Epr,Cpr,wpr,YM,N4e,Apr,Lpr,$Y,ypr,xpr,$pr,ZM,q4e,kpr,Spr,kY,Rpr,Ppr,Bpr,KM,j4e,Ipr,Npr,SY,qpr,jpr,Dpr,eE,D4e,Gpr,Opr,RY,Vpr,Xpr,zpr,oE,G4e,Qpr,Wpr,PY,Upr,Hpr,Jpr,rE,O4e,Ypr,Zpr,BY,Kpr,e_r,o_r,tE,r_r,V4e,t_r,a_r,X4e,n_r,s_r,aE,vto,tc,nE,z4e,bk,l_r,Q4e,i_r,Fto,zo,vk,d_r,ac,c_r,IY,m_r,f_r,NY,g_r,h_r,u_r,Fk,p_r,W4e,__r,b_r,v_r,$t,Tk,F_r,U4e,T_r,M_r,nc,E_r,H4e,C_r,w_r,qY,A_r,L_r,y_r,sE,x_r,io,Mk,$_r,J4e,k_r,S_r,hn,R_r,Y4e,P_r,B_r,Z4e,I_r,N_r,K4e,q_r,j_r,D_r,U,lE,eCe,G_r,O_r,jY,V_r,X_r,z_r,iE,oCe,Q_r,W_r,DY,U_r,H_r,J_r,dE,rCe,Y_r,Z_r,GY,K_r,e1r,o1r,cE,tCe,r1r,t1r,OY,a1r,n1r,s1r,mE,aCe,l1r,i1r,VY,d1r,c1r,m1r,fE,nCe,f1r,g1r,XY,h1r,u1r,p1r,gE,sCe,_1r,b1r,zY,v1r,F1r,T1r,hE,lCe,M1r,E1r,QY,C1r,w1r,A1r,uE,iCe,L1r,y1r,WY,x1r,$1r,k1r,pE,dCe,S1r,R1r,UY,P1r,B1r,I1r,_E,cCe,N1r,q1r,HY,j1r,D1r,G1r,bE,mCe,O1r,V1r,JY,X1r,z1r,Q1r,vE,fCe,W1r,U1r,YY,H1r,J1r,Y1r,FE,gCe,Z1r,K1r,ZY,e2r,o2r,r2r,TE,hCe,t2r,a2r,KY,n2r,s2r,l2r,ME,uCe,i2r,d2r,eZ,c2r,m2r,f2r,EE,pCe,g2r,h2r,oZ,u2r,p2r,_2r,CE,_Ce,b2r,v2r,rZ,F2r,T2r,M2r,wE,bCe,E2r,C2r,tZ,w2r,A2r,L2r,AE,vCe,y2r,x2r,aZ,$2r,k2r,S2r,LE,FCe,R2r,P2r,nZ,B2r,I2r,N2r,yE,TCe,q2r,j2r,sZ,D2r,G2r,O2r,xE,MCe,V2r,X2r,lZ,z2r,Q2r,W2r,$E,ECe,U2r,H2r,iZ,J2r,Y2r,Z2r,kE,CCe,K2r,ebr,dZ,obr,rbr,tbr,SE,wCe,abr,nbr,cZ,sbr,lbr,ibr,RE,ACe,dbr,cbr,mZ,mbr,fbr,gbr,PE,LCe,hbr,ubr,fZ,pbr,_br,bbr,BE,yCe,vbr,Fbr,gZ,Tbr,Mbr,Ebr,IE,xCe,Cbr,wbr,hZ,Abr,Lbr,ybr,NE,$Ce,xbr,$br,uZ,kbr,Sbr,Rbr,qE,kCe,Pbr,Bbr,pZ,Ibr,Nbr,qbr,jE,SCe,jbr,Dbr,_Z,Gbr,Obr,Vbr,DE,RCe,Xbr,zbr,bZ,Qbr,Wbr,Ubr,GE,PCe,Hbr,Jbr,vZ,Ybr,Zbr,Kbr,OE,BCe,evr,ovr,FZ,rvr,tvr,avr,VE,ICe,nvr,svr,TZ,lvr,ivr,dvr,XE,NCe,cvr,mvr,MZ,fvr,gvr,hvr,zE,qCe,uvr,pvr,EZ,_vr,bvr,vvr,QE,jCe,Fvr,Tvr,CZ,Mvr,Evr,Cvr,WE,DCe,wvr,Avr,wZ,Lvr,yvr,xvr,UE,$vr,GCe,kvr,Svr,OCe,Rvr,Pvr,HE,Tto,sc,JE,VCe,Ek,Bvr,XCe,Ivr,Mto,Qo,Ck,Nvr,lc,qvr,AZ,jvr,Dvr,LZ,Gvr,Ovr,Vvr,wk,Xvr,zCe,zvr,Qvr,Wvr,kt,Ak,Uvr,QCe,Hvr,Jvr,ic,Yvr,WCe,Zvr,Kvr,yZ,eFr,oFr,rFr,YE,tFr,co,Lk,aFr,UCe,nFr,sFr,un,lFr,HCe,iFr,dFr,JCe,cFr,mFr,YCe,fFr,gFr,hFr,O,ZE,ZCe,uFr,pFr,xZ,_Fr,bFr,vFr,KE,KCe,FFr,TFr,$Z,MFr,EFr,CFr,e4,e3e,wFr,AFr,kZ,LFr,yFr,xFr,o4,o3e,$Fr,kFr,SZ,SFr,RFr,PFr,r4,r3e,BFr,IFr,RZ,NFr,qFr,jFr,t4,t3e,DFr,GFr,PZ,OFr,VFr,XFr,a4,a3e,zFr,QFr,BZ,WFr,UFr,HFr,n4,n3e,JFr,YFr,IZ,ZFr,KFr,eTr,s4,s3e,oTr,rTr,NZ,tTr,aTr,nTr,l4,l3e,sTr,lTr,qZ,iTr,dTr,cTr,i4,i3e,mTr,fTr,jZ,gTr,hTr,uTr,d4,d3e,pTr,_Tr,DZ,bTr,vTr,FTr,c4,c3e,TTr,MTr,GZ,ETr,CTr,wTr,m4,m3e,ATr,LTr,OZ,yTr,xTr,$Tr,f4,f3e,kTr,STr,VZ,RTr,PTr,BTr,g4,g3e,ITr,NTr,XZ,qTr,jTr,DTr,h4,h3e,GTr,OTr,zZ,VTr,XTr,zTr,u4,u3e,QTr,WTr,QZ,UTr,HTr,JTr,p4,p3e,YTr,ZTr,WZ,KTr,eMr,oMr,_4,_3e,rMr,tMr,UZ,aMr,nMr,sMr,b4,b3e,lMr,iMr,HZ,dMr,cMr,mMr,v4,v3e,fMr,gMr,JZ,hMr,uMr,pMr,F4,F3e,_Mr,bMr,YZ,vMr,FMr,TMr,T4,T3e,MMr,EMr,ZZ,CMr,wMr,AMr,M4,M3e,LMr,yMr,KZ,xMr,$Mr,kMr,E4,E3e,SMr,RMr,eK,PMr,BMr,IMr,C4,C3e,NMr,qMr,oK,jMr,DMr,GMr,w4,w3e,OMr,VMr,rK,XMr,zMr,QMr,A4,A3e,WMr,UMr,tK,HMr,JMr,YMr,L4,L3e,ZMr,KMr,aK,eEr,oEr,rEr,y4,y3e,tEr,aEr,nK,nEr,sEr,lEr,x4,x3e,iEr,dEr,sK,cEr,mEr,fEr,$4,$3e,gEr,hEr,lK,uEr,pEr,_Er,k4,k3e,bEr,vEr,iK,FEr,TEr,MEr,S4,S3e,EEr,CEr,dK,wEr,AEr,LEr,R4,R3e,yEr,xEr,cK,$Er,kEr,SEr,P4,P3e,REr,PEr,mK,BEr,IEr,NEr,B4,B3e,qEr,jEr,fK,DEr,GEr,OEr,I4,I3e,VEr,XEr,gK,zEr,QEr,WEr,N4,N3e,UEr,HEr,hK,JEr,YEr,ZEr,q4,q3e,KEr,e4r,uK,o4r,r4r,t4r,j4,j3e,a4r,n4r,pK,s4r,l4r,i4r,D4,D3e,d4r,c4r,_K,m4r,f4r,g4r,G4,G3e,h4r,u4r,bK,p4r,_4r,b4r,O4,O3e,v4r,F4r,vK,T4r,M4r,E4r,V4,V3e,C4r,w4r,FK,A4r,L4r,y4r,X4,X3e,x4r,$4r,TK,k4r,S4r,R4r,z4,z3e,P4r,B4r,MK,I4r,N4r,q4r,Q4,j4r,Q3e,D4r,G4r,W3e,O4r,V4r,W4,Eto,dc,U4,U3e,yk,X4r,H3e,z4r,Cto,Wo,xk,Q4r,cc,W4r,EK,U4r,H4r,CK,J4r,Y4r,Z4r,$k,K4r,J3e,eCr,oCr,rCr,St,kk,tCr,Y3e,aCr,nCr,mc,sCr,Z3e,lCr,iCr,wK,dCr,cCr,mCr,H4,fCr,mo,Sk,gCr,K3e,hCr,uCr,pn,pCr,e5e,_Cr,bCr,o5e,vCr,FCr,r5e,TCr,MCr,ECr,t5e,J4,a5e,CCr,wCr,AK,ACr,LCr,yCr,Y4,xCr,n5e,$Cr,kCr,s5e,SCr,RCr,Z4,wto,fc,K4,l5e,Rk,PCr,i5e,BCr,Ato,Uo,Pk,ICr,gc,NCr,LK,qCr,jCr,yK,DCr,GCr,OCr,Bk,VCr,d5e,XCr,zCr,QCr,Rt,Ik,WCr,c5e,UCr,HCr,hc,JCr,m5e,YCr,ZCr,xK,KCr,e3r,o3r,eC,r3r,fo,Nk,t3r,f5e,a3r,n3r,_n,s3r,g5e,l3r,i3r,h5e,d3r,c3r,u5e,m3r,f3r,g3r,uc,oC,p5e,h3r,u3r,$K,p3r,_3r,b3r,rC,_5e,v3r,F3r,kK,T3r,M3r,E3r,tC,b5e,C3r,w3r,SK,A3r,L3r,y3r,aC,x3r,v5e,$3r,k3r,F5e,S3r,R3r,nC,Lto,pc,sC,T5e,qk,P3r,M5e,B3r,yto,Ho,jk,I3r,_c,N3r,RK,q3r,j3r,PK,D3r,G3r,O3r,Dk,V3r,E5e,X3r,z3r,Q3r,Pt,Gk,W3r,C5e,U3r,H3r,bc,J3r,w5e,Y3r,Z3r,BK,K3r,e5r,o5r,lC,r5r,go,Ok,t5r,A5e,a5r,n5r,bn,s5r,L5e,l5r,i5r,y5e,d5r,c5r,x5e,m5r,f5r,g5r,be,iC,$5e,h5r,u5r,IK,p5r,_5r,b5r,dC,k5e,v5r,F5r,NK,T5r,M5r,E5r,cC,S5e,C5r,w5r,qK,A5r,L5r,y5r,mC,R5e,x5r,$5r,jK,k5r,S5r,R5r,xl,P5e,P5r,B5r,DK,I5r,N5r,GK,q5r,j5r,D5r,fC,B5e,G5r,O5r,OK,V5r,X5r,z5r,$l,I5e,Q5r,W5r,VK,U5r,H5r,XK,J5r,Y5r,Z5r,gC,N5e,K5r,e0r,zK,o0r,r0r,t0r,Bt,q5e,a0r,n0r,QK,s0r,l0r,WK,i0r,d0r,UK,c0r,m0r,f0r,hC,j5e,g0r,h0r,HK,u0r,p0r,_0r,uC,D5e,b0r,v0r,JK,F0r,T0r,M0r,pC,G5e,E0r,C0r,YK,w0r,A0r,L0r,_C,O5e,y0r,x0r,ZK,$0r,k0r,S0r,bC,V5e,R0r,P0r,KK,B0r,I0r,N0r,vC,X5e,q0r,j0r,eee,D0r,G0r,O0r,FC,z5e,V0r,X0r,oee,z0r,Q0r,W0r,TC,Q5e,U0r,H0r,ree,J0r,Y0r,Z0r,MC,W5e,K0r,ewr,tee,owr,rwr,twr,EC,awr,U5e,nwr,swr,H5e,lwr,iwr,CC,xto,vc,wC,J5e,Vk,dwr,Y5e,cwr,$to,Jo,Xk,mwr,Fc,fwr,aee,gwr,hwr,nee,uwr,pwr,_wr,zk,bwr,Z5e,vwr,Fwr,Twr,It,Qk,Mwr,K5e,Ewr,Cwr,Tc,wwr,e0e,Awr,Lwr,see,ywr,xwr,$wr,AC,kwr,ho,Wk,Swr,o0e,Rwr,Pwr,vn,Bwr,r0e,Iwr,Nwr,t0e,qwr,jwr,a0e,Dwr,Gwr,Owr,n0e,LC,s0e,Vwr,Xwr,lee,zwr,Qwr,Wwr,yC,Uwr,l0e,Hwr,Jwr,i0e,Ywr,Zwr,xC,kto,Mc,$C,d0e,Uk,Kwr,c0e,eAr,Sto,Yo,Hk,oAr,Ec,rAr,iee,tAr,aAr,dee,nAr,sAr,lAr,Jk,iAr,m0e,dAr,cAr,mAr,Nt,Yk,fAr,f0e,gAr,hAr,Cc,uAr,g0e,pAr,_Ar,cee,bAr,vAr,FAr,kC,TAr,uo,Zk,MAr,h0e,EAr,CAr,Fn,wAr,u0e,AAr,LAr,p0e,yAr,xAr,_0e,$Ar,kAr,SAr,b0e,SC,v0e,RAr,PAr,mee,BAr,IAr,NAr,RC,qAr,F0e,jAr,DAr,T0e,GAr,OAr,PC,Rto,wc,BC,M0e,Kk,VAr,E0e,XAr,Pto,Zo,eS,zAr,Ac,QAr,fee,WAr,UAr,gee,HAr,JAr,YAr,oS,ZAr,C0e,KAr,e6r,o6r,qt,rS,r6r,w0e,t6r,a6r,Lc,n6r,A0e,s6r,l6r,hee,i6r,d6r,c6r,IC,m6r,po,tS,f6r,L0e,g6r,h6r,Tn,u6r,y0e,p6r,_6r,x0e,b6r,v6r,$0e,F6r,T6r,M6r,k0e,NC,S0e,E6r,C6r,uee,w6r,A6r,L6r,qC,y6r,R0e,x6r,$6r,P0e,k6r,S6r,jC,Bto,yc,DC,B0e,aS,R6r,I0e,P6r,Ito,Ko,nS,B6r,xc,I6r,pee,N6r,q6r,_ee,j6r,D6r,G6r,sS,O6r,N0e,V6r,X6r,z6r,jt,lS,Q6r,q0e,W6r,U6r,$c,H6r,j0e,J6r,Y6r,bee,Z6r,K6r,e7r,GC,o7r,_o,iS,r7r,D0e,t7r,a7r,Mn,n7r,G0e,s7r,l7r,O0e,i7r,d7r,V0e,c7r,m7r,f7r,Be,OC,X0e,g7r,h7r,vee,u7r,p7r,_7r,VC,z0e,b7r,v7r,Fee,F7r,T7r,M7r,XC,Q0e,E7r,C7r,Tee,w7r,A7r,L7r,zC,W0e,y7r,x7r,Mee,$7r,k7r,S7r,QC,U0e,R7r,P7r,Eee,B7r,I7r,N7r,WC,H0e,q7r,j7r,Cee,D7r,G7r,O7r,UC,J0e,V7r,X7r,wee,z7r,Q7r,W7r,HC,Y0e,U7r,H7r,Aee,J7r,Y7r,Z7r,JC,Z0e,K7r,eLr,Lee,oLr,rLr,tLr,YC,aLr,K0e,nLr,sLr,ewe,lLr,iLr,ZC,Nto,kc,KC,owe,dS,dLr,rwe,cLr,qto,er,cS,mLr,Sc,fLr,yee,gLr,hLr,xee,uLr,pLr,_Lr,mS,bLr,twe,vLr,FLr,TLr,Dt,fS,MLr,awe,ELr,CLr,Rc,wLr,nwe,ALr,LLr,$ee,yLr,xLr,$Lr,e3,kLr,bo,gS,SLr,swe,RLr,PLr,En,BLr,lwe,ILr,NLr,iwe,qLr,jLr,dwe,DLr,GLr,OLr,ut,o3,cwe,VLr,XLr,kee,zLr,QLr,WLr,r3,mwe,ULr,HLr,See,JLr,YLr,ZLr,t3,fwe,KLr,e8r,Ree,o8r,r8r,t8r,a3,gwe,a8r,n8r,Pee,s8r,l8r,i8r,n3,hwe,d8r,c8r,Bee,m8r,f8r,g8r,s3,h8r,uwe,u8r,p8r,pwe,_8r,b8r,l3,jto,Pc,i3,_we,hS,v8r,bwe,F8r,Dto,or,uS,T8r,Bc,M8r,Iee,E8r,C8r,Nee,w8r,A8r,L8r,pS,y8r,vwe,x8r,$8r,k8r,Gt,_S,S8r,Fwe,R8r,P8r,Ic,B8r,Twe,I8r,N8r,qee,q8r,j8r,D8r,d3,G8r,vo,bS,O8r,Mwe,V8r,X8r,Cn,z8r,Ewe,Q8r,W8r,Cwe,U8r,H8r,wwe,J8r,Y8r,Z8r,Le,c3,Awe,K8r,eyr,jee,oyr,ryr,tyr,m3,Lwe,ayr,nyr,Dee,syr,lyr,iyr,f3,ywe,dyr,cyr,Gee,myr,fyr,gyr,g3,xwe,hyr,uyr,Oee,pyr,_yr,byr,h3,$we,vyr,Fyr,Vee,Tyr,Myr,Eyr,u3,kwe,Cyr,wyr,Xee,Ayr,Lyr,yyr,p3,Swe,xyr,$yr,zee,kyr,Syr,Ryr,_3,Rwe,Pyr,Byr,Qee,Iyr,Nyr,qyr,b3,Pwe,jyr,Dyr,Wee,Gyr,Oyr,Vyr,v3,Bwe,Xyr,zyr,Uee,Qyr,Wyr,Uyr,F3,Hyr,Iwe,Jyr,Yyr,Nwe,Zyr,Kyr,T3,Gto,Nc,M3,qwe,vS,e9r,jwe,o9r,Oto,rr,FS,r9r,qc,t9r,Hee,a9r,n9r,Jee,s9r,l9r,i9r,TS,d9r,Dwe,c9r,m9r,f9r,Ot,MS,g9r,Gwe,h9r,u9r,jc,p9r,Owe,_9r,b9r,Yee,v9r,F9r,T9r,E3,M9r,Fo,ES,E9r,Vwe,C9r,w9r,wn,A9r,Xwe,L9r,y9r,zwe,x9r,$9r,Qwe,k9r,S9r,R9r,Dc,C3,Wwe,P9r,B9r,Zee,I9r,N9r,q9r,w3,Uwe,j9r,D9r,Kee,G9r,O9r,V9r,A3,Hwe,X9r,z9r,eoe,Q9r,W9r,U9r,L3,H9r,Jwe,J9r,Y9r,Ywe,Z9r,K9r,y3,Vto,Gc,x3,Zwe,CS,exr,Kwe,oxr,Xto,tr,wS,rxr,Oc,txr,ooe,axr,nxr,roe,sxr,lxr,ixr,AS,dxr,eAe,cxr,mxr,fxr,Vt,LS,gxr,oAe,hxr,uxr,Vc,pxr,rAe,_xr,bxr,toe,vxr,Fxr,Txr,$3,Mxr,To,yS,Exr,tAe,Cxr,wxr,An,Axr,aAe,Lxr,yxr,nAe,xxr,$xr,sAe,kxr,Sxr,Rxr,pt,k3,lAe,Pxr,Bxr,aoe,Ixr,Nxr,qxr,S3,iAe,jxr,Dxr,noe,Gxr,Oxr,Vxr,R3,dAe,Xxr,zxr,soe,Qxr,Wxr,Uxr,P3,cAe,Hxr,Jxr,loe,Yxr,Zxr,Kxr,B3,mAe,e$r,o$r,ioe,r$r,t$r,a$r,I3,n$r,fAe,s$r,l$r,gAe,i$r,d$r,N3,zto,Xc,q3,hAe,xS,c$r,uAe,m$r,Qto,ar,$S,f$r,zc,g$r,doe,h$r,u$r,coe,p$r,_$r,b$r,kS,v$r,pAe,F$r,T$r,M$r,Xt,SS,E$r,_Ae,C$r,w$r,Qc,A$r,bAe,L$r,y$r,moe,x$r,$$r,k$r,j3,S$r,Mo,RS,R$r,vAe,P$r,B$r,Ln,I$r,FAe,N$r,q$r,TAe,j$r,D$r,MAe,G$r,O$r,V$r,yn,D3,EAe,X$r,z$r,foe,Q$r,W$r,U$r,G3,CAe,H$r,J$r,goe,Y$r,Z$r,K$r,O3,wAe,ekr,okr,hoe,rkr,tkr,akr,V3,AAe,nkr,skr,uoe,lkr,ikr,dkr,X3,ckr,LAe,mkr,fkr,yAe,gkr,hkr,z3,Wto,Wc,Q3,xAe,PS,ukr,$Ae,pkr,Uto,nr,BS,_kr,Uc,bkr,poe,vkr,Fkr,_oe,Tkr,Mkr,Ekr,IS,Ckr,kAe,wkr,Akr,Lkr,zt,NS,ykr,SAe,xkr,$kr,Hc,kkr,RAe,Skr,Rkr,boe,Pkr,Bkr,Ikr,W3,Nkr,Eo,qS,qkr,PAe,jkr,Dkr,xn,Gkr,BAe,Okr,Vkr,IAe,Xkr,zkr,NAe,Qkr,Wkr,Ukr,$n,U3,qAe,Hkr,Jkr,voe,Ykr,Zkr,Kkr,H3,jAe,eSr,oSr,Foe,rSr,tSr,aSr,J3,DAe,nSr,sSr,Toe,lSr,iSr,dSr,Y3,GAe,cSr,mSr,Moe,fSr,gSr,hSr,Z3,uSr,OAe,pSr,_Sr,VAe,bSr,vSr,K3,Hto,Jc,e5,XAe,jS,FSr,zAe,TSr,Jto,sr,DS,MSr,Yc,ESr,Eoe,CSr,wSr,Coe,ASr,LSr,ySr,GS,xSr,QAe,$Sr,kSr,SSr,Qt,OS,RSr,WAe,PSr,BSr,Zc,ISr,UAe,NSr,qSr,woe,jSr,DSr,GSr,o5,OSr,Co,VS,VSr,HAe,XSr,zSr,kn,QSr,JAe,WSr,USr,YAe,HSr,JSr,ZAe,YSr,ZSr,KSr,KAe,r5,e6e,eRr,oRr,Aoe,rRr,tRr,aRr,t5,nRr,o6e,sRr,lRr,r6e,iRr,dRr,a5,Yto,Kc,n5,t6e,XS,cRr,a6e,mRr,Zto,lr,zS,fRr,em,gRr,Loe,hRr,uRr,yoe,pRr,_Rr,bRr,QS,vRr,n6e,FRr,TRr,MRr,Wt,WS,ERr,s6e,CRr,wRr,om,ARr,l6e,LRr,yRr,xoe,xRr,$Rr,kRr,s5,SRr,wo,US,RRr,i6e,PRr,BRr,Sn,IRr,d6e,NRr,qRr,c6e,jRr,DRr,m6e,GRr,ORr,VRr,_t,l5,f6e,XRr,zRr,$oe,QRr,WRr,URr,i5,g6e,HRr,JRr,koe,YRr,ZRr,KRr,d5,h6e,ePr,oPr,Soe,rPr,tPr,aPr,c5,u6e,nPr,sPr,Roe,lPr,iPr,dPr,m5,p6e,cPr,mPr,Poe,fPr,gPr,hPr,f5,uPr,_6e,pPr,_Pr,b6e,bPr,vPr,g5,Kto,rm,h5,v6e,HS,FPr,F6e,TPr,eao,ir,JS,MPr,tm,EPr,Boe,CPr,wPr,Ioe,APr,LPr,yPr,YS,xPr,T6e,$Pr,kPr,SPr,Ut,ZS,RPr,M6e,PPr,BPr,am,IPr,E6e,NPr,qPr,Noe,jPr,DPr,GPr,u5,OPr,Ao,KS,VPr,C6e,XPr,zPr,Rn,QPr,w6e,WPr,UPr,A6e,HPr,JPr,L6e,YPr,ZPr,KPr,y6e,p5,x6e,eBr,oBr,qoe,rBr,tBr,aBr,_5,nBr,$6e,sBr,lBr,k6e,iBr,dBr,b5,oao,nm,v5,S6e,eR,cBr,R6e,mBr,rao,dr,oR,fBr,sm,gBr,joe,hBr,uBr,Doe,pBr,_Br,bBr,rR,vBr,P6e,FBr,TBr,MBr,Ht,tR,EBr,B6e,CBr,wBr,lm,ABr,I6e,LBr,yBr,Goe,xBr,$Br,kBr,F5,SBr,Lo,aR,RBr,N6e,PBr,BBr,Pn,IBr,q6e,NBr,qBr,j6e,jBr,DBr,D6e,GBr,OBr,VBr,G6e,T5,O6e,XBr,zBr,Ooe,QBr,WBr,UBr,M5,HBr,V6e,JBr,YBr,X6e,ZBr,KBr,E5,tao,im,C5,z6e,nR,eIr,Q6e,oIr,aao,cr,sR,rIr,dm,tIr,Voe,aIr,nIr,Xoe,sIr,lIr,iIr,lR,dIr,W6e,cIr,mIr,fIr,Jt,iR,gIr,U6e,hIr,uIr,cm,pIr,H6e,_Ir,bIr,zoe,vIr,FIr,TIr,w5,MIr,Dr,dR,EIr,J6e,CIr,wIr,Bn,AIr,Y6e,LIr,yIr,Z6e,xIr,$Ir,K6e,kIr,SIr,RIr,B,A5,e7e,PIr,BIr,Qoe,IIr,NIr,qIr,L5,o7e,jIr,DIr,Woe,GIr,OIr,VIr,y5,r7e,XIr,zIr,Uoe,QIr,WIr,UIr,x5,t7e,HIr,JIr,Hoe,YIr,ZIr,KIr,$5,a7e,eNr,oNr,Joe,rNr,tNr,aNr,k5,n7e,nNr,sNr,Yoe,lNr,iNr,dNr,S5,s7e,cNr,mNr,Zoe,fNr,gNr,hNr,R5,l7e,uNr,pNr,Koe,_Nr,bNr,vNr,P5,i7e,FNr,TNr,ere,MNr,ENr,CNr,B5,d7e,wNr,ANr,ore,LNr,yNr,xNr,I5,c7e,$Nr,kNr,rre,SNr,RNr,PNr,N5,m7e,BNr,INr,tre,NNr,qNr,jNr,q5,f7e,DNr,GNr,are,ONr,VNr,XNr,j5,g7e,zNr,QNr,nre,WNr,UNr,HNr,D5,h7e,JNr,YNr,sre,ZNr,KNr,eqr,G5,u7e,oqr,rqr,lre,tqr,aqr,nqr,O5,p7e,sqr,lqr,ire,iqr,dqr,cqr,V5,_7e,mqr,fqr,dre,gqr,hqr,uqr,X5,b7e,pqr,_qr,cre,bqr,vqr,Fqr,kl,v7e,Tqr,Mqr,mre,Eqr,Cqr,fre,wqr,Aqr,Lqr,z5,F7e,yqr,xqr,gre,$qr,kqr,Sqr,Q5,T7e,Rqr,Pqr,hre,Bqr,Iqr,Nqr,W5,M7e,qqr,jqr,ure,Dqr,Gqr,Oqr,U5,E7e,Vqr,Xqr,pre,zqr,Qqr,Wqr,H5,C7e,Uqr,Hqr,_re,Jqr,Yqr,Zqr,J5,w7e,Kqr,ejr,bre,ojr,rjr,tjr,Y5,A7e,ajr,njr,vre,sjr,ljr,ijr,Z5,L7e,djr,cjr,Fre,mjr,fjr,gjr,K5,y7e,hjr,ujr,Tre,pjr,_jr,bjr,e0,x7e,vjr,Fjr,Mre,Tjr,Mjr,Ejr,o0,$7e,Cjr,wjr,Ere,Ajr,Ljr,yjr,r0,k7e,xjr,$jr,Cre,kjr,Sjr,Rjr,t0,S7e,Pjr,Bjr,wre,Ijr,Njr,qjr,a0,R7e,jjr,Djr,Are,Gjr,Ojr,Vjr,n0,P7e,Xjr,zjr,Lre,Qjr,Wjr,Ujr,s0,B7e,Hjr,Jjr,yre,Yjr,Zjr,Kjr,l0,I7e,eDr,oDr,xre,rDr,tDr,aDr,i0,N7e,nDr,sDr,$re,lDr,iDr,dDr,d0,q7e,cDr,mDr,kre,fDr,gDr,hDr,c0,j7e,uDr,pDr,Sre,_Dr,bDr,vDr,m0,D7e,FDr,TDr,Rre,MDr,EDr,CDr,f0,G7e,wDr,ADr,Pre,LDr,yDr,xDr,g0,O7e,$Dr,kDr,Bre,SDr,RDr,PDr,h0,V7e,BDr,IDr,Ire,NDr,qDr,jDr,u0,X7e,DDr,GDr,Nre,ODr,VDr,XDr,p0,z7e,zDr,QDr,qre,WDr,UDr,HDr,_0,Q7e,JDr,YDr,jre,ZDr,KDr,eGr,b0,W7e,oGr,rGr,Dre,tGr,aGr,nGr,v0,U7e,sGr,lGr,Gre,iGr,dGr,cGr,F0,H7e,mGr,fGr,Ore,gGr,hGr,uGr,T0,J7e,pGr,_Gr,Vre,bGr,vGr,FGr,M0,Y7e,TGr,MGr,Xre,EGr,CGr,wGr,E0,Z7e,AGr,LGr,zre,yGr,xGr,$Gr,C0,K7e,kGr,SGr,Qre,RGr,PGr,BGr,w0,eLe,IGr,NGr,Wre,qGr,jGr,DGr,A0,oLe,GGr,OGr,Ure,VGr,XGr,zGr,L0,rLe,QGr,WGr,Hre,UGr,HGr,JGr,y0,nao,mm,x0,tLe,cR,YGr,aLe,ZGr,sao,mr,mR,KGr,fm,eOr,Jre,oOr,rOr,Yre,tOr,aOr,nOr,fR,sOr,nLe,lOr,iOr,dOr,Yt,gR,cOr,sLe,mOr,fOr,gm,gOr,lLe,hOr,uOr,Zre,pOr,_Or,bOr,$0,vOr,Gr,hR,FOr,iLe,TOr,MOr,In,EOr,dLe,COr,wOr,cLe,AOr,LOr,mLe,yOr,xOr,$Or,le,k0,fLe,kOr,SOr,Kre,ROr,POr,BOr,S0,gLe,IOr,NOr,ete,qOr,jOr,DOr,R0,hLe,GOr,OOr,ote,VOr,XOr,zOr,P0,uLe,QOr,WOr,rte,UOr,HOr,JOr,B0,pLe,YOr,ZOr,tte,KOr,eVr,oVr,I0,_Le,rVr,tVr,ate,aVr,nVr,sVr,N0,bLe,lVr,iVr,nte,dVr,cVr,mVr,q0,vLe,fVr,gVr,ste,hVr,uVr,pVr,j0,FLe,_Vr,bVr,lte,vVr,FVr,TVr,D0,TLe,MVr,EVr,ite,CVr,wVr,AVr,G0,MLe,LVr,yVr,dte,xVr,$Vr,kVr,O0,ELe,SVr,RVr,cte,PVr,BVr,IVr,V0,CLe,NVr,qVr,mte,jVr,DVr,GVr,X0,wLe,OVr,VVr,fte,XVr,zVr,QVr,z0,ALe,WVr,UVr,gte,HVr,JVr,YVr,Q0,LLe,ZVr,KVr,hte,eXr,oXr,rXr,W0,yLe,tXr,aXr,ute,nXr,sXr,lXr,U0,xLe,iXr,dXr,pte,cXr,mXr,fXr,H0,$Le,gXr,hXr,_te,uXr,pXr,_Xr,J0,kLe,bXr,vXr,bte,FXr,TXr,MXr,Y0,SLe,EXr,CXr,vte,wXr,AXr,LXr,Z0,RLe,yXr,xXr,Fte,$Xr,kXr,SXr,K0,PLe,RXr,PXr,Tte,BXr,IXr,NXr,ew,lao,hm,ow,BLe,uR,qXr,ILe,jXr,iao,fr,pR,DXr,um,GXr,Mte,OXr,VXr,Ete,XXr,zXr,QXr,_R,WXr,NLe,UXr,HXr,JXr,Zt,bR,YXr,qLe,ZXr,KXr,pm,ezr,jLe,ozr,rzr,Cte,tzr,azr,nzr,rw,szr,Or,vR,lzr,DLe,izr,dzr,Nn,czr,GLe,mzr,fzr,OLe,gzr,hzr,VLe,uzr,pzr,_zr,Me,tw,XLe,bzr,vzr,wte,Fzr,Tzr,Mzr,aw,zLe,Ezr,Czr,Ate,wzr,Azr,Lzr,nw,QLe,yzr,xzr,Lte,$zr,kzr,Szr,sw,WLe,Rzr,Pzr,yte,Bzr,Izr,Nzr,lw,ULe,qzr,jzr,xte,Dzr,Gzr,Ozr,iw,HLe,Vzr,Xzr,$te,zzr,Qzr,Wzr,dw,JLe,Uzr,Hzr,kte,Jzr,Yzr,Zzr,cw,YLe,Kzr,eQr,Ste,oQr,rQr,tQr,mw,ZLe,aQr,nQr,Rte,sQr,lQr,iQr,fw,KLe,dQr,cQr,Pte,mQr,fQr,gQr,gw,e8e,hQr,uQr,Bte,pQr,_Qr,bQr,hw,o8e,vQr,FQr,Ite,TQr,MQr,EQr,uw,r8e,CQr,wQr,Nte,AQr,LQr,yQr,pw,t8e,xQr,$Qr,qte,kQr,SQr,RQr,_w,dao,_m,bw,a8e,FR,PQr,n8e,BQr,cao,gr,TR,IQr,bm,NQr,jte,qQr,jQr,Dte,DQr,GQr,OQr,MR,VQr,s8e,XQr,zQr,QQr,Kt,ER,WQr,l8e,UQr,HQr,vm,JQr,i8e,YQr,ZQr,Gte,KQr,eWr,oWr,vw,rWr,Vr,CR,tWr,d8e,aWr,nWr,qn,sWr,c8e,lWr,iWr,m8e,dWr,cWr,f8e,mWr,fWr,gWr,ye,Fw,g8e,hWr,uWr,Ote,pWr,_Wr,bWr,Tw,h8e,vWr,FWr,Vte,TWr,MWr,EWr,Mw,u8e,CWr,wWr,Xte,AWr,LWr,yWr,Sl,p8e,xWr,$Wr,zte,kWr,SWr,Qte,RWr,PWr,BWr,Ew,_8e,IWr,NWr,Wte,qWr,jWr,DWr,Cw,b8e,GWr,OWr,Ute,VWr,XWr,zWr,ww,v8e,QWr,WWr,Hte,UWr,HWr,JWr,Aw,F8e,YWr,ZWr,Jte,KWr,eUr,oUr,Lw,T8e,rUr,tUr,Yte,aUr,nUr,sUr,yw,M8e,lUr,iUr,Zte,dUr,cUr,mUr,xw,mao,Fm,$w,E8e,wR,fUr,C8e,gUr,fao,hr,AR,hUr,Tm,uUr,Kte,pUr,_Ur,eae,bUr,vUr,FUr,LR,TUr,w8e,MUr,EUr,CUr,ea,yR,wUr,A8e,AUr,LUr,Mm,yUr,L8e,xUr,$Ur,oae,kUr,SUr,RUr,kw,PUr,Xr,xR,BUr,y8e,IUr,NUr,jn,qUr,x8e,jUr,DUr,$8e,GUr,OUr,k8e,VUr,XUr,zUr,Em,Sw,S8e,QUr,WUr,rae,UUr,HUr,JUr,Rw,R8e,YUr,ZUr,tae,KUr,eHr,oHr,Pw,P8e,rHr,tHr,aae,aHr,nHr,sHr,Bw,gao,Cm,Iw,B8e,$R,lHr,I8e,iHr,hao,ur,kR,dHr,wm,cHr,nae,mHr,fHr,sae,gHr,hHr,uHr,SR,pHr,N8e,_Hr,bHr,vHr,oa,RR,FHr,q8e,THr,MHr,Am,EHr,j8e,CHr,wHr,lae,AHr,LHr,yHr,Nw,xHr,zr,PR,$Hr,D8e,kHr,SHr,Dn,RHr,G8e,PHr,BHr,O8e,IHr,NHr,V8e,qHr,jHr,DHr,ge,qw,X8e,GHr,OHr,iae,VHr,XHr,zHr,jw,z8e,QHr,WHr,dae,UHr,HHr,JHr,Dw,Q8e,YHr,ZHr,cae,KHr,eJr,oJr,Gw,W8e,rJr,tJr,mae,aJr,nJr,sJr,Ow,U8e,lJr,iJr,fae,dJr,cJr,mJr,Vw,H8e,fJr,gJr,gae,hJr,uJr,pJr,Xw,J8e,_Jr,bJr,hae,vJr,FJr,TJr,zw,Y8e,MJr,EJr,uae,CJr,wJr,AJr,Qw,Z8e,LJr,yJr,pae,xJr,$Jr,kJr,Ww,K8e,SJr,RJr,_ae,PJr,BJr,IJr,Uw,eye,NJr,qJr,bae,jJr,DJr,GJr,Hw,oye,OJr,VJr,vae,XJr,zJr,QJr,Jw,rye,WJr,UJr,Fae,HJr,JJr,YJr,Yw,tye,ZJr,KJr,Tae,eYr,oYr,rYr,Zw,aye,tYr,aYr,Mae,nYr,sYr,lYr,Kw,nye,iYr,dYr,Eae,cYr,mYr,fYr,eA,sye,gYr,hYr,Cae,uYr,pYr,_Yr,oA,lye,bYr,vYr,wae,FYr,TYr,MYr,rA,iye,EYr,CYr,Aae,wYr,AYr,LYr,tA,dye,yYr,xYr,Lae,$Yr,kYr,SYr,aA,uao,Lm,nA,cye,BR,RYr,mye,PYr,pao,pr,IR,BYr,ym,IYr,yae,NYr,qYr,xae,jYr,DYr,GYr,NR,OYr,fye,VYr,XYr,zYr,ra,qR,QYr,gye,WYr,UYr,xm,HYr,hye,JYr,YYr,$ae,ZYr,KYr,eZr,sA,oZr,Qr,jR,rZr,uye,tZr,aZr,Gn,nZr,pye,sZr,lZr,_ye,iZr,dZr,bye,cZr,mZr,fZr,xe,lA,vye,gZr,hZr,kae,uZr,pZr,_Zr,iA,Fye,bZr,vZr,Sae,FZr,TZr,MZr,dA,Tye,EZr,CZr,Rae,wZr,AZr,LZr,cA,Mye,yZr,xZr,Pae,$Zr,kZr,SZr,mA,Eye,RZr,PZr,Bae,BZr,IZr,NZr,fA,Cye,qZr,jZr,Iae,DZr,GZr,OZr,gA,wye,VZr,XZr,Nae,zZr,QZr,WZr,hA,Aye,UZr,HZr,qae,JZr,YZr,ZZr,uA,Lye,KZr,eKr,jae,oKr,rKr,tKr,pA,yye,aKr,nKr,Dae,sKr,lKr,iKr,_A,_ao,$m,bA,xye,DR,dKr,$ye,cKr,bao,_r,GR,mKr,km,fKr,Gae,gKr,hKr,Oae,uKr,pKr,_Kr,OR,bKr,kye,vKr,FKr,TKr,ta,VR,MKr,Sye,EKr,CKr,Sm,wKr,Rye,AKr,LKr,Vae,yKr,xKr,$Kr,vA,kKr,Wr,XR,SKr,Pye,RKr,PKr,On,BKr,Bye,IKr,NKr,Iye,qKr,jKr,Nye,DKr,GKr,OKr,re,FA,qye,VKr,XKr,Xae,zKr,QKr,WKr,TA,jye,UKr,HKr,zae,JKr,YKr,ZKr,MA,Dye,KKr,eet,Qae,oet,ret,tet,EA,Gye,aet,net,Wae,set,iet,det,CA,Oye,cet,met,Uae,fet,get,het,wA,Vye,uet,pet,Hae,_et,bet,vet,AA,Xye,Fet,Tet,Jae,Met,Eet,Cet,LA,zye,wet,Aet,Yae,Let,yet,xet,yA,Qye,$et,ket,Zae,Set,Ret,Pet,xA,Wye,Bet,Iet,Kae,Net,qet,jet,$A,Uye,Det,Get,ene,Oet,Vet,Xet,kA,Hye,zet,Qet,one,Wet,Uet,Het,SA,Jye,Jet,Yet,rne,Zet,Ket,eot,RA,Yye,oot,rot,tne,tot,aot,not,PA,Zye,sot,lot,ane,iot,dot,cot,BA,Kye,mot,fot,nne,got,hot,uot,IA,e9e,pot,_ot,sne,bot,vot,Fot,NA,o9e,Tot,Mot,lne,Eot,Cot,wot,qA,r9e,Aot,Lot,ine,yot,xot,$ot,jA,t9e,kot,Sot,dne,Rot,Pot,Bot,DA,a9e,Iot,Not,cne,qot,jot,Dot,GA,n9e,Got,Oot,mne,Vot,Xot,zot,OA,s9e,Qot,Wot,fne,Uot,Hot,Jot,VA,l9e,Yot,Zot,gne,Kot,ert,ort,XA,i9e,rrt,trt,hne,art,nrt,srt,zA,d9e,lrt,irt,une,drt,crt,mrt,QA,c9e,frt,grt,pne,hrt,urt,prt,WA,vao,Rm,UA,m9e,zR,_rt,f9e,brt,Fao,br,QR,vrt,Pm,Frt,_ne,Trt,Mrt,bne,Ert,Crt,wrt,WR,Art,g9e,Lrt,yrt,xrt,aa,UR,$rt,h9e,krt,Srt,Bm,Rrt,u9e,Prt,Brt,vne,Irt,Nrt,qrt,HA,jrt,Ur,HR,Drt,p9e,Grt,Ort,Vn,Vrt,_9e,Xrt,zrt,b9e,Qrt,Wrt,v9e,Urt,Hrt,Jrt,ve,JA,F9e,Yrt,Zrt,Fne,Krt,ett,ott,YA,T9e,rtt,ttt,Tne,att,ntt,stt,ZA,M9e,ltt,itt,Mne,dtt,ctt,mtt,KA,E9e,ftt,gtt,Ene,htt,utt,ptt,e6,C9e,_tt,btt,Cne,vtt,Ftt,Ttt,o6,w9e,Mtt,Ett,wne,Ctt,wtt,Att,r6,A9e,Ltt,ytt,Ane,xtt,$tt,ktt,t6,L9e,Stt,Rtt,Lne,Ptt,Btt,Itt,a6,y9e,Ntt,qtt,yne,jtt,Dtt,Gtt,n6,x9e,Ott,Vtt,xne,Xtt,ztt,Qtt,s6,$9e,Wtt,Utt,$ne,Htt,Jtt,Ytt,l6,k9e,Ztt,Ktt,kne,eat,oat,rat,i6,S9e,tat,aat,Sne,nat,sat,lat,d6,R9e,iat,dat,Rne,cat,mat,fat,c6,P9e,gat,hat,Pne,uat,pat,_at,m6,B9e,bat,vat,Bne,Fat,Tat,Mat,f6,I9e,Eat,Cat,Ine,wat,Aat,Lat,g6,Tao,Im,h6,N9e,JR,yat,q9e,xat,Mao,vr,YR,$at,Nm,kat,Nne,Sat,Rat,qne,Pat,Bat,Iat,ZR,Nat,j9e,qat,jat,Dat,na,KR,Gat,D9e,Oat,Vat,qm,Xat,G9e,zat,Qat,jne,Wat,Uat,Hat,u6,Jat,Hr,eP,Yat,O9e,Zat,Kat,Xn,ent,V9e,ont,rnt,X9e,tnt,ant,z9e,nnt,snt,lnt,oP,p6,Q9e,int,dnt,Dne,cnt,mnt,fnt,_6,W9e,gnt,hnt,Gne,unt,pnt,_nt,b6,Eao,jm,v6,U9e,rP,bnt,H9e,vnt,Cao,Fr,tP,Fnt,Dm,Tnt,One,Mnt,Ent,Vne,Cnt,wnt,Ant,aP,Lnt,J9e,ynt,xnt,$nt,sa,nP,knt,Y9e,Snt,Rnt,Gm,Pnt,Z9e,Bnt,Int,Xne,Nnt,qnt,jnt,F6,Dnt,Jr,sP,Gnt,K9e,Ont,Vnt,zn,Xnt,exe,znt,Qnt,oxe,Wnt,Unt,rxe,Hnt,Jnt,Ynt,txe,T6,axe,Znt,Knt,zne,est,ost,rst,M6,wao,Om,E6,nxe,lP,tst,sxe,ast,Aao,Tr,iP,nst,Vm,sst,Qne,lst,ist,Wne,dst,cst,mst,dP,fst,lxe,gst,hst,ust,la,cP,pst,ixe,_st,bst,Xm,vst,dxe,Fst,Tst,Une,Mst,Est,Cst,C6,wst,Yr,mP,Ast,cxe,Lst,yst,Qn,xst,mxe,$st,kst,fxe,Sst,Rst,gxe,Pst,Bst,Ist,hxe,w6,uxe,Nst,qst,Hne,jst,Dst,Gst,A6,Lao,zm,L6,pxe,fP,Ost,_xe,Vst,yao,Mr,gP,Xst,Qm,zst,Jne,Qst,Wst,Yne,Ust,Hst,Jst,hP,Yst,bxe,Zst,Kst,elt,ia,uP,olt,vxe,rlt,tlt,Wm,alt,Fxe,nlt,slt,Zne,llt,ilt,dlt,y6,clt,Zr,pP,mlt,Txe,flt,glt,Wn,hlt,Mxe,ult,plt,Exe,_lt,blt,Cxe,vlt,Flt,Tlt,ce,x6,wxe,Mlt,Elt,Kne,Clt,wlt,Alt,$6,Axe,Llt,ylt,ese,xlt,$lt,klt,k6,Lxe,Slt,Rlt,ose,Plt,Blt,Ilt,S6,yxe,Nlt,qlt,rse,jlt,Dlt,Glt,R6,xxe,Olt,Vlt,tse,Xlt,zlt,Qlt,P6,$xe,Wlt,Ult,ase,Hlt,Jlt,Ylt,B6,kxe,Zlt,Klt,nse,eit,oit,rit,I6,Sxe,tit,ait,sse,nit,sit,lit,N6,Rxe,iit,dit,lse,cit,mit,fit,q6,Pxe,git,hit,ise,uit,pit,_it,j6,Bxe,bit,vit,dse,Fit,Tit,Mit,D6,Ixe,Eit,Cit,cse,wit,Ait,Lit,G6,Nxe,yit,xit,mse,$it,kit,Sit,O6,qxe,Rit,Pit,fse,Bit,Iit,Nit,V6,jxe,qit,jit,gse,Dit,Git,Oit,X6,Dxe,Vit,Xit,hse,zit,Qit,Wit,z6,Gxe,Uit,Hit,use,Jit,Yit,Zit,Q6,Oxe,Kit,edt,pse,odt,rdt,tdt,W6,Vxe,adt,ndt,_se,sdt,ldt,idt,U6,Xxe,ddt,cdt,bse,mdt,fdt,gdt,H6,zxe,hdt,udt,vse,pdt,_dt,bdt,J6,xao,Um,Y6,Qxe,_P,vdt,Wxe,Fdt,$ao,Er,bP,Tdt,Hm,Mdt,Fse,Edt,Cdt,Tse,wdt,Adt,Ldt,vP,ydt,Uxe,xdt,$dt,kdt,da,FP,Sdt,Hxe,Rdt,Pdt,Jm,Bdt,Jxe,Idt,Ndt,Mse,qdt,jdt,Ddt,Z6,Gdt,Kr,TP,Odt,Yxe,Vdt,Xdt,Un,zdt,Zxe,Qdt,Wdt,Kxe,Udt,Hdt,e$e,Jdt,Ydt,Zdt,me,K6,o$e,Kdt,ect,Ese,oct,rct,tct,e7,r$e,act,nct,Cse,sct,lct,ict,o7,t$e,dct,cct,wse,mct,fct,gct,r7,a$e,hct,uct,Ase,pct,_ct,bct,t7,n$e,vct,Fct,Lse,Tct,Mct,Ect,a7,s$e,Cct,wct,yse,Act,Lct,yct,n7,l$e,xct,$ct,xse,kct,Sct,Rct,s7,i$e,Pct,Bct,$se,Ict,Nct,qct,l7,d$e,jct,Dct,kse,Gct,Oct,Vct,i7,c$e,Xct,zct,Sse,Qct,Wct,Uct,d7,m$e,Hct,Jct,Rse,Yct,Zct,Kct,c7,f$e,emt,omt,Pse,rmt,tmt,amt,m7,g$e,nmt,smt,Bse,lmt,imt,dmt,f7,h$e,cmt,mmt,Ise,fmt,gmt,hmt,g7,u$e,umt,pmt,Nse,_mt,bmt,vmt,h7,p$e,Fmt,Tmt,qse,Mmt,Emt,Cmt,u7,_$e,wmt,Amt,jse,Lmt,ymt,xmt,p7,b$e,$mt,kmt,Dse,Smt,Rmt,Pmt,_7,v$e,Bmt,Imt,Gse,Nmt,qmt,jmt,b7,F$e,Dmt,Gmt,Ose,Omt,Vmt,Xmt,v7,T$e,zmt,Qmt,Vse,Wmt,Umt,Hmt,F7,kao,Ym,T7,M$e,MP,Jmt,E$e,Ymt,Sao,Cr,EP,Zmt,Zm,Kmt,Xse,eft,oft,zse,rft,tft,aft,CP,nft,C$e,sft,lft,ift,ca,wP,dft,w$e,cft,mft,Km,fft,A$e,gft,hft,Qse,uft,pft,_ft,M7,bft,et,AP,vft,L$e,Fft,Tft,Hn,Mft,y$e,Eft,Cft,x$e,wft,Aft,$$e,Lft,yft,xft,k$e,E7,S$e,$ft,kft,Wse,Sft,Rft,Pft,C7,Rao,ef,w7,R$e,LP,Bft,P$e,Ift,Pao,wr,yP,Nft,of,qft,Use,jft,Dft,Hse,Gft,Oft,Vft,xP,Xft,B$e,zft,Qft,Wft,ma,$P,Uft,I$e,Hft,Jft,rf,Yft,N$e,Zft,Kft,Jse,egt,ogt,rgt,A7,tgt,ot,kP,agt,q$e,ngt,sgt,Jn,lgt,j$e,igt,dgt,D$e,cgt,mgt,G$e,fgt,ggt,hgt,SP,L7,O$e,ugt,pgt,Yse,_gt,bgt,vgt,y7,V$e,Fgt,Tgt,Zse,Mgt,Egt,Cgt,x7,Bao,tf,$7,X$e,RP,wgt,z$e,Agt,Iao,Ar,PP,Lgt,af,ygt,Kse,xgt,$gt,ele,kgt,Sgt,Rgt,BP,Pgt,Q$e,Bgt,Igt,Ngt,fa,IP,qgt,W$e,jgt,Dgt,nf,Ggt,U$e,Ogt,Vgt,ole,Xgt,zgt,Qgt,k7,Wgt,rt,NP,Ugt,H$e,Hgt,Jgt,Yn,Ygt,J$e,Zgt,Kgt,Y$e,eht,oht,Z$e,rht,tht,aht,te,S7,K$e,nht,sht,rle,lht,iht,dht,R7,eke,cht,mht,tle,fht,ght,hht,P7,oke,uht,pht,ale,_ht,bht,vht,B7,rke,Fht,Tht,nle,Mht,Eht,Cht,I7,tke,wht,Aht,sle,Lht,yht,xht,N7,ake,$ht,kht,lle,Sht,Rht,Pht,q7,nke,Bht,Iht,ile,Nht,qht,jht,j7,ske,Dht,Ght,dle,Oht,Vht,Xht,D7,lke,zht,Qht,cle,Wht,Uht,Hht,G7,ike,Jht,Yht,mle,Zht,Kht,eut,O7,dke,out,rut,fle,tut,aut,nut,V7,cke,sut,lut,gle,iut,dut,cut,X7,mke,mut,fut,hle,gut,hut,uut,z7,fke,put,_ut,ule,but,vut,Fut,Q7,gke,Tut,Mut,ple,Eut,Cut,wut,W7,hke,Aut,Lut,_le,yut,xut,$ut,U7,uke,kut,Sut,ble,Rut,Put,But,H7,pke,Iut,Nut,vle,qut,jut,Dut,J7,_ke,Gut,Out,Fle,Vut,Xut,zut,Y7,bke,Qut,Wut,Tle,Uut,Hut,Jut,Z7,vke,Yut,Zut,Mle,Kut,ept,opt,K7,Fke,rpt,tpt,Ele,apt,npt,spt,eL,Tke,lpt,ipt,Cle,dpt,cpt,mpt,oL,Mke,fpt,gpt,wle,hpt,upt,ppt,rL,Eke,_pt,bpt,Ale,vpt,Fpt,Tpt,tL,Cke,Mpt,Ept,Lle,Cpt,wpt,Apt,aL,wke,Lpt,ypt,yle,xpt,$pt,kpt,nL,Nao,sf,sL,Ake,qP,Spt,Lke,Rpt,qao,Lr,jP,Ppt,lf,Bpt,xle,Ipt,Npt,$le,qpt,jpt,Dpt,DP,Gpt,yke,Opt,Vpt,Xpt,ga,GP,zpt,xke,Qpt,Wpt,df,Upt,$ke,Hpt,Jpt,kle,Ypt,Zpt,Kpt,lL,e_t,tt,OP,o_t,kke,r_t,t_t,Zn,a_t,Ske,n_t,s_t,Rke,l_t,i_t,Pke,d_t,c_t,m_t,$e,iL,Bke,f_t,g_t,Sle,h_t,u_t,p_t,dL,Ike,__t,b_t,Rle,v_t,F_t,T_t,cL,Nke,M_t,E_t,Ple,C_t,w_t,A_t,mL,qke,L_t,y_t,Ble,x_t,$_t,k_t,fL,jke,S_t,R_t,Ile,P_t,B_t,I_t,gL,Dke,N_t,q_t,Nle,j_t,D_t,G_t,hL,Gke,O_t,V_t,qle,X_t,z_t,Q_t,uL,Oke,W_t,U_t,jle,H_t,J_t,Y_t,pL,Vke,Z_t,K_t,Dle,e1t,o1t,r1t,_L,Xke,t1t,a1t,Gle,n1t,s1t,l1t,bL,jao,cf,vL,zke,VP,i1t,Qke,d1t,Dao,yr,XP,c1t,mf,m1t,Ole,f1t,g1t,Vle,h1t,u1t,p1t,zP,_1t,Wke,b1t,v1t,F1t,ha,QP,T1t,Uke,M1t,E1t,ff,C1t,Hke,w1t,A1t,Xle,L1t,y1t,x1t,FL,$1t,at,WP,k1t,Jke,S1t,R1t,Kn,P1t,Yke,B1t,I1t,Zke,N1t,q1t,Kke,j1t,D1t,G1t,Ee,TL,eSe,O1t,V1t,zle,X1t,z1t,Q1t,ML,oSe,W1t,U1t,Qle,H1t,J1t,Y1t,EL,rSe,Z1t,K1t,Wle,e2t,o2t,r2t,CL,tSe,t2t,a2t,Ule,n2t,s2t,l2t,wL,aSe,i2t,d2t,Hle,c2t,m2t,f2t,AL,nSe,g2t,h2t,Jle,u2t,p2t,_2t,LL,sSe,b2t,v2t,Yle,F2t,T2t,M2t,yL,lSe,E2t,C2t,Zle,w2t,A2t,L2t,xL,iSe,y2t,x2t,Kle,$2t,k2t,S2t,$L,dSe,R2t,P2t,eie,B2t,I2t,N2t,kL,cSe,q2t,j2t,oie,D2t,G2t,O2t,SL,mSe,V2t,X2t,rie,z2t,Q2t,W2t,RL,fSe,U2t,H2t,tie,J2t,Y2t,Z2t,PL,Gao,gf,BL,gSe,UP,K2t,hSe,ebt,Oao,xr,HP,obt,hf,rbt,aie,tbt,abt,nie,nbt,sbt,lbt,JP,ibt,uSe,dbt,cbt,mbt,ua,YP,fbt,pSe,gbt,hbt,uf,ubt,_Se,pbt,_bt,sie,bbt,vbt,Fbt,IL,Tbt,nt,ZP,Mbt,bSe,Ebt,Cbt,es,wbt,vSe,Abt,Lbt,FSe,ybt,xbt,TSe,$bt,kbt,Sbt,ke,NL,MSe,Rbt,Pbt,lie,Bbt,Ibt,Nbt,qL,ESe,qbt,jbt,iie,Dbt,Gbt,Obt,jL,CSe,Vbt,Xbt,die,zbt,Qbt,Wbt,DL,wSe,Ubt,Hbt,cie,Jbt,Ybt,Zbt,GL,ASe,Kbt,evt,mie,ovt,rvt,tvt,OL,LSe,avt,nvt,fie,svt,lvt,ivt,VL,ySe,dvt,cvt,gie,mvt,fvt,gvt,XL,xSe,hvt,uvt,hie,pvt,_vt,bvt,zL,$Se,vvt,Fvt,uie,Tvt,Mvt,Evt,QL,kSe,Cvt,wvt,pie,Avt,Lvt,yvt,WL,Vao,pf,UL,SSe,KP,xvt,RSe,$vt,Xao,$r,eB,kvt,_f,Svt,_ie,Rvt,Pvt,bie,Bvt,Ivt,Nvt,oB,qvt,PSe,jvt,Dvt,Gvt,pa,rB,Ovt,BSe,Vvt,Xvt,bf,zvt,ISe,Qvt,Wvt,vie,Uvt,Hvt,Jvt,HL,Yvt,st,tB,Zvt,NSe,Kvt,eFt,os,oFt,qSe,rFt,tFt,jSe,aFt,nFt,DSe,sFt,lFt,iFt,Se,JL,GSe,dFt,cFt,Fie,mFt,fFt,gFt,YL,OSe,hFt,uFt,Tie,pFt,_Ft,bFt,ZL,VSe,vFt,FFt,Mie,TFt,MFt,EFt,KL,XSe,CFt,wFt,Eie,AFt,LFt,yFt,e8,zSe,xFt,$Ft,Cie,kFt,SFt,RFt,o8,QSe,PFt,BFt,wie,IFt,NFt,qFt,r8,WSe,jFt,DFt,Aie,GFt,OFt,VFt,t8,USe,XFt,zFt,Lie,QFt,WFt,UFt,a8,HSe,HFt,JFt,yie,YFt,ZFt,KFt,n8,JSe,eTt,oTt,xie,rTt,tTt,aTt,s8,zao,vf,l8,YSe,aB,nTt,ZSe,sTt,Qao,kr,nB,lTt,Ff,iTt,$ie,dTt,cTt,kie,mTt,fTt,gTt,sB,hTt,KSe,uTt,pTt,_Tt,_a,lB,bTt,eRe,vTt,FTt,Tf,TTt,oRe,MTt,ETt,Sie,CTt,wTt,ATt,i8,LTt,lt,iB,yTt,rRe,xTt,$Tt,rs,kTt,tRe,STt,RTt,aRe,PTt,BTt,nRe,ITt,NTt,qTt,Re,d8,sRe,jTt,DTt,Rie,GTt,OTt,VTt,c8,lRe,XTt,zTt,Pie,QTt,WTt,UTt,m8,iRe,HTt,JTt,Bie,YTt,ZTt,KTt,f8,dRe,eMt,oMt,Iie,rMt,tMt,aMt,g8,cRe,nMt,sMt,Nie,lMt,iMt,dMt,h8,mRe,cMt,mMt,qie,fMt,gMt,hMt,u8,fRe,uMt,pMt,jie,_Mt,bMt,vMt,p8,gRe,FMt,TMt,Die,MMt,EMt,CMt,_8,hRe,wMt,AMt,Gie,LMt,yMt,xMt,b8,uRe,$Mt,kMt,Oie,SMt,RMt,PMt,v8,Wao,Mf,F8,pRe,dB,BMt,_Re,IMt,Uao,Sr,cB,NMt,Ef,qMt,Vie,jMt,DMt,Xie,GMt,OMt,VMt,mB,XMt,bRe,zMt,QMt,WMt,ba,fB,UMt,vRe,HMt,JMt,Cf,YMt,FRe,ZMt,KMt,zie,eEt,oEt,rEt,T8,tEt,it,gB,aEt,TRe,nEt,sEt,ts,lEt,MRe,iEt,dEt,ERe,cEt,mEt,CRe,fEt,gEt,hEt,Pe,M8,wRe,uEt,pEt,Qie,_Et,bEt,vEt,E8,ARe,FEt,TEt,Wie,MEt,EEt,CEt,C8,LRe,wEt,AEt,Uie,LEt,yEt,xEt,w8,yRe,$Et,kEt,Hie,SEt,REt,PEt,A8,xRe,BEt,IEt,Jie,NEt,qEt,jEt,L8,$Re,DEt,GEt,Yie,OEt,VEt,XEt,y8,kRe,zEt,QEt,Zie,WEt,UEt,HEt,x8,SRe,JEt,YEt,Kie,ZEt,KEt,e4t,$8,RRe,o4t,r4t,ede,t4t,a4t,n4t,k8,PRe,s4t,l4t,ode,i4t,d4t,c4t,S8,Hao,wf,R8,BRe,hB,m4t,IRe,f4t,Jao,Rr,uB,g4t,Af,h4t,rde,u4t,p4t,tde,_4t,b4t,v4t,pB,F4t,NRe,T4t,M4t,E4t,va,_B,C4t,qRe,w4t,A4t,Lf,L4t,jRe,y4t,x4t,ade,$4t,k4t,S4t,P8,R4t,dt,bB,P4t,DRe,B4t,I4t,as,N4t,GRe,q4t,j4t,ORe,D4t,G4t,VRe,O4t,V4t,X4t,ze,B8,XRe,z4t,Q4t,nde,W4t,U4t,H4t,I8,zRe,J4t,Y4t,sde,Z4t,K4t,eCt,N8,QRe,oCt,rCt,lde,tCt,aCt,nCt,q8,WRe,sCt,lCt,ide,iCt,dCt,cCt,j8,URe,mCt,fCt,dde,gCt,hCt,uCt,D8,HRe,pCt,_Ct,cde,bCt,vCt,FCt,G8,JRe,TCt,MCt,mde,ECt,CCt,wCt,O8,YRe,ACt,LCt,fde,yCt,xCt,$Ct,V8,Yao,yf,X8,ZRe,vB,kCt,KRe,SCt,Zao,Pr,FB,RCt,xf,PCt,gde,BCt,ICt,hde,NCt,qCt,jCt,TB,DCt,ePe,GCt,OCt,VCt,Fa,MB,XCt,oPe,zCt,QCt,$f,WCt,rPe,UCt,HCt,ude,JCt,YCt,ZCt,z8,KCt,ct,EB,e3t,tPe,o3t,r3t,ns,t3t,aPe,a3t,n3t,nPe,s3t,l3t,sPe,i3t,d3t,c3t,Qe,Q8,lPe,m3t,f3t,pde,g3t,h3t,u3t,W8,iPe,p3t,_3t,_de,b3t,v3t,F3t,U8,dPe,T3t,M3t,bde,E3t,C3t,w3t,H8,cPe,A3t,L3t,vde,y3t,x3t,$3t,J8,mPe,k3t,S3t,Fde,R3t,P3t,B3t,Y8,fPe,I3t,N3t,Tde,q3t,j3t,D3t,Z8,gPe,G3t,O3t,Mde,V3t,X3t,z3t,K8,hPe,Q3t,W3t,Ede,U3t,H3t,J3t,ey,Kao,kf,oy,uPe,CB,Y3t,pPe,Z3t,eno,Br,wB,K3t,Sf,e5t,Cde,o5t,r5t,wde,t5t,a5t,n5t,AB,s5t,_Pe,l5t,i5t,d5t,Ta,LB,c5t,bPe,m5t,f5t,Rf,g5t,vPe,h5t,u5t,Ade,p5t,_5t,b5t,ry,v5t,mt,yB,F5t,FPe,T5t,M5t,ss,E5t,TPe,C5t,w5t,MPe,A5t,L5t,EPe,y5t,x5t,$5t,CPe,ty,wPe,k5t,S5t,Lde,R5t,P5t,B5t,ay,ono,Pf,ny,APe,xB,I5t,LPe,N5t,rno,Ir,$B,q5t,Bf,j5t,yde,D5t,G5t,xde,O5t,V5t,X5t,kB,z5t,yPe,Q5t,W5t,U5t,Ma,SB,H5t,xPe,J5t,Y5t,If,Z5t,$Pe,K5t,e0t,$de,o0t,r0t,t0t,sy,a0t,ft,RB,n0t,kPe,s0t,l0t,ls,i0t,SPe,d0t,c0t,RPe,m0t,f0t,PPe,g0t,h0t,u0t,PB,ly,BPe,p0t,_0t,kde,b0t,v0t,F0t,iy,IPe,T0t,M0t,Sde,E0t,C0t,w0t,dy,tno,Nf,cy,NPe,BB,A0t,qPe,L0t,ano,Nr,IB,y0t,qf,x0t,Rde,$0t,k0t,Pde,S0t,R0t,P0t,NB,B0t,jPe,I0t,N0t,q0t,Ea,qB,j0t,DPe,D0t,G0t,jf,O0t,GPe,V0t,X0t,Bde,z0t,Q0t,W0t,my,U0t,gt,jB,H0t,OPe,J0t,Y0t,is,Z0t,VPe,K0t,ewt,XPe,owt,rwt,zPe,twt,awt,nwt,QPe,fy,WPe,swt,lwt,Ide,iwt,dwt,cwt,gy,nno;return d=new oe({}),en=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),e$=new oe({}),o$=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Uf=new mwt({props:{warning:!0,$$slots:{default:[R4a]},$$scope:{ctx:$}}}),r$=new oe({}),t$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L662"}}),s$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L685"}}),Mu=new I({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[P4a]},$$scope:{ctx:$}}}),l$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L808"}}),i$=new oe({}),d$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L429"}}),f$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L443"}}),sp=new I({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[B4a]},$$scope:{ctx:$}}}),g$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L644"}}),h$=new oe({}),u$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L203"}}),b$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L217"}}),Zp=new mwt({props:{$$slots:{default:[I4a]},$$scope:{ctx:$}}}),Kp=new I({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[N4a]},$$scope:{ctx:$}}}),v$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L344"}}),F$=new oe({}),T$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),C$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),w_=new mwt({props:{$$slots:{default:[q4a]},$$scope:{ctx:$}}}),A_=new I({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[j4a]},$$scope:{ctx:$}}}),w$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),A$=new oe({}),L$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L886"}}),x$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x_=new I({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[D4a]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J2=new I({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[G4a]},$$scope:{ctx:$}}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L893"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z2=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[O4a]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ub=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[V4a]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L908"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Jb=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[X4a]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Dv=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[z4a]},$$scope:{ctx:$}}}),G$=new oe({}),O$=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1051"}}),X$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ov=new I({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[Q4a]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Qv=new I({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[W4a]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L915"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Uv=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[U4a]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),BF=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[H4a]},$$scope:{ctx:$}}}),Z$=new oe({}),K$=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L922"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),NF=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[J4a]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nT=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Y4a]},$$scope:{ctx:$}}}),tk=new oe({}),ak=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L931"}}),sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lT=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Z4a]},$$scope:{ctx:$}}}),lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mM=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[K4a]},$$scope:{ctx:$}}}),ik=new oe({}),dk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L987"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[eCa]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WM=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[oCa]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L994"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HM=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[rCa]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aE=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[tCa]},$$scope:{ctx:$}}}),bk=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L980"}}),Tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sE=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[aCa]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HE=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[nCa]},$$scope:{ctx:$}}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L940"}}),Ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YE=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[sCa]},$$scope:{ctx:$}}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W4=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[lCa]},$$scope:{ctx:$}}}),yk=new oe({}),xk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L947"}}),kk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H4=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[iCa]},$$scope:{ctx:$}}}),Sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z4=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[dCa]},$$scope:{ctx:$}}}),Rk=new oe({}),Pk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L969"}}),Ik=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eC=new I({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[cCa]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nC=new I({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[mCa]},$$scope:{ctx:$}}}),qk=new oe({}),jk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1003"}}),Gk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lC=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[fCa]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),CC=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[gCa]},$$scope:{ctx:$}}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1058"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),AC=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[hCa]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xC=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[uCa]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1065"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kC=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[pCa]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[_Ca]},$$scope:{ctx:$}}}),Kk=new oe({}),eS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L958"}}),rS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IC=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[bCa]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[vCa]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1072"}}),lS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[FCa]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZC=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[TCa]},$$scope:{ctx:$}}}),dS=new oe({}),cS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1095"}}),fS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e3=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[MCa]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l3=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[ECa]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1079"}}),_S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d3=new I({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[CCa]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T3=new I({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[wCa]},$$scope:{ctx:$}}}),vS=new oe({}),FS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1086"}}),MS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E3=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[ACa]},$$scope:{ctx:$}}}),ES=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y3=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[LCa]},$$scope:{ctx:$}}}),CS=new oe({}),wS=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1104"}}),LS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$3=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[yCa]},$$scope:{ctx:$}}}),yS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[xCa]},$$scope:{ctx:$}}}),xS=new oe({}),$S=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1111"}}),SS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),j3=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[$Ca]},$$scope:{ctx:$}}}),RS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z3=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[kCa]},$$scope:{ctx:$}}}),PS=new oe({}),BS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1035"}}),NS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W3=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[SCa]},$$scope:{ctx:$}}}),qS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),K3=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[RCa]},$$scope:{ctx:$}}}),jS=new oe({}),DS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1010"}}),OS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o5=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[PCa]},$$scope:{ctx:$}}}),VS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[BCa]},$$scope:{ctx:$}}}),XS=new oe({}),zS=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1017"}}),WS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[ICa]},$$scope:{ctx:$}}}),US=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g5=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[NCa]},$$scope:{ctx:$}}}),HS=new oe({}),JS=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1026"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u5=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[qCa]},$$scope:{ctx:$}}}),KS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),b5=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[jCa]},$$scope:{ctx:$}}}),eR=new oe({}),oR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1042"}}),tR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),F5=new I({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[DCa]},$$scope:{ctx:$}}}),aR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E5=new I({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[GCa]},$$scope:{ctx:$}}}),nR=new oe({}),sR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L439"}}),iR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w5=new I({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[OCa]},$$scope:{ctx:$}}}),dR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y0=new I({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[VCa]},$$scope:{ctx:$}}}),cR=new oe({}),mR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L446"}}),gR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$0=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[XCa]},$$scope:{ctx:$}}}),hR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ew=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[zCa]},$$scope:{ctx:$}}}),uR=new oe({}),pR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L461"}}),bR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rw=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[QCa]},$$scope:{ctx:$}}}),vR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_w=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[WCa]},$$scope:{ctx:$}}}),FR=new oe({}),TR=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L477"}}),ER=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vw=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[UCa]},$$scope:{ctx:$}}}),CR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xw=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[HCa]},$$scope:{ctx:$}}}),wR=new oe({}),AR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L486"}}),yR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kw=new I({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[JCa]},$$scope:{ctx:$}}}),xR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Bw=new I({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[YCa]},$$scope:{ctx:$}}}),$R=new oe({}),kR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L502"}}),RR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Nw=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[ZCa]},$$scope:{ctx:$}}}),PR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aA=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[KCa]},$$scope:{ctx:$}}}),BR=new oe({}),IR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L509"}}),qR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sA=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[e3a]},$$scope:{ctx:$}}}),jR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_A=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[o3a]},$$scope:{ctx:$}}}),DR=new oe({}),GR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L518"}}),VR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vA=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[r3a]},$$scope:{ctx:$}}}),XR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WA=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[t3a]},$$scope:{ctx:$}}}),zR=new oe({}),QR=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L565"}}),UR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HA=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[a3a]},$$scope:{ctx:$}}}),HR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g6=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[n3a]},$$scope:{ctx:$}}}),JR=new oe({}),YR=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L572"}}),KR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u6=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[s3a]},$$scope:{ctx:$}}}),eP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),b6=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[l3a]},$$scope:{ctx:$}}}),rP=new oe({}),tP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L545"}}),nP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),F6=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[i3a]},$$scope:{ctx:$}}}),sP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M6=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[d3a]},$$scope:{ctx:$}}}),lP=new oe({}),iP=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L534"}}),cP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C6=new I({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[c3a]},$$scope:{ctx:$}}}),mP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A6=new I({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[m3a]},$$scope:{ctx:$}}}),fP=new oe({}),gP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L556"}}),uP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y6=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[f3a]},$$scope:{ctx:$}}}),pP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J6=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[g3a]},$$scope:{ctx:$}}}),_P=new oe({}),bP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L527"}}),FP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z6=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[h3a]},$$scope:{ctx:$}}}),TP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F7=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[u3a]},$$scope:{ctx:$}}}),MP=new oe({}),EP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L495"}}),wP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M7=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[p3a]},$$scope:{ctx:$}}}),AP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C7=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[_3a]},$$scope:{ctx:$}}}),LP=new oe({}),yP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L581"}}),$P=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A7=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[b3a]},$$scope:{ctx:$}}}),kP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x7=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[v3a]},$$scope:{ctx:$}}}),RP=new oe({}),PP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),IP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k7=new I({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[F3a]},$$scope:{ctx:$}}}),NP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nL=new I({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[T3a]},$$scope:{ctx:$}}}),qP=new oe({}),jP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),GP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lL=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[M3a]},$$scope:{ctx:$}}}),OP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bL=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[E3a]},$$scope:{ctx:$}}}),VP=new oe({}),XP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),QP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),FL=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[C3a]},$$scope:{ctx:$}}}),WP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PL=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[w3a]},$$scope:{ctx:$}}}),UP=new oe({}),HP=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),YP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IL=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[A3a]},$$scope:{ctx:$}}}),ZP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WL=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[L3a]},$$scope:{ctx:$}}}),KP=new oe({}),eB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),rB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HL=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[y3a]},$$scope:{ctx:$}}}),tB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s8=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[x3a]},$$scope:{ctx:$}}}),aB=new oe({}),nB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),lB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i8=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[$3a]},$$scope:{ctx:$}}}),iB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v8=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[k3a]},$$scope:{ctx:$}}}),dB=new oe({}),cB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),fB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T8=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[S3a]},$$scope:{ctx:$}}}),gB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S8=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[R3a]},$$scope:{ctx:$}}}),hB=new oe({}),uB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),_B=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P8=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[P3a]},$$scope:{ctx:$}}}),bB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V8=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[B3a]},$$scope:{ctx:$}}}),vB=new oe({}),FB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),MB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z8=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[I3a]},$$scope:{ctx:$}}}),EB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ey=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[N3a]},$$scope:{ctx:$}}}),CB=new oe({}),wB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),LB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ry=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[q3a]},$$scope:{ctx:$}}}),yB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ay=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[j3a]},$$scope:{ctx:$}}}),xB=new oe({}),$B=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),SB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sy=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[D3a]},$$scope:{ctx:$}}}),RB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dy=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[G3a]},$$scope:{ctx:$}}}),BB=new oe({}),IB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),qB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),my=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[O3a]},$$scope:{ctx:$}}}),jB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gy=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[V3a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),pd=o("Auto Classes"),Vf=l(),Ft=a("p"),_d=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),bd=a("code"),Jx=o("from_pretrained()"),Xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),vd=o("Instantiating one of "),cs=a("a"),Yx=o("AutoConfig"),ms=o(", "),fs=a("a"),Zx=o("AutoModel"),Fd=o(`, and
`),gs=a("a"),Kx=o("AutoTokenizer"),Td=o(" will directly create a class of the relevant architecture. For instance"),zf=l(),F(en.$$.fragment),Je=l(),Ae=a("p"),fN=o("will create a model that is an instance of "),Md=a("a"),gN=o("BertModel"),hN=o("."),ko=l(),on=a("p"),uN=o("There is one class of "),Qf=a("code"),pN=o("AutoModel"),Llo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Oro=l(),Ed=a("h2"),Wf=a("a"),zme=a("span"),F(e$.$$.fragment),ylo=l(),Qme=a("span"),xlo=o("Extending the Auto Classes"),Vro=l(),hs=a("p"),$lo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Wme=a("code"),klo=o("NewModel"),Slo=o(", make sure you have a "),Ume=a("code"),Rlo=o("NewModelConfig"),Plo=o(` then you can add those to the auto
classes like this:`),Xro=l(),F(o$.$$.fragment),zro=l(),_N=a("p"),Blo=o("You will then be able to use the auto classes like you would usually do!"),Qro=l(),F(Uf.$$.fragment),Wro=l(),Cd=a("h2"),Hf=a("a"),Hme=a("span"),F(r$.$$.fragment),Ilo=l(),Jme=a("span"),Nlo=o("AutoConfig"),Uro=l(),So=a("div"),F(t$.$$.fragment),qlo=l(),a$=a("p"),jlo=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),bN=a("a"),Dlo=o("from_pretrained()"),Glo=o(" class method."),Olo=l(),n$=a("p"),Vlo=o("This class cannot be instantiated directly using "),Yme=a("code"),Xlo=o("__init__()"),zlo=o(" (throws an error)."),Qlo=l(),qr=a("div"),F(s$.$$.fragment),Wlo=l(),Zme=a("p"),Ulo=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Hlo=l(),wd=a("p"),Jlo=o("The configuration class to instantiate is selected based on the "),Kme=a("code"),Ylo=o("model_type"),Zlo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),efe=a("code"),Klo=o("pretrained_model_name_or_path"),eio=o(":"),oio=l(),A=a("ul"),Jf=a("li"),ofe=a("strong"),rio=o("albert"),tio=o(" \u2014 "),vN=a("a"),aio=o("AlbertConfig"),nio=o(" (ALBERT model)"),sio=l(),Yf=a("li"),rfe=a("strong"),lio=o("bart"),iio=o(" \u2014 "),FN=a("a"),dio=o("BartConfig"),cio=o(" (BART model)"),mio=l(),Zf=a("li"),tfe=a("strong"),fio=o("beit"),gio=o(" \u2014 "),TN=a("a"),hio=o("BeitConfig"),uio=o(" (BEiT model)"),pio=l(),Kf=a("li"),afe=a("strong"),_io=o("bert"),bio=o(" \u2014 "),MN=a("a"),vio=o("BertConfig"),Fio=o(" (BERT model)"),Tio=l(),eg=a("li"),nfe=a("strong"),Mio=o("bert-generation"),Eio=o(" \u2014 "),EN=a("a"),Cio=o("BertGenerationConfig"),wio=o(" (Bert Generation model)"),Aio=l(),og=a("li"),sfe=a("strong"),Lio=o("big_bird"),yio=o(" \u2014 "),CN=a("a"),xio=o("BigBirdConfig"),$io=o(" (BigBird model)"),kio=l(),rg=a("li"),lfe=a("strong"),Sio=o("bigbird_pegasus"),Rio=o(" \u2014 "),wN=a("a"),Pio=o("BigBirdPegasusConfig"),Bio=o(" (BigBird-Pegasus model)"),Iio=l(),tg=a("li"),ife=a("strong"),Nio=o("blenderbot"),qio=o(" \u2014 "),AN=a("a"),jio=o("BlenderbotConfig"),Dio=o(" (Blenderbot model)"),Gio=l(),ag=a("li"),dfe=a("strong"),Oio=o("blenderbot-small"),Vio=o(" \u2014 "),LN=a("a"),Xio=o("BlenderbotSmallConfig"),zio=o(" (BlenderbotSmall model)"),Qio=l(),ng=a("li"),cfe=a("strong"),Wio=o("bloom"),Uio=o(" \u2014 "),yN=a("a"),Hio=o("BloomConfig"),Jio=o(" (BLOOM model)"),Yio=l(),sg=a("li"),mfe=a("strong"),Zio=o("camembert"),Kio=o(" \u2014 "),xN=a("a"),edo=o("CamembertConfig"),odo=o(" (CamemBERT model)"),rdo=l(),lg=a("li"),ffe=a("strong"),tdo=o("canine"),ado=o(" \u2014 "),$N=a("a"),ndo=o("CanineConfig"),sdo=o(" (CANINE model)"),ldo=l(),ig=a("li"),gfe=a("strong"),ido=o("clip"),ddo=o(" \u2014 "),kN=a("a"),cdo=o("CLIPConfig"),mdo=o(" (CLIP model)"),fdo=l(),dg=a("li"),hfe=a("strong"),gdo=o("codegen"),hdo=o(" \u2014 "),SN=a("a"),udo=o("CodeGenConfig"),pdo=o(" (CodeGen model)"),_do=l(),cg=a("li"),ufe=a("strong"),bdo=o("conditional_detr"),vdo=o(" \u2014 "),RN=a("a"),Fdo=o("ConditionalDetrConfig"),Tdo=o(" (Conditional DETR model)"),Mdo=l(),mg=a("li"),pfe=a("strong"),Edo=o("convbert"),Cdo=o(" \u2014 "),PN=a("a"),wdo=o("ConvBertConfig"),Ado=o(" (ConvBERT model)"),Ldo=l(),fg=a("li"),_fe=a("strong"),ydo=o("convnext"),xdo=o(" \u2014 "),BN=a("a"),$do=o("ConvNextConfig"),kdo=o(" (ConvNeXT model)"),Sdo=l(),gg=a("li"),bfe=a("strong"),Rdo=o("ctrl"),Pdo=o(" \u2014 "),IN=a("a"),Bdo=o("CTRLConfig"),Ido=o(" (CTRL model)"),Ndo=l(),hg=a("li"),vfe=a("strong"),qdo=o("cvt"),jdo=o(" \u2014 "),NN=a("a"),Ddo=o("CvtConfig"),Gdo=o(" (CvT model)"),Odo=l(),ug=a("li"),Ffe=a("strong"),Vdo=o("data2vec-audio"),Xdo=o(" \u2014 "),qN=a("a"),zdo=o("Data2VecAudioConfig"),Qdo=o(" (Data2VecAudio model)"),Wdo=l(),pg=a("li"),Tfe=a("strong"),Udo=o("data2vec-text"),Hdo=o(" \u2014 "),jN=a("a"),Jdo=o("Data2VecTextConfig"),Ydo=o(" (Data2VecText model)"),Zdo=l(),_g=a("li"),Mfe=a("strong"),Kdo=o("data2vec-vision"),eco=o(" \u2014 "),DN=a("a"),oco=o("Data2VecVisionConfig"),rco=o(" (Data2VecVision model)"),tco=l(),bg=a("li"),Efe=a("strong"),aco=o("deberta"),nco=o(" \u2014 "),GN=a("a"),sco=o("DebertaConfig"),lco=o(" (DeBERTa model)"),ico=l(),vg=a("li"),Cfe=a("strong"),dco=o("deberta-v2"),cco=o(" \u2014 "),ON=a("a"),mco=o("DebertaV2Config"),fco=o(" (DeBERTa-v2 model)"),gco=l(),Fg=a("li"),wfe=a("strong"),hco=o("decision_transformer"),uco=o(" \u2014 "),VN=a("a"),pco=o("DecisionTransformerConfig"),_co=o(" (Decision Transformer model)"),bco=l(),Tg=a("li"),Afe=a("strong"),vco=o("deformable_detr"),Fco=o(" \u2014 "),XN=a("a"),Tco=o("DeformableDetrConfig"),Mco=o(" (Deformable DETR model)"),Eco=l(),Mg=a("li"),Lfe=a("strong"),Cco=o("deit"),wco=o(" \u2014 "),zN=a("a"),Aco=o("DeiTConfig"),Lco=o(" (DeiT model)"),yco=l(),Eg=a("li"),yfe=a("strong"),xco=o("detr"),$co=o(" \u2014 "),QN=a("a"),kco=o("DetrConfig"),Sco=o(" (DETR model)"),Rco=l(),Cg=a("li"),xfe=a("strong"),Pco=o("distilbert"),Bco=o(" \u2014 "),WN=a("a"),Ico=o("DistilBertConfig"),Nco=o(" (DistilBERT model)"),qco=l(),wg=a("li"),$fe=a("strong"),jco=o("donut-swin"),Dco=o(" \u2014 "),UN=a("a"),Gco=o("DonutSwinConfig"),Oco=o(" (DonutSwin model)"),Vco=l(),Ag=a("li"),kfe=a("strong"),Xco=o("dpr"),zco=o(" \u2014 "),HN=a("a"),Qco=o("DPRConfig"),Wco=o(" (DPR model)"),Uco=l(),Lg=a("li"),Sfe=a("strong"),Hco=o("dpt"),Jco=o(" \u2014 "),JN=a("a"),Yco=o("DPTConfig"),Zco=o(" (DPT model)"),Kco=l(),yg=a("li"),Rfe=a("strong"),emo=o("electra"),omo=o(" \u2014 "),YN=a("a"),rmo=o("ElectraConfig"),tmo=o(" (ELECTRA model)"),amo=l(),xg=a("li"),Pfe=a("strong"),nmo=o("encoder-decoder"),smo=o(" \u2014 "),ZN=a("a"),lmo=o("EncoderDecoderConfig"),imo=o(" (Encoder decoder model)"),dmo=l(),$g=a("li"),Bfe=a("strong"),cmo=o("ernie"),mmo=o(" \u2014 "),KN=a("a"),fmo=o("ErnieConfig"),gmo=o(" (ERNIE model)"),hmo=l(),kg=a("li"),Ife=a("strong"),umo=o("esm"),pmo=o(" \u2014 "),eq=a("a"),_mo=o("EsmConfig"),bmo=o(" (ESM model)"),vmo=l(),Sg=a("li"),Nfe=a("strong"),Fmo=o("flaubert"),Tmo=o(" \u2014 "),oq=a("a"),Mmo=o("FlaubertConfig"),Emo=o(" (FlauBERT model)"),Cmo=l(),Rg=a("li"),qfe=a("strong"),wmo=o("flava"),Amo=o(" \u2014 "),rq=a("a"),Lmo=o("FlavaConfig"),ymo=o(" (FLAVA model)"),xmo=l(),Pg=a("li"),jfe=a("strong"),$mo=o("fnet"),kmo=o(" \u2014 "),tq=a("a"),Smo=o("FNetConfig"),Rmo=o(" (FNet model)"),Pmo=l(),Bg=a("li"),Dfe=a("strong"),Bmo=o("fsmt"),Imo=o(" \u2014 "),aq=a("a"),Nmo=o("FSMTConfig"),qmo=o(" (FairSeq Machine-Translation model)"),jmo=l(),Ig=a("li"),Gfe=a("strong"),Dmo=o("funnel"),Gmo=o(" \u2014 "),nq=a("a"),Omo=o("FunnelConfig"),Vmo=o(" (Funnel Transformer model)"),Xmo=l(),Ng=a("li"),Ofe=a("strong"),zmo=o("glpn"),Qmo=o(" \u2014 "),sq=a("a"),Wmo=o("GLPNConfig"),Umo=o(" (GLPN model)"),Hmo=l(),qg=a("li"),Vfe=a("strong"),Jmo=o("gpt2"),Ymo=o(" \u2014 "),lq=a("a"),Zmo=o("GPT2Config"),Kmo=o(" (OpenAI GPT-2 model)"),efo=l(),jg=a("li"),Xfe=a("strong"),ofo=o("gpt_neo"),rfo=o(" \u2014 "),iq=a("a"),tfo=o("GPTNeoConfig"),afo=o(" (GPT Neo model)"),nfo=l(),Dg=a("li"),zfe=a("strong"),sfo=o("gpt_neox"),lfo=o(" \u2014 "),dq=a("a"),ifo=o("GPTNeoXConfig"),dfo=o(" (GPT NeoX model)"),cfo=l(),Gg=a("li"),Qfe=a("strong"),mfo=o("gpt_neox_japanese"),ffo=o(" \u2014 "),cq=a("a"),gfo=o("GPTNeoXJapaneseConfig"),hfo=o(" (GPT NeoX Japanese model)"),ufo=l(),Og=a("li"),Wfe=a("strong"),pfo=o("gptj"),_fo=o(" \u2014 "),mq=a("a"),bfo=o("GPTJConfig"),vfo=o(" (GPT-J model)"),Ffo=l(),Vg=a("li"),Ufe=a("strong"),Tfo=o("groupvit"),Mfo=o(" \u2014 "),fq=a("a"),Efo=o("GroupViTConfig"),Cfo=o(" (GroupViT model)"),wfo=l(),Xg=a("li"),Hfe=a("strong"),Afo=o("hubert"),Lfo=o(" \u2014 "),gq=a("a"),yfo=o("HubertConfig"),xfo=o(" (Hubert model)"),$fo=l(),zg=a("li"),Jfe=a("strong"),kfo=o("ibert"),Sfo=o(" \u2014 "),hq=a("a"),Rfo=o("IBertConfig"),Pfo=o(" (I-BERT model)"),Bfo=l(),Qg=a("li"),Yfe=a("strong"),Ifo=o("imagegpt"),Nfo=o(" \u2014 "),uq=a("a"),qfo=o("ImageGPTConfig"),jfo=o(" (ImageGPT model)"),Dfo=l(),Wg=a("li"),Zfe=a("strong"),Gfo=o("layoutlm"),Ofo=o(" \u2014 "),pq=a("a"),Vfo=o("LayoutLMConfig"),Xfo=o(" (LayoutLM model)"),zfo=l(),Ug=a("li"),Kfe=a("strong"),Qfo=o("layoutlmv2"),Wfo=o(" \u2014 "),_q=a("a"),Ufo=o("LayoutLMv2Config"),Hfo=o(" (LayoutLMv2 model)"),Jfo=l(),Hg=a("li"),ege=a("strong"),Yfo=o("layoutlmv3"),Zfo=o(" \u2014 "),bq=a("a"),Kfo=o("LayoutLMv3Config"),ego=o(" (LayoutLMv3 model)"),ogo=l(),Jg=a("li"),oge=a("strong"),rgo=o("led"),tgo=o(" \u2014 "),vq=a("a"),ago=o("LEDConfig"),ngo=o(" (LED model)"),sgo=l(),Yg=a("li"),rge=a("strong"),lgo=o("levit"),igo=o(" \u2014 "),Fq=a("a"),dgo=o("LevitConfig"),cgo=o(" (LeViT model)"),mgo=l(),Zg=a("li"),tge=a("strong"),fgo=o("lilt"),ggo=o(" \u2014 "),Tq=a("a"),hgo=o("LiltConfig"),ugo=o(" (LiLT model)"),pgo=l(),Kg=a("li"),age=a("strong"),_go=o("longformer"),bgo=o(" \u2014 "),Mq=a("a"),vgo=o("LongformerConfig"),Fgo=o(" (Longformer model)"),Tgo=l(),eh=a("li"),nge=a("strong"),Mgo=o("longt5"),Ego=o(" \u2014 "),Eq=a("a"),Cgo=o("LongT5Config"),wgo=o(" (LongT5 model)"),Ago=l(),oh=a("li"),sge=a("strong"),Lgo=o("luke"),ygo=o(" \u2014 "),Cq=a("a"),xgo=o("LukeConfig"),$go=o(" (LUKE model)"),kgo=l(),rh=a("li"),lge=a("strong"),Sgo=o("lxmert"),Rgo=o(" \u2014 "),wq=a("a"),Pgo=o("LxmertConfig"),Bgo=o(" (LXMERT model)"),Igo=l(),th=a("li"),ige=a("strong"),Ngo=o("m2m_100"),qgo=o(" \u2014 "),Aq=a("a"),jgo=o("M2M100Config"),Dgo=o(" (M2M100 model)"),Ggo=l(),ah=a("li"),dge=a("strong"),Ogo=o("marian"),Vgo=o(" \u2014 "),Lq=a("a"),Xgo=o("MarianConfig"),zgo=o(" (Marian model)"),Qgo=l(),nh=a("li"),cge=a("strong"),Wgo=o("markuplm"),Ugo=o(" \u2014 "),yq=a("a"),Hgo=o("MarkupLMConfig"),Jgo=o(" (MarkupLM model)"),Ygo=l(),sh=a("li"),mge=a("strong"),Zgo=o("maskformer"),Kgo=o(" \u2014 "),xq=a("a"),eho=o("MaskFormerConfig"),oho=o(" (MaskFormer model)"),rho=l(),lh=a("li"),fge=a("strong"),tho=o("mbart"),aho=o(" \u2014 "),$q=a("a"),nho=o("MBartConfig"),sho=o(" (mBART model)"),lho=l(),ih=a("li"),gge=a("strong"),iho=o("mctct"),dho=o(" \u2014 "),kq=a("a"),cho=o("MCTCTConfig"),mho=o(" (M-CTC-T model)"),fho=l(),dh=a("li"),hge=a("strong"),gho=o("megatron-bert"),hho=o(" \u2014 "),Sq=a("a"),uho=o("MegatronBertConfig"),pho=o(" (Megatron-BERT model)"),_ho=l(),ch=a("li"),uge=a("strong"),bho=o("mobilebert"),vho=o(" \u2014 "),Rq=a("a"),Fho=o("MobileBertConfig"),Tho=o(" (MobileBERT model)"),Mho=l(),mh=a("li"),pge=a("strong"),Eho=o("mobilevit"),Cho=o(" \u2014 "),Pq=a("a"),who=o("MobileViTConfig"),Aho=o(" (MobileViT model)"),Lho=l(),fh=a("li"),_ge=a("strong"),yho=o("mpnet"),xho=o(" \u2014 "),Bq=a("a"),$ho=o("MPNetConfig"),kho=o(" (MPNet model)"),Sho=l(),gh=a("li"),bge=a("strong"),Rho=o("mt5"),Pho=o(" \u2014 "),Iq=a("a"),Bho=o("MT5Config"),Iho=o(" (MT5 model)"),Nho=l(),hh=a("li"),vge=a("strong"),qho=o("mvp"),jho=o(" \u2014 "),Nq=a("a"),Dho=o("MvpConfig"),Gho=o(" (MVP model)"),Oho=l(),uh=a("li"),Fge=a("strong"),Vho=o("nezha"),Xho=o(" \u2014 "),qq=a("a"),zho=o("NezhaConfig"),Qho=o(" (Nezha model)"),Who=l(),ph=a("li"),Tge=a("strong"),Uho=o("nystromformer"),Hho=o(" \u2014 "),jq=a("a"),Jho=o("NystromformerConfig"),Yho=o(" (Nystr\xF6mformer model)"),Zho=l(),_h=a("li"),Mge=a("strong"),Kho=o("openai-gpt"),euo=o(" \u2014 "),Dq=a("a"),ouo=o("OpenAIGPTConfig"),ruo=o(" (OpenAI GPT model)"),tuo=l(),bh=a("li"),Ege=a("strong"),auo=o("opt"),nuo=o(" \u2014 "),Gq=a("a"),suo=o("OPTConfig"),luo=o(" (OPT model)"),iuo=l(),vh=a("li"),Cge=a("strong"),duo=o("owlvit"),cuo=o(" \u2014 "),Oq=a("a"),muo=o("OwlViTConfig"),fuo=o(" (OWL-ViT model)"),guo=l(),Fh=a("li"),wge=a("strong"),huo=o("pegasus"),uuo=o(" \u2014 "),Vq=a("a"),puo=o("PegasusConfig"),_uo=o(" (Pegasus model)"),buo=l(),Th=a("li"),Age=a("strong"),vuo=o("pegasus_x"),Fuo=o(" \u2014 "),Xq=a("a"),Tuo=o("PegasusXConfig"),Muo=o(" (PEGASUS-X model)"),Euo=l(),Mh=a("li"),Lge=a("strong"),Cuo=o("perceiver"),wuo=o(" \u2014 "),zq=a("a"),Auo=o("PerceiverConfig"),Luo=o(" (Perceiver model)"),yuo=l(),Eh=a("li"),yge=a("strong"),xuo=o("plbart"),$uo=o(" \u2014 "),Qq=a("a"),kuo=o("PLBartConfig"),Suo=o(" (PLBart model)"),Ruo=l(),Ch=a("li"),xge=a("strong"),Puo=o("poolformer"),Buo=o(" \u2014 "),Wq=a("a"),Iuo=o("PoolFormerConfig"),Nuo=o(" (PoolFormer model)"),quo=l(),wh=a("li"),$ge=a("strong"),juo=o("prophetnet"),Duo=o(" \u2014 "),Uq=a("a"),Guo=o("ProphetNetConfig"),Ouo=o(" (ProphetNet model)"),Vuo=l(),Ah=a("li"),kge=a("strong"),Xuo=o("qdqbert"),zuo=o(" \u2014 "),Hq=a("a"),Quo=o("QDQBertConfig"),Wuo=o(" (QDQBert model)"),Uuo=l(),Lh=a("li"),Sge=a("strong"),Huo=o("rag"),Juo=o(" \u2014 "),Jq=a("a"),Yuo=o("RagConfig"),Zuo=o(" (RAG model)"),Kuo=l(),yh=a("li"),Rge=a("strong"),epo=o("realm"),opo=o(" \u2014 "),Yq=a("a"),rpo=o("RealmConfig"),tpo=o(" (REALM model)"),apo=l(),xh=a("li"),Pge=a("strong"),npo=o("reformer"),spo=o(" \u2014 "),Zq=a("a"),lpo=o("ReformerConfig"),ipo=o(" (Reformer model)"),dpo=l(),$h=a("li"),Bge=a("strong"),cpo=o("regnet"),mpo=o(" \u2014 "),Kq=a("a"),fpo=o("RegNetConfig"),gpo=o(" (RegNet model)"),hpo=l(),kh=a("li"),Ige=a("strong"),upo=o("rembert"),ppo=o(" \u2014 "),ej=a("a"),_po=o("RemBertConfig"),bpo=o(" (RemBERT model)"),vpo=l(),Sh=a("li"),Nge=a("strong"),Fpo=o("resnet"),Tpo=o(" \u2014 "),oj=a("a"),Mpo=o("ResNetConfig"),Epo=o(" (ResNet model)"),Cpo=l(),Rh=a("li"),qge=a("strong"),wpo=o("retribert"),Apo=o(" \u2014 "),rj=a("a"),Lpo=o("RetriBertConfig"),ypo=o(" (RetriBERT model)"),xpo=l(),Ph=a("li"),jge=a("strong"),$po=o("roberta"),kpo=o(" \u2014 "),tj=a("a"),Spo=o("RobertaConfig"),Rpo=o(" (RoBERTa model)"),Ppo=l(),Bh=a("li"),Dge=a("strong"),Bpo=o("roformer"),Ipo=o(" \u2014 "),aj=a("a"),Npo=o("RoFormerConfig"),qpo=o(" (RoFormer model)"),jpo=l(),Ih=a("li"),Gge=a("strong"),Dpo=o("segformer"),Gpo=o(" \u2014 "),nj=a("a"),Opo=o("SegformerConfig"),Vpo=o(" (SegFormer model)"),Xpo=l(),Nh=a("li"),Oge=a("strong"),zpo=o("sew"),Qpo=o(" \u2014 "),sj=a("a"),Wpo=o("SEWConfig"),Upo=o(" (SEW model)"),Hpo=l(),qh=a("li"),Vge=a("strong"),Jpo=o("sew-d"),Ypo=o(" \u2014 "),lj=a("a"),Zpo=o("SEWDConfig"),Kpo=o(" (SEW-D model)"),e_o=l(),jh=a("li"),Xge=a("strong"),o_o=o("speech-encoder-decoder"),r_o=o(" \u2014 "),ij=a("a"),t_o=o("SpeechEncoderDecoderConfig"),a_o=o(" (Speech Encoder decoder model)"),n_o=l(),Dh=a("li"),zge=a("strong"),s_o=o("speech_to_text"),l_o=o(" \u2014 "),dj=a("a"),i_o=o("Speech2TextConfig"),d_o=o(" (Speech2Text model)"),c_o=l(),Gh=a("li"),Qge=a("strong"),m_o=o("speech_to_text_2"),f_o=o(" \u2014 "),cj=a("a"),g_o=o("Speech2Text2Config"),h_o=o(" (Speech2Text2 model)"),u_o=l(),Oh=a("li"),Wge=a("strong"),p_o=o("splinter"),__o=o(" \u2014 "),mj=a("a"),b_o=o("SplinterConfig"),v_o=o(" (Splinter model)"),F_o=l(),Vh=a("li"),Uge=a("strong"),T_o=o("squeezebert"),M_o=o(" \u2014 "),fj=a("a"),E_o=o("SqueezeBertConfig"),C_o=o(" (SqueezeBERT model)"),w_o=l(),Xh=a("li"),Hge=a("strong"),A_o=o("swin"),L_o=o(" \u2014 "),gj=a("a"),y_o=o("SwinConfig"),x_o=o(" (Swin Transformer model)"),$_o=l(),zh=a("li"),Jge=a("strong"),k_o=o("swinv2"),S_o=o(" \u2014 "),hj=a("a"),R_o=o("Swinv2Config"),P_o=o(" (Swin Transformer V2 model)"),B_o=l(),Qh=a("li"),Yge=a("strong"),I_o=o("t5"),N_o=o(" \u2014 "),uj=a("a"),q_o=o("T5Config"),j_o=o(" (T5 model)"),D_o=l(),Wh=a("li"),Zge=a("strong"),G_o=o("tapas"),O_o=o(" \u2014 "),pj=a("a"),V_o=o("TapasConfig"),X_o=o(" (TAPAS model)"),z_o=l(),Uh=a("li"),Kge=a("strong"),Q_o=o("time_series_transformer"),W_o=o(" \u2014 "),_j=a("a"),U_o=o("TimeSeriesTransformerConfig"),H_o=o(" (Time Series Transformer model)"),J_o=l(),Hh=a("li"),ehe=a("strong"),Y_o=o("trajectory_transformer"),Z_o=o(" \u2014 "),bj=a("a"),K_o=o("TrajectoryTransformerConfig"),e1o=o(" (Trajectory Transformer model)"),o1o=l(),Jh=a("li"),ohe=a("strong"),r1o=o("transfo-xl"),t1o=o(" \u2014 "),vj=a("a"),a1o=o("TransfoXLConfig"),n1o=o(" (Transformer-XL model)"),s1o=l(),Yh=a("li"),rhe=a("strong"),l1o=o("trocr"),i1o=o(" \u2014 "),Fj=a("a"),d1o=o("TrOCRConfig"),c1o=o(" (TrOCR model)"),m1o=l(),Zh=a("li"),the=a("strong"),f1o=o("unispeech"),g1o=o(" \u2014 "),Tj=a("a"),h1o=o("UniSpeechConfig"),u1o=o(" (UniSpeech model)"),p1o=l(),Kh=a("li"),ahe=a("strong"),_1o=o("unispeech-sat"),b1o=o(" \u2014 "),Mj=a("a"),v1o=o("UniSpeechSatConfig"),F1o=o(" (UniSpeechSat model)"),T1o=l(),eu=a("li"),nhe=a("strong"),M1o=o("van"),E1o=o(" \u2014 "),Ej=a("a"),C1o=o("VanConfig"),w1o=o(" (VAN model)"),A1o=l(),ou=a("li"),she=a("strong"),L1o=o("videomae"),y1o=o(" \u2014 "),Cj=a("a"),x1o=o("VideoMAEConfig"),$1o=o(" (VideoMAE model)"),k1o=l(),ru=a("li"),lhe=a("strong"),S1o=o("vilt"),R1o=o(" \u2014 "),wj=a("a"),P1o=o("ViltConfig"),B1o=o(" (ViLT model)"),I1o=l(),tu=a("li"),ihe=a("strong"),N1o=o("vision-encoder-decoder"),q1o=o(" \u2014 "),Aj=a("a"),j1o=o("VisionEncoderDecoderConfig"),D1o=o(" (Vision Encoder decoder model)"),G1o=l(),au=a("li"),dhe=a("strong"),O1o=o("vision-text-dual-encoder"),V1o=o(" \u2014 "),Lj=a("a"),X1o=o("VisionTextDualEncoderConfig"),z1o=o(" (VisionTextDualEncoder model)"),Q1o=l(),nu=a("li"),che=a("strong"),W1o=o("visual_bert"),U1o=o(" \u2014 "),yj=a("a"),H1o=o("VisualBertConfig"),J1o=o(" (VisualBERT model)"),Y1o=l(),su=a("li"),mhe=a("strong"),Z1o=o("vit"),K1o=o(" \u2014 "),xj=a("a"),e2o=o("ViTConfig"),o2o=o(" (ViT model)"),r2o=l(),lu=a("li"),fhe=a("strong"),t2o=o("vit_mae"),a2o=o(" \u2014 "),$j=a("a"),n2o=o("ViTMAEConfig"),s2o=o(" (ViTMAE model)"),l2o=l(),iu=a("li"),ghe=a("strong"),i2o=o("vit_msn"),d2o=o(" \u2014 "),kj=a("a"),c2o=o("ViTMSNConfig"),m2o=o(" (ViTMSN model)"),f2o=l(),du=a("li"),hhe=a("strong"),g2o=o("wav2vec2"),h2o=o(" \u2014 "),Sj=a("a"),u2o=o("Wav2Vec2Config"),p2o=o(" (Wav2Vec2 model)"),_2o=l(),cu=a("li"),uhe=a("strong"),b2o=o("wav2vec2-conformer"),v2o=o(" \u2014 "),Rj=a("a"),F2o=o("Wav2Vec2ConformerConfig"),T2o=o(" (Wav2Vec2-Conformer model)"),M2o=l(),mu=a("li"),phe=a("strong"),E2o=o("wavlm"),C2o=o(" \u2014 "),Pj=a("a"),w2o=o("WavLMConfig"),A2o=o(" (WavLM model)"),L2o=l(),fu=a("li"),_he=a("strong"),y2o=o("whisper"),x2o=o(" \u2014 "),Bj=a("a"),$2o=o("WhisperConfig"),k2o=o(" (Whisper model)"),S2o=l(),gu=a("li"),bhe=a("strong"),R2o=o("xclip"),P2o=o(" \u2014 "),Ij=a("a"),B2o=o("XCLIPConfig"),I2o=o(" (X-CLIP model)"),N2o=l(),hu=a("li"),vhe=a("strong"),q2o=o("xglm"),j2o=o(" \u2014 "),Nj=a("a"),D2o=o("XGLMConfig"),G2o=o(" (XGLM model)"),O2o=l(),uu=a("li"),Fhe=a("strong"),V2o=o("xlm"),X2o=o(" \u2014 "),qj=a("a"),z2o=o("XLMConfig"),Q2o=o(" (XLM model)"),W2o=l(),pu=a("li"),The=a("strong"),U2o=o("xlm-prophetnet"),H2o=o(" \u2014 "),jj=a("a"),J2o=o("XLMProphetNetConfig"),Y2o=o(" (XLM-ProphetNet model)"),Z2o=l(),_u=a("li"),Mhe=a("strong"),K2o=o("xlm-roberta"),ebo=o(" \u2014 "),Dj=a("a"),obo=o("XLMRobertaConfig"),rbo=o(" (XLM-RoBERTa model)"),tbo=l(),bu=a("li"),Ehe=a("strong"),abo=o("xlm-roberta-xl"),nbo=o(" \u2014 "),Gj=a("a"),sbo=o("XLMRobertaXLConfig"),lbo=o(" (XLM-RoBERTa-XL model)"),ibo=l(),vu=a("li"),Che=a("strong"),dbo=o("xlnet"),cbo=o(" \u2014 "),Oj=a("a"),mbo=o("XLNetConfig"),fbo=o(" (XLNet model)"),gbo=l(),Fu=a("li"),whe=a("strong"),hbo=o("yolos"),ubo=o(" \u2014 "),Vj=a("a"),pbo=o("YolosConfig"),_bo=o(" (YOLOS model)"),bbo=l(),Tu=a("li"),Ahe=a("strong"),vbo=o("yoso"),Fbo=o(" \u2014 "),Xj=a("a"),Tbo=o("YosoConfig"),Mbo=o(" (YOSO model)"),Ebo=l(),F(Mu.$$.fragment),Cbo=l(),Eu=a("div"),F(l$.$$.fragment),wbo=l(),Lhe=a("p"),Abo=o("Register a new configuration for this class."),Hro=l(),Ad=a("h2"),Cu=a("a"),yhe=a("span"),F(i$.$$.fragment),Lbo=l(),xhe=a("span"),ybo=o("AutoTokenizer"),Jro=l(),Ro=a("div"),F(d$.$$.fragment),xbo=l(),c$=a("p"),$bo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),zj=a("a"),kbo=o("AutoTokenizer.from_pretrained()"),Sbo=o(" class method."),Rbo=l(),m$=a("p"),Pbo=o("This class cannot be instantiated directly using "),$he=a("code"),Bbo=o("__init__()"),Ibo=o(" (throws an error)."),Nbo=l(),jr=a("div"),F(f$.$$.fragment),qbo=l(),khe=a("p"),jbo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Dbo=l(),rn=a("p"),Gbo=o("The tokenizer class to instantiate is selected based on the "),She=a("code"),Obo=o("model_type"),Vbo=o(` property of the config object (either
passed as an argument or loaded from `),Rhe=a("code"),Xbo=o("pretrained_model_name_or_path"),zbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Phe=a("code"),Qbo=o("pretrained_model_name_or_path"),Wbo=o(":"),Ubo=l(),k=a("ul"),us=a("li"),Bhe=a("strong"),Hbo=o("albert"),Jbo=o(" \u2014 "),Qj=a("a"),Ybo=o("AlbertTokenizer"),Zbo=o(" or "),Wj=a("a"),Kbo=o("AlbertTokenizerFast"),evo=o(" (ALBERT model)"),ovo=l(),ps=a("li"),Ihe=a("strong"),rvo=o("bart"),tvo=o(" \u2014 "),Uj=a("a"),avo=o("BartTokenizer"),nvo=o(" or "),Hj=a("a"),svo=o("BartTokenizerFast"),lvo=o(" (BART model)"),ivo=l(),_s=a("li"),Nhe=a("strong"),dvo=o("barthez"),cvo=o(" \u2014 "),Jj=a("a"),mvo=o("BarthezTokenizer"),fvo=o(" or "),Yj=a("a"),gvo=o("BarthezTokenizerFast"),hvo=o(" (BARThez model)"),uvo=l(),wu=a("li"),qhe=a("strong"),pvo=o("bartpho"),_vo=o(" \u2014 "),Zj=a("a"),bvo=o("BartphoTokenizer"),vvo=o(" (BARTpho model)"),Fvo=l(),bs=a("li"),jhe=a("strong"),Tvo=o("bert"),Mvo=o(" \u2014 "),Kj=a("a"),Evo=o("BertTokenizer"),Cvo=o(" or "),eD=a("a"),wvo=o("BertTokenizerFast"),Avo=o(" (BERT model)"),Lvo=l(),Au=a("li"),Dhe=a("strong"),yvo=o("bert-generation"),xvo=o(" \u2014 "),oD=a("a"),$vo=o("BertGenerationTokenizer"),kvo=o(" (Bert Generation model)"),Svo=l(),Lu=a("li"),Ghe=a("strong"),Rvo=o("bert-japanese"),Pvo=o(" \u2014 "),rD=a("a"),Bvo=o("BertJapaneseTokenizer"),Ivo=o(" (BertJapanese model)"),Nvo=l(),yu=a("li"),Ohe=a("strong"),qvo=o("bertweet"),jvo=o(" \u2014 "),tD=a("a"),Dvo=o("BertweetTokenizer"),Gvo=o(" (BERTweet model)"),Ovo=l(),vs=a("li"),Vhe=a("strong"),Vvo=o("big_bird"),Xvo=o(" \u2014 "),aD=a("a"),zvo=o("BigBirdTokenizer"),Qvo=o(" or "),nD=a("a"),Wvo=o("BigBirdTokenizerFast"),Uvo=o(" (BigBird model)"),Hvo=l(),Fs=a("li"),Xhe=a("strong"),Jvo=o("bigbird_pegasus"),Yvo=o(" \u2014 "),sD=a("a"),Zvo=o("PegasusTokenizer"),Kvo=o(" or "),lD=a("a"),eFo=o("PegasusTokenizerFast"),oFo=o(" (BigBird-Pegasus model)"),rFo=l(),Ts=a("li"),zhe=a("strong"),tFo=o("blenderbot"),aFo=o(" \u2014 "),iD=a("a"),nFo=o("BlenderbotTokenizer"),sFo=o(" or "),dD=a("a"),lFo=o("BlenderbotTokenizerFast"),iFo=o(" (Blenderbot model)"),dFo=l(),xu=a("li"),Qhe=a("strong"),cFo=o("blenderbot-small"),mFo=o(" \u2014 "),cD=a("a"),fFo=o("BlenderbotSmallTokenizer"),gFo=o(" (BlenderbotSmall model)"),hFo=l(),$u=a("li"),Whe=a("strong"),uFo=o("bloom"),pFo=o(" \u2014 "),mD=a("a"),_Fo=o("BloomTokenizerFast"),bFo=o(" (BLOOM model)"),vFo=l(),ku=a("li"),Uhe=a("strong"),FFo=o("byt5"),TFo=o(" \u2014 "),fD=a("a"),MFo=o("ByT5Tokenizer"),EFo=o(" (ByT5 model)"),CFo=l(),Ms=a("li"),Hhe=a("strong"),wFo=o("camembert"),AFo=o(" \u2014 "),gD=a("a"),LFo=o("CamembertTokenizer"),yFo=o(" or "),hD=a("a"),xFo=o("CamembertTokenizerFast"),$Fo=o(" (CamemBERT model)"),kFo=l(),Su=a("li"),Jhe=a("strong"),SFo=o("canine"),RFo=o(" \u2014 "),uD=a("a"),PFo=o("CanineTokenizer"),BFo=o(" (CANINE model)"),IFo=l(),Es=a("li"),Yhe=a("strong"),NFo=o("clip"),qFo=o(" \u2014 "),pD=a("a"),jFo=o("CLIPTokenizer"),DFo=o(" or "),_D=a("a"),GFo=o("CLIPTokenizerFast"),OFo=o(" (CLIP model)"),VFo=l(),Cs=a("li"),Zhe=a("strong"),XFo=o("codegen"),zFo=o(" \u2014 "),bD=a("a"),QFo=o("CodeGenTokenizer"),WFo=o(" or "),vD=a("a"),UFo=o("CodeGenTokenizerFast"),HFo=o(" (CodeGen model)"),JFo=l(),ws=a("li"),Khe=a("strong"),YFo=o("convbert"),ZFo=o(" \u2014 "),FD=a("a"),KFo=o("ConvBertTokenizer"),eTo=o(" or "),TD=a("a"),oTo=o("ConvBertTokenizerFast"),rTo=o(" (ConvBERT model)"),tTo=l(),As=a("li"),eue=a("strong"),aTo=o("cpm"),nTo=o(" \u2014 "),MD=a("a"),sTo=o("CpmTokenizer"),lTo=o(" or "),ED=a("a"),iTo=o("CpmTokenizerFast"),dTo=o(" (CPM model)"),cTo=l(),Ru=a("li"),oue=a("strong"),mTo=o("ctrl"),fTo=o(" \u2014 "),CD=a("a"),gTo=o("CTRLTokenizer"),hTo=o(" (CTRL model)"),uTo=l(),Ls=a("li"),rue=a("strong"),pTo=o("data2vec-text"),_To=o(" \u2014 "),wD=a("a"),bTo=o("RobertaTokenizer"),vTo=o(" or "),AD=a("a"),FTo=o("RobertaTokenizerFast"),TTo=o(" (Data2VecText model)"),MTo=l(),ys=a("li"),tue=a("strong"),ETo=o("deberta"),CTo=o(" \u2014 "),LD=a("a"),wTo=o("DebertaTokenizer"),ATo=o(" or "),yD=a("a"),LTo=o("DebertaTokenizerFast"),yTo=o(" (DeBERTa model)"),xTo=l(),xs=a("li"),aue=a("strong"),$To=o("deberta-v2"),kTo=o(" \u2014 "),xD=a("a"),STo=o("DebertaV2Tokenizer"),RTo=o(" or "),$D=a("a"),PTo=o("DebertaV2TokenizerFast"),BTo=o(" (DeBERTa-v2 model)"),ITo=l(),$s=a("li"),nue=a("strong"),NTo=o("distilbert"),qTo=o(" \u2014 "),kD=a("a"),jTo=o("DistilBertTokenizer"),DTo=o(" or "),SD=a("a"),GTo=o("DistilBertTokenizerFast"),OTo=o(" (DistilBERT model)"),VTo=l(),ks=a("li"),sue=a("strong"),XTo=o("dpr"),zTo=o(" \u2014 "),RD=a("a"),QTo=o("DPRQuestionEncoderTokenizer"),WTo=o(" or "),PD=a("a"),UTo=o("DPRQuestionEncoderTokenizerFast"),HTo=o(" (DPR model)"),JTo=l(),Ss=a("li"),lue=a("strong"),YTo=o("electra"),ZTo=o(" \u2014 "),BD=a("a"),KTo=o("ElectraTokenizer"),eMo=o(" or "),ID=a("a"),oMo=o("ElectraTokenizerFast"),rMo=o(" (ELECTRA model)"),tMo=l(),Rs=a("li"),iue=a("strong"),aMo=o("ernie"),nMo=o(" \u2014 "),ND=a("a"),sMo=o("BertTokenizer"),lMo=o(" or "),qD=a("a"),iMo=o("BertTokenizerFast"),dMo=o(" (ERNIE model)"),cMo=l(),Pu=a("li"),due=a("strong"),mMo=o("flaubert"),fMo=o(" \u2014 "),jD=a("a"),gMo=o("FlaubertTokenizer"),hMo=o(" (FlauBERT model)"),uMo=l(),Ps=a("li"),cue=a("strong"),pMo=o("fnet"),_Mo=o(" \u2014 "),DD=a("a"),bMo=o("FNetTokenizer"),vMo=o(" or "),GD=a("a"),FMo=o("FNetTokenizerFast"),TMo=o(" (FNet model)"),MMo=l(),Bu=a("li"),mue=a("strong"),EMo=o("fsmt"),CMo=o(" \u2014 "),OD=a("a"),wMo=o("FSMTTokenizer"),AMo=o(" (FairSeq Machine-Translation model)"),LMo=l(),Bs=a("li"),fue=a("strong"),yMo=o("funnel"),xMo=o(" \u2014 "),VD=a("a"),$Mo=o("FunnelTokenizer"),kMo=o(" or "),XD=a("a"),SMo=o("FunnelTokenizerFast"),RMo=o(" (Funnel Transformer model)"),PMo=l(),Is=a("li"),gue=a("strong"),BMo=o("gpt2"),IMo=o(" \u2014 "),zD=a("a"),NMo=o("GPT2Tokenizer"),qMo=o(" or "),QD=a("a"),jMo=o("GPT2TokenizerFast"),DMo=o(" (OpenAI GPT-2 model)"),GMo=l(),Ns=a("li"),hue=a("strong"),OMo=o("gpt_neo"),VMo=o(" \u2014 "),WD=a("a"),XMo=o("GPT2Tokenizer"),zMo=o(" or "),UD=a("a"),QMo=o("GPT2TokenizerFast"),WMo=o(" (GPT Neo model)"),UMo=l(),Iu=a("li"),uue=a("strong"),HMo=o("gpt_neox"),JMo=o(" \u2014 "),HD=a("a"),YMo=o("GPTNeoXTokenizerFast"),ZMo=o(" (GPT NeoX model)"),KMo=l(),Nu=a("li"),pue=a("strong"),eEo=o("gpt_neox_japanese"),oEo=o(" \u2014 "),JD=a("a"),rEo=o("GPTNeoXJapaneseTokenizer"),tEo=o(" (GPT NeoX Japanese model)"),aEo=l(),qs=a("li"),_ue=a("strong"),nEo=o("gptj"),sEo=o(" \u2014 "),YD=a("a"),lEo=o("GPT2Tokenizer"),iEo=o(" or "),ZD=a("a"),dEo=o("GPT2TokenizerFast"),cEo=o(" (GPT-J model)"),mEo=l(),js=a("li"),bue=a("strong"),fEo=o("groupvit"),gEo=o(" \u2014 "),KD=a("a"),hEo=o("CLIPTokenizer"),uEo=o(" or "),eG=a("a"),pEo=o("CLIPTokenizerFast"),_Eo=o(" (GroupViT model)"),bEo=l(),Ds=a("li"),vue=a("strong"),vEo=o("herbert"),FEo=o(" \u2014 "),oG=a("a"),TEo=o("HerbertTokenizer"),MEo=o(" or "),rG=a("a"),EEo=o("HerbertTokenizerFast"),CEo=o(" (HerBERT model)"),wEo=l(),qu=a("li"),Fue=a("strong"),AEo=o("hubert"),LEo=o(" \u2014 "),tG=a("a"),yEo=o("Wav2Vec2CTCTokenizer"),xEo=o(" (Hubert model)"),$Eo=l(),Gs=a("li"),Tue=a("strong"),kEo=o("ibert"),SEo=o(" \u2014 "),aG=a("a"),REo=o("RobertaTokenizer"),PEo=o(" or "),nG=a("a"),BEo=o("RobertaTokenizerFast"),IEo=o(" (I-BERT model)"),NEo=l(),Os=a("li"),Mue=a("strong"),qEo=o("layoutlm"),jEo=o(" \u2014 "),sG=a("a"),DEo=o("LayoutLMTokenizer"),GEo=o(" or "),lG=a("a"),OEo=o("LayoutLMTokenizerFast"),VEo=o(" (LayoutLM model)"),XEo=l(),Vs=a("li"),Eue=a("strong"),zEo=o("layoutlmv2"),QEo=o(" \u2014 "),iG=a("a"),WEo=o("LayoutLMv2Tokenizer"),UEo=o(" or "),dG=a("a"),HEo=o("LayoutLMv2TokenizerFast"),JEo=o(" (LayoutLMv2 model)"),YEo=l(),Xs=a("li"),Cue=a("strong"),ZEo=o("layoutlmv3"),KEo=o(" \u2014 "),cG=a("a"),e4o=o("LayoutLMv3Tokenizer"),o4o=o(" or "),mG=a("a"),r4o=o("LayoutLMv3TokenizerFast"),t4o=o(" (LayoutLMv3 model)"),a4o=l(),zs=a("li"),wue=a("strong"),n4o=o("layoutxlm"),s4o=o(" \u2014 "),fG=a("a"),l4o=o("LayoutXLMTokenizer"),i4o=o(" or "),gG=a("a"),d4o=o("LayoutXLMTokenizerFast"),c4o=o(" (LayoutXLM model)"),m4o=l(),Qs=a("li"),Aue=a("strong"),f4o=o("led"),g4o=o(" \u2014 "),hG=a("a"),h4o=o("LEDTokenizer"),u4o=o(" or "),uG=a("a"),p4o=o("LEDTokenizerFast"),_4o=o(" (LED model)"),b4o=l(),Ws=a("li"),Lue=a("strong"),v4o=o("lilt"),F4o=o(" \u2014 "),pG=a("a"),T4o=o("LayoutLMv3Tokenizer"),M4o=o(" or "),_G=a("a"),E4o=o("LayoutLMv3TokenizerFast"),C4o=o(" (LiLT model)"),w4o=l(),Us=a("li"),yue=a("strong"),A4o=o("longformer"),L4o=o(" \u2014 "),bG=a("a"),y4o=o("LongformerTokenizer"),x4o=o(" or "),vG=a("a"),$4o=o("LongformerTokenizerFast"),k4o=o(" (Longformer model)"),S4o=l(),Hs=a("li"),xue=a("strong"),R4o=o("longt5"),P4o=o(" \u2014 "),FG=a("a"),B4o=o("T5Tokenizer"),I4o=o(" or "),TG=a("a"),N4o=o("T5TokenizerFast"),q4o=o(" (LongT5 model)"),j4o=l(),ju=a("li"),$ue=a("strong"),D4o=o("luke"),G4o=o(" \u2014 "),MG=a("a"),O4o=o("LukeTokenizer"),V4o=o(" (LUKE model)"),X4o=l(),Js=a("li"),kue=a("strong"),z4o=o("lxmert"),Q4o=o(" \u2014 "),EG=a("a"),W4o=o("LxmertTokenizer"),U4o=o(" or "),CG=a("a"),H4o=o("LxmertTokenizerFast"),J4o=o(" (LXMERT model)"),Y4o=l(),Du=a("li"),Sue=a("strong"),Z4o=o("m2m_100"),K4o=o(" \u2014 "),wG=a("a"),eCo=o("M2M100Tokenizer"),oCo=o(" (M2M100 model)"),rCo=l(),Gu=a("li"),Rue=a("strong"),tCo=o("marian"),aCo=o(" \u2014 "),AG=a("a"),nCo=o("MarianTokenizer"),sCo=o(" (Marian model)"),lCo=l(),Ys=a("li"),Pue=a("strong"),iCo=o("mbart"),dCo=o(" \u2014 "),LG=a("a"),cCo=o("MBartTokenizer"),mCo=o(" or "),yG=a("a"),fCo=o("MBartTokenizerFast"),gCo=o(" (mBART model)"),hCo=l(),Zs=a("li"),Bue=a("strong"),uCo=o("mbart50"),pCo=o(" \u2014 "),xG=a("a"),_Co=o("MBart50Tokenizer"),bCo=o(" or "),$G=a("a"),vCo=o("MBart50TokenizerFast"),FCo=o(" (mBART-50 model)"),TCo=l(),Ks=a("li"),Iue=a("strong"),MCo=o("megatron-bert"),ECo=o(" \u2014 "),kG=a("a"),CCo=o("BertTokenizer"),wCo=o(" or "),SG=a("a"),ACo=o("BertTokenizerFast"),LCo=o(" (Megatron-BERT model)"),yCo=l(),Ou=a("li"),Nue=a("strong"),xCo=o("mluke"),$Co=o(" \u2014 "),RG=a("a"),kCo=o("MLukeTokenizer"),SCo=o(" (mLUKE model)"),RCo=l(),el=a("li"),que=a("strong"),PCo=o("mobilebert"),BCo=o(" \u2014 "),PG=a("a"),ICo=o("MobileBertTokenizer"),NCo=o(" or "),BG=a("a"),qCo=o("MobileBertTokenizerFast"),jCo=o(" (MobileBERT model)"),DCo=l(),ol=a("li"),jue=a("strong"),GCo=o("mpnet"),OCo=o(" \u2014 "),IG=a("a"),VCo=o("MPNetTokenizer"),XCo=o(" or "),NG=a("a"),zCo=o("MPNetTokenizerFast"),QCo=o(" (MPNet model)"),WCo=l(),rl=a("li"),Due=a("strong"),UCo=o("mt5"),HCo=o(" \u2014 "),qG=a("a"),JCo=o("MT5Tokenizer"),YCo=o(" or "),jG=a("a"),ZCo=o("MT5TokenizerFast"),KCo=o(" (MT5 model)"),e3o=l(),tl=a("li"),Gue=a("strong"),o3o=o("mvp"),r3o=o(" \u2014 "),DG=a("a"),t3o=o("MvpTokenizer"),a3o=o(" or "),GG=a("a"),n3o=o("MvpTokenizerFast"),s3o=o(" (MVP model)"),l3o=l(),al=a("li"),Oue=a("strong"),i3o=o("nezha"),d3o=o(" \u2014 "),OG=a("a"),c3o=o("BertTokenizer"),m3o=o(" or "),VG=a("a"),f3o=o("BertTokenizerFast"),g3o=o(" (Nezha model)"),h3o=l(),nl=a("li"),Vue=a("strong"),u3o=o("nllb"),p3o=o(" \u2014 "),XG=a("a"),_3o=o("NllbTokenizer"),b3o=o(" or "),zG=a("a"),v3o=o("NllbTokenizerFast"),F3o=o(" (NLLB model)"),T3o=l(),sl=a("li"),Xue=a("strong"),M3o=o("nystromformer"),E3o=o(" \u2014 "),QG=a("a"),C3o=o("AlbertTokenizer"),w3o=o(" or "),WG=a("a"),A3o=o("AlbertTokenizerFast"),L3o=o(" (Nystr\xF6mformer model)"),y3o=l(),ll=a("li"),zue=a("strong"),x3o=o("openai-gpt"),$3o=o(" \u2014 "),UG=a("a"),k3o=o("OpenAIGPTTokenizer"),S3o=o(" or "),HG=a("a"),R3o=o("OpenAIGPTTokenizerFast"),P3o=o(" (OpenAI GPT model)"),B3o=l(),Vu=a("li"),Que=a("strong"),I3o=o("opt"),N3o=o(" \u2014 "),JG=a("a"),q3o=o("GPT2Tokenizer"),j3o=o(" (OPT model)"),D3o=l(),il=a("li"),Wue=a("strong"),G3o=o("owlvit"),O3o=o(" \u2014 "),YG=a("a"),V3o=o("CLIPTokenizer"),X3o=o(" or "),ZG=a("a"),z3o=o("CLIPTokenizerFast"),Q3o=o(" (OWL-ViT model)"),W3o=l(),dl=a("li"),Uue=a("strong"),U3o=o("pegasus"),H3o=o(" \u2014 "),KG=a("a"),J3o=o("PegasusTokenizer"),Y3o=o(" or "),eO=a("a"),Z3o=o("PegasusTokenizerFast"),K3o=o(" (Pegasus model)"),e5o=l(),Xu=a("li"),Hue=a("strong"),o5o=o("perceiver"),r5o=o(" \u2014 "),oO=a("a"),t5o=o("PerceiverTokenizer"),a5o=o(" (Perceiver model)"),n5o=l(),zu=a("li"),Jue=a("strong"),s5o=o("phobert"),l5o=o(" \u2014 "),rO=a("a"),i5o=o("PhobertTokenizer"),d5o=o(" (PhoBERT model)"),c5o=l(),Qu=a("li"),Yue=a("strong"),m5o=o("plbart"),f5o=o(" \u2014 "),tO=a("a"),g5o=o("PLBartTokenizer"),h5o=o(" (PLBart model)"),u5o=l(),Wu=a("li"),Zue=a("strong"),p5o=o("prophetnet"),_5o=o(" \u2014 "),aO=a("a"),b5o=o("ProphetNetTokenizer"),v5o=o(" (ProphetNet model)"),F5o=l(),cl=a("li"),Kue=a("strong"),T5o=o("qdqbert"),M5o=o(" \u2014 "),nO=a("a"),E5o=o("BertTokenizer"),C5o=o(" or "),sO=a("a"),w5o=o("BertTokenizerFast"),A5o=o(" (QDQBert model)"),L5o=l(),Uu=a("li"),epe=a("strong"),y5o=o("rag"),x5o=o(" \u2014 "),lO=a("a"),$5o=o("RagTokenizer"),k5o=o(" (RAG model)"),S5o=l(),ml=a("li"),ope=a("strong"),R5o=o("realm"),P5o=o(" \u2014 "),iO=a("a"),B5o=o("RealmTokenizer"),I5o=o(" or "),dO=a("a"),N5o=o("RealmTokenizerFast"),q5o=o(" (REALM model)"),j5o=l(),fl=a("li"),rpe=a("strong"),D5o=o("reformer"),G5o=o(" \u2014 "),cO=a("a"),O5o=o("ReformerTokenizer"),V5o=o(" or "),mO=a("a"),X5o=o("ReformerTokenizerFast"),z5o=o(" (Reformer model)"),Q5o=l(),gl=a("li"),tpe=a("strong"),W5o=o("rembert"),U5o=o(" \u2014 "),fO=a("a"),H5o=o("RemBertTokenizer"),J5o=o(" or "),gO=a("a"),Y5o=o("RemBertTokenizerFast"),Z5o=o(" (RemBERT model)"),K5o=l(),hl=a("li"),ape=a("strong"),e0o=o("retribert"),o0o=o(" \u2014 "),hO=a("a"),r0o=o("RetriBertTokenizer"),t0o=o(" or "),uO=a("a"),a0o=o("RetriBertTokenizerFast"),n0o=o(" (RetriBERT model)"),s0o=l(),ul=a("li"),npe=a("strong"),l0o=o("roberta"),i0o=o(" \u2014 "),pO=a("a"),d0o=o("RobertaTokenizer"),c0o=o(" or "),_O=a("a"),m0o=o("RobertaTokenizerFast"),f0o=o(" (RoBERTa model)"),g0o=l(),pl=a("li"),spe=a("strong"),h0o=o("roformer"),u0o=o(" \u2014 "),bO=a("a"),p0o=o("RoFormerTokenizer"),_0o=o(" or "),vO=a("a"),b0o=o("RoFormerTokenizerFast"),v0o=o(" (RoFormer model)"),F0o=l(),Hu=a("li"),lpe=a("strong"),T0o=o("speech_to_text"),M0o=o(" \u2014 "),FO=a("a"),E0o=o("Speech2TextTokenizer"),C0o=o(" (Speech2Text model)"),w0o=l(),Ju=a("li"),ipe=a("strong"),A0o=o("speech_to_text_2"),L0o=o(" \u2014 "),TO=a("a"),y0o=o("Speech2Text2Tokenizer"),x0o=o(" (Speech2Text2 model)"),$0o=l(),_l=a("li"),dpe=a("strong"),k0o=o("splinter"),S0o=o(" \u2014 "),MO=a("a"),R0o=o("SplinterTokenizer"),P0o=o(" or "),EO=a("a"),B0o=o("SplinterTokenizerFast"),I0o=o(" (Splinter model)"),N0o=l(),bl=a("li"),cpe=a("strong"),q0o=o("squeezebert"),j0o=o(" \u2014 "),CO=a("a"),D0o=o("SqueezeBertTokenizer"),G0o=o(" or "),wO=a("a"),O0o=o("SqueezeBertTokenizerFast"),V0o=o(" (SqueezeBERT model)"),X0o=l(),vl=a("li"),mpe=a("strong"),z0o=o("t5"),Q0o=o(" \u2014 "),AO=a("a"),W0o=o("T5Tokenizer"),U0o=o(" or "),LO=a("a"),H0o=o("T5TokenizerFast"),J0o=o(" (T5 model)"),Y0o=l(),Yu=a("li"),fpe=a("strong"),Z0o=o("tapas"),K0o=o(" \u2014 "),yO=a("a"),ewo=o("TapasTokenizer"),owo=o(" (TAPAS model)"),rwo=l(),Zu=a("li"),gpe=a("strong"),two=o("tapex"),awo=o(" \u2014 "),xO=a("a"),nwo=o("TapexTokenizer"),swo=o(" (TAPEX model)"),lwo=l(),Ku=a("li"),hpe=a("strong"),iwo=o("transfo-xl"),dwo=o(" \u2014 "),$O=a("a"),cwo=o("TransfoXLTokenizer"),mwo=o(" (Transformer-XL model)"),fwo=l(),Fl=a("li"),upe=a("strong"),gwo=o("vilt"),hwo=o(" \u2014 "),kO=a("a"),uwo=o("BertTokenizer"),pwo=o(" or "),SO=a("a"),_wo=o("BertTokenizerFast"),bwo=o(" (ViLT model)"),vwo=l(),Tl=a("li"),ppe=a("strong"),Fwo=o("visual_bert"),Two=o(" \u2014 "),RO=a("a"),Mwo=o("BertTokenizer"),Ewo=o(" or "),PO=a("a"),Cwo=o("BertTokenizerFast"),wwo=o(" (VisualBERT model)"),Awo=l(),ep=a("li"),_pe=a("strong"),Lwo=o("wav2vec2"),ywo=o(" \u2014 "),BO=a("a"),xwo=o("Wav2Vec2CTCTokenizer"),$wo=o(" (Wav2Vec2 model)"),kwo=l(),op=a("li"),bpe=a("strong"),Swo=o("wav2vec2-conformer"),Rwo=o(" \u2014 "),IO=a("a"),Pwo=o("Wav2Vec2CTCTokenizer"),Bwo=o(" (Wav2Vec2-Conformer model)"),Iwo=l(),rp=a("li"),vpe=a("strong"),Nwo=o("wav2vec2_phoneme"),qwo=o(" \u2014 "),NO=a("a"),jwo=o("Wav2Vec2PhonemeCTCTokenizer"),Dwo=o(" (Wav2Vec2Phoneme model)"),Gwo=l(),tp=a("li"),Fpe=a("strong"),Owo=o("whisper"),Vwo=o(" \u2014 "),qO=a("a"),Xwo=o("WhisperTokenizer"),zwo=o(" (Whisper model)"),Qwo=l(),Ml=a("li"),Tpe=a("strong"),Wwo=o("xclip"),Uwo=o(" \u2014 "),jO=a("a"),Hwo=o("CLIPTokenizer"),Jwo=o(" or "),DO=a("a"),Ywo=o("CLIPTokenizerFast"),Zwo=o(" (X-CLIP model)"),Kwo=l(),El=a("li"),Mpe=a("strong"),eAo=o("xglm"),oAo=o(" \u2014 "),GO=a("a"),rAo=o("XGLMTokenizer"),tAo=o(" or "),OO=a("a"),aAo=o("XGLMTokenizerFast"),nAo=o(" (XGLM model)"),sAo=l(),ap=a("li"),Epe=a("strong"),lAo=o("xlm"),iAo=o(" \u2014 "),VO=a("a"),dAo=o("XLMTokenizer"),cAo=o(" (XLM model)"),mAo=l(),np=a("li"),Cpe=a("strong"),fAo=o("xlm-prophetnet"),gAo=o(" \u2014 "),XO=a("a"),hAo=o("XLMProphetNetTokenizer"),uAo=o(" (XLM-ProphetNet model)"),pAo=l(),Cl=a("li"),wpe=a("strong"),_Ao=o("xlm-roberta"),bAo=o(" \u2014 "),zO=a("a"),vAo=o("XLMRobertaTokenizer"),FAo=o(" or "),QO=a("a"),TAo=o("XLMRobertaTokenizerFast"),MAo=o(" (XLM-RoBERTa model)"),EAo=l(),wl=a("li"),Ape=a("strong"),CAo=o("xlm-roberta-xl"),wAo=o(" \u2014 "),WO=a("a"),AAo=o("XLMRobertaTokenizer"),LAo=o(" or "),UO=a("a"),yAo=o("XLMRobertaTokenizerFast"),xAo=o(" (XLM-RoBERTa-XL model)"),$Ao=l(),Al=a("li"),Lpe=a("strong"),kAo=o("xlnet"),SAo=o(" \u2014 "),HO=a("a"),RAo=o("XLNetTokenizer"),PAo=o(" or "),JO=a("a"),BAo=o("XLNetTokenizerFast"),IAo=o(" (XLNet model)"),NAo=l(),Ll=a("li"),ype=a("strong"),qAo=o("yoso"),jAo=o(" \u2014 "),YO=a("a"),DAo=o("AlbertTokenizer"),GAo=o(" or "),ZO=a("a"),OAo=o("AlbertTokenizerFast"),VAo=o(" (YOSO model)"),XAo=l(),F(sp.$$.fragment),zAo=l(),lp=a("div"),F(g$.$$.fragment),QAo=l(),xpe=a("p"),WAo=o("Register a new tokenizer in this mapping."),Yro=l(),Ld=a("h2"),ip=a("a"),$pe=a("span"),F(h$.$$.fragment),UAo=l(),kpe=a("span"),HAo=o("AutoFeatureExtractor"),Zro=l(),Po=a("div"),F(u$.$$.fragment),JAo=l(),p$=a("p"),YAo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KO=a("a"),ZAo=o("AutoFeatureExtractor.from_pretrained()"),KAo=o(" class method."),e6o=l(),_$=a("p"),o6o=o("This class cannot be instantiated directly using "),Spe=a("code"),r6o=o("__init__()"),t6o=o(" (throws an error)."),a6o=l(),Ye=a("div"),F(b$.$$.fragment),n6o=l(),Rpe=a("p"),s6o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),l6o=l(),tn=a("p"),i6o=o("The feature extractor class to instantiate is selected based on the "),Ppe=a("code"),d6o=o("model_type"),c6o=o(` property of the config object
(either passed as an argument or loaded from `),Bpe=a("code"),m6o=o("pretrained_model_name_or_path"),f6o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ipe=a("code"),g6o=o("pretrained_model_name_or_path"),h6o=o(":"),u6o=l(),z=a("ul"),dp=a("li"),Npe=a("strong"),p6o=o("beit"),_6o=o(" \u2014 "),eV=a("a"),b6o=o("BeitFeatureExtractor"),v6o=o(" (BEiT model)"),F6o=l(),cp=a("li"),qpe=a("strong"),T6o=o("clip"),M6o=o(" \u2014 "),oV=a("a"),E6o=o("CLIPFeatureExtractor"),C6o=o(" (CLIP model)"),w6o=l(),mp=a("li"),jpe=a("strong"),A6o=o("conditional_detr"),L6o=o(" \u2014 "),rV=a("a"),y6o=o("ConditionalDetrFeatureExtractor"),x6o=o(" (Conditional DETR model)"),$6o=l(),fp=a("li"),Dpe=a("strong"),k6o=o("convnext"),S6o=o(" \u2014 "),tV=a("a"),R6o=o("ConvNextFeatureExtractor"),P6o=o(" (ConvNeXT model)"),B6o=l(),gp=a("li"),Gpe=a("strong"),I6o=o("cvt"),N6o=o(" \u2014 "),aV=a("a"),q6o=o("ConvNextFeatureExtractor"),j6o=o(" (CvT model)"),D6o=l(),hp=a("li"),Ope=a("strong"),G6o=o("data2vec-audio"),O6o=o(" \u2014 "),nV=a("a"),V6o=o("Wav2Vec2FeatureExtractor"),X6o=o(" (Data2VecAudio model)"),z6o=l(),up=a("li"),Vpe=a("strong"),Q6o=o("data2vec-vision"),W6o=o(" \u2014 "),sV=a("a"),U6o=o("BeitFeatureExtractor"),H6o=o(" (Data2VecVision model)"),J6o=l(),pp=a("li"),Xpe=a("strong"),Y6o=o("deformable_detr"),Z6o=o(" \u2014 "),lV=a("a"),K6o=o("DeformableDetrFeatureExtractor"),e7o=o(" (Deformable DETR model)"),o7o=l(),_p=a("li"),zpe=a("strong"),r7o=o("deit"),t7o=o(" \u2014 "),iV=a("a"),a7o=o("DeiTFeatureExtractor"),n7o=o(" (DeiT model)"),s7o=l(),bp=a("li"),Qpe=a("strong"),l7o=o("detr"),i7o=o(" \u2014 "),dV=a("a"),d7o=o("DetrFeatureExtractor"),c7o=o(" (DETR model)"),m7o=l(),vp=a("li"),Wpe=a("strong"),f7o=o("donut"),g7o=o(" \u2014 "),cV=a("a"),h7o=o("DonutFeatureExtractor"),u7o=o(" (Donut model)"),p7o=l(),Fp=a("li"),Upe=a("strong"),_7o=o("dpt"),b7o=o(" \u2014 "),mV=a("a"),v7o=o("DPTFeatureExtractor"),F7o=o(" (DPT model)"),T7o=l(),Tp=a("li"),Hpe=a("strong"),M7o=o("flava"),E7o=o(" \u2014 "),fV=a("a"),C7o=o("FlavaFeatureExtractor"),w7o=o(" (FLAVA model)"),A7o=l(),Mp=a("li"),Jpe=a("strong"),L7o=o("glpn"),y7o=o(" \u2014 "),gV=a("a"),x7o=o("GLPNFeatureExtractor"),$7o=o(" (GLPN model)"),k7o=l(),Ep=a("li"),Ype=a("strong"),S7o=o("groupvit"),R7o=o(" \u2014 "),hV=a("a"),P7o=o("CLIPFeatureExtractor"),B7o=o(" (GroupViT model)"),I7o=l(),Cp=a("li"),Zpe=a("strong"),N7o=o("hubert"),q7o=o(" \u2014 "),uV=a("a"),j7o=o("Wav2Vec2FeatureExtractor"),D7o=o(" (Hubert model)"),G7o=l(),wp=a("li"),Kpe=a("strong"),O7o=o("imagegpt"),V7o=o(" \u2014 "),pV=a("a"),X7o=o("ImageGPTFeatureExtractor"),z7o=o(" (ImageGPT model)"),Q7o=l(),Ap=a("li"),e_e=a("strong"),W7o=o("layoutlmv2"),U7o=o(" \u2014 "),_V=a("a"),H7o=o("LayoutLMv2FeatureExtractor"),J7o=o(" (LayoutLMv2 model)"),Y7o=l(),Lp=a("li"),o_e=a("strong"),Z7o=o("layoutlmv3"),K7o=o(" \u2014 "),bV=a("a"),eLo=o("LayoutLMv3FeatureExtractor"),oLo=o(" (LayoutLMv3 model)"),rLo=l(),yp=a("li"),r_e=a("strong"),tLo=o("levit"),aLo=o(" \u2014 "),vV=a("a"),nLo=o("LevitFeatureExtractor"),sLo=o(" (LeViT model)"),lLo=l(),xp=a("li"),t_e=a("strong"),iLo=o("maskformer"),dLo=o(" \u2014 "),FV=a("a"),cLo=o("MaskFormerFeatureExtractor"),mLo=o(" (MaskFormer model)"),fLo=l(),$p=a("li"),a_e=a("strong"),gLo=o("mctct"),hLo=o(" \u2014 "),TV=a("a"),uLo=o("MCTCTFeatureExtractor"),pLo=o(" (M-CTC-T model)"),_Lo=l(),kp=a("li"),n_e=a("strong"),bLo=o("mobilevit"),vLo=o(" \u2014 "),MV=a("a"),FLo=o("MobileViTFeatureExtractor"),TLo=o(" (MobileViT model)"),MLo=l(),Sp=a("li"),s_e=a("strong"),ELo=o("owlvit"),CLo=o(" \u2014 "),EV=a("a"),wLo=o("OwlViTFeatureExtractor"),ALo=o(" (OWL-ViT model)"),LLo=l(),Rp=a("li"),l_e=a("strong"),yLo=o("perceiver"),xLo=o(" \u2014 "),CV=a("a"),$Lo=o("PerceiverFeatureExtractor"),kLo=o(" (Perceiver model)"),SLo=l(),Pp=a("li"),i_e=a("strong"),RLo=o("poolformer"),PLo=o(" \u2014 "),wV=a("a"),BLo=o("PoolFormerFeatureExtractor"),ILo=o(" (PoolFormer model)"),NLo=l(),Bp=a("li"),d_e=a("strong"),qLo=o("regnet"),jLo=o(" \u2014 "),AV=a("a"),DLo=o("ConvNextFeatureExtractor"),GLo=o(" (RegNet model)"),OLo=l(),Ip=a("li"),c_e=a("strong"),VLo=o("resnet"),XLo=o(" \u2014 "),LV=a("a"),zLo=o("ConvNextFeatureExtractor"),QLo=o(" (ResNet model)"),WLo=l(),Np=a("li"),m_e=a("strong"),ULo=o("segformer"),HLo=o(" \u2014 "),yV=a("a"),JLo=o("SegformerFeatureExtractor"),YLo=o(" (SegFormer model)"),ZLo=l(),qp=a("li"),f_e=a("strong"),KLo=o("speech_to_text"),e8o=o(" \u2014 "),xV=a("a"),o8o=o("Speech2TextFeatureExtractor"),r8o=o(" (Speech2Text model)"),t8o=l(),jp=a("li"),g_e=a("strong"),a8o=o("swin"),n8o=o(" \u2014 "),$V=a("a"),s8o=o("ViTFeatureExtractor"),l8o=o(" (Swin Transformer model)"),i8o=l(),Dp=a("li"),h_e=a("strong"),d8o=o("swinv2"),c8o=o(" \u2014 "),kV=a("a"),m8o=o("ViTFeatureExtractor"),f8o=o(" (Swin Transformer V2 model)"),g8o=l(),Gp=a("li"),u_e=a("strong"),h8o=o("van"),u8o=o(" \u2014 "),SV=a("a"),p8o=o("ConvNextFeatureExtractor"),_8o=o(" (VAN model)"),b8o=l(),Op=a("li"),p_e=a("strong"),v8o=o("videomae"),F8o=o(" \u2014 "),RV=a("a"),T8o=o("VideoMAEFeatureExtractor"),M8o=o(" (VideoMAE model)"),E8o=l(),Vp=a("li"),__e=a("strong"),C8o=o("vilt"),w8o=o(" \u2014 "),PV=a("a"),A8o=o("ViltFeatureExtractor"),L8o=o(" (ViLT model)"),y8o=l(),Xp=a("li"),b_e=a("strong"),x8o=o("vit"),$8o=o(" \u2014 "),BV=a("a"),k8o=o("ViTFeatureExtractor"),S8o=o(" (ViT model)"),R8o=l(),zp=a("li"),v_e=a("strong"),P8o=o("vit_mae"),B8o=o(" \u2014 "),IV=a("a"),I8o=o("ViTFeatureExtractor"),N8o=o(" (ViTMAE model)"),q8o=l(),Qp=a("li"),F_e=a("strong"),j8o=o("vit_msn"),D8o=o(" \u2014 "),NV=a("a"),G8o=o("ViTFeatureExtractor"),O8o=o(" (ViTMSN model)"),V8o=l(),Wp=a("li"),T_e=a("strong"),X8o=o("wav2vec2"),z8o=o(" \u2014 "),qV=a("a"),Q8o=o("Wav2Vec2FeatureExtractor"),W8o=o(" (Wav2Vec2 model)"),U8o=l(),Up=a("li"),M_e=a("strong"),H8o=o("wav2vec2-conformer"),J8o=o(" \u2014 "),jV=a("a"),Y8o=o("Wav2Vec2FeatureExtractor"),Z8o=o(" (Wav2Vec2-Conformer model)"),K8o=l(),Hp=a("li"),E_e=a("strong"),eyo=o("whisper"),oyo=o(" \u2014 "),DV=a("a"),ryo=o("WhisperFeatureExtractor"),tyo=o(" (Whisper model)"),ayo=l(),Jp=a("li"),C_e=a("strong"),nyo=o("xclip"),syo=o(" \u2014 "),GV=a("a"),lyo=o("CLIPFeatureExtractor"),iyo=o(" (X-CLIP model)"),dyo=l(),Yp=a("li"),w_e=a("strong"),cyo=o("yolos"),myo=o(" \u2014 "),OV=a("a"),fyo=o("YolosFeatureExtractor"),gyo=o(" (YOLOS model)"),hyo=l(),F(Zp.$$.fragment),uyo=l(),F(Kp.$$.fragment),pyo=l(),e_=a("div"),F(v$.$$.fragment),_yo=l(),A_e=a("p"),byo=o("Register a new feature extractor for this class."),Kro=l(),yd=a("h2"),o_=a("a"),L_e=a("span"),F(F$.$$.fragment),vyo=l(),y_e=a("span"),Fyo=o("AutoProcessor"),eto=l(),Bo=a("div"),F(T$.$$.fragment),Tyo=l(),M$=a("p"),Myo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),VV=a("a"),Eyo=o("AutoProcessor.from_pretrained()"),Cyo=o(" class method."),wyo=l(),E$=a("p"),Ayo=o("This class cannot be instantiated directly using "),x_e=a("code"),Lyo=o("__init__()"),yyo=o(" (throws an error)."),xyo=l(),Ze=a("div"),F(C$.$$.fragment),$yo=l(),$_e=a("p"),kyo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Syo=l(),xd=a("p"),Ryo=o("The processor class to instantiate is selected based on the "),k_e=a("code"),Pyo=o("model_type"),Byo=o(` property of the config object (either
passed as an argument or loaded from `),S_e=a("code"),Iyo=o("pretrained_model_name_or_path"),Nyo=o(" if possible):"),qyo=l(),se=a("ul"),r_=a("li"),R_e=a("strong"),jyo=o("clip"),Dyo=o(" \u2014 "),XV=a("a"),Gyo=o("CLIPProcessor"),Oyo=o(" (CLIP model)"),Vyo=l(),t_=a("li"),P_e=a("strong"),Xyo=o("donut"),zyo=o(" \u2014 "),zV=a("a"),Qyo=o("DonutProcessor"),Wyo=o(" (Donut model)"),Uyo=l(),a_=a("li"),B_e=a("strong"),Hyo=o("flava"),Jyo=o(" \u2014 "),QV=a("a"),Yyo=o("FlavaProcessor"),Zyo=o(" (FLAVA model)"),Kyo=l(),n_=a("li"),I_e=a("strong"),e9o=o("groupvit"),o9o=o(" \u2014 "),WV=a("a"),r9o=o("CLIPProcessor"),t9o=o(" (GroupViT model)"),a9o=l(),s_=a("li"),N_e=a("strong"),n9o=o("layoutlmv2"),s9o=o(" \u2014 "),UV=a("a"),l9o=o("LayoutLMv2Processor"),i9o=o(" (LayoutLMv2 model)"),d9o=l(),l_=a("li"),q_e=a("strong"),c9o=o("layoutlmv3"),m9o=o(" \u2014 "),HV=a("a"),f9o=o("LayoutLMv3Processor"),g9o=o(" (LayoutLMv3 model)"),h9o=l(),i_=a("li"),j_e=a("strong"),u9o=o("layoutxlm"),p9o=o(" \u2014 "),JV=a("a"),_9o=o("LayoutXLMProcessor"),b9o=o(" (LayoutXLM model)"),v9o=l(),d_=a("li"),D_e=a("strong"),F9o=o("markuplm"),T9o=o(" \u2014 "),YV=a("a"),M9o=o("MarkupLMProcessor"),E9o=o(" (MarkupLM model)"),C9o=l(),c_=a("li"),G_e=a("strong"),w9o=o("owlvit"),A9o=o(" \u2014 "),ZV=a("a"),L9o=o("OwlViTProcessor"),y9o=o(" (OWL-ViT model)"),x9o=l(),m_=a("li"),O_e=a("strong"),$9o=o("sew"),k9o=o(" \u2014 "),KV=a("a"),S9o=o("Wav2Vec2Processor"),R9o=o(" (SEW model)"),P9o=l(),f_=a("li"),V_e=a("strong"),B9o=o("sew-d"),I9o=o(" \u2014 "),eX=a("a"),N9o=o("Wav2Vec2Processor"),q9o=o(" (SEW-D model)"),j9o=l(),g_=a("li"),X_e=a("strong"),D9o=o("speech_to_text"),G9o=o(" \u2014 "),oX=a("a"),O9o=o("Speech2TextProcessor"),V9o=o(" (Speech2Text model)"),X9o=l(),h_=a("li"),z_e=a("strong"),z9o=o("speech_to_text_2"),Q9o=o(" \u2014 "),rX=a("a"),W9o=o("Speech2Text2Processor"),U9o=o(" (Speech2Text2 model)"),H9o=l(),u_=a("li"),Q_e=a("strong"),J9o=o("trocr"),Y9o=o(" \u2014 "),tX=a("a"),Z9o=o("TrOCRProcessor"),K9o=o(" (TrOCR model)"),exo=l(),p_=a("li"),W_e=a("strong"),oxo=o("unispeech"),rxo=o(" \u2014 "),aX=a("a"),txo=o("Wav2Vec2Processor"),axo=o(" (UniSpeech model)"),nxo=l(),__=a("li"),U_e=a("strong"),sxo=o("unispeech-sat"),lxo=o(" \u2014 "),nX=a("a"),ixo=o("Wav2Vec2Processor"),dxo=o(" (UniSpeechSat model)"),cxo=l(),b_=a("li"),H_e=a("strong"),mxo=o("vilt"),fxo=o(" \u2014 "),sX=a("a"),gxo=o("ViltProcessor"),hxo=o(" (ViLT model)"),uxo=l(),v_=a("li"),J_e=a("strong"),pxo=o("vision-text-dual-encoder"),_xo=o(" \u2014 "),lX=a("a"),bxo=o("VisionTextDualEncoderProcessor"),vxo=o(" (VisionTextDualEncoder model)"),Fxo=l(),F_=a("li"),Y_e=a("strong"),Txo=o("wav2vec2"),Mxo=o(" \u2014 "),iX=a("a"),Exo=o("Wav2Vec2Processor"),Cxo=o(" (Wav2Vec2 model)"),wxo=l(),T_=a("li"),Z_e=a("strong"),Axo=o("wav2vec2-conformer"),Lxo=o(" \u2014 "),dX=a("a"),yxo=o("Wav2Vec2Processor"),xxo=o(" (Wav2Vec2-Conformer model)"),$xo=l(),M_=a("li"),K_e=a("strong"),kxo=o("wavlm"),Sxo=o(" \u2014 "),cX=a("a"),Rxo=o("Wav2Vec2Processor"),Pxo=o(" (WavLM model)"),Bxo=l(),E_=a("li"),e1e=a("strong"),Ixo=o("whisper"),Nxo=o(" \u2014 "),mX=a("a"),qxo=o("WhisperProcessor"),jxo=o(" (Whisper model)"),Dxo=l(),C_=a("li"),o1e=a("strong"),Gxo=o("xclip"),Oxo=o(" \u2014 "),fX=a("a"),Vxo=o("CLIPProcessor"),Xxo=o(" (X-CLIP model)"),zxo=l(),F(w_.$$.fragment),Qxo=l(),F(A_.$$.fragment),Wxo=l(),L_=a("div"),F(w$.$$.fragment),Uxo=l(),r1e=a("p"),Hxo=o("Register a new processor for this class."),oto=l(),$d=a("h2"),y_=a("a"),t1e=a("span"),F(A$.$$.fragment),Jxo=l(),a1e=a("span"),Yxo=o("AutoModel"),rto=l(),Io=a("div"),F(L$.$$.fragment),Zxo=l(),kd=a("p"),Kxo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gX=a("a"),e$o=o("from_pretrained()"),o$o=o(" class method or the "),hX=a("a"),r$o=o("from_config()"),t$o=o(` class
method.`),a$o=l(),y$=a("p"),n$o=o("This class cannot be instantiated directly using "),n1e=a("code"),s$o=o("__init__()"),l$o=o(" (throws an error)."),i$o=l(),Tt=a("div"),F(x$.$$.fragment),d$o=l(),s1e=a("p"),c$o=o("Instantiates one of the base model classes of the library from a configuration."),m$o=l(),Sd=a("p"),f$o=o(`Note:
Loading a model from its configuration file does `),l1e=a("strong"),g$o=o("not"),h$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uX=a("a"),u$o=o("from_pretrained()"),p$o=o(" to load the model weights."),_$o=l(),F(x_.$$.fragment),b$o=l(),Ke=a("div"),F($$.$$.fragment),v$o=l(),i1e=a("p"),F$o=o("Instantiate one of the base model classes of the library from a pretrained model."),T$o=l(),an=a("p"),M$o=o("The model class to instantiate is selected based on the "),d1e=a("code"),E$o=o("model_type"),C$o=o(` property of the config object (either
passed as an argument or loaded from `),c1e=a("code"),w$o=o("pretrained_model_name_or_path"),A$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m1e=a("code"),L$o=o("pretrained_model_name_or_path"),y$o=o(":"),x$o=l(),y=a("ul"),$_=a("li"),f1e=a("strong"),$$o=o("albert"),k$o=o(" \u2014 "),pX=a("a"),S$o=o("AlbertModel"),R$o=o(" (ALBERT model)"),P$o=l(),k_=a("li"),g1e=a("strong"),B$o=o("bart"),I$o=o(" \u2014 "),_X=a("a"),N$o=o("BartModel"),q$o=o(" (BART model)"),j$o=l(),S_=a("li"),h1e=a("strong"),D$o=o("beit"),G$o=o(" \u2014 "),bX=a("a"),O$o=o("BeitModel"),V$o=o(" (BEiT model)"),X$o=l(),R_=a("li"),u1e=a("strong"),z$o=o("bert"),Q$o=o(" \u2014 "),vX=a("a"),W$o=o("BertModel"),U$o=o(" (BERT model)"),H$o=l(),P_=a("li"),p1e=a("strong"),J$o=o("bert-generation"),Y$o=o(" \u2014 "),FX=a("a"),Z$o=o("BertGenerationEncoder"),K$o=o(" (Bert Generation model)"),eko=l(),B_=a("li"),_1e=a("strong"),oko=o("big_bird"),rko=o(" \u2014 "),TX=a("a"),tko=o("BigBirdModel"),ako=o(" (BigBird model)"),nko=l(),I_=a("li"),b1e=a("strong"),sko=o("bigbird_pegasus"),lko=o(" \u2014 "),MX=a("a"),iko=o("BigBirdPegasusModel"),dko=o(" (BigBird-Pegasus model)"),cko=l(),N_=a("li"),v1e=a("strong"),mko=o("blenderbot"),fko=o(" \u2014 "),EX=a("a"),gko=o("BlenderbotModel"),hko=o(" (Blenderbot model)"),uko=l(),q_=a("li"),F1e=a("strong"),pko=o("blenderbot-small"),_ko=o(" \u2014 "),CX=a("a"),bko=o("BlenderbotSmallModel"),vko=o(" (BlenderbotSmall model)"),Fko=l(),j_=a("li"),T1e=a("strong"),Tko=o("bloom"),Mko=o(" \u2014 "),wX=a("a"),Eko=o("BloomModel"),Cko=o(" (BLOOM model)"),wko=l(),D_=a("li"),M1e=a("strong"),Ako=o("camembert"),Lko=o(" \u2014 "),AX=a("a"),yko=o("CamembertModel"),xko=o(" (CamemBERT model)"),$ko=l(),G_=a("li"),E1e=a("strong"),kko=o("canine"),Sko=o(" \u2014 "),LX=a("a"),Rko=o("CanineModel"),Pko=o(" (CANINE model)"),Bko=l(),O_=a("li"),C1e=a("strong"),Iko=o("clip"),Nko=o(" \u2014 "),yX=a("a"),qko=o("CLIPModel"),jko=o(" (CLIP model)"),Dko=l(),V_=a("li"),w1e=a("strong"),Gko=o("codegen"),Oko=o(" \u2014 "),xX=a("a"),Vko=o("CodeGenModel"),Xko=o(" (CodeGen model)"),zko=l(),X_=a("li"),A1e=a("strong"),Qko=o("conditional_detr"),Wko=o(" \u2014 "),$X=a("a"),Uko=o("ConditionalDetrModel"),Hko=o(" (Conditional DETR model)"),Jko=l(),z_=a("li"),L1e=a("strong"),Yko=o("convbert"),Zko=o(" \u2014 "),kX=a("a"),Kko=o("ConvBertModel"),eSo=o(" (ConvBERT model)"),oSo=l(),Q_=a("li"),y1e=a("strong"),rSo=o("convnext"),tSo=o(" \u2014 "),SX=a("a"),aSo=o("ConvNextModel"),nSo=o(" (ConvNeXT model)"),sSo=l(),W_=a("li"),x1e=a("strong"),lSo=o("ctrl"),iSo=o(" \u2014 "),RX=a("a"),dSo=o("CTRLModel"),cSo=o(" (CTRL model)"),mSo=l(),U_=a("li"),$1e=a("strong"),fSo=o("cvt"),gSo=o(" \u2014 "),PX=a("a"),hSo=o("CvtModel"),uSo=o(" (CvT model)"),pSo=l(),H_=a("li"),k1e=a("strong"),_So=o("data2vec-audio"),bSo=o(" \u2014 "),BX=a("a"),vSo=o("Data2VecAudioModel"),FSo=o(" (Data2VecAudio model)"),TSo=l(),J_=a("li"),S1e=a("strong"),MSo=o("data2vec-text"),ESo=o(" \u2014 "),IX=a("a"),CSo=o("Data2VecTextModel"),wSo=o(" (Data2VecText model)"),ASo=l(),Y_=a("li"),R1e=a("strong"),LSo=o("data2vec-vision"),ySo=o(" \u2014 "),NX=a("a"),xSo=o("Data2VecVisionModel"),$So=o(" (Data2VecVision model)"),kSo=l(),Z_=a("li"),P1e=a("strong"),SSo=o("deberta"),RSo=o(" \u2014 "),qX=a("a"),PSo=o("DebertaModel"),BSo=o(" (DeBERTa model)"),ISo=l(),K_=a("li"),B1e=a("strong"),NSo=o("deberta-v2"),qSo=o(" \u2014 "),jX=a("a"),jSo=o("DebertaV2Model"),DSo=o(" (DeBERTa-v2 model)"),GSo=l(),e1=a("li"),I1e=a("strong"),OSo=o("decision_transformer"),VSo=o(" \u2014 "),DX=a("a"),XSo=o("DecisionTransformerModel"),zSo=o(" (Decision Transformer model)"),QSo=l(),o1=a("li"),N1e=a("strong"),WSo=o("deformable_detr"),USo=o(" \u2014 "),GX=a("a"),HSo=o("DeformableDetrModel"),JSo=o(" (Deformable DETR model)"),YSo=l(),r1=a("li"),q1e=a("strong"),ZSo=o("deit"),KSo=o(" \u2014 "),OX=a("a"),eRo=o("DeiTModel"),oRo=o(" (DeiT model)"),rRo=l(),t1=a("li"),j1e=a("strong"),tRo=o("detr"),aRo=o(" \u2014 "),VX=a("a"),nRo=o("DetrModel"),sRo=o(" (DETR model)"),lRo=l(),a1=a("li"),D1e=a("strong"),iRo=o("distilbert"),dRo=o(" \u2014 "),XX=a("a"),cRo=o("DistilBertModel"),mRo=o(" (DistilBERT model)"),fRo=l(),n1=a("li"),G1e=a("strong"),gRo=o("donut-swin"),hRo=o(" \u2014 "),zX=a("a"),uRo=o("DonutSwinModel"),pRo=o(" (DonutSwin model)"),_Ro=l(),s1=a("li"),O1e=a("strong"),bRo=o("dpr"),vRo=o(" \u2014 "),QX=a("a"),FRo=o("DPRQuestionEncoder"),TRo=o(" (DPR model)"),MRo=l(),l1=a("li"),V1e=a("strong"),ERo=o("dpt"),CRo=o(" \u2014 "),WX=a("a"),wRo=o("DPTModel"),ARo=o(" (DPT model)"),LRo=l(),i1=a("li"),X1e=a("strong"),yRo=o("electra"),xRo=o(" \u2014 "),UX=a("a"),$Ro=o("ElectraModel"),kRo=o(" (ELECTRA model)"),SRo=l(),d1=a("li"),z1e=a("strong"),RRo=o("ernie"),PRo=o(" \u2014 "),HX=a("a"),BRo=o("ErnieModel"),IRo=o(" (ERNIE model)"),NRo=l(),c1=a("li"),Q1e=a("strong"),qRo=o("esm"),jRo=o(" \u2014 "),JX=a("a"),DRo=o("EsmModel"),GRo=o(" (ESM model)"),ORo=l(),m1=a("li"),W1e=a("strong"),VRo=o("flaubert"),XRo=o(" \u2014 "),YX=a("a"),zRo=o("FlaubertModel"),QRo=o(" (FlauBERT model)"),WRo=l(),f1=a("li"),U1e=a("strong"),URo=o("flava"),HRo=o(" \u2014 "),ZX=a("a"),JRo=o("FlavaModel"),YRo=o(" (FLAVA model)"),ZRo=l(),g1=a("li"),H1e=a("strong"),KRo=o("fnet"),ePo=o(" \u2014 "),KX=a("a"),oPo=o("FNetModel"),rPo=o(" (FNet model)"),tPo=l(),h1=a("li"),J1e=a("strong"),aPo=o("fsmt"),nPo=o(" \u2014 "),ez=a("a"),sPo=o("FSMTModel"),lPo=o(" (FairSeq Machine-Translation model)"),iPo=l(),yl=a("li"),Y1e=a("strong"),dPo=o("funnel"),cPo=o(" \u2014 "),oz=a("a"),mPo=o("FunnelModel"),fPo=o(" or "),rz=a("a"),gPo=o("FunnelBaseModel"),hPo=o(" (Funnel Transformer model)"),uPo=l(),u1=a("li"),Z1e=a("strong"),pPo=o("glpn"),_Po=o(" \u2014 "),tz=a("a"),bPo=o("GLPNModel"),vPo=o(" (GLPN model)"),FPo=l(),p1=a("li"),K1e=a("strong"),TPo=o("gpt2"),MPo=o(" \u2014 "),az=a("a"),EPo=o("GPT2Model"),CPo=o(" (OpenAI GPT-2 model)"),wPo=l(),_1=a("li"),e2e=a("strong"),APo=o("gpt_neo"),LPo=o(" \u2014 "),nz=a("a"),yPo=o("GPTNeoModel"),xPo=o(" (GPT Neo model)"),$Po=l(),b1=a("li"),o2e=a("strong"),kPo=o("gpt_neox"),SPo=o(" \u2014 "),sz=a("a"),RPo=o("GPTNeoXModel"),PPo=o(" (GPT NeoX model)"),BPo=l(),v1=a("li"),r2e=a("strong"),IPo=o("gpt_neox_japanese"),NPo=o(" \u2014 "),lz=a("a"),qPo=o("GPTNeoXJapaneseModel"),jPo=o(" (GPT NeoX Japanese model)"),DPo=l(),F1=a("li"),t2e=a("strong"),GPo=o("gptj"),OPo=o(" \u2014 "),iz=a("a"),VPo=o("GPTJModel"),XPo=o(" (GPT-J model)"),zPo=l(),T1=a("li"),a2e=a("strong"),QPo=o("groupvit"),WPo=o(" \u2014 "),dz=a("a"),UPo=o("GroupViTModel"),HPo=o(" (GroupViT model)"),JPo=l(),M1=a("li"),n2e=a("strong"),YPo=o("hubert"),ZPo=o(" \u2014 "),cz=a("a"),KPo=o("HubertModel"),eBo=o(" (Hubert model)"),oBo=l(),E1=a("li"),s2e=a("strong"),rBo=o("ibert"),tBo=o(" \u2014 "),mz=a("a"),aBo=o("IBertModel"),nBo=o(" (I-BERT model)"),sBo=l(),C1=a("li"),l2e=a("strong"),lBo=o("imagegpt"),iBo=o(" \u2014 "),fz=a("a"),dBo=o("ImageGPTModel"),cBo=o(" (ImageGPT model)"),mBo=l(),w1=a("li"),i2e=a("strong"),fBo=o("layoutlm"),gBo=o(" \u2014 "),gz=a("a"),hBo=o("LayoutLMModel"),uBo=o(" (LayoutLM model)"),pBo=l(),A1=a("li"),d2e=a("strong"),_Bo=o("layoutlmv2"),bBo=o(" \u2014 "),hz=a("a"),vBo=o("LayoutLMv2Model"),FBo=o(" (LayoutLMv2 model)"),TBo=l(),L1=a("li"),c2e=a("strong"),MBo=o("layoutlmv3"),EBo=o(" \u2014 "),uz=a("a"),CBo=o("LayoutLMv3Model"),wBo=o(" (LayoutLMv3 model)"),ABo=l(),y1=a("li"),m2e=a("strong"),LBo=o("led"),yBo=o(" \u2014 "),pz=a("a"),xBo=o("LEDModel"),$Bo=o(" (LED model)"),kBo=l(),x1=a("li"),f2e=a("strong"),SBo=o("levit"),RBo=o(" \u2014 "),_z=a("a"),PBo=o("LevitModel"),BBo=o(" (LeViT model)"),IBo=l(),$1=a("li"),g2e=a("strong"),NBo=o("lilt"),qBo=o(" \u2014 "),bz=a("a"),jBo=o("LiltModel"),DBo=o(" (LiLT model)"),GBo=l(),k1=a("li"),h2e=a("strong"),OBo=o("longformer"),VBo=o(" \u2014 "),vz=a("a"),XBo=o("LongformerModel"),zBo=o(" (Longformer model)"),QBo=l(),S1=a("li"),u2e=a("strong"),WBo=o("longt5"),UBo=o(" \u2014 "),Fz=a("a"),HBo=o("LongT5Model"),JBo=o(" (LongT5 model)"),YBo=l(),R1=a("li"),p2e=a("strong"),ZBo=o("luke"),KBo=o(" \u2014 "),Tz=a("a"),eIo=o("LukeModel"),oIo=o(" (LUKE model)"),rIo=l(),P1=a("li"),_2e=a("strong"),tIo=o("lxmert"),aIo=o(" \u2014 "),Mz=a("a"),nIo=o("LxmertModel"),sIo=o(" (LXMERT model)"),lIo=l(),B1=a("li"),b2e=a("strong"),iIo=o("m2m_100"),dIo=o(" \u2014 "),Ez=a("a"),cIo=o("M2M100Model"),mIo=o(" (M2M100 model)"),fIo=l(),I1=a("li"),v2e=a("strong"),gIo=o("marian"),hIo=o(" \u2014 "),Cz=a("a"),uIo=o("MarianModel"),pIo=o(" (Marian model)"),_Io=l(),N1=a("li"),F2e=a("strong"),bIo=o("markuplm"),vIo=o(" \u2014 "),wz=a("a"),FIo=o("MarkupLMModel"),TIo=o(" (MarkupLM model)"),MIo=l(),q1=a("li"),T2e=a("strong"),EIo=o("maskformer"),CIo=o(" \u2014 "),Az=a("a"),wIo=o("MaskFormerModel"),AIo=o(" (MaskFormer model)"),LIo=l(),j1=a("li"),M2e=a("strong"),yIo=o("mbart"),xIo=o(" \u2014 "),Lz=a("a"),$Io=o("MBartModel"),kIo=o(" (mBART model)"),SIo=l(),D1=a("li"),E2e=a("strong"),RIo=o("mctct"),PIo=o(" \u2014 "),yz=a("a"),BIo=o("MCTCTModel"),IIo=o(" (M-CTC-T model)"),NIo=l(),G1=a("li"),C2e=a("strong"),qIo=o("megatron-bert"),jIo=o(" \u2014 "),xz=a("a"),DIo=o("MegatronBertModel"),GIo=o(" (Megatron-BERT model)"),OIo=l(),O1=a("li"),w2e=a("strong"),VIo=o("mobilebert"),XIo=o(" \u2014 "),$z=a("a"),zIo=o("MobileBertModel"),QIo=o(" (MobileBERT model)"),WIo=l(),V1=a("li"),A2e=a("strong"),UIo=o("mobilevit"),HIo=o(" \u2014 "),kz=a("a"),JIo=o("MobileViTModel"),YIo=o(" (MobileViT model)"),ZIo=l(),X1=a("li"),L2e=a("strong"),KIo=o("mpnet"),eNo=o(" \u2014 "),Sz=a("a"),oNo=o("MPNetModel"),rNo=o(" (MPNet model)"),tNo=l(),z1=a("li"),y2e=a("strong"),aNo=o("mt5"),nNo=o(" \u2014 "),Rz=a("a"),sNo=o("MT5Model"),lNo=o(" (MT5 model)"),iNo=l(),Q1=a("li"),x2e=a("strong"),dNo=o("mvp"),cNo=o(" \u2014 "),Pz=a("a"),mNo=o("MvpModel"),fNo=o(" (MVP model)"),gNo=l(),W1=a("li"),$2e=a("strong"),hNo=o("nezha"),uNo=o(" \u2014 "),Bz=a("a"),pNo=o("NezhaModel"),_No=o(" (Nezha model)"),bNo=l(),U1=a("li"),k2e=a("strong"),vNo=o("nllb"),FNo=o(" \u2014 "),Iz=a("a"),TNo=o("M2M100Model"),MNo=o(" (NLLB model)"),ENo=l(),H1=a("li"),S2e=a("strong"),CNo=o("nystromformer"),wNo=o(" \u2014 "),Nz=a("a"),ANo=o("NystromformerModel"),LNo=o(" (Nystr\xF6mformer model)"),yNo=l(),J1=a("li"),R2e=a("strong"),xNo=o("openai-gpt"),$No=o(" \u2014 "),qz=a("a"),kNo=o("OpenAIGPTModel"),SNo=o(" (OpenAI GPT model)"),RNo=l(),Y1=a("li"),P2e=a("strong"),PNo=o("opt"),BNo=o(" \u2014 "),jz=a("a"),INo=o("OPTModel"),NNo=o(" (OPT model)"),qNo=l(),Z1=a("li"),B2e=a("strong"),jNo=o("owlvit"),DNo=o(" \u2014 "),Dz=a("a"),GNo=o("OwlViTModel"),ONo=o(" (OWL-ViT model)"),VNo=l(),K1=a("li"),I2e=a("strong"),XNo=o("pegasus"),zNo=o(" \u2014 "),Gz=a("a"),QNo=o("PegasusModel"),WNo=o(" (Pegasus model)"),UNo=l(),e2=a("li"),N2e=a("strong"),HNo=o("pegasus_x"),JNo=o(" \u2014 "),Oz=a("a"),YNo=o("PegasusXModel"),ZNo=o(" (PEGASUS-X model)"),KNo=l(),o2=a("li"),q2e=a("strong"),eqo=o("perceiver"),oqo=o(" \u2014 "),Vz=a("a"),rqo=o("PerceiverModel"),tqo=o(" (Perceiver model)"),aqo=l(),r2=a("li"),j2e=a("strong"),nqo=o("plbart"),sqo=o(" \u2014 "),Xz=a("a"),lqo=o("PLBartModel"),iqo=o(" (PLBart model)"),dqo=l(),t2=a("li"),D2e=a("strong"),cqo=o("poolformer"),mqo=o(" \u2014 "),zz=a("a"),fqo=o("PoolFormerModel"),gqo=o(" (PoolFormer model)"),hqo=l(),a2=a("li"),G2e=a("strong"),uqo=o("prophetnet"),pqo=o(" \u2014 "),Qz=a("a"),_qo=o("ProphetNetModel"),bqo=o(" (ProphetNet model)"),vqo=l(),n2=a("li"),O2e=a("strong"),Fqo=o("qdqbert"),Tqo=o(" \u2014 "),Wz=a("a"),Mqo=o("QDQBertModel"),Eqo=o(" (QDQBert model)"),Cqo=l(),s2=a("li"),V2e=a("strong"),wqo=o("reformer"),Aqo=o(" \u2014 "),Uz=a("a"),Lqo=o("ReformerModel"),yqo=o(" (Reformer model)"),xqo=l(),l2=a("li"),X2e=a("strong"),$qo=o("regnet"),kqo=o(" \u2014 "),Hz=a("a"),Sqo=o("RegNetModel"),Rqo=o(" (RegNet model)"),Pqo=l(),i2=a("li"),z2e=a("strong"),Bqo=o("rembert"),Iqo=o(" \u2014 "),Jz=a("a"),Nqo=o("RemBertModel"),qqo=o(" (RemBERT model)"),jqo=l(),d2=a("li"),Q2e=a("strong"),Dqo=o("resnet"),Gqo=o(" \u2014 "),Yz=a("a"),Oqo=o("ResNetModel"),Vqo=o(" (ResNet model)"),Xqo=l(),c2=a("li"),W2e=a("strong"),zqo=o("retribert"),Qqo=o(" \u2014 "),Zz=a("a"),Wqo=o("RetriBertModel"),Uqo=o(" (RetriBERT model)"),Hqo=l(),m2=a("li"),U2e=a("strong"),Jqo=o("roberta"),Yqo=o(" \u2014 "),Kz=a("a"),Zqo=o("RobertaModel"),Kqo=o(" (RoBERTa model)"),ejo=l(),f2=a("li"),H2e=a("strong"),ojo=o("roformer"),rjo=o(" \u2014 "),eQ=a("a"),tjo=o("RoFormerModel"),ajo=o(" (RoFormer model)"),njo=l(),g2=a("li"),J2e=a("strong"),sjo=o("segformer"),ljo=o(" \u2014 "),oQ=a("a"),ijo=o("SegformerModel"),djo=o(" (SegFormer model)"),cjo=l(),h2=a("li"),Y2e=a("strong"),mjo=o("sew"),fjo=o(" \u2014 "),rQ=a("a"),gjo=o("SEWModel"),hjo=o(" (SEW model)"),ujo=l(),u2=a("li"),Z2e=a("strong"),pjo=o("sew-d"),_jo=o(" \u2014 "),tQ=a("a"),bjo=o("SEWDModel"),vjo=o(" (SEW-D model)"),Fjo=l(),p2=a("li"),K2e=a("strong"),Tjo=o("speech_to_text"),Mjo=o(" \u2014 "),aQ=a("a"),Ejo=o("Speech2TextModel"),Cjo=o(" (Speech2Text model)"),wjo=l(),_2=a("li"),ebe=a("strong"),Ajo=o("splinter"),Ljo=o(" \u2014 "),nQ=a("a"),yjo=o("SplinterModel"),xjo=o(" (Splinter model)"),$jo=l(),b2=a("li"),obe=a("strong"),kjo=o("squeezebert"),Sjo=o(" \u2014 "),sQ=a("a"),Rjo=o("SqueezeBertModel"),Pjo=o(" (SqueezeBERT model)"),Bjo=l(),v2=a("li"),rbe=a("strong"),Ijo=o("swin"),Njo=o(" \u2014 "),lQ=a("a"),qjo=o("SwinModel"),jjo=o(" (Swin Transformer model)"),Djo=l(),F2=a("li"),tbe=a("strong"),Gjo=o("swinv2"),Ojo=o(" \u2014 "),iQ=a("a"),Vjo=o("Swinv2Model"),Xjo=o(" (Swin Transformer V2 model)"),zjo=l(),T2=a("li"),abe=a("strong"),Qjo=o("t5"),Wjo=o(" \u2014 "),dQ=a("a"),Ujo=o("T5Model"),Hjo=o(" (T5 model)"),Jjo=l(),M2=a("li"),nbe=a("strong"),Yjo=o("tapas"),Zjo=o(" \u2014 "),cQ=a("a"),Kjo=o("TapasModel"),eDo=o(" (TAPAS model)"),oDo=l(),E2=a("li"),sbe=a("strong"),rDo=o("time_series_transformer"),tDo=o(" \u2014 "),mQ=a("a"),aDo=o("TimeSeriesTransformerModel"),nDo=o(" (Time Series Transformer model)"),sDo=l(),C2=a("li"),lbe=a("strong"),lDo=o("trajectory_transformer"),iDo=o(" \u2014 "),fQ=a("a"),dDo=o("TrajectoryTransformerModel"),cDo=o(" (Trajectory Transformer model)"),mDo=l(),w2=a("li"),ibe=a("strong"),fDo=o("transfo-xl"),gDo=o(" \u2014 "),gQ=a("a"),hDo=o("TransfoXLModel"),uDo=o(" (Transformer-XL model)"),pDo=l(),A2=a("li"),dbe=a("strong"),_Do=o("unispeech"),bDo=o(" \u2014 "),hQ=a("a"),vDo=o("UniSpeechModel"),FDo=o(" (UniSpeech model)"),TDo=l(),L2=a("li"),cbe=a("strong"),MDo=o("unispeech-sat"),EDo=o(" \u2014 "),uQ=a("a"),CDo=o("UniSpeechSatModel"),wDo=o(" (UniSpeechSat model)"),ADo=l(),y2=a("li"),mbe=a("strong"),LDo=o("van"),yDo=o(" \u2014 "),pQ=a("a"),xDo=o("VanModel"),$Do=o(" (VAN model)"),kDo=l(),x2=a("li"),fbe=a("strong"),SDo=o("videomae"),RDo=o(" \u2014 "),_Q=a("a"),PDo=o("VideoMAEModel"),BDo=o(" (VideoMAE model)"),IDo=l(),$2=a("li"),gbe=a("strong"),NDo=o("vilt"),qDo=o(" \u2014 "),bQ=a("a"),jDo=o("ViltModel"),DDo=o(" (ViLT model)"),GDo=l(),k2=a("li"),hbe=a("strong"),ODo=o("vision-text-dual-encoder"),VDo=o(" \u2014 "),vQ=a("a"),XDo=o("VisionTextDualEncoderModel"),zDo=o(" (VisionTextDualEncoder model)"),QDo=l(),S2=a("li"),ube=a("strong"),WDo=o("visual_bert"),UDo=o(" \u2014 "),FQ=a("a"),HDo=o("VisualBertModel"),JDo=o(" (VisualBERT model)"),YDo=l(),R2=a("li"),pbe=a("strong"),ZDo=o("vit"),KDo=o(" \u2014 "),TQ=a("a"),eGo=o("ViTModel"),oGo=o(" (ViT model)"),rGo=l(),P2=a("li"),_be=a("strong"),tGo=o("vit_mae"),aGo=o(" \u2014 "),MQ=a("a"),nGo=o("ViTMAEModel"),sGo=o(" (ViTMAE model)"),lGo=l(),B2=a("li"),bbe=a("strong"),iGo=o("vit_msn"),dGo=o(" \u2014 "),EQ=a("a"),cGo=o("ViTMSNModel"),mGo=o(" (ViTMSN model)"),fGo=l(),I2=a("li"),vbe=a("strong"),gGo=o("wav2vec2"),hGo=o(" \u2014 "),CQ=a("a"),uGo=o("Wav2Vec2Model"),pGo=o(" (Wav2Vec2 model)"),_Go=l(),N2=a("li"),Fbe=a("strong"),bGo=o("wav2vec2-conformer"),vGo=o(" \u2014 "),wQ=a("a"),FGo=o("Wav2Vec2ConformerModel"),TGo=o(" (Wav2Vec2-Conformer model)"),MGo=l(),q2=a("li"),Tbe=a("strong"),EGo=o("wavlm"),CGo=o(" \u2014 "),AQ=a("a"),wGo=o("WavLMModel"),AGo=o(" (WavLM model)"),LGo=l(),j2=a("li"),Mbe=a("strong"),yGo=o("whisper"),xGo=o(" \u2014 "),LQ=a("a"),$Go=o("WhisperModel"),kGo=o(" (Whisper model)"),SGo=l(),D2=a("li"),Ebe=a("strong"),RGo=o("xclip"),PGo=o(" \u2014 "),yQ=a("a"),BGo=o("XCLIPModel"),IGo=o(" (X-CLIP model)"),NGo=l(),G2=a("li"),Cbe=a("strong"),qGo=o("xglm"),jGo=o(" \u2014 "),xQ=a("a"),DGo=o("XGLMModel"),GGo=o(" (XGLM model)"),OGo=l(),O2=a("li"),wbe=a("strong"),VGo=o("xlm"),XGo=o(" \u2014 "),$Q=a("a"),zGo=o("XLMModel"),QGo=o(" (XLM model)"),WGo=l(),V2=a("li"),Abe=a("strong"),UGo=o("xlm-prophetnet"),HGo=o(" \u2014 "),kQ=a("a"),JGo=o("XLMProphetNetModel"),YGo=o(" (XLM-ProphetNet model)"),ZGo=l(),X2=a("li"),Lbe=a("strong"),KGo=o("xlm-roberta"),eOo=o(" \u2014 "),SQ=a("a"),oOo=o("XLMRobertaModel"),rOo=o(" (XLM-RoBERTa model)"),tOo=l(),z2=a("li"),ybe=a("strong"),aOo=o("xlm-roberta-xl"),nOo=o(" \u2014 "),RQ=a("a"),sOo=o("XLMRobertaXLModel"),lOo=o(" (XLM-RoBERTa-XL model)"),iOo=l(),Q2=a("li"),xbe=a("strong"),dOo=o("xlnet"),cOo=o(" \u2014 "),PQ=a("a"),mOo=o("XLNetModel"),fOo=o(" (XLNet model)"),gOo=l(),W2=a("li"),$be=a("strong"),hOo=o("yolos"),uOo=o(" \u2014 "),BQ=a("a"),pOo=o("YolosModel"),_Oo=o(" (YOLOS model)"),bOo=l(),U2=a("li"),kbe=a("strong"),vOo=o("yoso"),FOo=o(" \u2014 "),IQ=a("a"),TOo=o("YosoModel"),MOo=o(" (YOSO model)"),EOo=l(),H2=a("p"),COo=o("The model is set in evaluation mode by default using "),Sbe=a("code"),wOo=o("model.eval()"),AOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rbe=a("code"),LOo=o("model.train()"),yOo=l(),F(J2.$$.fragment),tto=l(),Rd=a("h2"),Y2=a("a"),Pbe=a("span"),F(k$.$$.fragment),xOo=l(),Bbe=a("span"),$Oo=o("AutoModelForPreTraining"),ato=l(),No=a("div"),F(S$.$$.fragment),kOo=l(),Pd=a("p"),SOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),NQ=a("a"),ROo=o("from_pretrained()"),POo=o(" class method or the "),qQ=a("a"),BOo=o("from_config()"),IOo=o(` class
method.`),NOo=l(),R$=a("p"),qOo=o("This class cannot be instantiated directly using "),Ibe=a("code"),jOo=o("__init__()"),DOo=o(" (throws an error)."),GOo=l(),Mt=a("div"),F(P$.$$.fragment),OOo=l(),Nbe=a("p"),VOo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),XOo=l(),Bd=a("p"),zOo=o(`Note:
Loading a model from its configuration file does `),qbe=a("strong"),QOo=o("not"),WOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jQ=a("a"),UOo=o("from_pretrained()"),HOo=o(" to load the model weights."),JOo=l(),F(Z2.$$.fragment),YOo=l(),eo=a("div"),F(B$.$$.fragment),ZOo=l(),jbe=a("p"),KOo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),eVo=l(),nn=a("p"),oVo=o("The model class to instantiate is selected based on the "),Dbe=a("code"),rVo=o("model_type"),tVo=o(` property of the config object (either
passed as an argument or loaded from `),Gbe=a("code"),aVo=o("pretrained_model_name_or_path"),nVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Obe=a("code"),sVo=o("pretrained_model_name_or_path"),lVo=o(":"),iVo=l(),G=a("ul"),K2=a("li"),Vbe=a("strong"),dVo=o("albert"),cVo=o(" \u2014 "),DQ=a("a"),mVo=o("AlbertForPreTraining"),fVo=o(" (ALBERT model)"),gVo=l(),eb=a("li"),Xbe=a("strong"),hVo=o("bart"),uVo=o(" \u2014 "),GQ=a("a"),pVo=o("BartForConditionalGeneration"),_Vo=o(" (BART model)"),bVo=l(),ob=a("li"),zbe=a("strong"),vVo=o("bert"),FVo=o(" \u2014 "),OQ=a("a"),TVo=o("BertForPreTraining"),MVo=o(" (BERT model)"),EVo=l(),rb=a("li"),Qbe=a("strong"),CVo=o("big_bird"),wVo=o(" \u2014 "),VQ=a("a"),AVo=o("BigBirdForPreTraining"),LVo=o(" (BigBird model)"),yVo=l(),tb=a("li"),Wbe=a("strong"),xVo=o("bloom"),$Vo=o(" \u2014 "),XQ=a("a"),kVo=o("BloomForCausalLM"),SVo=o(" (BLOOM model)"),RVo=l(),ab=a("li"),Ube=a("strong"),PVo=o("camembert"),BVo=o(" \u2014 "),zQ=a("a"),IVo=o("CamembertForMaskedLM"),NVo=o(" (CamemBERT model)"),qVo=l(),nb=a("li"),Hbe=a("strong"),jVo=o("ctrl"),DVo=o(" \u2014 "),QQ=a("a"),GVo=o("CTRLLMHeadModel"),OVo=o(" (CTRL model)"),VVo=l(),sb=a("li"),Jbe=a("strong"),XVo=o("data2vec-text"),zVo=o(" \u2014 "),WQ=a("a"),QVo=o("Data2VecTextForMaskedLM"),WVo=o(" (Data2VecText model)"),UVo=l(),lb=a("li"),Ybe=a("strong"),HVo=o("deberta"),JVo=o(" \u2014 "),UQ=a("a"),YVo=o("DebertaForMaskedLM"),ZVo=o(" (DeBERTa model)"),KVo=l(),ib=a("li"),Zbe=a("strong"),eXo=o("deberta-v2"),oXo=o(" \u2014 "),HQ=a("a"),rXo=o("DebertaV2ForMaskedLM"),tXo=o(" (DeBERTa-v2 model)"),aXo=l(),db=a("li"),Kbe=a("strong"),nXo=o("distilbert"),sXo=o(" \u2014 "),JQ=a("a"),lXo=o("DistilBertForMaskedLM"),iXo=o(" (DistilBERT model)"),dXo=l(),cb=a("li"),eve=a("strong"),cXo=o("electra"),mXo=o(" \u2014 "),YQ=a("a"),fXo=o("ElectraForPreTraining"),gXo=o(" (ELECTRA model)"),hXo=l(),mb=a("li"),ove=a("strong"),uXo=o("ernie"),pXo=o(" \u2014 "),ZQ=a("a"),_Xo=o("ErnieForPreTraining"),bXo=o(" (ERNIE model)"),vXo=l(),fb=a("li"),rve=a("strong"),FXo=o("flaubert"),TXo=o(" \u2014 "),KQ=a("a"),MXo=o("FlaubertWithLMHeadModel"),EXo=o(" (FlauBERT model)"),CXo=l(),gb=a("li"),tve=a("strong"),wXo=o("flava"),AXo=o(" \u2014 "),eW=a("a"),LXo=o("FlavaForPreTraining"),yXo=o(" (FLAVA model)"),xXo=l(),hb=a("li"),ave=a("strong"),$Xo=o("fnet"),kXo=o(" \u2014 "),oW=a("a"),SXo=o("FNetForPreTraining"),RXo=o(" (FNet model)"),PXo=l(),ub=a("li"),nve=a("strong"),BXo=o("fsmt"),IXo=o(" \u2014 "),rW=a("a"),NXo=o("FSMTForConditionalGeneration"),qXo=o(" (FairSeq Machine-Translation model)"),jXo=l(),pb=a("li"),sve=a("strong"),DXo=o("funnel"),GXo=o(" \u2014 "),tW=a("a"),OXo=o("FunnelForPreTraining"),VXo=o(" (Funnel Transformer model)"),XXo=l(),_b=a("li"),lve=a("strong"),zXo=o("gpt2"),QXo=o(" \u2014 "),aW=a("a"),WXo=o("GPT2LMHeadModel"),UXo=o(" (OpenAI GPT-2 model)"),HXo=l(),bb=a("li"),ive=a("strong"),JXo=o("ibert"),YXo=o(" \u2014 "),nW=a("a"),ZXo=o("IBertForMaskedLM"),KXo=o(" (I-BERT model)"),ezo=l(),vb=a("li"),dve=a("strong"),ozo=o("layoutlm"),rzo=o(" \u2014 "),sW=a("a"),tzo=o("LayoutLMForMaskedLM"),azo=o(" (LayoutLM model)"),nzo=l(),Fb=a("li"),cve=a("strong"),szo=o("longformer"),lzo=o(" \u2014 "),lW=a("a"),izo=o("LongformerForMaskedLM"),dzo=o(" (Longformer model)"),czo=l(),Tb=a("li"),mve=a("strong"),mzo=o("luke"),fzo=o(" \u2014 "),iW=a("a"),gzo=o("LukeForMaskedLM"),hzo=o(" (LUKE model)"),uzo=l(),Mb=a("li"),fve=a("strong"),pzo=o("lxmert"),_zo=o(" \u2014 "),dW=a("a"),bzo=o("LxmertForPreTraining"),vzo=o(" (LXMERT model)"),Fzo=l(),Eb=a("li"),gve=a("strong"),Tzo=o("megatron-bert"),Mzo=o(" \u2014 "),cW=a("a"),Ezo=o("MegatronBertForPreTraining"),Czo=o(" (Megatron-BERT model)"),wzo=l(),Cb=a("li"),hve=a("strong"),Azo=o("mobilebert"),Lzo=o(" \u2014 "),mW=a("a"),yzo=o("MobileBertForPreTraining"),xzo=o(" (MobileBERT model)"),$zo=l(),wb=a("li"),uve=a("strong"),kzo=o("mpnet"),Szo=o(" \u2014 "),fW=a("a"),Rzo=o("MPNetForMaskedLM"),Pzo=o(" (MPNet model)"),Bzo=l(),Ab=a("li"),pve=a("strong"),Izo=o("mvp"),Nzo=o(" \u2014 "),gW=a("a"),qzo=o("MvpForConditionalGeneration"),jzo=o(" (MVP model)"),Dzo=l(),Lb=a("li"),_ve=a("strong"),Gzo=o("nezha"),Ozo=o(" \u2014 "),hW=a("a"),Vzo=o("NezhaForPreTraining"),Xzo=o(" (Nezha model)"),zzo=l(),yb=a("li"),bve=a("strong"),Qzo=o("openai-gpt"),Wzo=o(" \u2014 "),uW=a("a"),Uzo=o("OpenAIGPTLMHeadModel"),Hzo=o(" (OpenAI GPT model)"),Jzo=l(),xb=a("li"),vve=a("strong"),Yzo=o("retribert"),Zzo=o(" \u2014 "),pW=a("a"),Kzo=o("RetriBertModel"),eQo=o(" (RetriBERT model)"),oQo=l(),$b=a("li"),Fve=a("strong"),rQo=o("roberta"),tQo=o(" \u2014 "),_W=a("a"),aQo=o("RobertaForMaskedLM"),nQo=o(" (RoBERTa model)"),sQo=l(),kb=a("li"),Tve=a("strong"),lQo=o("splinter"),iQo=o(" \u2014 "),bW=a("a"),dQo=o("SplinterForPreTraining"),cQo=o(" (Splinter model)"),mQo=l(),Sb=a("li"),Mve=a("strong"),fQo=o("squeezebert"),gQo=o(" \u2014 "),vW=a("a"),hQo=o("SqueezeBertForMaskedLM"),uQo=o(" (SqueezeBERT model)"),pQo=l(),Rb=a("li"),Eve=a("strong"),_Qo=o("t5"),bQo=o(" \u2014 "),FW=a("a"),vQo=o("T5ForConditionalGeneration"),FQo=o(" (T5 model)"),TQo=l(),Pb=a("li"),Cve=a("strong"),MQo=o("tapas"),EQo=o(" \u2014 "),TW=a("a"),CQo=o("TapasForMaskedLM"),wQo=o(" (TAPAS model)"),AQo=l(),Bb=a("li"),wve=a("strong"),LQo=o("transfo-xl"),yQo=o(" \u2014 "),MW=a("a"),xQo=o("TransfoXLLMHeadModel"),$Qo=o(" (Transformer-XL model)"),kQo=l(),Ib=a("li"),Ave=a("strong"),SQo=o("unispeech"),RQo=o(" \u2014 "),EW=a("a"),PQo=o("UniSpeechForPreTraining"),BQo=o(" (UniSpeech model)"),IQo=l(),Nb=a("li"),Lve=a("strong"),NQo=o("unispeech-sat"),qQo=o(" \u2014 "),CW=a("a"),jQo=o("UniSpeechSatForPreTraining"),DQo=o(" (UniSpeechSat model)"),GQo=l(),qb=a("li"),yve=a("strong"),OQo=o("videomae"),VQo=o(" \u2014 "),wW=a("a"),XQo=o("VideoMAEForPreTraining"),zQo=o(" (VideoMAE model)"),QQo=l(),jb=a("li"),xve=a("strong"),WQo=o("visual_bert"),UQo=o(" \u2014 "),AW=a("a"),HQo=o("VisualBertForPreTraining"),JQo=o(" (VisualBERT model)"),YQo=l(),Db=a("li"),$ve=a("strong"),ZQo=o("vit_mae"),KQo=o(" \u2014 "),LW=a("a"),eWo=o("ViTMAEForPreTraining"),oWo=o(" (ViTMAE model)"),rWo=l(),Gb=a("li"),kve=a("strong"),tWo=o("wav2vec2"),aWo=o(" \u2014 "),yW=a("a"),nWo=o("Wav2Vec2ForPreTraining"),sWo=o(" (Wav2Vec2 model)"),lWo=l(),Ob=a("li"),Sve=a("strong"),iWo=o("wav2vec2-conformer"),dWo=o(" \u2014 "),xW=a("a"),cWo=o("Wav2Vec2ConformerForPreTraining"),mWo=o(" (Wav2Vec2-Conformer model)"),fWo=l(),Vb=a("li"),Rve=a("strong"),gWo=o("xlm"),hWo=o(" \u2014 "),$W=a("a"),uWo=o("XLMWithLMHeadModel"),pWo=o(" (XLM model)"),_Wo=l(),Xb=a("li"),Pve=a("strong"),bWo=o("xlm-roberta"),vWo=o(" \u2014 "),kW=a("a"),FWo=o("XLMRobertaForMaskedLM"),TWo=o(" (XLM-RoBERTa model)"),MWo=l(),zb=a("li"),Bve=a("strong"),EWo=o("xlm-roberta-xl"),CWo=o(" \u2014 "),SW=a("a"),wWo=o("XLMRobertaXLForMaskedLM"),AWo=o(" (XLM-RoBERTa-XL model)"),LWo=l(),Qb=a("li"),Ive=a("strong"),yWo=o("xlnet"),xWo=o(" \u2014 "),RW=a("a"),$Wo=o("XLNetLMHeadModel"),kWo=o(" (XLNet model)"),SWo=l(),Wb=a("p"),RWo=o("The model is set in evaluation mode by default using "),Nve=a("code"),PWo=o("model.eval()"),BWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qve=a("code"),IWo=o("model.train()"),NWo=l(),F(Ub.$$.fragment),nto=l(),Id=a("h2"),Hb=a("a"),jve=a("span"),F(I$.$$.fragment),qWo=l(),Dve=a("span"),jWo=o("AutoModelForCausalLM"),sto=l(),qo=a("div"),F(N$.$$.fragment),DWo=l(),Nd=a("p"),GWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),PW=a("a"),OWo=o("from_pretrained()"),VWo=o(" class method or the "),BW=a("a"),XWo=o("from_config()"),zWo=o(` class
method.`),QWo=l(),q$=a("p"),WWo=o("This class cannot be instantiated directly using "),Gve=a("code"),UWo=o("__init__()"),HWo=o(" (throws an error)."),JWo=l(),Et=a("div"),F(j$.$$.fragment),YWo=l(),Ove=a("p"),ZWo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),KWo=l(),qd=a("p"),eUo=o(`Note:
Loading a model from its configuration file does `),Vve=a("strong"),oUo=o("not"),rUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IW=a("a"),tUo=o("from_pretrained()"),aUo=o(" to load the model weights."),nUo=l(),F(Jb.$$.fragment),sUo=l(),oo=a("div"),F(D$.$$.fragment),lUo=l(),Xve=a("p"),iUo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),dUo=l(),sn=a("p"),cUo=o("The model class to instantiate is selected based on the "),zve=a("code"),mUo=o("model_type"),fUo=o(` property of the config object (either
passed as an argument or loaded from `),Qve=a("code"),gUo=o("pretrained_model_name_or_path"),hUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=a("code"),uUo=o("pretrained_model_name_or_path"),pUo=o(":"),_Uo=l(),Q=a("ul"),Yb=a("li"),Uve=a("strong"),bUo=o("bart"),vUo=o(" \u2014 "),NW=a("a"),FUo=o("BartForCausalLM"),TUo=o(" (BART model)"),MUo=l(),Zb=a("li"),Hve=a("strong"),EUo=o("bert"),CUo=o(" \u2014 "),qW=a("a"),wUo=o("BertLMHeadModel"),AUo=o(" (BERT model)"),LUo=l(),Kb=a("li"),Jve=a("strong"),yUo=o("bert-generation"),xUo=o(" \u2014 "),jW=a("a"),$Uo=o("BertGenerationDecoder"),kUo=o(" (Bert Generation model)"),SUo=l(),ev=a("li"),Yve=a("strong"),RUo=o("big_bird"),PUo=o(" \u2014 "),DW=a("a"),BUo=o("BigBirdForCausalLM"),IUo=o(" (BigBird model)"),NUo=l(),ov=a("li"),Zve=a("strong"),qUo=o("bigbird_pegasus"),jUo=o(" \u2014 "),GW=a("a"),DUo=o("BigBirdPegasusForCausalLM"),GUo=o(" (BigBird-Pegasus model)"),OUo=l(),rv=a("li"),Kve=a("strong"),VUo=o("blenderbot"),XUo=o(" \u2014 "),OW=a("a"),zUo=o("BlenderbotForCausalLM"),QUo=o(" (Blenderbot model)"),WUo=l(),tv=a("li"),eFe=a("strong"),UUo=o("blenderbot-small"),HUo=o(" \u2014 "),VW=a("a"),JUo=o("BlenderbotSmallForCausalLM"),YUo=o(" (BlenderbotSmall model)"),ZUo=l(),av=a("li"),oFe=a("strong"),KUo=o("bloom"),eHo=o(" \u2014 "),XW=a("a"),oHo=o("BloomForCausalLM"),rHo=o(" (BLOOM model)"),tHo=l(),nv=a("li"),rFe=a("strong"),aHo=o("camembert"),nHo=o(" \u2014 "),zW=a("a"),sHo=o("CamembertForCausalLM"),lHo=o(" (CamemBERT model)"),iHo=l(),sv=a("li"),tFe=a("strong"),dHo=o("codegen"),cHo=o(" \u2014 "),QW=a("a"),mHo=o("CodeGenForCausalLM"),fHo=o(" (CodeGen model)"),gHo=l(),lv=a("li"),aFe=a("strong"),hHo=o("ctrl"),uHo=o(" \u2014 "),WW=a("a"),pHo=o("CTRLLMHeadModel"),_Ho=o(" (CTRL model)"),bHo=l(),iv=a("li"),nFe=a("strong"),vHo=o("data2vec-text"),FHo=o(" \u2014 "),UW=a("a"),THo=o("Data2VecTextForCausalLM"),MHo=o(" (Data2VecText model)"),EHo=l(),dv=a("li"),sFe=a("strong"),CHo=o("electra"),wHo=o(" \u2014 "),HW=a("a"),AHo=o("ElectraForCausalLM"),LHo=o(" (ELECTRA model)"),yHo=l(),cv=a("li"),lFe=a("strong"),xHo=o("ernie"),$Ho=o(" \u2014 "),JW=a("a"),kHo=o("ErnieForCausalLM"),SHo=o(" (ERNIE model)"),RHo=l(),mv=a("li"),iFe=a("strong"),PHo=o("gpt2"),BHo=o(" \u2014 "),YW=a("a"),IHo=o("GPT2LMHeadModel"),NHo=o(" (OpenAI GPT-2 model)"),qHo=l(),fv=a("li"),dFe=a("strong"),jHo=o("gpt_neo"),DHo=o(" \u2014 "),ZW=a("a"),GHo=o("GPTNeoForCausalLM"),OHo=o(" (GPT Neo model)"),VHo=l(),gv=a("li"),cFe=a("strong"),XHo=o("gpt_neox"),zHo=o(" \u2014 "),KW=a("a"),QHo=o("GPTNeoXForCausalLM"),WHo=o(" (GPT NeoX model)"),UHo=l(),hv=a("li"),mFe=a("strong"),HHo=o("gpt_neox_japanese"),JHo=o(" \u2014 "),eU=a("a"),YHo=o("GPTNeoXJapaneseForCausalLM"),ZHo=o(" (GPT NeoX Japanese model)"),KHo=l(),uv=a("li"),fFe=a("strong"),eJo=o("gptj"),oJo=o(" \u2014 "),oU=a("a"),rJo=o("GPTJForCausalLM"),tJo=o(" (GPT-J model)"),aJo=l(),pv=a("li"),gFe=a("strong"),nJo=o("marian"),sJo=o(" \u2014 "),rU=a("a"),lJo=o("MarianForCausalLM"),iJo=o(" (Marian model)"),dJo=l(),_v=a("li"),hFe=a("strong"),cJo=o("mbart"),mJo=o(" \u2014 "),tU=a("a"),fJo=o("MBartForCausalLM"),gJo=o(" (mBART model)"),hJo=l(),bv=a("li"),uFe=a("strong"),uJo=o("megatron-bert"),pJo=o(" \u2014 "),aU=a("a"),_Jo=o("MegatronBertForCausalLM"),bJo=o(" (Megatron-BERT model)"),vJo=l(),vv=a("li"),pFe=a("strong"),FJo=o("mvp"),TJo=o(" \u2014 "),nU=a("a"),MJo=o("MvpForCausalLM"),EJo=o(" (MVP model)"),CJo=l(),Fv=a("li"),_Fe=a("strong"),wJo=o("openai-gpt"),AJo=o(" \u2014 "),sU=a("a"),LJo=o("OpenAIGPTLMHeadModel"),yJo=o(" (OpenAI GPT model)"),xJo=l(),Tv=a("li"),bFe=a("strong"),$Jo=o("opt"),kJo=o(" \u2014 "),lU=a("a"),SJo=o("OPTForCausalLM"),RJo=o(" (OPT model)"),PJo=l(),Mv=a("li"),vFe=a("strong"),BJo=o("pegasus"),IJo=o(" \u2014 "),iU=a("a"),NJo=o("PegasusForCausalLM"),qJo=o(" (Pegasus model)"),jJo=l(),Ev=a("li"),FFe=a("strong"),DJo=o("plbart"),GJo=o(" \u2014 "),dU=a("a"),OJo=o("PLBartForCausalLM"),VJo=o(" (PLBart model)"),XJo=l(),Cv=a("li"),TFe=a("strong"),zJo=o("prophetnet"),QJo=o(" \u2014 "),cU=a("a"),WJo=o("ProphetNetForCausalLM"),UJo=o(" (ProphetNet model)"),HJo=l(),wv=a("li"),MFe=a("strong"),JJo=o("qdqbert"),YJo=o(" \u2014 "),mU=a("a"),ZJo=o("QDQBertLMHeadModel"),KJo=o(" (QDQBert model)"),eYo=l(),Av=a("li"),EFe=a("strong"),oYo=o("reformer"),rYo=o(" \u2014 "),fU=a("a"),tYo=o("ReformerModelWithLMHead"),aYo=o(" (Reformer model)"),nYo=l(),Lv=a("li"),CFe=a("strong"),sYo=o("rembert"),lYo=o(" \u2014 "),gU=a("a"),iYo=o("RemBertForCausalLM"),dYo=o(" (RemBERT model)"),cYo=l(),yv=a("li"),wFe=a("strong"),mYo=o("roberta"),fYo=o(" \u2014 "),hU=a("a"),gYo=o("RobertaForCausalLM"),hYo=o(" (RoBERTa model)"),uYo=l(),xv=a("li"),AFe=a("strong"),pYo=o("roformer"),_Yo=o(" \u2014 "),uU=a("a"),bYo=o("RoFormerForCausalLM"),vYo=o(" (RoFormer model)"),FYo=l(),$v=a("li"),LFe=a("strong"),TYo=o("speech_to_text_2"),MYo=o(" \u2014 "),pU=a("a"),EYo=o("Speech2Text2ForCausalLM"),CYo=o(" (Speech2Text2 model)"),wYo=l(),kv=a("li"),yFe=a("strong"),AYo=o("transfo-xl"),LYo=o(" \u2014 "),_U=a("a"),yYo=o("TransfoXLLMHeadModel"),xYo=o(" (Transformer-XL model)"),$Yo=l(),Sv=a("li"),xFe=a("strong"),kYo=o("trocr"),SYo=o(" \u2014 "),bU=a("a"),RYo=o("TrOCRForCausalLM"),PYo=o(" (TrOCR model)"),BYo=l(),Rv=a("li"),$Fe=a("strong"),IYo=o("xglm"),NYo=o(" \u2014 "),vU=a("a"),qYo=o("XGLMForCausalLM"),jYo=o(" (XGLM model)"),DYo=l(),Pv=a("li"),kFe=a("strong"),GYo=o("xlm"),OYo=o(" \u2014 "),FU=a("a"),VYo=o("XLMWithLMHeadModel"),XYo=o(" (XLM model)"),zYo=l(),Bv=a("li"),SFe=a("strong"),QYo=o("xlm-prophetnet"),WYo=o(" \u2014 "),TU=a("a"),UYo=o("XLMProphetNetForCausalLM"),HYo=o(" (XLM-ProphetNet model)"),JYo=l(),Iv=a("li"),RFe=a("strong"),YYo=o("xlm-roberta"),ZYo=o(" \u2014 "),MU=a("a"),KYo=o("XLMRobertaForCausalLM"),eZo=o(" (XLM-RoBERTa model)"),oZo=l(),Nv=a("li"),PFe=a("strong"),rZo=o("xlm-roberta-xl"),tZo=o(" \u2014 "),EU=a("a"),aZo=o("XLMRobertaXLForCausalLM"),nZo=o(" (XLM-RoBERTa-XL model)"),sZo=l(),qv=a("li"),BFe=a("strong"),lZo=o("xlnet"),iZo=o(" \u2014 "),CU=a("a"),dZo=o("XLNetLMHeadModel"),cZo=o(" (XLNet model)"),mZo=l(),jv=a("p"),fZo=o("The model is set in evaluation mode by default using "),IFe=a("code"),gZo=o("model.eval()"),hZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NFe=a("code"),uZo=o("model.train()"),pZo=l(),F(Dv.$$.fragment),lto=l(),jd=a("h2"),Gv=a("a"),qFe=a("span"),F(G$.$$.fragment),_Zo=l(),jFe=a("span"),bZo=o("AutoModelForDepthEstimation"),ito=l(),jo=a("div"),F(O$.$$.fragment),vZo=l(),Dd=a("p"),FZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),wU=a("a"),TZo=o("from_pretrained()"),MZo=o(" class method or the "),AU=a("a"),EZo=o("from_config()"),CZo=o(` class
method.`),wZo=l(),V$=a("p"),AZo=o("This class cannot be instantiated directly using "),DFe=a("code"),LZo=o("__init__()"),yZo=o(" (throws an error)."),xZo=l(),Ct=a("div"),F(X$.$$.fragment),$Zo=l(),GFe=a("p"),kZo=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),SZo=l(),Gd=a("p"),RZo=o(`Note:
Loading a model from its configuration file does `),OFe=a("strong"),PZo=o("not"),BZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),IZo=o("from_pretrained()"),NZo=o(" to load the model weights."),qZo=l(),F(Ov.$$.fragment),jZo=l(),ro=a("div"),F(z$.$$.fragment),DZo=l(),VFe=a("p"),GZo=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),OZo=l(),ln=a("p"),VZo=o("The model class to instantiate is selected based on the "),XFe=a("code"),XZo=o("model_type"),zZo=o(` property of the config object (either
passed as an argument or loaded from `),zFe=a("code"),QZo=o("pretrained_model_name_or_path"),WZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=a("code"),UZo=o("pretrained_model_name_or_path"),HZo=o(":"),JZo=l(),Q$=a("ul"),Vv=a("li"),WFe=a("strong"),YZo=o("dpt"),ZZo=o(" \u2014 "),yU=a("a"),KZo=o("DPTForDepthEstimation"),eKo=o(" (DPT model)"),oKo=l(),Xv=a("li"),UFe=a("strong"),rKo=o("glpn"),tKo=o(" \u2014 "),xU=a("a"),aKo=o("GLPNForDepthEstimation"),nKo=o(" (GLPN model)"),sKo=l(),zv=a("p"),lKo=o("The model is set in evaluation mode by default using "),HFe=a("code"),iKo=o("model.eval()"),dKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JFe=a("code"),cKo=o("model.train()"),mKo=l(),F(Qv.$$.fragment),dto=l(),Od=a("h2"),Wv=a("a"),YFe=a("span"),F(W$.$$.fragment),fKo=l(),ZFe=a("span"),gKo=o("AutoModelForMaskedLM"),cto=l(),Do=a("div"),F(U$.$$.fragment),hKo=l(),Vd=a("p"),uKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),$U=a("a"),pKo=o("from_pretrained()"),_Ko=o(" class method or the "),kU=a("a"),bKo=o("from_config()"),vKo=o(` class
method.`),FKo=l(),H$=a("p"),TKo=o("This class cannot be instantiated directly using "),KFe=a("code"),MKo=o("__init__()"),EKo=o(" (throws an error)."),CKo=l(),wt=a("div"),F(J$.$$.fragment),wKo=l(),eTe=a("p"),AKo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),LKo=l(),Xd=a("p"),yKo=o(`Note:
Loading a model from its configuration file does `),oTe=a("strong"),xKo=o("not"),$Ko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SU=a("a"),kKo=o("from_pretrained()"),SKo=o(" to load the model weights."),RKo=l(),F(Uv.$$.fragment),PKo=l(),to=a("div"),F(Y$.$$.fragment),BKo=l(),rTe=a("p"),IKo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),NKo=l(),dn=a("p"),qKo=o("The model class to instantiate is selected based on the "),tTe=a("code"),jKo=o("model_type"),DKo=o(` property of the config object (either
passed as an argument or loaded from `),aTe=a("code"),GKo=o("pretrained_model_name_or_path"),OKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nTe=a("code"),VKo=o("pretrained_model_name_or_path"),XKo=o(":"),zKo=l(),Y=a("ul"),Hv=a("li"),sTe=a("strong"),QKo=o("albert"),WKo=o(" \u2014 "),RU=a("a"),UKo=o("AlbertForMaskedLM"),HKo=o(" (ALBERT model)"),JKo=l(),Jv=a("li"),lTe=a("strong"),YKo=o("bart"),ZKo=o(" \u2014 "),PU=a("a"),KKo=o("BartForConditionalGeneration"),eer=o(" (BART model)"),oer=l(),Yv=a("li"),iTe=a("strong"),rer=o("bert"),ter=o(" \u2014 "),BU=a("a"),aer=o("BertForMaskedLM"),ner=o(" (BERT model)"),ser=l(),Zv=a("li"),dTe=a("strong"),ler=o("big_bird"),ier=o(" \u2014 "),IU=a("a"),der=o("BigBirdForMaskedLM"),cer=o(" (BigBird model)"),mer=l(),Kv=a("li"),cTe=a("strong"),fer=o("camembert"),ger=o(" \u2014 "),NU=a("a"),her=o("CamembertForMaskedLM"),uer=o(" (CamemBERT model)"),per=l(),eF=a("li"),mTe=a("strong"),_er=o("convbert"),ber=o(" \u2014 "),qU=a("a"),ver=o("ConvBertForMaskedLM"),Fer=o(" (ConvBERT model)"),Ter=l(),oF=a("li"),fTe=a("strong"),Mer=o("data2vec-text"),Eer=o(" \u2014 "),jU=a("a"),Cer=o("Data2VecTextForMaskedLM"),wer=o(" (Data2VecText model)"),Aer=l(),rF=a("li"),gTe=a("strong"),Ler=o("deberta"),yer=o(" \u2014 "),DU=a("a"),xer=o("DebertaForMaskedLM"),$er=o(" (DeBERTa model)"),ker=l(),tF=a("li"),hTe=a("strong"),Ser=o("deberta-v2"),Rer=o(" \u2014 "),GU=a("a"),Per=o("DebertaV2ForMaskedLM"),Ber=o(" (DeBERTa-v2 model)"),Ier=l(),aF=a("li"),uTe=a("strong"),Ner=o("distilbert"),qer=o(" \u2014 "),OU=a("a"),jer=o("DistilBertForMaskedLM"),Der=o(" (DistilBERT model)"),Ger=l(),nF=a("li"),pTe=a("strong"),Oer=o("electra"),Ver=o(" \u2014 "),VU=a("a"),Xer=o("ElectraForMaskedLM"),zer=o(" (ELECTRA model)"),Qer=l(),sF=a("li"),_Te=a("strong"),Wer=o("ernie"),Uer=o(" \u2014 "),XU=a("a"),Her=o("ErnieForMaskedLM"),Jer=o(" (ERNIE model)"),Yer=l(),lF=a("li"),bTe=a("strong"),Zer=o("flaubert"),Ker=o(" \u2014 "),zU=a("a"),eor=o("FlaubertWithLMHeadModel"),oor=o(" (FlauBERT model)"),ror=l(),iF=a("li"),vTe=a("strong"),tor=o("fnet"),aor=o(" \u2014 "),QU=a("a"),nor=o("FNetForMaskedLM"),sor=o(" (FNet model)"),lor=l(),dF=a("li"),FTe=a("strong"),ior=o("funnel"),dor=o(" \u2014 "),WU=a("a"),cor=o("FunnelForMaskedLM"),mor=o(" (Funnel Transformer model)"),gor=l(),cF=a("li"),TTe=a("strong"),hor=o("ibert"),uor=o(" \u2014 "),UU=a("a"),por=o("IBertForMaskedLM"),_or=o(" (I-BERT model)"),bor=l(),mF=a("li"),MTe=a("strong"),vor=o("layoutlm"),For=o(" \u2014 "),HU=a("a"),Tor=o("LayoutLMForMaskedLM"),Mor=o(" (LayoutLM model)"),Eor=l(),fF=a("li"),ETe=a("strong"),Cor=o("longformer"),wor=o(" \u2014 "),JU=a("a"),Aor=o("LongformerForMaskedLM"),Lor=o(" (Longformer model)"),yor=l(),gF=a("li"),CTe=a("strong"),xor=o("luke"),$or=o(" \u2014 "),YU=a("a"),kor=o("LukeForMaskedLM"),Sor=o(" (LUKE model)"),Ror=l(),hF=a("li"),wTe=a("strong"),Por=o("mbart"),Bor=o(" \u2014 "),ZU=a("a"),Ior=o("MBartForConditionalGeneration"),Nor=o(" (mBART model)"),qor=l(),uF=a("li"),ATe=a("strong"),jor=o("megatron-bert"),Dor=o(" \u2014 "),KU=a("a"),Gor=o("MegatronBertForMaskedLM"),Oor=o(" (Megatron-BERT model)"),Vor=l(),pF=a("li"),LTe=a("strong"),Xor=o("mobilebert"),zor=o(" \u2014 "),eH=a("a"),Qor=o("MobileBertForMaskedLM"),Wor=o(" (MobileBERT model)"),Uor=l(),_F=a("li"),yTe=a("strong"),Hor=o("mpnet"),Jor=o(" \u2014 "),oH=a("a"),Yor=o("MPNetForMaskedLM"),Zor=o(" (MPNet model)"),Kor=l(),bF=a("li"),xTe=a("strong"),err=o("mvp"),orr=o(" \u2014 "),rH=a("a"),rrr=o("MvpForConditionalGeneration"),trr=o(" (MVP model)"),arr=l(),vF=a("li"),$Te=a("strong"),nrr=o("nezha"),srr=o(" \u2014 "),tH=a("a"),lrr=o("NezhaForMaskedLM"),irr=o(" (Nezha model)"),drr=l(),FF=a("li"),kTe=a("strong"),crr=o("nystromformer"),mrr=o(" \u2014 "),aH=a("a"),frr=o("NystromformerForMaskedLM"),grr=o(" (Nystr\xF6mformer model)"),hrr=l(),TF=a("li"),STe=a("strong"),urr=o("perceiver"),prr=o(" \u2014 "),nH=a("a"),_rr=o("PerceiverForMaskedLM"),brr=o(" (Perceiver model)"),vrr=l(),MF=a("li"),RTe=a("strong"),Frr=o("qdqbert"),Trr=o(" \u2014 "),sH=a("a"),Mrr=o("QDQBertForMaskedLM"),Err=o(" (QDQBert model)"),Crr=l(),EF=a("li"),PTe=a("strong"),wrr=o("reformer"),Arr=o(" \u2014 "),lH=a("a"),Lrr=o("ReformerForMaskedLM"),yrr=o(" (Reformer model)"),xrr=l(),CF=a("li"),BTe=a("strong"),$rr=o("rembert"),krr=o(" \u2014 "),iH=a("a"),Srr=o("RemBertForMaskedLM"),Rrr=o(" (RemBERT model)"),Prr=l(),wF=a("li"),ITe=a("strong"),Brr=o("roberta"),Irr=o(" \u2014 "),dH=a("a"),Nrr=o("RobertaForMaskedLM"),qrr=o(" (RoBERTa model)"),jrr=l(),AF=a("li"),NTe=a("strong"),Drr=o("roformer"),Grr=o(" \u2014 "),cH=a("a"),Orr=o("RoFormerForMaskedLM"),Vrr=o(" (RoFormer model)"),Xrr=l(),LF=a("li"),qTe=a("strong"),zrr=o("squeezebert"),Qrr=o(" \u2014 "),mH=a("a"),Wrr=o("SqueezeBertForMaskedLM"),Urr=o(" (SqueezeBERT model)"),Hrr=l(),yF=a("li"),jTe=a("strong"),Jrr=o("tapas"),Yrr=o(" \u2014 "),fH=a("a"),Zrr=o("TapasForMaskedLM"),Krr=o(" (TAPAS model)"),etr=l(),xF=a("li"),DTe=a("strong"),otr=o("wav2vec2"),rtr=o(" \u2014 "),GTe=a("code"),ttr=o("Wav2Vec2ForMaskedLM"),atr=o(" (Wav2Vec2 model)"),ntr=l(),$F=a("li"),OTe=a("strong"),str=o("xlm"),ltr=o(" \u2014 "),gH=a("a"),itr=o("XLMWithLMHeadModel"),dtr=o(" (XLM model)"),ctr=l(),kF=a("li"),VTe=a("strong"),mtr=o("xlm-roberta"),ftr=o(" \u2014 "),hH=a("a"),gtr=o("XLMRobertaForMaskedLM"),htr=o(" (XLM-RoBERTa model)"),utr=l(),SF=a("li"),XTe=a("strong"),ptr=o("xlm-roberta-xl"),_tr=o(" \u2014 "),uH=a("a"),btr=o("XLMRobertaXLForMaskedLM"),vtr=o(" (XLM-RoBERTa-XL model)"),Ftr=l(),RF=a("li"),zTe=a("strong"),Ttr=o("yoso"),Mtr=o(" \u2014 "),pH=a("a"),Etr=o("YosoForMaskedLM"),Ctr=o(" (YOSO model)"),wtr=l(),PF=a("p"),Atr=o("The model is set in evaluation mode by default using "),QTe=a("code"),Ltr=o("model.eval()"),ytr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WTe=a("code"),xtr=o("model.train()"),$tr=l(),F(BF.$$.fragment),mto=l(),zd=a("h2"),IF=a("a"),UTe=a("span"),F(Z$.$$.fragment),ktr=l(),HTe=a("span"),Str=o("AutoModelForSeq2SeqLM"),fto=l(),Go=a("div"),F(K$.$$.fragment),Rtr=l(),Qd=a("p"),Ptr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_H=a("a"),Btr=o("from_pretrained()"),Itr=o(" class method or the "),bH=a("a"),Ntr=o("from_config()"),qtr=o(` class
method.`),jtr=l(),ek=a("p"),Dtr=o("This class cannot be instantiated directly using "),JTe=a("code"),Gtr=o("__init__()"),Otr=o(" (throws an error)."),Vtr=l(),At=a("div"),F(ok.$$.fragment),Xtr=l(),YTe=a("p"),ztr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qtr=l(),Wd=a("p"),Wtr=o(`Note:
Loading a model from its configuration file does `),ZTe=a("strong"),Utr=o("not"),Htr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vH=a("a"),Jtr=o("from_pretrained()"),Ytr=o(" to load the model weights."),Ztr=l(),F(NF.$$.fragment),Ktr=l(),ao=a("div"),F(rk.$$.fragment),ear=l(),KTe=a("p"),oar=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),rar=l(),cn=a("p"),tar=o("The model class to instantiate is selected based on the "),eMe=a("code"),aar=o("model_type"),nar=o(` property of the config object (either
passed as an argument or loaded from `),oMe=a("code"),sar=o("pretrained_model_name_or_path"),lar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rMe=a("code"),iar=o("pretrained_model_name_or_path"),dar=o(":"),car=l(),fe=a("ul"),qF=a("li"),tMe=a("strong"),mar=o("bart"),far=o(" \u2014 "),FH=a("a"),gar=o("BartForConditionalGeneration"),har=o(" (BART model)"),uar=l(),jF=a("li"),aMe=a("strong"),par=o("bigbird_pegasus"),_ar=o(" \u2014 "),TH=a("a"),bar=o("BigBirdPegasusForConditionalGeneration"),Far=o(" (BigBird-Pegasus model)"),Tar=l(),DF=a("li"),nMe=a("strong"),Mar=o("blenderbot"),Ear=o(" \u2014 "),MH=a("a"),Car=o("BlenderbotForConditionalGeneration"),war=o(" (Blenderbot model)"),Aar=l(),GF=a("li"),sMe=a("strong"),Lar=o("blenderbot-small"),yar=o(" \u2014 "),EH=a("a"),xar=o("BlenderbotSmallForConditionalGeneration"),$ar=o(" (BlenderbotSmall model)"),kar=l(),OF=a("li"),lMe=a("strong"),Sar=o("encoder-decoder"),Rar=o(" \u2014 "),CH=a("a"),Par=o("EncoderDecoderModel"),Bar=o(" (Encoder decoder model)"),Iar=l(),VF=a("li"),iMe=a("strong"),Nar=o("fsmt"),qar=o(" \u2014 "),wH=a("a"),jar=o("FSMTForConditionalGeneration"),Dar=o(" (FairSeq Machine-Translation model)"),Gar=l(),XF=a("li"),dMe=a("strong"),Oar=o("led"),Var=o(" \u2014 "),AH=a("a"),Xar=o("LEDForConditionalGeneration"),zar=o(" (LED model)"),Qar=l(),zF=a("li"),cMe=a("strong"),War=o("longt5"),Uar=o(" \u2014 "),LH=a("a"),Har=o("LongT5ForConditionalGeneration"),Jar=o(" (LongT5 model)"),Yar=l(),QF=a("li"),mMe=a("strong"),Zar=o("m2m_100"),Kar=o(" \u2014 "),yH=a("a"),enr=o("M2M100ForConditionalGeneration"),onr=o(" (M2M100 model)"),rnr=l(),WF=a("li"),fMe=a("strong"),tnr=o("marian"),anr=o(" \u2014 "),xH=a("a"),nnr=o("MarianMTModel"),snr=o(" (Marian model)"),lnr=l(),UF=a("li"),gMe=a("strong"),inr=o("mbart"),dnr=o(" \u2014 "),$H=a("a"),cnr=o("MBartForConditionalGeneration"),mnr=o(" (mBART model)"),fnr=l(),HF=a("li"),hMe=a("strong"),gnr=o("mt5"),hnr=o(" \u2014 "),kH=a("a"),unr=o("MT5ForConditionalGeneration"),pnr=o(" (MT5 model)"),_nr=l(),JF=a("li"),uMe=a("strong"),bnr=o("mvp"),vnr=o(" \u2014 "),SH=a("a"),Fnr=o("MvpForConditionalGeneration"),Tnr=o(" (MVP model)"),Mnr=l(),YF=a("li"),pMe=a("strong"),Enr=o("nllb"),Cnr=o(" \u2014 "),RH=a("a"),wnr=o("M2M100ForConditionalGeneration"),Anr=o(" (NLLB model)"),Lnr=l(),ZF=a("li"),_Me=a("strong"),ynr=o("pegasus"),xnr=o(" \u2014 "),PH=a("a"),$nr=o("PegasusForConditionalGeneration"),knr=o(" (Pegasus model)"),Snr=l(),KF=a("li"),bMe=a("strong"),Rnr=o("pegasus_x"),Pnr=o(" \u2014 "),BH=a("a"),Bnr=o("PegasusXForConditionalGeneration"),Inr=o(" (PEGASUS-X model)"),Nnr=l(),eT=a("li"),vMe=a("strong"),qnr=o("plbart"),jnr=o(" \u2014 "),IH=a("a"),Dnr=o("PLBartForConditionalGeneration"),Gnr=o(" (PLBart model)"),Onr=l(),oT=a("li"),FMe=a("strong"),Vnr=o("prophetnet"),Xnr=o(" \u2014 "),NH=a("a"),znr=o("ProphetNetForConditionalGeneration"),Qnr=o(" (ProphetNet model)"),Wnr=l(),rT=a("li"),TMe=a("strong"),Unr=o("t5"),Hnr=o(" \u2014 "),qH=a("a"),Jnr=o("T5ForConditionalGeneration"),Ynr=o(" (T5 model)"),Znr=l(),tT=a("li"),MMe=a("strong"),Knr=o("xlm-prophetnet"),esr=o(" \u2014 "),jH=a("a"),osr=o("XLMProphetNetForConditionalGeneration"),rsr=o(" (XLM-ProphetNet model)"),tsr=l(),aT=a("p"),asr=o("The model is set in evaluation mode by default using "),EMe=a("code"),nsr=o("model.eval()"),ssr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CMe=a("code"),lsr=o("model.train()"),isr=l(),F(nT.$$.fragment),gto=l(),Ud=a("h2"),sT=a("a"),wMe=a("span"),F(tk.$$.fragment),dsr=l(),AMe=a("span"),csr=o("AutoModelForSequenceClassification"),hto=l(),Oo=a("div"),F(ak.$$.fragment),msr=l(),Hd=a("p"),fsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),DH=a("a"),gsr=o("from_pretrained()"),hsr=o(" class method or the "),GH=a("a"),usr=o("from_config()"),psr=o(` class
method.`),_sr=l(),nk=a("p"),bsr=o("This class cannot be instantiated directly using "),LMe=a("code"),vsr=o("__init__()"),Fsr=o(" (throws an error)."),Tsr=l(),Lt=a("div"),F(sk.$$.fragment),Msr=l(),yMe=a("p"),Esr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Csr=l(),Jd=a("p"),wsr=o(`Note:
Loading a model from its configuration file does `),xMe=a("strong"),Asr=o("not"),Lsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OH=a("a"),ysr=o("from_pretrained()"),xsr=o(" to load the model weights."),$sr=l(),F(lT.$$.fragment),ksr=l(),no=a("div"),F(lk.$$.fragment),Ssr=l(),$Me=a("p"),Rsr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Psr=l(),mn=a("p"),Bsr=o("The model class to instantiate is selected based on the "),kMe=a("code"),Isr=o("model_type"),Nsr=o(` property of the config object (either
passed as an argument or loaded from `),SMe=a("code"),qsr=o("pretrained_model_name_or_path"),jsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RMe=a("code"),Dsr=o("pretrained_model_name_or_path"),Gsr=o(":"),Osr=l(),q=a("ul"),iT=a("li"),PMe=a("strong"),Vsr=o("albert"),Xsr=o(" \u2014 "),VH=a("a"),zsr=o("AlbertForSequenceClassification"),Qsr=o(" (ALBERT model)"),Wsr=l(),dT=a("li"),BMe=a("strong"),Usr=o("bart"),Hsr=o(" \u2014 "),XH=a("a"),Jsr=o("BartForSequenceClassification"),Ysr=o(" (BART model)"),Zsr=l(),cT=a("li"),IMe=a("strong"),Ksr=o("bert"),elr=o(" \u2014 "),zH=a("a"),olr=o("BertForSequenceClassification"),rlr=o(" (BERT model)"),tlr=l(),mT=a("li"),NMe=a("strong"),alr=o("big_bird"),nlr=o(" \u2014 "),QH=a("a"),slr=o("BigBirdForSequenceClassification"),llr=o(" (BigBird model)"),ilr=l(),fT=a("li"),qMe=a("strong"),dlr=o("bigbird_pegasus"),clr=o(" \u2014 "),WH=a("a"),mlr=o("BigBirdPegasusForSequenceClassification"),flr=o(" (BigBird-Pegasus model)"),glr=l(),gT=a("li"),jMe=a("strong"),hlr=o("bloom"),ulr=o(" \u2014 "),UH=a("a"),plr=o("BloomForSequenceClassification"),_lr=o(" (BLOOM model)"),blr=l(),hT=a("li"),DMe=a("strong"),vlr=o("camembert"),Flr=o(" \u2014 "),HH=a("a"),Tlr=o("CamembertForSequenceClassification"),Mlr=o(" (CamemBERT model)"),Elr=l(),uT=a("li"),GMe=a("strong"),Clr=o("canine"),wlr=o(" \u2014 "),JH=a("a"),Alr=o("CanineForSequenceClassification"),Llr=o(" (CANINE model)"),ylr=l(),pT=a("li"),OMe=a("strong"),xlr=o("convbert"),$lr=o(" \u2014 "),YH=a("a"),klr=o("ConvBertForSequenceClassification"),Slr=o(" (ConvBERT model)"),Rlr=l(),_T=a("li"),VMe=a("strong"),Plr=o("ctrl"),Blr=o(" \u2014 "),ZH=a("a"),Ilr=o("CTRLForSequenceClassification"),Nlr=o(" (CTRL model)"),qlr=l(),bT=a("li"),XMe=a("strong"),jlr=o("data2vec-text"),Dlr=o(" \u2014 "),KH=a("a"),Glr=o("Data2VecTextForSequenceClassification"),Olr=o(" (Data2VecText model)"),Vlr=l(),vT=a("li"),zMe=a("strong"),Xlr=o("deberta"),zlr=o(" \u2014 "),eJ=a("a"),Qlr=o("DebertaForSequenceClassification"),Wlr=o(" (DeBERTa model)"),Ulr=l(),FT=a("li"),QMe=a("strong"),Hlr=o("deberta-v2"),Jlr=o(" \u2014 "),oJ=a("a"),Ylr=o("DebertaV2ForSequenceClassification"),Zlr=o(" (DeBERTa-v2 model)"),Klr=l(),TT=a("li"),WMe=a("strong"),eir=o("distilbert"),oir=o(" \u2014 "),rJ=a("a"),rir=o("DistilBertForSequenceClassification"),tir=o(" (DistilBERT model)"),air=l(),MT=a("li"),UMe=a("strong"),nir=o("electra"),sir=o(" \u2014 "),tJ=a("a"),lir=o("ElectraForSequenceClassification"),iir=o(" (ELECTRA model)"),dir=l(),ET=a("li"),HMe=a("strong"),cir=o("ernie"),mir=o(" \u2014 "),aJ=a("a"),fir=o("ErnieForSequenceClassification"),gir=o(" (ERNIE model)"),hir=l(),CT=a("li"),JMe=a("strong"),uir=o("esm"),pir=o(" \u2014 "),nJ=a("a"),_ir=o("EsmForSequenceClassification"),bir=o(" (ESM model)"),vir=l(),wT=a("li"),YMe=a("strong"),Fir=o("flaubert"),Tir=o(" \u2014 "),sJ=a("a"),Mir=o("FlaubertForSequenceClassification"),Eir=o(" (FlauBERT model)"),Cir=l(),AT=a("li"),ZMe=a("strong"),wir=o("fnet"),Air=o(" \u2014 "),lJ=a("a"),Lir=o("FNetForSequenceClassification"),yir=o(" (FNet model)"),xir=l(),LT=a("li"),KMe=a("strong"),$ir=o("funnel"),kir=o(" \u2014 "),iJ=a("a"),Sir=o("FunnelForSequenceClassification"),Rir=o(" (Funnel Transformer model)"),Pir=l(),yT=a("li"),eEe=a("strong"),Bir=o("gpt2"),Iir=o(" \u2014 "),dJ=a("a"),Nir=o("GPT2ForSequenceClassification"),qir=o(" (OpenAI GPT-2 model)"),jir=l(),xT=a("li"),oEe=a("strong"),Dir=o("gpt_neo"),Gir=o(" \u2014 "),cJ=a("a"),Oir=o("GPTNeoForSequenceClassification"),Vir=o(" (GPT Neo model)"),Xir=l(),$T=a("li"),rEe=a("strong"),zir=o("gptj"),Qir=o(" \u2014 "),mJ=a("a"),Wir=o("GPTJForSequenceClassification"),Uir=o(" (GPT-J model)"),Hir=l(),kT=a("li"),tEe=a("strong"),Jir=o("ibert"),Yir=o(" \u2014 "),fJ=a("a"),Zir=o("IBertForSequenceClassification"),Kir=o(" (I-BERT model)"),edr=l(),ST=a("li"),aEe=a("strong"),odr=o("layoutlm"),rdr=o(" \u2014 "),gJ=a("a"),tdr=o("LayoutLMForSequenceClassification"),adr=o(" (LayoutLM model)"),ndr=l(),RT=a("li"),nEe=a("strong"),sdr=o("layoutlmv2"),ldr=o(" \u2014 "),hJ=a("a"),idr=o("LayoutLMv2ForSequenceClassification"),ddr=o(" (LayoutLMv2 model)"),cdr=l(),PT=a("li"),sEe=a("strong"),mdr=o("layoutlmv3"),fdr=o(" \u2014 "),uJ=a("a"),gdr=o("LayoutLMv3ForSequenceClassification"),hdr=o(" (LayoutLMv3 model)"),udr=l(),BT=a("li"),lEe=a("strong"),pdr=o("led"),_dr=o(" \u2014 "),pJ=a("a"),bdr=o("LEDForSequenceClassification"),vdr=o(" (LED model)"),Fdr=l(),IT=a("li"),iEe=a("strong"),Tdr=o("lilt"),Mdr=o(" \u2014 "),_J=a("a"),Edr=o("LiltForSequenceClassification"),Cdr=o(" (LiLT model)"),wdr=l(),NT=a("li"),dEe=a("strong"),Adr=o("longformer"),Ldr=o(" \u2014 "),bJ=a("a"),ydr=o("LongformerForSequenceClassification"),xdr=o(" (Longformer model)"),$dr=l(),qT=a("li"),cEe=a("strong"),kdr=o("luke"),Sdr=o(" \u2014 "),vJ=a("a"),Rdr=o("LukeForSequenceClassification"),Pdr=o(" (LUKE model)"),Bdr=l(),jT=a("li"),mEe=a("strong"),Idr=o("markuplm"),Ndr=o(" \u2014 "),FJ=a("a"),qdr=o("MarkupLMForSequenceClassification"),jdr=o(" (MarkupLM model)"),Ddr=l(),DT=a("li"),fEe=a("strong"),Gdr=o("mbart"),Odr=o(" \u2014 "),TJ=a("a"),Vdr=o("MBartForSequenceClassification"),Xdr=o(" (mBART model)"),zdr=l(),GT=a("li"),gEe=a("strong"),Qdr=o("megatron-bert"),Wdr=o(" \u2014 "),MJ=a("a"),Udr=o("MegatronBertForSequenceClassification"),Hdr=o(" (Megatron-BERT model)"),Jdr=l(),OT=a("li"),hEe=a("strong"),Ydr=o("mobilebert"),Zdr=o(" \u2014 "),EJ=a("a"),Kdr=o("MobileBertForSequenceClassification"),ecr=o(" (MobileBERT model)"),ocr=l(),VT=a("li"),uEe=a("strong"),rcr=o("mpnet"),tcr=o(" \u2014 "),CJ=a("a"),acr=o("MPNetForSequenceClassification"),ncr=o(" (MPNet model)"),scr=l(),XT=a("li"),pEe=a("strong"),lcr=o("mvp"),icr=o(" \u2014 "),wJ=a("a"),dcr=o("MvpForSequenceClassification"),ccr=o(" (MVP model)"),mcr=l(),zT=a("li"),_Ee=a("strong"),fcr=o("nezha"),gcr=o(" \u2014 "),AJ=a("a"),hcr=o("NezhaForSequenceClassification"),ucr=o(" (Nezha model)"),pcr=l(),QT=a("li"),bEe=a("strong"),_cr=o("nystromformer"),bcr=o(" \u2014 "),LJ=a("a"),vcr=o("NystromformerForSequenceClassification"),Fcr=o(" (Nystr\xF6mformer model)"),Tcr=l(),WT=a("li"),vEe=a("strong"),Mcr=o("openai-gpt"),Ecr=o(" \u2014 "),yJ=a("a"),Ccr=o("OpenAIGPTForSequenceClassification"),wcr=o(" (OpenAI GPT model)"),Acr=l(),UT=a("li"),FEe=a("strong"),Lcr=o("opt"),ycr=o(" \u2014 "),xJ=a("a"),xcr=o("OPTForSequenceClassification"),$cr=o(" (OPT model)"),kcr=l(),HT=a("li"),TEe=a("strong"),Scr=o("perceiver"),Rcr=o(" \u2014 "),$J=a("a"),Pcr=o("PerceiverForSequenceClassification"),Bcr=o(" (Perceiver model)"),Icr=l(),JT=a("li"),MEe=a("strong"),Ncr=o("plbart"),qcr=o(" \u2014 "),kJ=a("a"),jcr=o("PLBartForSequenceClassification"),Dcr=o(" (PLBart model)"),Gcr=l(),YT=a("li"),EEe=a("strong"),Ocr=o("qdqbert"),Vcr=o(" \u2014 "),SJ=a("a"),Xcr=o("QDQBertForSequenceClassification"),zcr=o(" (QDQBert model)"),Qcr=l(),ZT=a("li"),CEe=a("strong"),Wcr=o("reformer"),Ucr=o(" \u2014 "),RJ=a("a"),Hcr=o("ReformerForSequenceClassification"),Jcr=o(" (Reformer model)"),Ycr=l(),KT=a("li"),wEe=a("strong"),Zcr=o("rembert"),Kcr=o(" \u2014 "),PJ=a("a"),emr=o("RemBertForSequenceClassification"),omr=o(" (RemBERT model)"),rmr=l(),eM=a("li"),AEe=a("strong"),tmr=o("roberta"),amr=o(" \u2014 "),BJ=a("a"),nmr=o("RobertaForSequenceClassification"),smr=o(" (RoBERTa model)"),lmr=l(),oM=a("li"),LEe=a("strong"),imr=o("roformer"),dmr=o(" \u2014 "),IJ=a("a"),cmr=o("RoFormerForSequenceClassification"),mmr=o(" (RoFormer model)"),fmr=l(),rM=a("li"),yEe=a("strong"),gmr=o("squeezebert"),hmr=o(" \u2014 "),NJ=a("a"),umr=o("SqueezeBertForSequenceClassification"),pmr=o(" (SqueezeBERT model)"),_mr=l(),tM=a("li"),xEe=a("strong"),bmr=o("tapas"),vmr=o(" \u2014 "),qJ=a("a"),Fmr=o("TapasForSequenceClassification"),Tmr=o(" (TAPAS model)"),Mmr=l(),aM=a("li"),$Ee=a("strong"),Emr=o("transfo-xl"),Cmr=o(" \u2014 "),jJ=a("a"),wmr=o("TransfoXLForSequenceClassification"),Amr=o(" (Transformer-XL model)"),Lmr=l(),nM=a("li"),kEe=a("strong"),ymr=o("xlm"),xmr=o(" \u2014 "),DJ=a("a"),$mr=o("XLMForSequenceClassification"),kmr=o(" (XLM model)"),Smr=l(),sM=a("li"),SEe=a("strong"),Rmr=o("xlm-roberta"),Pmr=o(" \u2014 "),GJ=a("a"),Bmr=o("XLMRobertaForSequenceClassification"),Imr=o(" (XLM-RoBERTa model)"),Nmr=l(),lM=a("li"),REe=a("strong"),qmr=o("xlm-roberta-xl"),jmr=o(" \u2014 "),OJ=a("a"),Dmr=o("XLMRobertaXLForSequenceClassification"),Gmr=o(" (XLM-RoBERTa-XL model)"),Omr=l(),iM=a("li"),PEe=a("strong"),Vmr=o("xlnet"),Xmr=o(" \u2014 "),VJ=a("a"),zmr=o("XLNetForSequenceClassification"),Qmr=o(" (XLNet model)"),Wmr=l(),dM=a("li"),BEe=a("strong"),Umr=o("yoso"),Hmr=o(" \u2014 "),XJ=a("a"),Jmr=o("YosoForSequenceClassification"),Ymr=o(" (YOSO model)"),Zmr=l(),cM=a("p"),Kmr=o("The model is set in evaluation mode by default using "),IEe=a("code"),efr=o("model.eval()"),ofr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NEe=a("code"),rfr=o("model.train()"),tfr=l(),F(mM.$$.fragment),uto=l(),Yd=a("h2"),fM=a("a"),qEe=a("span"),F(ik.$$.fragment),afr=l(),jEe=a("span"),nfr=o("AutoModelForMultipleChoice"),pto=l(),Vo=a("div"),F(dk.$$.fragment),sfr=l(),Zd=a("p"),lfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zJ=a("a"),ifr=o("from_pretrained()"),dfr=o(" class method or the "),QJ=a("a"),cfr=o("from_config()"),mfr=o(` class
method.`),ffr=l(),ck=a("p"),gfr=o("This class cannot be instantiated directly using "),DEe=a("code"),hfr=o("__init__()"),ufr=o(" (throws an error)."),pfr=l(),yt=a("div"),F(mk.$$.fragment),_fr=l(),GEe=a("p"),bfr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vfr=l(),Kd=a("p"),Ffr=o(`Note:
Loading a model from its configuration file does `),OEe=a("strong"),Tfr=o("not"),Mfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=a("a"),Efr=o("from_pretrained()"),Cfr=o(" to load the model weights."),wfr=l(),F(gM.$$.fragment),Afr=l(),so=a("div"),F(fk.$$.fragment),Lfr=l(),VEe=a("p"),yfr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xfr=l(),fn=a("p"),$fr=o("The model class to instantiate is selected based on the "),XEe=a("code"),kfr=o("model_type"),Sfr=o(` property of the config object (either
passed as an argument or loaded from `),zEe=a("code"),Rfr=o("pretrained_model_name_or_path"),Pfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=a("code"),Bfr=o("pretrained_model_name_or_path"),Ifr=o(":"),Nfr=l(),K=a("ul"),hM=a("li"),WEe=a("strong"),qfr=o("albert"),jfr=o(" \u2014 "),UJ=a("a"),Dfr=o("AlbertForMultipleChoice"),Gfr=o(" (ALBERT model)"),Ofr=l(),uM=a("li"),UEe=a("strong"),Vfr=o("bert"),Xfr=o(" \u2014 "),HJ=a("a"),zfr=o("BertForMultipleChoice"),Qfr=o(" (BERT model)"),Wfr=l(),pM=a("li"),HEe=a("strong"),Ufr=o("big_bird"),Hfr=o(" \u2014 "),JJ=a("a"),Jfr=o("BigBirdForMultipleChoice"),Yfr=o(" (BigBird model)"),Zfr=l(),_M=a("li"),JEe=a("strong"),Kfr=o("camembert"),egr=o(" \u2014 "),YJ=a("a"),ogr=o("CamembertForMultipleChoice"),rgr=o(" (CamemBERT model)"),tgr=l(),bM=a("li"),YEe=a("strong"),agr=o("canine"),ngr=o(" \u2014 "),ZJ=a("a"),sgr=o("CanineForMultipleChoice"),lgr=o(" (CANINE model)"),igr=l(),vM=a("li"),ZEe=a("strong"),dgr=o("convbert"),cgr=o(" \u2014 "),KJ=a("a"),mgr=o("ConvBertForMultipleChoice"),fgr=o(" (ConvBERT model)"),ggr=l(),FM=a("li"),KEe=a("strong"),hgr=o("data2vec-text"),ugr=o(" \u2014 "),eY=a("a"),pgr=o("Data2VecTextForMultipleChoice"),_gr=o(" (Data2VecText model)"),bgr=l(),TM=a("li"),e4e=a("strong"),vgr=o("deberta-v2"),Fgr=o(" \u2014 "),oY=a("a"),Tgr=o("DebertaV2ForMultipleChoice"),Mgr=o(" (DeBERTa-v2 model)"),Egr=l(),MM=a("li"),o4e=a("strong"),Cgr=o("distilbert"),wgr=o(" \u2014 "),rY=a("a"),Agr=o("DistilBertForMultipleChoice"),Lgr=o(" (DistilBERT model)"),ygr=l(),EM=a("li"),r4e=a("strong"),xgr=o("electra"),$gr=o(" \u2014 "),tY=a("a"),kgr=o("ElectraForMultipleChoice"),Sgr=o(" (ELECTRA model)"),Rgr=l(),CM=a("li"),t4e=a("strong"),Pgr=o("ernie"),Bgr=o(" \u2014 "),aY=a("a"),Igr=o("ErnieForMultipleChoice"),Ngr=o(" (ERNIE model)"),qgr=l(),wM=a("li"),a4e=a("strong"),jgr=o("flaubert"),Dgr=o(" \u2014 "),nY=a("a"),Ggr=o("FlaubertForMultipleChoice"),Ogr=o(" (FlauBERT model)"),Vgr=l(),AM=a("li"),n4e=a("strong"),Xgr=o("fnet"),zgr=o(" \u2014 "),sY=a("a"),Qgr=o("FNetForMultipleChoice"),Wgr=o(" (FNet model)"),Ugr=l(),LM=a("li"),s4e=a("strong"),Hgr=o("funnel"),Jgr=o(" \u2014 "),lY=a("a"),Ygr=o("FunnelForMultipleChoice"),Zgr=o(" (Funnel Transformer model)"),Kgr=l(),yM=a("li"),l4e=a("strong"),ehr=o("ibert"),ohr=o(" \u2014 "),iY=a("a"),rhr=o("IBertForMultipleChoice"),thr=o(" (I-BERT model)"),ahr=l(),xM=a("li"),i4e=a("strong"),nhr=o("longformer"),shr=o(" \u2014 "),dY=a("a"),lhr=o("LongformerForMultipleChoice"),ihr=o(" (Longformer model)"),dhr=l(),$M=a("li"),d4e=a("strong"),chr=o("luke"),mhr=o(" \u2014 "),cY=a("a"),fhr=o("LukeForMultipleChoice"),ghr=o(" (LUKE model)"),hhr=l(),kM=a("li"),c4e=a("strong"),uhr=o("megatron-bert"),phr=o(" \u2014 "),mY=a("a"),_hr=o("MegatronBertForMultipleChoice"),bhr=o(" (Megatron-BERT model)"),vhr=l(),SM=a("li"),m4e=a("strong"),Fhr=o("mobilebert"),Thr=o(" \u2014 "),fY=a("a"),Mhr=o("MobileBertForMultipleChoice"),Ehr=o(" (MobileBERT model)"),Chr=l(),RM=a("li"),f4e=a("strong"),whr=o("mpnet"),Ahr=o(" \u2014 "),gY=a("a"),Lhr=o("MPNetForMultipleChoice"),yhr=o(" (MPNet model)"),xhr=l(),PM=a("li"),g4e=a("strong"),$hr=o("nezha"),khr=o(" \u2014 "),hY=a("a"),Shr=o("NezhaForMultipleChoice"),Rhr=o(" (Nezha model)"),Phr=l(),BM=a("li"),h4e=a("strong"),Bhr=o("nystromformer"),Ihr=o(" \u2014 "),uY=a("a"),Nhr=o("NystromformerForMultipleChoice"),qhr=o(" (Nystr\xF6mformer model)"),jhr=l(),IM=a("li"),u4e=a("strong"),Dhr=o("qdqbert"),Ghr=o(" \u2014 "),pY=a("a"),Ohr=o("QDQBertForMultipleChoice"),Vhr=o(" (QDQBert model)"),Xhr=l(),NM=a("li"),p4e=a("strong"),zhr=o("rembert"),Qhr=o(" \u2014 "),_Y=a("a"),Whr=o("RemBertForMultipleChoice"),Uhr=o(" (RemBERT model)"),Hhr=l(),qM=a("li"),_4e=a("strong"),Jhr=o("roberta"),Yhr=o(" \u2014 "),bY=a("a"),Zhr=o("RobertaForMultipleChoice"),Khr=o(" (RoBERTa model)"),eur=l(),jM=a("li"),b4e=a("strong"),our=o("roformer"),rur=o(" \u2014 "),vY=a("a"),tur=o("RoFormerForMultipleChoice"),aur=o(" (RoFormer model)"),nur=l(),DM=a("li"),v4e=a("strong"),sur=o("squeezebert"),lur=o(" \u2014 "),FY=a("a"),iur=o("SqueezeBertForMultipleChoice"),dur=o(" (SqueezeBERT model)"),cur=l(),GM=a("li"),F4e=a("strong"),mur=o("xlm"),fur=o(" \u2014 "),TY=a("a"),gur=o("XLMForMultipleChoice"),hur=o(" (XLM model)"),uur=l(),OM=a("li"),T4e=a("strong"),pur=o("xlm-roberta"),_ur=o(" \u2014 "),MY=a("a"),bur=o("XLMRobertaForMultipleChoice"),vur=o(" (XLM-RoBERTa model)"),Fur=l(),VM=a("li"),M4e=a("strong"),Tur=o("xlm-roberta-xl"),Mur=o(" \u2014 "),EY=a("a"),Eur=o("XLMRobertaXLForMultipleChoice"),Cur=o(" (XLM-RoBERTa-XL model)"),wur=l(),XM=a("li"),E4e=a("strong"),Aur=o("xlnet"),Lur=o(" \u2014 "),CY=a("a"),yur=o("XLNetForMultipleChoice"),xur=o(" (XLNet model)"),$ur=l(),zM=a("li"),C4e=a("strong"),kur=o("yoso"),Sur=o(" \u2014 "),wY=a("a"),Rur=o("YosoForMultipleChoice"),Pur=o(" (YOSO model)"),Bur=l(),QM=a("p"),Iur=o("The model is set in evaluation mode by default using "),w4e=a("code"),Nur=o("model.eval()"),qur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A4e=a("code"),jur=o("model.train()"),Dur=l(),F(WM.$$.fragment),_to=l(),ec=a("h2"),UM=a("a"),L4e=a("span"),F(gk.$$.fragment),Gur=l(),y4e=a("span"),Our=o("AutoModelForNextSentencePrediction"),bto=l(),Xo=a("div"),F(hk.$$.fragment),Vur=l(),oc=a("p"),Xur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),AY=a("a"),zur=o("from_pretrained()"),Qur=o(" class method or the "),LY=a("a"),Wur=o("from_config()"),Uur=o(` class
method.`),Hur=l(),uk=a("p"),Jur=o("This class cannot be instantiated directly using "),x4e=a("code"),Yur=o("__init__()"),Zur=o(" (throws an error)."),Kur=l(),xt=a("div"),F(pk.$$.fragment),epr=l(),$4e=a("p"),opr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),rpr=l(),rc=a("p"),tpr=o(`Note:
Loading a model from its configuration file does `),k4e=a("strong"),apr=o("not"),npr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=a("a"),spr=o("from_pretrained()"),lpr=o(" to load the model weights."),ipr=l(),F(HM.$$.fragment),dpr=l(),lo=a("div"),F(_k.$$.fragment),cpr=l(),S4e=a("p"),mpr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),fpr=l(),gn=a("p"),gpr=o("The model class to instantiate is selected based on the "),R4e=a("code"),hpr=o("model_type"),upr=o(` property of the config object (either
passed as an argument or loaded from `),P4e=a("code"),ppr=o("pretrained_model_name_or_path"),_pr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=a("code"),bpr=o("pretrained_model_name_or_path"),vpr=o(":"),Fpr=l(),Ue=a("ul"),JM=a("li"),I4e=a("strong"),Tpr=o("bert"),Mpr=o(" \u2014 "),xY=a("a"),Epr=o("BertForNextSentencePrediction"),Cpr=o(" (BERT model)"),wpr=l(),YM=a("li"),N4e=a("strong"),Apr=o("ernie"),Lpr=o(" \u2014 "),$Y=a("a"),ypr=o("ErnieForNextSentencePrediction"),xpr=o(" (ERNIE model)"),$pr=l(),ZM=a("li"),q4e=a("strong"),kpr=o("fnet"),Spr=o(" \u2014 "),kY=a("a"),Rpr=o("FNetForNextSentencePrediction"),Ppr=o(" (FNet model)"),Bpr=l(),KM=a("li"),j4e=a("strong"),Ipr=o("megatron-bert"),Npr=o(" \u2014 "),SY=a("a"),qpr=o("MegatronBertForNextSentencePrediction"),jpr=o(" (Megatron-BERT model)"),Dpr=l(),eE=a("li"),D4e=a("strong"),Gpr=o("mobilebert"),Opr=o(" \u2014 "),RY=a("a"),Vpr=o("MobileBertForNextSentencePrediction"),Xpr=o(" (MobileBERT model)"),zpr=l(),oE=a("li"),G4e=a("strong"),Qpr=o("nezha"),Wpr=o(" \u2014 "),PY=a("a"),Upr=o("NezhaForNextSentencePrediction"),Hpr=o(" (Nezha model)"),Jpr=l(),rE=a("li"),O4e=a("strong"),Ypr=o("qdqbert"),Zpr=o(" \u2014 "),BY=a("a"),Kpr=o("QDQBertForNextSentencePrediction"),e_r=o(" (QDQBert model)"),o_r=l(),tE=a("p"),r_r=o("The model is set in evaluation mode by default using "),V4e=a("code"),t_r=o("model.eval()"),a_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X4e=a("code"),n_r=o("model.train()"),s_r=l(),F(aE.$$.fragment),vto=l(),tc=a("h2"),nE=a("a"),z4e=a("span"),F(bk.$$.fragment),l_r=l(),Q4e=a("span"),i_r=o("AutoModelForTokenClassification"),Fto=l(),zo=a("div"),F(vk.$$.fragment),d_r=l(),ac=a("p"),c_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),IY=a("a"),m_r=o("from_pretrained()"),f_r=o(" class method or the "),NY=a("a"),g_r=o("from_config()"),h_r=o(` class
method.`),u_r=l(),Fk=a("p"),p_r=o("This class cannot be instantiated directly using "),W4e=a("code"),__r=o("__init__()"),b_r=o(" (throws an error)."),v_r=l(),$t=a("div"),F(Tk.$$.fragment),F_r=l(),U4e=a("p"),T_r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),M_r=l(),nc=a("p"),E_r=o(`Note:
Loading a model from its configuration file does `),H4e=a("strong"),C_r=o("not"),w_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qY=a("a"),A_r=o("from_pretrained()"),L_r=o(" to load the model weights."),y_r=l(),F(sE.$$.fragment),x_r=l(),io=a("div"),F(Mk.$$.fragment),$_r=l(),J4e=a("p"),k_r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),S_r=l(),hn=a("p"),R_r=o("The model class to instantiate is selected based on the "),Y4e=a("code"),P_r=o("model_type"),B_r=o(` property of the config object (either
passed as an argument or loaded from `),Z4e=a("code"),I_r=o("pretrained_model_name_or_path"),N_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=a("code"),q_r=o("pretrained_model_name_or_path"),j_r=o(":"),D_r=l(),U=a("ul"),lE=a("li"),eCe=a("strong"),G_r=o("albert"),O_r=o(" \u2014 "),jY=a("a"),V_r=o("AlbertForTokenClassification"),X_r=o(" (ALBERT model)"),z_r=l(),iE=a("li"),oCe=a("strong"),Q_r=o("bert"),W_r=o(" \u2014 "),DY=a("a"),U_r=o("BertForTokenClassification"),H_r=o(" (BERT model)"),J_r=l(),dE=a("li"),rCe=a("strong"),Y_r=o("big_bird"),Z_r=o(" \u2014 "),GY=a("a"),K_r=o("BigBirdForTokenClassification"),e1r=o(" (BigBird model)"),o1r=l(),cE=a("li"),tCe=a("strong"),r1r=o("bloom"),t1r=o(" \u2014 "),OY=a("a"),a1r=o("BloomForTokenClassification"),n1r=o(" (BLOOM model)"),s1r=l(),mE=a("li"),aCe=a("strong"),l1r=o("camembert"),i1r=o(" \u2014 "),VY=a("a"),d1r=o("CamembertForTokenClassification"),c1r=o(" (CamemBERT model)"),m1r=l(),fE=a("li"),nCe=a("strong"),f1r=o("canine"),g1r=o(" \u2014 "),XY=a("a"),h1r=o("CanineForTokenClassification"),u1r=o(" (CANINE model)"),p1r=l(),gE=a("li"),sCe=a("strong"),_1r=o("convbert"),b1r=o(" \u2014 "),zY=a("a"),v1r=o("ConvBertForTokenClassification"),F1r=o(" (ConvBERT model)"),T1r=l(),hE=a("li"),lCe=a("strong"),M1r=o("data2vec-text"),E1r=o(" \u2014 "),QY=a("a"),C1r=o("Data2VecTextForTokenClassification"),w1r=o(" (Data2VecText model)"),A1r=l(),uE=a("li"),iCe=a("strong"),L1r=o("deberta"),y1r=o(" \u2014 "),WY=a("a"),x1r=o("DebertaForTokenClassification"),$1r=o(" (DeBERTa model)"),k1r=l(),pE=a("li"),dCe=a("strong"),S1r=o("deberta-v2"),R1r=o(" \u2014 "),UY=a("a"),P1r=o("DebertaV2ForTokenClassification"),B1r=o(" (DeBERTa-v2 model)"),I1r=l(),_E=a("li"),cCe=a("strong"),N1r=o("distilbert"),q1r=o(" \u2014 "),HY=a("a"),j1r=o("DistilBertForTokenClassification"),D1r=o(" (DistilBERT model)"),G1r=l(),bE=a("li"),mCe=a("strong"),O1r=o("electra"),V1r=o(" \u2014 "),JY=a("a"),X1r=o("ElectraForTokenClassification"),z1r=o(" (ELECTRA model)"),Q1r=l(),vE=a("li"),fCe=a("strong"),W1r=o("ernie"),U1r=o(" \u2014 "),YY=a("a"),H1r=o("ErnieForTokenClassification"),J1r=o(" (ERNIE model)"),Y1r=l(),FE=a("li"),gCe=a("strong"),Z1r=o("esm"),K1r=o(" \u2014 "),ZY=a("a"),e2r=o("EsmForTokenClassification"),o2r=o(" (ESM model)"),r2r=l(),TE=a("li"),hCe=a("strong"),t2r=o("flaubert"),a2r=o(" \u2014 "),KY=a("a"),n2r=o("FlaubertForTokenClassification"),s2r=o(" (FlauBERT model)"),l2r=l(),ME=a("li"),uCe=a("strong"),i2r=o("fnet"),d2r=o(" \u2014 "),eZ=a("a"),c2r=o("FNetForTokenClassification"),m2r=o(" (FNet model)"),f2r=l(),EE=a("li"),pCe=a("strong"),g2r=o("funnel"),h2r=o(" \u2014 "),oZ=a("a"),u2r=o("FunnelForTokenClassification"),p2r=o(" (Funnel Transformer model)"),_2r=l(),CE=a("li"),_Ce=a("strong"),b2r=o("gpt2"),v2r=o(" \u2014 "),rZ=a("a"),F2r=o("GPT2ForTokenClassification"),T2r=o(" (OpenAI GPT-2 model)"),M2r=l(),wE=a("li"),bCe=a("strong"),E2r=o("ibert"),C2r=o(" \u2014 "),tZ=a("a"),w2r=o("IBertForTokenClassification"),A2r=o(" (I-BERT model)"),L2r=l(),AE=a("li"),vCe=a("strong"),y2r=o("layoutlm"),x2r=o(" \u2014 "),aZ=a("a"),$2r=o("LayoutLMForTokenClassification"),k2r=o(" (LayoutLM model)"),S2r=l(),LE=a("li"),FCe=a("strong"),R2r=o("layoutlmv2"),P2r=o(" \u2014 "),nZ=a("a"),B2r=o("LayoutLMv2ForTokenClassification"),I2r=o(" (LayoutLMv2 model)"),N2r=l(),yE=a("li"),TCe=a("strong"),q2r=o("layoutlmv3"),j2r=o(" \u2014 "),sZ=a("a"),D2r=o("LayoutLMv3ForTokenClassification"),G2r=o(" (LayoutLMv3 model)"),O2r=l(),xE=a("li"),MCe=a("strong"),V2r=o("lilt"),X2r=o(" \u2014 "),lZ=a("a"),z2r=o("LiltForTokenClassification"),Q2r=o(" (LiLT model)"),W2r=l(),$E=a("li"),ECe=a("strong"),U2r=o("longformer"),H2r=o(" \u2014 "),iZ=a("a"),J2r=o("LongformerForTokenClassification"),Y2r=o(" (Longformer model)"),Z2r=l(),kE=a("li"),CCe=a("strong"),K2r=o("luke"),ebr=o(" \u2014 "),dZ=a("a"),obr=o("LukeForTokenClassification"),rbr=o(" (LUKE model)"),tbr=l(),SE=a("li"),wCe=a("strong"),abr=o("markuplm"),nbr=o(" \u2014 "),cZ=a("a"),sbr=o("MarkupLMForTokenClassification"),lbr=o(" (MarkupLM model)"),ibr=l(),RE=a("li"),ACe=a("strong"),dbr=o("megatron-bert"),cbr=o(" \u2014 "),mZ=a("a"),mbr=o("MegatronBertForTokenClassification"),fbr=o(" (Megatron-BERT model)"),gbr=l(),PE=a("li"),LCe=a("strong"),hbr=o("mobilebert"),ubr=o(" \u2014 "),fZ=a("a"),pbr=o("MobileBertForTokenClassification"),_br=o(" (MobileBERT model)"),bbr=l(),BE=a("li"),yCe=a("strong"),vbr=o("mpnet"),Fbr=o(" \u2014 "),gZ=a("a"),Tbr=o("MPNetForTokenClassification"),Mbr=o(" (MPNet model)"),Ebr=l(),IE=a("li"),xCe=a("strong"),Cbr=o("nezha"),wbr=o(" \u2014 "),hZ=a("a"),Abr=o("NezhaForTokenClassification"),Lbr=o(" (Nezha model)"),ybr=l(),NE=a("li"),$Ce=a("strong"),xbr=o("nystromformer"),$br=o(" \u2014 "),uZ=a("a"),kbr=o("NystromformerForTokenClassification"),Sbr=o(" (Nystr\xF6mformer model)"),Rbr=l(),qE=a("li"),kCe=a("strong"),Pbr=o("qdqbert"),Bbr=o(" \u2014 "),pZ=a("a"),Ibr=o("QDQBertForTokenClassification"),Nbr=o(" (QDQBert model)"),qbr=l(),jE=a("li"),SCe=a("strong"),jbr=o("rembert"),Dbr=o(" \u2014 "),_Z=a("a"),Gbr=o("RemBertForTokenClassification"),Obr=o(" (RemBERT model)"),Vbr=l(),DE=a("li"),RCe=a("strong"),Xbr=o("roberta"),zbr=o(" \u2014 "),bZ=a("a"),Qbr=o("RobertaForTokenClassification"),Wbr=o(" (RoBERTa model)"),Ubr=l(),GE=a("li"),PCe=a("strong"),Hbr=o("roformer"),Jbr=o(" \u2014 "),vZ=a("a"),Ybr=o("RoFormerForTokenClassification"),Zbr=o(" (RoFormer model)"),Kbr=l(),OE=a("li"),BCe=a("strong"),evr=o("squeezebert"),ovr=o(" \u2014 "),FZ=a("a"),rvr=o("SqueezeBertForTokenClassification"),tvr=o(" (SqueezeBERT model)"),avr=l(),VE=a("li"),ICe=a("strong"),nvr=o("xlm"),svr=o(" \u2014 "),TZ=a("a"),lvr=o("XLMForTokenClassification"),ivr=o(" (XLM model)"),dvr=l(),XE=a("li"),NCe=a("strong"),cvr=o("xlm-roberta"),mvr=o(" \u2014 "),MZ=a("a"),fvr=o("XLMRobertaForTokenClassification"),gvr=o(" (XLM-RoBERTa model)"),hvr=l(),zE=a("li"),qCe=a("strong"),uvr=o("xlm-roberta-xl"),pvr=o(" \u2014 "),EZ=a("a"),_vr=o("XLMRobertaXLForTokenClassification"),bvr=o(" (XLM-RoBERTa-XL model)"),vvr=l(),QE=a("li"),jCe=a("strong"),Fvr=o("xlnet"),Tvr=o(" \u2014 "),CZ=a("a"),Mvr=o("XLNetForTokenClassification"),Evr=o(" (XLNet model)"),Cvr=l(),WE=a("li"),DCe=a("strong"),wvr=o("yoso"),Avr=o(" \u2014 "),wZ=a("a"),Lvr=o("YosoForTokenClassification"),yvr=o(" (YOSO model)"),xvr=l(),UE=a("p"),$vr=o("The model is set in evaluation mode by default using "),GCe=a("code"),kvr=o("model.eval()"),Svr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),OCe=a("code"),Rvr=o("model.train()"),Pvr=l(),F(HE.$$.fragment),Tto=l(),sc=a("h2"),JE=a("a"),VCe=a("span"),F(Ek.$$.fragment),Bvr=l(),XCe=a("span"),Ivr=o("AutoModelForQuestionAnswering"),Mto=l(),Qo=a("div"),F(Ck.$$.fragment),Nvr=l(),lc=a("p"),qvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),AZ=a("a"),jvr=o("from_pretrained()"),Dvr=o(" class method or the "),LZ=a("a"),Gvr=o("from_config()"),Ovr=o(` class
method.`),Vvr=l(),wk=a("p"),Xvr=o("This class cannot be instantiated directly using "),zCe=a("code"),zvr=o("__init__()"),Qvr=o(" (throws an error)."),Wvr=l(),kt=a("div"),F(Ak.$$.fragment),Uvr=l(),QCe=a("p"),Hvr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Jvr=l(),ic=a("p"),Yvr=o(`Note:
Loading a model from its configuration file does `),WCe=a("strong"),Zvr=o("not"),Kvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yZ=a("a"),eFr=o("from_pretrained()"),oFr=o(" to load the model weights."),rFr=l(),F(YE.$$.fragment),tFr=l(),co=a("div"),F(Lk.$$.fragment),aFr=l(),UCe=a("p"),nFr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),sFr=l(),un=a("p"),lFr=o("The model class to instantiate is selected based on the "),HCe=a("code"),iFr=o("model_type"),dFr=o(` property of the config object (either
passed as an argument or loaded from `),JCe=a("code"),cFr=o("pretrained_model_name_or_path"),mFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YCe=a("code"),fFr=o("pretrained_model_name_or_path"),gFr=o(":"),hFr=l(),O=a("ul"),ZE=a("li"),ZCe=a("strong"),uFr=o("albert"),pFr=o(" \u2014 "),xZ=a("a"),_Fr=o("AlbertForQuestionAnswering"),bFr=o(" (ALBERT model)"),vFr=l(),KE=a("li"),KCe=a("strong"),FFr=o("bart"),TFr=o(" \u2014 "),$Z=a("a"),MFr=o("BartForQuestionAnswering"),EFr=o(" (BART model)"),CFr=l(),e4=a("li"),e3e=a("strong"),wFr=o("bert"),AFr=o(" \u2014 "),kZ=a("a"),LFr=o("BertForQuestionAnswering"),yFr=o(" (BERT model)"),xFr=l(),o4=a("li"),o3e=a("strong"),$Fr=o("big_bird"),kFr=o(" \u2014 "),SZ=a("a"),SFr=o("BigBirdForQuestionAnswering"),RFr=o(" (BigBird model)"),PFr=l(),r4=a("li"),r3e=a("strong"),BFr=o("bigbird_pegasus"),IFr=o(" \u2014 "),RZ=a("a"),NFr=o("BigBirdPegasusForQuestionAnswering"),qFr=o(" (BigBird-Pegasus model)"),jFr=l(),t4=a("li"),t3e=a("strong"),DFr=o("bloom"),GFr=o(" \u2014 "),PZ=a("a"),OFr=o("BloomForQuestionAnswering"),VFr=o(" (BLOOM model)"),XFr=l(),a4=a("li"),a3e=a("strong"),zFr=o("camembert"),QFr=o(" \u2014 "),BZ=a("a"),WFr=o("CamembertForQuestionAnswering"),UFr=o(" (CamemBERT model)"),HFr=l(),n4=a("li"),n3e=a("strong"),JFr=o("canine"),YFr=o(" \u2014 "),IZ=a("a"),ZFr=o("CanineForQuestionAnswering"),KFr=o(" (CANINE model)"),eTr=l(),s4=a("li"),s3e=a("strong"),oTr=o("convbert"),rTr=o(" \u2014 "),NZ=a("a"),tTr=o("ConvBertForQuestionAnswering"),aTr=o(" (ConvBERT model)"),nTr=l(),l4=a("li"),l3e=a("strong"),sTr=o("data2vec-text"),lTr=o(" \u2014 "),qZ=a("a"),iTr=o("Data2VecTextForQuestionAnswering"),dTr=o(" (Data2VecText model)"),cTr=l(),i4=a("li"),i3e=a("strong"),mTr=o("deberta"),fTr=o(" \u2014 "),jZ=a("a"),gTr=o("DebertaForQuestionAnswering"),hTr=o(" (DeBERTa model)"),uTr=l(),d4=a("li"),d3e=a("strong"),pTr=o("deberta-v2"),_Tr=o(" \u2014 "),DZ=a("a"),bTr=o("DebertaV2ForQuestionAnswering"),vTr=o(" (DeBERTa-v2 model)"),FTr=l(),c4=a("li"),c3e=a("strong"),TTr=o("distilbert"),MTr=o(" \u2014 "),GZ=a("a"),ETr=o("DistilBertForQuestionAnswering"),CTr=o(" (DistilBERT model)"),wTr=l(),m4=a("li"),m3e=a("strong"),ATr=o("electra"),LTr=o(" \u2014 "),OZ=a("a"),yTr=o("ElectraForQuestionAnswering"),xTr=o(" (ELECTRA model)"),$Tr=l(),f4=a("li"),f3e=a("strong"),kTr=o("ernie"),STr=o(" \u2014 "),VZ=a("a"),RTr=o("ErnieForQuestionAnswering"),PTr=o(" (ERNIE model)"),BTr=l(),g4=a("li"),g3e=a("strong"),ITr=o("flaubert"),NTr=o(" \u2014 "),XZ=a("a"),qTr=o("FlaubertForQuestionAnsweringSimple"),jTr=o(" (FlauBERT model)"),DTr=l(),h4=a("li"),h3e=a("strong"),GTr=o("fnet"),OTr=o(" \u2014 "),zZ=a("a"),VTr=o("FNetForQuestionAnswering"),XTr=o(" (FNet model)"),zTr=l(),u4=a("li"),u3e=a("strong"),QTr=o("funnel"),WTr=o(" \u2014 "),QZ=a("a"),UTr=o("FunnelForQuestionAnswering"),HTr=o(" (Funnel Transformer model)"),JTr=l(),p4=a("li"),p3e=a("strong"),YTr=o("gptj"),ZTr=o(" \u2014 "),WZ=a("a"),KTr=o("GPTJForQuestionAnswering"),eMr=o(" (GPT-J model)"),oMr=l(),_4=a("li"),_3e=a("strong"),rMr=o("ibert"),tMr=o(" \u2014 "),UZ=a("a"),aMr=o("IBertForQuestionAnswering"),nMr=o(" (I-BERT model)"),sMr=l(),b4=a("li"),b3e=a("strong"),lMr=o("layoutlmv2"),iMr=o(" \u2014 "),HZ=a("a"),dMr=o("LayoutLMv2ForQuestionAnswering"),cMr=o(" (LayoutLMv2 model)"),mMr=l(),v4=a("li"),v3e=a("strong"),fMr=o("layoutlmv3"),gMr=o(" \u2014 "),JZ=a("a"),hMr=o("LayoutLMv3ForQuestionAnswering"),uMr=o(" (LayoutLMv3 model)"),pMr=l(),F4=a("li"),F3e=a("strong"),_Mr=o("led"),bMr=o(" \u2014 "),YZ=a("a"),vMr=o("LEDForQuestionAnswering"),FMr=o(" (LED model)"),TMr=l(),T4=a("li"),T3e=a("strong"),MMr=o("lilt"),EMr=o(" \u2014 "),ZZ=a("a"),CMr=o("LiltForQuestionAnswering"),wMr=o(" (LiLT model)"),AMr=l(),M4=a("li"),M3e=a("strong"),LMr=o("longformer"),yMr=o(" \u2014 "),KZ=a("a"),xMr=o("LongformerForQuestionAnswering"),$Mr=o(" (Longformer model)"),kMr=l(),E4=a("li"),E3e=a("strong"),SMr=o("luke"),RMr=o(" \u2014 "),eK=a("a"),PMr=o("LukeForQuestionAnswering"),BMr=o(" (LUKE model)"),IMr=l(),C4=a("li"),C3e=a("strong"),NMr=o("lxmert"),qMr=o(" \u2014 "),oK=a("a"),jMr=o("LxmertForQuestionAnswering"),DMr=o(" (LXMERT model)"),GMr=l(),w4=a("li"),w3e=a("strong"),OMr=o("markuplm"),VMr=o(" \u2014 "),rK=a("a"),XMr=o("MarkupLMForQuestionAnswering"),zMr=o(" (MarkupLM model)"),QMr=l(),A4=a("li"),A3e=a("strong"),WMr=o("mbart"),UMr=o(" \u2014 "),tK=a("a"),HMr=o("MBartForQuestionAnswering"),JMr=o(" (mBART model)"),YMr=l(),L4=a("li"),L3e=a("strong"),ZMr=o("megatron-bert"),KMr=o(" \u2014 "),aK=a("a"),eEr=o("MegatronBertForQuestionAnswering"),oEr=o(" (Megatron-BERT model)"),rEr=l(),y4=a("li"),y3e=a("strong"),tEr=o("mobilebert"),aEr=o(" \u2014 "),nK=a("a"),nEr=o("MobileBertForQuestionAnswering"),sEr=o(" (MobileBERT model)"),lEr=l(),x4=a("li"),x3e=a("strong"),iEr=o("mpnet"),dEr=o(" \u2014 "),sK=a("a"),cEr=o("MPNetForQuestionAnswering"),mEr=o(" (MPNet model)"),fEr=l(),$4=a("li"),$3e=a("strong"),gEr=o("mvp"),hEr=o(" \u2014 "),lK=a("a"),uEr=o("MvpForQuestionAnswering"),pEr=o(" (MVP model)"),_Er=l(),k4=a("li"),k3e=a("strong"),bEr=o("nezha"),vEr=o(" \u2014 "),iK=a("a"),FEr=o("NezhaForQuestionAnswering"),TEr=o(" (Nezha model)"),MEr=l(),S4=a("li"),S3e=a("strong"),EEr=o("nystromformer"),CEr=o(" \u2014 "),dK=a("a"),wEr=o("NystromformerForQuestionAnswering"),AEr=o(" (Nystr\xF6mformer model)"),LEr=l(),R4=a("li"),R3e=a("strong"),yEr=o("opt"),xEr=o(" \u2014 "),cK=a("a"),$Er=o("OPTForQuestionAnswering"),kEr=o(" (OPT model)"),SEr=l(),P4=a("li"),P3e=a("strong"),REr=o("qdqbert"),PEr=o(" \u2014 "),mK=a("a"),BEr=o("QDQBertForQuestionAnswering"),IEr=o(" (QDQBert model)"),NEr=l(),B4=a("li"),B3e=a("strong"),qEr=o("reformer"),jEr=o(" \u2014 "),fK=a("a"),DEr=o("ReformerForQuestionAnswering"),GEr=o(" (Reformer model)"),OEr=l(),I4=a("li"),I3e=a("strong"),VEr=o("rembert"),XEr=o(" \u2014 "),gK=a("a"),zEr=o("RemBertForQuestionAnswering"),QEr=o(" (RemBERT model)"),WEr=l(),N4=a("li"),N3e=a("strong"),UEr=o("roberta"),HEr=o(" \u2014 "),hK=a("a"),JEr=o("RobertaForQuestionAnswering"),YEr=o(" (RoBERTa model)"),ZEr=l(),q4=a("li"),q3e=a("strong"),KEr=o("roformer"),e4r=o(" \u2014 "),uK=a("a"),o4r=o("RoFormerForQuestionAnswering"),r4r=o(" (RoFormer model)"),t4r=l(),j4=a("li"),j3e=a("strong"),a4r=o("splinter"),n4r=o(" \u2014 "),pK=a("a"),s4r=o("SplinterForQuestionAnswering"),l4r=o(" (Splinter model)"),i4r=l(),D4=a("li"),D3e=a("strong"),d4r=o("squeezebert"),c4r=o(" \u2014 "),_K=a("a"),m4r=o("SqueezeBertForQuestionAnswering"),f4r=o(" (SqueezeBERT model)"),g4r=l(),G4=a("li"),G3e=a("strong"),h4r=o("xlm"),u4r=o(" \u2014 "),bK=a("a"),p4r=o("XLMForQuestionAnsweringSimple"),_4r=o(" (XLM model)"),b4r=l(),O4=a("li"),O3e=a("strong"),v4r=o("xlm-roberta"),F4r=o(" \u2014 "),vK=a("a"),T4r=o("XLMRobertaForQuestionAnswering"),M4r=o(" (XLM-RoBERTa model)"),E4r=l(),V4=a("li"),V3e=a("strong"),C4r=o("xlm-roberta-xl"),w4r=o(" \u2014 "),FK=a("a"),A4r=o("XLMRobertaXLForQuestionAnswering"),L4r=o(" (XLM-RoBERTa-XL model)"),y4r=l(),X4=a("li"),X3e=a("strong"),x4r=o("xlnet"),$4r=o(" \u2014 "),TK=a("a"),k4r=o("XLNetForQuestionAnsweringSimple"),S4r=o(" (XLNet model)"),R4r=l(),z4=a("li"),z3e=a("strong"),P4r=o("yoso"),B4r=o(" \u2014 "),MK=a("a"),I4r=o("YosoForQuestionAnswering"),N4r=o(" (YOSO model)"),q4r=l(),Q4=a("p"),j4r=o("The model is set in evaluation mode by default using "),Q3e=a("code"),D4r=o("model.eval()"),G4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W3e=a("code"),O4r=o("model.train()"),V4r=l(),F(W4.$$.fragment),Eto=l(),dc=a("h2"),U4=a("a"),U3e=a("span"),F(yk.$$.fragment),X4r=l(),H3e=a("span"),z4r=o("AutoModelForTableQuestionAnswering"),Cto=l(),Wo=a("div"),F(xk.$$.fragment),Q4r=l(),cc=a("p"),W4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),EK=a("a"),U4r=o("from_pretrained()"),H4r=o(" class method or the "),CK=a("a"),J4r=o("from_config()"),Y4r=o(` class
method.`),Z4r=l(),$k=a("p"),K4r=o("This class cannot be instantiated directly using "),J3e=a("code"),eCr=o("__init__()"),oCr=o(" (throws an error)."),rCr=l(),St=a("div"),F(kk.$$.fragment),tCr=l(),Y3e=a("p"),aCr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),nCr=l(),mc=a("p"),sCr=o(`Note:
Loading a model from its configuration file does `),Z3e=a("strong"),lCr=o("not"),iCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=a("a"),dCr=o("from_pretrained()"),cCr=o(" to load the model weights."),mCr=l(),F(H4.$$.fragment),fCr=l(),mo=a("div"),F(Sk.$$.fragment),gCr=l(),K3e=a("p"),hCr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),uCr=l(),pn=a("p"),pCr=o("The model class to instantiate is selected based on the "),e5e=a("code"),_Cr=o("model_type"),bCr=o(` property of the config object (either
passed as an argument or loaded from `),o5e=a("code"),vCr=o("pretrained_model_name_or_path"),FCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r5e=a("code"),TCr=o("pretrained_model_name_or_path"),MCr=o(":"),ECr=l(),t5e=a("ul"),J4=a("li"),a5e=a("strong"),CCr=o("tapas"),wCr=o(" \u2014 "),AK=a("a"),ACr=o("TapasForQuestionAnswering"),LCr=o(" (TAPAS model)"),yCr=l(),Y4=a("p"),xCr=o("The model is set in evaluation mode by default using "),n5e=a("code"),$Cr=o("model.eval()"),kCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s5e=a("code"),SCr=o("model.train()"),RCr=l(),F(Z4.$$.fragment),wto=l(),fc=a("h2"),K4=a("a"),l5e=a("span"),F(Rk.$$.fragment),PCr=l(),i5e=a("span"),BCr=o("AutoModelForDocumentQuestionAnswering"),Ato=l(),Uo=a("div"),F(Pk.$$.fragment),ICr=l(),gc=a("p"),NCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),LK=a("a"),qCr=o("from_pretrained()"),jCr=o(" class method or the "),yK=a("a"),DCr=o("from_config()"),GCr=o(` class
method.`),OCr=l(),Bk=a("p"),VCr=o("This class cannot be instantiated directly using "),d5e=a("code"),XCr=o("__init__()"),zCr=o(" (throws an error)."),QCr=l(),Rt=a("div"),F(Ik.$$.fragment),WCr=l(),c5e=a("p"),UCr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),HCr=l(),hc=a("p"),JCr=o(`Note:
Loading a model from its configuration file does `),m5e=a("strong"),YCr=o("not"),ZCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=a("a"),KCr=o("from_pretrained()"),e3r=o(" to load the model weights."),o3r=l(),F(eC.$$.fragment),r3r=l(),fo=a("div"),F(Nk.$$.fragment),t3r=l(),f5e=a("p"),a3r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),n3r=l(),_n=a("p"),s3r=o("The model class to instantiate is selected based on the "),g5e=a("code"),l3r=o("model_type"),i3r=o(` property of the config object (either
passed as an argument or loaded from `),h5e=a("code"),d3r=o("pretrained_model_name_or_path"),c3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u5e=a("code"),m3r=o("pretrained_model_name_or_path"),f3r=o(":"),g3r=l(),uc=a("ul"),oC=a("li"),p5e=a("strong"),h3r=o("layoutlm"),u3r=o(" \u2014 "),$K=a("a"),p3r=o("LayoutLMForQuestionAnswering"),_3r=o(" (LayoutLM model)"),b3r=l(),rC=a("li"),_5e=a("strong"),v3r=o("layoutlmv2"),F3r=o(" \u2014 "),kK=a("a"),T3r=o("LayoutLMv2ForQuestionAnswering"),M3r=o(" (LayoutLMv2 model)"),E3r=l(),tC=a("li"),b5e=a("strong"),C3r=o("layoutlmv3"),w3r=o(" \u2014 "),SK=a("a"),A3r=o("LayoutLMv3ForQuestionAnswering"),L3r=o(" (LayoutLMv3 model)"),y3r=l(),aC=a("p"),x3r=o("The model is set in evaluation mode by default using "),v5e=a("code"),$3r=o("model.eval()"),k3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=a("code"),S3r=o("model.train()"),R3r=l(),F(nC.$$.fragment),Lto=l(),pc=a("h2"),sC=a("a"),T5e=a("span"),F(qk.$$.fragment),P3r=l(),M5e=a("span"),B3r=o("AutoModelForImageClassification"),yto=l(),Ho=a("div"),F(jk.$$.fragment),I3r=l(),_c=a("p"),N3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),RK=a("a"),q3r=o("from_pretrained()"),j3r=o(" class method or the "),PK=a("a"),D3r=o("from_config()"),G3r=o(` class
method.`),O3r=l(),Dk=a("p"),V3r=o("This class cannot be instantiated directly using "),E5e=a("code"),X3r=o("__init__()"),z3r=o(" (throws an error)."),Q3r=l(),Pt=a("div"),F(Gk.$$.fragment),W3r=l(),C5e=a("p"),U3r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),H3r=l(),bc=a("p"),J3r=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),Y3r=o("not"),Z3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BK=a("a"),K3r=o("from_pretrained()"),e5r=o(" to load the model weights."),o5r=l(),F(lC.$$.fragment),r5r=l(),go=a("div"),F(Ok.$$.fragment),t5r=l(),A5e=a("p"),a5r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),n5r=l(),bn=a("p"),s5r=o("The model class to instantiate is selected based on the "),L5e=a("code"),l5r=o("model_type"),i5r=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),d5r=o("pretrained_model_name_or_path"),c5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),m5r=o("pretrained_model_name_or_path"),f5r=o(":"),g5r=l(),be=a("ul"),iC=a("li"),$5e=a("strong"),h5r=o("beit"),u5r=o(" \u2014 "),IK=a("a"),p5r=o("BeitForImageClassification"),_5r=o(" (BEiT model)"),b5r=l(),dC=a("li"),k5e=a("strong"),v5r=o("convnext"),F5r=o(" \u2014 "),NK=a("a"),T5r=o("ConvNextForImageClassification"),M5r=o(" (ConvNeXT model)"),E5r=l(),cC=a("li"),S5e=a("strong"),C5r=o("cvt"),w5r=o(" \u2014 "),qK=a("a"),A5r=o("CvtForImageClassification"),L5r=o(" (CvT model)"),y5r=l(),mC=a("li"),R5e=a("strong"),x5r=o("data2vec-vision"),$5r=o(" \u2014 "),jK=a("a"),k5r=o("Data2VecVisionForImageClassification"),S5r=o(" (Data2VecVision model)"),R5r=l(),xl=a("li"),P5e=a("strong"),P5r=o("deit"),B5r=o(" \u2014 "),DK=a("a"),I5r=o("DeiTForImageClassification"),N5r=o(" or "),GK=a("a"),q5r=o("DeiTForImageClassificationWithTeacher"),j5r=o(" (DeiT model)"),D5r=l(),fC=a("li"),B5e=a("strong"),G5r=o("imagegpt"),O5r=o(" \u2014 "),OK=a("a"),V5r=o("ImageGPTForImageClassification"),X5r=o(" (ImageGPT model)"),z5r=l(),$l=a("li"),I5e=a("strong"),Q5r=o("levit"),W5r=o(" \u2014 "),VK=a("a"),U5r=o("LevitForImageClassification"),H5r=o(" or "),XK=a("a"),J5r=o("LevitForImageClassificationWithTeacher"),Y5r=o(" (LeViT model)"),Z5r=l(),gC=a("li"),N5e=a("strong"),K5r=o("mobilevit"),e0r=o(" \u2014 "),zK=a("a"),o0r=o("MobileViTForImageClassification"),r0r=o(" (MobileViT model)"),t0r=l(),Bt=a("li"),q5e=a("strong"),a0r=o("perceiver"),n0r=o(" \u2014 "),QK=a("a"),s0r=o("PerceiverForImageClassificationLearned"),l0r=o(" or "),WK=a("a"),i0r=o("PerceiverForImageClassificationFourier"),d0r=o(" or "),UK=a("a"),c0r=o("PerceiverForImageClassificationConvProcessing"),m0r=o(" (Perceiver model)"),f0r=l(),hC=a("li"),j5e=a("strong"),g0r=o("poolformer"),h0r=o(" \u2014 "),HK=a("a"),u0r=o("PoolFormerForImageClassification"),p0r=o(" (PoolFormer model)"),_0r=l(),uC=a("li"),D5e=a("strong"),b0r=o("regnet"),v0r=o(" \u2014 "),JK=a("a"),F0r=o("RegNetForImageClassification"),T0r=o(" (RegNet model)"),M0r=l(),pC=a("li"),G5e=a("strong"),E0r=o("resnet"),C0r=o(" \u2014 "),YK=a("a"),w0r=o("ResNetForImageClassification"),A0r=o(" (ResNet model)"),L0r=l(),_C=a("li"),O5e=a("strong"),y0r=o("segformer"),x0r=o(" \u2014 "),ZK=a("a"),$0r=o("SegformerForImageClassification"),k0r=o(" (SegFormer model)"),S0r=l(),bC=a("li"),V5e=a("strong"),R0r=o("swin"),P0r=o(" \u2014 "),KK=a("a"),B0r=o("SwinForImageClassification"),I0r=o(" (Swin Transformer model)"),N0r=l(),vC=a("li"),X5e=a("strong"),q0r=o("swinv2"),j0r=o(" \u2014 "),eee=a("a"),D0r=o("Swinv2ForImageClassification"),G0r=o(" (Swin Transformer V2 model)"),O0r=l(),FC=a("li"),z5e=a("strong"),V0r=o("van"),X0r=o(" \u2014 "),oee=a("a"),z0r=o("VanForImageClassification"),Q0r=o(" (VAN model)"),W0r=l(),TC=a("li"),Q5e=a("strong"),U0r=o("vit"),H0r=o(" \u2014 "),ree=a("a"),J0r=o("ViTForImageClassification"),Y0r=o(" (ViT model)"),Z0r=l(),MC=a("li"),W5e=a("strong"),K0r=o("vit_msn"),ewr=o(" \u2014 "),tee=a("a"),owr=o("ViTMSNForImageClassification"),rwr=o(" (ViTMSN model)"),twr=l(),EC=a("p"),awr=o("The model is set in evaluation mode by default using "),U5e=a("code"),nwr=o("model.eval()"),swr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H5e=a("code"),lwr=o("model.train()"),iwr=l(),F(CC.$$.fragment),xto=l(),vc=a("h2"),wC=a("a"),J5e=a("span"),F(Vk.$$.fragment),dwr=l(),Y5e=a("span"),cwr=o("AutoModelForVideoClassification"),$to=l(),Jo=a("div"),F(Xk.$$.fragment),mwr=l(),Fc=a("p"),fwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),aee=a("a"),gwr=o("from_pretrained()"),hwr=o(" class method or the "),nee=a("a"),uwr=o("from_config()"),pwr=o(` class
method.`),_wr=l(),zk=a("p"),bwr=o("This class cannot be instantiated directly using "),Z5e=a("code"),vwr=o("__init__()"),Fwr=o(" (throws an error)."),Twr=l(),It=a("div"),F(Qk.$$.fragment),Mwr=l(),K5e=a("p"),Ewr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),Cwr=l(),Tc=a("p"),wwr=o(`Note:
Loading a model from its configuration file does `),e0e=a("strong"),Awr=o("not"),Lwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),see=a("a"),ywr=o("from_pretrained()"),xwr=o(" to load the model weights."),$wr=l(),F(AC.$$.fragment),kwr=l(),ho=a("div"),F(Wk.$$.fragment),Swr=l(),o0e=a("p"),Rwr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),Pwr=l(),vn=a("p"),Bwr=o("The model class to instantiate is selected based on the "),r0e=a("code"),Iwr=o("model_type"),Nwr=o(` property of the config object (either
passed as an argument or loaded from `),t0e=a("code"),qwr=o("pretrained_model_name_or_path"),jwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=a("code"),Dwr=o("pretrained_model_name_or_path"),Gwr=o(":"),Owr=l(),n0e=a("ul"),LC=a("li"),s0e=a("strong"),Vwr=o("videomae"),Xwr=o(" \u2014 "),lee=a("a"),zwr=o("VideoMAEForVideoClassification"),Qwr=o(" (VideoMAE model)"),Wwr=l(),yC=a("p"),Uwr=o("The model is set in evaluation mode by default using "),l0e=a("code"),Hwr=o("model.eval()"),Jwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),i0e=a("code"),Ywr=o("model.train()"),Zwr=l(),F(xC.$$.fragment),kto=l(),Mc=a("h2"),$C=a("a"),d0e=a("span"),F(Uk.$$.fragment),Kwr=l(),c0e=a("span"),eAr=o("AutoModelForVision2Seq"),Sto=l(),Yo=a("div"),F(Hk.$$.fragment),oAr=l(),Ec=a("p"),rAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),iee=a("a"),tAr=o("from_pretrained()"),aAr=o(" class method or the "),dee=a("a"),nAr=o("from_config()"),sAr=o(` class
method.`),lAr=l(),Jk=a("p"),iAr=o("This class cannot be instantiated directly using "),m0e=a("code"),dAr=o("__init__()"),cAr=o(" (throws an error)."),mAr=l(),Nt=a("div"),F(Yk.$$.fragment),fAr=l(),f0e=a("p"),gAr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),hAr=l(),Cc=a("p"),uAr=o(`Note:
Loading a model from its configuration file does `),g0e=a("strong"),pAr=o("not"),_Ar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cee=a("a"),bAr=o("from_pretrained()"),vAr=o(" to load the model weights."),FAr=l(),F(kC.$$.fragment),TAr=l(),uo=a("div"),F(Zk.$$.fragment),MAr=l(),h0e=a("p"),EAr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CAr=l(),Fn=a("p"),wAr=o("The model class to instantiate is selected based on the "),u0e=a("code"),AAr=o("model_type"),LAr=o(` property of the config object (either
passed as an argument or loaded from `),p0e=a("code"),yAr=o("pretrained_model_name_or_path"),xAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=a("code"),$Ar=o("pretrained_model_name_or_path"),kAr=o(":"),SAr=l(),b0e=a("ul"),SC=a("li"),v0e=a("strong"),RAr=o("vision-encoder-decoder"),PAr=o(" \u2014 "),mee=a("a"),BAr=o("VisionEncoderDecoderModel"),IAr=o(" (Vision Encoder decoder model)"),NAr=l(),RC=a("p"),qAr=o("The model is set in evaluation mode by default using "),F0e=a("code"),jAr=o("model.eval()"),DAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T0e=a("code"),GAr=o("model.train()"),OAr=l(),F(PC.$$.fragment),Rto=l(),wc=a("h2"),BC=a("a"),M0e=a("span"),F(Kk.$$.fragment),VAr=l(),E0e=a("span"),XAr=o("AutoModelForVisualQuestionAnswering"),Pto=l(),Zo=a("div"),F(eS.$$.fragment),zAr=l(),Ac=a("p"),QAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),fee=a("a"),WAr=o("from_pretrained()"),UAr=o(" class method or the "),gee=a("a"),HAr=o("from_config()"),JAr=o(` class
method.`),YAr=l(),oS=a("p"),ZAr=o("This class cannot be instantiated directly using "),C0e=a("code"),KAr=o("__init__()"),e6r=o(" (throws an error)."),o6r=l(),qt=a("div"),F(rS.$$.fragment),r6r=l(),w0e=a("p"),t6r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),a6r=l(),Lc=a("p"),n6r=o(`Note:
Loading a model from its configuration file does `),A0e=a("strong"),s6r=o("not"),l6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hee=a("a"),i6r=o("from_pretrained()"),d6r=o(" to load the model weights."),c6r=l(),F(IC.$$.fragment),m6r=l(),po=a("div"),F(tS.$$.fragment),f6r=l(),L0e=a("p"),g6r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),h6r=l(),Tn=a("p"),u6r=o("The model class to instantiate is selected based on the "),y0e=a("code"),p6r=o("model_type"),_6r=o(` property of the config object (either
passed as an argument or loaded from `),x0e=a("code"),b6r=o("pretrained_model_name_or_path"),v6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$0e=a("code"),F6r=o("pretrained_model_name_or_path"),T6r=o(":"),M6r=l(),k0e=a("ul"),NC=a("li"),S0e=a("strong"),E6r=o("vilt"),C6r=o(" \u2014 "),uee=a("a"),w6r=o("ViltForQuestionAnswering"),A6r=o(" (ViLT model)"),L6r=l(),qC=a("p"),y6r=o("The model is set in evaluation mode by default using "),R0e=a("code"),x6r=o("model.eval()"),$6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P0e=a("code"),k6r=o("model.train()"),S6r=l(),F(jC.$$.fragment),Bto=l(),yc=a("h2"),DC=a("a"),B0e=a("span"),F(aS.$$.fragment),R6r=l(),I0e=a("span"),P6r=o("AutoModelForAudioClassification"),Ito=l(),Ko=a("div"),F(nS.$$.fragment),B6r=l(),xc=a("p"),I6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),pee=a("a"),N6r=o("from_pretrained()"),q6r=o(" class method or the "),_ee=a("a"),j6r=o("from_config()"),D6r=o(` class
method.`),G6r=l(),sS=a("p"),O6r=o("This class cannot be instantiated directly using "),N0e=a("code"),V6r=o("__init__()"),X6r=o(" (throws an error)."),z6r=l(),jt=a("div"),F(lS.$$.fragment),Q6r=l(),q0e=a("p"),W6r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),U6r=l(),$c=a("p"),H6r=o(`Note:
Loading a model from its configuration file does `),j0e=a("strong"),J6r=o("not"),Y6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bee=a("a"),Z6r=o("from_pretrained()"),K6r=o(" to load the model weights."),e7r=l(),F(GC.$$.fragment),o7r=l(),_o=a("div"),F(iS.$$.fragment),r7r=l(),D0e=a("p"),t7r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),a7r=l(),Mn=a("p"),n7r=o("The model class to instantiate is selected based on the "),G0e=a("code"),s7r=o("model_type"),l7r=o(` property of the config object (either
passed as an argument or loaded from `),O0e=a("code"),i7r=o("pretrained_model_name_or_path"),d7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V0e=a("code"),c7r=o("pretrained_model_name_or_path"),m7r=o(":"),f7r=l(),Be=a("ul"),OC=a("li"),X0e=a("strong"),g7r=o("data2vec-audio"),h7r=o(" \u2014 "),vee=a("a"),u7r=o("Data2VecAudioForSequenceClassification"),p7r=o(" (Data2VecAudio model)"),_7r=l(),VC=a("li"),z0e=a("strong"),b7r=o("hubert"),v7r=o(" \u2014 "),Fee=a("a"),F7r=o("HubertForSequenceClassification"),T7r=o(" (Hubert model)"),M7r=l(),XC=a("li"),Q0e=a("strong"),E7r=o("sew"),C7r=o(" \u2014 "),Tee=a("a"),w7r=o("SEWForSequenceClassification"),A7r=o(" (SEW model)"),L7r=l(),zC=a("li"),W0e=a("strong"),y7r=o("sew-d"),x7r=o(" \u2014 "),Mee=a("a"),$7r=o("SEWDForSequenceClassification"),k7r=o(" (SEW-D model)"),S7r=l(),QC=a("li"),U0e=a("strong"),R7r=o("unispeech"),P7r=o(" \u2014 "),Eee=a("a"),B7r=o("UniSpeechForSequenceClassification"),I7r=o(" (UniSpeech model)"),N7r=l(),WC=a("li"),H0e=a("strong"),q7r=o("unispeech-sat"),j7r=o(" \u2014 "),Cee=a("a"),D7r=o("UniSpeechSatForSequenceClassification"),G7r=o(" (UniSpeechSat model)"),O7r=l(),UC=a("li"),J0e=a("strong"),V7r=o("wav2vec2"),X7r=o(" \u2014 "),wee=a("a"),z7r=o("Wav2Vec2ForSequenceClassification"),Q7r=o(" (Wav2Vec2 model)"),W7r=l(),HC=a("li"),Y0e=a("strong"),U7r=o("wav2vec2-conformer"),H7r=o(" \u2014 "),Aee=a("a"),J7r=o("Wav2Vec2ConformerForSequenceClassification"),Y7r=o(" (Wav2Vec2-Conformer model)"),Z7r=l(),JC=a("li"),Z0e=a("strong"),K7r=o("wavlm"),eLr=o(" \u2014 "),Lee=a("a"),oLr=o("WavLMForSequenceClassification"),rLr=o(" (WavLM model)"),tLr=l(),YC=a("p"),aLr=o("The model is set in evaluation mode by default using "),K0e=a("code"),nLr=o("model.eval()"),sLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ewe=a("code"),lLr=o("model.train()"),iLr=l(),F(ZC.$$.fragment),Nto=l(),kc=a("h2"),KC=a("a"),owe=a("span"),F(dS.$$.fragment),dLr=l(),rwe=a("span"),cLr=o("AutoModelForAudioFrameClassification"),qto=l(),er=a("div"),F(cS.$$.fragment),mLr=l(),Sc=a("p"),fLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),yee=a("a"),gLr=o("from_pretrained()"),hLr=o(" class method or the "),xee=a("a"),uLr=o("from_config()"),pLr=o(` class
method.`),_Lr=l(),mS=a("p"),bLr=o("This class cannot be instantiated directly using "),twe=a("code"),vLr=o("__init__()"),FLr=o(" (throws an error)."),TLr=l(),Dt=a("div"),F(fS.$$.fragment),MLr=l(),awe=a("p"),ELr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),CLr=l(),Rc=a("p"),wLr=o(`Note:
Loading a model from its configuration file does `),nwe=a("strong"),ALr=o("not"),LLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ee=a("a"),yLr=o("from_pretrained()"),xLr=o(" to load the model weights."),$Lr=l(),F(e3.$$.fragment),kLr=l(),bo=a("div"),F(gS.$$.fragment),SLr=l(),swe=a("p"),RLr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),PLr=l(),En=a("p"),BLr=o("The model class to instantiate is selected based on the "),lwe=a("code"),ILr=o("model_type"),NLr=o(` property of the config object (either
passed as an argument or loaded from `),iwe=a("code"),qLr=o("pretrained_model_name_or_path"),jLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=a("code"),DLr=o("pretrained_model_name_or_path"),GLr=o(":"),OLr=l(),ut=a("ul"),o3=a("li"),cwe=a("strong"),VLr=o("data2vec-audio"),XLr=o(" \u2014 "),kee=a("a"),zLr=o("Data2VecAudioForAudioFrameClassification"),QLr=o(" (Data2VecAudio model)"),WLr=l(),r3=a("li"),mwe=a("strong"),ULr=o("unispeech-sat"),HLr=o(" \u2014 "),See=a("a"),JLr=o("UniSpeechSatForAudioFrameClassification"),YLr=o(" (UniSpeechSat model)"),ZLr=l(),t3=a("li"),fwe=a("strong"),KLr=o("wav2vec2"),e8r=o(" \u2014 "),Ree=a("a"),o8r=o("Wav2Vec2ForAudioFrameClassification"),r8r=o(" (Wav2Vec2 model)"),t8r=l(),a3=a("li"),gwe=a("strong"),a8r=o("wav2vec2-conformer"),n8r=o(" \u2014 "),Pee=a("a"),s8r=o("Wav2Vec2ConformerForAudioFrameClassification"),l8r=o(" (Wav2Vec2-Conformer model)"),i8r=l(),n3=a("li"),hwe=a("strong"),d8r=o("wavlm"),c8r=o(" \u2014 "),Bee=a("a"),m8r=o("WavLMForAudioFrameClassification"),f8r=o(" (WavLM model)"),g8r=l(),s3=a("p"),h8r=o("The model is set in evaluation mode by default using "),uwe=a("code"),u8r=o("model.eval()"),p8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pwe=a("code"),_8r=o("model.train()"),b8r=l(),F(l3.$$.fragment),jto=l(),Pc=a("h2"),i3=a("a"),_we=a("span"),F(hS.$$.fragment),v8r=l(),bwe=a("span"),F8r=o("AutoModelForCTC"),Dto=l(),or=a("div"),F(uS.$$.fragment),T8r=l(),Bc=a("p"),M8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Iee=a("a"),E8r=o("from_pretrained()"),C8r=o(" class method or the "),Nee=a("a"),w8r=o("from_config()"),A8r=o(` class
method.`),L8r=l(),pS=a("p"),y8r=o("This class cannot be instantiated directly using "),vwe=a("code"),x8r=o("__init__()"),$8r=o(" (throws an error)."),k8r=l(),Gt=a("div"),F(_S.$$.fragment),S8r=l(),Fwe=a("p"),R8r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),P8r=l(),Ic=a("p"),B8r=o(`Note:
Loading a model from its configuration file does `),Twe=a("strong"),I8r=o("not"),N8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qee=a("a"),q8r=o("from_pretrained()"),j8r=o(" to load the model weights."),D8r=l(),F(d3.$$.fragment),G8r=l(),vo=a("div"),F(bS.$$.fragment),O8r=l(),Mwe=a("p"),V8r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),X8r=l(),Cn=a("p"),z8r=o("The model class to instantiate is selected based on the "),Ewe=a("code"),Q8r=o("model_type"),W8r=o(` property of the config object (either
passed as an argument or loaded from `),Cwe=a("code"),U8r=o("pretrained_model_name_or_path"),H8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wwe=a("code"),J8r=o("pretrained_model_name_or_path"),Y8r=o(":"),Z8r=l(),Le=a("ul"),c3=a("li"),Awe=a("strong"),K8r=o("data2vec-audio"),eyr=o(" \u2014 "),jee=a("a"),oyr=o("Data2VecAudioForCTC"),ryr=o(" (Data2VecAudio model)"),tyr=l(),m3=a("li"),Lwe=a("strong"),ayr=o("hubert"),nyr=o(" \u2014 "),Dee=a("a"),syr=o("HubertForCTC"),lyr=o(" (Hubert model)"),iyr=l(),f3=a("li"),ywe=a("strong"),dyr=o("mctct"),cyr=o(" \u2014 "),Gee=a("a"),myr=o("MCTCTForCTC"),fyr=o(" (M-CTC-T model)"),gyr=l(),g3=a("li"),xwe=a("strong"),hyr=o("sew"),uyr=o(" \u2014 "),Oee=a("a"),pyr=o("SEWForCTC"),_yr=o(" (SEW model)"),byr=l(),h3=a("li"),$we=a("strong"),vyr=o("sew-d"),Fyr=o(" \u2014 "),Vee=a("a"),Tyr=o("SEWDForCTC"),Myr=o(" (SEW-D model)"),Eyr=l(),u3=a("li"),kwe=a("strong"),Cyr=o("unispeech"),wyr=o(" \u2014 "),Xee=a("a"),Ayr=o("UniSpeechForCTC"),Lyr=o(" (UniSpeech model)"),yyr=l(),p3=a("li"),Swe=a("strong"),xyr=o("unispeech-sat"),$yr=o(" \u2014 "),zee=a("a"),kyr=o("UniSpeechSatForCTC"),Syr=o(" (UniSpeechSat model)"),Ryr=l(),_3=a("li"),Rwe=a("strong"),Pyr=o("wav2vec2"),Byr=o(" \u2014 "),Qee=a("a"),Iyr=o("Wav2Vec2ForCTC"),Nyr=o(" (Wav2Vec2 model)"),qyr=l(),b3=a("li"),Pwe=a("strong"),jyr=o("wav2vec2-conformer"),Dyr=o(" \u2014 "),Wee=a("a"),Gyr=o("Wav2Vec2ConformerForCTC"),Oyr=o(" (Wav2Vec2-Conformer model)"),Vyr=l(),v3=a("li"),Bwe=a("strong"),Xyr=o("wavlm"),zyr=o(" \u2014 "),Uee=a("a"),Qyr=o("WavLMForCTC"),Wyr=o(" (WavLM model)"),Uyr=l(),F3=a("p"),Hyr=o("The model is set in evaluation mode by default using "),Iwe=a("code"),Jyr=o("model.eval()"),Yyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nwe=a("code"),Zyr=o("model.train()"),Kyr=l(),F(T3.$$.fragment),Gto=l(),Nc=a("h2"),M3=a("a"),qwe=a("span"),F(vS.$$.fragment),e9r=l(),jwe=a("span"),o9r=o("AutoModelForSpeechSeq2Seq"),Oto=l(),rr=a("div"),F(FS.$$.fragment),r9r=l(),qc=a("p"),t9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Hee=a("a"),a9r=o("from_pretrained()"),n9r=o(" class method or the "),Jee=a("a"),s9r=o("from_config()"),l9r=o(` class
method.`),i9r=l(),TS=a("p"),d9r=o("This class cannot be instantiated directly using "),Dwe=a("code"),c9r=o("__init__()"),m9r=o(" (throws an error)."),f9r=l(),Ot=a("div"),F(MS.$$.fragment),g9r=l(),Gwe=a("p"),h9r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),u9r=l(),jc=a("p"),p9r=o(`Note:
Loading a model from its configuration file does `),Owe=a("strong"),_9r=o("not"),b9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=a("a"),v9r=o("from_pretrained()"),F9r=o(" to load the model weights."),T9r=l(),F(E3.$$.fragment),M9r=l(),Fo=a("div"),F(ES.$$.fragment),E9r=l(),Vwe=a("p"),C9r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),w9r=l(),wn=a("p"),A9r=o("The model class to instantiate is selected based on the "),Xwe=a("code"),L9r=o("model_type"),y9r=o(` property of the config object (either
passed as an argument or loaded from `),zwe=a("code"),x9r=o("pretrained_model_name_or_path"),$9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qwe=a("code"),k9r=o("pretrained_model_name_or_path"),S9r=o(":"),R9r=l(),Dc=a("ul"),C3=a("li"),Wwe=a("strong"),P9r=o("speech-encoder-decoder"),B9r=o(" \u2014 "),Zee=a("a"),I9r=o("SpeechEncoderDecoderModel"),N9r=o(" (Speech Encoder decoder model)"),q9r=l(),w3=a("li"),Uwe=a("strong"),j9r=o("speech_to_text"),D9r=o(" \u2014 "),Kee=a("a"),G9r=o("Speech2TextForConditionalGeneration"),O9r=o(" (Speech2Text model)"),V9r=l(),A3=a("li"),Hwe=a("strong"),X9r=o("whisper"),z9r=o(" \u2014 "),eoe=a("a"),Q9r=o("WhisperForConditionalGeneration"),W9r=o(" (Whisper model)"),U9r=l(),L3=a("p"),H9r=o("The model is set in evaluation mode by default using "),Jwe=a("code"),J9r=o("model.eval()"),Y9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ywe=a("code"),Z9r=o("model.train()"),K9r=l(),F(y3.$$.fragment),Vto=l(),Gc=a("h2"),x3=a("a"),Zwe=a("span"),F(CS.$$.fragment),exr=l(),Kwe=a("span"),oxr=o("AutoModelForAudioXVector"),Xto=l(),tr=a("div"),F(wS.$$.fragment),rxr=l(),Oc=a("p"),txr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),ooe=a("a"),axr=o("from_pretrained()"),nxr=o(" class method or the "),roe=a("a"),sxr=o("from_config()"),lxr=o(` class
method.`),ixr=l(),AS=a("p"),dxr=o("This class cannot be instantiated directly using "),eAe=a("code"),cxr=o("__init__()"),mxr=o(" (throws an error)."),fxr=l(),Vt=a("div"),F(LS.$$.fragment),gxr=l(),oAe=a("p"),hxr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),uxr=l(),Vc=a("p"),pxr=o(`Note:
Loading a model from its configuration file does `),rAe=a("strong"),_xr=o("not"),bxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=a("a"),vxr=o("from_pretrained()"),Fxr=o(" to load the model weights."),Txr=l(),F($3.$$.fragment),Mxr=l(),To=a("div"),F(yS.$$.fragment),Exr=l(),tAe=a("p"),Cxr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),wxr=l(),An=a("p"),Axr=o("The model class to instantiate is selected based on the "),aAe=a("code"),Lxr=o("model_type"),yxr=o(` property of the config object (either
passed as an argument or loaded from `),nAe=a("code"),xxr=o("pretrained_model_name_or_path"),$xr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sAe=a("code"),kxr=o("pretrained_model_name_or_path"),Sxr=o(":"),Rxr=l(),pt=a("ul"),k3=a("li"),lAe=a("strong"),Pxr=o("data2vec-audio"),Bxr=o(" \u2014 "),aoe=a("a"),Ixr=o("Data2VecAudioForXVector"),Nxr=o(" (Data2VecAudio model)"),qxr=l(),S3=a("li"),iAe=a("strong"),jxr=o("unispeech-sat"),Dxr=o(" \u2014 "),noe=a("a"),Gxr=o("UniSpeechSatForXVector"),Oxr=o(" (UniSpeechSat model)"),Vxr=l(),R3=a("li"),dAe=a("strong"),Xxr=o("wav2vec2"),zxr=o(" \u2014 "),soe=a("a"),Qxr=o("Wav2Vec2ForXVector"),Wxr=o(" (Wav2Vec2 model)"),Uxr=l(),P3=a("li"),cAe=a("strong"),Hxr=o("wav2vec2-conformer"),Jxr=o(" \u2014 "),loe=a("a"),Yxr=o("Wav2Vec2ConformerForXVector"),Zxr=o(" (Wav2Vec2-Conformer model)"),Kxr=l(),B3=a("li"),mAe=a("strong"),e$r=o("wavlm"),o$r=o(" \u2014 "),ioe=a("a"),r$r=o("WavLMForXVector"),t$r=o(" (WavLM model)"),a$r=l(),I3=a("p"),n$r=o("The model is set in evaluation mode by default using "),fAe=a("code"),s$r=o("model.eval()"),l$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gAe=a("code"),i$r=o("model.train()"),d$r=l(),F(N3.$$.fragment),zto=l(),Xc=a("h2"),q3=a("a"),hAe=a("span"),F(xS.$$.fragment),c$r=l(),uAe=a("span"),m$r=o("AutoModelForMaskedImageModeling"),Qto=l(),ar=a("div"),F($S.$$.fragment),f$r=l(),zc=a("p"),g$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),doe=a("a"),h$r=o("from_pretrained()"),u$r=o(" class method or the "),coe=a("a"),p$r=o("from_config()"),_$r=o(` class
method.`),b$r=l(),kS=a("p"),v$r=o("This class cannot be instantiated directly using "),pAe=a("code"),F$r=o("__init__()"),T$r=o(" (throws an error)."),M$r=l(),Xt=a("div"),F(SS.$$.fragment),E$r=l(),_Ae=a("p"),C$r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),w$r=l(),Qc=a("p"),A$r=o(`Note:
Loading a model from its configuration file does `),bAe=a("strong"),L$r=o("not"),y$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=a("a"),x$r=o("from_pretrained()"),$$r=o(" to load the model weights."),k$r=l(),F(j3.$$.fragment),S$r=l(),Mo=a("div"),F(RS.$$.fragment),R$r=l(),vAe=a("p"),P$r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B$r=l(),Ln=a("p"),I$r=o("The model class to instantiate is selected based on the "),FAe=a("code"),N$r=o("model_type"),q$r=o(` property of the config object (either
passed as an argument or loaded from `),TAe=a("code"),j$r=o("pretrained_model_name_or_path"),D$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MAe=a("code"),G$r=o("pretrained_model_name_or_path"),O$r=o(":"),V$r=l(),yn=a("ul"),D3=a("li"),EAe=a("strong"),X$r=o("deit"),z$r=o(" \u2014 "),foe=a("a"),Q$r=o("DeiTForMaskedImageModeling"),W$r=o(" (DeiT model)"),U$r=l(),G3=a("li"),CAe=a("strong"),H$r=o("swin"),J$r=o(" \u2014 "),goe=a("a"),Y$r=o("SwinForMaskedImageModeling"),Z$r=o(" (Swin Transformer model)"),K$r=l(),O3=a("li"),wAe=a("strong"),ekr=o("swinv2"),okr=o(" \u2014 "),hoe=a("a"),rkr=o("Swinv2ForMaskedImageModeling"),tkr=o(" (Swin Transformer V2 model)"),akr=l(),V3=a("li"),AAe=a("strong"),nkr=o("vit"),skr=o(" \u2014 "),uoe=a("a"),lkr=o("ViTForMaskedImageModeling"),ikr=o(" (ViT model)"),dkr=l(),X3=a("p"),ckr=o("The model is set in evaluation mode by default using "),LAe=a("code"),mkr=o("model.eval()"),fkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yAe=a("code"),gkr=o("model.train()"),hkr=l(),F(z3.$$.fragment),Wto=l(),Wc=a("h2"),Q3=a("a"),xAe=a("span"),F(PS.$$.fragment),ukr=l(),$Ae=a("span"),pkr=o("AutoModelForObjectDetection"),Uto=l(),nr=a("div"),F(BS.$$.fragment),_kr=l(),Uc=a("p"),bkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),poe=a("a"),vkr=o("from_pretrained()"),Fkr=o(" class method or the "),_oe=a("a"),Tkr=o("from_config()"),Mkr=o(` class
method.`),Ekr=l(),IS=a("p"),Ckr=o("This class cannot be instantiated directly using "),kAe=a("code"),wkr=o("__init__()"),Akr=o(" (throws an error)."),Lkr=l(),zt=a("div"),F(NS.$$.fragment),ykr=l(),SAe=a("p"),xkr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),$kr=l(),Hc=a("p"),kkr=o(`Note:
Loading a model from its configuration file does `),RAe=a("strong"),Skr=o("not"),Rkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=a("a"),Pkr=o("from_pretrained()"),Bkr=o(" to load the model weights."),Ikr=l(),F(W3.$$.fragment),Nkr=l(),Eo=a("div"),F(qS.$$.fragment),qkr=l(),PAe=a("p"),jkr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Dkr=l(),xn=a("p"),Gkr=o("The model class to instantiate is selected based on the "),BAe=a("code"),Okr=o("model_type"),Vkr=o(` property of the config object (either
passed as an argument or loaded from `),IAe=a("code"),Xkr=o("pretrained_model_name_or_path"),zkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NAe=a("code"),Qkr=o("pretrained_model_name_or_path"),Wkr=o(":"),Ukr=l(),$n=a("ul"),U3=a("li"),qAe=a("strong"),Hkr=o("conditional_detr"),Jkr=o(" \u2014 "),voe=a("a"),Ykr=o("ConditionalDetrForObjectDetection"),Zkr=o(" (Conditional DETR model)"),Kkr=l(),H3=a("li"),jAe=a("strong"),eSr=o("deformable_detr"),oSr=o(" \u2014 "),Foe=a("a"),rSr=o("DeformableDetrForObjectDetection"),tSr=o(" (Deformable DETR model)"),aSr=l(),J3=a("li"),DAe=a("strong"),nSr=o("detr"),sSr=o(" \u2014 "),Toe=a("a"),lSr=o("DetrForObjectDetection"),iSr=o(" (DETR model)"),dSr=l(),Y3=a("li"),GAe=a("strong"),cSr=o("yolos"),mSr=o(" \u2014 "),Moe=a("a"),fSr=o("YolosForObjectDetection"),gSr=o(" (YOLOS model)"),hSr=l(),Z3=a("p"),uSr=o("The model is set in evaluation mode by default using "),OAe=a("code"),pSr=o("model.eval()"),_Sr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VAe=a("code"),bSr=o("model.train()"),vSr=l(),F(K3.$$.fragment),Hto=l(),Jc=a("h2"),e5=a("a"),XAe=a("span"),F(jS.$$.fragment),FSr=l(),zAe=a("span"),TSr=o("AutoModelForImageSegmentation"),Jto=l(),sr=a("div"),F(DS.$$.fragment),MSr=l(),Yc=a("p"),ESr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Eoe=a("a"),CSr=o("from_pretrained()"),wSr=o(" class method or the "),Coe=a("a"),ASr=o("from_config()"),LSr=o(` class
method.`),ySr=l(),GS=a("p"),xSr=o("This class cannot be instantiated directly using "),QAe=a("code"),$Sr=o("__init__()"),kSr=o(" (throws an error)."),SSr=l(),Qt=a("div"),F(OS.$$.fragment),RSr=l(),WAe=a("p"),PSr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),BSr=l(),Zc=a("p"),ISr=o(`Note:
Loading a model from its configuration file does `),UAe=a("strong"),NSr=o("not"),qSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),woe=a("a"),jSr=o("from_pretrained()"),DSr=o(" to load the model weights."),GSr=l(),F(o5.$$.fragment),OSr=l(),Co=a("div"),F(VS.$$.fragment),VSr=l(),HAe=a("p"),XSr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),zSr=l(),kn=a("p"),QSr=o("The model class to instantiate is selected based on the "),JAe=a("code"),WSr=o("model_type"),USr=o(` property of the config object (either
passed as an argument or loaded from `),YAe=a("code"),HSr=o("pretrained_model_name_or_path"),JSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZAe=a("code"),YSr=o("pretrained_model_name_or_path"),ZSr=o(":"),KSr=l(),KAe=a("ul"),r5=a("li"),e6e=a("strong"),eRr=o("detr"),oRr=o(" \u2014 "),Aoe=a("a"),rRr=o("DetrForSegmentation"),tRr=o(" (DETR model)"),aRr=l(),t5=a("p"),nRr=o("The model is set in evaluation mode by default using "),o6e=a("code"),sRr=o("model.eval()"),lRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r6e=a("code"),iRr=o("model.train()"),dRr=l(),F(a5.$$.fragment),Yto=l(),Kc=a("h2"),n5=a("a"),t6e=a("span"),F(XS.$$.fragment),cRr=l(),a6e=a("span"),mRr=o("AutoModelForSemanticSegmentation"),Zto=l(),lr=a("div"),F(zS.$$.fragment),fRr=l(),em=a("p"),gRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Loe=a("a"),hRr=o("from_pretrained()"),uRr=o(" class method or the "),yoe=a("a"),pRr=o("from_config()"),_Rr=o(` class
method.`),bRr=l(),QS=a("p"),vRr=o("This class cannot be instantiated directly using "),n6e=a("code"),FRr=o("__init__()"),TRr=o(" (throws an error)."),MRr=l(),Wt=a("div"),F(WS.$$.fragment),ERr=l(),s6e=a("p"),CRr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),wRr=l(),om=a("p"),ARr=o(`Note:
Loading a model from its configuration file does `),l6e=a("strong"),LRr=o("not"),yRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xoe=a("a"),xRr=o("from_pretrained()"),$Rr=o(" to load the model weights."),kRr=l(),F(s5.$$.fragment),SRr=l(),wo=a("div"),F(US.$$.fragment),RRr=l(),i6e=a("p"),PRr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),BRr=l(),Sn=a("p"),IRr=o("The model class to instantiate is selected based on the "),d6e=a("code"),NRr=o("model_type"),qRr=o(` property of the config object (either
passed as an argument or loaded from `),c6e=a("code"),jRr=o("pretrained_model_name_or_path"),DRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=a("code"),GRr=o("pretrained_model_name_or_path"),ORr=o(":"),VRr=l(),_t=a("ul"),l5=a("li"),f6e=a("strong"),XRr=o("beit"),zRr=o(" \u2014 "),$oe=a("a"),QRr=o("BeitForSemanticSegmentation"),WRr=o(" (BEiT model)"),URr=l(),i5=a("li"),g6e=a("strong"),HRr=o("data2vec-vision"),JRr=o(" \u2014 "),koe=a("a"),YRr=o("Data2VecVisionForSemanticSegmentation"),ZRr=o(" (Data2VecVision model)"),KRr=l(),d5=a("li"),h6e=a("strong"),ePr=o("dpt"),oPr=o(" \u2014 "),Soe=a("a"),rPr=o("DPTForSemanticSegmentation"),tPr=o(" (DPT model)"),aPr=l(),c5=a("li"),u6e=a("strong"),nPr=o("mobilevit"),sPr=o(" \u2014 "),Roe=a("a"),lPr=o("MobileViTForSemanticSegmentation"),iPr=o(" (MobileViT model)"),dPr=l(),m5=a("li"),p6e=a("strong"),cPr=o("segformer"),mPr=o(" \u2014 "),Poe=a("a"),fPr=o("SegformerForSemanticSegmentation"),gPr=o(" (SegFormer model)"),hPr=l(),f5=a("p"),uPr=o("The model is set in evaluation mode by default using "),_6e=a("code"),pPr=o("model.eval()"),_Pr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b6e=a("code"),bPr=o("model.train()"),vPr=l(),F(g5.$$.fragment),Kto=l(),rm=a("h2"),h5=a("a"),v6e=a("span"),F(HS.$$.fragment),FPr=l(),F6e=a("span"),TPr=o("AutoModelForInstanceSegmentation"),eao=l(),ir=a("div"),F(JS.$$.fragment),MPr=l(),tm=a("p"),EPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Boe=a("a"),CPr=o("from_pretrained()"),wPr=o(" class method or the "),Ioe=a("a"),APr=o("from_config()"),LPr=o(` class
method.`),yPr=l(),YS=a("p"),xPr=o("This class cannot be instantiated directly using "),T6e=a("code"),$Pr=o("__init__()"),kPr=o(" (throws an error)."),SPr=l(),Ut=a("div"),F(ZS.$$.fragment),RPr=l(),M6e=a("p"),PPr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),BPr=l(),am=a("p"),IPr=o(`Note:
Loading a model from its configuration file does `),E6e=a("strong"),NPr=o("not"),qPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Noe=a("a"),jPr=o("from_pretrained()"),DPr=o(" to load the model weights."),GPr=l(),F(u5.$$.fragment),OPr=l(),Ao=a("div"),F(KS.$$.fragment),VPr=l(),C6e=a("p"),XPr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),zPr=l(),Rn=a("p"),QPr=o("The model class to instantiate is selected based on the "),w6e=a("code"),WPr=o("model_type"),UPr=o(` property of the config object (either
passed as an argument or loaded from `),A6e=a("code"),HPr=o("pretrained_model_name_or_path"),JPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L6e=a("code"),YPr=o("pretrained_model_name_or_path"),ZPr=o(":"),KPr=l(),y6e=a("ul"),p5=a("li"),x6e=a("strong"),eBr=o("maskformer"),oBr=o(" \u2014 "),qoe=a("a"),rBr=o("MaskFormerForInstanceSegmentation"),tBr=o(" (MaskFormer model)"),aBr=l(),_5=a("p"),nBr=o("The model is set in evaluation mode by default using "),$6e=a("code"),sBr=o("model.eval()"),lBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k6e=a("code"),iBr=o("model.train()"),dBr=l(),F(b5.$$.fragment),oao=l(),nm=a("h2"),v5=a("a"),S6e=a("span"),F(eR.$$.fragment),cBr=l(),R6e=a("span"),mBr=o("AutoModelForZeroShotObjectDetection"),rao=l(),dr=a("div"),F(oR.$$.fragment),fBr=l(),sm=a("p"),gBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),joe=a("a"),hBr=o("from_pretrained()"),uBr=o(" class method or the "),Doe=a("a"),pBr=o("from_config()"),_Br=o(` class
method.`),bBr=l(),rR=a("p"),vBr=o("This class cannot be instantiated directly using "),P6e=a("code"),FBr=o("__init__()"),TBr=o(" (throws an error)."),MBr=l(),Ht=a("div"),F(tR.$$.fragment),EBr=l(),B6e=a("p"),CBr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),wBr=l(),lm=a("p"),ABr=o(`Note:
Loading a model from its configuration file does `),I6e=a("strong"),LBr=o("not"),yBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=a("a"),xBr=o("from_pretrained()"),$Br=o(" to load the model weights."),kBr=l(),F(F5.$$.fragment),SBr=l(),Lo=a("div"),F(aR.$$.fragment),RBr=l(),N6e=a("p"),PBr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),BBr=l(),Pn=a("p"),IBr=o("The model class to instantiate is selected based on the "),q6e=a("code"),NBr=o("model_type"),qBr=o(` property of the config object (either
passed as an argument or loaded from `),j6e=a("code"),jBr=o("pretrained_model_name_or_path"),DBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=a("code"),GBr=o("pretrained_model_name_or_path"),OBr=o(":"),VBr=l(),G6e=a("ul"),T5=a("li"),O6e=a("strong"),XBr=o("owlvit"),zBr=o(" \u2014 "),Ooe=a("a"),QBr=o("OwlViTForObjectDetection"),WBr=o(" (OWL-ViT model)"),UBr=l(),M5=a("p"),HBr=o("The model is set in evaluation mode by default using "),V6e=a("code"),JBr=o("model.eval()"),YBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X6e=a("code"),ZBr=o("model.train()"),KBr=l(),F(E5.$$.fragment),tao=l(),im=a("h2"),C5=a("a"),z6e=a("span"),F(nR.$$.fragment),eIr=l(),Q6e=a("span"),oIr=o("TFAutoModel"),aao=l(),cr=a("div"),F(sR.$$.fragment),rIr=l(),dm=a("p"),tIr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Voe=a("a"),aIr=o("from_pretrained()"),nIr=o(" class method or the "),Xoe=a("a"),sIr=o("from_config()"),lIr=o(` class
method.`),iIr=l(),lR=a("p"),dIr=o("This class cannot be instantiated directly using "),W6e=a("code"),cIr=o("__init__()"),mIr=o(" (throws an error)."),fIr=l(),Jt=a("div"),F(iR.$$.fragment),gIr=l(),U6e=a("p"),hIr=o("Instantiates one of the base model classes of the library from a configuration."),uIr=l(),cm=a("p"),pIr=o(`Note:
Loading a model from its configuration file does `),H6e=a("strong"),_Ir=o("not"),bIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=a("a"),vIr=o("from_pretrained()"),FIr=o(" to load the model weights."),TIr=l(),F(w5.$$.fragment),MIr=l(),Dr=a("div"),F(dR.$$.fragment),EIr=l(),J6e=a("p"),CIr=o("Instantiate one of the base model classes of the library from a pretrained model."),wIr=l(),Bn=a("p"),AIr=o("The model class to instantiate is selected based on the "),Y6e=a("code"),LIr=o("model_type"),yIr=o(` property of the config object (either
passed as an argument or loaded from `),Z6e=a("code"),xIr=o("pretrained_model_name_or_path"),$Ir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K6e=a("code"),kIr=o("pretrained_model_name_or_path"),SIr=o(":"),RIr=l(),B=a("ul"),A5=a("li"),e7e=a("strong"),PIr=o("albert"),BIr=o(" \u2014 "),Qoe=a("a"),IIr=o("TFAlbertModel"),NIr=o(" (ALBERT model)"),qIr=l(),L5=a("li"),o7e=a("strong"),jIr=o("bart"),DIr=o(" \u2014 "),Woe=a("a"),GIr=o("TFBartModel"),OIr=o(" (BART model)"),VIr=l(),y5=a("li"),r7e=a("strong"),XIr=o("bert"),zIr=o(" \u2014 "),Uoe=a("a"),QIr=o("TFBertModel"),WIr=o(" (BERT model)"),UIr=l(),x5=a("li"),t7e=a("strong"),HIr=o("blenderbot"),JIr=o(" \u2014 "),Hoe=a("a"),YIr=o("TFBlenderbotModel"),ZIr=o(" (Blenderbot model)"),KIr=l(),$5=a("li"),a7e=a("strong"),eNr=o("blenderbot-small"),oNr=o(" \u2014 "),Joe=a("a"),rNr=o("TFBlenderbotSmallModel"),tNr=o(" (BlenderbotSmall model)"),aNr=l(),k5=a("li"),n7e=a("strong"),nNr=o("camembert"),sNr=o(" \u2014 "),Yoe=a("a"),lNr=o("TFCamembertModel"),iNr=o(" (CamemBERT model)"),dNr=l(),S5=a("li"),s7e=a("strong"),cNr=o("clip"),mNr=o(" \u2014 "),Zoe=a("a"),fNr=o("TFCLIPModel"),gNr=o(" (CLIP model)"),hNr=l(),R5=a("li"),l7e=a("strong"),uNr=o("convbert"),pNr=o(" \u2014 "),Koe=a("a"),_Nr=o("TFConvBertModel"),bNr=o(" (ConvBERT model)"),vNr=l(),P5=a("li"),i7e=a("strong"),FNr=o("convnext"),TNr=o(" \u2014 "),ere=a("a"),MNr=o("TFConvNextModel"),ENr=o(" (ConvNeXT model)"),CNr=l(),B5=a("li"),d7e=a("strong"),wNr=o("ctrl"),ANr=o(" \u2014 "),ore=a("a"),LNr=o("TFCTRLModel"),yNr=o(" (CTRL model)"),xNr=l(),I5=a("li"),c7e=a("strong"),$Nr=o("cvt"),kNr=o(" \u2014 "),rre=a("a"),SNr=o("TFCvtModel"),RNr=o(" (CvT model)"),PNr=l(),N5=a("li"),m7e=a("strong"),BNr=o("data2vec-vision"),INr=o(" \u2014 "),tre=a("a"),NNr=o("TFData2VecVisionModel"),qNr=o(" (Data2VecVision model)"),jNr=l(),q5=a("li"),f7e=a("strong"),DNr=o("deberta"),GNr=o(" \u2014 "),are=a("a"),ONr=o("TFDebertaModel"),VNr=o(" (DeBERTa model)"),XNr=l(),j5=a("li"),g7e=a("strong"),zNr=o("deberta-v2"),QNr=o(" \u2014 "),nre=a("a"),WNr=o("TFDebertaV2Model"),UNr=o(" (DeBERTa-v2 model)"),HNr=l(),D5=a("li"),h7e=a("strong"),JNr=o("deit"),YNr=o(" \u2014 "),sre=a("a"),ZNr=o("TFDeiTModel"),KNr=o(" (DeiT model)"),eqr=l(),G5=a("li"),u7e=a("strong"),oqr=o("distilbert"),rqr=o(" \u2014 "),lre=a("a"),tqr=o("TFDistilBertModel"),aqr=o(" (DistilBERT model)"),nqr=l(),O5=a("li"),p7e=a("strong"),sqr=o("dpr"),lqr=o(" \u2014 "),ire=a("a"),iqr=o("TFDPRQuestionEncoder"),dqr=o(" (DPR model)"),cqr=l(),V5=a("li"),_7e=a("strong"),mqr=o("electra"),fqr=o(" \u2014 "),dre=a("a"),gqr=o("TFElectraModel"),hqr=o(" (ELECTRA model)"),uqr=l(),X5=a("li"),b7e=a("strong"),pqr=o("flaubert"),_qr=o(" \u2014 "),cre=a("a"),bqr=o("TFFlaubertModel"),vqr=o(" (FlauBERT model)"),Fqr=l(),kl=a("li"),v7e=a("strong"),Tqr=o("funnel"),Mqr=o(" \u2014 "),mre=a("a"),Eqr=o("TFFunnelModel"),Cqr=o(" or "),fre=a("a"),wqr=o("TFFunnelBaseModel"),Aqr=o(" (Funnel Transformer model)"),Lqr=l(),z5=a("li"),F7e=a("strong"),yqr=o("gpt2"),xqr=o(" \u2014 "),gre=a("a"),$qr=o("TFGPT2Model"),kqr=o(" (OpenAI GPT-2 model)"),Sqr=l(),Q5=a("li"),T7e=a("strong"),Rqr=o("gptj"),Pqr=o(" \u2014 "),hre=a("a"),Bqr=o("TFGPTJModel"),Iqr=o(" (GPT-J model)"),Nqr=l(),W5=a("li"),M7e=a("strong"),qqr=o("groupvit"),jqr=o(" \u2014 "),ure=a("a"),Dqr=o("TFGroupViTModel"),Gqr=o(" (GroupViT model)"),Oqr=l(),U5=a("li"),E7e=a("strong"),Vqr=o("hubert"),Xqr=o(" \u2014 "),pre=a("a"),zqr=o("TFHubertModel"),Qqr=o(" (Hubert model)"),Wqr=l(),H5=a("li"),C7e=a("strong"),Uqr=o("layoutlm"),Hqr=o(" \u2014 "),_re=a("a"),Jqr=o("TFLayoutLMModel"),Yqr=o(" (LayoutLM model)"),Zqr=l(),J5=a("li"),w7e=a("strong"),Kqr=o("layoutlmv3"),ejr=o(" \u2014 "),bre=a("a"),ojr=o("TFLayoutLMv3Model"),rjr=o(" (LayoutLMv3 model)"),tjr=l(),Y5=a("li"),A7e=a("strong"),ajr=o("led"),njr=o(" \u2014 "),vre=a("a"),sjr=o("TFLEDModel"),ljr=o(" (LED model)"),ijr=l(),Z5=a("li"),L7e=a("strong"),djr=o("longformer"),cjr=o(" \u2014 "),Fre=a("a"),mjr=o("TFLongformerModel"),fjr=o(" (Longformer model)"),gjr=l(),K5=a("li"),y7e=a("strong"),hjr=o("lxmert"),ujr=o(" \u2014 "),Tre=a("a"),pjr=o("TFLxmertModel"),_jr=o(" (LXMERT model)"),bjr=l(),e0=a("li"),x7e=a("strong"),vjr=o("marian"),Fjr=o(" \u2014 "),Mre=a("a"),Tjr=o("TFMarianModel"),Mjr=o(" (Marian model)"),Ejr=l(),o0=a("li"),$7e=a("strong"),Cjr=o("mbart"),wjr=o(" \u2014 "),Ere=a("a"),Ajr=o("TFMBartModel"),Ljr=o(" (mBART model)"),yjr=l(),r0=a("li"),k7e=a("strong"),xjr=o("mobilebert"),$jr=o(" \u2014 "),Cre=a("a"),kjr=o("TFMobileBertModel"),Sjr=o(" (MobileBERT model)"),Rjr=l(),t0=a("li"),S7e=a("strong"),Pjr=o("mobilevit"),Bjr=o(" \u2014 "),wre=a("a"),Ijr=o("TFMobileViTModel"),Njr=o(" (MobileViT model)"),qjr=l(),a0=a("li"),R7e=a("strong"),jjr=o("mpnet"),Djr=o(" \u2014 "),Are=a("a"),Gjr=o("TFMPNetModel"),Ojr=o(" (MPNet model)"),Vjr=l(),n0=a("li"),P7e=a("strong"),Xjr=o("mt5"),zjr=o(" \u2014 "),Lre=a("a"),Qjr=o("TFMT5Model"),Wjr=o(" (MT5 model)"),Ujr=l(),s0=a("li"),B7e=a("strong"),Hjr=o("openai-gpt"),Jjr=o(" \u2014 "),yre=a("a"),Yjr=o("TFOpenAIGPTModel"),Zjr=o(" (OpenAI GPT model)"),Kjr=l(),l0=a("li"),I7e=a("strong"),eDr=o("opt"),oDr=o(" \u2014 "),xre=a("a"),rDr=o("TFOPTModel"),tDr=o(" (OPT model)"),aDr=l(),i0=a("li"),N7e=a("strong"),nDr=o("pegasus"),sDr=o(" \u2014 "),$re=a("a"),lDr=o("TFPegasusModel"),iDr=o(" (Pegasus model)"),dDr=l(),d0=a("li"),q7e=a("strong"),cDr=o("regnet"),mDr=o(" \u2014 "),kre=a("a"),fDr=o("TFRegNetModel"),gDr=o(" (RegNet model)"),hDr=l(),c0=a("li"),j7e=a("strong"),uDr=o("rembert"),pDr=o(" \u2014 "),Sre=a("a"),_Dr=o("TFRemBertModel"),bDr=o(" (RemBERT model)"),vDr=l(),m0=a("li"),D7e=a("strong"),FDr=o("resnet"),TDr=o(" \u2014 "),Rre=a("a"),MDr=o("TFResNetModel"),EDr=o(" (ResNet model)"),CDr=l(),f0=a("li"),G7e=a("strong"),wDr=o("roberta"),ADr=o(" \u2014 "),Pre=a("a"),LDr=o("TFRobertaModel"),yDr=o(" (RoBERTa model)"),xDr=l(),g0=a("li"),O7e=a("strong"),$Dr=o("roformer"),kDr=o(" \u2014 "),Bre=a("a"),SDr=o("TFRoFormerModel"),RDr=o(" (RoFormer model)"),PDr=l(),h0=a("li"),V7e=a("strong"),BDr=o("segformer"),IDr=o(" \u2014 "),Ire=a("a"),NDr=o("TFSegformerModel"),qDr=o(" (SegFormer model)"),jDr=l(),u0=a("li"),X7e=a("strong"),DDr=o("speech_to_text"),GDr=o(" \u2014 "),Nre=a("a"),ODr=o("TFSpeech2TextModel"),VDr=o(" (Speech2Text model)"),XDr=l(),p0=a("li"),z7e=a("strong"),zDr=o("swin"),QDr=o(" \u2014 "),qre=a("a"),WDr=o("TFSwinModel"),UDr=o(" (Swin Transformer model)"),HDr=l(),_0=a("li"),Q7e=a("strong"),JDr=o("t5"),YDr=o(" \u2014 "),jre=a("a"),ZDr=o("TFT5Model"),KDr=o(" (T5 model)"),eGr=l(),b0=a("li"),W7e=a("strong"),oGr=o("tapas"),rGr=o(" \u2014 "),Dre=a("a"),tGr=o("TFTapasModel"),aGr=o(" (TAPAS model)"),nGr=l(),v0=a("li"),U7e=a("strong"),sGr=o("transfo-xl"),lGr=o(" \u2014 "),Gre=a("a"),iGr=o("TFTransfoXLModel"),dGr=o(" (Transformer-XL model)"),cGr=l(),F0=a("li"),H7e=a("strong"),mGr=o("vit"),fGr=o(" \u2014 "),Ore=a("a"),gGr=o("TFViTModel"),hGr=o(" (ViT model)"),uGr=l(),T0=a("li"),J7e=a("strong"),pGr=o("vit_mae"),_Gr=o(" \u2014 "),Vre=a("a"),bGr=o("TFViTMAEModel"),vGr=o(" (ViTMAE model)"),FGr=l(),M0=a("li"),Y7e=a("strong"),TGr=o("wav2vec2"),MGr=o(" \u2014 "),Xre=a("a"),EGr=o("TFWav2Vec2Model"),CGr=o(" (Wav2Vec2 model)"),wGr=l(),E0=a("li"),Z7e=a("strong"),AGr=o("whisper"),LGr=o(" \u2014 "),zre=a("a"),yGr=o("TFWhisperModel"),xGr=o(" (Whisper model)"),$Gr=l(),C0=a("li"),K7e=a("strong"),kGr=o("xglm"),SGr=o(" \u2014 "),Qre=a("a"),RGr=o("TFXGLMModel"),PGr=o(" (XGLM model)"),BGr=l(),w0=a("li"),eLe=a("strong"),IGr=o("xlm"),NGr=o(" \u2014 "),Wre=a("a"),qGr=o("TFXLMModel"),jGr=o(" (XLM model)"),DGr=l(),A0=a("li"),oLe=a("strong"),GGr=o("xlm-roberta"),OGr=o(" \u2014 "),Ure=a("a"),VGr=o("TFXLMRobertaModel"),XGr=o(" (XLM-RoBERTa model)"),zGr=l(),L0=a("li"),rLe=a("strong"),QGr=o("xlnet"),WGr=o(" \u2014 "),Hre=a("a"),UGr=o("TFXLNetModel"),HGr=o(" (XLNet model)"),JGr=l(),F(y0.$$.fragment),nao=l(),mm=a("h2"),x0=a("a"),tLe=a("span"),F(cR.$$.fragment),YGr=l(),aLe=a("span"),ZGr=o("TFAutoModelForPreTraining"),sao=l(),mr=a("div"),F(mR.$$.fragment),KGr=l(),fm=a("p"),eOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Jre=a("a"),oOr=o("from_pretrained()"),rOr=o(" class method or the "),Yre=a("a"),tOr=o("from_config()"),aOr=o(` class
method.`),nOr=l(),fR=a("p"),sOr=o("This class cannot be instantiated directly using "),nLe=a("code"),lOr=o("__init__()"),iOr=o(" (throws an error)."),dOr=l(),Yt=a("div"),F(gR.$$.fragment),cOr=l(),sLe=a("p"),mOr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),fOr=l(),gm=a("p"),gOr=o(`Note:
Loading a model from its configuration file does `),lLe=a("strong"),hOr=o("not"),uOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=a("a"),pOr=o("from_pretrained()"),_Or=o(" to load the model weights."),bOr=l(),F($0.$$.fragment),vOr=l(),Gr=a("div"),F(hR.$$.fragment),FOr=l(),iLe=a("p"),TOr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),MOr=l(),In=a("p"),EOr=o("The model class to instantiate is selected based on the "),dLe=a("code"),COr=o("model_type"),wOr=o(` property of the config object (either
passed as an argument or loaded from `),cLe=a("code"),AOr=o("pretrained_model_name_or_path"),LOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mLe=a("code"),yOr=o("pretrained_model_name_or_path"),xOr=o(":"),$Or=l(),le=a("ul"),k0=a("li"),fLe=a("strong"),kOr=o("albert"),SOr=o(" \u2014 "),Kre=a("a"),ROr=o("TFAlbertForPreTraining"),POr=o(" (ALBERT model)"),BOr=l(),S0=a("li"),gLe=a("strong"),IOr=o("bart"),NOr=o(" \u2014 "),ete=a("a"),qOr=o("TFBartForConditionalGeneration"),jOr=o(" (BART model)"),DOr=l(),R0=a("li"),hLe=a("strong"),GOr=o("bert"),OOr=o(" \u2014 "),ote=a("a"),VOr=o("TFBertForPreTraining"),XOr=o(" (BERT model)"),zOr=l(),P0=a("li"),uLe=a("strong"),QOr=o("camembert"),WOr=o(" \u2014 "),rte=a("a"),UOr=o("TFCamembertForMaskedLM"),HOr=o(" (CamemBERT model)"),JOr=l(),B0=a("li"),pLe=a("strong"),YOr=o("ctrl"),ZOr=o(" \u2014 "),tte=a("a"),KOr=o("TFCTRLLMHeadModel"),eVr=o(" (CTRL model)"),oVr=l(),I0=a("li"),_Le=a("strong"),rVr=o("distilbert"),tVr=o(" \u2014 "),ate=a("a"),aVr=o("TFDistilBertForMaskedLM"),nVr=o(" (DistilBERT model)"),sVr=l(),N0=a("li"),bLe=a("strong"),lVr=o("electra"),iVr=o(" \u2014 "),nte=a("a"),dVr=o("TFElectraForPreTraining"),cVr=o(" (ELECTRA model)"),mVr=l(),q0=a("li"),vLe=a("strong"),fVr=o("flaubert"),gVr=o(" \u2014 "),ste=a("a"),hVr=o("TFFlaubertWithLMHeadModel"),uVr=o(" (FlauBERT model)"),pVr=l(),j0=a("li"),FLe=a("strong"),_Vr=o("funnel"),bVr=o(" \u2014 "),lte=a("a"),vVr=o("TFFunnelForPreTraining"),FVr=o(" (Funnel Transformer model)"),TVr=l(),D0=a("li"),TLe=a("strong"),MVr=o("gpt2"),EVr=o(" \u2014 "),ite=a("a"),CVr=o("TFGPT2LMHeadModel"),wVr=o(" (OpenAI GPT-2 model)"),AVr=l(),G0=a("li"),MLe=a("strong"),LVr=o("layoutlm"),yVr=o(" \u2014 "),dte=a("a"),xVr=o("TFLayoutLMForMaskedLM"),$Vr=o(" (LayoutLM model)"),kVr=l(),O0=a("li"),ELe=a("strong"),SVr=o("lxmert"),RVr=o(" \u2014 "),cte=a("a"),PVr=o("TFLxmertForPreTraining"),BVr=o(" (LXMERT model)"),IVr=l(),V0=a("li"),CLe=a("strong"),NVr=o("mobilebert"),qVr=o(" \u2014 "),mte=a("a"),jVr=o("TFMobileBertForPreTraining"),DVr=o(" (MobileBERT model)"),GVr=l(),X0=a("li"),wLe=a("strong"),OVr=o("mpnet"),VVr=o(" \u2014 "),fte=a("a"),XVr=o("TFMPNetForMaskedLM"),zVr=o(" (MPNet model)"),QVr=l(),z0=a("li"),ALe=a("strong"),WVr=o("openai-gpt"),UVr=o(" \u2014 "),gte=a("a"),HVr=o("TFOpenAIGPTLMHeadModel"),JVr=o(" (OpenAI GPT model)"),YVr=l(),Q0=a("li"),LLe=a("strong"),ZVr=o("roberta"),KVr=o(" \u2014 "),hte=a("a"),eXr=o("TFRobertaForMaskedLM"),oXr=o(" (RoBERTa model)"),rXr=l(),W0=a("li"),yLe=a("strong"),tXr=o("t5"),aXr=o(" \u2014 "),ute=a("a"),nXr=o("TFT5ForConditionalGeneration"),sXr=o(" (T5 model)"),lXr=l(),U0=a("li"),xLe=a("strong"),iXr=o("tapas"),dXr=o(" \u2014 "),pte=a("a"),cXr=o("TFTapasForMaskedLM"),mXr=o(" (TAPAS model)"),fXr=l(),H0=a("li"),$Le=a("strong"),gXr=o("transfo-xl"),hXr=o(" \u2014 "),_te=a("a"),uXr=o("TFTransfoXLLMHeadModel"),pXr=o(" (Transformer-XL model)"),_Xr=l(),J0=a("li"),kLe=a("strong"),bXr=o("vit_mae"),vXr=o(" \u2014 "),bte=a("a"),FXr=o("TFViTMAEForPreTraining"),TXr=o(" (ViTMAE model)"),MXr=l(),Y0=a("li"),SLe=a("strong"),EXr=o("xlm"),CXr=o(" \u2014 "),vte=a("a"),wXr=o("TFXLMWithLMHeadModel"),AXr=o(" (XLM model)"),LXr=l(),Z0=a("li"),RLe=a("strong"),yXr=o("xlm-roberta"),xXr=o(" \u2014 "),Fte=a("a"),$Xr=o("TFXLMRobertaForMaskedLM"),kXr=o(" (XLM-RoBERTa model)"),SXr=l(),K0=a("li"),PLe=a("strong"),RXr=o("xlnet"),PXr=o(" \u2014 "),Tte=a("a"),BXr=o("TFXLNetLMHeadModel"),IXr=o(" (XLNet model)"),NXr=l(),F(ew.$$.fragment),lao=l(),hm=a("h2"),ow=a("a"),BLe=a("span"),F(uR.$$.fragment),qXr=l(),ILe=a("span"),jXr=o("TFAutoModelForCausalLM"),iao=l(),fr=a("div"),F(pR.$$.fragment),DXr=l(),um=a("p"),GXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Mte=a("a"),OXr=o("from_pretrained()"),VXr=o(" class method or the "),Ete=a("a"),XXr=o("from_config()"),zXr=o(` class
method.`),QXr=l(),_R=a("p"),WXr=o("This class cannot be instantiated directly using "),NLe=a("code"),UXr=o("__init__()"),HXr=o(" (throws an error)."),JXr=l(),Zt=a("div"),F(bR.$$.fragment),YXr=l(),qLe=a("p"),ZXr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),KXr=l(),pm=a("p"),ezr=o(`Note:
Loading a model from its configuration file does `),jLe=a("strong"),ozr=o("not"),rzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cte=a("a"),tzr=o("from_pretrained()"),azr=o(" to load the model weights."),nzr=l(),F(rw.$$.fragment),szr=l(),Or=a("div"),F(vR.$$.fragment),lzr=l(),DLe=a("p"),izr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),dzr=l(),Nn=a("p"),czr=o("The model class to instantiate is selected based on the "),GLe=a("code"),mzr=o("model_type"),fzr=o(` property of the config object (either
passed as an argument or loaded from `),OLe=a("code"),gzr=o("pretrained_model_name_or_path"),hzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VLe=a("code"),uzr=o("pretrained_model_name_or_path"),pzr=o(":"),_zr=l(),Me=a("ul"),tw=a("li"),XLe=a("strong"),bzr=o("bert"),vzr=o(" \u2014 "),wte=a("a"),Fzr=o("TFBertLMHeadModel"),Tzr=o(" (BERT model)"),Mzr=l(),aw=a("li"),zLe=a("strong"),Ezr=o("camembert"),Czr=o(" \u2014 "),Ate=a("a"),wzr=o("TFCamembertForCausalLM"),Azr=o(" (CamemBERT model)"),Lzr=l(),nw=a("li"),QLe=a("strong"),yzr=o("ctrl"),xzr=o(" \u2014 "),Lte=a("a"),$zr=o("TFCTRLLMHeadModel"),kzr=o(" (CTRL model)"),Szr=l(),sw=a("li"),WLe=a("strong"),Rzr=o("gpt2"),Pzr=o(" \u2014 "),yte=a("a"),Bzr=o("TFGPT2LMHeadModel"),Izr=o(" (OpenAI GPT-2 model)"),Nzr=l(),lw=a("li"),ULe=a("strong"),qzr=o("gptj"),jzr=o(" \u2014 "),xte=a("a"),Dzr=o("TFGPTJForCausalLM"),Gzr=o(" (GPT-J model)"),Ozr=l(),iw=a("li"),HLe=a("strong"),Vzr=o("openai-gpt"),Xzr=o(" \u2014 "),$te=a("a"),zzr=o("TFOpenAIGPTLMHeadModel"),Qzr=o(" (OpenAI GPT model)"),Wzr=l(),dw=a("li"),JLe=a("strong"),Uzr=o("opt"),Hzr=o(" \u2014 "),kte=a("a"),Jzr=o("TFOPTForCausalLM"),Yzr=o(" (OPT model)"),Zzr=l(),cw=a("li"),YLe=a("strong"),Kzr=o("rembert"),eQr=o(" \u2014 "),Ste=a("a"),oQr=o("TFRemBertForCausalLM"),rQr=o(" (RemBERT model)"),tQr=l(),mw=a("li"),ZLe=a("strong"),aQr=o("roberta"),nQr=o(" \u2014 "),Rte=a("a"),sQr=o("TFRobertaForCausalLM"),lQr=o(" (RoBERTa model)"),iQr=l(),fw=a("li"),KLe=a("strong"),dQr=o("roformer"),cQr=o(" \u2014 "),Pte=a("a"),mQr=o("TFRoFormerForCausalLM"),fQr=o(" (RoFormer model)"),gQr=l(),gw=a("li"),e8e=a("strong"),hQr=o("transfo-xl"),uQr=o(" \u2014 "),Bte=a("a"),pQr=o("TFTransfoXLLMHeadModel"),_Qr=o(" (Transformer-XL model)"),bQr=l(),hw=a("li"),o8e=a("strong"),vQr=o("xglm"),FQr=o(" \u2014 "),Ite=a("a"),TQr=o("TFXGLMForCausalLM"),MQr=o(" (XGLM model)"),EQr=l(),uw=a("li"),r8e=a("strong"),CQr=o("xlm"),wQr=o(" \u2014 "),Nte=a("a"),AQr=o("TFXLMWithLMHeadModel"),LQr=o(" (XLM model)"),yQr=l(),pw=a("li"),t8e=a("strong"),xQr=o("xlnet"),$Qr=o(" \u2014 "),qte=a("a"),kQr=o("TFXLNetLMHeadModel"),SQr=o(" (XLNet model)"),RQr=l(),F(_w.$$.fragment),dao=l(),_m=a("h2"),bw=a("a"),a8e=a("span"),F(FR.$$.fragment),PQr=l(),n8e=a("span"),BQr=o("TFAutoModelForImageClassification"),cao=l(),gr=a("div"),F(TR.$$.fragment),IQr=l(),bm=a("p"),NQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jte=a("a"),qQr=o("from_pretrained()"),jQr=o(" class method or the "),Dte=a("a"),DQr=o("from_config()"),GQr=o(` class
method.`),OQr=l(),MR=a("p"),VQr=o("This class cannot be instantiated directly using "),s8e=a("code"),XQr=o("__init__()"),zQr=o(" (throws an error)."),QQr=l(),Kt=a("div"),F(ER.$$.fragment),WQr=l(),l8e=a("p"),UQr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),HQr=l(),vm=a("p"),JQr=o(`Note:
Loading a model from its configuration file does `),i8e=a("strong"),YQr=o("not"),ZQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("a"),KQr=o("from_pretrained()"),eWr=o(" to load the model weights."),oWr=l(),F(vw.$$.fragment),rWr=l(),Vr=a("div"),F(CR.$$.fragment),tWr=l(),d8e=a("p"),aWr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),nWr=l(),qn=a("p"),sWr=o("The model class to instantiate is selected based on the "),c8e=a("code"),lWr=o("model_type"),iWr=o(` property of the config object (either
passed as an argument or loaded from `),m8e=a("code"),dWr=o("pretrained_model_name_or_path"),cWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f8e=a("code"),mWr=o("pretrained_model_name_or_path"),fWr=o(":"),gWr=l(),ye=a("ul"),Fw=a("li"),g8e=a("strong"),hWr=o("convnext"),uWr=o(" \u2014 "),Ote=a("a"),pWr=o("TFConvNextForImageClassification"),_Wr=o(" (ConvNeXT model)"),bWr=l(),Tw=a("li"),h8e=a("strong"),vWr=o("cvt"),FWr=o(" \u2014 "),Vte=a("a"),TWr=o("TFCvtForImageClassification"),MWr=o(" (CvT model)"),EWr=l(),Mw=a("li"),u8e=a("strong"),CWr=o("data2vec-vision"),wWr=o(" \u2014 "),Xte=a("a"),AWr=o("TFData2VecVisionForImageClassification"),LWr=o(" (Data2VecVision model)"),yWr=l(),Sl=a("li"),p8e=a("strong"),xWr=o("deit"),$Wr=o(" \u2014 "),zte=a("a"),kWr=o("TFDeiTForImageClassification"),SWr=o(" or "),Qte=a("a"),RWr=o("TFDeiTForImageClassificationWithTeacher"),PWr=o(" (DeiT model)"),BWr=l(),Ew=a("li"),_8e=a("strong"),IWr=o("mobilevit"),NWr=o(" \u2014 "),Wte=a("a"),qWr=o("TFMobileViTForImageClassification"),jWr=o(" (MobileViT model)"),DWr=l(),Cw=a("li"),b8e=a("strong"),GWr=o("regnet"),OWr=o(" \u2014 "),Ute=a("a"),VWr=o("TFRegNetForImageClassification"),XWr=o(" (RegNet model)"),zWr=l(),ww=a("li"),v8e=a("strong"),QWr=o("resnet"),WWr=o(" \u2014 "),Hte=a("a"),UWr=o("TFResNetForImageClassification"),HWr=o(" (ResNet model)"),JWr=l(),Aw=a("li"),F8e=a("strong"),YWr=o("segformer"),ZWr=o(" \u2014 "),Jte=a("a"),KWr=o("TFSegformerForImageClassification"),eUr=o(" (SegFormer model)"),oUr=l(),Lw=a("li"),T8e=a("strong"),rUr=o("swin"),tUr=o(" \u2014 "),Yte=a("a"),aUr=o("TFSwinForImageClassification"),nUr=o(" (Swin Transformer model)"),sUr=l(),yw=a("li"),M8e=a("strong"),lUr=o("vit"),iUr=o(" \u2014 "),Zte=a("a"),dUr=o("TFViTForImageClassification"),cUr=o(" (ViT model)"),mUr=l(),F(xw.$$.fragment),mao=l(),Fm=a("h2"),$w=a("a"),E8e=a("span"),F(wR.$$.fragment),fUr=l(),C8e=a("span"),gUr=o("TFAutoModelForSemanticSegmentation"),fao=l(),hr=a("div"),F(AR.$$.fragment),hUr=l(),Tm=a("p"),uUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Kte=a("a"),pUr=o("from_pretrained()"),_Ur=o(" class method or the "),eae=a("a"),bUr=o("from_config()"),vUr=o(` class
method.`),FUr=l(),LR=a("p"),TUr=o("This class cannot be instantiated directly using "),w8e=a("code"),MUr=o("__init__()"),EUr=o(" (throws an error)."),CUr=l(),ea=a("div"),F(yR.$$.fragment),wUr=l(),A8e=a("p"),AUr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),LUr=l(),Mm=a("p"),yUr=o(`Note:
Loading a model from its configuration file does `),L8e=a("strong"),xUr=o("not"),$Ur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oae=a("a"),kUr=o("from_pretrained()"),SUr=o(" to load the model weights."),RUr=l(),F(kw.$$.fragment),PUr=l(),Xr=a("div"),F(xR.$$.fragment),BUr=l(),y8e=a("p"),IUr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),NUr=l(),jn=a("p"),qUr=o("The model class to instantiate is selected based on the "),x8e=a("code"),jUr=o("model_type"),DUr=o(` property of the config object (either
passed as an argument or loaded from `),$8e=a("code"),GUr=o("pretrained_model_name_or_path"),OUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k8e=a("code"),VUr=o("pretrained_model_name_or_path"),XUr=o(":"),zUr=l(),Em=a("ul"),Sw=a("li"),S8e=a("strong"),QUr=o("data2vec-vision"),WUr=o(" \u2014 "),rae=a("a"),UUr=o("TFData2VecVisionForSemanticSegmentation"),HUr=o(" (Data2VecVision model)"),JUr=l(),Rw=a("li"),R8e=a("strong"),YUr=o("mobilevit"),ZUr=o(" \u2014 "),tae=a("a"),KUr=o("TFMobileViTForSemanticSegmentation"),eHr=o(" (MobileViT model)"),oHr=l(),Pw=a("li"),P8e=a("strong"),rHr=o("segformer"),tHr=o(" \u2014 "),aae=a("a"),aHr=o("TFSegformerForSemanticSegmentation"),nHr=o(" (SegFormer model)"),sHr=l(),F(Bw.$$.fragment),gao=l(),Cm=a("h2"),Iw=a("a"),B8e=a("span"),F($R.$$.fragment),lHr=l(),I8e=a("span"),iHr=o("TFAutoModelForMaskedLM"),hao=l(),ur=a("div"),F(kR.$$.fragment),dHr=l(),wm=a("p"),cHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),nae=a("a"),mHr=o("from_pretrained()"),fHr=o(" class method or the "),sae=a("a"),gHr=o("from_config()"),hHr=o(` class
method.`),uHr=l(),SR=a("p"),pHr=o("This class cannot be instantiated directly using "),N8e=a("code"),_Hr=o("__init__()"),bHr=o(" (throws an error)."),vHr=l(),oa=a("div"),F(RR.$$.fragment),FHr=l(),q8e=a("p"),THr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),MHr=l(),Am=a("p"),EHr=o(`Note:
Loading a model from its configuration file does `),j8e=a("strong"),CHr=o("not"),wHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=a("a"),AHr=o("from_pretrained()"),LHr=o(" to load the model weights."),yHr=l(),F(Nw.$$.fragment),xHr=l(),zr=a("div"),F(PR.$$.fragment),$Hr=l(),D8e=a("p"),kHr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),SHr=l(),Dn=a("p"),RHr=o("The model class to instantiate is selected based on the "),G8e=a("code"),PHr=o("model_type"),BHr=o(` property of the config object (either
passed as an argument or loaded from `),O8e=a("code"),IHr=o("pretrained_model_name_or_path"),NHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V8e=a("code"),qHr=o("pretrained_model_name_or_path"),jHr=o(":"),DHr=l(),ge=a("ul"),qw=a("li"),X8e=a("strong"),GHr=o("albert"),OHr=o(" \u2014 "),iae=a("a"),VHr=o("TFAlbertForMaskedLM"),XHr=o(" (ALBERT model)"),zHr=l(),jw=a("li"),z8e=a("strong"),QHr=o("bert"),WHr=o(" \u2014 "),dae=a("a"),UHr=o("TFBertForMaskedLM"),HHr=o(" (BERT model)"),JHr=l(),Dw=a("li"),Q8e=a("strong"),YHr=o("camembert"),ZHr=o(" \u2014 "),cae=a("a"),KHr=o("TFCamembertForMaskedLM"),eJr=o(" (CamemBERT model)"),oJr=l(),Gw=a("li"),W8e=a("strong"),rJr=o("convbert"),tJr=o(" \u2014 "),mae=a("a"),aJr=o("TFConvBertForMaskedLM"),nJr=o(" (ConvBERT model)"),sJr=l(),Ow=a("li"),U8e=a("strong"),lJr=o("deberta"),iJr=o(" \u2014 "),fae=a("a"),dJr=o("TFDebertaForMaskedLM"),cJr=o(" (DeBERTa model)"),mJr=l(),Vw=a("li"),H8e=a("strong"),fJr=o("deberta-v2"),gJr=o(" \u2014 "),gae=a("a"),hJr=o("TFDebertaV2ForMaskedLM"),uJr=o(" (DeBERTa-v2 model)"),pJr=l(),Xw=a("li"),J8e=a("strong"),_Jr=o("distilbert"),bJr=o(" \u2014 "),hae=a("a"),vJr=o("TFDistilBertForMaskedLM"),FJr=o(" (DistilBERT model)"),TJr=l(),zw=a("li"),Y8e=a("strong"),MJr=o("electra"),EJr=o(" \u2014 "),uae=a("a"),CJr=o("TFElectraForMaskedLM"),wJr=o(" (ELECTRA model)"),AJr=l(),Qw=a("li"),Z8e=a("strong"),LJr=o("flaubert"),yJr=o(" \u2014 "),pae=a("a"),xJr=o("TFFlaubertWithLMHeadModel"),$Jr=o(" (FlauBERT model)"),kJr=l(),Ww=a("li"),K8e=a("strong"),SJr=o("funnel"),RJr=o(" \u2014 "),_ae=a("a"),PJr=o("TFFunnelForMaskedLM"),BJr=o(" (Funnel Transformer model)"),IJr=l(),Uw=a("li"),eye=a("strong"),NJr=o("layoutlm"),qJr=o(" \u2014 "),bae=a("a"),jJr=o("TFLayoutLMForMaskedLM"),DJr=o(" (LayoutLM model)"),GJr=l(),Hw=a("li"),oye=a("strong"),OJr=o("longformer"),VJr=o(" \u2014 "),vae=a("a"),XJr=o("TFLongformerForMaskedLM"),zJr=o(" (Longformer model)"),QJr=l(),Jw=a("li"),rye=a("strong"),WJr=o("mobilebert"),UJr=o(" \u2014 "),Fae=a("a"),HJr=o("TFMobileBertForMaskedLM"),JJr=o(" (MobileBERT model)"),YJr=l(),Yw=a("li"),tye=a("strong"),ZJr=o("mpnet"),KJr=o(" \u2014 "),Tae=a("a"),eYr=o("TFMPNetForMaskedLM"),oYr=o(" (MPNet model)"),rYr=l(),Zw=a("li"),aye=a("strong"),tYr=o("rembert"),aYr=o(" \u2014 "),Mae=a("a"),nYr=o("TFRemBertForMaskedLM"),sYr=o(" (RemBERT model)"),lYr=l(),Kw=a("li"),nye=a("strong"),iYr=o("roberta"),dYr=o(" \u2014 "),Eae=a("a"),cYr=o("TFRobertaForMaskedLM"),mYr=o(" (RoBERTa model)"),fYr=l(),eA=a("li"),sye=a("strong"),gYr=o("roformer"),hYr=o(" \u2014 "),Cae=a("a"),uYr=o("TFRoFormerForMaskedLM"),pYr=o(" (RoFormer model)"),_Yr=l(),oA=a("li"),lye=a("strong"),bYr=o("tapas"),vYr=o(" \u2014 "),wae=a("a"),FYr=o("TFTapasForMaskedLM"),TYr=o(" (TAPAS model)"),MYr=l(),rA=a("li"),iye=a("strong"),EYr=o("xlm"),CYr=o(" \u2014 "),Aae=a("a"),wYr=o("TFXLMWithLMHeadModel"),AYr=o(" (XLM model)"),LYr=l(),tA=a("li"),dye=a("strong"),yYr=o("xlm-roberta"),xYr=o(" \u2014 "),Lae=a("a"),$Yr=o("TFXLMRobertaForMaskedLM"),kYr=o(" (XLM-RoBERTa model)"),SYr=l(),F(aA.$$.fragment),uao=l(),Lm=a("h2"),nA=a("a"),cye=a("span"),F(BR.$$.fragment),RYr=l(),mye=a("span"),PYr=o("TFAutoModelForSeq2SeqLM"),pao=l(),pr=a("div"),F(IR.$$.fragment),BYr=l(),ym=a("p"),IYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yae=a("a"),NYr=o("from_pretrained()"),qYr=o(" class method or the "),xae=a("a"),jYr=o("from_config()"),DYr=o(` class
method.`),GYr=l(),NR=a("p"),OYr=o("This class cannot be instantiated directly using "),fye=a("code"),VYr=o("__init__()"),XYr=o(" (throws an error)."),zYr=l(),ra=a("div"),F(qR.$$.fragment),QYr=l(),gye=a("p"),WYr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),UYr=l(),xm=a("p"),HYr=o(`Note:
Loading a model from its configuration file does `),hye=a("strong"),JYr=o("not"),YYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ae=a("a"),ZYr=o("from_pretrained()"),KYr=o(" to load the model weights."),eZr=l(),F(sA.$$.fragment),oZr=l(),Qr=a("div"),F(jR.$$.fragment),rZr=l(),uye=a("p"),tZr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),aZr=l(),Gn=a("p"),nZr=o("The model class to instantiate is selected based on the "),pye=a("code"),sZr=o("model_type"),lZr=o(` property of the config object (either
passed as an argument or loaded from `),_ye=a("code"),iZr=o("pretrained_model_name_or_path"),dZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bye=a("code"),cZr=o("pretrained_model_name_or_path"),mZr=o(":"),fZr=l(),xe=a("ul"),lA=a("li"),vye=a("strong"),gZr=o("bart"),hZr=o(" \u2014 "),kae=a("a"),uZr=o("TFBartForConditionalGeneration"),pZr=o(" (BART model)"),_Zr=l(),iA=a("li"),Fye=a("strong"),bZr=o("blenderbot"),vZr=o(" \u2014 "),Sae=a("a"),FZr=o("TFBlenderbotForConditionalGeneration"),TZr=o(" (Blenderbot model)"),MZr=l(),dA=a("li"),Tye=a("strong"),EZr=o("blenderbot-small"),CZr=o(" \u2014 "),Rae=a("a"),wZr=o("TFBlenderbotSmallForConditionalGeneration"),AZr=o(" (BlenderbotSmall model)"),LZr=l(),cA=a("li"),Mye=a("strong"),yZr=o("encoder-decoder"),xZr=o(" \u2014 "),Pae=a("a"),$Zr=o("TFEncoderDecoderModel"),kZr=o(" (Encoder decoder model)"),SZr=l(),mA=a("li"),Eye=a("strong"),RZr=o("led"),PZr=o(" \u2014 "),Bae=a("a"),BZr=o("TFLEDForConditionalGeneration"),IZr=o(" (LED model)"),NZr=l(),fA=a("li"),Cye=a("strong"),qZr=o("marian"),jZr=o(" \u2014 "),Iae=a("a"),DZr=o("TFMarianMTModel"),GZr=o(" (Marian model)"),OZr=l(),gA=a("li"),wye=a("strong"),VZr=o("mbart"),XZr=o(" \u2014 "),Nae=a("a"),zZr=o("TFMBartForConditionalGeneration"),QZr=o(" (mBART model)"),WZr=l(),hA=a("li"),Aye=a("strong"),UZr=o("mt5"),HZr=o(" \u2014 "),qae=a("a"),JZr=o("TFMT5ForConditionalGeneration"),YZr=o(" (MT5 model)"),ZZr=l(),uA=a("li"),Lye=a("strong"),KZr=o("pegasus"),eKr=o(" \u2014 "),jae=a("a"),oKr=o("TFPegasusForConditionalGeneration"),rKr=o(" (Pegasus model)"),tKr=l(),pA=a("li"),yye=a("strong"),aKr=o("t5"),nKr=o(" \u2014 "),Dae=a("a"),sKr=o("TFT5ForConditionalGeneration"),lKr=o(" (T5 model)"),iKr=l(),F(_A.$$.fragment),_ao=l(),$m=a("h2"),bA=a("a"),xye=a("span"),F(DR.$$.fragment),dKr=l(),$ye=a("span"),cKr=o("TFAutoModelForSequenceClassification"),bao=l(),_r=a("div"),F(GR.$$.fragment),mKr=l(),km=a("p"),fKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Gae=a("a"),gKr=o("from_pretrained()"),hKr=o(" class method or the "),Oae=a("a"),uKr=o("from_config()"),pKr=o(` class
method.`),_Kr=l(),OR=a("p"),bKr=o("This class cannot be instantiated directly using "),kye=a("code"),vKr=o("__init__()"),FKr=o(" (throws an error)."),TKr=l(),ta=a("div"),F(VR.$$.fragment),MKr=l(),Sye=a("p"),EKr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),CKr=l(),Sm=a("p"),wKr=o(`Note:
Loading a model from its configuration file does `),Rye=a("strong"),AKr=o("not"),LKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vae=a("a"),yKr=o("from_pretrained()"),xKr=o(" to load the model weights."),$Kr=l(),F(vA.$$.fragment),kKr=l(),Wr=a("div"),F(XR.$$.fragment),SKr=l(),Pye=a("p"),RKr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),PKr=l(),On=a("p"),BKr=o("The model class to instantiate is selected based on the "),Bye=a("code"),IKr=o("model_type"),NKr=o(` property of the config object (either
passed as an argument or loaded from `),Iye=a("code"),qKr=o("pretrained_model_name_or_path"),jKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nye=a("code"),DKr=o("pretrained_model_name_or_path"),GKr=o(":"),OKr=l(),re=a("ul"),FA=a("li"),qye=a("strong"),VKr=o("albert"),XKr=o(" \u2014 "),Xae=a("a"),zKr=o("TFAlbertForSequenceClassification"),QKr=o(" (ALBERT model)"),WKr=l(),TA=a("li"),jye=a("strong"),UKr=o("bert"),HKr=o(" \u2014 "),zae=a("a"),JKr=o("TFBertForSequenceClassification"),YKr=o(" (BERT model)"),ZKr=l(),MA=a("li"),Dye=a("strong"),KKr=o("camembert"),eet=o(" \u2014 "),Qae=a("a"),oet=o("TFCamembertForSequenceClassification"),ret=o(" (CamemBERT model)"),tet=l(),EA=a("li"),Gye=a("strong"),aet=o("convbert"),net=o(" \u2014 "),Wae=a("a"),set=o("TFConvBertForSequenceClassification"),iet=o(" (ConvBERT model)"),det=l(),CA=a("li"),Oye=a("strong"),cet=o("ctrl"),met=o(" \u2014 "),Uae=a("a"),fet=o("TFCTRLForSequenceClassification"),get=o(" (CTRL model)"),het=l(),wA=a("li"),Vye=a("strong"),uet=o("deberta"),pet=o(" \u2014 "),Hae=a("a"),_et=o("TFDebertaForSequenceClassification"),bet=o(" (DeBERTa model)"),vet=l(),AA=a("li"),Xye=a("strong"),Fet=o("deberta-v2"),Tet=o(" \u2014 "),Jae=a("a"),Met=o("TFDebertaV2ForSequenceClassification"),Eet=o(" (DeBERTa-v2 model)"),Cet=l(),LA=a("li"),zye=a("strong"),wet=o("distilbert"),Aet=o(" \u2014 "),Yae=a("a"),Let=o("TFDistilBertForSequenceClassification"),yet=o(" (DistilBERT model)"),xet=l(),yA=a("li"),Qye=a("strong"),$et=o("electra"),ket=o(" \u2014 "),Zae=a("a"),Set=o("TFElectraForSequenceClassification"),Ret=o(" (ELECTRA model)"),Pet=l(),xA=a("li"),Wye=a("strong"),Bet=o("flaubert"),Iet=o(" \u2014 "),Kae=a("a"),Net=o("TFFlaubertForSequenceClassification"),qet=o(" (FlauBERT model)"),jet=l(),$A=a("li"),Uye=a("strong"),Det=o("funnel"),Get=o(" \u2014 "),ene=a("a"),Oet=o("TFFunnelForSequenceClassification"),Vet=o(" (Funnel Transformer model)"),Xet=l(),kA=a("li"),Hye=a("strong"),zet=o("gpt2"),Qet=o(" \u2014 "),one=a("a"),Wet=o("TFGPT2ForSequenceClassification"),Uet=o(" (OpenAI GPT-2 model)"),Het=l(),SA=a("li"),Jye=a("strong"),Jet=o("gptj"),Yet=o(" \u2014 "),rne=a("a"),Zet=o("TFGPTJForSequenceClassification"),Ket=o(" (GPT-J model)"),eot=l(),RA=a("li"),Yye=a("strong"),oot=o("layoutlm"),rot=o(" \u2014 "),tne=a("a"),tot=o("TFLayoutLMForSequenceClassification"),aot=o(" (LayoutLM model)"),not=l(),PA=a("li"),Zye=a("strong"),sot=o("layoutlmv3"),lot=o(" \u2014 "),ane=a("a"),iot=o("TFLayoutLMv3ForSequenceClassification"),dot=o(" (LayoutLMv3 model)"),cot=l(),BA=a("li"),Kye=a("strong"),mot=o("longformer"),fot=o(" \u2014 "),nne=a("a"),got=o("TFLongformerForSequenceClassification"),hot=o(" (Longformer model)"),uot=l(),IA=a("li"),e9e=a("strong"),pot=o("mobilebert"),_ot=o(" \u2014 "),sne=a("a"),bot=o("TFMobileBertForSequenceClassification"),vot=o(" (MobileBERT model)"),Fot=l(),NA=a("li"),o9e=a("strong"),Tot=o("mpnet"),Mot=o(" \u2014 "),lne=a("a"),Eot=o("TFMPNetForSequenceClassification"),Cot=o(" (MPNet model)"),wot=l(),qA=a("li"),r9e=a("strong"),Aot=o("openai-gpt"),Lot=o(" \u2014 "),ine=a("a"),yot=o("TFOpenAIGPTForSequenceClassification"),xot=o(" (OpenAI GPT model)"),$ot=l(),jA=a("li"),t9e=a("strong"),kot=o("rembert"),Sot=o(" \u2014 "),dne=a("a"),Rot=o("TFRemBertForSequenceClassification"),Pot=o(" (RemBERT model)"),Bot=l(),DA=a("li"),a9e=a("strong"),Iot=o("roberta"),Not=o(" \u2014 "),cne=a("a"),qot=o("TFRobertaForSequenceClassification"),jot=o(" (RoBERTa model)"),Dot=l(),GA=a("li"),n9e=a("strong"),Got=o("roformer"),Oot=o(" \u2014 "),mne=a("a"),Vot=o("TFRoFormerForSequenceClassification"),Xot=o(" (RoFormer model)"),zot=l(),OA=a("li"),s9e=a("strong"),Qot=o("tapas"),Wot=o(" \u2014 "),fne=a("a"),Uot=o("TFTapasForSequenceClassification"),Hot=o(" (TAPAS model)"),Jot=l(),VA=a("li"),l9e=a("strong"),Yot=o("transfo-xl"),Zot=o(" \u2014 "),gne=a("a"),Kot=o("TFTransfoXLForSequenceClassification"),ert=o(" (Transformer-XL model)"),ort=l(),XA=a("li"),i9e=a("strong"),rrt=o("xlm"),trt=o(" \u2014 "),hne=a("a"),art=o("TFXLMForSequenceClassification"),nrt=o(" (XLM model)"),srt=l(),zA=a("li"),d9e=a("strong"),lrt=o("xlm-roberta"),irt=o(" \u2014 "),une=a("a"),drt=o("TFXLMRobertaForSequenceClassification"),crt=o(" (XLM-RoBERTa model)"),mrt=l(),QA=a("li"),c9e=a("strong"),frt=o("xlnet"),grt=o(" \u2014 "),pne=a("a"),hrt=o("TFXLNetForSequenceClassification"),urt=o(" (XLNet model)"),prt=l(),F(WA.$$.fragment),vao=l(),Rm=a("h2"),UA=a("a"),m9e=a("span"),F(zR.$$.fragment),_rt=l(),f9e=a("span"),brt=o("TFAutoModelForMultipleChoice"),Fao=l(),br=a("div"),F(QR.$$.fragment),vrt=l(),Pm=a("p"),Frt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_ne=a("a"),Trt=o("from_pretrained()"),Mrt=o(" class method or the "),bne=a("a"),Ert=o("from_config()"),Crt=o(` class
method.`),wrt=l(),WR=a("p"),Art=o("This class cannot be instantiated directly using "),g9e=a("code"),Lrt=o("__init__()"),yrt=o(" (throws an error)."),xrt=l(),aa=a("div"),F(UR.$$.fragment),$rt=l(),h9e=a("p"),krt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Srt=l(),Bm=a("p"),Rrt=o(`Note:
Loading a model from its configuration file does `),u9e=a("strong"),Prt=o("not"),Brt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vne=a("a"),Irt=o("from_pretrained()"),Nrt=o(" to load the model weights."),qrt=l(),F(HA.$$.fragment),jrt=l(),Ur=a("div"),F(HR.$$.fragment),Drt=l(),p9e=a("p"),Grt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Ort=l(),Vn=a("p"),Vrt=o("The model class to instantiate is selected based on the "),_9e=a("code"),Xrt=o("model_type"),zrt=o(` property of the config object (either
passed as an argument or loaded from `),b9e=a("code"),Qrt=o("pretrained_model_name_or_path"),Wrt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v9e=a("code"),Urt=o("pretrained_model_name_or_path"),Hrt=o(":"),Jrt=l(),ve=a("ul"),JA=a("li"),F9e=a("strong"),Yrt=o("albert"),Zrt=o(" \u2014 "),Fne=a("a"),Krt=o("TFAlbertForMultipleChoice"),ett=o(" (ALBERT model)"),ott=l(),YA=a("li"),T9e=a("strong"),rtt=o("bert"),ttt=o(" \u2014 "),Tne=a("a"),att=o("TFBertForMultipleChoice"),ntt=o(" (BERT model)"),stt=l(),ZA=a("li"),M9e=a("strong"),ltt=o("camembert"),itt=o(" \u2014 "),Mne=a("a"),dtt=o("TFCamembertForMultipleChoice"),ctt=o(" (CamemBERT model)"),mtt=l(),KA=a("li"),E9e=a("strong"),ftt=o("convbert"),gtt=o(" \u2014 "),Ene=a("a"),htt=o("TFConvBertForMultipleChoice"),utt=o(" (ConvBERT model)"),ptt=l(),e6=a("li"),C9e=a("strong"),_tt=o("distilbert"),btt=o(" \u2014 "),Cne=a("a"),vtt=o("TFDistilBertForMultipleChoice"),Ftt=o(" (DistilBERT model)"),Ttt=l(),o6=a("li"),w9e=a("strong"),Mtt=o("electra"),Ett=o(" \u2014 "),wne=a("a"),Ctt=o("TFElectraForMultipleChoice"),wtt=o(" (ELECTRA model)"),Att=l(),r6=a("li"),A9e=a("strong"),Ltt=o("flaubert"),ytt=o(" \u2014 "),Ane=a("a"),xtt=o("TFFlaubertForMultipleChoice"),$tt=o(" (FlauBERT model)"),ktt=l(),t6=a("li"),L9e=a("strong"),Stt=o("funnel"),Rtt=o(" \u2014 "),Lne=a("a"),Ptt=o("TFFunnelForMultipleChoice"),Btt=o(" (Funnel Transformer model)"),Itt=l(),a6=a("li"),y9e=a("strong"),Ntt=o("longformer"),qtt=o(" \u2014 "),yne=a("a"),jtt=o("TFLongformerForMultipleChoice"),Dtt=o(" (Longformer model)"),Gtt=l(),n6=a("li"),x9e=a("strong"),Ott=o("mobilebert"),Vtt=o(" \u2014 "),xne=a("a"),Xtt=o("TFMobileBertForMultipleChoice"),ztt=o(" (MobileBERT model)"),Qtt=l(),s6=a("li"),$9e=a("strong"),Wtt=o("mpnet"),Utt=o(" \u2014 "),$ne=a("a"),Htt=o("TFMPNetForMultipleChoice"),Jtt=o(" (MPNet model)"),Ytt=l(),l6=a("li"),k9e=a("strong"),Ztt=o("rembert"),Ktt=o(" \u2014 "),kne=a("a"),eat=o("TFRemBertForMultipleChoice"),oat=o(" (RemBERT model)"),rat=l(),i6=a("li"),S9e=a("strong"),tat=o("roberta"),aat=o(" \u2014 "),Sne=a("a"),nat=o("TFRobertaForMultipleChoice"),sat=o(" (RoBERTa model)"),lat=l(),d6=a("li"),R9e=a("strong"),iat=o("roformer"),dat=o(" \u2014 "),Rne=a("a"),cat=o("TFRoFormerForMultipleChoice"),mat=o(" (RoFormer model)"),fat=l(),c6=a("li"),P9e=a("strong"),gat=o("xlm"),hat=o(" \u2014 "),Pne=a("a"),uat=o("TFXLMForMultipleChoice"),pat=o(" (XLM model)"),_at=l(),m6=a("li"),B9e=a("strong"),bat=o("xlm-roberta"),vat=o(" \u2014 "),Bne=a("a"),Fat=o("TFXLMRobertaForMultipleChoice"),Tat=o(" (XLM-RoBERTa model)"),Mat=l(),f6=a("li"),I9e=a("strong"),Eat=o("xlnet"),Cat=o(" \u2014 "),Ine=a("a"),wat=o("TFXLNetForMultipleChoice"),Aat=o(" (XLNet model)"),Lat=l(),F(g6.$$.fragment),Tao=l(),Im=a("h2"),h6=a("a"),N9e=a("span"),F(JR.$$.fragment),yat=l(),q9e=a("span"),xat=o("TFAutoModelForNextSentencePrediction"),Mao=l(),vr=a("div"),F(YR.$$.fragment),$at=l(),Nm=a("p"),kat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Nne=a("a"),Sat=o("from_pretrained()"),Rat=o(" class method or the "),qne=a("a"),Pat=o("from_config()"),Bat=o(` class
method.`),Iat=l(),ZR=a("p"),Nat=o("This class cannot be instantiated directly using "),j9e=a("code"),qat=o("__init__()"),jat=o(" (throws an error)."),Dat=l(),na=a("div"),F(KR.$$.fragment),Gat=l(),D9e=a("p"),Oat=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Vat=l(),qm=a("p"),Xat=o(`Note:
Loading a model from its configuration file does `),G9e=a("strong"),zat=o("not"),Qat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jne=a("a"),Wat=o("from_pretrained()"),Uat=o(" to load the model weights."),Hat=l(),F(u6.$$.fragment),Jat=l(),Hr=a("div"),F(eP.$$.fragment),Yat=l(),O9e=a("p"),Zat=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Kat=l(),Xn=a("p"),ent=o("The model class to instantiate is selected based on the "),V9e=a("code"),ont=o("model_type"),rnt=o(` property of the config object (either
passed as an argument or loaded from `),X9e=a("code"),tnt=o("pretrained_model_name_or_path"),ant=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=a("code"),nnt=o("pretrained_model_name_or_path"),snt=o(":"),lnt=l(),oP=a("ul"),p6=a("li"),Q9e=a("strong"),int=o("bert"),dnt=o(" \u2014 "),Dne=a("a"),cnt=o("TFBertForNextSentencePrediction"),mnt=o(" (BERT model)"),fnt=l(),_6=a("li"),W9e=a("strong"),gnt=o("mobilebert"),hnt=o(" \u2014 "),Gne=a("a"),unt=o("TFMobileBertForNextSentencePrediction"),pnt=o(" (MobileBERT model)"),_nt=l(),F(b6.$$.fragment),Eao=l(),jm=a("h2"),v6=a("a"),U9e=a("span"),F(rP.$$.fragment),bnt=l(),H9e=a("span"),vnt=o("TFAutoModelForTableQuestionAnswering"),Cao=l(),Fr=a("div"),F(tP.$$.fragment),Fnt=l(),Dm=a("p"),Tnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),One=a("a"),Mnt=o("from_pretrained()"),Ent=o(" class method or the "),Vne=a("a"),Cnt=o("from_config()"),wnt=o(` class
method.`),Ant=l(),aP=a("p"),Lnt=o("This class cannot be instantiated directly using "),J9e=a("code"),ynt=o("__init__()"),xnt=o(" (throws an error)."),$nt=l(),sa=a("div"),F(nP.$$.fragment),knt=l(),Y9e=a("p"),Snt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Rnt=l(),Gm=a("p"),Pnt=o(`Note:
Loading a model from its configuration file does `),Z9e=a("strong"),Bnt=o("not"),Int=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xne=a("a"),Nnt=o("from_pretrained()"),qnt=o(" to load the model weights."),jnt=l(),F(F6.$$.fragment),Dnt=l(),Jr=a("div"),F(sP.$$.fragment),Gnt=l(),K9e=a("p"),Ont=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Vnt=l(),zn=a("p"),Xnt=o("The model class to instantiate is selected based on the "),exe=a("code"),znt=o("model_type"),Qnt=o(` property of the config object (either
passed as an argument or loaded from `),oxe=a("code"),Wnt=o("pretrained_model_name_or_path"),Unt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rxe=a("code"),Hnt=o("pretrained_model_name_or_path"),Jnt=o(":"),Ynt=l(),txe=a("ul"),T6=a("li"),axe=a("strong"),Znt=o("tapas"),Knt=o(" \u2014 "),zne=a("a"),est=o("TFTapasForQuestionAnswering"),ost=o(" (TAPAS model)"),rst=l(),F(M6.$$.fragment),wao=l(),Om=a("h2"),E6=a("a"),nxe=a("span"),F(lP.$$.fragment),tst=l(),sxe=a("span"),ast=o("TFAutoModelForDocumentQuestionAnswering"),Aao=l(),Tr=a("div"),F(iP.$$.fragment),nst=l(),Vm=a("p"),sst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Qne=a("a"),lst=o("from_pretrained()"),ist=o(" class method or the "),Wne=a("a"),dst=o("from_config()"),cst=o(` class
method.`),mst=l(),dP=a("p"),fst=o("This class cannot be instantiated directly using "),lxe=a("code"),gst=o("__init__()"),hst=o(" (throws an error)."),ust=l(),la=a("div"),F(cP.$$.fragment),pst=l(),ixe=a("p"),_st=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),bst=l(),Xm=a("p"),vst=o(`Note:
Loading a model from its configuration file does `),dxe=a("strong"),Fst=o("not"),Tst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=a("a"),Mst=o("from_pretrained()"),Est=o(" to load the model weights."),Cst=l(),F(C6.$$.fragment),wst=l(),Yr=a("div"),F(mP.$$.fragment),Ast=l(),cxe=a("p"),Lst=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),yst=l(),Qn=a("p"),xst=o("The model class to instantiate is selected based on the "),mxe=a("code"),$st=o("model_type"),kst=o(` property of the config object (either
passed as an argument or loaded from `),fxe=a("code"),Sst=o("pretrained_model_name_or_path"),Rst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gxe=a("code"),Pst=o("pretrained_model_name_or_path"),Bst=o(":"),Ist=l(),hxe=a("ul"),w6=a("li"),uxe=a("strong"),Nst=o("layoutlm"),qst=o(" \u2014 "),Hne=a("a"),jst=o("TFLayoutLMForQuestionAnswering"),Dst=o(" (LayoutLM model)"),Gst=l(),F(A6.$$.fragment),Lao=l(),zm=a("h2"),L6=a("a"),pxe=a("span"),F(fP.$$.fragment),Ost=l(),_xe=a("span"),Vst=o("TFAutoModelForTokenClassification"),yao=l(),Mr=a("div"),F(gP.$$.fragment),Xst=l(),Qm=a("p"),zst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Jne=a("a"),Qst=o("from_pretrained()"),Wst=o(" class method or the "),Yne=a("a"),Ust=o("from_config()"),Hst=o(` class
method.`),Jst=l(),hP=a("p"),Yst=o("This class cannot be instantiated directly using "),bxe=a("code"),Zst=o("__init__()"),Kst=o(" (throws an error)."),elt=l(),ia=a("div"),F(uP.$$.fragment),olt=l(),vxe=a("p"),rlt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),tlt=l(),Wm=a("p"),alt=o(`Note:
Loading a model from its configuration file does `),Fxe=a("strong"),nlt=o("not"),slt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zne=a("a"),llt=o("from_pretrained()"),ilt=o(" to load the model weights."),dlt=l(),F(y6.$$.fragment),clt=l(),Zr=a("div"),F(pP.$$.fragment),mlt=l(),Txe=a("p"),flt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),glt=l(),Wn=a("p"),hlt=o("The model class to instantiate is selected based on the "),Mxe=a("code"),ult=o("model_type"),plt=o(` property of the config object (either
passed as an argument or loaded from `),Exe=a("code"),_lt=o("pretrained_model_name_or_path"),blt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cxe=a("code"),vlt=o("pretrained_model_name_or_path"),Flt=o(":"),Tlt=l(),ce=a("ul"),x6=a("li"),wxe=a("strong"),Mlt=o("albert"),Elt=o(" \u2014 "),Kne=a("a"),Clt=o("TFAlbertForTokenClassification"),wlt=o(" (ALBERT model)"),Alt=l(),$6=a("li"),Axe=a("strong"),Llt=o("bert"),ylt=o(" \u2014 "),ese=a("a"),xlt=o("TFBertForTokenClassification"),$lt=o(" (BERT model)"),klt=l(),k6=a("li"),Lxe=a("strong"),Slt=o("camembert"),Rlt=o(" \u2014 "),ose=a("a"),Plt=o("TFCamembertForTokenClassification"),Blt=o(" (CamemBERT model)"),Ilt=l(),S6=a("li"),yxe=a("strong"),Nlt=o("convbert"),qlt=o(" \u2014 "),rse=a("a"),jlt=o("TFConvBertForTokenClassification"),Dlt=o(" (ConvBERT model)"),Glt=l(),R6=a("li"),xxe=a("strong"),Olt=o("deberta"),Vlt=o(" \u2014 "),tse=a("a"),Xlt=o("TFDebertaForTokenClassification"),zlt=o(" (DeBERTa model)"),Qlt=l(),P6=a("li"),$xe=a("strong"),Wlt=o("deberta-v2"),Ult=o(" \u2014 "),ase=a("a"),Hlt=o("TFDebertaV2ForTokenClassification"),Jlt=o(" (DeBERTa-v2 model)"),Ylt=l(),B6=a("li"),kxe=a("strong"),Zlt=o("distilbert"),Klt=o(" \u2014 "),nse=a("a"),eit=o("TFDistilBertForTokenClassification"),oit=o(" (DistilBERT model)"),rit=l(),I6=a("li"),Sxe=a("strong"),tit=o("electra"),ait=o(" \u2014 "),sse=a("a"),nit=o("TFElectraForTokenClassification"),sit=o(" (ELECTRA model)"),lit=l(),N6=a("li"),Rxe=a("strong"),iit=o("flaubert"),dit=o(" \u2014 "),lse=a("a"),cit=o("TFFlaubertForTokenClassification"),mit=o(" (FlauBERT model)"),fit=l(),q6=a("li"),Pxe=a("strong"),git=o("funnel"),hit=o(" \u2014 "),ise=a("a"),uit=o("TFFunnelForTokenClassification"),pit=o(" (Funnel Transformer model)"),_it=l(),j6=a("li"),Bxe=a("strong"),bit=o("layoutlm"),vit=o(" \u2014 "),dse=a("a"),Fit=o("TFLayoutLMForTokenClassification"),Tit=o(" (LayoutLM model)"),Mit=l(),D6=a("li"),Ixe=a("strong"),Eit=o("layoutlmv3"),Cit=o(" \u2014 "),cse=a("a"),wit=o("TFLayoutLMv3ForTokenClassification"),Ait=o(" (LayoutLMv3 model)"),Lit=l(),G6=a("li"),Nxe=a("strong"),yit=o("longformer"),xit=o(" \u2014 "),mse=a("a"),$it=o("TFLongformerForTokenClassification"),kit=o(" (Longformer model)"),Sit=l(),O6=a("li"),qxe=a("strong"),Rit=o("mobilebert"),Pit=o(" \u2014 "),fse=a("a"),Bit=o("TFMobileBertForTokenClassification"),Iit=o(" (MobileBERT model)"),Nit=l(),V6=a("li"),jxe=a("strong"),qit=o("mpnet"),jit=o(" \u2014 "),gse=a("a"),Dit=o("TFMPNetForTokenClassification"),Git=o(" (MPNet model)"),Oit=l(),X6=a("li"),Dxe=a("strong"),Vit=o("rembert"),Xit=o(" \u2014 "),hse=a("a"),zit=o("TFRemBertForTokenClassification"),Qit=o(" (RemBERT model)"),Wit=l(),z6=a("li"),Gxe=a("strong"),Uit=o("roberta"),Hit=o(" \u2014 "),use=a("a"),Jit=o("TFRobertaForTokenClassification"),Yit=o(" (RoBERTa model)"),Zit=l(),Q6=a("li"),Oxe=a("strong"),Kit=o("roformer"),edt=o(" \u2014 "),pse=a("a"),odt=o("TFRoFormerForTokenClassification"),rdt=o(" (RoFormer model)"),tdt=l(),W6=a("li"),Vxe=a("strong"),adt=o("xlm"),ndt=o(" \u2014 "),_se=a("a"),sdt=o("TFXLMForTokenClassification"),ldt=o(" (XLM model)"),idt=l(),U6=a("li"),Xxe=a("strong"),ddt=o("xlm-roberta"),cdt=o(" \u2014 "),bse=a("a"),mdt=o("TFXLMRobertaForTokenClassification"),fdt=o(" (XLM-RoBERTa model)"),gdt=l(),H6=a("li"),zxe=a("strong"),hdt=o("xlnet"),udt=o(" \u2014 "),vse=a("a"),pdt=o("TFXLNetForTokenClassification"),_dt=o(" (XLNet model)"),bdt=l(),F(J6.$$.fragment),xao=l(),Um=a("h2"),Y6=a("a"),Qxe=a("span"),F(_P.$$.fragment),vdt=l(),Wxe=a("span"),Fdt=o("TFAutoModelForQuestionAnswering"),$ao=l(),Er=a("div"),F(bP.$$.fragment),Tdt=l(),Hm=a("p"),Mdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Fse=a("a"),Edt=o("from_pretrained()"),Cdt=o(" class method or the "),Tse=a("a"),wdt=o("from_config()"),Adt=o(` class
method.`),Ldt=l(),vP=a("p"),ydt=o("This class cannot be instantiated directly using "),Uxe=a("code"),xdt=o("__init__()"),$dt=o(" (throws an error)."),kdt=l(),da=a("div"),F(FP.$$.fragment),Sdt=l(),Hxe=a("p"),Rdt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Pdt=l(),Jm=a("p"),Bdt=o(`Note:
Loading a model from its configuration file does `),Jxe=a("strong"),Idt=o("not"),Ndt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mse=a("a"),qdt=o("from_pretrained()"),jdt=o(" to load the model weights."),Ddt=l(),F(Z6.$$.fragment),Gdt=l(),Kr=a("div"),F(TP.$$.fragment),Odt=l(),Yxe=a("p"),Vdt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Xdt=l(),Un=a("p"),zdt=o("The model class to instantiate is selected based on the "),Zxe=a("code"),Qdt=o("model_type"),Wdt=o(` property of the config object (either
passed as an argument or loaded from `),Kxe=a("code"),Udt=o("pretrained_model_name_or_path"),Hdt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e$e=a("code"),Jdt=o("pretrained_model_name_or_path"),Ydt=o(":"),Zdt=l(),me=a("ul"),K6=a("li"),o$e=a("strong"),Kdt=o("albert"),ect=o(" \u2014 "),Ese=a("a"),oct=o("TFAlbertForQuestionAnswering"),rct=o(" (ALBERT model)"),tct=l(),e7=a("li"),r$e=a("strong"),act=o("bert"),nct=o(" \u2014 "),Cse=a("a"),sct=o("TFBertForQuestionAnswering"),lct=o(" (BERT model)"),ict=l(),o7=a("li"),t$e=a("strong"),dct=o("camembert"),cct=o(" \u2014 "),wse=a("a"),mct=o("TFCamembertForQuestionAnswering"),fct=o(" (CamemBERT model)"),gct=l(),r7=a("li"),a$e=a("strong"),hct=o("convbert"),uct=o(" \u2014 "),Ase=a("a"),pct=o("TFConvBertForQuestionAnswering"),_ct=o(" (ConvBERT model)"),bct=l(),t7=a("li"),n$e=a("strong"),vct=o("deberta"),Fct=o(" \u2014 "),Lse=a("a"),Tct=o("TFDebertaForQuestionAnswering"),Mct=o(" (DeBERTa model)"),Ect=l(),a7=a("li"),s$e=a("strong"),Cct=o("deberta-v2"),wct=o(" \u2014 "),yse=a("a"),Act=o("TFDebertaV2ForQuestionAnswering"),Lct=o(" (DeBERTa-v2 model)"),yct=l(),n7=a("li"),l$e=a("strong"),xct=o("distilbert"),$ct=o(" \u2014 "),xse=a("a"),kct=o("TFDistilBertForQuestionAnswering"),Sct=o(" (DistilBERT model)"),Rct=l(),s7=a("li"),i$e=a("strong"),Pct=o("electra"),Bct=o(" \u2014 "),$se=a("a"),Ict=o("TFElectraForQuestionAnswering"),Nct=o(" (ELECTRA model)"),qct=l(),l7=a("li"),d$e=a("strong"),jct=o("flaubert"),Dct=o(" \u2014 "),kse=a("a"),Gct=o("TFFlaubertForQuestionAnsweringSimple"),Oct=o(" (FlauBERT model)"),Vct=l(),i7=a("li"),c$e=a("strong"),Xct=o("funnel"),zct=o(" \u2014 "),Sse=a("a"),Qct=o("TFFunnelForQuestionAnswering"),Wct=o(" (Funnel Transformer model)"),Uct=l(),d7=a("li"),m$e=a("strong"),Hct=o("gptj"),Jct=o(" \u2014 "),Rse=a("a"),Yct=o("TFGPTJForQuestionAnswering"),Zct=o(" (GPT-J model)"),Kct=l(),c7=a("li"),f$e=a("strong"),emt=o("layoutlmv3"),omt=o(" \u2014 "),Pse=a("a"),rmt=o("TFLayoutLMv3ForQuestionAnswering"),tmt=o(" (LayoutLMv3 model)"),amt=l(),m7=a("li"),g$e=a("strong"),nmt=o("longformer"),smt=o(" \u2014 "),Bse=a("a"),lmt=o("TFLongformerForQuestionAnswering"),imt=o(" (Longformer model)"),dmt=l(),f7=a("li"),h$e=a("strong"),cmt=o("mobilebert"),mmt=o(" \u2014 "),Ise=a("a"),fmt=o("TFMobileBertForQuestionAnswering"),gmt=o(" (MobileBERT model)"),hmt=l(),g7=a("li"),u$e=a("strong"),umt=o("mpnet"),pmt=o(" \u2014 "),Nse=a("a"),_mt=o("TFMPNetForQuestionAnswering"),bmt=o(" (MPNet model)"),vmt=l(),h7=a("li"),p$e=a("strong"),Fmt=o("rembert"),Tmt=o(" \u2014 "),qse=a("a"),Mmt=o("TFRemBertForQuestionAnswering"),Emt=o(" (RemBERT model)"),Cmt=l(),u7=a("li"),_$e=a("strong"),wmt=o("roberta"),Amt=o(" \u2014 "),jse=a("a"),Lmt=o("TFRobertaForQuestionAnswering"),ymt=o(" (RoBERTa model)"),xmt=l(),p7=a("li"),b$e=a("strong"),$mt=o("roformer"),kmt=o(" \u2014 "),Dse=a("a"),Smt=o("TFRoFormerForQuestionAnswering"),Rmt=o(" (RoFormer model)"),Pmt=l(),_7=a("li"),v$e=a("strong"),Bmt=o("xlm"),Imt=o(" \u2014 "),Gse=a("a"),Nmt=o("TFXLMForQuestionAnsweringSimple"),qmt=o(" (XLM model)"),jmt=l(),b7=a("li"),F$e=a("strong"),Dmt=o("xlm-roberta"),Gmt=o(" \u2014 "),Ose=a("a"),Omt=o("TFXLMRobertaForQuestionAnswering"),Vmt=o(" (XLM-RoBERTa model)"),Xmt=l(),v7=a("li"),T$e=a("strong"),zmt=o("xlnet"),Qmt=o(" \u2014 "),Vse=a("a"),Wmt=o("TFXLNetForQuestionAnsweringSimple"),Umt=o(" (XLNet model)"),Hmt=l(),F(F7.$$.fragment),kao=l(),Ym=a("h2"),T7=a("a"),M$e=a("span"),F(MP.$$.fragment),Jmt=l(),E$e=a("span"),Ymt=o("TFAutoModelForVision2Seq"),Sao=l(),Cr=a("div"),F(EP.$$.fragment),Zmt=l(),Zm=a("p"),Kmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Xse=a("a"),eft=o("from_pretrained()"),oft=o(" class method or the "),zse=a("a"),rft=o("from_config()"),tft=o(` class
method.`),aft=l(),CP=a("p"),nft=o("This class cannot be instantiated directly using "),C$e=a("code"),sft=o("__init__()"),lft=o(" (throws an error)."),ift=l(),ca=a("div"),F(wP.$$.fragment),dft=l(),w$e=a("p"),cft=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),mft=l(),Km=a("p"),fft=o(`Note:
Loading a model from its configuration file does `),A$e=a("strong"),gft=o("not"),hft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qse=a("a"),uft=o("from_pretrained()"),pft=o(" to load the model weights."),_ft=l(),F(M7.$$.fragment),bft=l(),et=a("div"),F(AP.$$.fragment),vft=l(),L$e=a("p"),Fft=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Tft=l(),Hn=a("p"),Mft=o("The model class to instantiate is selected based on the "),y$e=a("code"),Eft=o("model_type"),Cft=o(` property of the config object (either
passed as an argument or loaded from `),x$e=a("code"),wft=o("pretrained_model_name_or_path"),Aft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$$e=a("code"),Lft=o("pretrained_model_name_or_path"),yft=o(":"),xft=l(),k$e=a("ul"),E7=a("li"),S$e=a("strong"),$ft=o("vision-encoder-decoder"),kft=o(" \u2014 "),Wse=a("a"),Sft=o("TFVisionEncoderDecoderModel"),Rft=o(" (Vision Encoder decoder model)"),Pft=l(),F(C7.$$.fragment),Rao=l(),ef=a("h2"),w7=a("a"),R$e=a("span"),F(LP.$$.fragment),Bft=l(),P$e=a("span"),Ift=o("TFAutoModelForSpeechSeq2Seq"),Pao=l(),wr=a("div"),F(yP.$$.fragment),Nft=l(),of=a("p"),qft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Use=a("a"),jft=o("from_pretrained()"),Dft=o(" class method or the "),Hse=a("a"),Gft=o("from_config()"),Oft=o(` class
method.`),Vft=l(),xP=a("p"),Xft=o("This class cannot be instantiated directly using "),B$e=a("code"),zft=o("__init__()"),Qft=o(" (throws an error)."),Wft=l(),ma=a("div"),F($P.$$.fragment),Uft=l(),I$e=a("p"),Hft=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Jft=l(),rf=a("p"),Yft=o(`Note:
Loading a model from its configuration file does `),N$e=a("strong"),Zft=o("not"),Kft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jse=a("a"),egt=o("from_pretrained()"),ogt=o(" to load the model weights."),rgt=l(),F(A7.$$.fragment),tgt=l(),ot=a("div"),F(kP.$$.fragment),agt=l(),q$e=a("p"),ngt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),sgt=l(),Jn=a("p"),lgt=o("The model class to instantiate is selected based on the "),j$e=a("code"),igt=o("model_type"),dgt=o(` property of the config object (either
passed as an argument or loaded from `),D$e=a("code"),cgt=o("pretrained_model_name_or_path"),mgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G$e=a("code"),fgt=o("pretrained_model_name_or_path"),ggt=o(":"),hgt=l(),SP=a("ul"),L7=a("li"),O$e=a("strong"),ugt=o("speech_to_text"),pgt=o(" \u2014 "),Yse=a("a"),_gt=o("TFSpeech2TextForConditionalGeneration"),bgt=o(" (Speech2Text model)"),vgt=l(),y7=a("li"),V$e=a("strong"),Fgt=o("whisper"),Tgt=o(" \u2014 "),Zse=a("a"),Mgt=o("TFWhisperForConditionalGeneration"),Egt=o(" (Whisper model)"),Cgt=l(),F(x7.$$.fragment),Bao=l(),tf=a("h2"),$7=a("a"),X$e=a("span"),F(RP.$$.fragment),wgt=l(),z$e=a("span"),Agt=o("FlaxAutoModel"),Iao=l(),Ar=a("div"),F(PP.$$.fragment),Lgt=l(),af=a("p"),ygt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Kse=a("a"),xgt=o("from_pretrained()"),$gt=o(" class method or the "),ele=a("a"),kgt=o("from_config()"),Sgt=o(` class
method.`),Rgt=l(),BP=a("p"),Pgt=o("This class cannot be instantiated directly using "),Q$e=a("code"),Bgt=o("__init__()"),Igt=o(" (throws an error)."),Ngt=l(),fa=a("div"),F(IP.$$.fragment),qgt=l(),W$e=a("p"),jgt=o("Instantiates one of the base model classes of the library from a configuration."),Dgt=l(),nf=a("p"),Ggt=o(`Note:
Loading a model from its configuration file does `),U$e=a("strong"),Ogt=o("not"),Vgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ole=a("a"),Xgt=o("from_pretrained()"),zgt=o(" to load the model weights."),Qgt=l(),F(k7.$$.fragment),Wgt=l(),rt=a("div"),F(NP.$$.fragment),Ugt=l(),H$e=a("p"),Hgt=o("Instantiate one of the base model classes of the library from a pretrained model."),Jgt=l(),Yn=a("p"),Ygt=o("The model class to instantiate is selected based on the "),J$e=a("code"),Zgt=o("model_type"),Kgt=o(` property of the config object (either
passed as an argument or loaded from `),Y$e=a("code"),eht=o("pretrained_model_name_or_path"),oht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z$e=a("code"),rht=o("pretrained_model_name_or_path"),tht=o(":"),aht=l(),te=a("ul"),S7=a("li"),K$e=a("strong"),nht=o("albert"),sht=o(" \u2014 "),rle=a("a"),lht=o("FlaxAlbertModel"),iht=o(" (ALBERT model)"),dht=l(),R7=a("li"),eke=a("strong"),cht=o("bart"),mht=o(" \u2014 "),tle=a("a"),fht=o("FlaxBartModel"),ght=o(" (BART model)"),hht=l(),P7=a("li"),oke=a("strong"),uht=o("beit"),pht=o(" \u2014 "),ale=a("a"),_ht=o("FlaxBeitModel"),bht=o(" (BEiT model)"),vht=l(),B7=a("li"),rke=a("strong"),Fht=o("bert"),Tht=o(" \u2014 "),nle=a("a"),Mht=o("FlaxBertModel"),Eht=o(" (BERT model)"),Cht=l(),I7=a("li"),tke=a("strong"),wht=o("big_bird"),Aht=o(" \u2014 "),sle=a("a"),Lht=o("FlaxBigBirdModel"),yht=o(" (BigBird model)"),xht=l(),N7=a("li"),ake=a("strong"),$ht=o("blenderbot"),kht=o(" \u2014 "),lle=a("a"),Sht=o("FlaxBlenderbotModel"),Rht=o(" (Blenderbot model)"),Pht=l(),q7=a("li"),nke=a("strong"),Bht=o("blenderbot-small"),Iht=o(" \u2014 "),ile=a("a"),Nht=o("FlaxBlenderbotSmallModel"),qht=o(" (BlenderbotSmall model)"),jht=l(),j7=a("li"),ske=a("strong"),Dht=o("clip"),Ght=o(" \u2014 "),dle=a("a"),Oht=o("FlaxCLIPModel"),Vht=o(" (CLIP model)"),Xht=l(),D7=a("li"),lke=a("strong"),zht=o("distilbert"),Qht=o(" \u2014 "),cle=a("a"),Wht=o("FlaxDistilBertModel"),Uht=o(" (DistilBERT model)"),Hht=l(),G7=a("li"),ike=a("strong"),Jht=o("electra"),Yht=o(" \u2014 "),mle=a("a"),Zht=o("FlaxElectraModel"),Kht=o(" (ELECTRA model)"),eut=l(),O7=a("li"),dke=a("strong"),out=o("gpt2"),rut=o(" \u2014 "),fle=a("a"),tut=o("FlaxGPT2Model"),aut=o(" (OpenAI GPT-2 model)"),nut=l(),V7=a("li"),cke=a("strong"),sut=o("gpt_neo"),lut=o(" \u2014 "),gle=a("a"),iut=o("FlaxGPTNeoModel"),dut=o(" (GPT Neo model)"),cut=l(),X7=a("li"),mke=a("strong"),mut=o("gptj"),fut=o(" \u2014 "),hle=a("a"),gut=o("FlaxGPTJModel"),hut=o(" (GPT-J model)"),uut=l(),z7=a("li"),fke=a("strong"),put=o("longt5"),_ut=o(" \u2014 "),ule=a("a"),but=o("FlaxLongT5Model"),vut=o(" (LongT5 model)"),Fut=l(),Q7=a("li"),gke=a("strong"),Tut=o("marian"),Mut=o(" \u2014 "),ple=a("a"),Eut=o("FlaxMarianModel"),Cut=o(" (Marian model)"),wut=l(),W7=a("li"),hke=a("strong"),Aut=o("mbart"),Lut=o(" \u2014 "),_le=a("a"),yut=o("FlaxMBartModel"),xut=o(" (mBART model)"),$ut=l(),U7=a("li"),uke=a("strong"),kut=o("mt5"),Sut=o(" \u2014 "),ble=a("a"),Rut=o("FlaxMT5Model"),Put=o(" (MT5 model)"),But=l(),H7=a("li"),pke=a("strong"),Iut=o("opt"),Nut=o(" \u2014 "),vle=a("a"),qut=o("FlaxOPTModel"),jut=o(" (OPT model)"),Dut=l(),J7=a("li"),_ke=a("strong"),Gut=o("pegasus"),Out=o(" \u2014 "),Fle=a("a"),Vut=o("FlaxPegasusModel"),Xut=o(" (Pegasus model)"),zut=l(),Y7=a("li"),bke=a("strong"),Qut=o("roberta"),Wut=o(" \u2014 "),Tle=a("a"),Uut=o("FlaxRobertaModel"),Hut=o(" (RoBERTa model)"),Jut=l(),Z7=a("li"),vke=a("strong"),Yut=o("roformer"),Zut=o(" \u2014 "),Mle=a("a"),Kut=o("FlaxRoFormerModel"),ept=o(" (RoFormer model)"),opt=l(),K7=a("li"),Fke=a("strong"),rpt=o("t5"),tpt=o(" \u2014 "),Ele=a("a"),apt=o("FlaxT5Model"),npt=o(" (T5 model)"),spt=l(),eL=a("li"),Tke=a("strong"),lpt=o("vision-text-dual-encoder"),ipt=o(" \u2014 "),Cle=a("a"),dpt=o("FlaxVisionTextDualEncoderModel"),cpt=o(" (VisionTextDualEncoder model)"),mpt=l(),oL=a("li"),Mke=a("strong"),fpt=o("vit"),gpt=o(" \u2014 "),wle=a("a"),hpt=o("FlaxViTModel"),upt=o(" (ViT model)"),ppt=l(),rL=a("li"),Eke=a("strong"),_pt=o("wav2vec2"),bpt=o(" \u2014 "),Ale=a("a"),vpt=o("FlaxWav2Vec2Model"),Fpt=o(" (Wav2Vec2 model)"),Tpt=l(),tL=a("li"),Cke=a("strong"),Mpt=o("xglm"),Ept=o(" \u2014 "),Lle=a("a"),Cpt=o("FlaxXGLMModel"),wpt=o(" (XGLM model)"),Apt=l(),aL=a("li"),wke=a("strong"),Lpt=o("xlm-roberta"),ypt=o(" \u2014 "),yle=a("a"),xpt=o("FlaxXLMRobertaModel"),$pt=o(" (XLM-RoBERTa model)"),kpt=l(),F(nL.$$.fragment),Nao=l(),sf=a("h2"),sL=a("a"),Ake=a("span"),F(qP.$$.fragment),Spt=l(),Lke=a("span"),Rpt=o("FlaxAutoModelForCausalLM"),qao=l(),Lr=a("div"),F(jP.$$.fragment),Ppt=l(),lf=a("p"),Bpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),xle=a("a"),Ipt=o("from_pretrained()"),Npt=o(" class method or the "),$le=a("a"),qpt=o("from_config()"),jpt=o(` class
method.`),Dpt=l(),DP=a("p"),Gpt=o("This class cannot be instantiated directly using "),yke=a("code"),Opt=o("__init__()"),Vpt=o(" (throws an error)."),Xpt=l(),ga=a("div"),F(GP.$$.fragment),zpt=l(),xke=a("p"),Qpt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Wpt=l(),df=a("p"),Upt=o(`Note:
Loading a model from its configuration file does `),$ke=a("strong"),Hpt=o("not"),Jpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kle=a("a"),Ypt=o("from_pretrained()"),Zpt=o(" to load the model weights."),Kpt=l(),F(lL.$$.fragment),e_t=l(),tt=a("div"),F(OP.$$.fragment),o_t=l(),kke=a("p"),r_t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),t_t=l(),Zn=a("p"),a_t=o("The model class to instantiate is selected based on the "),Ske=a("code"),n_t=o("model_type"),s_t=o(` property of the config object (either
passed as an argument or loaded from `),Rke=a("code"),l_t=o("pretrained_model_name_or_path"),i_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pke=a("code"),d_t=o("pretrained_model_name_or_path"),c_t=o(":"),m_t=l(),$e=a("ul"),iL=a("li"),Bke=a("strong"),f_t=o("bart"),g_t=o(" \u2014 "),Sle=a("a"),h_t=o("FlaxBartForCausalLM"),u_t=o(" (BART model)"),p_t=l(),dL=a("li"),Ike=a("strong"),__t=o("bert"),b_t=o(" \u2014 "),Rle=a("a"),v_t=o("FlaxBertForCausalLM"),F_t=o(" (BERT model)"),T_t=l(),cL=a("li"),Nke=a("strong"),M_t=o("big_bird"),E_t=o(" \u2014 "),Ple=a("a"),C_t=o("FlaxBigBirdForCausalLM"),w_t=o(" (BigBird model)"),A_t=l(),mL=a("li"),qke=a("strong"),L_t=o("electra"),y_t=o(" \u2014 "),Ble=a("a"),x_t=o("FlaxElectraForCausalLM"),$_t=o(" (ELECTRA model)"),k_t=l(),fL=a("li"),jke=a("strong"),S_t=o("gpt2"),R_t=o(" \u2014 "),Ile=a("a"),P_t=o("FlaxGPT2LMHeadModel"),B_t=o(" (OpenAI GPT-2 model)"),I_t=l(),gL=a("li"),Dke=a("strong"),N_t=o("gpt_neo"),q_t=o(" \u2014 "),Nle=a("a"),j_t=o("FlaxGPTNeoForCausalLM"),D_t=o(" (GPT Neo model)"),G_t=l(),hL=a("li"),Gke=a("strong"),O_t=o("gptj"),V_t=o(" \u2014 "),qle=a("a"),X_t=o("FlaxGPTJForCausalLM"),z_t=o(" (GPT-J model)"),Q_t=l(),uL=a("li"),Oke=a("strong"),W_t=o("opt"),U_t=o(" \u2014 "),jle=a("a"),H_t=o("FlaxOPTForCausalLM"),J_t=o(" (OPT model)"),Y_t=l(),pL=a("li"),Vke=a("strong"),Z_t=o("roberta"),K_t=o(" \u2014 "),Dle=a("a"),e1t=o("FlaxRobertaForCausalLM"),o1t=o(" (RoBERTa model)"),r1t=l(),_L=a("li"),Xke=a("strong"),t1t=o("xglm"),a1t=o(" \u2014 "),Gle=a("a"),n1t=o("FlaxXGLMForCausalLM"),s1t=o(" (XGLM model)"),l1t=l(),F(bL.$$.fragment),jao=l(),cf=a("h2"),vL=a("a"),zke=a("span"),F(VP.$$.fragment),i1t=l(),Qke=a("span"),d1t=o("FlaxAutoModelForPreTraining"),Dao=l(),yr=a("div"),F(XP.$$.fragment),c1t=l(),mf=a("p"),m1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Ole=a("a"),f1t=o("from_pretrained()"),g1t=o(" class method or the "),Vle=a("a"),h1t=o("from_config()"),u1t=o(` class
method.`),p1t=l(),zP=a("p"),_1t=o("This class cannot be instantiated directly using "),Wke=a("code"),b1t=o("__init__()"),v1t=o(" (throws an error)."),F1t=l(),ha=a("div"),F(QP.$$.fragment),T1t=l(),Uke=a("p"),M1t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),E1t=l(),ff=a("p"),C1t=o(`Note:
Loading a model from its configuration file does `),Hke=a("strong"),w1t=o("not"),A1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xle=a("a"),L1t=o("from_pretrained()"),y1t=o(" to load the model weights."),x1t=l(),F(FL.$$.fragment),$1t=l(),at=a("div"),F(WP.$$.fragment),k1t=l(),Jke=a("p"),S1t=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),R1t=l(),Kn=a("p"),P1t=o("The model class to instantiate is selected based on the "),Yke=a("code"),B1t=o("model_type"),I1t=o(` property of the config object (either
passed as an argument or loaded from `),Zke=a("code"),N1t=o("pretrained_model_name_or_path"),q1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kke=a("code"),j1t=o("pretrained_model_name_or_path"),D1t=o(":"),G1t=l(),Ee=a("ul"),TL=a("li"),eSe=a("strong"),O1t=o("albert"),V1t=o(" \u2014 "),zle=a("a"),X1t=o("FlaxAlbertForPreTraining"),z1t=o(" (ALBERT model)"),Q1t=l(),ML=a("li"),oSe=a("strong"),W1t=o("bart"),U1t=o(" \u2014 "),Qle=a("a"),H1t=o("FlaxBartForConditionalGeneration"),J1t=o(" (BART model)"),Y1t=l(),EL=a("li"),rSe=a("strong"),Z1t=o("bert"),K1t=o(" \u2014 "),Wle=a("a"),e2t=o("FlaxBertForPreTraining"),o2t=o(" (BERT model)"),r2t=l(),CL=a("li"),tSe=a("strong"),t2t=o("big_bird"),a2t=o(" \u2014 "),Ule=a("a"),n2t=o("FlaxBigBirdForPreTraining"),s2t=o(" (BigBird model)"),l2t=l(),wL=a("li"),aSe=a("strong"),i2t=o("electra"),d2t=o(" \u2014 "),Hle=a("a"),c2t=o("FlaxElectraForPreTraining"),m2t=o(" (ELECTRA model)"),f2t=l(),AL=a("li"),nSe=a("strong"),g2t=o("longt5"),h2t=o(" \u2014 "),Jle=a("a"),u2t=o("FlaxLongT5ForConditionalGeneration"),p2t=o(" (LongT5 model)"),_2t=l(),LL=a("li"),sSe=a("strong"),b2t=o("mbart"),v2t=o(" \u2014 "),Yle=a("a"),F2t=o("FlaxMBartForConditionalGeneration"),T2t=o(" (mBART model)"),M2t=l(),yL=a("li"),lSe=a("strong"),E2t=o("mt5"),C2t=o(" \u2014 "),Zle=a("a"),w2t=o("FlaxMT5ForConditionalGeneration"),A2t=o(" (MT5 model)"),L2t=l(),xL=a("li"),iSe=a("strong"),y2t=o("roberta"),x2t=o(" \u2014 "),Kle=a("a"),$2t=o("FlaxRobertaForMaskedLM"),k2t=o(" (RoBERTa model)"),S2t=l(),$L=a("li"),dSe=a("strong"),R2t=o("roformer"),P2t=o(" \u2014 "),eie=a("a"),B2t=o("FlaxRoFormerForMaskedLM"),I2t=o(" (RoFormer model)"),N2t=l(),kL=a("li"),cSe=a("strong"),q2t=o("t5"),j2t=o(" \u2014 "),oie=a("a"),D2t=o("FlaxT5ForConditionalGeneration"),G2t=o(" (T5 model)"),O2t=l(),SL=a("li"),mSe=a("strong"),V2t=o("wav2vec2"),X2t=o(" \u2014 "),rie=a("a"),z2t=o("FlaxWav2Vec2ForPreTraining"),Q2t=o(" (Wav2Vec2 model)"),W2t=l(),RL=a("li"),fSe=a("strong"),U2t=o("xlm-roberta"),H2t=o(" \u2014 "),tie=a("a"),J2t=o("FlaxXLMRobertaForMaskedLM"),Y2t=o(" (XLM-RoBERTa model)"),Z2t=l(),F(PL.$$.fragment),Gao=l(),gf=a("h2"),BL=a("a"),gSe=a("span"),F(UP.$$.fragment),K2t=l(),hSe=a("span"),ebt=o("FlaxAutoModelForMaskedLM"),Oao=l(),xr=a("div"),F(HP.$$.fragment),obt=l(),hf=a("p"),rbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aie=a("a"),tbt=o("from_pretrained()"),abt=o(" class method or the "),nie=a("a"),nbt=o("from_config()"),sbt=o(` class
method.`),lbt=l(),JP=a("p"),ibt=o("This class cannot be instantiated directly using "),uSe=a("code"),dbt=o("__init__()"),cbt=o(" (throws an error)."),mbt=l(),ua=a("div"),F(YP.$$.fragment),fbt=l(),pSe=a("p"),gbt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),hbt=l(),uf=a("p"),ubt=o(`Note:
Loading a model from its configuration file does `),_Se=a("strong"),pbt=o("not"),_bt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=a("a"),bbt=o("from_pretrained()"),vbt=o(" to load the model weights."),Fbt=l(),F(IL.$$.fragment),Tbt=l(),nt=a("div"),F(ZP.$$.fragment),Mbt=l(),bSe=a("p"),Ebt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Cbt=l(),es=a("p"),wbt=o("The model class to instantiate is selected based on the "),vSe=a("code"),Abt=o("model_type"),Lbt=o(` property of the config object (either
passed as an argument or loaded from `),FSe=a("code"),ybt=o("pretrained_model_name_or_path"),xbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TSe=a("code"),$bt=o("pretrained_model_name_or_path"),kbt=o(":"),Sbt=l(),ke=a("ul"),NL=a("li"),MSe=a("strong"),Rbt=o("albert"),Pbt=o(" \u2014 "),lie=a("a"),Bbt=o("FlaxAlbertForMaskedLM"),Ibt=o(" (ALBERT model)"),Nbt=l(),qL=a("li"),ESe=a("strong"),qbt=o("bart"),jbt=o(" \u2014 "),iie=a("a"),Dbt=o("FlaxBartForConditionalGeneration"),Gbt=o(" (BART model)"),Obt=l(),jL=a("li"),CSe=a("strong"),Vbt=o("bert"),Xbt=o(" \u2014 "),die=a("a"),zbt=o("FlaxBertForMaskedLM"),Qbt=o(" (BERT model)"),Wbt=l(),DL=a("li"),wSe=a("strong"),Ubt=o("big_bird"),Hbt=o(" \u2014 "),cie=a("a"),Jbt=o("FlaxBigBirdForMaskedLM"),Ybt=o(" (BigBird model)"),Zbt=l(),GL=a("li"),ASe=a("strong"),Kbt=o("distilbert"),evt=o(" \u2014 "),mie=a("a"),ovt=o("FlaxDistilBertForMaskedLM"),rvt=o(" (DistilBERT model)"),tvt=l(),OL=a("li"),LSe=a("strong"),avt=o("electra"),nvt=o(" \u2014 "),fie=a("a"),svt=o("FlaxElectraForMaskedLM"),lvt=o(" (ELECTRA model)"),ivt=l(),VL=a("li"),ySe=a("strong"),dvt=o("mbart"),cvt=o(" \u2014 "),gie=a("a"),mvt=o("FlaxMBartForConditionalGeneration"),fvt=o(" (mBART model)"),gvt=l(),XL=a("li"),xSe=a("strong"),hvt=o("roberta"),uvt=o(" \u2014 "),hie=a("a"),pvt=o("FlaxRobertaForMaskedLM"),_vt=o(" (RoBERTa model)"),bvt=l(),zL=a("li"),$Se=a("strong"),vvt=o("roformer"),Fvt=o(" \u2014 "),uie=a("a"),Tvt=o("FlaxRoFormerForMaskedLM"),Mvt=o(" (RoFormer model)"),Evt=l(),QL=a("li"),kSe=a("strong"),Cvt=o("xlm-roberta"),wvt=o(" \u2014 "),pie=a("a"),Avt=o("FlaxXLMRobertaForMaskedLM"),Lvt=o(" (XLM-RoBERTa model)"),yvt=l(),F(WL.$$.fragment),Vao=l(),pf=a("h2"),UL=a("a"),SSe=a("span"),F(KP.$$.fragment),xvt=l(),RSe=a("span"),$vt=o("FlaxAutoModelForSeq2SeqLM"),Xao=l(),$r=a("div"),F(eB.$$.fragment),kvt=l(),_f=a("p"),Svt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_ie=a("a"),Rvt=o("from_pretrained()"),Pvt=o(" class method or the "),bie=a("a"),Bvt=o("from_config()"),Ivt=o(` class
method.`),Nvt=l(),oB=a("p"),qvt=o("This class cannot be instantiated directly using "),PSe=a("code"),jvt=o("__init__()"),Dvt=o(" (throws an error)."),Gvt=l(),pa=a("div"),F(rB.$$.fragment),Ovt=l(),BSe=a("p"),Vvt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Xvt=l(),bf=a("p"),zvt=o(`Note:
Loading a model from its configuration file does `),ISe=a("strong"),Qvt=o("not"),Wvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vie=a("a"),Uvt=o("from_pretrained()"),Hvt=o(" to load the model weights."),Jvt=l(),F(HL.$$.fragment),Yvt=l(),st=a("div"),F(tB.$$.fragment),Zvt=l(),NSe=a("p"),Kvt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),eFt=l(),os=a("p"),oFt=o("The model class to instantiate is selected based on the "),qSe=a("code"),rFt=o("model_type"),tFt=o(` property of the config object (either
passed as an argument or loaded from `),jSe=a("code"),aFt=o("pretrained_model_name_or_path"),nFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DSe=a("code"),sFt=o("pretrained_model_name_or_path"),lFt=o(":"),iFt=l(),Se=a("ul"),JL=a("li"),GSe=a("strong"),dFt=o("bart"),cFt=o(" \u2014 "),Fie=a("a"),mFt=o("FlaxBartForConditionalGeneration"),fFt=o(" (BART model)"),gFt=l(),YL=a("li"),OSe=a("strong"),hFt=o("blenderbot"),uFt=o(" \u2014 "),Tie=a("a"),pFt=o("FlaxBlenderbotForConditionalGeneration"),_Ft=o(" (Blenderbot model)"),bFt=l(),ZL=a("li"),VSe=a("strong"),vFt=o("blenderbot-small"),FFt=o(" \u2014 "),Mie=a("a"),TFt=o("FlaxBlenderbotSmallForConditionalGeneration"),MFt=o(" (BlenderbotSmall model)"),EFt=l(),KL=a("li"),XSe=a("strong"),CFt=o("encoder-decoder"),wFt=o(" \u2014 "),Eie=a("a"),AFt=o("FlaxEncoderDecoderModel"),LFt=o(" (Encoder decoder model)"),yFt=l(),e8=a("li"),zSe=a("strong"),xFt=o("longt5"),$Ft=o(" \u2014 "),Cie=a("a"),kFt=o("FlaxLongT5ForConditionalGeneration"),SFt=o(" (LongT5 model)"),RFt=l(),o8=a("li"),QSe=a("strong"),PFt=o("marian"),BFt=o(" \u2014 "),wie=a("a"),IFt=o("FlaxMarianMTModel"),NFt=o(" (Marian model)"),qFt=l(),r8=a("li"),WSe=a("strong"),jFt=o("mbart"),DFt=o(" \u2014 "),Aie=a("a"),GFt=o("FlaxMBartForConditionalGeneration"),OFt=o(" (mBART model)"),VFt=l(),t8=a("li"),USe=a("strong"),XFt=o("mt5"),zFt=o(" \u2014 "),Lie=a("a"),QFt=o("FlaxMT5ForConditionalGeneration"),WFt=o(" (MT5 model)"),UFt=l(),a8=a("li"),HSe=a("strong"),HFt=o("pegasus"),JFt=o(" \u2014 "),yie=a("a"),YFt=o("FlaxPegasusForConditionalGeneration"),ZFt=o(" (Pegasus model)"),KFt=l(),n8=a("li"),JSe=a("strong"),eTt=o("t5"),oTt=o(" \u2014 "),xie=a("a"),rTt=o("FlaxT5ForConditionalGeneration"),tTt=o(" (T5 model)"),aTt=l(),F(s8.$$.fragment),zao=l(),vf=a("h2"),l8=a("a"),YSe=a("span"),F(aB.$$.fragment),nTt=l(),ZSe=a("span"),sTt=o("FlaxAutoModelForSequenceClassification"),Qao=l(),kr=a("div"),F(nB.$$.fragment),lTt=l(),Ff=a("p"),iTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$ie=a("a"),dTt=o("from_pretrained()"),cTt=o(" class method or the "),kie=a("a"),mTt=o("from_config()"),fTt=o(` class
method.`),gTt=l(),sB=a("p"),hTt=o("This class cannot be instantiated directly using "),KSe=a("code"),uTt=o("__init__()"),pTt=o(" (throws an error)."),_Tt=l(),_a=a("div"),F(lB.$$.fragment),bTt=l(),eRe=a("p"),vTt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),FTt=l(),Tf=a("p"),TTt=o(`Note:
Loading a model from its configuration file does `),oRe=a("strong"),MTt=o("not"),ETt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sie=a("a"),CTt=o("from_pretrained()"),wTt=o(" to load the model weights."),ATt=l(),F(i8.$$.fragment),LTt=l(),lt=a("div"),F(iB.$$.fragment),yTt=l(),rRe=a("p"),xTt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),$Tt=l(),rs=a("p"),kTt=o("The model class to instantiate is selected based on the "),tRe=a("code"),STt=o("model_type"),RTt=o(` property of the config object (either
passed as an argument or loaded from `),aRe=a("code"),PTt=o("pretrained_model_name_or_path"),BTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nRe=a("code"),ITt=o("pretrained_model_name_or_path"),NTt=o(":"),qTt=l(),Re=a("ul"),d8=a("li"),sRe=a("strong"),jTt=o("albert"),DTt=o(" \u2014 "),Rie=a("a"),GTt=o("FlaxAlbertForSequenceClassification"),OTt=o(" (ALBERT model)"),VTt=l(),c8=a("li"),lRe=a("strong"),XTt=o("bart"),zTt=o(" \u2014 "),Pie=a("a"),QTt=o("FlaxBartForSequenceClassification"),WTt=o(" (BART model)"),UTt=l(),m8=a("li"),iRe=a("strong"),HTt=o("bert"),JTt=o(" \u2014 "),Bie=a("a"),YTt=o("FlaxBertForSequenceClassification"),ZTt=o(" (BERT model)"),KTt=l(),f8=a("li"),dRe=a("strong"),eMt=o("big_bird"),oMt=o(" \u2014 "),Iie=a("a"),rMt=o("FlaxBigBirdForSequenceClassification"),tMt=o(" (BigBird model)"),aMt=l(),g8=a("li"),cRe=a("strong"),nMt=o("distilbert"),sMt=o(" \u2014 "),Nie=a("a"),lMt=o("FlaxDistilBertForSequenceClassification"),iMt=o(" (DistilBERT model)"),dMt=l(),h8=a("li"),mRe=a("strong"),cMt=o("electra"),mMt=o(" \u2014 "),qie=a("a"),fMt=o("FlaxElectraForSequenceClassification"),gMt=o(" (ELECTRA model)"),hMt=l(),u8=a("li"),fRe=a("strong"),uMt=o("mbart"),pMt=o(" \u2014 "),jie=a("a"),_Mt=o("FlaxMBartForSequenceClassification"),bMt=o(" (mBART model)"),vMt=l(),p8=a("li"),gRe=a("strong"),FMt=o("roberta"),TMt=o(" \u2014 "),Die=a("a"),MMt=o("FlaxRobertaForSequenceClassification"),EMt=o(" (RoBERTa model)"),CMt=l(),_8=a("li"),hRe=a("strong"),wMt=o("roformer"),AMt=o(" \u2014 "),Gie=a("a"),LMt=o("FlaxRoFormerForSequenceClassification"),yMt=o(" (RoFormer model)"),xMt=l(),b8=a("li"),uRe=a("strong"),$Mt=o("xlm-roberta"),kMt=o(" \u2014 "),Oie=a("a"),SMt=o("FlaxXLMRobertaForSequenceClassification"),RMt=o(" (XLM-RoBERTa model)"),PMt=l(),F(v8.$$.fragment),Wao=l(),Mf=a("h2"),F8=a("a"),pRe=a("span"),F(dB.$$.fragment),BMt=l(),_Re=a("span"),IMt=o("FlaxAutoModelForQuestionAnswering"),Uao=l(),Sr=a("div"),F(cB.$$.fragment),NMt=l(),Ef=a("p"),qMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Vie=a("a"),jMt=o("from_pretrained()"),DMt=o(" class method or the "),Xie=a("a"),GMt=o("from_config()"),OMt=o(` class
method.`),VMt=l(),mB=a("p"),XMt=o("This class cannot be instantiated directly using "),bRe=a("code"),zMt=o("__init__()"),QMt=o(" (throws an error)."),WMt=l(),ba=a("div"),F(fB.$$.fragment),UMt=l(),vRe=a("p"),HMt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),JMt=l(),Cf=a("p"),YMt=o(`Note:
Loading a model from its configuration file does `),FRe=a("strong"),ZMt=o("not"),KMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zie=a("a"),eEt=o("from_pretrained()"),oEt=o(" to load the model weights."),rEt=l(),F(T8.$$.fragment),tEt=l(),it=a("div"),F(gB.$$.fragment),aEt=l(),TRe=a("p"),nEt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),sEt=l(),ts=a("p"),lEt=o("The model class to instantiate is selected based on the "),MRe=a("code"),iEt=o("model_type"),dEt=o(` property of the config object (either
passed as an argument or loaded from `),ERe=a("code"),cEt=o("pretrained_model_name_or_path"),mEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CRe=a("code"),fEt=o("pretrained_model_name_or_path"),gEt=o(":"),hEt=l(),Pe=a("ul"),M8=a("li"),wRe=a("strong"),uEt=o("albert"),pEt=o(" \u2014 "),Qie=a("a"),_Et=o("FlaxAlbertForQuestionAnswering"),bEt=o(" (ALBERT model)"),vEt=l(),E8=a("li"),ARe=a("strong"),FEt=o("bart"),TEt=o(" \u2014 "),Wie=a("a"),MEt=o("FlaxBartForQuestionAnswering"),EEt=o(" (BART model)"),CEt=l(),C8=a("li"),LRe=a("strong"),wEt=o("bert"),AEt=o(" \u2014 "),Uie=a("a"),LEt=o("FlaxBertForQuestionAnswering"),yEt=o(" (BERT model)"),xEt=l(),w8=a("li"),yRe=a("strong"),$Et=o("big_bird"),kEt=o(" \u2014 "),Hie=a("a"),SEt=o("FlaxBigBirdForQuestionAnswering"),REt=o(" (BigBird model)"),PEt=l(),A8=a("li"),xRe=a("strong"),BEt=o("distilbert"),IEt=o(" \u2014 "),Jie=a("a"),NEt=o("FlaxDistilBertForQuestionAnswering"),qEt=o(" (DistilBERT model)"),jEt=l(),L8=a("li"),$Re=a("strong"),DEt=o("electra"),GEt=o(" \u2014 "),Yie=a("a"),OEt=o("FlaxElectraForQuestionAnswering"),VEt=o(" (ELECTRA model)"),XEt=l(),y8=a("li"),kRe=a("strong"),zEt=o("mbart"),QEt=o(" \u2014 "),Zie=a("a"),WEt=o("FlaxMBartForQuestionAnswering"),UEt=o(" (mBART model)"),HEt=l(),x8=a("li"),SRe=a("strong"),JEt=o("roberta"),YEt=o(" \u2014 "),Kie=a("a"),ZEt=o("FlaxRobertaForQuestionAnswering"),KEt=o(" (RoBERTa model)"),e4t=l(),$8=a("li"),RRe=a("strong"),o4t=o("roformer"),r4t=o(" \u2014 "),ede=a("a"),t4t=o("FlaxRoFormerForQuestionAnswering"),a4t=o(" (RoFormer model)"),n4t=l(),k8=a("li"),PRe=a("strong"),s4t=o("xlm-roberta"),l4t=o(" \u2014 "),ode=a("a"),i4t=o("FlaxXLMRobertaForQuestionAnswering"),d4t=o(" (XLM-RoBERTa model)"),c4t=l(),F(S8.$$.fragment),Hao=l(),wf=a("h2"),R8=a("a"),BRe=a("span"),F(hB.$$.fragment),m4t=l(),IRe=a("span"),f4t=o("FlaxAutoModelForTokenClassification"),Jao=l(),Rr=a("div"),F(uB.$$.fragment),g4t=l(),Af=a("p"),h4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),rde=a("a"),u4t=o("from_pretrained()"),p4t=o(" class method or the "),tde=a("a"),_4t=o("from_config()"),b4t=o(` class
method.`),v4t=l(),pB=a("p"),F4t=o("This class cannot be instantiated directly using "),NRe=a("code"),T4t=o("__init__()"),M4t=o(" (throws an error)."),E4t=l(),va=a("div"),F(_B.$$.fragment),C4t=l(),qRe=a("p"),w4t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),A4t=l(),Lf=a("p"),L4t=o(`Note:
Loading a model from its configuration file does `),jRe=a("strong"),y4t=o("not"),x4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ade=a("a"),$4t=o("from_pretrained()"),k4t=o(" to load the model weights."),S4t=l(),F(P8.$$.fragment),R4t=l(),dt=a("div"),F(bB.$$.fragment),P4t=l(),DRe=a("p"),B4t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),I4t=l(),as=a("p"),N4t=o("The model class to instantiate is selected based on the "),GRe=a("code"),q4t=o("model_type"),j4t=o(` property of the config object (either
passed as an argument or loaded from `),ORe=a("code"),D4t=o("pretrained_model_name_or_path"),G4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VRe=a("code"),O4t=o("pretrained_model_name_or_path"),V4t=o(":"),X4t=l(),ze=a("ul"),B8=a("li"),XRe=a("strong"),z4t=o("albert"),Q4t=o(" \u2014 "),nde=a("a"),W4t=o("FlaxAlbertForTokenClassification"),U4t=o(" (ALBERT model)"),H4t=l(),I8=a("li"),zRe=a("strong"),J4t=o("bert"),Y4t=o(" \u2014 "),sde=a("a"),Z4t=o("FlaxBertForTokenClassification"),K4t=o(" (BERT model)"),eCt=l(),N8=a("li"),QRe=a("strong"),oCt=o("big_bird"),rCt=o(" \u2014 "),lde=a("a"),tCt=o("FlaxBigBirdForTokenClassification"),aCt=o(" (BigBird model)"),nCt=l(),q8=a("li"),WRe=a("strong"),sCt=o("distilbert"),lCt=o(" \u2014 "),ide=a("a"),iCt=o("FlaxDistilBertForTokenClassification"),dCt=o(" (DistilBERT model)"),cCt=l(),j8=a("li"),URe=a("strong"),mCt=o("electra"),fCt=o(" \u2014 "),dde=a("a"),gCt=o("FlaxElectraForTokenClassification"),hCt=o(" (ELECTRA model)"),uCt=l(),D8=a("li"),HRe=a("strong"),pCt=o("roberta"),_Ct=o(" \u2014 "),cde=a("a"),bCt=o("FlaxRobertaForTokenClassification"),vCt=o(" (RoBERTa model)"),FCt=l(),G8=a("li"),JRe=a("strong"),TCt=o("roformer"),MCt=o(" \u2014 "),mde=a("a"),ECt=o("FlaxRoFormerForTokenClassification"),CCt=o(" (RoFormer model)"),wCt=l(),O8=a("li"),YRe=a("strong"),ACt=o("xlm-roberta"),LCt=o(" \u2014 "),fde=a("a"),yCt=o("FlaxXLMRobertaForTokenClassification"),xCt=o(" (XLM-RoBERTa model)"),$Ct=l(),F(V8.$$.fragment),Yao=l(),yf=a("h2"),X8=a("a"),ZRe=a("span"),F(vB.$$.fragment),kCt=l(),KRe=a("span"),SCt=o("FlaxAutoModelForMultipleChoice"),Zao=l(),Pr=a("div"),F(FB.$$.fragment),RCt=l(),xf=a("p"),PCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),gde=a("a"),BCt=o("from_pretrained()"),ICt=o(" class method or the "),hde=a("a"),NCt=o("from_config()"),qCt=o(` class
method.`),jCt=l(),TB=a("p"),DCt=o("This class cannot be instantiated directly using "),ePe=a("code"),GCt=o("__init__()"),OCt=o(" (throws an error)."),VCt=l(),Fa=a("div"),F(MB.$$.fragment),XCt=l(),oPe=a("p"),zCt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),QCt=l(),$f=a("p"),WCt=o(`Note:
Loading a model from its configuration file does `),rPe=a("strong"),UCt=o("not"),HCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ude=a("a"),JCt=o("from_pretrained()"),YCt=o(" to load the model weights."),ZCt=l(),F(z8.$$.fragment),KCt=l(),ct=a("div"),F(EB.$$.fragment),e3t=l(),tPe=a("p"),o3t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),r3t=l(),ns=a("p"),t3t=o("The model class to instantiate is selected based on the "),aPe=a("code"),a3t=o("model_type"),n3t=o(` property of the config object (either
passed as an argument or loaded from `),nPe=a("code"),s3t=o("pretrained_model_name_or_path"),l3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sPe=a("code"),i3t=o("pretrained_model_name_or_path"),d3t=o(":"),c3t=l(),Qe=a("ul"),Q8=a("li"),lPe=a("strong"),m3t=o("albert"),f3t=o(" \u2014 "),pde=a("a"),g3t=o("FlaxAlbertForMultipleChoice"),h3t=o(" (ALBERT model)"),u3t=l(),W8=a("li"),iPe=a("strong"),p3t=o("bert"),_3t=o(" \u2014 "),_de=a("a"),b3t=o("FlaxBertForMultipleChoice"),v3t=o(" (BERT model)"),F3t=l(),U8=a("li"),dPe=a("strong"),T3t=o("big_bird"),M3t=o(" \u2014 "),bde=a("a"),E3t=o("FlaxBigBirdForMultipleChoice"),C3t=o(" (BigBird model)"),w3t=l(),H8=a("li"),cPe=a("strong"),A3t=o("distilbert"),L3t=o(" \u2014 "),vde=a("a"),y3t=o("FlaxDistilBertForMultipleChoice"),x3t=o(" (DistilBERT model)"),$3t=l(),J8=a("li"),mPe=a("strong"),k3t=o("electra"),S3t=o(" \u2014 "),Fde=a("a"),R3t=o("FlaxElectraForMultipleChoice"),P3t=o(" (ELECTRA model)"),B3t=l(),Y8=a("li"),fPe=a("strong"),I3t=o("roberta"),N3t=o(" \u2014 "),Tde=a("a"),q3t=o("FlaxRobertaForMultipleChoice"),j3t=o(" (RoBERTa model)"),D3t=l(),Z8=a("li"),gPe=a("strong"),G3t=o("roformer"),O3t=o(" \u2014 "),Mde=a("a"),V3t=o("FlaxRoFormerForMultipleChoice"),X3t=o(" (RoFormer model)"),z3t=l(),K8=a("li"),hPe=a("strong"),Q3t=o("xlm-roberta"),W3t=o(" \u2014 "),Ede=a("a"),U3t=o("FlaxXLMRobertaForMultipleChoice"),H3t=o(" (XLM-RoBERTa model)"),J3t=l(),F(ey.$$.fragment),Kao=l(),kf=a("h2"),oy=a("a"),uPe=a("span"),F(CB.$$.fragment),Y3t=l(),pPe=a("span"),Z3t=o("FlaxAutoModelForNextSentencePrediction"),eno=l(),Br=a("div"),F(wB.$$.fragment),K3t=l(),Sf=a("p"),e5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Cde=a("a"),o5t=o("from_pretrained()"),r5t=o(" class method or the "),wde=a("a"),t5t=o("from_config()"),a5t=o(` class
method.`),n5t=l(),AB=a("p"),s5t=o("This class cannot be instantiated directly using "),_Pe=a("code"),l5t=o("__init__()"),i5t=o(" (throws an error)."),d5t=l(),Ta=a("div"),F(LB.$$.fragment),c5t=l(),bPe=a("p"),m5t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),f5t=l(),Rf=a("p"),g5t=o(`Note:
Loading a model from its configuration file does `),vPe=a("strong"),h5t=o("not"),u5t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ade=a("a"),p5t=o("from_pretrained()"),_5t=o(" to load the model weights."),b5t=l(),F(ry.$$.fragment),v5t=l(),mt=a("div"),F(yB.$$.fragment),F5t=l(),FPe=a("p"),T5t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),M5t=l(),ss=a("p"),E5t=o("The model class to instantiate is selected based on the "),TPe=a("code"),C5t=o("model_type"),w5t=o(` property of the config object (either
passed as an argument or loaded from `),MPe=a("code"),A5t=o("pretrained_model_name_or_path"),L5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EPe=a("code"),y5t=o("pretrained_model_name_or_path"),x5t=o(":"),$5t=l(),CPe=a("ul"),ty=a("li"),wPe=a("strong"),k5t=o("bert"),S5t=o(" \u2014 "),Lde=a("a"),R5t=o("FlaxBertForNextSentencePrediction"),P5t=o(" (BERT model)"),B5t=l(),F(ay.$$.fragment),ono=l(),Pf=a("h2"),ny=a("a"),APe=a("span"),F(xB.$$.fragment),I5t=l(),LPe=a("span"),N5t=o("FlaxAutoModelForImageClassification"),rno=l(),Ir=a("div"),F($B.$$.fragment),q5t=l(),Bf=a("p"),j5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),yde=a("a"),D5t=o("from_pretrained()"),G5t=o(" class method or the "),xde=a("a"),O5t=o("from_config()"),V5t=o(` class
method.`),X5t=l(),kB=a("p"),z5t=o("This class cannot be instantiated directly using "),yPe=a("code"),Q5t=o("__init__()"),W5t=o(" (throws an error)."),U5t=l(),Ma=a("div"),F(SB.$$.fragment),H5t=l(),xPe=a("p"),J5t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Y5t=l(),If=a("p"),Z5t=o(`Note:
Loading a model from its configuration file does `),$Pe=a("strong"),K5t=o("not"),e0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$de=a("a"),o0t=o("from_pretrained()"),r0t=o(" to load the model weights."),t0t=l(),F(sy.$$.fragment),a0t=l(),ft=a("div"),F(RB.$$.fragment),n0t=l(),kPe=a("p"),s0t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),l0t=l(),ls=a("p"),i0t=o("The model class to instantiate is selected based on the "),SPe=a("code"),d0t=o("model_type"),c0t=o(` property of the config object (either
passed as an argument or loaded from `),RPe=a("code"),m0t=o("pretrained_model_name_or_path"),f0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PPe=a("code"),g0t=o("pretrained_model_name_or_path"),h0t=o(":"),u0t=l(),PB=a("ul"),ly=a("li"),BPe=a("strong"),p0t=o("beit"),_0t=o(" \u2014 "),kde=a("a"),b0t=o("FlaxBeitForImageClassification"),v0t=o(" (BEiT model)"),F0t=l(),iy=a("li"),IPe=a("strong"),T0t=o("vit"),M0t=o(" \u2014 "),Sde=a("a"),E0t=o("FlaxViTForImageClassification"),C0t=o(" (ViT model)"),w0t=l(),F(dy.$$.fragment),tno=l(),Nf=a("h2"),cy=a("a"),NPe=a("span"),F(BB.$$.fragment),A0t=l(),qPe=a("span"),L0t=o("FlaxAutoModelForVision2Seq"),ano=l(),Nr=a("div"),F(IB.$$.fragment),y0t=l(),qf=a("p"),x0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Rde=a("a"),$0t=o("from_pretrained()"),k0t=o(" class method or the "),Pde=a("a"),S0t=o("from_config()"),R0t=o(` class
method.`),P0t=l(),NB=a("p"),B0t=o("This class cannot be instantiated directly using "),jPe=a("code"),I0t=o("__init__()"),N0t=o(" (throws an error)."),q0t=l(),Ea=a("div"),F(qB.$$.fragment),j0t=l(),DPe=a("p"),D0t=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),G0t=l(),jf=a("p"),O0t=o(`Note:
Loading a model from its configuration file does `),GPe=a("strong"),V0t=o("not"),X0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bde=a("a"),z0t=o("from_pretrained()"),Q0t=o(" to load the model weights."),W0t=l(),F(my.$$.fragment),U0t=l(),gt=a("div"),F(jB.$$.fragment),H0t=l(),OPe=a("p"),J0t=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Y0t=l(),is=a("p"),Z0t=o("The model class to instantiate is selected based on the "),VPe=a("code"),K0t=o("model_type"),ewt=o(` property of the config object (either
passed as an argument or loaded from `),XPe=a("code"),owt=o("pretrained_model_name_or_path"),rwt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zPe=a("code"),twt=o("pretrained_model_name_or_path"),awt=o(":"),nwt=l(),QPe=a("ul"),fy=a("li"),WPe=a("strong"),swt=o("vision-encoder-decoder"),lwt=o(" \u2014 "),Ide=a("a"),iwt=o("FlaxVisionEncoderDecoderModel"),dwt=o(" (Vision Encoder decoder model)"),cwt=l(),F(gy.$$.fragment),this.h()},l(m){const _=k4a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var DB=s(u);f=n(DB,"A",{id:!0,class:!0,href:!0});var UPe=s(f);p=n(UPe,"SPAN",{});var HPe=s(p);T(d.$$.fragment,HPe),HPe.forEach(t),UPe.forEach(t),h=i(DB),$o=n(DB,"SPAN",{});var JPe=s($o);pd=r(JPe,"Auto Classes"),JPe.forEach(t),DB.forEach(t),Vf=i(m),Ft=n(m,"P",{});var GB=s(Ft);_d=r(GB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),bd=n(GB,"CODE",{});var YPe=s(bd);Jx=r(YPe,"from_pretrained()"),YPe.forEach(t),Xf=r(GB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),GB.forEach(t),Xe=i(m),He=n(m,"P",{});var ds=s(He);vd=r(ds,"Instantiating one of "),cs=n(ds,"A",{href:!0});var ZPe=s(cs);Yx=r(ZPe,"AutoConfig"),ZPe.forEach(t),ms=r(ds,", "),fs=n(ds,"A",{href:!0});var KPe=s(fs);Zx=r(KPe,"AutoModel"),KPe.forEach(t),Fd=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var eBe=s(gs);Kx=r(eBe,"AutoTokenizer"),eBe.forEach(t),Td=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),zf=i(m),T(en.$$.fragment,m),Je=i(m),Ae=n(m,"P",{});var OB=s(Ae);fN=r(OB,"will create a model that is an instance of "),Md=n(OB,"A",{href:!0});var oBe=s(Md);gN=r(oBe,"BertModel"),oBe.forEach(t),hN=r(OB,"."),OB.forEach(t),ko=i(m),on=n(m,"P",{});var VB=s(on);uN=r(VB,"There is one class of "),Qf=n(VB,"CODE",{});var rBe=s(Qf);pN=r(rBe,"AutoModel"),rBe.forEach(t),Llo=r(VB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),VB.forEach(t),Oro=i(m),Ed=n(m,"H2",{class:!0});var XB=s(Ed);Wf=n(XB,"A",{id:!0,class:!0,href:!0});var tBe=s(Wf);zme=n(tBe,"SPAN",{});var aBe=s(zme);T(e$.$$.fragment,aBe),aBe.forEach(t),tBe.forEach(t),ylo=i(XB),Qme=n(XB,"SPAN",{});var nBe=s(Qme);xlo=r(nBe,"Extending the Auto Classes"),nBe.forEach(t),XB.forEach(t),Vro=i(m),hs=n(m,"P",{});var Df=s(hs);$lo=r(Df,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Wme=n(Df,"CODE",{});var sBe=s(Wme);klo=r(sBe,"NewModel"),sBe.forEach(t),Slo=r(Df,", make sure you have a "),Ume=n(Df,"CODE",{});var lBe=s(Ume);Rlo=r(lBe,"NewModelConfig"),lBe.forEach(t),Plo=r(Df,` then you can add those to the auto
classes like this:`),Df.forEach(t),Xro=i(m),T(o$.$$.fragment,m),zro=i(m),_N=n(m,"P",{});var iBe=s(_N);Blo=r(iBe,"You will then be able to use the auto classes like you would usually do!"),iBe.forEach(t),Qro=i(m),T(Uf.$$.fragment,m),Wro=i(m),Cd=n(m,"H2",{class:!0});var zB=s(Cd);Hf=n(zB,"A",{id:!0,class:!0,href:!0});var dBe=s(Hf);Hme=n(dBe,"SPAN",{});var cBe=s(Hme);T(r$.$$.fragment,cBe),cBe.forEach(t),dBe.forEach(t),Ilo=i(zB),Jme=n(zB,"SPAN",{});var mBe=s(Jme);Nlo=r(mBe,"AutoConfig"),mBe.forEach(t),zB.forEach(t),Uro=i(m),So=n(m,"DIV",{class:!0});var bt=s(So);T(t$.$$.fragment,bt),qlo=i(bt),a$=n(bt,"P",{});var QB=s(a$);jlo=r(QB,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),bN=n(QB,"A",{href:!0});var fBe=s(bN);Dlo=r(fBe,"from_pretrained()"),fBe.forEach(t),Glo=r(QB," class method."),QB.forEach(t),Olo=i(bt),n$=n(bt,"P",{});var WB=s(n$);Vlo=r(WB,"This class cannot be instantiated directly using "),Yme=n(WB,"CODE",{});var gBe=s(Yme);Xlo=r(gBe,"__init__()"),gBe.forEach(t),zlo=r(WB," (throws an error)."),WB.forEach(t),Qlo=i(bt),qr=n(bt,"DIV",{class:!0});var vt=s(qr);T(s$.$$.fragment,vt),Wlo=i(vt),Zme=n(vt,"P",{});var hBe=s(Zme);Ulo=r(hBe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),hBe.forEach(t),Hlo=i(vt),wd=n(vt,"P",{});var Gf=s(wd);Jlo=r(Gf,"The configuration class to instantiate is selected based on the "),Kme=n(Gf,"CODE",{});var uBe=s(Kme);Ylo=r(uBe,"model_type"),uBe.forEach(t),Zlo=r(Gf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),efe=n(Gf,"CODE",{});var pBe=s(efe);Klo=r(pBe,"pretrained_model_name_or_path"),pBe.forEach(t),eio=r(Gf,":"),Gf.forEach(t),oio=i(vt),A=n(vt,"UL",{});var L=s(A);Jf=n(L,"LI",{});var hy=s(Jf);ofe=n(hy,"STRONG",{});var _Be=s(ofe);rio=r(_Be,"albert"),_Be.forEach(t),tio=r(hy," \u2014 "),vN=n(hy,"A",{href:!0});var bBe=s(vN);aio=r(bBe,"AlbertConfig"),bBe.forEach(t),nio=r(hy," (ALBERT model)"),hy.forEach(t),sio=i(L),Yf=n(L,"LI",{});var uy=s(Yf);rfe=n(uy,"STRONG",{});var vBe=s(rfe);lio=r(vBe,"bart"),vBe.forEach(t),iio=r(uy," \u2014 "),FN=n(uy,"A",{href:!0});var FBe=s(FN);dio=r(FBe,"BartConfig"),FBe.forEach(t),cio=r(uy," (BART model)"),uy.forEach(t),mio=i(L),Zf=n(L,"LI",{});var py=s(Zf);tfe=n(py,"STRONG",{});var TBe=s(tfe);fio=r(TBe,"beit"),TBe.forEach(t),gio=r(py," \u2014 "),TN=n(py,"A",{href:!0});var MBe=s(TN);hio=r(MBe,"BeitConfig"),MBe.forEach(t),uio=r(py," (BEiT model)"),py.forEach(t),pio=i(L),Kf=n(L,"LI",{});var _y=s(Kf);afe=n(_y,"STRONG",{});var EBe=s(afe);_io=r(EBe,"bert"),EBe.forEach(t),bio=r(_y," \u2014 "),MN=n(_y,"A",{href:!0});var CBe=s(MN);vio=r(CBe,"BertConfig"),CBe.forEach(t),Fio=r(_y," (BERT model)"),_y.forEach(t),Tio=i(L),eg=n(L,"LI",{});var by=s(eg);nfe=n(by,"STRONG",{});var wBe=s(nfe);Mio=r(wBe,"bert-generation"),wBe.forEach(t),Eio=r(by," \u2014 "),EN=n(by,"A",{href:!0});var ABe=s(EN);Cio=r(ABe,"BertGenerationConfig"),ABe.forEach(t),wio=r(by," (Bert Generation model)"),by.forEach(t),Aio=i(L),og=n(L,"LI",{});var vy=s(og);sfe=n(vy,"STRONG",{});var LBe=s(sfe);Lio=r(LBe,"big_bird"),LBe.forEach(t),yio=r(vy," \u2014 "),CN=n(vy,"A",{href:!0});var yBe=s(CN);xio=r(yBe,"BigBirdConfig"),yBe.forEach(t),$io=r(vy," (BigBird model)"),vy.forEach(t),kio=i(L),rg=n(L,"LI",{});var Fy=s(rg);lfe=n(Fy,"STRONG",{});var xBe=s(lfe);Sio=r(xBe,"bigbird_pegasus"),xBe.forEach(t),Rio=r(Fy," \u2014 "),wN=n(Fy,"A",{href:!0});var $Be=s(wN);Pio=r($Be,"BigBirdPegasusConfig"),$Be.forEach(t),Bio=r(Fy," (BigBird-Pegasus model)"),Fy.forEach(t),Iio=i(L),tg=n(L,"LI",{});var Ty=s(tg);ife=n(Ty,"STRONG",{});var kBe=s(ife);Nio=r(kBe,"blenderbot"),kBe.forEach(t),qio=r(Ty," \u2014 "),AN=n(Ty,"A",{href:!0});var SBe=s(AN);jio=r(SBe,"BlenderbotConfig"),SBe.forEach(t),Dio=r(Ty," (Blenderbot model)"),Ty.forEach(t),Gio=i(L),ag=n(L,"LI",{});var My=s(ag);dfe=n(My,"STRONG",{});var RBe=s(dfe);Oio=r(RBe,"blenderbot-small"),RBe.forEach(t),Vio=r(My," \u2014 "),LN=n(My,"A",{href:!0});var PBe=s(LN);Xio=r(PBe,"BlenderbotSmallConfig"),PBe.forEach(t),zio=r(My," (BlenderbotSmall model)"),My.forEach(t),Qio=i(L),ng=n(L,"LI",{});var Ey=s(ng);cfe=n(Ey,"STRONG",{});var BBe=s(cfe);Wio=r(BBe,"bloom"),BBe.forEach(t),Uio=r(Ey," \u2014 "),yN=n(Ey,"A",{href:!0});var IBe=s(yN);Hio=r(IBe,"BloomConfig"),IBe.forEach(t),Jio=r(Ey," (BLOOM model)"),Ey.forEach(t),Yio=i(L),sg=n(L,"LI",{});var Cy=s(sg);mfe=n(Cy,"STRONG",{});var NBe=s(mfe);Zio=r(NBe,"camembert"),NBe.forEach(t),Kio=r(Cy," \u2014 "),xN=n(Cy,"A",{href:!0});var qBe=s(xN);edo=r(qBe,"CamembertConfig"),qBe.forEach(t),odo=r(Cy," (CamemBERT model)"),Cy.forEach(t),rdo=i(L),lg=n(L,"LI",{});var wy=s(lg);ffe=n(wy,"STRONG",{});var jBe=s(ffe);tdo=r(jBe,"canine"),jBe.forEach(t),ado=r(wy," \u2014 "),$N=n(wy,"A",{href:!0});var DBe=s($N);ndo=r(DBe,"CanineConfig"),DBe.forEach(t),sdo=r(wy," (CANINE model)"),wy.forEach(t),ldo=i(L),ig=n(L,"LI",{});var Ay=s(ig);gfe=n(Ay,"STRONG",{});var GBe=s(gfe);ido=r(GBe,"clip"),GBe.forEach(t),ddo=r(Ay," \u2014 "),kN=n(Ay,"A",{href:!0});var OBe=s(kN);cdo=r(OBe,"CLIPConfig"),OBe.forEach(t),mdo=r(Ay," (CLIP model)"),Ay.forEach(t),fdo=i(L),dg=n(L,"LI",{});var Ly=s(dg);hfe=n(Ly,"STRONG",{});var VBe=s(hfe);gdo=r(VBe,"codegen"),VBe.forEach(t),hdo=r(Ly," \u2014 "),SN=n(Ly,"A",{href:!0});var XBe=s(SN);udo=r(XBe,"CodeGenConfig"),XBe.forEach(t),pdo=r(Ly," (CodeGen model)"),Ly.forEach(t),_do=i(L),cg=n(L,"LI",{});var yy=s(cg);ufe=n(yy,"STRONG",{});var zBe=s(ufe);bdo=r(zBe,"conditional_detr"),zBe.forEach(t),vdo=r(yy," \u2014 "),RN=n(yy,"A",{href:!0});var QBe=s(RN);Fdo=r(QBe,"ConditionalDetrConfig"),QBe.forEach(t),Tdo=r(yy," (Conditional DETR model)"),yy.forEach(t),Mdo=i(L),mg=n(L,"LI",{});var xy=s(mg);pfe=n(xy,"STRONG",{});var WBe=s(pfe);Edo=r(WBe,"convbert"),WBe.forEach(t),Cdo=r(xy," \u2014 "),PN=n(xy,"A",{href:!0});var UBe=s(PN);wdo=r(UBe,"ConvBertConfig"),UBe.forEach(t),Ado=r(xy," (ConvBERT model)"),xy.forEach(t),Ldo=i(L),fg=n(L,"LI",{});var $y=s(fg);_fe=n($y,"STRONG",{});var HBe=s(_fe);ydo=r(HBe,"convnext"),HBe.forEach(t),xdo=r($y," \u2014 "),BN=n($y,"A",{href:!0});var JBe=s(BN);$do=r(JBe,"ConvNextConfig"),JBe.forEach(t),kdo=r($y," (ConvNeXT model)"),$y.forEach(t),Sdo=i(L),gg=n(L,"LI",{});var ky=s(gg);bfe=n(ky,"STRONG",{});var YBe=s(bfe);Rdo=r(YBe,"ctrl"),YBe.forEach(t),Pdo=r(ky," \u2014 "),IN=n(ky,"A",{href:!0});var ZBe=s(IN);Bdo=r(ZBe,"CTRLConfig"),ZBe.forEach(t),Ido=r(ky," (CTRL model)"),ky.forEach(t),Ndo=i(L),hg=n(L,"LI",{});var Sy=s(hg);vfe=n(Sy,"STRONG",{});var KBe=s(vfe);qdo=r(KBe,"cvt"),KBe.forEach(t),jdo=r(Sy," \u2014 "),NN=n(Sy,"A",{href:!0});var eIe=s(NN);Ddo=r(eIe,"CvtConfig"),eIe.forEach(t),Gdo=r(Sy," (CvT model)"),Sy.forEach(t),Odo=i(L),ug=n(L,"LI",{});var Ry=s(ug);Ffe=n(Ry,"STRONG",{});var oIe=s(Ffe);Vdo=r(oIe,"data2vec-audio"),oIe.forEach(t),Xdo=r(Ry," \u2014 "),qN=n(Ry,"A",{href:!0});var rIe=s(qN);zdo=r(rIe,"Data2VecAudioConfig"),rIe.forEach(t),Qdo=r(Ry," (Data2VecAudio model)"),Ry.forEach(t),Wdo=i(L),pg=n(L,"LI",{});var Py=s(pg);Tfe=n(Py,"STRONG",{});var tIe=s(Tfe);Udo=r(tIe,"data2vec-text"),tIe.forEach(t),Hdo=r(Py," \u2014 "),jN=n(Py,"A",{href:!0});var aIe=s(jN);Jdo=r(aIe,"Data2VecTextConfig"),aIe.forEach(t),Ydo=r(Py," (Data2VecText model)"),Py.forEach(t),Zdo=i(L),_g=n(L,"LI",{});var By=s(_g);Mfe=n(By,"STRONG",{});var nIe=s(Mfe);Kdo=r(nIe,"data2vec-vision"),nIe.forEach(t),eco=r(By," \u2014 "),DN=n(By,"A",{href:!0});var sIe=s(DN);oco=r(sIe,"Data2VecVisionConfig"),sIe.forEach(t),rco=r(By," (Data2VecVision model)"),By.forEach(t),tco=i(L),bg=n(L,"LI",{});var Iy=s(bg);Efe=n(Iy,"STRONG",{});var lIe=s(Efe);aco=r(lIe,"deberta"),lIe.forEach(t),nco=r(Iy," \u2014 "),GN=n(Iy,"A",{href:!0});var iIe=s(GN);sco=r(iIe,"DebertaConfig"),iIe.forEach(t),lco=r(Iy," (DeBERTa model)"),Iy.forEach(t),ico=i(L),vg=n(L,"LI",{});var Ny=s(vg);Cfe=n(Ny,"STRONG",{});var dIe=s(Cfe);dco=r(dIe,"deberta-v2"),dIe.forEach(t),cco=r(Ny," \u2014 "),ON=n(Ny,"A",{href:!0});var cIe=s(ON);mco=r(cIe,"DebertaV2Config"),cIe.forEach(t),fco=r(Ny," (DeBERTa-v2 model)"),Ny.forEach(t),gco=i(L),Fg=n(L,"LI",{});var qy=s(Fg);wfe=n(qy,"STRONG",{});var mIe=s(wfe);hco=r(mIe,"decision_transformer"),mIe.forEach(t),uco=r(qy," \u2014 "),VN=n(qy,"A",{href:!0});var fIe=s(VN);pco=r(fIe,"DecisionTransformerConfig"),fIe.forEach(t),_co=r(qy," (Decision Transformer model)"),qy.forEach(t),bco=i(L),Tg=n(L,"LI",{});var jy=s(Tg);Afe=n(jy,"STRONG",{});var gIe=s(Afe);vco=r(gIe,"deformable_detr"),gIe.forEach(t),Fco=r(jy," \u2014 "),XN=n(jy,"A",{href:!0});var hIe=s(XN);Tco=r(hIe,"DeformableDetrConfig"),hIe.forEach(t),Mco=r(jy," (Deformable DETR model)"),jy.forEach(t),Eco=i(L),Mg=n(L,"LI",{});var Dy=s(Mg);Lfe=n(Dy,"STRONG",{});var uIe=s(Lfe);Cco=r(uIe,"deit"),uIe.forEach(t),wco=r(Dy," \u2014 "),zN=n(Dy,"A",{href:!0});var pIe=s(zN);Aco=r(pIe,"DeiTConfig"),pIe.forEach(t),Lco=r(Dy," (DeiT model)"),Dy.forEach(t),yco=i(L),Eg=n(L,"LI",{});var Gy=s(Eg);yfe=n(Gy,"STRONG",{});var fwt=s(yfe);xco=r(fwt,"detr"),fwt.forEach(t),$co=r(Gy," \u2014 "),QN=n(Gy,"A",{href:!0});var gwt=s(QN);kco=r(gwt,"DetrConfig"),gwt.forEach(t),Sco=r(Gy," (DETR model)"),Gy.forEach(t),Rco=i(L),Cg=n(L,"LI",{});var _Ie=s(Cg);xfe=n(_Ie,"STRONG",{});var hwt=s(xfe);Pco=r(hwt,"distilbert"),hwt.forEach(t),Bco=r(_Ie," \u2014 "),WN=n(_Ie,"A",{href:!0});var uwt=s(WN);Ico=r(uwt,"DistilBertConfig"),uwt.forEach(t),Nco=r(_Ie," (DistilBERT model)"),_Ie.forEach(t),qco=i(L),wg=n(L,"LI",{});var bIe=s(wg);$fe=n(bIe,"STRONG",{});var pwt=s($fe);jco=r(pwt,"donut-swin"),pwt.forEach(t),Dco=r(bIe," \u2014 "),UN=n(bIe,"A",{href:!0});var _wt=s(UN);Gco=r(_wt,"DonutSwinConfig"),_wt.forEach(t),Oco=r(bIe," (DonutSwin model)"),bIe.forEach(t),Vco=i(L),Ag=n(L,"LI",{});var vIe=s(Ag);kfe=n(vIe,"STRONG",{});var bwt=s(kfe);Xco=r(bwt,"dpr"),bwt.forEach(t),zco=r(vIe," \u2014 "),HN=n(vIe,"A",{href:!0});var vwt=s(HN);Qco=r(vwt,"DPRConfig"),vwt.forEach(t),Wco=r(vIe," (DPR model)"),vIe.forEach(t),Uco=i(L),Lg=n(L,"LI",{});var FIe=s(Lg);Sfe=n(FIe,"STRONG",{});var Fwt=s(Sfe);Hco=r(Fwt,"dpt"),Fwt.forEach(t),Jco=r(FIe," \u2014 "),JN=n(FIe,"A",{href:!0});var Twt=s(JN);Yco=r(Twt,"DPTConfig"),Twt.forEach(t),Zco=r(FIe," (DPT model)"),FIe.forEach(t),Kco=i(L),yg=n(L,"LI",{});var TIe=s(yg);Rfe=n(TIe,"STRONG",{});var Mwt=s(Rfe);emo=r(Mwt,"electra"),Mwt.forEach(t),omo=r(TIe," \u2014 "),YN=n(TIe,"A",{href:!0});var Ewt=s(YN);rmo=r(Ewt,"ElectraConfig"),Ewt.forEach(t),tmo=r(TIe," (ELECTRA model)"),TIe.forEach(t),amo=i(L),xg=n(L,"LI",{});var MIe=s(xg);Pfe=n(MIe,"STRONG",{});var Cwt=s(Pfe);nmo=r(Cwt,"encoder-decoder"),Cwt.forEach(t),smo=r(MIe," \u2014 "),ZN=n(MIe,"A",{href:!0});var wwt=s(ZN);lmo=r(wwt,"EncoderDecoderConfig"),wwt.forEach(t),imo=r(MIe," (Encoder decoder model)"),MIe.forEach(t),dmo=i(L),$g=n(L,"LI",{});var EIe=s($g);Bfe=n(EIe,"STRONG",{});var Awt=s(Bfe);cmo=r(Awt,"ernie"),Awt.forEach(t),mmo=r(EIe," \u2014 "),KN=n(EIe,"A",{href:!0});var Lwt=s(KN);fmo=r(Lwt,"ErnieConfig"),Lwt.forEach(t),gmo=r(EIe," (ERNIE model)"),EIe.forEach(t),hmo=i(L),kg=n(L,"LI",{});var CIe=s(kg);Ife=n(CIe,"STRONG",{});var ywt=s(Ife);umo=r(ywt,"esm"),ywt.forEach(t),pmo=r(CIe," \u2014 "),eq=n(CIe,"A",{href:!0});var xwt=s(eq);_mo=r(xwt,"EsmConfig"),xwt.forEach(t),bmo=r(CIe," (ESM model)"),CIe.forEach(t),vmo=i(L),Sg=n(L,"LI",{});var wIe=s(Sg);Nfe=n(wIe,"STRONG",{});var $wt=s(Nfe);Fmo=r($wt,"flaubert"),$wt.forEach(t),Tmo=r(wIe," \u2014 "),oq=n(wIe,"A",{href:!0});var kwt=s(oq);Mmo=r(kwt,"FlaubertConfig"),kwt.forEach(t),Emo=r(wIe," (FlauBERT model)"),wIe.forEach(t),Cmo=i(L),Rg=n(L,"LI",{});var AIe=s(Rg);qfe=n(AIe,"STRONG",{});var Swt=s(qfe);wmo=r(Swt,"flava"),Swt.forEach(t),Amo=r(AIe," \u2014 "),rq=n(AIe,"A",{href:!0});var Rwt=s(rq);Lmo=r(Rwt,"FlavaConfig"),Rwt.forEach(t),ymo=r(AIe," (FLAVA model)"),AIe.forEach(t),xmo=i(L),Pg=n(L,"LI",{});var LIe=s(Pg);jfe=n(LIe,"STRONG",{});var Pwt=s(jfe);$mo=r(Pwt,"fnet"),Pwt.forEach(t),kmo=r(LIe," \u2014 "),tq=n(LIe,"A",{href:!0});var Bwt=s(tq);Smo=r(Bwt,"FNetConfig"),Bwt.forEach(t),Rmo=r(LIe," (FNet model)"),LIe.forEach(t),Pmo=i(L),Bg=n(L,"LI",{});var yIe=s(Bg);Dfe=n(yIe,"STRONG",{});var Iwt=s(Dfe);Bmo=r(Iwt,"fsmt"),Iwt.forEach(t),Imo=r(yIe," \u2014 "),aq=n(yIe,"A",{href:!0});var Nwt=s(aq);Nmo=r(Nwt,"FSMTConfig"),Nwt.forEach(t),qmo=r(yIe," (FairSeq Machine-Translation model)"),yIe.forEach(t),jmo=i(L),Ig=n(L,"LI",{});var xIe=s(Ig);Gfe=n(xIe,"STRONG",{});var qwt=s(Gfe);Dmo=r(qwt,"funnel"),qwt.forEach(t),Gmo=r(xIe," \u2014 "),nq=n(xIe,"A",{href:!0});var jwt=s(nq);Omo=r(jwt,"FunnelConfig"),jwt.forEach(t),Vmo=r(xIe," (Funnel Transformer model)"),xIe.forEach(t),Xmo=i(L),Ng=n(L,"LI",{});var $Ie=s(Ng);Ofe=n($Ie,"STRONG",{});var Dwt=s(Ofe);zmo=r(Dwt,"glpn"),Dwt.forEach(t),Qmo=r($Ie," \u2014 "),sq=n($Ie,"A",{href:!0});var Gwt=s(sq);Wmo=r(Gwt,"GLPNConfig"),Gwt.forEach(t),Umo=r($Ie," (GLPN model)"),$Ie.forEach(t),Hmo=i(L),qg=n(L,"LI",{});var kIe=s(qg);Vfe=n(kIe,"STRONG",{});var Owt=s(Vfe);Jmo=r(Owt,"gpt2"),Owt.forEach(t),Ymo=r(kIe," \u2014 "),lq=n(kIe,"A",{href:!0});var Vwt=s(lq);Zmo=r(Vwt,"GPT2Config"),Vwt.forEach(t),Kmo=r(kIe," (OpenAI GPT-2 model)"),kIe.forEach(t),efo=i(L),jg=n(L,"LI",{});var SIe=s(jg);Xfe=n(SIe,"STRONG",{});var Xwt=s(Xfe);ofo=r(Xwt,"gpt_neo"),Xwt.forEach(t),rfo=r(SIe," \u2014 "),iq=n(SIe,"A",{href:!0});var zwt=s(iq);tfo=r(zwt,"GPTNeoConfig"),zwt.forEach(t),afo=r(SIe," (GPT Neo model)"),SIe.forEach(t),nfo=i(L),Dg=n(L,"LI",{});var RIe=s(Dg);zfe=n(RIe,"STRONG",{});var Qwt=s(zfe);sfo=r(Qwt,"gpt_neox"),Qwt.forEach(t),lfo=r(RIe," \u2014 "),dq=n(RIe,"A",{href:!0});var Wwt=s(dq);ifo=r(Wwt,"GPTNeoXConfig"),Wwt.forEach(t),dfo=r(RIe," (GPT NeoX model)"),RIe.forEach(t),cfo=i(L),Gg=n(L,"LI",{});var PIe=s(Gg);Qfe=n(PIe,"STRONG",{});var Uwt=s(Qfe);mfo=r(Uwt,"gpt_neox_japanese"),Uwt.forEach(t),ffo=r(PIe," \u2014 "),cq=n(PIe,"A",{href:!0});var Hwt=s(cq);gfo=r(Hwt,"GPTNeoXJapaneseConfig"),Hwt.forEach(t),hfo=r(PIe," (GPT NeoX Japanese model)"),PIe.forEach(t),ufo=i(L),Og=n(L,"LI",{});var BIe=s(Og);Wfe=n(BIe,"STRONG",{});var Jwt=s(Wfe);pfo=r(Jwt,"gptj"),Jwt.forEach(t),_fo=r(BIe," \u2014 "),mq=n(BIe,"A",{href:!0});var Ywt=s(mq);bfo=r(Ywt,"GPTJConfig"),Ywt.forEach(t),vfo=r(BIe," (GPT-J model)"),BIe.forEach(t),Ffo=i(L),Vg=n(L,"LI",{});var IIe=s(Vg);Ufe=n(IIe,"STRONG",{});var Zwt=s(Ufe);Tfo=r(Zwt,"groupvit"),Zwt.forEach(t),Mfo=r(IIe," \u2014 "),fq=n(IIe,"A",{href:!0});var Kwt=s(fq);Efo=r(Kwt,"GroupViTConfig"),Kwt.forEach(t),Cfo=r(IIe," (GroupViT model)"),IIe.forEach(t),wfo=i(L),Xg=n(L,"LI",{});var NIe=s(Xg);Hfe=n(NIe,"STRONG",{});var eAt=s(Hfe);Afo=r(eAt,"hubert"),eAt.forEach(t),Lfo=r(NIe," \u2014 "),gq=n(NIe,"A",{href:!0});var oAt=s(gq);yfo=r(oAt,"HubertConfig"),oAt.forEach(t),xfo=r(NIe," (Hubert model)"),NIe.forEach(t),$fo=i(L),zg=n(L,"LI",{});var qIe=s(zg);Jfe=n(qIe,"STRONG",{});var rAt=s(Jfe);kfo=r(rAt,"ibert"),rAt.forEach(t),Sfo=r(qIe," \u2014 "),hq=n(qIe,"A",{href:!0});var tAt=s(hq);Rfo=r(tAt,"IBertConfig"),tAt.forEach(t),Pfo=r(qIe," (I-BERT model)"),qIe.forEach(t),Bfo=i(L),Qg=n(L,"LI",{});var jIe=s(Qg);Yfe=n(jIe,"STRONG",{});var aAt=s(Yfe);Ifo=r(aAt,"imagegpt"),aAt.forEach(t),Nfo=r(jIe," \u2014 "),uq=n(jIe,"A",{href:!0});var nAt=s(uq);qfo=r(nAt,"ImageGPTConfig"),nAt.forEach(t),jfo=r(jIe," (ImageGPT model)"),jIe.forEach(t),Dfo=i(L),Wg=n(L,"LI",{});var DIe=s(Wg);Zfe=n(DIe,"STRONG",{});var sAt=s(Zfe);Gfo=r(sAt,"layoutlm"),sAt.forEach(t),Ofo=r(DIe," \u2014 "),pq=n(DIe,"A",{href:!0});var lAt=s(pq);Vfo=r(lAt,"LayoutLMConfig"),lAt.forEach(t),Xfo=r(DIe," (LayoutLM model)"),DIe.forEach(t),zfo=i(L),Ug=n(L,"LI",{});var GIe=s(Ug);Kfe=n(GIe,"STRONG",{});var iAt=s(Kfe);Qfo=r(iAt,"layoutlmv2"),iAt.forEach(t),Wfo=r(GIe," \u2014 "),_q=n(GIe,"A",{href:!0});var dAt=s(_q);Ufo=r(dAt,"LayoutLMv2Config"),dAt.forEach(t),Hfo=r(GIe," (LayoutLMv2 model)"),GIe.forEach(t),Jfo=i(L),Hg=n(L,"LI",{});var OIe=s(Hg);ege=n(OIe,"STRONG",{});var cAt=s(ege);Yfo=r(cAt,"layoutlmv3"),cAt.forEach(t),Zfo=r(OIe," \u2014 "),bq=n(OIe,"A",{href:!0});var mAt=s(bq);Kfo=r(mAt,"LayoutLMv3Config"),mAt.forEach(t),ego=r(OIe," (LayoutLMv3 model)"),OIe.forEach(t),ogo=i(L),Jg=n(L,"LI",{});var VIe=s(Jg);oge=n(VIe,"STRONG",{});var fAt=s(oge);rgo=r(fAt,"led"),fAt.forEach(t),tgo=r(VIe," \u2014 "),vq=n(VIe,"A",{href:!0});var gAt=s(vq);ago=r(gAt,"LEDConfig"),gAt.forEach(t),ngo=r(VIe," (LED model)"),VIe.forEach(t),sgo=i(L),Yg=n(L,"LI",{});var XIe=s(Yg);rge=n(XIe,"STRONG",{});var hAt=s(rge);lgo=r(hAt,"levit"),hAt.forEach(t),igo=r(XIe," \u2014 "),Fq=n(XIe,"A",{href:!0});var uAt=s(Fq);dgo=r(uAt,"LevitConfig"),uAt.forEach(t),cgo=r(XIe," (LeViT model)"),XIe.forEach(t),mgo=i(L),Zg=n(L,"LI",{});var zIe=s(Zg);tge=n(zIe,"STRONG",{});var pAt=s(tge);fgo=r(pAt,"lilt"),pAt.forEach(t),ggo=r(zIe," \u2014 "),Tq=n(zIe,"A",{href:!0});var _At=s(Tq);hgo=r(_At,"LiltConfig"),_At.forEach(t),ugo=r(zIe," (LiLT model)"),zIe.forEach(t),pgo=i(L),Kg=n(L,"LI",{});var QIe=s(Kg);age=n(QIe,"STRONG",{});var bAt=s(age);_go=r(bAt,"longformer"),bAt.forEach(t),bgo=r(QIe," \u2014 "),Mq=n(QIe,"A",{href:!0});var vAt=s(Mq);vgo=r(vAt,"LongformerConfig"),vAt.forEach(t),Fgo=r(QIe," (Longformer model)"),QIe.forEach(t),Tgo=i(L),eh=n(L,"LI",{});var WIe=s(eh);nge=n(WIe,"STRONG",{});var FAt=s(nge);Mgo=r(FAt,"longt5"),FAt.forEach(t),Ego=r(WIe," \u2014 "),Eq=n(WIe,"A",{href:!0});var TAt=s(Eq);Cgo=r(TAt,"LongT5Config"),TAt.forEach(t),wgo=r(WIe," (LongT5 model)"),WIe.forEach(t),Ago=i(L),oh=n(L,"LI",{});var UIe=s(oh);sge=n(UIe,"STRONG",{});var MAt=s(sge);Lgo=r(MAt,"luke"),MAt.forEach(t),ygo=r(UIe," \u2014 "),Cq=n(UIe,"A",{href:!0});var EAt=s(Cq);xgo=r(EAt,"LukeConfig"),EAt.forEach(t),$go=r(UIe," (LUKE model)"),UIe.forEach(t),kgo=i(L),rh=n(L,"LI",{});var HIe=s(rh);lge=n(HIe,"STRONG",{});var CAt=s(lge);Sgo=r(CAt,"lxmert"),CAt.forEach(t),Rgo=r(HIe," \u2014 "),wq=n(HIe,"A",{href:!0});var wAt=s(wq);Pgo=r(wAt,"LxmertConfig"),wAt.forEach(t),Bgo=r(HIe," (LXMERT model)"),HIe.forEach(t),Igo=i(L),th=n(L,"LI",{});var JIe=s(th);ige=n(JIe,"STRONG",{});var AAt=s(ige);Ngo=r(AAt,"m2m_100"),AAt.forEach(t),qgo=r(JIe," \u2014 "),Aq=n(JIe,"A",{href:!0});var LAt=s(Aq);jgo=r(LAt,"M2M100Config"),LAt.forEach(t),Dgo=r(JIe," (M2M100 model)"),JIe.forEach(t),Ggo=i(L),ah=n(L,"LI",{});var YIe=s(ah);dge=n(YIe,"STRONG",{});var yAt=s(dge);Ogo=r(yAt,"marian"),yAt.forEach(t),Vgo=r(YIe," \u2014 "),Lq=n(YIe,"A",{href:!0});var xAt=s(Lq);Xgo=r(xAt,"MarianConfig"),xAt.forEach(t),zgo=r(YIe," (Marian model)"),YIe.forEach(t),Qgo=i(L),nh=n(L,"LI",{});var ZIe=s(nh);cge=n(ZIe,"STRONG",{});var $At=s(cge);Wgo=r($At,"markuplm"),$At.forEach(t),Ugo=r(ZIe," \u2014 "),yq=n(ZIe,"A",{href:!0});var kAt=s(yq);Hgo=r(kAt,"MarkupLMConfig"),kAt.forEach(t),Jgo=r(ZIe," (MarkupLM model)"),ZIe.forEach(t),Ygo=i(L),sh=n(L,"LI",{});var KIe=s(sh);mge=n(KIe,"STRONG",{});var SAt=s(mge);Zgo=r(SAt,"maskformer"),SAt.forEach(t),Kgo=r(KIe," \u2014 "),xq=n(KIe,"A",{href:!0});var RAt=s(xq);eho=r(RAt,"MaskFormerConfig"),RAt.forEach(t),oho=r(KIe," (MaskFormer model)"),KIe.forEach(t),rho=i(L),lh=n(L,"LI",{});var eNe=s(lh);fge=n(eNe,"STRONG",{});var PAt=s(fge);tho=r(PAt,"mbart"),PAt.forEach(t),aho=r(eNe," \u2014 "),$q=n(eNe,"A",{href:!0});var BAt=s($q);nho=r(BAt,"MBartConfig"),BAt.forEach(t),sho=r(eNe," (mBART model)"),eNe.forEach(t),lho=i(L),ih=n(L,"LI",{});var oNe=s(ih);gge=n(oNe,"STRONG",{});var IAt=s(gge);iho=r(IAt,"mctct"),IAt.forEach(t),dho=r(oNe," \u2014 "),kq=n(oNe,"A",{href:!0});var NAt=s(kq);cho=r(NAt,"MCTCTConfig"),NAt.forEach(t),mho=r(oNe," (M-CTC-T model)"),oNe.forEach(t),fho=i(L),dh=n(L,"LI",{});var rNe=s(dh);hge=n(rNe,"STRONG",{});var qAt=s(hge);gho=r(qAt,"megatron-bert"),qAt.forEach(t),hho=r(rNe," \u2014 "),Sq=n(rNe,"A",{href:!0});var jAt=s(Sq);uho=r(jAt,"MegatronBertConfig"),jAt.forEach(t),pho=r(rNe," (Megatron-BERT model)"),rNe.forEach(t),_ho=i(L),ch=n(L,"LI",{});var tNe=s(ch);uge=n(tNe,"STRONG",{});var DAt=s(uge);bho=r(DAt,"mobilebert"),DAt.forEach(t),vho=r(tNe," \u2014 "),Rq=n(tNe,"A",{href:!0});var GAt=s(Rq);Fho=r(GAt,"MobileBertConfig"),GAt.forEach(t),Tho=r(tNe," (MobileBERT model)"),tNe.forEach(t),Mho=i(L),mh=n(L,"LI",{});var aNe=s(mh);pge=n(aNe,"STRONG",{});var OAt=s(pge);Eho=r(OAt,"mobilevit"),OAt.forEach(t),Cho=r(aNe," \u2014 "),Pq=n(aNe,"A",{href:!0});var VAt=s(Pq);who=r(VAt,"MobileViTConfig"),VAt.forEach(t),Aho=r(aNe," (MobileViT model)"),aNe.forEach(t),Lho=i(L),fh=n(L,"LI",{});var nNe=s(fh);_ge=n(nNe,"STRONG",{});var XAt=s(_ge);yho=r(XAt,"mpnet"),XAt.forEach(t),xho=r(nNe," \u2014 "),Bq=n(nNe,"A",{href:!0});var zAt=s(Bq);$ho=r(zAt,"MPNetConfig"),zAt.forEach(t),kho=r(nNe," (MPNet model)"),nNe.forEach(t),Sho=i(L),gh=n(L,"LI",{});var sNe=s(gh);bge=n(sNe,"STRONG",{});var QAt=s(bge);Rho=r(QAt,"mt5"),QAt.forEach(t),Pho=r(sNe," \u2014 "),Iq=n(sNe,"A",{href:!0});var WAt=s(Iq);Bho=r(WAt,"MT5Config"),WAt.forEach(t),Iho=r(sNe," (MT5 model)"),sNe.forEach(t),Nho=i(L),hh=n(L,"LI",{});var lNe=s(hh);vge=n(lNe,"STRONG",{});var UAt=s(vge);qho=r(UAt,"mvp"),UAt.forEach(t),jho=r(lNe," \u2014 "),Nq=n(lNe,"A",{href:!0});var HAt=s(Nq);Dho=r(HAt,"MvpConfig"),HAt.forEach(t),Gho=r(lNe," (MVP model)"),lNe.forEach(t),Oho=i(L),uh=n(L,"LI",{});var iNe=s(uh);Fge=n(iNe,"STRONG",{});var JAt=s(Fge);Vho=r(JAt,"nezha"),JAt.forEach(t),Xho=r(iNe," \u2014 "),qq=n(iNe,"A",{href:!0});var YAt=s(qq);zho=r(YAt,"NezhaConfig"),YAt.forEach(t),Qho=r(iNe," (Nezha model)"),iNe.forEach(t),Who=i(L),ph=n(L,"LI",{});var dNe=s(ph);Tge=n(dNe,"STRONG",{});var ZAt=s(Tge);Uho=r(ZAt,"nystromformer"),ZAt.forEach(t),Hho=r(dNe," \u2014 "),jq=n(dNe,"A",{href:!0});var KAt=s(jq);Jho=r(KAt,"NystromformerConfig"),KAt.forEach(t),Yho=r(dNe," (Nystr\xF6mformer model)"),dNe.forEach(t),Zho=i(L),_h=n(L,"LI",{});var cNe=s(_h);Mge=n(cNe,"STRONG",{});var e6t=s(Mge);Kho=r(e6t,"openai-gpt"),e6t.forEach(t),euo=r(cNe," \u2014 "),Dq=n(cNe,"A",{href:!0});var o6t=s(Dq);ouo=r(o6t,"OpenAIGPTConfig"),o6t.forEach(t),ruo=r(cNe," (OpenAI GPT model)"),cNe.forEach(t),tuo=i(L),bh=n(L,"LI",{});var mNe=s(bh);Ege=n(mNe,"STRONG",{});var r6t=s(Ege);auo=r(r6t,"opt"),r6t.forEach(t),nuo=r(mNe," \u2014 "),Gq=n(mNe,"A",{href:!0});var t6t=s(Gq);suo=r(t6t,"OPTConfig"),t6t.forEach(t),luo=r(mNe," (OPT model)"),mNe.forEach(t),iuo=i(L),vh=n(L,"LI",{});var fNe=s(vh);Cge=n(fNe,"STRONG",{});var a6t=s(Cge);duo=r(a6t,"owlvit"),a6t.forEach(t),cuo=r(fNe," \u2014 "),Oq=n(fNe,"A",{href:!0});var n6t=s(Oq);muo=r(n6t,"OwlViTConfig"),n6t.forEach(t),fuo=r(fNe," (OWL-ViT model)"),fNe.forEach(t),guo=i(L),Fh=n(L,"LI",{});var gNe=s(Fh);wge=n(gNe,"STRONG",{});var s6t=s(wge);huo=r(s6t,"pegasus"),s6t.forEach(t),uuo=r(gNe," \u2014 "),Vq=n(gNe,"A",{href:!0});var l6t=s(Vq);puo=r(l6t,"PegasusConfig"),l6t.forEach(t),_uo=r(gNe," (Pegasus model)"),gNe.forEach(t),buo=i(L),Th=n(L,"LI",{});var hNe=s(Th);Age=n(hNe,"STRONG",{});var i6t=s(Age);vuo=r(i6t,"pegasus_x"),i6t.forEach(t),Fuo=r(hNe," \u2014 "),Xq=n(hNe,"A",{href:!0});var d6t=s(Xq);Tuo=r(d6t,"PegasusXConfig"),d6t.forEach(t),Muo=r(hNe," (PEGASUS-X model)"),hNe.forEach(t),Euo=i(L),Mh=n(L,"LI",{});var uNe=s(Mh);Lge=n(uNe,"STRONG",{});var c6t=s(Lge);Cuo=r(c6t,"perceiver"),c6t.forEach(t),wuo=r(uNe," \u2014 "),zq=n(uNe,"A",{href:!0});var m6t=s(zq);Auo=r(m6t,"PerceiverConfig"),m6t.forEach(t),Luo=r(uNe," (Perceiver model)"),uNe.forEach(t),yuo=i(L),Eh=n(L,"LI",{});var pNe=s(Eh);yge=n(pNe,"STRONG",{});var f6t=s(yge);xuo=r(f6t,"plbart"),f6t.forEach(t),$uo=r(pNe," \u2014 "),Qq=n(pNe,"A",{href:!0});var g6t=s(Qq);kuo=r(g6t,"PLBartConfig"),g6t.forEach(t),Suo=r(pNe," (PLBart model)"),pNe.forEach(t),Ruo=i(L),Ch=n(L,"LI",{});var _Ne=s(Ch);xge=n(_Ne,"STRONG",{});var h6t=s(xge);Puo=r(h6t,"poolformer"),h6t.forEach(t),Buo=r(_Ne," \u2014 "),Wq=n(_Ne,"A",{href:!0});var u6t=s(Wq);Iuo=r(u6t,"PoolFormerConfig"),u6t.forEach(t),Nuo=r(_Ne," (PoolFormer model)"),_Ne.forEach(t),quo=i(L),wh=n(L,"LI",{});var bNe=s(wh);$ge=n(bNe,"STRONG",{});var p6t=s($ge);juo=r(p6t,"prophetnet"),p6t.forEach(t),Duo=r(bNe," \u2014 "),Uq=n(bNe,"A",{href:!0});var _6t=s(Uq);Guo=r(_6t,"ProphetNetConfig"),_6t.forEach(t),Ouo=r(bNe," (ProphetNet model)"),bNe.forEach(t),Vuo=i(L),Ah=n(L,"LI",{});var vNe=s(Ah);kge=n(vNe,"STRONG",{});var b6t=s(kge);Xuo=r(b6t,"qdqbert"),b6t.forEach(t),zuo=r(vNe," \u2014 "),Hq=n(vNe,"A",{href:!0});var v6t=s(Hq);Quo=r(v6t,"QDQBertConfig"),v6t.forEach(t),Wuo=r(vNe," (QDQBert model)"),vNe.forEach(t),Uuo=i(L),Lh=n(L,"LI",{});var FNe=s(Lh);Sge=n(FNe,"STRONG",{});var F6t=s(Sge);Huo=r(F6t,"rag"),F6t.forEach(t),Juo=r(FNe," \u2014 "),Jq=n(FNe,"A",{href:!0});var T6t=s(Jq);Yuo=r(T6t,"RagConfig"),T6t.forEach(t),Zuo=r(FNe," (RAG model)"),FNe.forEach(t),Kuo=i(L),yh=n(L,"LI",{});var TNe=s(yh);Rge=n(TNe,"STRONG",{});var M6t=s(Rge);epo=r(M6t,"realm"),M6t.forEach(t),opo=r(TNe," \u2014 "),Yq=n(TNe,"A",{href:!0});var E6t=s(Yq);rpo=r(E6t,"RealmConfig"),E6t.forEach(t),tpo=r(TNe," (REALM model)"),TNe.forEach(t),apo=i(L),xh=n(L,"LI",{});var MNe=s(xh);Pge=n(MNe,"STRONG",{});var C6t=s(Pge);npo=r(C6t,"reformer"),C6t.forEach(t),spo=r(MNe," \u2014 "),Zq=n(MNe,"A",{href:!0});var w6t=s(Zq);lpo=r(w6t,"ReformerConfig"),w6t.forEach(t),ipo=r(MNe," (Reformer model)"),MNe.forEach(t),dpo=i(L),$h=n(L,"LI",{});var ENe=s($h);Bge=n(ENe,"STRONG",{});var A6t=s(Bge);cpo=r(A6t,"regnet"),A6t.forEach(t),mpo=r(ENe," \u2014 "),Kq=n(ENe,"A",{href:!0});var L6t=s(Kq);fpo=r(L6t,"RegNetConfig"),L6t.forEach(t),gpo=r(ENe," (RegNet model)"),ENe.forEach(t),hpo=i(L),kh=n(L,"LI",{});var CNe=s(kh);Ige=n(CNe,"STRONG",{});var y6t=s(Ige);upo=r(y6t,"rembert"),y6t.forEach(t),ppo=r(CNe," \u2014 "),ej=n(CNe,"A",{href:!0});var x6t=s(ej);_po=r(x6t,"RemBertConfig"),x6t.forEach(t),bpo=r(CNe," (RemBERT model)"),CNe.forEach(t),vpo=i(L),Sh=n(L,"LI",{});var wNe=s(Sh);Nge=n(wNe,"STRONG",{});var $6t=s(Nge);Fpo=r($6t,"resnet"),$6t.forEach(t),Tpo=r(wNe," \u2014 "),oj=n(wNe,"A",{href:!0});var k6t=s(oj);Mpo=r(k6t,"ResNetConfig"),k6t.forEach(t),Epo=r(wNe," (ResNet model)"),wNe.forEach(t),Cpo=i(L),Rh=n(L,"LI",{});var ANe=s(Rh);qge=n(ANe,"STRONG",{});var S6t=s(qge);wpo=r(S6t,"retribert"),S6t.forEach(t),Apo=r(ANe," \u2014 "),rj=n(ANe,"A",{href:!0});var R6t=s(rj);Lpo=r(R6t,"RetriBertConfig"),R6t.forEach(t),ypo=r(ANe," (RetriBERT model)"),ANe.forEach(t),xpo=i(L),Ph=n(L,"LI",{});var LNe=s(Ph);jge=n(LNe,"STRONG",{});var P6t=s(jge);$po=r(P6t,"roberta"),P6t.forEach(t),kpo=r(LNe," \u2014 "),tj=n(LNe,"A",{href:!0});var B6t=s(tj);Spo=r(B6t,"RobertaConfig"),B6t.forEach(t),Rpo=r(LNe," (RoBERTa model)"),LNe.forEach(t),Ppo=i(L),Bh=n(L,"LI",{});var yNe=s(Bh);Dge=n(yNe,"STRONG",{});var I6t=s(Dge);Bpo=r(I6t,"roformer"),I6t.forEach(t),Ipo=r(yNe," \u2014 "),aj=n(yNe,"A",{href:!0});var N6t=s(aj);Npo=r(N6t,"RoFormerConfig"),N6t.forEach(t),qpo=r(yNe," (RoFormer model)"),yNe.forEach(t),jpo=i(L),Ih=n(L,"LI",{});var xNe=s(Ih);Gge=n(xNe,"STRONG",{});var q6t=s(Gge);Dpo=r(q6t,"segformer"),q6t.forEach(t),Gpo=r(xNe," \u2014 "),nj=n(xNe,"A",{href:!0});var j6t=s(nj);Opo=r(j6t,"SegformerConfig"),j6t.forEach(t),Vpo=r(xNe," (SegFormer model)"),xNe.forEach(t),Xpo=i(L),Nh=n(L,"LI",{});var $Ne=s(Nh);Oge=n($Ne,"STRONG",{});var D6t=s(Oge);zpo=r(D6t,"sew"),D6t.forEach(t),Qpo=r($Ne," \u2014 "),sj=n($Ne,"A",{href:!0});var G6t=s(sj);Wpo=r(G6t,"SEWConfig"),G6t.forEach(t),Upo=r($Ne," (SEW model)"),$Ne.forEach(t),Hpo=i(L),qh=n(L,"LI",{});var kNe=s(qh);Vge=n(kNe,"STRONG",{});var O6t=s(Vge);Jpo=r(O6t,"sew-d"),O6t.forEach(t),Ypo=r(kNe," \u2014 "),lj=n(kNe,"A",{href:!0});var V6t=s(lj);Zpo=r(V6t,"SEWDConfig"),V6t.forEach(t),Kpo=r(kNe," (SEW-D model)"),kNe.forEach(t),e_o=i(L),jh=n(L,"LI",{});var SNe=s(jh);Xge=n(SNe,"STRONG",{});var X6t=s(Xge);o_o=r(X6t,"speech-encoder-decoder"),X6t.forEach(t),r_o=r(SNe," \u2014 "),ij=n(SNe,"A",{href:!0});var z6t=s(ij);t_o=r(z6t,"SpeechEncoderDecoderConfig"),z6t.forEach(t),a_o=r(SNe," (Speech Encoder decoder model)"),SNe.forEach(t),n_o=i(L),Dh=n(L,"LI",{});var RNe=s(Dh);zge=n(RNe,"STRONG",{});var Q6t=s(zge);s_o=r(Q6t,"speech_to_text"),Q6t.forEach(t),l_o=r(RNe," \u2014 "),dj=n(RNe,"A",{href:!0});var W6t=s(dj);i_o=r(W6t,"Speech2TextConfig"),W6t.forEach(t),d_o=r(RNe," (Speech2Text model)"),RNe.forEach(t),c_o=i(L),Gh=n(L,"LI",{});var PNe=s(Gh);Qge=n(PNe,"STRONG",{});var U6t=s(Qge);m_o=r(U6t,"speech_to_text_2"),U6t.forEach(t),f_o=r(PNe," \u2014 "),cj=n(PNe,"A",{href:!0});var H6t=s(cj);g_o=r(H6t,"Speech2Text2Config"),H6t.forEach(t),h_o=r(PNe," (Speech2Text2 model)"),PNe.forEach(t),u_o=i(L),Oh=n(L,"LI",{});var BNe=s(Oh);Wge=n(BNe,"STRONG",{});var J6t=s(Wge);p_o=r(J6t,"splinter"),J6t.forEach(t),__o=r(BNe," \u2014 "),mj=n(BNe,"A",{href:!0});var Y6t=s(mj);b_o=r(Y6t,"SplinterConfig"),Y6t.forEach(t),v_o=r(BNe," (Splinter model)"),BNe.forEach(t),F_o=i(L),Vh=n(L,"LI",{});var INe=s(Vh);Uge=n(INe,"STRONG",{});var Z6t=s(Uge);T_o=r(Z6t,"squeezebert"),Z6t.forEach(t),M_o=r(INe," \u2014 "),fj=n(INe,"A",{href:!0});var K6t=s(fj);E_o=r(K6t,"SqueezeBertConfig"),K6t.forEach(t),C_o=r(INe," (SqueezeBERT model)"),INe.forEach(t),w_o=i(L),Xh=n(L,"LI",{});var NNe=s(Xh);Hge=n(NNe,"STRONG",{});var e7t=s(Hge);A_o=r(e7t,"swin"),e7t.forEach(t),L_o=r(NNe," \u2014 "),gj=n(NNe,"A",{href:!0});var o7t=s(gj);y_o=r(o7t,"SwinConfig"),o7t.forEach(t),x_o=r(NNe," (Swin Transformer model)"),NNe.forEach(t),$_o=i(L),zh=n(L,"LI",{});var qNe=s(zh);Jge=n(qNe,"STRONG",{});var r7t=s(Jge);k_o=r(r7t,"swinv2"),r7t.forEach(t),S_o=r(qNe," \u2014 "),hj=n(qNe,"A",{href:!0});var t7t=s(hj);R_o=r(t7t,"Swinv2Config"),t7t.forEach(t),P_o=r(qNe," (Swin Transformer V2 model)"),qNe.forEach(t),B_o=i(L),Qh=n(L,"LI",{});var jNe=s(Qh);Yge=n(jNe,"STRONG",{});var a7t=s(Yge);I_o=r(a7t,"t5"),a7t.forEach(t),N_o=r(jNe," \u2014 "),uj=n(jNe,"A",{href:!0});var n7t=s(uj);q_o=r(n7t,"T5Config"),n7t.forEach(t),j_o=r(jNe," (T5 model)"),jNe.forEach(t),D_o=i(L),Wh=n(L,"LI",{});var DNe=s(Wh);Zge=n(DNe,"STRONG",{});var s7t=s(Zge);G_o=r(s7t,"tapas"),s7t.forEach(t),O_o=r(DNe," \u2014 "),pj=n(DNe,"A",{href:!0});var l7t=s(pj);V_o=r(l7t,"TapasConfig"),l7t.forEach(t),X_o=r(DNe," (TAPAS model)"),DNe.forEach(t),z_o=i(L),Uh=n(L,"LI",{});var GNe=s(Uh);Kge=n(GNe,"STRONG",{});var i7t=s(Kge);Q_o=r(i7t,"time_series_transformer"),i7t.forEach(t),W_o=r(GNe," \u2014 "),_j=n(GNe,"A",{href:!0});var d7t=s(_j);U_o=r(d7t,"TimeSeriesTransformerConfig"),d7t.forEach(t),H_o=r(GNe," (Time Series Transformer model)"),GNe.forEach(t),J_o=i(L),Hh=n(L,"LI",{});var ONe=s(Hh);ehe=n(ONe,"STRONG",{});var c7t=s(ehe);Y_o=r(c7t,"trajectory_transformer"),c7t.forEach(t),Z_o=r(ONe," \u2014 "),bj=n(ONe,"A",{href:!0});var m7t=s(bj);K_o=r(m7t,"TrajectoryTransformerConfig"),m7t.forEach(t),e1o=r(ONe," (Trajectory Transformer model)"),ONe.forEach(t),o1o=i(L),Jh=n(L,"LI",{});var VNe=s(Jh);ohe=n(VNe,"STRONG",{});var f7t=s(ohe);r1o=r(f7t,"transfo-xl"),f7t.forEach(t),t1o=r(VNe," \u2014 "),vj=n(VNe,"A",{href:!0});var g7t=s(vj);a1o=r(g7t,"TransfoXLConfig"),g7t.forEach(t),n1o=r(VNe," (Transformer-XL model)"),VNe.forEach(t),s1o=i(L),Yh=n(L,"LI",{});var XNe=s(Yh);rhe=n(XNe,"STRONG",{});var h7t=s(rhe);l1o=r(h7t,"trocr"),h7t.forEach(t),i1o=r(XNe," \u2014 "),Fj=n(XNe,"A",{href:!0});var u7t=s(Fj);d1o=r(u7t,"TrOCRConfig"),u7t.forEach(t),c1o=r(XNe," (TrOCR model)"),XNe.forEach(t),m1o=i(L),Zh=n(L,"LI",{});var zNe=s(Zh);the=n(zNe,"STRONG",{});var p7t=s(the);f1o=r(p7t,"unispeech"),p7t.forEach(t),g1o=r(zNe," \u2014 "),Tj=n(zNe,"A",{href:!0});var _7t=s(Tj);h1o=r(_7t,"UniSpeechConfig"),_7t.forEach(t),u1o=r(zNe," (UniSpeech model)"),zNe.forEach(t),p1o=i(L),Kh=n(L,"LI",{});var QNe=s(Kh);ahe=n(QNe,"STRONG",{});var b7t=s(ahe);_1o=r(b7t,"unispeech-sat"),b7t.forEach(t),b1o=r(QNe," \u2014 "),Mj=n(QNe,"A",{href:!0});var v7t=s(Mj);v1o=r(v7t,"UniSpeechSatConfig"),v7t.forEach(t),F1o=r(QNe," (UniSpeechSat model)"),QNe.forEach(t),T1o=i(L),eu=n(L,"LI",{});var WNe=s(eu);nhe=n(WNe,"STRONG",{});var F7t=s(nhe);M1o=r(F7t,"van"),F7t.forEach(t),E1o=r(WNe," \u2014 "),Ej=n(WNe,"A",{href:!0});var T7t=s(Ej);C1o=r(T7t,"VanConfig"),T7t.forEach(t),w1o=r(WNe," (VAN model)"),WNe.forEach(t),A1o=i(L),ou=n(L,"LI",{});var UNe=s(ou);she=n(UNe,"STRONG",{});var M7t=s(she);L1o=r(M7t,"videomae"),M7t.forEach(t),y1o=r(UNe," \u2014 "),Cj=n(UNe,"A",{href:!0});var E7t=s(Cj);x1o=r(E7t,"VideoMAEConfig"),E7t.forEach(t),$1o=r(UNe," (VideoMAE model)"),UNe.forEach(t),k1o=i(L),ru=n(L,"LI",{});var HNe=s(ru);lhe=n(HNe,"STRONG",{});var C7t=s(lhe);S1o=r(C7t,"vilt"),C7t.forEach(t),R1o=r(HNe," \u2014 "),wj=n(HNe,"A",{href:!0});var w7t=s(wj);P1o=r(w7t,"ViltConfig"),w7t.forEach(t),B1o=r(HNe," (ViLT model)"),HNe.forEach(t),I1o=i(L),tu=n(L,"LI",{});var JNe=s(tu);ihe=n(JNe,"STRONG",{});var A7t=s(ihe);N1o=r(A7t,"vision-encoder-decoder"),A7t.forEach(t),q1o=r(JNe," \u2014 "),Aj=n(JNe,"A",{href:!0});var L7t=s(Aj);j1o=r(L7t,"VisionEncoderDecoderConfig"),L7t.forEach(t),D1o=r(JNe," (Vision Encoder decoder model)"),JNe.forEach(t),G1o=i(L),au=n(L,"LI",{});var YNe=s(au);dhe=n(YNe,"STRONG",{});var y7t=s(dhe);O1o=r(y7t,"vision-text-dual-encoder"),y7t.forEach(t),V1o=r(YNe," \u2014 "),Lj=n(YNe,"A",{href:!0});var x7t=s(Lj);X1o=r(x7t,"VisionTextDualEncoderConfig"),x7t.forEach(t),z1o=r(YNe," (VisionTextDualEncoder model)"),YNe.forEach(t),Q1o=i(L),nu=n(L,"LI",{});var ZNe=s(nu);che=n(ZNe,"STRONG",{});var $7t=s(che);W1o=r($7t,"visual_bert"),$7t.forEach(t),U1o=r(ZNe," \u2014 "),yj=n(ZNe,"A",{href:!0});var k7t=s(yj);H1o=r(k7t,"VisualBertConfig"),k7t.forEach(t),J1o=r(ZNe," (VisualBERT model)"),ZNe.forEach(t),Y1o=i(L),su=n(L,"LI",{});var KNe=s(su);mhe=n(KNe,"STRONG",{});var S7t=s(mhe);Z1o=r(S7t,"vit"),S7t.forEach(t),K1o=r(KNe," \u2014 "),xj=n(KNe,"A",{href:!0});var R7t=s(xj);e2o=r(R7t,"ViTConfig"),R7t.forEach(t),o2o=r(KNe," (ViT model)"),KNe.forEach(t),r2o=i(L),lu=n(L,"LI",{});var eqe=s(lu);fhe=n(eqe,"STRONG",{});var P7t=s(fhe);t2o=r(P7t,"vit_mae"),P7t.forEach(t),a2o=r(eqe," \u2014 "),$j=n(eqe,"A",{href:!0});var B7t=s($j);n2o=r(B7t,"ViTMAEConfig"),B7t.forEach(t),s2o=r(eqe," (ViTMAE model)"),eqe.forEach(t),l2o=i(L),iu=n(L,"LI",{});var oqe=s(iu);ghe=n(oqe,"STRONG",{});var I7t=s(ghe);i2o=r(I7t,"vit_msn"),I7t.forEach(t),d2o=r(oqe," \u2014 "),kj=n(oqe,"A",{href:!0});var N7t=s(kj);c2o=r(N7t,"ViTMSNConfig"),N7t.forEach(t),m2o=r(oqe," (ViTMSN model)"),oqe.forEach(t),f2o=i(L),du=n(L,"LI",{});var rqe=s(du);hhe=n(rqe,"STRONG",{});var q7t=s(hhe);g2o=r(q7t,"wav2vec2"),q7t.forEach(t),h2o=r(rqe," \u2014 "),Sj=n(rqe,"A",{href:!0});var j7t=s(Sj);u2o=r(j7t,"Wav2Vec2Config"),j7t.forEach(t),p2o=r(rqe," (Wav2Vec2 model)"),rqe.forEach(t),_2o=i(L),cu=n(L,"LI",{});var tqe=s(cu);uhe=n(tqe,"STRONG",{});var D7t=s(uhe);b2o=r(D7t,"wav2vec2-conformer"),D7t.forEach(t),v2o=r(tqe," \u2014 "),Rj=n(tqe,"A",{href:!0});var G7t=s(Rj);F2o=r(G7t,"Wav2Vec2ConformerConfig"),G7t.forEach(t),T2o=r(tqe," (Wav2Vec2-Conformer model)"),tqe.forEach(t),M2o=i(L),mu=n(L,"LI",{});var aqe=s(mu);phe=n(aqe,"STRONG",{});var O7t=s(phe);E2o=r(O7t,"wavlm"),O7t.forEach(t),C2o=r(aqe," \u2014 "),Pj=n(aqe,"A",{href:!0});var V7t=s(Pj);w2o=r(V7t,"WavLMConfig"),V7t.forEach(t),A2o=r(aqe," (WavLM model)"),aqe.forEach(t),L2o=i(L),fu=n(L,"LI",{});var nqe=s(fu);_he=n(nqe,"STRONG",{});var X7t=s(_he);y2o=r(X7t,"whisper"),X7t.forEach(t),x2o=r(nqe," \u2014 "),Bj=n(nqe,"A",{href:!0});var z7t=s(Bj);$2o=r(z7t,"WhisperConfig"),z7t.forEach(t),k2o=r(nqe," (Whisper model)"),nqe.forEach(t),S2o=i(L),gu=n(L,"LI",{});var sqe=s(gu);bhe=n(sqe,"STRONG",{});var Q7t=s(bhe);R2o=r(Q7t,"xclip"),Q7t.forEach(t),P2o=r(sqe," \u2014 "),Ij=n(sqe,"A",{href:!0});var W7t=s(Ij);B2o=r(W7t,"XCLIPConfig"),W7t.forEach(t),I2o=r(sqe," (X-CLIP model)"),sqe.forEach(t),N2o=i(L),hu=n(L,"LI",{});var lqe=s(hu);vhe=n(lqe,"STRONG",{});var U7t=s(vhe);q2o=r(U7t,"xglm"),U7t.forEach(t),j2o=r(lqe," \u2014 "),Nj=n(lqe,"A",{href:!0});var H7t=s(Nj);D2o=r(H7t,"XGLMConfig"),H7t.forEach(t),G2o=r(lqe," (XGLM model)"),lqe.forEach(t),O2o=i(L),uu=n(L,"LI",{});var iqe=s(uu);Fhe=n(iqe,"STRONG",{});var J7t=s(Fhe);V2o=r(J7t,"xlm"),J7t.forEach(t),X2o=r(iqe," \u2014 "),qj=n(iqe,"A",{href:!0});var Y7t=s(qj);z2o=r(Y7t,"XLMConfig"),Y7t.forEach(t),Q2o=r(iqe," (XLM model)"),iqe.forEach(t),W2o=i(L),pu=n(L,"LI",{});var dqe=s(pu);The=n(dqe,"STRONG",{});var Z7t=s(The);U2o=r(Z7t,"xlm-prophetnet"),Z7t.forEach(t),H2o=r(dqe," \u2014 "),jj=n(dqe,"A",{href:!0});var K7t=s(jj);J2o=r(K7t,"XLMProphetNetConfig"),K7t.forEach(t),Y2o=r(dqe," (XLM-ProphetNet model)"),dqe.forEach(t),Z2o=i(L),_u=n(L,"LI",{});var cqe=s(_u);Mhe=n(cqe,"STRONG",{});var eLt=s(Mhe);K2o=r(eLt,"xlm-roberta"),eLt.forEach(t),ebo=r(cqe," \u2014 "),Dj=n(cqe,"A",{href:!0});var oLt=s(Dj);obo=r(oLt,"XLMRobertaConfig"),oLt.forEach(t),rbo=r(cqe," (XLM-RoBERTa model)"),cqe.forEach(t),tbo=i(L),bu=n(L,"LI",{});var mqe=s(bu);Ehe=n(mqe,"STRONG",{});var rLt=s(Ehe);abo=r(rLt,"xlm-roberta-xl"),rLt.forEach(t),nbo=r(mqe," \u2014 "),Gj=n(mqe,"A",{href:!0});var tLt=s(Gj);sbo=r(tLt,"XLMRobertaXLConfig"),tLt.forEach(t),lbo=r(mqe," (XLM-RoBERTa-XL model)"),mqe.forEach(t),ibo=i(L),vu=n(L,"LI",{});var fqe=s(vu);Che=n(fqe,"STRONG",{});var aLt=s(Che);dbo=r(aLt,"xlnet"),aLt.forEach(t),cbo=r(fqe," \u2014 "),Oj=n(fqe,"A",{href:!0});var nLt=s(Oj);mbo=r(nLt,"XLNetConfig"),nLt.forEach(t),fbo=r(fqe," (XLNet model)"),fqe.forEach(t),gbo=i(L),Fu=n(L,"LI",{});var gqe=s(Fu);whe=n(gqe,"STRONG",{});var sLt=s(whe);hbo=r(sLt,"yolos"),sLt.forEach(t),ubo=r(gqe," \u2014 "),Vj=n(gqe,"A",{href:!0});var lLt=s(Vj);pbo=r(lLt,"YolosConfig"),lLt.forEach(t),_bo=r(gqe," (YOLOS model)"),gqe.forEach(t),bbo=i(L),Tu=n(L,"LI",{});var hqe=s(Tu);Ahe=n(hqe,"STRONG",{});var iLt=s(Ahe);vbo=r(iLt,"yoso"),iLt.forEach(t),Fbo=r(hqe," \u2014 "),Xj=n(hqe,"A",{href:!0});var dLt=s(Xj);Tbo=r(dLt,"YosoConfig"),dLt.forEach(t),Mbo=r(hqe," (YOSO model)"),hqe.forEach(t),L.forEach(t),Ebo=i(vt),T(Mu.$$.fragment,vt),vt.forEach(t),Cbo=i(bt),Eu=n(bt,"DIV",{class:!0});var sno=s(Eu);T(l$.$$.fragment,sno),wbo=i(sno),Lhe=n(sno,"P",{});var cLt=s(Lhe);Abo=r(cLt,"Register a new configuration for this class."),cLt.forEach(t),sno.forEach(t),bt.forEach(t),Hro=i(m),Ad=n(m,"H2",{class:!0});var lno=s(Ad);Cu=n(lno,"A",{id:!0,class:!0,href:!0});var mLt=s(Cu);yhe=n(mLt,"SPAN",{});var fLt=s(yhe);T(i$.$$.fragment,fLt),fLt.forEach(t),mLt.forEach(t),Lbo=i(lno),xhe=n(lno,"SPAN",{});var gLt=s(xhe);ybo=r(gLt,"AutoTokenizer"),gLt.forEach(t),lno.forEach(t),Jro=i(m),Ro=n(m,"DIV",{class:!0});var Rl=s(Ro);T(d$.$$.fragment,Rl),xbo=i(Rl),c$=n(Rl,"P",{});var ino=s(c$);$bo=r(ino,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),zj=n(ino,"A",{href:!0});var hLt=s(zj);kbo=r(hLt,"AutoTokenizer.from_pretrained()"),hLt.forEach(t),Sbo=r(ino," class method."),ino.forEach(t),Rbo=i(Rl),m$=n(Rl,"P",{});var dno=s(m$);Pbo=r(dno,"This class cannot be instantiated directly using "),$he=n(dno,"CODE",{});var uLt=s($he);Bbo=r(uLt,"__init__()"),uLt.forEach(t),Ibo=r(dno," (throws an error)."),dno.forEach(t),Nbo=i(Rl),jr=n(Rl,"DIV",{class:!0});var Pl=s(jr);T(f$.$$.fragment,Pl),qbo=i(Pl),khe=n(Pl,"P",{});var pLt=s(khe);jbo=r(pLt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),pLt.forEach(t),Dbo=i(Pl),rn=n(Pl,"P",{});var Oy=s(rn);Gbo=r(Oy,"The tokenizer class to instantiate is selected based on the "),She=n(Oy,"CODE",{});var _Lt=s(She);Obo=r(_Lt,"model_type"),_Lt.forEach(t),Vbo=r(Oy,` property of the config object (either
passed as an argument or loaded from `),Rhe=n(Oy,"CODE",{});var bLt=s(Rhe);Xbo=r(bLt,"pretrained_model_name_or_path"),bLt.forEach(t),zbo=r(Oy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Phe=n(Oy,"CODE",{});var vLt=s(Phe);Qbo=r(vLt,"pretrained_model_name_or_path"),vLt.forEach(t),Wbo=r(Oy,":"),Oy.forEach(t),Ubo=i(Pl),k=n(Pl,"UL",{});var S=s(k);us=n(S,"LI",{});var UB=s(us);Bhe=n(UB,"STRONG",{});var FLt=s(Bhe);Hbo=r(FLt,"albert"),FLt.forEach(t),Jbo=r(UB," \u2014 "),Qj=n(UB,"A",{href:!0});var TLt=s(Qj);Ybo=r(TLt,"AlbertTokenizer"),TLt.forEach(t),Zbo=r(UB," or "),Wj=n(UB,"A",{href:!0});var MLt=s(Wj);Kbo=r(MLt,"AlbertTokenizerFast"),MLt.forEach(t),evo=r(UB," (ALBERT model)"),UB.forEach(t),ovo=i(S),ps=n(S,"LI",{});var HB=s(ps);Ihe=n(HB,"STRONG",{});var ELt=s(Ihe);rvo=r(ELt,"bart"),ELt.forEach(t),tvo=r(HB," \u2014 "),Uj=n(HB,"A",{href:!0});var CLt=s(Uj);avo=r(CLt,"BartTokenizer"),CLt.forEach(t),nvo=r(HB," or "),Hj=n(HB,"A",{href:!0});var wLt=s(Hj);svo=r(wLt,"BartTokenizerFast"),wLt.forEach(t),lvo=r(HB," (BART model)"),HB.forEach(t),ivo=i(S),_s=n(S,"LI",{});var JB=s(_s);Nhe=n(JB,"STRONG",{});var ALt=s(Nhe);dvo=r(ALt,"barthez"),ALt.forEach(t),cvo=r(JB," \u2014 "),Jj=n(JB,"A",{href:!0});var LLt=s(Jj);mvo=r(LLt,"BarthezTokenizer"),LLt.forEach(t),fvo=r(JB," or "),Yj=n(JB,"A",{href:!0});var yLt=s(Yj);gvo=r(yLt,"BarthezTokenizerFast"),yLt.forEach(t),hvo=r(JB," (BARThez model)"),JB.forEach(t),uvo=i(S),wu=n(S,"LI",{});var uqe=s(wu);qhe=n(uqe,"STRONG",{});var xLt=s(qhe);pvo=r(xLt,"bartpho"),xLt.forEach(t),_vo=r(uqe," \u2014 "),Zj=n(uqe,"A",{href:!0});var $Lt=s(Zj);bvo=r($Lt,"BartphoTokenizer"),$Lt.forEach(t),vvo=r(uqe," (BARTpho model)"),uqe.forEach(t),Fvo=i(S),bs=n(S,"LI",{});var YB=s(bs);jhe=n(YB,"STRONG",{});var kLt=s(jhe);Tvo=r(kLt,"bert"),kLt.forEach(t),Mvo=r(YB," \u2014 "),Kj=n(YB,"A",{href:!0});var SLt=s(Kj);Evo=r(SLt,"BertTokenizer"),SLt.forEach(t),Cvo=r(YB," or "),eD=n(YB,"A",{href:!0});var RLt=s(eD);wvo=r(RLt,"BertTokenizerFast"),RLt.forEach(t),Avo=r(YB," (BERT model)"),YB.forEach(t),Lvo=i(S),Au=n(S,"LI",{});var pqe=s(Au);Dhe=n(pqe,"STRONG",{});var PLt=s(Dhe);yvo=r(PLt,"bert-generation"),PLt.forEach(t),xvo=r(pqe," \u2014 "),oD=n(pqe,"A",{href:!0});var BLt=s(oD);$vo=r(BLt,"BertGenerationTokenizer"),BLt.forEach(t),kvo=r(pqe," (Bert Generation model)"),pqe.forEach(t),Svo=i(S),Lu=n(S,"LI",{});var _qe=s(Lu);Ghe=n(_qe,"STRONG",{});var ILt=s(Ghe);Rvo=r(ILt,"bert-japanese"),ILt.forEach(t),Pvo=r(_qe," \u2014 "),rD=n(_qe,"A",{href:!0});var NLt=s(rD);Bvo=r(NLt,"BertJapaneseTokenizer"),NLt.forEach(t),Ivo=r(_qe," (BertJapanese model)"),_qe.forEach(t),Nvo=i(S),yu=n(S,"LI",{});var bqe=s(yu);Ohe=n(bqe,"STRONG",{});var qLt=s(Ohe);qvo=r(qLt,"bertweet"),qLt.forEach(t),jvo=r(bqe," \u2014 "),tD=n(bqe,"A",{href:!0});var jLt=s(tD);Dvo=r(jLt,"BertweetTokenizer"),jLt.forEach(t),Gvo=r(bqe," (BERTweet model)"),bqe.forEach(t),Ovo=i(S),vs=n(S,"LI",{});var ZB=s(vs);Vhe=n(ZB,"STRONG",{});var DLt=s(Vhe);Vvo=r(DLt,"big_bird"),DLt.forEach(t),Xvo=r(ZB," \u2014 "),aD=n(ZB,"A",{href:!0});var GLt=s(aD);zvo=r(GLt,"BigBirdTokenizer"),GLt.forEach(t),Qvo=r(ZB," or "),nD=n(ZB,"A",{href:!0});var OLt=s(nD);Wvo=r(OLt,"BigBirdTokenizerFast"),OLt.forEach(t),Uvo=r(ZB," (BigBird model)"),ZB.forEach(t),Hvo=i(S),Fs=n(S,"LI",{});var KB=s(Fs);Xhe=n(KB,"STRONG",{});var VLt=s(Xhe);Jvo=r(VLt,"bigbird_pegasus"),VLt.forEach(t),Yvo=r(KB," \u2014 "),sD=n(KB,"A",{href:!0});var XLt=s(sD);Zvo=r(XLt,"PegasusTokenizer"),XLt.forEach(t),Kvo=r(KB," or "),lD=n(KB,"A",{href:!0});var zLt=s(lD);eFo=r(zLt,"PegasusTokenizerFast"),zLt.forEach(t),oFo=r(KB," (BigBird-Pegasus model)"),KB.forEach(t),rFo=i(S),Ts=n(S,"LI",{});var eI=s(Ts);zhe=n(eI,"STRONG",{});var QLt=s(zhe);tFo=r(QLt,"blenderbot"),QLt.forEach(t),aFo=r(eI," \u2014 "),iD=n(eI,"A",{href:!0});var WLt=s(iD);nFo=r(WLt,"BlenderbotTokenizer"),WLt.forEach(t),sFo=r(eI," or "),dD=n(eI,"A",{href:!0});var ULt=s(dD);lFo=r(ULt,"BlenderbotTokenizerFast"),ULt.forEach(t),iFo=r(eI," (Blenderbot model)"),eI.forEach(t),dFo=i(S),xu=n(S,"LI",{});var vqe=s(xu);Qhe=n(vqe,"STRONG",{});var HLt=s(Qhe);cFo=r(HLt,"blenderbot-small"),HLt.forEach(t),mFo=r(vqe," \u2014 "),cD=n(vqe,"A",{href:!0});var JLt=s(cD);fFo=r(JLt,"BlenderbotSmallTokenizer"),JLt.forEach(t),gFo=r(vqe," (BlenderbotSmall model)"),vqe.forEach(t),hFo=i(S),$u=n(S,"LI",{});var Fqe=s($u);Whe=n(Fqe,"STRONG",{});var YLt=s(Whe);uFo=r(YLt,"bloom"),YLt.forEach(t),pFo=r(Fqe," \u2014 "),mD=n(Fqe,"A",{href:!0});var ZLt=s(mD);_Fo=r(ZLt,"BloomTokenizerFast"),ZLt.forEach(t),bFo=r(Fqe," (BLOOM model)"),Fqe.forEach(t),vFo=i(S),ku=n(S,"LI",{});var Tqe=s(ku);Uhe=n(Tqe,"STRONG",{});var KLt=s(Uhe);FFo=r(KLt,"byt5"),KLt.forEach(t),TFo=r(Tqe," \u2014 "),fD=n(Tqe,"A",{href:!0});var e8t=s(fD);MFo=r(e8t,"ByT5Tokenizer"),e8t.forEach(t),EFo=r(Tqe," (ByT5 model)"),Tqe.forEach(t),CFo=i(S),Ms=n(S,"LI",{});var oI=s(Ms);Hhe=n(oI,"STRONG",{});var o8t=s(Hhe);wFo=r(o8t,"camembert"),o8t.forEach(t),AFo=r(oI," \u2014 "),gD=n(oI,"A",{href:!0});var r8t=s(gD);LFo=r(r8t,"CamembertTokenizer"),r8t.forEach(t),yFo=r(oI," or "),hD=n(oI,"A",{href:!0});var t8t=s(hD);xFo=r(t8t,"CamembertTokenizerFast"),t8t.forEach(t),$Fo=r(oI," (CamemBERT model)"),oI.forEach(t),kFo=i(S),Su=n(S,"LI",{});var Mqe=s(Su);Jhe=n(Mqe,"STRONG",{});var a8t=s(Jhe);SFo=r(a8t,"canine"),a8t.forEach(t),RFo=r(Mqe," \u2014 "),uD=n(Mqe,"A",{href:!0});var n8t=s(uD);PFo=r(n8t,"CanineTokenizer"),n8t.forEach(t),BFo=r(Mqe," (CANINE model)"),Mqe.forEach(t),IFo=i(S),Es=n(S,"LI",{});var rI=s(Es);Yhe=n(rI,"STRONG",{});var s8t=s(Yhe);NFo=r(s8t,"clip"),s8t.forEach(t),qFo=r(rI," \u2014 "),pD=n(rI,"A",{href:!0});var l8t=s(pD);jFo=r(l8t,"CLIPTokenizer"),l8t.forEach(t),DFo=r(rI," or "),_D=n(rI,"A",{href:!0});var i8t=s(_D);GFo=r(i8t,"CLIPTokenizerFast"),i8t.forEach(t),OFo=r(rI," (CLIP model)"),rI.forEach(t),VFo=i(S),Cs=n(S,"LI",{});var tI=s(Cs);Zhe=n(tI,"STRONG",{});var d8t=s(Zhe);XFo=r(d8t,"codegen"),d8t.forEach(t),zFo=r(tI," \u2014 "),bD=n(tI,"A",{href:!0});var c8t=s(bD);QFo=r(c8t,"CodeGenTokenizer"),c8t.forEach(t),WFo=r(tI," or "),vD=n(tI,"A",{href:!0});var m8t=s(vD);UFo=r(m8t,"CodeGenTokenizerFast"),m8t.forEach(t),HFo=r(tI," (CodeGen model)"),tI.forEach(t),JFo=i(S),ws=n(S,"LI",{});var aI=s(ws);Khe=n(aI,"STRONG",{});var f8t=s(Khe);YFo=r(f8t,"convbert"),f8t.forEach(t),ZFo=r(aI," \u2014 "),FD=n(aI,"A",{href:!0});var g8t=s(FD);KFo=r(g8t,"ConvBertTokenizer"),g8t.forEach(t),eTo=r(aI," or "),TD=n(aI,"A",{href:!0});var h8t=s(TD);oTo=r(h8t,"ConvBertTokenizerFast"),h8t.forEach(t),rTo=r(aI," (ConvBERT model)"),aI.forEach(t),tTo=i(S),As=n(S,"LI",{});var nI=s(As);eue=n(nI,"STRONG",{});var u8t=s(eue);aTo=r(u8t,"cpm"),u8t.forEach(t),nTo=r(nI," \u2014 "),MD=n(nI,"A",{href:!0});var p8t=s(MD);sTo=r(p8t,"CpmTokenizer"),p8t.forEach(t),lTo=r(nI," or "),ED=n(nI,"A",{href:!0});var _8t=s(ED);iTo=r(_8t,"CpmTokenizerFast"),_8t.forEach(t),dTo=r(nI," (CPM model)"),nI.forEach(t),cTo=i(S),Ru=n(S,"LI",{});var Eqe=s(Ru);oue=n(Eqe,"STRONG",{});var b8t=s(oue);mTo=r(b8t,"ctrl"),b8t.forEach(t),fTo=r(Eqe," \u2014 "),CD=n(Eqe,"A",{href:!0});var v8t=s(CD);gTo=r(v8t,"CTRLTokenizer"),v8t.forEach(t),hTo=r(Eqe," (CTRL model)"),Eqe.forEach(t),uTo=i(S),Ls=n(S,"LI",{});var sI=s(Ls);rue=n(sI,"STRONG",{});var F8t=s(rue);pTo=r(F8t,"data2vec-text"),F8t.forEach(t),_To=r(sI," \u2014 "),wD=n(sI,"A",{href:!0});var T8t=s(wD);bTo=r(T8t,"RobertaTokenizer"),T8t.forEach(t),vTo=r(sI," or "),AD=n(sI,"A",{href:!0});var M8t=s(AD);FTo=r(M8t,"RobertaTokenizerFast"),M8t.forEach(t),TTo=r(sI," (Data2VecText model)"),sI.forEach(t),MTo=i(S),ys=n(S,"LI",{});var lI=s(ys);tue=n(lI,"STRONG",{});var E8t=s(tue);ETo=r(E8t,"deberta"),E8t.forEach(t),CTo=r(lI," \u2014 "),LD=n(lI,"A",{href:!0});var C8t=s(LD);wTo=r(C8t,"DebertaTokenizer"),C8t.forEach(t),ATo=r(lI," or "),yD=n(lI,"A",{href:!0});var w8t=s(yD);LTo=r(w8t,"DebertaTokenizerFast"),w8t.forEach(t),yTo=r(lI," (DeBERTa model)"),lI.forEach(t),xTo=i(S),xs=n(S,"LI",{});var iI=s(xs);aue=n(iI,"STRONG",{});var A8t=s(aue);$To=r(A8t,"deberta-v2"),A8t.forEach(t),kTo=r(iI," \u2014 "),xD=n(iI,"A",{href:!0});var L8t=s(xD);STo=r(L8t,"DebertaV2Tokenizer"),L8t.forEach(t),RTo=r(iI," or "),$D=n(iI,"A",{href:!0});var y8t=s($D);PTo=r(y8t,"DebertaV2TokenizerFast"),y8t.forEach(t),BTo=r(iI," (DeBERTa-v2 model)"),iI.forEach(t),ITo=i(S),$s=n(S,"LI",{});var dI=s($s);nue=n(dI,"STRONG",{});var x8t=s(nue);NTo=r(x8t,"distilbert"),x8t.forEach(t),qTo=r(dI," \u2014 "),kD=n(dI,"A",{href:!0});var $8t=s(kD);jTo=r($8t,"DistilBertTokenizer"),$8t.forEach(t),DTo=r(dI," or "),SD=n(dI,"A",{href:!0});var k8t=s(SD);GTo=r(k8t,"DistilBertTokenizerFast"),k8t.forEach(t),OTo=r(dI," (DistilBERT model)"),dI.forEach(t),VTo=i(S),ks=n(S,"LI",{});var cI=s(ks);sue=n(cI,"STRONG",{});var S8t=s(sue);XTo=r(S8t,"dpr"),S8t.forEach(t),zTo=r(cI," \u2014 "),RD=n(cI,"A",{href:!0});var R8t=s(RD);QTo=r(R8t,"DPRQuestionEncoderTokenizer"),R8t.forEach(t),WTo=r(cI," or "),PD=n(cI,"A",{href:!0});var P8t=s(PD);UTo=r(P8t,"DPRQuestionEncoderTokenizerFast"),P8t.forEach(t),HTo=r(cI," (DPR model)"),cI.forEach(t),JTo=i(S),Ss=n(S,"LI",{});var mI=s(Ss);lue=n(mI,"STRONG",{});var B8t=s(lue);YTo=r(B8t,"electra"),B8t.forEach(t),ZTo=r(mI," \u2014 "),BD=n(mI,"A",{href:!0});var I8t=s(BD);KTo=r(I8t,"ElectraTokenizer"),I8t.forEach(t),eMo=r(mI," or "),ID=n(mI,"A",{href:!0});var N8t=s(ID);oMo=r(N8t,"ElectraTokenizerFast"),N8t.forEach(t),rMo=r(mI," (ELECTRA model)"),mI.forEach(t),tMo=i(S),Rs=n(S,"LI",{});var fI=s(Rs);iue=n(fI,"STRONG",{});var q8t=s(iue);aMo=r(q8t,"ernie"),q8t.forEach(t),nMo=r(fI," \u2014 "),ND=n(fI,"A",{href:!0});var j8t=s(ND);sMo=r(j8t,"BertTokenizer"),j8t.forEach(t),lMo=r(fI," or "),qD=n(fI,"A",{href:!0});var D8t=s(qD);iMo=r(D8t,"BertTokenizerFast"),D8t.forEach(t),dMo=r(fI," (ERNIE model)"),fI.forEach(t),cMo=i(S),Pu=n(S,"LI",{});var Cqe=s(Pu);due=n(Cqe,"STRONG",{});var G8t=s(due);mMo=r(G8t,"flaubert"),G8t.forEach(t),fMo=r(Cqe," \u2014 "),jD=n(Cqe,"A",{href:!0});var O8t=s(jD);gMo=r(O8t,"FlaubertTokenizer"),O8t.forEach(t),hMo=r(Cqe," (FlauBERT model)"),Cqe.forEach(t),uMo=i(S),Ps=n(S,"LI",{});var gI=s(Ps);cue=n(gI,"STRONG",{});var V8t=s(cue);pMo=r(V8t,"fnet"),V8t.forEach(t),_Mo=r(gI," \u2014 "),DD=n(gI,"A",{href:!0});var X8t=s(DD);bMo=r(X8t,"FNetTokenizer"),X8t.forEach(t),vMo=r(gI," or "),GD=n(gI,"A",{href:!0});var z8t=s(GD);FMo=r(z8t,"FNetTokenizerFast"),z8t.forEach(t),TMo=r(gI," (FNet model)"),gI.forEach(t),MMo=i(S),Bu=n(S,"LI",{});var wqe=s(Bu);mue=n(wqe,"STRONG",{});var Q8t=s(mue);EMo=r(Q8t,"fsmt"),Q8t.forEach(t),CMo=r(wqe," \u2014 "),OD=n(wqe,"A",{href:!0});var W8t=s(OD);wMo=r(W8t,"FSMTTokenizer"),W8t.forEach(t),AMo=r(wqe," (FairSeq Machine-Translation model)"),wqe.forEach(t),LMo=i(S),Bs=n(S,"LI",{});var hI=s(Bs);fue=n(hI,"STRONG",{});var U8t=s(fue);yMo=r(U8t,"funnel"),U8t.forEach(t),xMo=r(hI," \u2014 "),VD=n(hI,"A",{href:!0});var H8t=s(VD);$Mo=r(H8t,"FunnelTokenizer"),H8t.forEach(t),kMo=r(hI," or "),XD=n(hI,"A",{href:!0});var J8t=s(XD);SMo=r(J8t,"FunnelTokenizerFast"),J8t.forEach(t),RMo=r(hI," (Funnel Transformer model)"),hI.forEach(t),PMo=i(S),Is=n(S,"LI",{});var uI=s(Is);gue=n(uI,"STRONG",{});var Y8t=s(gue);BMo=r(Y8t,"gpt2"),Y8t.forEach(t),IMo=r(uI," \u2014 "),zD=n(uI,"A",{href:!0});var Z8t=s(zD);NMo=r(Z8t,"GPT2Tokenizer"),Z8t.forEach(t),qMo=r(uI," or "),QD=n(uI,"A",{href:!0});var K8t=s(QD);jMo=r(K8t,"GPT2TokenizerFast"),K8t.forEach(t),DMo=r(uI," (OpenAI GPT-2 model)"),uI.forEach(t),GMo=i(S),Ns=n(S,"LI",{});var pI=s(Ns);hue=n(pI,"STRONG",{});var eyt=s(hue);OMo=r(eyt,"gpt_neo"),eyt.forEach(t),VMo=r(pI," \u2014 "),WD=n(pI,"A",{href:!0});var oyt=s(WD);XMo=r(oyt,"GPT2Tokenizer"),oyt.forEach(t),zMo=r(pI," or "),UD=n(pI,"A",{href:!0});var ryt=s(UD);QMo=r(ryt,"GPT2TokenizerFast"),ryt.forEach(t),WMo=r(pI," (GPT Neo model)"),pI.forEach(t),UMo=i(S),Iu=n(S,"LI",{});var Aqe=s(Iu);uue=n(Aqe,"STRONG",{});var tyt=s(uue);HMo=r(tyt,"gpt_neox"),tyt.forEach(t),JMo=r(Aqe," \u2014 "),HD=n(Aqe,"A",{href:!0});var ayt=s(HD);YMo=r(ayt,"GPTNeoXTokenizerFast"),ayt.forEach(t),ZMo=r(Aqe," (GPT NeoX model)"),Aqe.forEach(t),KMo=i(S),Nu=n(S,"LI",{});var Lqe=s(Nu);pue=n(Lqe,"STRONG",{});var nyt=s(pue);eEo=r(nyt,"gpt_neox_japanese"),nyt.forEach(t),oEo=r(Lqe," \u2014 "),JD=n(Lqe,"A",{href:!0});var syt=s(JD);rEo=r(syt,"GPTNeoXJapaneseTokenizer"),syt.forEach(t),tEo=r(Lqe," (GPT NeoX Japanese model)"),Lqe.forEach(t),aEo=i(S),qs=n(S,"LI",{});var _I=s(qs);_ue=n(_I,"STRONG",{});var lyt=s(_ue);nEo=r(lyt,"gptj"),lyt.forEach(t),sEo=r(_I," \u2014 "),YD=n(_I,"A",{href:!0});var iyt=s(YD);lEo=r(iyt,"GPT2Tokenizer"),iyt.forEach(t),iEo=r(_I," or "),ZD=n(_I,"A",{href:!0});var dyt=s(ZD);dEo=r(dyt,"GPT2TokenizerFast"),dyt.forEach(t),cEo=r(_I," (GPT-J model)"),_I.forEach(t),mEo=i(S),js=n(S,"LI",{});var bI=s(js);bue=n(bI,"STRONG",{});var cyt=s(bue);fEo=r(cyt,"groupvit"),cyt.forEach(t),gEo=r(bI," \u2014 "),KD=n(bI,"A",{href:!0});var myt=s(KD);hEo=r(myt,"CLIPTokenizer"),myt.forEach(t),uEo=r(bI," or "),eG=n(bI,"A",{href:!0});var fyt=s(eG);pEo=r(fyt,"CLIPTokenizerFast"),fyt.forEach(t),_Eo=r(bI," (GroupViT model)"),bI.forEach(t),bEo=i(S),Ds=n(S,"LI",{});var vI=s(Ds);vue=n(vI,"STRONG",{});var gyt=s(vue);vEo=r(gyt,"herbert"),gyt.forEach(t),FEo=r(vI," \u2014 "),oG=n(vI,"A",{href:!0});var hyt=s(oG);TEo=r(hyt,"HerbertTokenizer"),hyt.forEach(t),MEo=r(vI," or "),rG=n(vI,"A",{href:!0});var uyt=s(rG);EEo=r(uyt,"HerbertTokenizerFast"),uyt.forEach(t),CEo=r(vI," (HerBERT model)"),vI.forEach(t),wEo=i(S),qu=n(S,"LI",{});var yqe=s(qu);Fue=n(yqe,"STRONG",{});var pyt=s(Fue);AEo=r(pyt,"hubert"),pyt.forEach(t),LEo=r(yqe," \u2014 "),tG=n(yqe,"A",{href:!0});var _yt=s(tG);yEo=r(_yt,"Wav2Vec2CTCTokenizer"),_yt.forEach(t),xEo=r(yqe," (Hubert model)"),yqe.forEach(t),$Eo=i(S),Gs=n(S,"LI",{});var FI=s(Gs);Tue=n(FI,"STRONG",{});var byt=s(Tue);kEo=r(byt,"ibert"),byt.forEach(t),SEo=r(FI," \u2014 "),aG=n(FI,"A",{href:!0});var vyt=s(aG);REo=r(vyt,"RobertaTokenizer"),vyt.forEach(t),PEo=r(FI," or "),nG=n(FI,"A",{href:!0});var Fyt=s(nG);BEo=r(Fyt,"RobertaTokenizerFast"),Fyt.forEach(t),IEo=r(FI," (I-BERT model)"),FI.forEach(t),NEo=i(S),Os=n(S,"LI",{});var TI=s(Os);Mue=n(TI,"STRONG",{});var Tyt=s(Mue);qEo=r(Tyt,"layoutlm"),Tyt.forEach(t),jEo=r(TI," \u2014 "),sG=n(TI,"A",{href:!0});var Myt=s(sG);DEo=r(Myt,"LayoutLMTokenizer"),Myt.forEach(t),GEo=r(TI," or "),lG=n(TI,"A",{href:!0});var Eyt=s(lG);OEo=r(Eyt,"LayoutLMTokenizerFast"),Eyt.forEach(t),VEo=r(TI," (LayoutLM model)"),TI.forEach(t),XEo=i(S),Vs=n(S,"LI",{});var MI=s(Vs);Eue=n(MI,"STRONG",{});var Cyt=s(Eue);zEo=r(Cyt,"layoutlmv2"),Cyt.forEach(t),QEo=r(MI," \u2014 "),iG=n(MI,"A",{href:!0});var wyt=s(iG);WEo=r(wyt,"LayoutLMv2Tokenizer"),wyt.forEach(t),UEo=r(MI," or "),dG=n(MI,"A",{href:!0});var Ayt=s(dG);HEo=r(Ayt,"LayoutLMv2TokenizerFast"),Ayt.forEach(t),JEo=r(MI," (LayoutLMv2 model)"),MI.forEach(t),YEo=i(S),Xs=n(S,"LI",{});var EI=s(Xs);Cue=n(EI,"STRONG",{});var Lyt=s(Cue);ZEo=r(Lyt,"layoutlmv3"),Lyt.forEach(t),KEo=r(EI," \u2014 "),cG=n(EI,"A",{href:!0});var yyt=s(cG);e4o=r(yyt,"LayoutLMv3Tokenizer"),yyt.forEach(t),o4o=r(EI," or "),mG=n(EI,"A",{href:!0});var xyt=s(mG);r4o=r(xyt,"LayoutLMv3TokenizerFast"),xyt.forEach(t),t4o=r(EI," (LayoutLMv3 model)"),EI.forEach(t),a4o=i(S),zs=n(S,"LI",{});var CI=s(zs);wue=n(CI,"STRONG",{});var $yt=s(wue);n4o=r($yt,"layoutxlm"),$yt.forEach(t),s4o=r(CI," \u2014 "),fG=n(CI,"A",{href:!0});var kyt=s(fG);l4o=r(kyt,"LayoutXLMTokenizer"),kyt.forEach(t),i4o=r(CI," or "),gG=n(CI,"A",{href:!0});var Syt=s(gG);d4o=r(Syt,"LayoutXLMTokenizerFast"),Syt.forEach(t),c4o=r(CI," (LayoutXLM model)"),CI.forEach(t),m4o=i(S),Qs=n(S,"LI",{});var wI=s(Qs);Aue=n(wI,"STRONG",{});var Ryt=s(Aue);f4o=r(Ryt,"led"),Ryt.forEach(t),g4o=r(wI," \u2014 "),hG=n(wI,"A",{href:!0});var Pyt=s(hG);h4o=r(Pyt,"LEDTokenizer"),Pyt.forEach(t),u4o=r(wI," or "),uG=n(wI,"A",{href:!0});var Byt=s(uG);p4o=r(Byt,"LEDTokenizerFast"),Byt.forEach(t),_4o=r(wI," (LED model)"),wI.forEach(t),b4o=i(S),Ws=n(S,"LI",{});var AI=s(Ws);Lue=n(AI,"STRONG",{});var Iyt=s(Lue);v4o=r(Iyt,"lilt"),Iyt.forEach(t),F4o=r(AI," \u2014 "),pG=n(AI,"A",{href:!0});var Nyt=s(pG);T4o=r(Nyt,"LayoutLMv3Tokenizer"),Nyt.forEach(t),M4o=r(AI," or "),_G=n(AI,"A",{href:!0});var qyt=s(_G);E4o=r(qyt,"LayoutLMv3TokenizerFast"),qyt.forEach(t),C4o=r(AI," (LiLT model)"),AI.forEach(t),w4o=i(S),Us=n(S,"LI",{});var LI=s(Us);yue=n(LI,"STRONG",{});var jyt=s(yue);A4o=r(jyt,"longformer"),jyt.forEach(t),L4o=r(LI," \u2014 "),bG=n(LI,"A",{href:!0});var Dyt=s(bG);y4o=r(Dyt,"LongformerTokenizer"),Dyt.forEach(t),x4o=r(LI," or "),vG=n(LI,"A",{href:!0});var Gyt=s(vG);$4o=r(Gyt,"LongformerTokenizerFast"),Gyt.forEach(t),k4o=r(LI," (Longformer model)"),LI.forEach(t),S4o=i(S),Hs=n(S,"LI",{});var yI=s(Hs);xue=n(yI,"STRONG",{});var Oyt=s(xue);R4o=r(Oyt,"longt5"),Oyt.forEach(t),P4o=r(yI," \u2014 "),FG=n(yI,"A",{href:!0});var Vyt=s(FG);B4o=r(Vyt,"T5Tokenizer"),Vyt.forEach(t),I4o=r(yI," or "),TG=n(yI,"A",{href:!0});var Xyt=s(TG);N4o=r(Xyt,"T5TokenizerFast"),Xyt.forEach(t),q4o=r(yI," (LongT5 model)"),yI.forEach(t),j4o=i(S),ju=n(S,"LI",{});var xqe=s(ju);$ue=n(xqe,"STRONG",{});var zyt=s($ue);D4o=r(zyt,"luke"),zyt.forEach(t),G4o=r(xqe," \u2014 "),MG=n(xqe,"A",{href:!0});var Qyt=s(MG);O4o=r(Qyt,"LukeTokenizer"),Qyt.forEach(t),V4o=r(xqe," (LUKE model)"),xqe.forEach(t),X4o=i(S),Js=n(S,"LI",{});var xI=s(Js);kue=n(xI,"STRONG",{});var Wyt=s(kue);z4o=r(Wyt,"lxmert"),Wyt.forEach(t),Q4o=r(xI," \u2014 "),EG=n(xI,"A",{href:!0});var Uyt=s(EG);W4o=r(Uyt,"LxmertTokenizer"),Uyt.forEach(t),U4o=r(xI," or "),CG=n(xI,"A",{href:!0});var Hyt=s(CG);H4o=r(Hyt,"LxmertTokenizerFast"),Hyt.forEach(t),J4o=r(xI," (LXMERT model)"),xI.forEach(t),Y4o=i(S),Du=n(S,"LI",{});var $qe=s(Du);Sue=n($qe,"STRONG",{});var Jyt=s(Sue);Z4o=r(Jyt,"m2m_100"),Jyt.forEach(t),K4o=r($qe," \u2014 "),wG=n($qe,"A",{href:!0});var Yyt=s(wG);eCo=r(Yyt,"M2M100Tokenizer"),Yyt.forEach(t),oCo=r($qe," (M2M100 model)"),$qe.forEach(t),rCo=i(S),Gu=n(S,"LI",{});var kqe=s(Gu);Rue=n(kqe,"STRONG",{});var Zyt=s(Rue);tCo=r(Zyt,"marian"),Zyt.forEach(t),aCo=r(kqe," \u2014 "),AG=n(kqe,"A",{href:!0});var Kyt=s(AG);nCo=r(Kyt,"MarianTokenizer"),Kyt.forEach(t),sCo=r(kqe," (Marian model)"),kqe.forEach(t),lCo=i(S),Ys=n(S,"LI",{});var $I=s(Ys);Pue=n($I,"STRONG",{});var e9t=s(Pue);iCo=r(e9t,"mbart"),e9t.forEach(t),dCo=r($I," \u2014 "),LG=n($I,"A",{href:!0});var o9t=s(LG);cCo=r(o9t,"MBartTokenizer"),o9t.forEach(t),mCo=r($I," or "),yG=n($I,"A",{href:!0});var r9t=s(yG);fCo=r(r9t,"MBartTokenizerFast"),r9t.forEach(t),gCo=r($I," (mBART model)"),$I.forEach(t),hCo=i(S),Zs=n(S,"LI",{});var kI=s(Zs);Bue=n(kI,"STRONG",{});var t9t=s(Bue);uCo=r(t9t,"mbart50"),t9t.forEach(t),pCo=r(kI," \u2014 "),xG=n(kI,"A",{href:!0});var a9t=s(xG);_Co=r(a9t,"MBart50Tokenizer"),a9t.forEach(t),bCo=r(kI," or "),$G=n(kI,"A",{href:!0});var n9t=s($G);vCo=r(n9t,"MBart50TokenizerFast"),n9t.forEach(t),FCo=r(kI," (mBART-50 model)"),kI.forEach(t),TCo=i(S),Ks=n(S,"LI",{});var SI=s(Ks);Iue=n(SI,"STRONG",{});var s9t=s(Iue);MCo=r(s9t,"megatron-bert"),s9t.forEach(t),ECo=r(SI," \u2014 "),kG=n(SI,"A",{href:!0});var l9t=s(kG);CCo=r(l9t,"BertTokenizer"),l9t.forEach(t),wCo=r(SI," or "),SG=n(SI,"A",{href:!0});var i9t=s(SG);ACo=r(i9t,"BertTokenizerFast"),i9t.forEach(t),LCo=r(SI," (Megatron-BERT model)"),SI.forEach(t),yCo=i(S),Ou=n(S,"LI",{});var Sqe=s(Ou);Nue=n(Sqe,"STRONG",{});var d9t=s(Nue);xCo=r(d9t,"mluke"),d9t.forEach(t),$Co=r(Sqe," \u2014 "),RG=n(Sqe,"A",{href:!0});var c9t=s(RG);kCo=r(c9t,"MLukeTokenizer"),c9t.forEach(t),SCo=r(Sqe," (mLUKE model)"),Sqe.forEach(t),RCo=i(S),el=n(S,"LI",{});var RI=s(el);que=n(RI,"STRONG",{});var m9t=s(que);PCo=r(m9t,"mobilebert"),m9t.forEach(t),BCo=r(RI," \u2014 "),PG=n(RI,"A",{href:!0});var f9t=s(PG);ICo=r(f9t,"MobileBertTokenizer"),f9t.forEach(t),NCo=r(RI," or "),BG=n(RI,"A",{href:!0});var g9t=s(BG);qCo=r(g9t,"MobileBertTokenizerFast"),g9t.forEach(t),jCo=r(RI," (MobileBERT model)"),RI.forEach(t),DCo=i(S),ol=n(S,"LI",{});var PI=s(ol);jue=n(PI,"STRONG",{});var h9t=s(jue);GCo=r(h9t,"mpnet"),h9t.forEach(t),OCo=r(PI," \u2014 "),IG=n(PI,"A",{href:!0});var u9t=s(IG);VCo=r(u9t,"MPNetTokenizer"),u9t.forEach(t),XCo=r(PI," or "),NG=n(PI,"A",{href:!0});var p9t=s(NG);zCo=r(p9t,"MPNetTokenizerFast"),p9t.forEach(t),QCo=r(PI," (MPNet model)"),PI.forEach(t),WCo=i(S),rl=n(S,"LI",{});var BI=s(rl);Due=n(BI,"STRONG",{});var _9t=s(Due);UCo=r(_9t,"mt5"),_9t.forEach(t),HCo=r(BI," \u2014 "),qG=n(BI,"A",{href:!0});var b9t=s(qG);JCo=r(b9t,"MT5Tokenizer"),b9t.forEach(t),YCo=r(BI," or "),jG=n(BI,"A",{href:!0});var v9t=s(jG);ZCo=r(v9t,"MT5TokenizerFast"),v9t.forEach(t),KCo=r(BI," (MT5 model)"),BI.forEach(t),e3o=i(S),tl=n(S,"LI",{});var II=s(tl);Gue=n(II,"STRONG",{});var F9t=s(Gue);o3o=r(F9t,"mvp"),F9t.forEach(t),r3o=r(II," \u2014 "),DG=n(II,"A",{href:!0});var T9t=s(DG);t3o=r(T9t,"MvpTokenizer"),T9t.forEach(t),a3o=r(II," or "),GG=n(II,"A",{href:!0});var M9t=s(GG);n3o=r(M9t,"MvpTokenizerFast"),M9t.forEach(t),s3o=r(II," (MVP model)"),II.forEach(t),l3o=i(S),al=n(S,"LI",{});var NI=s(al);Oue=n(NI,"STRONG",{});var E9t=s(Oue);i3o=r(E9t,"nezha"),E9t.forEach(t),d3o=r(NI," \u2014 "),OG=n(NI,"A",{href:!0});var C9t=s(OG);c3o=r(C9t,"BertTokenizer"),C9t.forEach(t),m3o=r(NI," or "),VG=n(NI,"A",{href:!0});var w9t=s(VG);f3o=r(w9t,"BertTokenizerFast"),w9t.forEach(t),g3o=r(NI," (Nezha model)"),NI.forEach(t),h3o=i(S),nl=n(S,"LI",{});var qI=s(nl);Vue=n(qI,"STRONG",{});var A9t=s(Vue);u3o=r(A9t,"nllb"),A9t.forEach(t),p3o=r(qI," \u2014 "),XG=n(qI,"A",{href:!0});var L9t=s(XG);_3o=r(L9t,"NllbTokenizer"),L9t.forEach(t),b3o=r(qI," or "),zG=n(qI,"A",{href:!0});var y9t=s(zG);v3o=r(y9t,"NllbTokenizerFast"),y9t.forEach(t),F3o=r(qI," (NLLB model)"),qI.forEach(t),T3o=i(S),sl=n(S,"LI",{});var jI=s(sl);Xue=n(jI,"STRONG",{});var x9t=s(Xue);M3o=r(x9t,"nystromformer"),x9t.forEach(t),E3o=r(jI," \u2014 "),QG=n(jI,"A",{href:!0});var $9t=s(QG);C3o=r($9t,"AlbertTokenizer"),$9t.forEach(t),w3o=r(jI," or "),WG=n(jI,"A",{href:!0});var k9t=s(WG);A3o=r(k9t,"AlbertTokenizerFast"),k9t.forEach(t),L3o=r(jI," (Nystr\xF6mformer model)"),jI.forEach(t),y3o=i(S),ll=n(S,"LI",{});var DI=s(ll);zue=n(DI,"STRONG",{});var S9t=s(zue);x3o=r(S9t,"openai-gpt"),S9t.forEach(t),$3o=r(DI," \u2014 "),UG=n(DI,"A",{href:!0});var R9t=s(UG);k3o=r(R9t,"OpenAIGPTTokenizer"),R9t.forEach(t),S3o=r(DI," or "),HG=n(DI,"A",{href:!0});var P9t=s(HG);R3o=r(P9t,"OpenAIGPTTokenizerFast"),P9t.forEach(t),P3o=r(DI," (OpenAI GPT model)"),DI.forEach(t),B3o=i(S),Vu=n(S,"LI",{});var Rqe=s(Vu);Que=n(Rqe,"STRONG",{});var B9t=s(Que);I3o=r(B9t,"opt"),B9t.forEach(t),N3o=r(Rqe," \u2014 "),JG=n(Rqe,"A",{href:!0});var I9t=s(JG);q3o=r(I9t,"GPT2Tokenizer"),I9t.forEach(t),j3o=r(Rqe," (OPT model)"),Rqe.forEach(t),D3o=i(S),il=n(S,"LI",{});var GI=s(il);Wue=n(GI,"STRONG",{});var N9t=s(Wue);G3o=r(N9t,"owlvit"),N9t.forEach(t),O3o=r(GI," \u2014 "),YG=n(GI,"A",{href:!0});var q9t=s(YG);V3o=r(q9t,"CLIPTokenizer"),q9t.forEach(t),X3o=r(GI," or "),ZG=n(GI,"A",{href:!0});var j9t=s(ZG);z3o=r(j9t,"CLIPTokenizerFast"),j9t.forEach(t),Q3o=r(GI," (OWL-ViT model)"),GI.forEach(t),W3o=i(S),dl=n(S,"LI",{});var OI=s(dl);Uue=n(OI,"STRONG",{});var D9t=s(Uue);U3o=r(D9t,"pegasus"),D9t.forEach(t),H3o=r(OI," \u2014 "),KG=n(OI,"A",{href:!0});var G9t=s(KG);J3o=r(G9t,"PegasusTokenizer"),G9t.forEach(t),Y3o=r(OI," or "),eO=n(OI,"A",{href:!0});var O9t=s(eO);Z3o=r(O9t,"PegasusTokenizerFast"),O9t.forEach(t),K3o=r(OI," (Pegasus model)"),OI.forEach(t),e5o=i(S),Xu=n(S,"LI",{});var Pqe=s(Xu);Hue=n(Pqe,"STRONG",{});var V9t=s(Hue);o5o=r(V9t,"perceiver"),V9t.forEach(t),r5o=r(Pqe," \u2014 "),oO=n(Pqe,"A",{href:!0});var X9t=s(oO);t5o=r(X9t,"PerceiverTokenizer"),X9t.forEach(t),a5o=r(Pqe," (Perceiver model)"),Pqe.forEach(t),n5o=i(S),zu=n(S,"LI",{});var Bqe=s(zu);Jue=n(Bqe,"STRONG",{});var z9t=s(Jue);s5o=r(z9t,"phobert"),z9t.forEach(t),l5o=r(Bqe," \u2014 "),rO=n(Bqe,"A",{href:!0});var Q9t=s(rO);i5o=r(Q9t,"PhobertTokenizer"),Q9t.forEach(t),d5o=r(Bqe," (PhoBERT model)"),Bqe.forEach(t),c5o=i(S),Qu=n(S,"LI",{});var Iqe=s(Qu);Yue=n(Iqe,"STRONG",{});var W9t=s(Yue);m5o=r(W9t,"plbart"),W9t.forEach(t),f5o=r(Iqe," \u2014 "),tO=n(Iqe,"A",{href:!0});var U9t=s(tO);g5o=r(U9t,"PLBartTokenizer"),U9t.forEach(t),h5o=r(Iqe," (PLBart model)"),Iqe.forEach(t),u5o=i(S),Wu=n(S,"LI",{});var Nqe=s(Wu);Zue=n(Nqe,"STRONG",{});var H9t=s(Zue);p5o=r(H9t,"prophetnet"),H9t.forEach(t),_5o=r(Nqe," \u2014 "),aO=n(Nqe,"A",{href:!0});var J9t=s(aO);b5o=r(J9t,"ProphetNetTokenizer"),J9t.forEach(t),v5o=r(Nqe," (ProphetNet model)"),Nqe.forEach(t),F5o=i(S),cl=n(S,"LI",{});var VI=s(cl);Kue=n(VI,"STRONG",{});var Y9t=s(Kue);T5o=r(Y9t,"qdqbert"),Y9t.forEach(t),M5o=r(VI," \u2014 "),nO=n(VI,"A",{href:!0});var Z9t=s(nO);E5o=r(Z9t,"BertTokenizer"),Z9t.forEach(t),C5o=r(VI," or "),sO=n(VI,"A",{href:!0});var K9t=s(sO);w5o=r(K9t,"BertTokenizerFast"),K9t.forEach(t),A5o=r(VI," (QDQBert model)"),VI.forEach(t),L5o=i(S),Uu=n(S,"LI",{});var qqe=s(Uu);epe=n(qqe,"STRONG",{});var ext=s(epe);y5o=r(ext,"rag"),ext.forEach(t),x5o=r(qqe," \u2014 "),lO=n(qqe,"A",{href:!0});var oxt=s(lO);$5o=r(oxt,"RagTokenizer"),oxt.forEach(t),k5o=r(qqe," (RAG model)"),qqe.forEach(t),S5o=i(S),ml=n(S,"LI",{});var XI=s(ml);ope=n(XI,"STRONG",{});var rxt=s(ope);R5o=r(rxt,"realm"),rxt.forEach(t),P5o=r(XI," \u2014 "),iO=n(XI,"A",{href:!0});var txt=s(iO);B5o=r(txt,"RealmTokenizer"),txt.forEach(t),I5o=r(XI," or "),dO=n(XI,"A",{href:!0});var axt=s(dO);N5o=r(axt,"RealmTokenizerFast"),axt.forEach(t),q5o=r(XI," (REALM model)"),XI.forEach(t),j5o=i(S),fl=n(S,"LI",{});var zI=s(fl);rpe=n(zI,"STRONG",{});var nxt=s(rpe);D5o=r(nxt,"reformer"),nxt.forEach(t),G5o=r(zI," \u2014 "),cO=n(zI,"A",{href:!0});var sxt=s(cO);O5o=r(sxt,"ReformerTokenizer"),sxt.forEach(t),V5o=r(zI," or "),mO=n(zI,"A",{href:!0});var lxt=s(mO);X5o=r(lxt,"ReformerTokenizerFast"),lxt.forEach(t),z5o=r(zI," (Reformer model)"),zI.forEach(t),Q5o=i(S),gl=n(S,"LI",{});var QI=s(gl);tpe=n(QI,"STRONG",{});var ixt=s(tpe);W5o=r(ixt,"rembert"),ixt.forEach(t),U5o=r(QI," \u2014 "),fO=n(QI,"A",{href:!0});var dxt=s(fO);H5o=r(dxt,"RemBertTokenizer"),dxt.forEach(t),J5o=r(QI," or "),gO=n(QI,"A",{href:!0});var cxt=s(gO);Y5o=r(cxt,"RemBertTokenizerFast"),cxt.forEach(t),Z5o=r(QI," (RemBERT model)"),QI.forEach(t),K5o=i(S),hl=n(S,"LI",{});var WI=s(hl);ape=n(WI,"STRONG",{});var mxt=s(ape);e0o=r(mxt,"retribert"),mxt.forEach(t),o0o=r(WI," \u2014 "),hO=n(WI,"A",{href:!0});var fxt=s(hO);r0o=r(fxt,"RetriBertTokenizer"),fxt.forEach(t),t0o=r(WI," or "),uO=n(WI,"A",{href:!0});var gxt=s(uO);a0o=r(gxt,"RetriBertTokenizerFast"),gxt.forEach(t),n0o=r(WI," (RetriBERT model)"),WI.forEach(t),s0o=i(S),ul=n(S,"LI",{});var UI=s(ul);npe=n(UI,"STRONG",{});var hxt=s(npe);l0o=r(hxt,"roberta"),hxt.forEach(t),i0o=r(UI," \u2014 "),pO=n(UI,"A",{href:!0});var uxt=s(pO);d0o=r(uxt,"RobertaTokenizer"),uxt.forEach(t),c0o=r(UI," or "),_O=n(UI,"A",{href:!0});var pxt=s(_O);m0o=r(pxt,"RobertaTokenizerFast"),pxt.forEach(t),f0o=r(UI," (RoBERTa model)"),UI.forEach(t),g0o=i(S),pl=n(S,"LI",{});var HI=s(pl);spe=n(HI,"STRONG",{});var _xt=s(spe);h0o=r(_xt,"roformer"),_xt.forEach(t),u0o=r(HI," \u2014 "),bO=n(HI,"A",{href:!0});var bxt=s(bO);p0o=r(bxt,"RoFormerTokenizer"),bxt.forEach(t),_0o=r(HI," or "),vO=n(HI,"A",{href:!0});var vxt=s(vO);b0o=r(vxt,"RoFormerTokenizerFast"),vxt.forEach(t),v0o=r(HI," (RoFormer model)"),HI.forEach(t),F0o=i(S),Hu=n(S,"LI",{});var jqe=s(Hu);lpe=n(jqe,"STRONG",{});var Fxt=s(lpe);T0o=r(Fxt,"speech_to_text"),Fxt.forEach(t),M0o=r(jqe," \u2014 "),FO=n(jqe,"A",{href:!0});var Txt=s(FO);E0o=r(Txt,"Speech2TextTokenizer"),Txt.forEach(t),C0o=r(jqe," (Speech2Text model)"),jqe.forEach(t),w0o=i(S),Ju=n(S,"LI",{});var Dqe=s(Ju);ipe=n(Dqe,"STRONG",{});var Mxt=s(ipe);A0o=r(Mxt,"speech_to_text_2"),Mxt.forEach(t),L0o=r(Dqe," \u2014 "),TO=n(Dqe,"A",{href:!0});var Ext=s(TO);y0o=r(Ext,"Speech2Text2Tokenizer"),Ext.forEach(t),x0o=r(Dqe," (Speech2Text2 model)"),Dqe.forEach(t),$0o=i(S),_l=n(S,"LI",{});var JI=s(_l);dpe=n(JI,"STRONG",{});var Cxt=s(dpe);k0o=r(Cxt,"splinter"),Cxt.forEach(t),S0o=r(JI," \u2014 "),MO=n(JI,"A",{href:!0});var wxt=s(MO);R0o=r(wxt,"SplinterTokenizer"),wxt.forEach(t),P0o=r(JI," or "),EO=n(JI,"A",{href:!0});var Axt=s(EO);B0o=r(Axt,"SplinterTokenizerFast"),Axt.forEach(t),I0o=r(JI," (Splinter model)"),JI.forEach(t),N0o=i(S),bl=n(S,"LI",{});var YI=s(bl);cpe=n(YI,"STRONG",{});var Lxt=s(cpe);q0o=r(Lxt,"squeezebert"),Lxt.forEach(t),j0o=r(YI," \u2014 "),CO=n(YI,"A",{href:!0});var yxt=s(CO);D0o=r(yxt,"SqueezeBertTokenizer"),yxt.forEach(t),G0o=r(YI," or "),wO=n(YI,"A",{href:!0});var xxt=s(wO);O0o=r(xxt,"SqueezeBertTokenizerFast"),xxt.forEach(t),V0o=r(YI," (SqueezeBERT model)"),YI.forEach(t),X0o=i(S),vl=n(S,"LI",{});var ZI=s(vl);mpe=n(ZI,"STRONG",{});var $xt=s(mpe);z0o=r($xt,"t5"),$xt.forEach(t),Q0o=r(ZI," \u2014 "),AO=n(ZI,"A",{href:!0});var kxt=s(AO);W0o=r(kxt,"T5Tokenizer"),kxt.forEach(t),U0o=r(ZI," or "),LO=n(ZI,"A",{href:!0});var Sxt=s(LO);H0o=r(Sxt,"T5TokenizerFast"),Sxt.forEach(t),J0o=r(ZI," (T5 model)"),ZI.forEach(t),Y0o=i(S),Yu=n(S,"LI",{});var Gqe=s(Yu);fpe=n(Gqe,"STRONG",{});var Rxt=s(fpe);Z0o=r(Rxt,"tapas"),Rxt.forEach(t),K0o=r(Gqe," \u2014 "),yO=n(Gqe,"A",{href:!0});var Pxt=s(yO);ewo=r(Pxt,"TapasTokenizer"),Pxt.forEach(t),owo=r(Gqe," (TAPAS model)"),Gqe.forEach(t),rwo=i(S),Zu=n(S,"LI",{});var Oqe=s(Zu);gpe=n(Oqe,"STRONG",{});var Bxt=s(gpe);two=r(Bxt,"tapex"),Bxt.forEach(t),awo=r(Oqe," \u2014 "),xO=n(Oqe,"A",{href:!0});var Ixt=s(xO);nwo=r(Ixt,"TapexTokenizer"),Ixt.forEach(t),swo=r(Oqe," (TAPEX model)"),Oqe.forEach(t),lwo=i(S),Ku=n(S,"LI",{});var Vqe=s(Ku);hpe=n(Vqe,"STRONG",{});var Nxt=s(hpe);iwo=r(Nxt,"transfo-xl"),Nxt.forEach(t),dwo=r(Vqe," \u2014 "),$O=n(Vqe,"A",{href:!0});var qxt=s($O);cwo=r(qxt,"TransfoXLTokenizer"),qxt.forEach(t),mwo=r(Vqe," (Transformer-XL model)"),Vqe.forEach(t),fwo=i(S),Fl=n(S,"LI",{});var KI=s(Fl);upe=n(KI,"STRONG",{});var jxt=s(upe);gwo=r(jxt,"vilt"),jxt.forEach(t),hwo=r(KI," \u2014 "),kO=n(KI,"A",{href:!0});var Dxt=s(kO);uwo=r(Dxt,"BertTokenizer"),Dxt.forEach(t),pwo=r(KI," or "),SO=n(KI,"A",{href:!0});var Gxt=s(SO);_wo=r(Gxt,"BertTokenizerFast"),Gxt.forEach(t),bwo=r(KI," (ViLT model)"),KI.forEach(t),vwo=i(S),Tl=n(S,"LI",{});var eN=s(Tl);ppe=n(eN,"STRONG",{});var Oxt=s(ppe);Fwo=r(Oxt,"visual_bert"),Oxt.forEach(t),Two=r(eN," \u2014 "),RO=n(eN,"A",{href:!0});var Vxt=s(RO);Mwo=r(Vxt,"BertTokenizer"),Vxt.forEach(t),Ewo=r(eN," or "),PO=n(eN,"A",{href:!0});var Xxt=s(PO);Cwo=r(Xxt,"BertTokenizerFast"),Xxt.forEach(t),wwo=r(eN," (VisualBERT model)"),eN.forEach(t),Awo=i(S),ep=n(S,"LI",{});var Xqe=s(ep);_pe=n(Xqe,"STRONG",{});var zxt=s(_pe);Lwo=r(zxt,"wav2vec2"),zxt.forEach(t),ywo=r(Xqe," \u2014 "),BO=n(Xqe,"A",{href:!0});var Qxt=s(BO);xwo=r(Qxt,"Wav2Vec2CTCTokenizer"),Qxt.forEach(t),$wo=r(Xqe," (Wav2Vec2 model)"),Xqe.forEach(t),kwo=i(S),op=n(S,"LI",{});var zqe=s(op);bpe=n(zqe,"STRONG",{});var Wxt=s(bpe);Swo=r(Wxt,"wav2vec2-conformer"),Wxt.forEach(t),Rwo=r(zqe," \u2014 "),IO=n(zqe,"A",{href:!0});var Uxt=s(IO);Pwo=r(Uxt,"Wav2Vec2CTCTokenizer"),Uxt.forEach(t),Bwo=r(zqe," (Wav2Vec2-Conformer model)"),zqe.forEach(t),Iwo=i(S),rp=n(S,"LI",{});var Qqe=s(rp);vpe=n(Qqe,"STRONG",{});var Hxt=s(vpe);Nwo=r(Hxt,"wav2vec2_phoneme"),Hxt.forEach(t),qwo=r(Qqe," \u2014 "),NO=n(Qqe,"A",{href:!0});var Jxt=s(NO);jwo=r(Jxt,"Wav2Vec2PhonemeCTCTokenizer"),Jxt.forEach(t),Dwo=r(Qqe," (Wav2Vec2Phoneme model)"),Qqe.forEach(t),Gwo=i(S),tp=n(S,"LI",{});var Wqe=s(tp);Fpe=n(Wqe,"STRONG",{});var Yxt=s(Fpe);Owo=r(Yxt,"whisper"),Yxt.forEach(t),Vwo=r(Wqe," \u2014 "),qO=n(Wqe,"A",{href:!0});var Zxt=s(qO);Xwo=r(Zxt,"WhisperTokenizer"),Zxt.forEach(t),zwo=r(Wqe," (Whisper model)"),Wqe.forEach(t),Qwo=i(S),Ml=n(S,"LI",{});var oN=s(Ml);Tpe=n(oN,"STRONG",{});var Kxt=s(Tpe);Wwo=r(Kxt,"xclip"),Kxt.forEach(t),Uwo=r(oN," \u2014 "),jO=n(oN,"A",{href:!0});var e$t=s(jO);Hwo=r(e$t,"CLIPTokenizer"),e$t.forEach(t),Jwo=r(oN," or "),DO=n(oN,"A",{href:!0});var o$t=s(DO);Ywo=r(o$t,"CLIPTokenizerFast"),o$t.forEach(t),Zwo=r(oN," (X-CLIP model)"),oN.forEach(t),Kwo=i(S),El=n(S,"LI",{});var rN=s(El);Mpe=n(rN,"STRONG",{});var r$t=s(Mpe);eAo=r(r$t,"xglm"),r$t.forEach(t),oAo=r(rN," \u2014 "),GO=n(rN,"A",{href:!0});var t$t=s(GO);rAo=r(t$t,"XGLMTokenizer"),t$t.forEach(t),tAo=r(rN," or "),OO=n(rN,"A",{href:!0});var a$t=s(OO);aAo=r(a$t,"XGLMTokenizerFast"),a$t.forEach(t),nAo=r(rN," (XGLM model)"),rN.forEach(t),sAo=i(S),ap=n(S,"LI",{});var Uqe=s(ap);Epe=n(Uqe,"STRONG",{});var n$t=s(Epe);lAo=r(n$t,"xlm"),n$t.forEach(t),iAo=r(Uqe," \u2014 "),VO=n(Uqe,"A",{href:!0});var s$t=s(VO);dAo=r(s$t,"XLMTokenizer"),s$t.forEach(t),cAo=r(Uqe," (XLM model)"),Uqe.forEach(t),mAo=i(S),np=n(S,"LI",{});var Hqe=s(np);Cpe=n(Hqe,"STRONG",{});var l$t=s(Cpe);fAo=r(l$t,"xlm-prophetnet"),l$t.forEach(t),gAo=r(Hqe," \u2014 "),XO=n(Hqe,"A",{href:!0});var i$t=s(XO);hAo=r(i$t,"XLMProphetNetTokenizer"),i$t.forEach(t),uAo=r(Hqe," (XLM-ProphetNet model)"),Hqe.forEach(t),pAo=i(S),Cl=n(S,"LI",{});var tN=s(Cl);wpe=n(tN,"STRONG",{});var d$t=s(wpe);_Ao=r(d$t,"xlm-roberta"),d$t.forEach(t),bAo=r(tN," \u2014 "),zO=n(tN,"A",{href:!0});var c$t=s(zO);vAo=r(c$t,"XLMRobertaTokenizer"),c$t.forEach(t),FAo=r(tN," or "),QO=n(tN,"A",{href:!0});var m$t=s(QO);TAo=r(m$t,"XLMRobertaTokenizerFast"),m$t.forEach(t),MAo=r(tN," (XLM-RoBERTa model)"),tN.forEach(t),EAo=i(S),wl=n(S,"LI",{});var aN=s(wl);Ape=n(aN,"STRONG",{});var f$t=s(Ape);CAo=r(f$t,"xlm-roberta-xl"),f$t.forEach(t),wAo=r(aN," \u2014 "),WO=n(aN,"A",{href:!0});var g$t=s(WO);AAo=r(g$t,"XLMRobertaTokenizer"),g$t.forEach(t),LAo=r(aN," or "),UO=n(aN,"A",{href:!0});var h$t=s(UO);yAo=r(h$t,"XLMRobertaTokenizerFast"),h$t.forEach(t),xAo=r(aN," (XLM-RoBERTa-XL model)"),aN.forEach(t),$Ao=i(S),Al=n(S,"LI",{});var nN=s(Al);Lpe=n(nN,"STRONG",{});var u$t=s(Lpe);kAo=r(u$t,"xlnet"),u$t.forEach(t),SAo=r(nN," \u2014 "),HO=n(nN,"A",{href:!0});var p$t=s(HO);RAo=r(p$t,"XLNetTokenizer"),p$t.forEach(t),PAo=r(nN," or "),JO=n(nN,"A",{href:!0});var _$t=s(JO);BAo=r(_$t,"XLNetTokenizerFast"),_$t.forEach(t),IAo=r(nN," (XLNet model)"),nN.forEach(t),NAo=i(S),Ll=n(S,"LI",{});var sN=s(Ll);ype=n(sN,"STRONG",{});var b$t=s(ype);qAo=r(b$t,"yoso"),b$t.forEach(t),jAo=r(sN," \u2014 "),YO=n(sN,"A",{href:!0});var v$t=s(YO);DAo=r(v$t,"AlbertTokenizer"),v$t.forEach(t),GAo=r(sN," or "),ZO=n(sN,"A",{href:!0});var F$t=s(ZO);OAo=r(F$t,"AlbertTokenizerFast"),F$t.forEach(t),VAo=r(sN," (YOSO model)"),sN.forEach(t),S.forEach(t),XAo=i(Pl),T(sp.$$.fragment,Pl),Pl.forEach(t),zAo=i(Rl),lp=n(Rl,"DIV",{class:!0});var cno=s(lp);T(g$.$$.fragment,cno),QAo=i(cno),xpe=n(cno,"P",{});var T$t=s(xpe);WAo=r(T$t,"Register a new tokenizer in this mapping."),T$t.forEach(t),cno.forEach(t),Rl.forEach(t),Yro=i(m),Ld=n(m,"H2",{class:!0});var mno=s(Ld);ip=n(mno,"A",{id:!0,class:!0,href:!0});var M$t=s(ip);$pe=n(M$t,"SPAN",{});var E$t=s($pe);T(h$.$$.fragment,E$t),E$t.forEach(t),M$t.forEach(t),UAo=i(mno),kpe=n(mno,"SPAN",{});var C$t=s(kpe);HAo=r(C$t,"AutoFeatureExtractor"),C$t.forEach(t),mno.forEach(t),Zro=i(m),Po=n(m,"DIV",{class:!0});var Bl=s(Po);T(u$.$$.fragment,Bl),JAo=i(Bl),p$=n(Bl,"P",{});var fno=s(p$);YAo=r(fno,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),KO=n(fno,"A",{href:!0});var w$t=s(KO);ZAo=r(w$t,"AutoFeatureExtractor.from_pretrained()"),w$t.forEach(t),KAo=r(fno," class method."),fno.forEach(t),e6o=i(Bl),_$=n(Bl,"P",{});var gno=s(_$);o6o=r(gno,"This class cannot be instantiated directly using "),Spe=n(gno,"CODE",{});var A$t=s(Spe);r6o=r(A$t,"__init__()"),A$t.forEach(t),t6o=r(gno," (throws an error)."),gno.forEach(t),a6o=i(Bl),Ye=n(Bl,"DIV",{class:!0});var Ca=s(Ye);T(b$.$$.fragment,Ca),n6o=i(Ca),Rpe=n(Ca,"P",{});var L$t=s(Rpe);s6o=r(L$t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),L$t.forEach(t),l6o=i(Ca),tn=n(Ca,"P",{});var Vy=s(tn);i6o=r(Vy,"The feature extractor class to instantiate is selected based on the "),Ppe=n(Vy,"CODE",{});var y$t=s(Ppe);d6o=r(y$t,"model_type"),y$t.forEach(t),c6o=r(Vy,` property of the config object
(either passed as an argument or loaded from `),Bpe=n(Vy,"CODE",{});var x$t=s(Bpe);m6o=r(x$t,"pretrained_model_name_or_path"),x$t.forEach(t),f6o=r(Vy,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ipe=n(Vy,"CODE",{});var $$t=s(Ipe);g6o=r($$t,"pretrained_model_name_or_path"),$$t.forEach(t),h6o=r(Vy,":"),Vy.forEach(t),u6o=i(Ca),z=n(Ca,"UL",{});var W=s(z);dp=n(W,"LI",{});var Jqe=s(dp);Npe=n(Jqe,"STRONG",{});var k$t=s(Npe);p6o=r(k$t,"beit"),k$t.forEach(t),_6o=r(Jqe," \u2014 "),eV=n(Jqe,"A",{href:!0});var S$t=s(eV);b6o=r(S$t,"BeitFeatureExtractor"),S$t.forEach(t),v6o=r(Jqe," (BEiT model)"),Jqe.forEach(t),F6o=i(W),cp=n(W,"LI",{});var Yqe=s(cp);qpe=n(Yqe,"STRONG",{});var R$t=s(qpe);T6o=r(R$t,"clip"),R$t.forEach(t),M6o=r(Yqe," \u2014 "),oV=n(Yqe,"A",{href:!0});var P$t=s(oV);E6o=r(P$t,"CLIPFeatureExtractor"),P$t.forEach(t),C6o=r(Yqe," (CLIP model)"),Yqe.forEach(t),w6o=i(W),mp=n(W,"LI",{});var Zqe=s(mp);jpe=n(Zqe,"STRONG",{});var B$t=s(jpe);A6o=r(B$t,"conditional_detr"),B$t.forEach(t),L6o=r(Zqe," \u2014 "),rV=n(Zqe,"A",{href:!0});var I$t=s(rV);y6o=r(I$t,"ConditionalDetrFeatureExtractor"),I$t.forEach(t),x6o=r(Zqe," (Conditional DETR model)"),Zqe.forEach(t),$6o=i(W),fp=n(W,"LI",{});var Kqe=s(fp);Dpe=n(Kqe,"STRONG",{});var N$t=s(Dpe);k6o=r(N$t,"convnext"),N$t.forEach(t),S6o=r(Kqe," \u2014 "),tV=n(Kqe,"A",{href:!0});var q$t=s(tV);R6o=r(q$t,"ConvNextFeatureExtractor"),q$t.forEach(t),P6o=r(Kqe," (ConvNeXT model)"),Kqe.forEach(t),B6o=i(W),gp=n(W,"LI",{});var eje=s(gp);Gpe=n(eje,"STRONG",{});var j$t=s(Gpe);I6o=r(j$t,"cvt"),j$t.forEach(t),N6o=r(eje," \u2014 "),aV=n(eje,"A",{href:!0});var D$t=s(aV);q6o=r(D$t,"ConvNextFeatureExtractor"),D$t.forEach(t),j6o=r(eje," (CvT model)"),eje.forEach(t),D6o=i(W),hp=n(W,"LI",{});var oje=s(hp);Ope=n(oje,"STRONG",{});var G$t=s(Ope);G6o=r(G$t,"data2vec-audio"),G$t.forEach(t),O6o=r(oje," \u2014 "),nV=n(oje,"A",{href:!0});var O$t=s(nV);V6o=r(O$t,"Wav2Vec2FeatureExtractor"),O$t.forEach(t),X6o=r(oje," (Data2VecAudio model)"),oje.forEach(t),z6o=i(W),up=n(W,"LI",{});var rje=s(up);Vpe=n(rje,"STRONG",{});var V$t=s(Vpe);Q6o=r(V$t,"data2vec-vision"),V$t.forEach(t),W6o=r(rje," \u2014 "),sV=n(rje,"A",{href:!0});var X$t=s(sV);U6o=r(X$t,"BeitFeatureExtractor"),X$t.forEach(t),H6o=r(rje," (Data2VecVision model)"),rje.forEach(t),J6o=i(W),pp=n(W,"LI",{});var tje=s(pp);Xpe=n(tje,"STRONG",{});var z$t=s(Xpe);Y6o=r(z$t,"deformable_detr"),z$t.forEach(t),Z6o=r(tje," \u2014 "),lV=n(tje,"A",{href:!0});var Q$t=s(lV);K6o=r(Q$t,"DeformableDetrFeatureExtractor"),Q$t.forEach(t),e7o=r(tje," (Deformable DETR model)"),tje.forEach(t),o7o=i(W),_p=n(W,"LI",{});var aje=s(_p);zpe=n(aje,"STRONG",{});var W$t=s(zpe);r7o=r(W$t,"deit"),W$t.forEach(t),t7o=r(aje," \u2014 "),iV=n(aje,"A",{href:!0});var U$t=s(iV);a7o=r(U$t,"DeiTFeatureExtractor"),U$t.forEach(t),n7o=r(aje," (DeiT model)"),aje.forEach(t),s7o=i(W),bp=n(W,"LI",{});var nje=s(bp);Qpe=n(nje,"STRONG",{});var H$t=s(Qpe);l7o=r(H$t,"detr"),H$t.forEach(t),i7o=r(nje," \u2014 "),dV=n(nje,"A",{href:!0});var J$t=s(dV);d7o=r(J$t,"DetrFeatureExtractor"),J$t.forEach(t),c7o=r(nje," (DETR model)"),nje.forEach(t),m7o=i(W),vp=n(W,"LI",{});var sje=s(vp);Wpe=n(sje,"STRONG",{});var Y$t=s(Wpe);f7o=r(Y$t,"donut"),Y$t.forEach(t),g7o=r(sje," \u2014 "),cV=n(sje,"A",{href:!0});var Z$t=s(cV);h7o=r(Z$t,"DonutFeatureExtractor"),Z$t.forEach(t),u7o=r(sje," (Donut model)"),sje.forEach(t),p7o=i(W),Fp=n(W,"LI",{});var lje=s(Fp);Upe=n(lje,"STRONG",{});var K$t=s(Upe);_7o=r(K$t,"dpt"),K$t.forEach(t),b7o=r(lje," \u2014 "),mV=n(lje,"A",{href:!0});var ekt=s(mV);v7o=r(ekt,"DPTFeatureExtractor"),ekt.forEach(t),F7o=r(lje," (DPT model)"),lje.forEach(t),T7o=i(W),Tp=n(W,"LI",{});var ije=s(Tp);Hpe=n(ije,"STRONG",{});var okt=s(Hpe);M7o=r(okt,"flava"),okt.forEach(t),E7o=r(ije," \u2014 "),fV=n(ije,"A",{href:!0});var rkt=s(fV);C7o=r(rkt,"FlavaFeatureExtractor"),rkt.forEach(t),w7o=r(ije," (FLAVA model)"),ije.forEach(t),A7o=i(W),Mp=n(W,"LI",{});var dje=s(Mp);Jpe=n(dje,"STRONG",{});var tkt=s(Jpe);L7o=r(tkt,"glpn"),tkt.forEach(t),y7o=r(dje," \u2014 "),gV=n(dje,"A",{href:!0});var akt=s(gV);x7o=r(akt,"GLPNFeatureExtractor"),akt.forEach(t),$7o=r(dje," (GLPN model)"),dje.forEach(t),k7o=i(W),Ep=n(W,"LI",{});var cje=s(Ep);Ype=n(cje,"STRONG",{});var nkt=s(Ype);S7o=r(nkt,"groupvit"),nkt.forEach(t),R7o=r(cje," \u2014 "),hV=n(cje,"A",{href:!0});var skt=s(hV);P7o=r(skt,"CLIPFeatureExtractor"),skt.forEach(t),B7o=r(cje," (GroupViT model)"),cje.forEach(t),I7o=i(W),Cp=n(W,"LI",{});var mje=s(Cp);Zpe=n(mje,"STRONG",{});var lkt=s(Zpe);N7o=r(lkt,"hubert"),lkt.forEach(t),q7o=r(mje," \u2014 "),uV=n(mje,"A",{href:!0});var ikt=s(uV);j7o=r(ikt,"Wav2Vec2FeatureExtractor"),ikt.forEach(t),D7o=r(mje," (Hubert model)"),mje.forEach(t),G7o=i(W),wp=n(W,"LI",{});var fje=s(wp);Kpe=n(fje,"STRONG",{});var dkt=s(Kpe);O7o=r(dkt,"imagegpt"),dkt.forEach(t),V7o=r(fje," \u2014 "),pV=n(fje,"A",{href:!0});var ckt=s(pV);X7o=r(ckt,"ImageGPTFeatureExtractor"),ckt.forEach(t),z7o=r(fje," (ImageGPT model)"),fje.forEach(t),Q7o=i(W),Ap=n(W,"LI",{});var gje=s(Ap);e_e=n(gje,"STRONG",{});var mkt=s(e_e);W7o=r(mkt,"layoutlmv2"),mkt.forEach(t),U7o=r(gje," \u2014 "),_V=n(gje,"A",{href:!0});var fkt=s(_V);H7o=r(fkt,"LayoutLMv2FeatureExtractor"),fkt.forEach(t),J7o=r(gje," (LayoutLMv2 model)"),gje.forEach(t),Y7o=i(W),Lp=n(W,"LI",{});var hje=s(Lp);o_e=n(hje,"STRONG",{});var gkt=s(o_e);Z7o=r(gkt,"layoutlmv3"),gkt.forEach(t),K7o=r(hje," \u2014 "),bV=n(hje,"A",{href:!0});var hkt=s(bV);eLo=r(hkt,"LayoutLMv3FeatureExtractor"),hkt.forEach(t),oLo=r(hje," (LayoutLMv3 model)"),hje.forEach(t),rLo=i(W),yp=n(W,"LI",{});var uje=s(yp);r_e=n(uje,"STRONG",{});var ukt=s(r_e);tLo=r(ukt,"levit"),ukt.forEach(t),aLo=r(uje," \u2014 "),vV=n(uje,"A",{href:!0});var pkt=s(vV);nLo=r(pkt,"LevitFeatureExtractor"),pkt.forEach(t),sLo=r(uje," (LeViT model)"),uje.forEach(t),lLo=i(W),xp=n(W,"LI",{});var pje=s(xp);t_e=n(pje,"STRONG",{});var _kt=s(t_e);iLo=r(_kt,"maskformer"),_kt.forEach(t),dLo=r(pje," \u2014 "),FV=n(pje,"A",{href:!0});var bkt=s(FV);cLo=r(bkt,"MaskFormerFeatureExtractor"),bkt.forEach(t),mLo=r(pje," (MaskFormer model)"),pje.forEach(t),fLo=i(W),$p=n(W,"LI",{});var _je=s($p);a_e=n(_je,"STRONG",{});var vkt=s(a_e);gLo=r(vkt,"mctct"),vkt.forEach(t),hLo=r(_je," \u2014 "),TV=n(_je,"A",{href:!0});var Fkt=s(TV);uLo=r(Fkt,"MCTCTFeatureExtractor"),Fkt.forEach(t),pLo=r(_je," (M-CTC-T model)"),_je.forEach(t),_Lo=i(W),kp=n(W,"LI",{});var bje=s(kp);n_e=n(bje,"STRONG",{});var Tkt=s(n_e);bLo=r(Tkt,"mobilevit"),Tkt.forEach(t),vLo=r(bje," \u2014 "),MV=n(bje,"A",{href:!0});var Mkt=s(MV);FLo=r(Mkt,"MobileViTFeatureExtractor"),Mkt.forEach(t),TLo=r(bje," (MobileViT model)"),bje.forEach(t),MLo=i(W),Sp=n(W,"LI",{});var vje=s(Sp);s_e=n(vje,"STRONG",{});var Ekt=s(s_e);ELo=r(Ekt,"owlvit"),Ekt.forEach(t),CLo=r(vje," \u2014 "),EV=n(vje,"A",{href:!0});var Ckt=s(EV);wLo=r(Ckt,"OwlViTFeatureExtractor"),Ckt.forEach(t),ALo=r(vje," (OWL-ViT model)"),vje.forEach(t),LLo=i(W),Rp=n(W,"LI",{});var Fje=s(Rp);l_e=n(Fje,"STRONG",{});var wkt=s(l_e);yLo=r(wkt,"perceiver"),wkt.forEach(t),xLo=r(Fje," \u2014 "),CV=n(Fje,"A",{href:!0});var Akt=s(CV);$Lo=r(Akt,"PerceiverFeatureExtractor"),Akt.forEach(t),kLo=r(Fje," (Perceiver model)"),Fje.forEach(t),SLo=i(W),Pp=n(W,"LI",{});var Tje=s(Pp);i_e=n(Tje,"STRONG",{});var Lkt=s(i_e);RLo=r(Lkt,"poolformer"),Lkt.forEach(t),PLo=r(Tje," \u2014 "),wV=n(Tje,"A",{href:!0});var ykt=s(wV);BLo=r(ykt,"PoolFormerFeatureExtractor"),ykt.forEach(t),ILo=r(Tje," (PoolFormer model)"),Tje.forEach(t),NLo=i(W),Bp=n(W,"LI",{});var Mje=s(Bp);d_e=n(Mje,"STRONG",{});var xkt=s(d_e);qLo=r(xkt,"regnet"),xkt.forEach(t),jLo=r(Mje," \u2014 "),AV=n(Mje,"A",{href:!0});var $kt=s(AV);DLo=r($kt,"ConvNextFeatureExtractor"),$kt.forEach(t),GLo=r(Mje," (RegNet model)"),Mje.forEach(t),OLo=i(W),Ip=n(W,"LI",{});var Eje=s(Ip);c_e=n(Eje,"STRONG",{});var kkt=s(c_e);VLo=r(kkt,"resnet"),kkt.forEach(t),XLo=r(Eje," \u2014 "),LV=n(Eje,"A",{href:!0});var Skt=s(LV);zLo=r(Skt,"ConvNextFeatureExtractor"),Skt.forEach(t),QLo=r(Eje," (ResNet model)"),Eje.forEach(t),WLo=i(W),Np=n(W,"LI",{});var Cje=s(Np);m_e=n(Cje,"STRONG",{});var Rkt=s(m_e);ULo=r(Rkt,"segformer"),Rkt.forEach(t),HLo=r(Cje," \u2014 "),yV=n(Cje,"A",{href:!0});var Pkt=s(yV);JLo=r(Pkt,"SegformerFeatureExtractor"),Pkt.forEach(t),YLo=r(Cje," (SegFormer model)"),Cje.forEach(t),ZLo=i(W),qp=n(W,"LI",{});var wje=s(qp);f_e=n(wje,"STRONG",{});var Bkt=s(f_e);KLo=r(Bkt,"speech_to_text"),Bkt.forEach(t),e8o=r(wje," \u2014 "),xV=n(wje,"A",{href:!0});var Ikt=s(xV);o8o=r(Ikt,"Speech2TextFeatureExtractor"),Ikt.forEach(t),r8o=r(wje," (Speech2Text model)"),wje.forEach(t),t8o=i(W),jp=n(W,"LI",{});var Aje=s(jp);g_e=n(Aje,"STRONG",{});var Nkt=s(g_e);a8o=r(Nkt,"swin"),Nkt.forEach(t),n8o=r(Aje," \u2014 "),$V=n(Aje,"A",{href:!0});var qkt=s($V);s8o=r(qkt,"ViTFeatureExtractor"),qkt.forEach(t),l8o=r(Aje," (Swin Transformer model)"),Aje.forEach(t),i8o=i(W),Dp=n(W,"LI",{});var Lje=s(Dp);h_e=n(Lje,"STRONG",{});var jkt=s(h_e);d8o=r(jkt,"swinv2"),jkt.forEach(t),c8o=r(Lje," \u2014 "),kV=n(Lje,"A",{href:!0});var Dkt=s(kV);m8o=r(Dkt,"ViTFeatureExtractor"),Dkt.forEach(t),f8o=r(Lje," (Swin Transformer V2 model)"),Lje.forEach(t),g8o=i(W),Gp=n(W,"LI",{});var yje=s(Gp);u_e=n(yje,"STRONG",{});var Gkt=s(u_e);h8o=r(Gkt,"van"),Gkt.forEach(t),u8o=r(yje," \u2014 "),SV=n(yje,"A",{href:!0});var Okt=s(SV);p8o=r(Okt,"ConvNextFeatureExtractor"),Okt.forEach(t),_8o=r(yje," (VAN model)"),yje.forEach(t),b8o=i(W),Op=n(W,"LI",{});var xje=s(Op);p_e=n(xje,"STRONG",{});var Vkt=s(p_e);v8o=r(Vkt,"videomae"),Vkt.forEach(t),F8o=r(xje," \u2014 "),RV=n(xje,"A",{href:!0});var Xkt=s(RV);T8o=r(Xkt,"VideoMAEFeatureExtractor"),Xkt.forEach(t),M8o=r(xje," (VideoMAE model)"),xje.forEach(t),E8o=i(W),Vp=n(W,"LI",{});var $je=s(Vp);__e=n($je,"STRONG",{});var zkt=s(__e);C8o=r(zkt,"vilt"),zkt.forEach(t),w8o=r($je," \u2014 "),PV=n($je,"A",{href:!0});var Qkt=s(PV);A8o=r(Qkt,"ViltFeatureExtractor"),Qkt.forEach(t),L8o=r($je," (ViLT model)"),$je.forEach(t),y8o=i(W),Xp=n(W,"LI",{});var kje=s(Xp);b_e=n(kje,"STRONG",{});var Wkt=s(b_e);x8o=r(Wkt,"vit"),Wkt.forEach(t),$8o=r(kje," \u2014 "),BV=n(kje,"A",{href:!0});var Ukt=s(BV);k8o=r(Ukt,"ViTFeatureExtractor"),Ukt.forEach(t),S8o=r(kje," (ViT model)"),kje.forEach(t),R8o=i(W),zp=n(W,"LI",{});var Sje=s(zp);v_e=n(Sje,"STRONG",{});var Hkt=s(v_e);P8o=r(Hkt,"vit_mae"),Hkt.forEach(t),B8o=r(Sje," \u2014 "),IV=n(Sje,"A",{href:!0});var Jkt=s(IV);I8o=r(Jkt,"ViTFeatureExtractor"),Jkt.forEach(t),N8o=r(Sje," (ViTMAE model)"),Sje.forEach(t),q8o=i(W),Qp=n(W,"LI",{});var Rje=s(Qp);F_e=n(Rje,"STRONG",{});var Ykt=s(F_e);j8o=r(Ykt,"vit_msn"),Ykt.forEach(t),D8o=r(Rje," \u2014 "),NV=n(Rje,"A",{href:!0});var Zkt=s(NV);G8o=r(Zkt,"ViTFeatureExtractor"),Zkt.forEach(t),O8o=r(Rje," (ViTMSN model)"),Rje.forEach(t),V8o=i(W),Wp=n(W,"LI",{});var Pje=s(Wp);T_e=n(Pje,"STRONG",{});var Kkt=s(T_e);X8o=r(Kkt,"wav2vec2"),Kkt.forEach(t),z8o=r(Pje," \u2014 "),qV=n(Pje,"A",{href:!0});var eSt=s(qV);Q8o=r(eSt,"Wav2Vec2FeatureExtractor"),eSt.forEach(t),W8o=r(Pje," (Wav2Vec2 model)"),Pje.forEach(t),U8o=i(W),Up=n(W,"LI",{});var Bje=s(Up);M_e=n(Bje,"STRONG",{});var oSt=s(M_e);H8o=r(oSt,"wav2vec2-conformer"),oSt.forEach(t),J8o=r(Bje," \u2014 "),jV=n(Bje,"A",{href:!0});var rSt=s(jV);Y8o=r(rSt,"Wav2Vec2FeatureExtractor"),rSt.forEach(t),Z8o=r(Bje," (Wav2Vec2-Conformer model)"),Bje.forEach(t),K8o=i(W),Hp=n(W,"LI",{});var Ije=s(Hp);E_e=n(Ije,"STRONG",{});var tSt=s(E_e);eyo=r(tSt,"whisper"),tSt.forEach(t),oyo=r(Ije," \u2014 "),DV=n(Ije,"A",{href:!0});var aSt=s(DV);ryo=r(aSt,"WhisperFeatureExtractor"),aSt.forEach(t),tyo=r(Ije," (Whisper model)"),Ije.forEach(t),ayo=i(W),Jp=n(W,"LI",{});var Nje=s(Jp);C_e=n(Nje,"STRONG",{});var nSt=s(C_e);nyo=r(nSt,"xclip"),nSt.forEach(t),syo=r(Nje," \u2014 "),GV=n(Nje,"A",{href:!0});var sSt=s(GV);lyo=r(sSt,"CLIPFeatureExtractor"),sSt.forEach(t),iyo=r(Nje," (X-CLIP model)"),Nje.forEach(t),dyo=i(W),Yp=n(W,"LI",{});var qje=s(Yp);w_e=n(qje,"STRONG",{});var lSt=s(w_e);cyo=r(lSt,"yolos"),lSt.forEach(t),myo=r(qje," \u2014 "),OV=n(qje,"A",{href:!0});var iSt=s(OV);fyo=r(iSt,"YolosFeatureExtractor"),iSt.forEach(t),gyo=r(qje," (YOLOS model)"),qje.forEach(t),W.forEach(t),hyo=i(Ca),T(Zp.$$.fragment,Ca),uyo=i(Ca),T(Kp.$$.fragment,Ca),Ca.forEach(t),pyo=i(Bl),e_=n(Bl,"DIV",{class:!0});var hno=s(e_);T(v$.$$.fragment,hno),_yo=i(hno),A_e=n(hno,"P",{});var dSt=s(A_e);byo=r(dSt,"Register a new feature extractor for this class."),dSt.forEach(t),hno.forEach(t),Bl.forEach(t),Kro=i(m),yd=n(m,"H2",{class:!0});var uno=s(yd);o_=n(uno,"A",{id:!0,class:!0,href:!0});var cSt=s(o_);L_e=n(cSt,"SPAN",{});var mSt=s(L_e);T(F$.$$.fragment,mSt),mSt.forEach(t),cSt.forEach(t),vyo=i(uno),y_e=n(uno,"SPAN",{});var fSt=s(y_e);Fyo=r(fSt,"AutoProcessor"),fSt.forEach(t),uno.forEach(t),eto=i(m),Bo=n(m,"DIV",{class:!0});var Il=s(Bo);T(T$.$$.fragment,Il),Tyo=i(Il),M$=n(Il,"P",{});var pno=s(M$);Myo=r(pno,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),VV=n(pno,"A",{href:!0});var gSt=s(VV);Eyo=r(gSt,"AutoProcessor.from_pretrained()"),gSt.forEach(t),Cyo=r(pno," class method."),pno.forEach(t),wyo=i(Il),E$=n(Il,"P",{});var _no=s(E$);Ayo=r(_no,"This class cannot be instantiated directly using "),x_e=n(_no,"CODE",{});var hSt=s(x_e);Lyo=r(hSt,"__init__()"),hSt.forEach(t),yyo=r(_no," (throws an error)."),_no.forEach(t),xyo=i(Il),Ze=n(Il,"DIV",{class:!0});var wa=s(Ze);T(C$.$$.fragment,wa),$yo=i(wa),$_e=n(wa,"P",{});var uSt=s($_e);kyo=r(uSt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),uSt.forEach(t),Syo=i(wa),xd=n(wa,"P",{});var Nde=s(xd);Ryo=r(Nde,"The processor class to instantiate is selected based on the "),k_e=n(Nde,"CODE",{});var pSt=s(k_e);Pyo=r(pSt,"model_type"),pSt.forEach(t),Byo=r(Nde,` property of the config object (either
passed as an argument or loaded from `),S_e=n(Nde,"CODE",{});var _St=s(S_e);Iyo=r(_St,"pretrained_model_name_or_path"),_St.forEach(t),Nyo=r(Nde," if possible):"),Nde.forEach(t),qyo=i(wa),se=n(wa,"UL",{});var ie=s(se);r_=n(ie,"LI",{});var jje=s(r_);R_e=n(jje,"STRONG",{});var bSt=s(R_e);jyo=r(bSt,"clip"),bSt.forEach(t),Dyo=r(jje," \u2014 "),XV=n(jje,"A",{href:!0});var vSt=s(XV);Gyo=r(vSt,"CLIPProcessor"),vSt.forEach(t),Oyo=r(jje," (CLIP model)"),jje.forEach(t),Vyo=i(ie),t_=n(ie,"LI",{});var Dje=s(t_);P_e=n(Dje,"STRONG",{});var FSt=s(P_e);Xyo=r(FSt,"donut"),FSt.forEach(t),zyo=r(Dje," \u2014 "),zV=n(Dje,"A",{href:!0});var TSt=s(zV);Qyo=r(TSt,"DonutProcessor"),TSt.forEach(t),Wyo=r(Dje," (Donut model)"),Dje.forEach(t),Uyo=i(ie),a_=n(ie,"LI",{});var Gje=s(a_);B_e=n(Gje,"STRONG",{});var MSt=s(B_e);Hyo=r(MSt,"flava"),MSt.forEach(t),Jyo=r(Gje," \u2014 "),QV=n(Gje,"A",{href:!0});var ESt=s(QV);Yyo=r(ESt,"FlavaProcessor"),ESt.forEach(t),Zyo=r(Gje," (FLAVA model)"),Gje.forEach(t),Kyo=i(ie),n_=n(ie,"LI",{});var Oje=s(n_);I_e=n(Oje,"STRONG",{});var CSt=s(I_e);e9o=r(CSt,"groupvit"),CSt.forEach(t),o9o=r(Oje," \u2014 "),WV=n(Oje,"A",{href:!0});var wSt=s(WV);r9o=r(wSt,"CLIPProcessor"),wSt.forEach(t),t9o=r(Oje," (GroupViT model)"),Oje.forEach(t),a9o=i(ie),s_=n(ie,"LI",{});var Vje=s(s_);N_e=n(Vje,"STRONG",{});var ASt=s(N_e);n9o=r(ASt,"layoutlmv2"),ASt.forEach(t),s9o=r(Vje," \u2014 "),UV=n(Vje,"A",{href:!0});var LSt=s(UV);l9o=r(LSt,"LayoutLMv2Processor"),LSt.forEach(t),i9o=r(Vje," (LayoutLMv2 model)"),Vje.forEach(t),d9o=i(ie),l_=n(ie,"LI",{});var Xje=s(l_);q_e=n(Xje,"STRONG",{});var ySt=s(q_e);c9o=r(ySt,"layoutlmv3"),ySt.forEach(t),m9o=r(Xje," \u2014 "),HV=n(Xje,"A",{href:!0});var xSt=s(HV);f9o=r(xSt,"LayoutLMv3Processor"),xSt.forEach(t),g9o=r(Xje," (LayoutLMv3 model)"),Xje.forEach(t),h9o=i(ie),i_=n(ie,"LI",{});var zje=s(i_);j_e=n(zje,"STRONG",{});var $St=s(j_e);u9o=r($St,"layoutxlm"),$St.forEach(t),p9o=r(zje," \u2014 "),JV=n(zje,"A",{href:!0});var kSt=s(JV);_9o=r(kSt,"LayoutXLMProcessor"),kSt.forEach(t),b9o=r(zje," (LayoutXLM model)"),zje.forEach(t),v9o=i(ie),d_=n(ie,"LI",{});var Qje=s(d_);D_e=n(Qje,"STRONG",{});var SSt=s(D_e);F9o=r(SSt,"markuplm"),SSt.forEach(t),T9o=r(Qje," \u2014 "),YV=n(Qje,"A",{href:!0});var RSt=s(YV);M9o=r(RSt,"MarkupLMProcessor"),RSt.forEach(t),E9o=r(Qje," (MarkupLM model)"),Qje.forEach(t),C9o=i(ie),c_=n(ie,"LI",{});var Wje=s(c_);G_e=n(Wje,"STRONG",{});var PSt=s(G_e);w9o=r(PSt,"owlvit"),PSt.forEach(t),A9o=r(Wje," \u2014 "),ZV=n(Wje,"A",{href:!0});var BSt=s(ZV);L9o=r(BSt,"OwlViTProcessor"),BSt.forEach(t),y9o=r(Wje," (OWL-ViT model)"),Wje.forEach(t),x9o=i(ie),m_=n(ie,"LI",{});var Uje=s(m_);O_e=n(Uje,"STRONG",{});var ISt=s(O_e);$9o=r(ISt,"sew"),ISt.forEach(t),k9o=r(Uje," \u2014 "),KV=n(Uje,"A",{href:!0});var NSt=s(KV);S9o=r(NSt,"Wav2Vec2Processor"),NSt.forEach(t),R9o=r(Uje," (SEW model)"),Uje.forEach(t),P9o=i(ie),f_=n(ie,"LI",{});var Hje=s(f_);V_e=n(Hje,"STRONG",{});var qSt=s(V_e);B9o=r(qSt,"sew-d"),qSt.forEach(t),I9o=r(Hje," \u2014 "),eX=n(Hje,"A",{href:!0});var jSt=s(eX);N9o=r(jSt,"Wav2Vec2Processor"),jSt.forEach(t),q9o=r(Hje," (SEW-D model)"),Hje.forEach(t),j9o=i(ie),g_=n(ie,"LI",{});var Jje=s(g_);X_e=n(Jje,"STRONG",{});var DSt=s(X_e);D9o=r(DSt,"speech_to_text"),DSt.forEach(t),G9o=r(Jje," \u2014 "),oX=n(Jje,"A",{href:!0});var GSt=s(oX);O9o=r(GSt,"Speech2TextProcessor"),GSt.forEach(t),V9o=r(Jje," (Speech2Text model)"),Jje.forEach(t),X9o=i(ie),h_=n(ie,"LI",{});var Yje=s(h_);z_e=n(Yje,"STRONG",{});var OSt=s(z_e);z9o=r(OSt,"speech_to_text_2"),OSt.forEach(t),Q9o=r(Yje," \u2014 "),rX=n(Yje,"A",{href:!0});var VSt=s(rX);W9o=r(VSt,"Speech2Text2Processor"),VSt.forEach(t),U9o=r(Yje," (Speech2Text2 model)"),Yje.forEach(t),H9o=i(ie),u_=n(ie,"LI",{});var Zje=s(u_);Q_e=n(Zje,"STRONG",{});var XSt=s(Q_e);J9o=r(XSt,"trocr"),XSt.forEach(t),Y9o=r(Zje," \u2014 "),tX=n(Zje,"A",{href:!0});var zSt=s(tX);Z9o=r(zSt,"TrOCRProcessor"),zSt.forEach(t),K9o=r(Zje," (TrOCR model)"),Zje.forEach(t),exo=i(ie),p_=n(ie,"LI",{});var Kje=s(p_);W_e=n(Kje,"STRONG",{});var QSt=s(W_e);oxo=r(QSt,"unispeech"),QSt.forEach(t),rxo=r(Kje," \u2014 "),aX=n(Kje,"A",{href:!0});var WSt=s(aX);txo=r(WSt,"Wav2Vec2Processor"),WSt.forEach(t),axo=r(Kje," (UniSpeech model)"),Kje.forEach(t),nxo=i(ie),__=n(ie,"LI",{});var eDe=s(__);U_e=n(eDe,"STRONG",{});var USt=s(U_e);sxo=r(USt,"unispeech-sat"),USt.forEach(t),lxo=r(eDe," \u2014 "),nX=n(eDe,"A",{href:!0});var HSt=s(nX);ixo=r(HSt,"Wav2Vec2Processor"),HSt.forEach(t),dxo=r(eDe," (UniSpeechSat model)"),eDe.forEach(t),cxo=i(ie),b_=n(ie,"LI",{});var oDe=s(b_);H_e=n(oDe,"STRONG",{});var JSt=s(H_e);mxo=r(JSt,"vilt"),JSt.forEach(t),fxo=r(oDe," \u2014 "),sX=n(oDe,"A",{href:!0});var YSt=s(sX);gxo=r(YSt,"ViltProcessor"),YSt.forEach(t),hxo=r(oDe," (ViLT model)"),oDe.forEach(t),uxo=i(ie),v_=n(ie,"LI",{});var rDe=s(v_);J_e=n(rDe,"STRONG",{});var ZSt=s(J_e);pxo=r(ZSt,"vision-text-dual-encoder"),ZSt.forEach(t),_xo=r(rDe," \u2014 "),lX=n(rDe,"A",{href:!0});var KSt=s(lX);bxo=r(KSt,"VisionTextDualEncoderProcessor"),KSt.forEach(t),vxo=r(rDe," (VisionTextDualEncoder model)"),rDe.forEach(t),Fxo=i(ie),F_=n(ie,"LI",{});var tDe=s(F_);Y_e=n(tDe,"STRONG",{});var eRt=s(Y_e);Txo=r(eRt,"wav2vec2"),eRt.forEach(t),Mxo=r(tDe," \u2014 "),iX=n(tDe,"A",{href:!0});var oRt=s(iX);Exo=r(oRt,"Wav2Vec2Processor"),oRt.forEach(t),Cxo=r(tDe," (Wav2Vec2 model)"),tDe.forEach(t),wxo=i(ie),T_=n(ie,"LI",{});var aDe=s(T_);Z_e=n(aDe,"STRONG",{});var rRt=s(Z_e);Axo=r(rRt,"wav2vec2-conformer"),rRt.forEach(t),Lxo=r(aDe," \u2014 "),dX=n(aDe,"A",{href:!0});var tRt=s(dX);yxo=r(tRt,"Wav2Vec2Processor"),tRt.forEach(t),xxo=r(aDe," (Wav2Vec2-Conformer model)"),aDe.forEach(t),$xo=i(ie),M_=n(ie,"LI",{});var nDe=s(M_);K_e=n(nDe,"STRONG",{});var aRt=s(K_e);kxo=r(aRt,"wavlm"),aRt.forEach(t),Sxo=r(nDe," \u2014 "),cX=n(nDe,"A",{href:!0});var nRt=s(cX);Rxo=r(nRt,"Wav2Vec2Processor"),nRt.forEach(t),Pxo=r(nDe," (WavLM model)"),nDe.forEach(t),Bxo=i(ie),E_=n(ie,"LI",{});var sDe=s(E_);e1e=n(sDe,"STRONG",{});var sRt=s(e1e);Ixo=r(sRt,"whisper"),sRt.forEach(t),Nxo=r(sDe," \u2014 "),mX=n(sDe,"A",{href:!0});var lRt=s(mX);qxo=r(lRt,"WhisperProcessor"),lRt.forEach(t),jxo=r(sDe," (Whisper model)"),sDe.forEach(t),Dxo=i(ie),C_=n(ie,"LI",{});var lDe=s(C_);o1e=n(lDe,"STRONG",{});var iRt=s(o1e);Gxo=r(iRt,"xclip"),iRt.forEach(t),Oxo=r(lDe," \u2014 "),fX=n(lDe,"A",{href:!0});var dRt=s(fX);Vxo=r(dRt,"CLIPProcessor"),dRt.forEach(t),Xxo=r(lDe," (X-CLIP model)"),lDe.forEach(t),ie.forEach(t),zxo=i(wa),T(w_.$$.fragment,wa),Qxo=i(wa),T(A_.$$.fragment,wa),wa.forEach(t),Wxo=i(Il),L_=n(Il,"DIV",{class:!0});var bno=s(L_);T(w$.$$.fragment,bno),Uxo=i(bno),r1e=n(bno,"P",{});var cRt=s(r1e);Hxo=r(cRt,"Register a new processor for this class."),cRt.forEach(t),bno.forEach(t),Il.forEach(t),oto=i(m),$d=n(m,"H2",{class:!0});var vno=s($d);y_=n(vno,"A",{id:!0,class:!0,href:!0});var mRt=s(y_);t1e=n(mRt,"SPAN",{});var fRt=s(t1e);T(A$.$$.fragment,fRt),fRt.forEach(t),mRt.forEach(t),Jxo=i(vno),a1e=n(vno,"SPAN",{});var gRt=s(a1e);Yxo=r(gRt,"AutoModel"),gRt.forEach(t),vno.forEach(t),rto=i(m),Io=n(m,"DIV",{class:!0});var Nl=s(Io);T(L$.$$.fragment,Nl),Zxo=i(Nl),kd=n(Nl,"P",{});var qde=s(kd);Kxo=r(qde,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gX=n(qde,"A",{href:!0});var hRt=s(gX);e$o=r(hRt,"from_pretrained()"),hRt.forEach(t),o$o=r(qde," class method or the "),hX=n(qde,"A",{href:!0});var uRt=s(hX);r$o=r(uRt,"from_config()"),uRt.forEach(t),t$o=r(qde,` class
method.`),qde.forEach(t),a$o=i(Nl),y$=n(Nl,"P",{});var Fno=s(y$);n$o=r(Fno,"This class cannot be instantiated directly using "),n1e=n(Fno,"CODE",{});var pRt=s(n1e);s$o=r(pRt,"__init__()"),pRt.forEach(t),l$o=r(Fno," (throws an error)."),Fno.forEach(t),i$o=i(Nl),Tt=n(Nl,"DIV",{class:!0});var Xy=s(Tt);T(x$.$$.fragment,Xy),d$o=i(Xy),s1e=n(Xy,"P",{});var _Rt=s(s1e);c$o=r(_Rt,"Instantiates one of the base model classes of the library from a configuration."),_Rt.forEach(t),m$o=i(Xy),Sd=n(Xy,"P",{});var jde=s(Sd);f$o=r(jde,`Note:
Loading a model from its configuration file does `),l1e=n(jde,"STRONG",{});var bRt=s(l1e);g$o=r(bRt,"not"),bRt.forEach(t),h$o=r(jde,` load the model weights. It only affects the
model\u2019s configuration. Use `),uX=n(jde,"A",{href:!0});var vRt=s(uX);u$o=r(vRt,"from_pretrained()"),vRt.forEach(t),p$o=r(jde," to load the model weights."),jde.forEach(t),_$o=i(Xy),T(x_.$$.fragment,Xy),Xy.forEach(t),b$o=i(Nl),Ke=n(Nl,"DIV",{class:!0});var Aa=s(Ke);T($$.$$.fragment,Aa),v$o=i(Aa),i1e=n(Aa,"P",{});var FRt=s(i1e);F$o=r(FRt,"Instantiate one of the base model classes of the library from a pretrained model."),FRt.forEach(t),T$o=i(Aa),an=n(Aa,"P",{});var zy=s(an);M$o=r(zy,"The model class to instantiate is selected based on the "),d1e=n(zy,"CODE",{});var TRt=s(d1e);E$o=r(TRt,"model_type"),TRt.forEach(t),C$o=r(zy,` property of the config object (either
passed as an argument or loaded from `),c1e=n(zy,"CODE",{});var MRt=s(c1e);w$o=r(MRt,"pretrained_model_name_or_path"),MRt.forEach(t),A$o=r(zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m1e=n(zy,"CODE",{});var ERt=s(m1e);L$o=r(ERt,"pretrained_model_name_or_path"),ERt.forEach(t),y$o=r(zy,":"),zy.forEach(t),x$o=i(Aa),y=n(Aa,"UL",{});var x=s(y);$_=n(x,"LI",{});var iDe=s($_);f1e=n(iDe,"STRONG",{});var CRt=s(f1e);$$o=r(CRt,"albert"),CRt.forEach(t),k$o=r(iDe," \u2014 "),pX=n(iDe,"A",{href:!0});var wRt=s(pX);S$o=r(wRt,"AlbertModel"),wRt.forEach(t),R$o=r(iDe," (ALBERT model)"),iDe.forEach(t),P$o=i(x),k_=n(x,"LI",{});var dDe=s(k_);g1e=n(dDe,"STRONG",{});var ARt=s(g1e);B$o=r(ARt,"bart"),ARt.forEach(t),I$o=r(dDe," \u2014 "),_X=n(dDe,"A",{href:!0});var LRt=s(_X);N$o=r(LRt,"BartModel"),LRt.forEach(t),q$o=r(dDe," (BART model)"),dDe.forEach(t),j$o=i(x),S_=n(x,"LI",{});var cDe=s(S_);h1e=n(cDe,"STRONG",{});var yRt=s(h1e);D$o=r(yRt,"beit"),yRt.forEach(t),G$o=r(cDe," \u2014 "),bX=n(cDe,"A",{href:!0});var xRt=s(bX);O$o=r(xRt,"BeitModel"),xRt.forEach(t),V$o=r(cDe," (BEiT model)"),cDe.forEach(t),X$o=i(x),R_=n(x,"LI",{});var mDe=s(R_);u1e=n(mDe,"STRONG",{});var $Rt=s(u1e);z$o=r($Rt,"bert"),$Rt.forEach(t),Q$o=r(mDe," \u2014 "),vX=n(mDe,"A",{href:!0});var kRt=s(vX);W$o=r(kRt,"BertModel"),kRt.forEach(t),U$o=r(mDe," (BERT model)"),mDe.forEach(t),H$o=i(x),P_=n(x,"LI",{});var fDe=s(P_);p1e=n(fDe,"STRONG",{});var SRt=s(p1e);J$o=r(SRt,"bert-generation"),SRt.forEach(t),Y$o=r(fDe," \u2014 "),FX=n(fDe,"A",{href:!0});var RRt=s(FX);Z$o=r(RRt,"BertGenerationEncoder"),RRt.forEach(t),K$o=r(fDe," (Bert Generation model)"),fDe.forEach(t),eko=i(x),B_=n(x,"LI",{});var gDe=s(B_);_1e=n(gDe,"STRONG",{});var PRt=s(_1e);oko=r(PRt,"big_bird"),PRt.forEach(t),rko=r(gDe," \u2014 "),TX=n(gDe,"A",{href:!0});var BRt=s(TX);tko=r(BRt,"BigBirdModel"),BRt.forEach(t),ako=r(gDe," (BigBird model)"),gDe.forEach(t),nko=i(x),I_=n(x,"LI",{});var hDe=s(I_);b1e=n(hDe,"STRONG",{});var IRt=s(b1e);sko=r(IRt,"bigbird_pegasus"),IRt.forEach(t),lko=r(hDe," \u2014 "),MX=n(hDe,"A",{href:!0});var NRt=s(MX);iko=r(NRt,"BigBirdPegasusModel"),NRt.forEach(t),dko=r(hDe," (BigBird-Pegasus model)"),hDe.forEach(t),cko=i(x),N_=n(x,"LI",{});var uDe=s(N_);v1e=n(uDe,"STRONG",{});var qRt=s(v1e);mko=r(qRt,"blenderbot"),qRt.forEach(t),fko=r(uDe," \u2014 "),EX=n(uDe,"A",{href:!0});var jRt=s(EX);gko=r(jRt,"BlenderbotModel"),jRt.forEach(t),hko=r(uDe," (Blenderbot model)"),uDe.forEach(t),uko=i(x),q_=n(x,"LI",{});var pDe=s(q_);F1e=n(pDe,"STRONG",{});var DRt=s(F1e);pko=r(DRt,"blenderbot-small"),DRt.forEach(t),_ko=r(pDe," \u2014 "),CX=n(pDe,"A",{href:!0});var GRt=s(CX);bko=r(GRt,"BlenderbotSmallModel"),GRt.forEach(t),vko=r(pDe," (BlenderbotSmall model)"),pDe.forEach(t),Fko=i(x),j_=n(x,"LI",{});var _De=s(j_);T1e=n(_De,"STRONG",{});var ORt=s(T1e);Tko=r(ORt,"bloom"),ORt.forEach(t),Mko=r(_De," \u2014 "),wX=n(_De,"A",{href:!0});var VRt=s(wX);Eko=r(VRt,"BloomModel"),VRt.forEach(t),Cko=r(_De," (BLOOM model)"),_De.forEach(t),wko=i(x),D_=n(x,"LI",{});var bDe=s(D_);M1e=n(bDe,"STRONG",{});var XRt=s(M1e);Ako=r(XRt,"camembert"),XRt.forEach(t),Lko=r(bDe," \u2014 "),AX=n(bDe,"A",{href:!0});var zRt=s(AX);yko=r(zRt,"CamembertModel"),zRt.forEach(t),xko=r(bDe," (CamemBERT model)"),bDe.forEach(t),$ko=i(x),G_=n(x,"LI",{});var vDe=s(G_);E1e=n(vDe,"STRONG",{});var QRt=s(E1e);kko=r(QRt,"canine"),QRt.forEach(t),Sko=r(vDe," \u2014 "),LX=n(vDe,"A",{href:!0});var WRt=s(LX);Rko=r(WRt,"CanineModel"),WRt.forEach(t),Pko=r(vDe," (CANINE model)"),vDe.forEach(t),Bko=i(x),O_=n(x,"LI",{});var FDe=s(O_);C1e=n(FDe,"STRONG",{});var URt=s(C1e);Iko=r(URt,"clip"),URt.forEach(t),Nko=r(FDe," \u2014 "),yX=n(FDe,"A",{href:!0});var HRt=s(yX);qko=r(HRt,"CLIPModel"),HRt.forEach(t),jko=r(FDe," (CLIP model)"),FDe.forEach(t),Dko=i(x),V_=n(x,"LI",{});var TDe=s(V_);w1e=n(TDe,"STRONG",{});var JRt=s(w1e);Gko=r(JRt,"codegen"),JRt.forEach(t),Oko=r(TDe," \u2014 "),xX=n(TDe,"A",{href:!0});var YRt=s(xX);Vko=r(YRt,"CodeGenModel"),YRt.forEach(t),Xko=r(TDe," (CodeGen model)"),TDe.forEach(t),zko=i(x),X_=n(x,"LI",{});var MDe=s(X_);A1e=n(MDe,"STRONG",{});var ZRt=s(A1e);Qko=r(ZRt,"conditional_detr"),ZRt.forEach(t),Wko=r(MDe," \u2014 "),$X=n(MDe,"A",{href:!0});var KRt=s($X);Uko=r(KRt,"ConditionalDetrModel"),KRt.forEach(t),Hko=r(MDe," (Conditional DETR model)"),MDe.forEach(t),Jko=i(x),z_=n(x,"LI",{});var EDe=s(z_);L1e=n(EDe,"STRONG",{});var ePt=s(L1e);Yko=r(ePt,"convbert"),ePt.forEach(t),Zko=r(EDe," \u2014 "),kX=n(EDe,"A",{href:!0});var oPt=s(kX);Kko=r(oPt,"ConvBertModel"),oPt.forEach(t),eSo=r(EDe," (ConvBERT model)"),EDe.forEach(t),oSo=i(x),Q_=n(x,"LI",{});var CDe=s(Q_);y1e=n(CDe,"STRONG",{});var rPt=s(y1e);rSo=r(rPt,"convnext"),rPt.forEach(t),tSo=r(CDe," \u2014 "),SX=n(CDe,"A",{href:!0});var tPt=s(SX);aSo=r(tPt,"ConvNextModel"),tPt.forEach(t),nSo=r(CDe," (ConvNeXT model)"),CDe.forEach(t),sSo=i(x),W_=n(x,"LI",{});var wDe=s(W_);x1e=n(wDe,"STRONG",{});var aPt=s(x1e);lSo=r(aPt,"ctrl"),aPt.forEach(t),iSo=r(wDe," \u2014 "),RX=n(wDe,"A",{href:!0});var nPt=s(RX);dSo=r(nPt,"CTRLModel"),nPt.forEach(t),cSo=r(wDe," (CTRL model)"),wDe.forEach(t),mSo=i(x),U_=n(x,"LI",{});var ADe=s(U_);$1e=n(ADe,"STRONG",{});var sPt=s($1e);fSo=r(sPt,"cvt"),sPt.forEach(t),gSo=r(ADe," \u2014 "),PX=n(ADe,"A",{href:!0});var lPt=s(PX);hSo=r(lPt,"CvtModel"),lPt.forEach(t),uSo=r(ADe," (CvT model)"),ADe.forEach(t),pSo=i(x),H_=n(x,"LI",{});var LDe=s(H_);k1e=n(LDe,"STRONG",{});var iPt=s(k1e);_So=r(iPt,"data2vec-audio"),iPt.forEach(t),bSo=r(LDe," \u2014 "),BX=n(LDe,"A",{href:!0});var dPt=s(BX);vSo=r(dPt,"Data2VecAudioModel"),dPt.forEach(t),FSo=r(LDe," (Data2VecAudio model)"),LDe.forEach(t),TSo=i(x),J_=n(x,"LI",{});var yDe=s(J_);S1e=n(yDe,"STRONG",{});var cPt=s(S1e);MSo=r(cPt,"data2vec-text"),cPt.forEach(t),ESo=r(yDe," \u2014 "),IX=n(yDe,"A",{href:!0});var mPt=s(IX);CSo=r(mPt,"Data2VecTextModel"),mPt.forEach(t),wSo=r(yDe," (Data2VecText model)"),yDe.forEach(t),ASo=i(x),Y_=n(x,"LI",{});var xDe=s(Y_);R1e=n(xDe,"STRONG",{});var fPt=s(R1e);LSo=r(fPt,"data2vec-vision"),fPt.forEach(t),ySo=r(xDe," \u2014 "),NX=n(xDe,"A",{href:!0});var gPt=s(NX);xSo=r(gPt,"Data2VecVisionModel"),gPt.forEach(t),$So=r(xDe," (Data2VecVision model)"),xDe.forEach(t),kSo=i(x),Z_=n(x,"LI",{});var $De=s(Z_);P1e=n($De,"STRONG",{});var hPt=s(P1e);SSo=r(hPt,"deberta"),hPt.forEach(t),RSo=r($De," \u2014 "),qX=n($De,"A",{href:!0});var uPt=s(qX);PSo=r(uPt,"DebertaModel"),uPt.forEach(t),BSo=r($De," (DeBERTa model)"),$De.forEach(t),ISo=i(x),K_=n(x,"LI",{});var kDe=s(K_);B1e=n(kDe,"STRONG",{});var pPt=s(B1e);NSo=r(pPt,"deberta-v2"),pPt.forEach(t),qSo=r(kDe," \u2014 "),jX=n(kDe,"A",{href:!0});var _Pt=s(jX);jSo=r(_Pt,"DebertaV2Model"),_Pt.forEach(t),DSo=r(kDe," (DeBERTa-v2 model)"),kDe.forEach(t),GSo=i(x),e1=n(x,"LI",{});var SDe=s(e1);I1e=n(SDe,"STRONG",{});var bPt=s(I1e);OSo=r(bPt,"decision_transformer"),bPt.forEach(t),VSo=r(SDe," \u2014 "),DX=n(SDe,"A",{href:!0});var vPt=s(DX);XSo=r(vPt,"DecisionTransformerModel"),vPt.forEach(t),zSo=r(SDe," (Decision Transformer model)"),SDe.forEach(t),QSo=i(x),o1=n(x,"LI",{});var RDe=s(o1);N1e=n(RDe,"STRONG",{});var FPt=s(N1e);WSo=r(FPt,"deformable_detr"),FPt.forEach(t),USo=r(RDe," \u2014 "),GX=n(RDe,"A",{href:!0});var TPt=s(GX);HSo=r(TPt,"DeformableDetrModel"),TPt.forEach(t),JSo=r(RDe," (Deformable DETR model)"),RDe.forEach(t),YSo=i(x),r1=n(x,"LI",{});var PDe=s(r1);q1e=n(PDe,"STRONG",{});var MPt=s(q1e);ZSo=r(MPt,"deit"),MPt.forEach(t),KSo=r(PDe," \u2014 "),OX=n(PDe,"A",{href:!0});var EPt=s(OX);eRo=r(EPt,"DeiTModel"),EPt.forEach(t),oRo=r(PDe," (DeiT model)"),PDe.forEach(t),rRo=i(x),t1=n(x,"LI",{});var BDe=s(t1);j1e=n(BDe,"STRONG",{});var CPt=s(j1e);tRo=r(CPt,"detr"),CPt.forEach(t),aRo=r(BDe," \u2014 "),VX=n(BDe,"A",{href:!0});var wPt=s(VX);nRo=r(wPt,"DetrModel"),wPt.forEach(t),sRo=r(BDe," (DETR model)"),BDe.forEach(t),lRo=i(x),a1=n(x,"LI",{});var IDe=s(a1);D1e=n(IDe,"STRONG",{});var APt=s(D1e);iRo=r(APt,"distilbert"),APt.forEach(t),dRo=r(IDe," \u2014 "),XX=n(IDe,"A",{href:!0});var LPt=s(XX);cRo=r(LPt,"DistilBertModel"),LPt.forEach(t),mRo=r(IDe," (DistilBERT model)"),IDe.forEach(t),fRo=i(x),n1=n(x,"LI",{});var NDe=s(n1);G1e=n(NDe,"STRONG",{});var yPt=s(G1e);gRo=r(yPt,"donut-swin"),yPt.forEach(t),hRo=r(NDe," \u2014 "),zX=n(NDe,"A",{href:!0});var xPt=s(zX);uRo=r(xPt,"DonutSwinModel"),xPt.forEach(t),pRo=r(NDe," (DonutSwin model)"),NDe.forEach(t),_Ro=i(x),s1=n(x,"LI",{});var qDe=s(s1);O1e=n(qDe,"STRONG",{});var $Pt=s(O1e);bRo=r($Pt,"dpr"),$Pt.forEach(t),vRo=r(qDe," \u2014 "),QX=n(qDe,"A",{href:!0});var kPt=s(QX);FRo=r(kPt,"DPRQuestionEncoder"),kPt.forEach(t),TRo=r(qDe," (DPR model)"),qDe.forEach(t),MRo=i(x),l1=n(x,"LI",{});var jDe=s(l1);V1e=n(jDe,"STRONG",{});var SPt=s(V1e);ERo=r(SPt,"dpt"),SPt.forEach(t),CRo=r(jDe," \u2014 "),WX=n(jDe,"A",{href:!0});var RPt=s(WX);wRo=r(RPt,"DPTModel"),RPt.forEach(t),ARo=r(jDe," (DPT model)"),jDe.forEach(t),LRo=i(x),i1=n(x,"LI",{});var DDe=s(i1);X1e=n(DDe,"STRONG",{});var PPt=s(X1e);yRo=r(PPt,"electra"),PPt.forEach(t),xRo=r(DDe," \u2014 "),UX=n(DDe,"A",{href:!0});var BPt=s(UX);$Ro=r(BPt,"ElectraModel"),BPt.forEach(t),kRo=r(DDe," (ELECTRA model)"),DDe.forEach(t),SRo=i(x),d1=n(x,"LI",{});var GDe=s(d1);z1e=n(GDe,"STRONG",{});var IPt=s(z1e);RRo=r(IPt,"ernie"),IPt.forEach(t),PRo=r(GDe," \u2014 "),HX=n(GDe,"A",{href:!0});var NPt=s(HX);BRo=r(NPt,"ErnieModel"),NPt.forEach(t),IRo=r(GDe," (ERNIE model)"),GDe.forEach(t),NRo=i(x),c1=n(x,"LI",{});var ODe=s(c1);Q1e=n(ODe,"STRONG",{});var qPt=s(Q1e);qRo=r(qPt,"esm"),qPt.forEach(t),jRo=r(ODe," \u2014 "),JX=n(ODe,"A",{href:!0});var jPt=s(JX);DRo=r(jPt,"EsmModel"),jPt.forEach(t),GRo=r(ODe," (ESM model)"),ODe.forEach(t),ORo=i(x),m1=n(x,"LI",{});var VDe=s(m1);W1e=n(VDe,"STRONG",{});var DPt=s(W1e);VRo=r(DPt,"flaubert"),DPt.forEach(t),XRo=r(VDe," \u2014 "),YX=n(VDe,"A",{href:!0});var GPt=s(YX);zRo=r(GPt,"FlaubertModel"),GPt.forEach(t),QRo=r(VDe," (FlauBERT model)"),VDe.forEach(t),WRo=i(x),f1=n(x,"LI",{});var XDe=s(f1);U1e=n(XDe,"STRONG",{});var OPt=s(U1e);URo=r(OPt,"flava"),OPt.forEach(t),HRo=r(XDe," \u2014 "),ZX=n(XDe,"A",{href:!0});var VPt=s(ZX);JRo=r(VPt,"FlavaModel"),VPt.forEach(t),YRo=r(XDe," (FLAVA model)"),XDe.forEach(t),ZRo=i(x),g1=n(x,"LI",{});var zDe=s(g1);H1e=n(zDe,"STRONG",{});var XPt=s(H1e);KRo=r(XPt,"fnet"),XPt.forEach(t),ePo=r(zDe," \u2014 "),KX=n(zDe,"A",{href:!0});var zPt=s(KX);oPo=r(zPt,"FNetModel"),zPt.forEach(t),rPo=r(zDe," (FNet model)"),zDe.forEach(t),tPo=i(x),h1=n(x,"LI",{});var QDe=s(h1);J1e=n(QDe,"STRONG",{});var QPt=s(J1e);aPo=r(QPt,"fsmt"),QPt.forEach(t),nPo=r(QDe," \u2014 "),ez=n(QDe,"A",{href:!0});var WPt=s(ez);sPo=r(WPt,"FSMTModel"),WPt.forEach(t),lPo=r(QDe," (FairSeq Machine-Translation model)"),QDe.forEach(t),iPo=i(x),yl=n(x,"LI",{});var lN=s(yl);Y1e=n(lN,"STRONG",{});var UPt=s(Y1e);dPo=r(UPt,"funnel"),UPt.forEach(t),cPo=r(lN," \u2014 "),oz=n(lN,"A",{href:!0});var HPt=s(oz);mPo=r(HPt,"FunnelModel"),HPt.forEach(t),fPo=r(lN," or "),rz=n(lN,"A",{href:!0});var JPt=s(rz);gPo=r(JPt,"FunnelBaseModel"),JPt.forEach(t),hPo=r(lN," (Funnel Transformer model)"),lN.forEach(t),uPo=i(x),u1=n(x,"LI",{});var WDe=s(u1);Z1e=n(WDe,"STRONG",{});var YPt=s(Z1e);pPo=r(YPt,"glpn"),YPt.forEach(t),_Po=r(WDe," \u2014 "),tz=n(WDe,"A",{href:!0});var ZPt=s(tz);bPo=r(ZPt,"GLPNModel"),ZPt.forEach(t),vPo=r(WDe," (GLPN model)"),WDe.forEach(t),FPo=i(x),p1=n(x,"LI",{});var UDe=s(p1);K1e=n(UDe,"STRONG",{});var KPt=s(K1e);TPo=r(KPt,"gpt2"),KPt.forEach(t),MPo=r(UDe," \u2014 "),az=n(UDe,"A",{href:!0});var eBt=s(az);EPo=r(eBt,"GPT2Model"),eBt.forEach(t),CPo=r(UDe," (OpenAI GPT-2 model)"),UDe.forEach(t),wPo=i(x),_1=n(x,"LI",{});var HDe=s(_1);e2e=n(HDe,"STRONG",{});var oBt=s(e2e);APo=r(oBt,"gpt_neo"),oBt.forEach(t),LPo=r(HDe," \u2014 "),nz=n(HDe,"A",{href:!0});var rBt=s(nz);yPo=r(rBt,"GPTNeoModel"),rBt.forEach(t),xPo=r(HDe," (GPT Neo model)"),HDe.forEach(t),$Po=i(x),b1=n(x,"LI",{});var JDe=s(b1);o2e=n(JDe,"STRONG",{});var tBt=s(o2e);kPo=r(tBt,"gpt_neox"),tBt.forEach(t),SPo=r(JDe," \u2014 "),sz=n(JDe,"A",{href:!0});var aBt=s(sz);RPo=r(aBt,"GPTNeoXModel"),aBt.forEach(t),PPo=r(JDe," (GPT NeoX model)"),JDe.forEach(t),BPo=i(x),v1=n(x,"LI",{});var YDe=s(v1);r2e=n(YDe,"STRONG",{});var nBt=s(r2e);IPo=r(nBt,"gpt_neox_japanese"),nBt.forEach(t),NPo=r(YDe," \u2014 "),lz=n(YDe,"A",{href:!0});var sBt=s(lz);qPo=r(sBt,"GPTNeoXJapaneseModel"),sBt.forEach(t),jPo=r(YDe," (GPT NeoX Japanese model)"),YDe.forEach(t),DPo=i(x),F1=n(x,"LI",{});var ZDe=s(F1);t2e=n(ZDe,"STRONG",{});var lBt=s(t2e);GPo=r(lBt,"gptj"),lBt.forEach(t),OPo=r(ZDe," \u2014 "),iz=n(ZDe,"A",{href:!0});var iBt=s(iz);VPo=r(iBt,"GPTJModel"),iBt.forEach(t),XPo=r(ZDe," (GPT-J model)"),ZDe.forEach(t),zPo=i(x),T1=n(x,"LI",{});var KDe=s(T1);a2e=n(KDe,"STRONG",{});var dBt=s(a2e);QPo=r(dBt,"groupvit"),dBt.forEach(t),WPo=r(KDe," \u2014 "),dz=n(KDe,"A",{href:!0});var cBt=s(dz);UPo=r(cBt,"GroupViTModel"),cBt.forEach(t),HPo=r(KDe," (GroupViT model)"),KDe.forEach(t),JPo=i(x),M1=n(x,"LI",{});var eGe=s(M1);n2e=n(eGe,"STRONG",{});var mBt=s(n2e);YPo=r(mBt,"hubert"),mBt.forEach(t),ZPo=r(eGe," \u2014 "),cz=n(eGe,"A",{href:!0});var fBt=s(cz);KPo=r(fBt,"HubertModel"),fBt.forEach(t),eBo=r(eGe," (Hubert model)"),eGe.forEach(t),oBo=i(x),E1=n(x,"LI",{});var oGe=s(E1);s2e=n(oGe,"STRONG",{});var gBt=s(s2e);rBo=r(gBt,"ibert"),gBt.forEach(t),tBo=r(oGe," \u2014 "),mz=n(oGe,"A",{href:!0});var hBt=s(mz);aBo=r(hBt,"IBertModel"),hBt.forEach(t),nBo=r(oGe," (I-BERT model)"),oGe.forEach(t),sBo=i(x),C1=n(x,"LI",{});var rGe=s(C1);l2e=n(rGe,"STRONG",{});var uBt=s(l2e);lBo=r(uBt,"imagegpt"),uBt.forEach(t),iBo=r(rGe," \u2014 "),fz=n(rGe,"A",{href:!0});var pBt=s(fz);dBo=r(pBt,"ImageGPTModel"),pBt.forEach(t),cBo=r(rGe," (ImageGPT model)"),rGe.forEach(t),mBo=i(x),w1=n(x,"LI",{});var tGe=s(w1);i2e=n(tGe,"STRONG",{});var _Bt=s(i2e);fBo=r(_Bt,"layoutlm"),_Bt.forEach(t),gBo=r(tGe," \u2014 "),gz=n(tGe,"A",{href:!0});var bBt=s(gz);hBo=r(bBt,"LayoutLMModel"),bBt.forEach(t),uBo=r(tGe," (LayoutLM model)"),tGe.forEach(t),pBo=i(x),A1=n(x,"LI",{});var aGe=s(A1);d2e=n(aGe,"STRONG",{});var vBt=s(d2e);_Bo=r(vBt,"layoutlmv2"),vBt.forEach(t),bBo=r(aGe," \u2014 "),hz=n(aGe,"A",{href:!0});var FBt=s(hz);vBo=r(FBt,"LayoutLMv2Model"),FBt.forEach(t),FBo=r(aGe," (LayoutLMv2 model)"),aGe.forEach(t),TBo=i(x),L1=n(x,"LI",{});var nGe=s(L1);c2e=n(nGe,"STRONG",{});var TBt=s(c2e);MBo=r(TBt,"layoutlmv3"),TBt.forEach(t),EBo=r(nGe," \u2014 "),uz=n(nGe,"A",{href:!0});var MBt=s(uz);CBo=r(MBt,"LayoutLMv3Model"),MBt.forEach(t),wBo=r(nGe," (LayoutLMv3 model)"),nGe.forEach(t),ABo=i(x),y1=n(x,"LI",{});var sGe=s(y1);m2e=n(sGe,"STRONG",{});var EBt=s(m2e);LBo=r(EBt,"led"),EBt.forEach(t),yBo=r(sGe," \u2014 "),pz=n(sGe,"A",{href:!0});var CBt=s(pz);xBo=r(CBt,"LEDModel"),CBt.forEach(t),$Bo=r(sGe," (LED model)"),sGe.forEach(t),kBo=i(x),x1=n(x,"LI",{});var lGe=s(x1);f2e=n(lGe,"STRONG",{});var wBt=s(f2e);SBo=r(wBt,"levit"),wBt.forEach(t),RBo=r(lGe," \u2014 "),_z=n(lGe,"A",{href:!0});var ABt=s(_z);PBo=r(ABt,"LevitModel"),ABt.forEach(t),BBo=r(lGe," (LeViT model)"),lGe.forEach(t),IBo=i(x),$1=n(x,"LI",{});var iGe=s($1);g2e=n(iGe,"STRONG",{});var LBt=s(g2e);NBo=r(LBt,"lilt"),LBt.forEach(t),qBo=r(iGe," \u2014 "),bz=n(iGe,"A",{href:!0});var yBt=s(bz);jBo=r(yBt,"LiltModel"),yBt.forEach(t),DBo=r(iGe," (LiLT model)"),iGe.forEach(t),GBo=i(x),k1=n(x,"LI",{});var dGe=s(k1);h2e=n(dGe,"STRONG",{});var xBt=s(h2e);OBo=r(xBt,"longformer"),xBt.forEach(t),VBo=r(dGe," \u2014 "),vz=n(dGe,"A",{href:!0});var $Bt=s(vz);XBo=r($Bt,"LongformerModel"),$Bt.forEach(t),zBo=r(dGe," (Longformer model)"),dGe.forEach(t),QBo=i(x),S1=n(x,"LI",{});var cGe=s(S1);u2e=n(cGe,"STRONG",{});var kBt=s(u2e);WBo=r(kBt,"longt5"),kBt.forEach(t),UBo=r(cGe," \u2014 "),Fz=n(cGe,"A",{href:!0});var SBt=s(Fz);HBo=r(SBt,"LongT5Model"),SBt.forEach(t),JBo=r(cGe," (LongT5 model)"),cGe.forEach(t),YBo=i(x),R1=n(x,"LI",{});var mGe=s(R1);p2e=n(mGe,"STRONG",{});var RBt=s(p2e);ZBo=r(RBt,"luke"),RBt.forEach(t),KBo=r(mGe," \u2014 "),Tz=n(mGe,"A",{href:!0});var PBt=s(Tz);eIo=r(PBt,"LukeModel"),PBt.forEach(t),oIo=r(mGe," (LUKE model)"),mGe.forEach(t),rIo=i(x),P1=n(x,"LI",{});var fGe=s(P1);_2e=n(fGe,"STRONG",{});var BBt=s(_2e);tIo=r(BBt,"lxmert"),BBt.forEach(t),aIo=r(fGe," \u2014 "),Mz=n(fGe,"A",{href:!0});var IBt=s(Mz);nIo=r(IBt,"LxmertModel"),IBt.forEach(t),sIo=r(fGe," (LXMERT model)"),fGe.forEach(t),lIo=i(x),B1=n(x,"LI",{});var gGe=s(B1);b2e=n(gGe,"STRONG",{});var NBt=s(b2e);iIo=r(NBt,"m2m_100"),NBt.forEach(t),dIo=r(gGe," \u2014 "),Ez=n(gGe,"A",{href:!0});var qBt=s(Ez);cIo=r(qBt,"M2M100Model"),qBt.forEach(t),mIo=r(gGe," (M2M100 model)"),gGe.forEach(t),fIo=i(x),I1=n(x,"LI",{});var hGe=s(I1);v2e=n(hGe,"STRONG",{});var jBt=s(v2e);gIo=r(jBt,"marian"),jBt.forEach(t),hIo=r(hGe," \u2014 "),Cz=n(hGe,"A",{href:!0});var DBt=s(Cz);uIo=r(DBt,"MarianModel"),DBt.forEach(t),pIo=r(hGe," (Marian model)"),hGe.forEach(t),_Io=i(x),N1=n(x,"LI",{});var uGe=s(N1);F2e=n(uGe,"STRONG",{});var GBt=s(F2e);bIo=r(GBt,"markuplm"),GBt.forEach(t),vIo=r(uGe," \u2014 "),wz=n(uGe,"A",{href:!0});var OBt=s(wz);FIo=r(OBt,"MarkupLMModel"),OBt.forEach(t),TIo=r(uGe," (MarkupLM model)"),uGe.forEach(t),MIo=i(x),q1=n(x,"LI",{});var pGe=s(q1);T2e=n(pGe,"STRONG",{});var VBt=s(T2e);EIo=r(VBt,"maskformer"),VBt.forEach(t),CIo=r(pGe," \u2014 "),Az=n(pGe,"A",{href:!0});var XBt=s(Az);wIo=r(XBt,"MaskFormerModel"),XBt.forEach(t),AIo=r(pGe," (MaskFormer model)"),pGe.forEach(t),LIo=i(x),j1=n(x,"LI",{});var _Ge=s(j1);M2e=n(_Ge,"STRONG",{});var zBt=s(M2e);yIo=r(zBt,"mbart"),zBt.forEach(t),xIo=r(_Ge," \u2014 "),Lz=n(_Ge,"A",{href:!0});var QBt=s(Lz);$Io=r(QBt,"MBartModel"),QBt.forEach(t),kIo=r(_Ge," (mBART model)"),_Ge.forEach(t),SIo=i(x),D1=n(x,"LI",{});var bGe=s(D1);E2e=n(bGe,"STRONG",{});var WBt=s(E2e);RIo=r(WBt,"mctct"),WBt.forEach(t),PIo=r(bGe," \u2014 "),yz=n(bGe,"A",{href:!0});var UBt=s(yz);BIo=r(UBt,"MCTCTModel"),UBt.forEach(t),IIo=r(bGe," (M-CTC-T model)"),bGe.forEach(t),NIo=i(x),G1=n(x,"LI",{});var vGe=s(G1);C2e=n(vGe,"STRONG",{});var HBt=s(C2e);qIo=r(HBt,"megatron-bert"),HBt.forEach(t),jIo=r(vGe," \u2014 "),xz=n(vGe,"A",{href:!0});var JBt=s(xz);DIo=r(JBt,"MegatronBertModel"),JBt.forEach(t),GIo=r(vGe," (Megatron-BERT model)"),vGe.forEach(t),OIo=i(x),O1=n(x,"LI",{});var FGe=s(O1);w2e=n(FGe,"STRONG",{});var YBt=s(w2e);VIo=r(YBt,"mobilebert"),YBt.forEach(t),XIo=r(FGe," \u2014 "),$z=n(FGe,"A",{href:!0});var ZBt=s($z);zIo=r(ZBt,"MobileBertModel"),ZBt.forEach(t),QIo=r(FGe," (MobileBERT model)"),FGe.forEach(t),WIo=i(x),V1=n(x,"LI",{});var TGe=s(V1);A2e=n(TGe,"STRONG",{});var KBt=s(A2e);UIo=r(KBt,"mobilevit"),KBt.forEach(t),HIo=r(TGe," \u2014 "),kz=n(TGe,"A",{href:!0});var eIt=s(kz);JIo=r(eIt,"MobileViTModel"),eIt.forEach(t),YIo=r(TGe," (MobileViT model)"),TGe.forEach(t),ZIo=i(x),X1=n(x,"LI",{});var MGe=s(X1);L2e=n(MGe,"STRONG",{});var oIt=s(L2e);KIo=r(oIt,"mpnet"),oIt.forEach(t),eNo=r(MGe," \u2014 "),Sz=n(MGe,"A",{href:!0});var rIt=s(Sz);oNo=r(rIt,"MPNetModel"),rIt.forEach(t),rNo=r(MGe," (MPNet model)"),MGe.forEach(t),tNo=i(x),z1=n(x,"LI",{});var EGe=s(z1);y2e=n(EGe,"STRONG",{});var tIt=s(y2e);aNo=r(tIt,"mt5"),tIt.forEach(t),nNo=r(EGe," \u2014 "),Rz=n(EGe,"A",{href:!0});var aIt=s(Rz);sNo=r(aIt,"MT5Model"),aIt.forEach(t),lNo=r(EGe," (MT5 model)"),EGe.forEach(t),iNo=i(x),Q1=n(x,"LI",{});var CGe=s(Q1);x2e=n(CGe,"STRONG",{});var nIt=s(x2e);dNo=r(nIt,"mvp"),nIt.forEach(t),cNo=r(CGe," \u2014 "),Pz=n(CGe,"A",{href:!0});var sIt=s(Pz);mNo=r(sIt,"MvpModel"),sIt.forEach(t),fNo=r(CGe," (MVP model)"),CGe.forEach(t),gNo=i(x),W1=n(x,"LI",{});var wGe=s(W1);$2e=n(wGe,"STRONG",{});var lIt=s($2e);hNo=r(lIt,"nezha"),lIt.forEach(t),uNo=r(wGe," \u2014 "),Bz=n(wGe,"A",{href:!0});var iIt=s(Bz);pNo=r(iIt,"NezhaModel"),iIt.forEach(t),_No=r(wGe," (Nezha model)"),wGe.forEach(t),bNo=i(x),U1=n(x,"LI",{});var AGe=s(U1);k2e=n(AGe,"STRONG",{});var dIt=s(k2e);vNo=r(dIt,"nllb"),dIt.forEach(t),FNo=r(AGe," \u2014 "),Iz=n(AGe,"A",{href:!0});var cIt=s(Iz);TNo=r(cIt,"M2M100Model"),cIt.forEach(t),MNo=r(AGe," (NLLB model)"),AGe.forEach(t),ENo=i(x),H1=n(x,"LI",{});var LGe=s(H1);S2e=n(LGe,"STRONG",{});var mIt=s(S2e);CNo=r(mIt,"nystromformer"),mIt.forEach(t),wNo=r(LGe," \u2014 "),Nz=n(LGe,"A",{href:!0});var fIt=s(Nz);ANo=r(fIt,"NystromformerModel"),fIt.forEach(t),LNo=r(LGe," (Nystr\xF6mformer model)"),LGe.forEach(t),yNo=i(x),J1=n(x,"LI",{});var yGe=s(J1);R2e=n(yGe,"STRONG",{});var gIt=s(R2e);xNo=r(gIt,"openai-gpt"),gIt.forEach(t),$No=r(yGe," \u2014 "),qz=n(yGe,"A",{href:!0});var hIt=s(qz);kNo=r(hIt,"OpenAIGPTModel"),hIt.forEach(t),SNo=r(yGe," (OpenAI GPT model)"),yGe.forEach(t),RNo=i(x),Y1=n(x,"LI",{});var xGe=s(Y1);P2e=n(xGe,"STRONG",{});var uIt=s(P2e);PNo=r(uIt,"opt"),uIt.forEach(t),BNo=r(xGe," \u2014 "),jz=n(xGe,"A",{href:!0});var pIt=s(jz);INo=r(pIt,"OPTModel"),pIt.forEach(t),NNo=r(xGe," (OPT model)"),xGe.forEach(t),qNo=i(x),Z1=n(x,"LI",{});var $Ge=s(Z1);B2e=n($Ge,"STRONG",{});var _It=s(B2e);jNo=r(_It,"owlvit"),_It.forEach(t),DNo=r($Ge," \u2014 "),Dz=n($Ge,"A",{href:!0});var bIt=s(Dz);GNo=r(bIt,"OwlViTModel"),bIt.forEach(t),ONo=r($Ge," (OWL-ViT model)"),$Ge.forEach(t),VNo=i(x),K1=n(x,"LI",{});var kGe=s(K1);I2e=n(kGe,"STRONG",{});var vIt=s(I2e);XNo=r(vIt,"pegasus"),vIt.forEach(t),zNo=r(kGe," \u2014 "),Gz=n(kGe,"A",{href:!0});var FIt=s(Gz);QNo=r(FIt,"PegasusModel"),FIt.forEach(t),WNo=r(kGe," (Pegasus model)"),kGe.forEach(t),UNo=i(x),e2=n(x,"LI",{});var SGe=s(e2);N2e=n(SGe,"STRONG",{});var TIt=s(N2e);HNo=r(TIt,"pegasus_x"),TIt.forEach(t),JNo=r(SGe," \u2014 "),Oz=n(SGe,"A",{href:!0});var MIt=s(Oz);YNo=r(MIt,"PegasusXModel"),MIt.forEach(t),ZNo=r(SGe," (PEGASUS-X model)"),SGe.forEach(t),KNo=i(x),o2=n(x,"LI",{});var RGe=s(o2);q2e=n(RGe,"STRONG",{});var EIt=s(q2e);eqo=r(EIt,"perceiver"),EIt.forEach(t),oqo=r(RGe," \u2014 "),Vz=n(RGe,"A",{href:!0});var CIt=s(Vz);rqo=r(CIt,"PerceiverModel"),CIt.forEach(t),tqo=r(RGe," (Perceiver model)"),RGe.forEach(t),aqo=i(x),r2=n(x,"LI",{});var PGe=s(r2);j2e=n(PGe,"STRONG",{});var wIt=s(j2e);nqo=r(wIt,"plbart"),wIt.forEach(t),sqo=r(PGe," \u2014 "),Xz=n(PGe,"A",{href:!0});var AIt=s(Xz);lqo=r(AIt,"PLBartModel"),AIt.forEach(t),iqo=r(PGe," (PLBart model)"),PGe.forEach(t),dqo=i(x),t2=n(x,"LI",{});var BGe=s(t2);D2e=n(BGe,"STRONG",{});var LIt=s(D2e);cqo=r(LIt,"poolformer"),LIt.forEach(t),mqo=r(BGe," \u2014 "),zz=n(BGe,"A",{href:!0});var yIt=s(zz);fqo=r(yIt,"PoolFormerModel"),yIt.forEach(t),gqo=r(BGe," (PoolFormer model)"),BGe.forEach(t),hqo=i(x),a2=n(x,"LI",{});var IGe=s(a2);G2e=n(IGe,"STRONG",{});var xIt=s(G2e);uqo=r(xIt,"prophetnet"),xIt.forEach(t),pqo=r(IGe," \u2014 "),Qz=n(IGe,"A",{href:!0});var $It=s(Qz);_qo=r($It,"ProphetNetModel"),$It.forEach(t),bqo=r(IGe," (ProphetNet model)"),IGe.forEach(t),vqo=i(x),n2=n(x,"LI",{});var NGe=s(n2);O2e=n(NGe,"STRONG",{});var kIt=s(O2e);Fqo=r(kIt,"qdqbert"),kIt.forEach(t),Tqo=r(NGe," \u2014 "),Wz=n(NGe,"A",{href:!0});var SIt=s(Wz);Mqo=r(SIt,"QDQBertModel"),SIt.forEach(t),Eqo=r(NGe," (QDQBert model)"),NGe.forEach(t),Cqo=i(x),s2=n(x,"LI",{});var qGe=s(s2);V2e=n(qGe,"STRONG",{});var RIt=s(V2e);wqo=r(RIt,"reformer"),RIt.forEach(t),Aqo=r(qGe," \u2014 "),Uz=n(qGe,"A",{href:!0});var PIt=s(Uz);Lqo=r(PIt,"ReformerModel"),PIt.forEach(t),yqo=r(qGe," (Reformer model)"),qGe.forEach(t),xqo=i(x),l2=n(x,"LI",{});var jGe=s(l2);X2e=n(jGe,"STRONG",{});var BIt=s(X2e);$qo=r(BIt,"regnet"),BIt.forEach(t),kqo=r(jGe," \u2014 "),Hz=n(jGe,"A",{href:!0});var IIt=s(Hz);Sqo=r(IIt,"RegNetModel"),IIt.forEach(t),Rqo=r(jGe," (RegNet model)"),jGe.forEach(t),Pqo=i(x),i2=n(x,"LI",{});var DGe=s(i2);z2e=n(DGe,"STRONG",{});var NIt=s(z2e);Bqo=r(NIt,"rembert"),NIt.forEach(t),Iqo=r(DGe," \u2014 "),Jz=n(DGe,"A",{href:!0});var qIt=s(Jz);Nqo=r(qIt,"RemBertModel"),qIt.forEach(t),qqo=r(DGe," (RemBERT model)"),DGe.forEach(t),jqo=i(x),d2=n(x,"LI",{});var GGe=s(d2);Q2e=n(GGe,"STRONG",{});var jIt=s(Q2e);Dqo=r(jIt,"resnet"),jIt.forEach(t),Gqo=r(GGe," \u2014 "),Yz=n(GGe,"A",{href:!0});var DIt=s(Yz);Oqo=r(DIt,"ResNetModel"),DIt.forEach(t),Vqo=r(GGe," (ResNet model)"),GGe.forEach(t),Xqo=i(x),c2=n(x,"LI",{});var OGe=s(c2);W2e=n(OGe,"STRONG",{});var GIt=s(W2e);zqo=r(GIt,"retribert"),GIt.forEach(t),Qqo=r(OGe," \u2014 "),Zz=n(OGe,"A",{href:!0});var OIt=s(Zz);Wqo=r(OIt,"RetriBertModel"),OIt.forEach(t),Uqo=r(OGe," (RetriBERT model)"),OGe.forEach(t),Hqo=i(x),m2=n(x,"LI",{});var VGe=s(m2);U2e=n(VGe,"STRONG",{});var VIt=s(U2e);Jqo=r(VIt,"roberta"),VIt.forEach(t),Yqo=r(VGe," \u2014 "),Kz=n(VGe,"A",{href:!0});var XIt=s(Kz);Zqo=r(XIt,"RobertaModel"),XIt.forEach(t),Kqo=r(VGe," (RoBERTa model)"),VGe.forEach(t),ejo=i(x),f2=n(x,"LI",{});var XGe=s(f2);H2e=n(XGe,"STRONG",{});var zIt=s(H2e);ojo=r(zIt,"roformer"),zIt.forEach(t),rjo=r(XGe," \u2014 "),eQ=n(XGe,"A",{href:!0});var QIt=s(eQ);tjo=r(QIt,"RoFormerModel"),QIt.forEach(t),ajo=r(XGe," (RoFormer model)"),XGe.forEach(t),njo=i(x),g2=n(x,"LI",{});var zGe=s(g2);J2e=n(zGe,"STRONG",{});var WIt=s(J2e);sjo=r(WIt,"segformer"),WIt.forEach(t),ljo=r(zGe," \u2014 "),oQ=n(zGe,"A",{href:!0});var UIt=s(oQ);ijo=r(UIt,"SegformerModel"),UIt.forEach(t),djo=r(zGe," (SegFormer model)"),zGe.forEach(t),cjo=i(x),h2=n(x,"LI",{});var QGe=s(h2);Y2e=n(QGe,"STRONG",{});var HIt=s(Y2e);mjo=r(HIt,"sew"),HIt.forEach(t),fjo=r(QGe," \u2014 "),rQ=n(QGe,"A",{href:!0});var JIt=s(rQ);gjo=r(JIt,"SEWModel"),JIt.forEach(t),hjo=r(QGe," (SEW model)"),QGe.forEach(t),ujo=i(x),u2=n(x,"LI",{});var WGe=s(u2);Z2e=n(WGe,"STRONG",{});var YIt=s(Z2e);pjo=r(YIt,"sew-d"),YIt.forEach(t),_jo=r(WGe," \u2014 "),tQ=n(WGe,"A",{href:!0});var ZIt=s(tQ);bjo=r(ZIt,"SEWDModel"),ZIt.forEach(t),vjo=r(WGe," (SEW-D model)"),WGe.forEach(t),Fjo=i(x),p2=n(x,"LI",{});var UGe=s(p2);K2e=n(UGe,"STRONG",{});var KIt=s(K2e);Tjo=r(KIt,"speech_to_text"),KIt.forEach(t),Mjo=r(UGe," \u2014 "),aQ=n(UGe,"A",{href:!0});var eNt=s(aQ);Ejo=r(eNt,"Speech2TextModel"),eNt.forEach(t),Cjo=r(UGe," (Speech2Text model)"),UGe.forEach(t),wjo=i(x),_2=n(x,"LI",{});var HGe=s(_2);ebe=n(HGe,"STRONG",{});var oNt=s(ebe);Ajo=r(oNt,"splinter"),oNt.forEach(t),Ljo=r(HGe," \u2014 "),nQ=n(HGe,"A",{href:!0});var rNt=s(nQ);yjo=r(rNt,"SplinterModel"),rNt.forEach(t),xjo=r(HGe," (Splinter model)"),HGe.forEach(t),$jo=i(x),b2=n(x,"LI",{});var JGe=s(b2);obe=n(JGe,"STRONG",{});var tNt=s(obe);kjo=r(tNt,"squeezebert"),tNt.forEach(t),Sjo=r(JGe," \u2014 "),sQ=n(JGe,"A",{href:!0});var aNt=s(sQ);Rjo=r(aNt,"SqueezeBertModel"),aNt.forEach(t),Pjo=r(JGe," (SqueezeBERT model)"),JGe.forEach(t),Bjo=i(x),v2=n(x,"LI",{});var YGe=s(v2);rbe=n(YGe,"STRONG",{});var nNt=s(rbe);Ijo=r(nNt,"swin"),nNt.forEach(t),Njo=r(YGe," \u2014 "),lQ=n(YGe,"A",{href:!0});var sNt=s(lQ);qjo=r(sNt,"SwinModel"),sNt.forEach(t),jjo=r(YGe," (Swin Transformer model)"),YGe.forEach(t),Djo=i(x),F2=n(x,"LI",{});var ZGe=s(F2);tbe=n(ZGe,"STRONG",{});var lNt=s(tbe);Gjo=r(lNt,"swinv2"),lNt.forEach(t),Ojo=r(ZGe," \u2014 "),iQ=n(ZGe,"A",{href:!0});var iNt=s(iQ);Vjo=r(iNt,"Swinv2Model"),iNt.forEach(t),Xjo=r(ZGe," (Swin Transformer V2 model)"),ZGe.forEach(t),zjo=i(x),T2=n(x,"LI",{});var KGe=s(T2);abe=n(KGe,"STRONG",{});var dNt=s(abe);Qjo=r(dNt,"t5"),dNt.forEach(t),Wjo=r(KGe," \u2014 "),dQ=n(KGe,"A",{href:!0});var cNt=s(dQ);Ujo=r(cNt,"T5Model"),cNt.forEach(t),Hjo=r(KGe," (T5 model)"),KGe.forEach(t),Jjo=i(x),M2=n(x,"LI",{});var eOe=s(M2);nbe=n(eOe,"STRONG",{});var mNt=s(nbe);Yjo=r(mNt,"tapas"),mNt.forEach(t),Zjo=r(eOe," \u2014 "),cQ=n(eOe,"A",{href:!0});var fNt=s(cQ);Kjo=r(fNt,"TapasModel"),fNt.forEach(t),eDo=r(eOe," (TAPAS model)"),eOe.forEach(t),oDo=i(x),E2=n(x,"LI",{});var oOe=s(E2);sbe=n(oOe,"STRONG",{});var gNt=s(sbe);rDo=r(gNt,"time_series_transformer"),gNt.forEach(t),tDo=r(oOe," \u2014 "),mQ=n(oOe,"A",{href:!0});var hNt=s(mQ);aDo=r(hNt,"TimeSeriesTransformerModel"),hNt.forEach(t),nDo=r(oOe," (Time Series Transformer model)"),oOe.forEach(t),sDo=i(x),C2=n(x,"LI",{});var rOe=s(C2);lbe=n(rOe,"STRONG",{});var uNt=s(lbe);lDo=r(uNt,"trajectory_transformer"),uNt.forEach(t),iDo=r(rOe," \u2014 "),fQ=n(rOe,"A",{href:!0});var pNt=s(fQ);dDo=r(pNt,"TrajectoryTransformerModel"),pNt.forEach(t),cDo=r(rOe," (Trajectory Transformer model)"),rOe.forEach(t),mDo=i(x),w2=n(x,"LI",{});var tOe=s(w2);ibe=n(tOe,"STRONG",{});var _Nt=s(ibe);fDo=r(_Nt,"transfo-xl"),_Nt.forEach(t),gDo=r(tOe," \u2014 "),gQ=n(tOe,"A",{href:!0});var bNt=s(gQ);hDo=r(bNt,"TransfoXLModel"),bNt.forEach(t),uDo=r(tOe," (Transformer-XL model)"),tOe.forEach(t),pDo=i(x),A2=n(x,"LI",{});var aOe=s(A2);dbe=n(aOe,"STRONG",{});var vNt=s(dbe);_Do=r(vNt,"unispeech"),vNt.forEach(t),bDo=r(aOe," \u2014 "),hQ=n(aOe,"A",{href:!0});var FNt=s(hQ);vDo=r(FNt,"UniSpeechModel"),FNt.forEach(t),FDo=r(aOe," (UniSpeech model)"),aOe.forEach(t),TDo=i(x),L2=n(x,"LI",{});var nOe=s(L2);cbe=n(nOe,"STRONG",{});var TNt=s(cbe);MDo=r(TNt,"unispeech-sat"),TNt.forEach(t),EDo=r(nOe," \u2014 "),uQ=n(nOe,"A",{href:!0});var MNt=s(uQ);CDo=r(MNt,"UniSpeechSatModel"),MNt.forEach(t),wDo=r(nOe," (UniSpeechSat model)"),nOe.forEach(t),ADo=i(x),y2=n(x,"LI",{});var sOe=s(y2);mbe=n(sOe,"STRONG",{});var ENt=s(mbe);LDo=r(ENt,"van"),ENt.forEach(t),yDo=r(sOe," \u2014 "),pQ=n(sOe,"A",{href:!0});var CNt=s(pQ);xDo=r(CNt,"VanModel"),CNt.forEach(t),$Do=r(sOe," (VAN model)"),sOe.forEach(t),kDo=i(x),x2=n(x,"LI",{});var lOe=s(x2);fbe=n(lOe,"STRONG",{});var wNt=s(fbe);SDo=r(wNt,"videomae"),wNt.forEach(t),RDo=r(lOe," \u2014 "),_Q=n(lOe,"A",{href:!0});var ANt=s(_Q);PDo=r(ANt,"VideoMAEModel"),ANt.forEach(t),BDo=r(lOe," (VideoMAE model)"),lOe.forEach(t),IDo=i(x),$2=n(x,"LI",{});var iOe=s($2);gbe=n(iOe,"STRONG",{});var LNt=s(gbe);NDo=r(LNt,"vilt"),LNt.forEach(t),qDo=r(iOe," \u2014 "),bQ=n(iOe,"A",{href:!0});var yNt=s(bQ);jDo=r(yNt,"ViltModel"),yNt.forEach(t),DDo=r(iOe," (ViLT model)"),iOe.forEach(t),GDo=i(x),k2=n(x,"LI",{});var dOe=s(k2);hbe=n(dOe,"STRONG",{});var xNt=s(hbe);ODo=r(xNt,"vision-text-dual-encoder"),xNt.forEach(t),VDo=r(dOe," \u2014 "),vQ=n(dOe,"A",{href:!0});var $Nt=s(vQ);XDo=r($Nt,"VisionTextDualEncoderModel"),$Nt.forEach(t),zDo=r(dOe," (VisionTextDualEncoder model)"),dOe.forEach(t),QDo=i(x),S2=n(x,"LI",{});var cOe=s(S2);ube=n(cOe,"STRONG",{});var kNt=s(ube);WDo=r(kNt,"visual_bert"),kNt.forEach(t),UDo=r(cOe," \u2014 "),FQ=n(cOe,"A",{href:!0});var SNt=s(FQ);HDo=r(SNt,"VisualBertModel"),SNt.forEach(t),JDo=r(cOe," (VisualBERT model)"),cOe.forEach(t),YDo=i(x),R2=n(x,"LI",{});var mOe=s(R2);pbe=n(mOe,"STRONG",{});var RNt=s(pbe);ZDo=r(RNt,"vit"),RNt.forEach(t),KDo=r(mOe," \u2014 "),TQ=n(mOe,"A",{href:!0});var PNt=s(TQ);eGo=r(PNt,"ViTModel"),PNt.forEach(t),oGo=r(mOe," (ViT model)"),mOe.forEach(t),rGo=i(x),P2=n(x,"LI",{});var fOe=s(P2);_be=n(fOe,"STRONG",{});var BNt=s(_be);tGo=r(BNt,"vit_mae"),BNt.forEach(t),aGo=r(fOe," \u2014 "),MQ=n(fOe,"A",{href:!0});var INt=s(MQ);nGo=r(INt,"ViTMAEModel"),INt.forEach(t),sGo=r(fOe," (ViTMAE model)"),fOe.forEach(t),lGo=i(x),B2=n(x,"LI",{});var gOe=s(B2);bbe=n(gOe,"STRONG",{});var NNt=s(bbe);iGo=r(NNt,"vit_msn"),NNt.forEach(t),dGo=r(gOe," \u2014 "),EQ=n(gOe,"A",{href:!0});var qNt=s(EQ);cGo=r(qNt,"ViTMSNModel"),qNt.forEach(t),mGo=r(gOe," (ViTMSN model)"),gOe.forEach(t),fGo=i(x),I2=n(x,"LI",{});var hOe=s(I2);vbe=n(hOe,"STRONG",{});var jNt=s(vbe);gGo=r(jNt,"wav2vec2"),jNt.forEach(t),hGo=r(hOe," \u2014 "),CQ=n(hOe,"A",{href:!0});var DNt=s(CQ);uGo=r(DNt,"Wav2Vec2Model"),DNt.forEach(t),pGo=r(hOe," (Wav2Vec2 model)"),hOe.forEach(t),_Go=i(x),N2=n(x,"LI",{});var uOe=s(N2);Fbe=n(uOe,"STRONG",{});var GNt=s(Fbe);bGo=r(GNt,"wav2vec2-conformer"),GNt.forEach(t),vGo=r(uOe," \u2014 "),wQ=n(uOe,"A",{href:!0});var ONt=s(wQ);FGo=r(ONt,"Wav2Vec2ConformerModel"),ONt.forEach(t),TGo=r(uOe," (Wav2Vec2-Conformer model)"),uOe.forEach(t),MGo=i(x),q2=n(x,"LI",{});var pOe=s(q2);Tbe=n(pOe,"STRONG",{});var VNt=s(Tbe);EGo=r(VNt,"wavlm"),VNt.forEach(t),CGo=r(pOe," \u2014 "),AQ=n(pOe,"A",{href:!0});var XNt=s(AQ);wGo=r(XNt,"WavLMModel"),XNt.forEach(t),AGo=r(pOe," (WavLM model)"),pOe.forEach(t),LGo=i(x),j2=n(x,"LI",{});var _Oe=s(j2);Mbe=n(_Oe,"STRONG",{});var zNt=s(Mbe);yGo=r(zNt,"whisper"),zNt.forEach(t),xGo=r(_Oe," \u2014 "),LQ=n(_Oe,"A",{href:!0});var QNt=s(LQ);$Go=r(QNt,"WhisperModel"),QNt.forEach(t),kGo=r(_Oe," (Whisper model)"),_Oe.forEach(t),SGo=i(x),D2=n(x,"LI",{});var bOe=s(D2);Ebe=n(bOe,"STRONG",{});var WNt=s(Ebe);RGo=r(WNt,"xclip"),WNt.forEach(t),PGo=r(bOe," \u2014 "),yQ=n(bOe,"A",{href:!0});var UNt=s(yQ);BGo=r(UNt,"XCLIPModel"),UNt.forEach(t),IGo=r(bOe," (X-CLIP model)"),bOe.forEach(t),NGo=i(x),G2=n(x,"LI",{});var vOe=s(G2);Cbe=n(vOe,"STRONG",{});var HNt=s(Cbe);qGo=r(HNt,"xglm"),HNt.forEach(t),jGo=r(vOe," \u2014 "),xQ=n(vOe,"A",{href:!0});var JNt=s(xQ);DGo=r(JNt,"XGLMModel"),JNt.forEach(t),GGo=r(vOe," (XGLM model)"),vOe.forEach(t),OGo=i(x),O2=n(x,"LI",{});var FOe=s(O2);wbe=n(FOe,"STRONG",{});var YNt=s(wbe);VGo=r(YNt,"xlm"),YNt.forEach(t),XGo=r(FOe," \u2014 "),$Q=n(FOe,"A",{href:!0});var ZNt=s($Q);zGo=r(ZNt,"XLMModel"),ZNt.forEach(t),QGo=r(FOe," (XLM model)"),FOe.forEach(t),WGo=i(x),V2=n(x,"LI",{});var TOe=s(V2);Abe=n(TOe,"STRONG",{});var KNt=s(Abe);UGo=r(KNt,"xlm-prophetnet"),KNt.forEach(t),HGo=r(TOe," \u2014 "),kQ=n(TOe,"A",{href:!0});var eqt=s(kQ);JGo=r(eqt,"XLMProphetNetModel"),eqt.forEach(t),YGo=r(TOe," (XLM-ProphetNet model)"),TOe.forEach(t),ZGo=i(x),X2=n(x,"LI",{});var MOe=s(X2);Lbe=n(MOe,"STRONG",{});var oqt=s(Lbe);KGo=r(oqt,"xlm-roberta"),oqt.forEach(t),eOo=r(MOe," \u2014 "),SQ=n(MOe,"A",{href:!0});var rqt=s(SQ);oOo=r(rqt,"XLMRobertaModel"),rqt.forEach(t),rOo=r(MOe," (XLM-RoBERTa model)"),MOe.forEach(t),tOo=i(x),z2=n(x,"LI",{});var EOe=s(z2);ybe=n(EOe,"STRONG",{});var tqt=s(ybe);aOo=r(tqt,"xlm-roberta-xl"),tqt.forEach(t),nOo=r(EOe," \u2014 "),RQ=n(EOe,"A",{href:!0});var aqt=s(RQ);sOo=r(aqt,"XLMRobertaXLModel"),aqt.forEach(t),lOo=r(EOe," (XLM-RoBERTa-XL model)"),EOe.forEach(t),iOo=i(x),Q2=n(x,"LI",{});var COe=s(Q2);xbe=n(COe,"STRONG",{});var nqt=s(xbe);dOo=r(nqt,"xlnet"),nqt.forEach(t),cOo=r(COe," \u2014 "),PQ=n(COe,"A",{href:!0});var sqt=s(PQ);mOo=r(sqt,"XLNetModel"),sqt.forEach(t),fOo=r(COe," (XLNet model)"),COe.forEach(t),gOo=i(x),W2=n(x,"LI",{});var wOe=s(W2);$be=n(wOe,"STRONG",{});var lqt=s($be);hOo=r(lqt,"yolos"),lqt.forEach(t),uOo=r(wOe," \u2014 "),BQ=n(wOe,"A",{href:!0});var iqt=s(BQ);pOo=r(iqt,"YolosModel"),iqt.forEach(t),_Oo=r(wOe," (YOLOS model)"),wOe.forEach(t),bOo=i(x),U2=n(x,"LI",{});var AOe=s(U2);kbe=n(AOe,"STRONG",{});var dqt=s(kbe);vOo=r(dqt,"yoso"),dqt.forEach(t),FOo=r(AOe," \u2014 "),IQ=n(AOe,"A",{href:!0});var cqt=s(IQ);TOo=r(cqt,"YosoModel"),cqt.forEach(t),MOo=r(AOe," (YOSO model)"),AOe.forEach(t),x.forEach(t),EOo=i(Aa),H2=n(Aa,"P",{});var LOe=s(H2);COo=r(LOe,"The model is set in evaluation mode by default using "),Sbe=n(LOe,"CODE",{});var mqt=s(Sbe);wOo=r(mqt,"model.eval()"),mqt.forEach(t),AOo=r(LOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rbe=n(LOe,"CODE",{});var fqt=s(Rbe);LOo=r(fqt,"model.train()"),fqt.forEach(t),LOe.forEach(t),yOo=i(Aa),T(J2.$$.fragment,Aa),Aa.forEach(t),Nl.forEach(t),tto=i(m),Rd=n(m,"H2",{class:!0});var Tno=s(Rd);Y2=n(Tno,"A",{id:!0,class:!0,href:!0});var gqt=s(Y2);Pbe=n(gqt,"SPAN",{});var hqt=s(Pbe);T(k$.$$.fragment,hqt),hqt.forEach(t),gqt.forEach(t),xOo=i(Tno),Bbe=n(Tno,"SPAN",{});var uqt=s(Bbe);$Oo=r(uqt,"AutoModelForPreTraining"),uqt.forEach(t),Tno.forEach(t),ato=i(m),No=n(m,"DIV",{class:!0});var ql=s(No);T(S$.$$.fragment,ql),kOo=i(ql),Pd=n(ql,"P",{});var Dde=s(Pd);SOo=r(Dde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),NQ=n(Dde,"A",{href:!0});var pqt=s(NQ);ROo=r(pqt,"from_pretrained()"),pqt.forEach(t),POo=r(Dde," class method or the "),qQ=n(Dde,"A",{href:!0});var _qt=s(qQ);BOo=r(_qt,"from_config()"),_qt.forEach(t),IOo=r(Dde,` class
method.`),Dde.forEach(t),NOo=i(ql),R$=n(ql,"P",{});var Mno=s(R$);qOo=r(Mno,"This class cannot be instantiated directly using "),Ibe=n(Mno,"CODE",{});var bqt=s(Ibe);jOo=r(bqt,"__init__()"),bqt.forEach(t),DOo=r(Mno," (throws an error)."),Mno.forEach(t),GOo=i(ql),Mt=n(ql,"DIV",{class:!0});var Qy=s(Mt);T(P$.$$.fragment,Qy),OOo=i(Qy),Nbe=n(Qy,"P",{});var vqt=s(Nbe);VOo=r(vqt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),vqt.forEach(t),XOo=i(Qy),Bd=n(Qy,"P",{});var Gde=s(Bd);zOo=r(Gde,`Note:
Loading a model from its configuration file does `),qbe=n(Gde,"STRONG",{});var Fqt=s(qbe);QOo=r(Fqt,"not"),Fqt.forEach(t),WOo=r(Gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),jQ=n(Gde,"A",{href:!0});var Tqt=s(jQ);UOo=r(Tqt,"from_pretrained()"),Tqt.forEach(t),HOo=r(Gde," to load the model weights."),Gde.forEach(t),JOo=i(Qy),T(Z2.$$.fragment,Qy),Qy.forEach(t),YOo=i(ql),eo=n(ql,"DIV",{class:!0});var La=s(eo);T(B$.$$.fragment,La),ZOo=i(La),jbe=n(La,"P",{});var Mqt=s(jbe);KOo=r(Mqt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Mqt.forEach(t),eVo=i(La),nn=n(La,"P",{});var Wy=s(nn);oVo=r(Wy,"The model class to instantiate is selected based on the "),Dbe=n(Wy,"CODE",{});var Eqt=s(Dbe);rVo=r(Eqt,"model_type"),Eqt.forEach(t),tVo=r(Wy,` property of the config object (either
passed as an argument or loaded from `),Gbe=n(Wy,"CODE",{});var Cqt=s(Gbe);aVo=r(Cqt,"pretrained_model_name_or_path"),Cqt.forEach(t),nVo=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Obe=n(Wy,"CODE",{});var wqt=s(Obe);sVo=r(wqt,"pretrained_model_name_or_path"),wqt.forEach(t),lVo=r(Wy,":"),Wy.forEach(t),iVo=i(La),G=n(La,"UL",{});var V=s(G);K2=n(V,"LI",{});var yOe=s(K2);Vbe=n(yOe,"STRONG",{});var Aqt=s(Vbe);dVo=r(Aqt,"albert"),Aqt.forEach(t),cVo=r(yOe," \u2014 "),DQ=n(yOe,"A",{href:!0});var Lqt=s(DQ);mVo=r(Lqt,"AlbertForPreTraining"),Lqt.forEach(t),fVo=r(yOe," (ALBERT model)"),yOe.forEach(t),gVo=i(V),eb=n(V,"LI",{});var xOe=s(eb);Xbe=n(xOe,"STRONG",{});var yqt=s(Xbe);hVo=r(yqt,"bart"),yqt.forEach(t),uVo=r(xOe," \u2014 "),GQ=n(xOe,"A",{href:!0});var xqt=s(GQ);pVo=r(xqt,"BartForConditionalGeneration"),xqt.forEach(t),_Vo=r(xOe," (BART model)"),xOe.forEach(t),bVo=i(V),ob=n(V,"LI",{});var $Oe=s(ob);zbe=n($Oe,"STRONG",{});var $qt=s(zbe);vVo=r($qt,"bert"),$qt.forEach(t),FVo=r($Oe," \u2014 "),OQ=n($Oe,"A",{href:!0});var kqt=s(OQ);TVo=r(kqt,"BertForPreTraining"),kqt.forEach(t),MVo=r($Oe," (BERT model)"),$Oe.forEach(t),EVo=i(V),rb=n(V,"LI",{});var kOe=s(rb);Qbe=n(kOe,"STRONG",{});var Sqt=s(Qbe);CVo=r(Sqt,"big_bird"),Sqt.forEach(t),wVo=r(kOe," \u2014 "),VQ=n(kOe,"A",{href:!0});var Rqt=s(VQ);AVo=r(Rqt,"BigBirdForPreTraining"),Rqt.forEach(t),LVo=r(kOe," (BigBird model)"),kOe.forEach(t),yVo=i(V),tb=n(V,"LI",{});var SOe=s(tb);Wbe=n(SOe,"STRONG",{});var Pqt=s(Wbe);xVo=r(Pqt,"bloom"),Pqt.forEach(t),$Vo=r(SOe," \u2014 "),XQ=n(SOe,"A",{href:!0});var Bqt=s(XQ);kVo=r(Bqt,"BloomForCausalLM"),Bqt.forEach(t),SVo=r(SOe," (BLOOM model)"),SOe.forEach(t),RVo=i(V),ab=n(V,"LI",{});var ROe=s(ab);Ube=n(ROe,"STRONG",{});var Iqt=s(Ube);PVo=r(Iqt,"camembert"),Iqt.forEach(t),BVo=r(ROe," \u2014 "),zQ=n(ROe,"A",{href:!0});var Nqt=s(zQ);IVo=r(Nqt,"CamembertForMaskedLM"),Nqt.forEach(t),NVo=r(ROe," (CamemBERT model)"),ROe.forEach(t),qVo=i(V),nb=n(V,"LI",{});var POe=s(nb);Hbe=n(POe,"STRONG",{});var qqt=s(Hbe);jVo=r(qqt,"ctrl"),qqt.forEach(t),DVo=r(POe," \u2014 "),QQ=n(POe,"A",{href:!0});var jqt=s(QQ);GVo=r(jqt,"CTRLLMHeadModel"),jqt.forEach(t),OVo=r(POe," (CTRL model)"),POe.forEach(t),VVo=i(V),sb=n(V,"LI",{});var BOe=s(sb);Jbe=n(BOe,"STRONG",{});var Dqt=s(Jbe);XVo=r(Dqt,"data2vec-text"),Dqt.forEach(t),zVo=r(BOe," \u2014 "),WQ=n(BOe,"A",{href:!0});var Gqt=s(WQ);QVo=r(Gqt,"Data2VecTextForMaskedLM"),Gqt.forEach(t),WVo=r(BOe," (Data2VecText model)"),BOe.forEach(t),UVo=i(V),lb=n(V,"LI",{});var IOe=s(lb);Ybe=n(IOe,"STRONG",{});var Oqt=s(Ybe);HVo=r(Oqt,"deberta"),Oqt.forEach(t),JVo=r(IOe," \u2014 "),UQ=n(IOe,"A",{href:!0});var Vqt=s(UQ);YVo=r(Vqt,"DebertaForMaskedLM"),Vqt.forEach(t),ZVo=r(IOe," (DeBERTa model)"),IOe.forEach(t),KVo=i(V),ib=n(V,"LI",{});var NOe=s(ib);Zbe=n(NOe,"STRONG",{});var Xqt=s(Zbe);eXo=r(Xqt,"deberta-v2"),Xqt.forEach(t),oXo=r(NOe," \u2014 "),HQ=n(NOe,"A",{href:!0});var zqt=s(HQ);rXo=r(zqt,"DebertaV2ForMaskedLM"),zqt.forEach(t),tXo=r(NOe," (DeBERTa-v2 model)"),NOe.forEach(t),aXo=i(V),db=n(V,"LI",{});var qOe=s(db);Kbe=n(qOe,"STRONG",{});var Qqt=s(Kbe);nXo=r(Qqt,"distilbert"),Qqt.forEach(t),sXo=r(qOe," \u2014 "),JQ=n(qOe,"A",{href:!0});var Wqt=s(JQ);lXo=r(Wqt,"DistilBertForMaskedLM"),Wqt.forEach(t),iXo=r(qOe," (DistilBERT model)"),qOe.forEach(t),dXo=i(V),cb=n(V,"LI",{});var jOe=s(cb);eve=n(jOe,"STRONG",{});var Uqt=s(eve);cXo=r(Uqt,"electra"),Uqt.forEach(t),mXo=r(jOe," \u2014 "),YQ=n(jOe,"A",{href:!0});var Hqt=s(YQ);fXo=r(Hqt,"ElectraForPreTraining"),Hqt.forEach(t),gXo=r(jOe," (ELECTRA model)"),jOe.forEach(t),hXo=i(V),mb=n(V,"LI",{});var DOe=s(mb);ove=n(DOe,"STRONG",{});var Jqt=s(ove);uXo=r(Jqt,"ernie"),Jqt.forEach(t),pXo=r(DOe," \u2014 "),ZQ=n(DOe,"A",{href:!0});var Yqt=s(ZQ);_Xo=r(Yqt,"ErnieForPreTraining"),Yqt.forEach(t),bXo=r(DOe," (ERNIE model)"),DOe.forEach(t),vXo=i(V),fb=n(V,"LI",{});var GOe=s(fb);rve=n(GOe,"STRONG",{});var Zqt=s(rve);FXo=r(Zqt,"flaubert"),Zqt.forEach(t),TXo=r(GOe," \u2014 "),KQ=n(GOe,"A",{href:!0});var Kqt=s(KQ);MXo=r(Kqt,"FlaubertWithLMHeadModel"),Kqt.forEach(t),EXo=r(GOe," (FlauBERT model)"),GOe.forEach(t),CXo=i(V),gb=n(V,"LI",{});var OOe=s(gb);tve=n(OOe,"STRONG",{});var ejt=s(tve);wXo=r(ejt,"flava"),ejt.forEach(t),AXo=r(OOe," \u2014 "),eW=n(OOe,"A",{href:!0});var ojt=s(eW);LXo=r(ojt,"FlavaForPreTraining"),ojt.forEach(t),yXo=r(OOe," (FLAVA model)"),OOe.forEach(t),xXo=i(V),hb=n(V,"LI",{});var VOe=s(hb);ave=n(VOe,"STRONG",{});var rjt=s(ave);$Xo=r(rjt,"fnet"),rjt.forEach(t),kXo=r(VOe," \u2014 "),oW=n(VOe,"A",{href:!0});var tjt=s(oW);SXo=r(tjt,"FNetForPreTraining"),tjt.forEach(t),RXo=r(VOe," (FNet model)"),VOe.forEach(t),PXo=i(V),ub=n(V,"LI",{});var XOe=s(ub);nve=n(XOe,"STRONG",{});var ajt=s(nve);BXo=r(ajt,"fsmt"),ajt.forEach(t),IXo=r(XOe," \u2014 "),rW=n(XOe,"A",{href:!0});var njt=s(rW);NXo=r(njt,"FSMTForConditionalGeneration"),njt.forEach(t),qXo=r(XOe," (FairSeq Machine-Translation model)"),XOe.forEach(t),jXo=i(V),pb=n(V,"LI",{});var zOe=s(pb);sve=n(zOe,"STRONG",{});var sjt=s(sve);DXo=r(sjt,"funnel"),sjt.forEach(t),GXo=r(zOe," \u2014 "),tW=n(zOe,"A",{href:!0});var ljt=s(tW);OXo=r(ljt,"FunnelForPreTraining"),ljt.forEach(t),VXo=r(zOe," (Funnel Transformer model)"),zOe.forEach(t),XXo=i(V),_b=n(V,"LI",{});var QOe=s(_b);lve=n(QOe,"STRONG",{});var ijt=s(lve);zXo=r(ijt,"gpt2"),ijt.forEach(t),QXo=r(QOe," \u2014 "),aW=n(QOe,"A",{href:!0});var djt=s(aW);WXo=r(djt,"GPT2LMHeadModel"),djt.forEach(t),UXo=r(QOe," (OpenAI GPT-2 model)"),QOe.forEach(t),HXo=i(V),bb=n(V,"LI",{});var WOe=s(bb);ive=n(WOe,"STRONG",{});var cjt=s(ive);JXo=r(cjt,"ibert"),cjt.forEach(t),YXo=r(WOe," \u2014 "),nW=n(WOe,"A",{href:!0});var mjt=s(nW);ZXo=r(mjt,"IBertForMaskedLM"),mjt.forEach(t),KXo=r(WOe," (I-BERT model)"),WOe.forEach(t),ezo=i(V),vb=n(V,"LI",{});var UOe=s(vb);dve=n(UOe,"STRONG",{});var fjt=s(dve);ozo=r(fjt,"layoutlm"),fjt.forEach(t),rzo=r(UOe," \u2014 "),sW=n(UOe,"A",{href:!0});var gjt=s(sW);tzo=r(gjt,"LayoutLMForMaskedLM"),gjt.forEach(t),azo=r(UOe," (LayoutLM model)"),UOe.forEach(t),nzo=i(V),Fb=n(V,"LI",{});var HOe=s(Fb);cve=n(HOe,"STRONG",{});var hjt=s(cve);szo=r(hjt,"longformer"),hjt.forEach(t),lzo=r(HOe," \u2014 "),lW=n(HOe,"A",{href:!0});var ujt=s(lW);izo=r(ujt,"LongformerForMaskedLM"),ujt.forEach(t),dzo=r(HOe," (Longformer model)"),HOe.forEach(t),czo=i(V),Tb=n(V,"LI",{});var JOe=s(Tb);mve=n(JOe,"STRONG",{});var pjt=s(mve);mzo=r(pjt,"luke"),pjt.forEach(t),fzo=r(JOe," \u2014 "),iW=n(JOe,"A",{href:!0});var _jt=s(iW);gzo=r(_jt,"LukeForMaskedLM"),_jt.forEach(t),hzo=r(JOe," (LUKE model)"),JOe.forEach(t),uzo=i(V),Mb=n(V,"LI",{});var YOe=s(Mb);fve=n(YOe,"STRONG",{});var bjt=s(fve);pzo=r(bjt,"lxmert"),bjt.forEach(t),_zo=r(YOe," \u2014 "),dW=n(YOe,"A",{href:!0});var vjt=s(dW);bzo=r(vjt,"LxmertForPreTraining"),vjt.forEach(t),vzo=r(YOe," (LXMERT model)"),YOe.forEach(t),Fzo=i(V),Eb=n(V,"LI",{});var ZOe=s(Eb);gve=n(ZOe,"STRONG",{});var Fjt=s(gve);Tzo=r(Fjt,"megatron-bert"),Fjt.forEach(t),Mzo=r(ZOe," \u2014 "),cW=n(ZOe,"A",{href:!0});var Tjt=s(cW);Ezo=r(Tjt,"MegatronBertForPreTraining"),Tjt.forEach(t),Czo=r(ZOe," (Megatron-BERT model)"),ZOe.forEach(t),wzo=i(V),Cb=n(V,"LI",{});var KOe=s(Cb);hve=n(KOe,"STRONG",{});var Mjt=s(hve);Azo=r(Mjt,"mobilebert"),Mjt.forEach(t),Lzo=r(KOe," \u2014 "),mW=n(KOe,"A",{href:!0});var Ejt=s(mW);yzo=r(Ejt,"MobileBertForPreTraining"),Ejt.forEach(t),xzo=r(KOe," (MobileBERT model)"),KOe.forEach(t),$zo=i(V),wb=n(V,"LI",{});var eVe=s(wb);uve=n(eVe,"STRONG",{});var Cjt=s(uve);kzo=r(Cjt,"mpnet"),Cjt.forEach(t),Szo=r(eVe," \u2014 "),fW=n(eVe,"A",{href:!0});var wjt=s(fW);Rzo=r(wjt,"MPNetForMaskedLM"),wjt.forEach(t),Pzo=r(eVe," (MPNet model)"),eVe.forEach(t),Bzo=i(V),Ab=n(V,"LI",{});var oVe=s(Ab);pve=n(oVe,"STRONG",{});var Ajt=s(pve);Izo=r(Ajt,"mvp"),Ajt.forEach(t),Nzo=r(oVe," \u2014 "),gW=n(oVe,"A",{href:!0});var Ljt=s(gW);qzo=r(Ljt,"MvpForConditionalGeneration"),Ljt.forEach(t),jzo=r(oVe," (MVP model)"),oVe.forEach(t),Dzo=i(V),Lb=n(V,"LI",{});var rVe=s(Lb);_ve=n(rVe,"STRONG",{});var yjt=s(_ve);Gzo=r(yjt,"nezha"),yjt.forEach(t),Ozo=r(rVe," \u2014 "),hW=n(rVe,"A",{href:!0});var xjt=s(hW);Vzo=r(xjt,"NezhaForPreTraining"),xjt.forEach(t),Xzo=r(rVe," (Nezha model)"),rVe.forEach(t),zzo=i(V),yb=n(V,"LI",{});var tVe=s(yb);bve=n(tVe,"STRONG",{});var $jt=s(bve);Qzo=r($jt,"openai-gpt"),$jt.forEach(t),Wzo=r(tVe," \u2014 "),uW=n(tVe,"A",{href:!0});var kjt=s(uW);Uzo=r(kjt,"OpenAIGPTLMHeadModel"),kjt.forEach(t),Hzo=r(tVe," (OpenAI GPT model)"),tVe.forEach(t),Jzo=i(V),xb=n(V,"LI",{});var aVe=s(xb);vve=n(aVe,"STRONG",{});var Sjt=s(vve);Yzo=r(Sjt,"retribert"),Sjt.forEach(t),Zzo=r(aVe," \u2014 "),pW=n(aVe,"A",{href:!0});var Rjt=s(pW);Kzo=r(Rjt,"RetriBertModel"),Rjt.forEach(t),eQo=r(aVe," (RetriBERT model)"),aVe.forEach(t),oQo=i(V),$b=n(V,"LI",{});var nVe=s($b);Fve=n(nVe,"STRONG",{});var Pjt=s(Fve);rQo=r(Pjt,"roberta"),Pjt.forEach(t),tQo=r(nVe," \u2014 "),_W=n(nVe,"A",{href:!0});var Bjt=s(_W);aQo=r(Bjt,"RobertaForMaskedLM"),Bjt.forEach(t),nQo=r(nVe," (RoBERTa model)"),nVe.forEach(t),sQo=i(V),kb=n(V,"LI",{});var sVe=s(kb);Tve=n(sVe,"STRONG",{});var Ijt=s(Tve);lQo=r(Ijt,"splinter"),Ijt.forEach(t),iQo=r(sVe," \u2014 "),bW=n(sVe,"A",{href:!0});var Njt=s(bW);dQo=r(Njt,"SplinterForPreTraining"),Njt.forEach(t),cQo=r(sVe," (Splinter model)"),sVe.forEach(t),mQo=i(V),Sb=n(V,"LI",{});var lVe=s(Sb);Mve=n(lVe,"STRONG",{});var qjt=s(Mve);fQo=r(qjt,"squeezebert"),qjt.forEach(t),gQo=r(lVe," \u2014 "),vW=n(lVe,"A",{href:!0});var jjt=s(vW);hQo=r(jjt,"SqueezeBertForMaskedLM"),jjt.forEach(t),uQo=r(lVe," (SqueezeBERT model)"),lVe.forEach(t),pQo=i(V),Rb=n(V,"LI",{});var iVe=s(Rb);Eve=n(iVe,"STRONG",{});var Djt=s(Eve);_Qo=r(Djt,"t5"),Djt.forEach(t),bQo=r(iVe," \u2014 "),FW=n(iVe,"A",{href:!0});var Gjt=s(FW);vQo=r(Gjt,"T5ForConditionalGeneration"),Gjt.forEach(t),FQo=r(iVe," (T5 model)"),iVe.forEach(t),TQo=i(V),Pb=n(V,"LI",{});var dVe=s(Pb);Cve=n(dVe,"STRONG",{});var Ojt=s(Cve);MQo=r(Ojt,"tapas"),Ojt.forEach(t),EQo=r(dVe," \u2014 "),TW=n(dVe,"A",{href:!0});var Vjt=s(TW);CQo=r(Vjt,"TapasForMaskedLM"),Vjt.forEach(t),wQo=r(dVe," (TAPAS model)"),dVe.forEach(t),AQo=i(V),Bb=n(V,"LI",{});var cVe=s(Bb);wve=n(cVe,"STRONG",{});var Xjt=s(wve);LQo=r(Xjt,"transfo-xl"),Xjt.forEach(t),yQo=r(cVe," \u2014 "),MW=n(cVe,"A",{href:!0});var zjt=s(MW);xQo=r(zjt,"TransfoXLLMHeadModel"),zjt.forEach(t),$Qo=r(cVe," (Transformer-XL model)"),cVe.forEach(t),kQo=i(V),Ib=n(V,"LI",{});var mVe=s(Ib);Ave=n(mVe,"STRONG",{});var Qjt=s(Ave);SQo=r(Qjt,"unispeech"),Qjt.forEach(t),RQo=r(mVe," \u2014 "),EW=n(mVe,"A",{href:!0});var Wjt=s(EW);PQo=r(Wjt,"UniSpeechForPreTraining"),Wjt.forEach(t),BQo=r(mVe," (UniSpeech model)"),mVe.forEach(t),IQo=i(V),Nb=n(V,"LI",{});var fVe=s(Nb);Lve=n(fVe,"STRONG",{});var Ujt=s(Lve);NQo=r(Ujt,"unispeech-sat"),Ujt.forEach(t),qQo=r(fVe," \u2014 "),CW=n(fVe,"A",{href:!0});var Hjt=s(CW);jQo=r(Hjt,"UniSpeechSatForPreTraining"),Hjt.forEach(t),DQo=r(fVe," (UniSpeechSat model)"),fVe.forEach(t),GQo=i(V),qb=n(V,"LI",{});var gVe=s(qb);yve=n(gVe,"STRONG",{});var Jjt=s(yve);OQo=r(Jjt,"videomae"),Jjt.forEach(t),VQo=r(gVe," \u2014 "),wW=n(gVe,"A",{href:!0});var Yjt=s(wW);XQo=r(Yjt,"VideoMAEForPreTraining"),Yjt.forEach(t),zQo=r(gVe," (VideoMAE model)"),gVe.forEach(t),QQo=i(V),jb=n(V,"LI",{});var hVe=s(jb);xve=n(hVe,"STRONG",{});var Zjt=s(xve);WQo=r(Zjt,"visual_bert"),Zjt.forEach(t),UQo=r(hVe," \u2014 "),AW=n(hVe,"A",{href:!0});var Kjt=s(AW);HQo=r(Kjt,"VisualBertForPreTraining"),Kjt.forEach(t),JQo=r(hVe," (VisualBERT model)"),hVe.forEach(t),YQo=i(V),Db=n(V,"LI",{});var uVe=s(Db);$ve=n(uVe,"STRONG",{});var eDt=s($ve);ZQo=r(eDt,"vit_mae"),eDt.forEach(t),KQo=r(uVe," \u2014 "),LW=n(uVe,"A",{href:!0});var oDt=s(LW);eWo=r(oDt,"ViTMAEForPreTraining"),oDt.forEach(t),oWo=r(uVe," (ViTMAE model)"),uVe.forEach(t),rWo=i(V),Gb=n(V,"LI",{});var pVe=s(Gb);kve=n(pVe,"STRONG",{});var rDt=s(kve);tWo=r(rDt,"wav2vec2"),rDt.forEach(t),aWo=r(pVe," \u2014 "),yW=n(pVe,"A",{href:!0});var tDt=s(yW);nWo=r(tDt,"Wav2Vec2ForPreTraining"),tDt.forEach(t),sWo=r(pVe," (Wav2Vec2 model)"),pVe.forEach(t),lWo=i(V),Ob=n(V,"LI",{});var _Ve=s(Ob);Sve=n(_Ve,"STRONG",{});var aDt=s(Sve);iWo=r(aDt,"wav2vec2-conformer"),aDt.forEach(t),dWo=r(_Ve," \u2014 "),xW=n(_Ve,"A",{href:!0});var nDt=s(xW);cWo=r(nDt,"Wav2Vec2ConformerForPreTraining"),nDt.forEach(t),mWo=r(_Ve," (Wav2Vec2-Conformer model)"),_Ve.forEach(t),fWo=i(V),Vb=n(V,"LI",{});var bVe=s(Vb);Rve=n(bVe,"STRONG",{});var sDt=s(Rve);gWo=r(sDt,"xlm"),sDt.forEach(t),hWo=r(bVe," \u2014 "),$W=n(bVe,"A",{href:!0});var lDt=s($W);uWo=r(lDt,"XLMWithLMHeadModel"),lDt.forEach(t),pWo=r(bVe," (XLM model)"),bVe.forEach(t),_Wo=i(V),Xb=n(V,"LI",{});var vVe=s(Xb);Pve=n(vVe,"STRONG",{});var iDt=s(Pve);bWo=r(iDt,"xlm-roberta"),iDt.forEach(t),vWo=r(vVe," \u2014 "),kW=n(vVe,"A",{href:!0});var dDt=s(kW);FWo=r(dDt,"XLMRobertaForMaskedLM"),dDt.forEach(t),TWo=r(vVe," (XLM-RoBERTa model)"),vVe.forEach(t),MWo=i(V),zb=n(V,"LI",{});var FVe=s(zb);Bve=n(FVe,"STRONG",{});var cDt=s(Bve);EWo=r(cDt,"xlm-roberta-xl"),cDt.forEach(t),CWo=r(FVe," \u2014 "),SW=n(FVe,"A",{href:!0});var mDt=s(SW);wWo=r(mDt,"XLMRobertaXLForMaskedLM"),mDt.forEach(t),AWo=r(FVe," (XLM-RoBERTa-XL model)"),FVe.forEach(t),LWo=i(V),Qb=n(V,"LI",{});var TVe=s(Qb);Ive=n(TVe,"STRONG",{});var fDt=s(Ive);yWo=r(fDt,"xlnet"),fDt.forEach(t),xWo=r(TVe," \u2014 "),RW=n(TVe,"A",{href:!0});var gDt=s(RW);$Wo=r(gDt,"XLNetLMHeadModel"),gDt.forEach(t),kWo=r(TVe," (XLNet model)"),TVe.forEach(t),V.forEach(t),SWo=i(La),Wb=n(La,"P",{});var MVe=s(Wb);RWo=r(MVe,"The model is set in evaluation mode by default using "),Nve=n(MVe,"CODE",{});var hDt=s(Nve);PWo=r(hDt,"model.eval()"),hDt.forEach(t),BWo=r(MVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qve=n(MVe,"CODE",{});var uDt=s(qve);IWo=r(uDt,"model.train()"),uDt.forEach(t),MVe.forEach(t),NWo=i(La),T(Ub.$$.fragment,La),La.forEach(t),ql.forEach(t),nto=i(m),Id=n(m,"H2",{class:!0});var Eno=s(Id);Hb=n(Eno,"A",{id:!0,class:!0,href:!0});var pDt=s(Hb);jve=n(pDt,"SPAN",{});var _Dt=s(jve);T(I$.$$.fragment,_Dt),_Dt.forEach(t),pDt.forEach(t),qWo=i(Eno),Dve=n(Eno,"SPAN",{});var bDt=s(Dve);jWo=r(bDt,"AutoModelForCausalLM"),bDt.forEach(t),Eno.forEach(t),sto=i(m),qo=n(m,"DIV",{class:!0});var jl=s(qo);T(N$.$$.fragment,jl),DWo=i(jl),Nd=n(jl,"P",{});var Ode=s(Nd);GWo=r(Ode,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),PW=n(Ode,"A",{href:!0});var vDt=s(PW);OWo=r(vDt,"from_pretrained()"),vDt.forEach(t),VWo=r(Ode," class method or the "),BW=n(Ode,"A",{href:!0});var FDt=s(BW);XWo=r(FDt,"from_config()"),FDt.forEach(t),zWo=r(Ode,` class
method.`),Ode.forEach(t),QWo=i(jl),q$=n(jl,"P",{});var Cno=s(q$);WWo=r(Cno,"This class cannot be instantiated directly using "),Gve=n(Cno,"CODE",{});var TDt=s(Gve);UWo=r(TDt,"__init__()"),TDt.forEach(t),HWo=r(Cno," (throws an error)."),Cno.forEach(t),JWo=i(jl),Et=n(jl,"DIV",{class:!0});var Uy=s(Et);T(j$.$$.fragment,Uy),YWo=i(Uy),Ove=n(Uy,"P",{});var MDt=s(Ove);ZWo=r(MDt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),MDt.forEach(t),KWo=i(Uy),qd=n(Uy,"P",{});var Vde=s(qd);eUo=r(Vde,`Note:
Loading a model from its configuration file does `),Vve=n(Vde,"STRONG",{});var EDt=s(Vve);oUo=r(EDt,"not"),EDt.forEach(t),rUo=r(Vde,` load the model weights. It only affects the
model\u2019s configuration. Use `),IW=n(Vde,"A",{href:!0});var CDt=s(IW);tUo=r(CDt,"from_pretrained()"),CDt.forEach(t),aUo=r(Vde," to load the model weights."),Vde.forEach(t),nUo=i(Uy),T(Jb.$$.fragment,Uy),Uy.forEach(t),sUo=i(jl),oo=n(jl,"DIV",{class:!0});var ya=s(oo);T(D$.$$.fragment,ya),lUo=i(ya),Xve=n(ya,"P",{});var wDt=s(Xve);iUo=r(wDt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),wDt.forEach(t),dUo=i(ya),sn=n(ya,"P",{});var Hy=s(sn);cUo=r(Hy,"The model class to instantiate is selected based on the "),zve=n(Hy,"CODE",{});var ADt=s(zve);mUo=r(ADt,"model_type"),ADt.forEach(t),fUo=r(Hy,` property of the config object (either
passed as an argument or loaded from `),Qve=n(Hy,"CODE",{});var LDt=s(Qve);gUo=r(LDt,"pretrained_model_name_or_path"),LDt.forEach(t),hUo=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=n(Hy,"CODE",{});var yDt=s(Wve);uUo=r(yDt,"pretrained_model_name_or_path"),yDt.forEach(t),pUo=r(Hy,":"),Hy.forEach(t),_Uo=i(ya),Q=n(ya,"UL",{});var H=s(Q);Yb=n(H,"LI",{});var EVe=s(Yb);Uve=n(EVe,"STRONG",{});var xDt=s(Uve);bUo=r(xDt,"bart"),xDt.forEach(t),vUo=r(EVe," \u2014 "),NW=n(EVe,"A",{href:!0});var $Dt=s(NW);FUo=r($Dt,"BartForCausalLM"),$Dt.forEach(t),TUo=r(EVe," (BART model)"),EVe.forEach(t),MUo=i(H),Zb=n(H,"LI",{});var CVe=s(Zb);Hve=n(CVe,"STRONG",{});var kDt=s(Hve);EUo=r(kDt,"bert"),kDt.forEach(t),CUo=r(CVe," \u2014 "),qW=n(CVe,"A",{href:!0});var SDt=s(qW);wUo=r(SDt,"BertLMHeadModel"),SDt.forEach(t),AUo=r(CVe," (BERT model)"),CVe.forEach(t),LUo=i(H),Kb=n(H,"LI",{});var wVe=s(Kb);Jve=n(wVe,"STRONG",{});var RDt=s(Jve);yUo=r(RDt,"bert-generation"),RDt.forEach(t),xUo=r(wVe," \u2014 "),jW=n(wVe,"A",{href:!0});var PDt=s(jW);$Uo=r(PDt,"BertGenerationDecoder"),PDt.forEach(t),kUo=r(wVe," (Bert Generation model)"),wVe.forEach(t),SUo=i(H),ev=n(H,"LI",{});var AVe=s(ev);Yve=n(AVe,"STRONG",{});var BDt=s(Yve);RUo=r(BDt,"big_bird"),BDt.forEach(t),PUo=r(AVe," \u2014 "),DW=n(AVe,"A",{href:!0});var IDt=s(DW);BUo=r(IDt,"BigBirdForCausalLM"),IDt.forEach(t),IUo=r(AVe," (BigBird model)"),AVe.forEach(t),NUo=i(H),ov=n(H,"LI",{});var LVe=s(ov);Zve=n(LVe,"STRONG",{});var NDt=s(Zve);qUo=r(NDt,"bigbird_pegasus"),NDt.forEach(t),jUo=r(LVe," \u2014 "),GW=n(LVe,"A",{href:!0});var qDt=s(GW);DUo=r(qDt,"BigBirdPegasusForCausalLM"),qDt.forEach(t),GUo=r(LVe," (BigBird-Pegasus model)"),LVe.forEach(t),OUo=i(H),rv=n(H,"LI",{});var yVe=s(rv);Kve=n(yVe,"STRONG",{});var jDt=s(Kve);VUo=r(jDt,"blenderbot"),jDt.forEach(t),XUo=r(yVe," \u2014 "),OW=n(yVe,"A",{href:!0});var DDt=s(OW);zUo=r(DDt,"BlenderbotForCausalLM"),DDt.forEach(t),QUo=r(yVe," (Blenderbot model)"),yVe.forEach(t),WUo=i(H),tv=n(H,"LI",{});var xVe=s(tv);eFe=n(xVe,"STRONG",{});var GDt=s(eFe);UUo=r(GDt,"blenderbot-small"),GDt.forEach(t),HUo=r(xVe," \u2014 "),VW=n(xVe,"A",{href:!0});var ODt=s(VW);JUo=r(ODt,"BlenderbotSmallForCausalLM"),ODt.forEach(t),YUo=r(xVe," (BlenderbotSmall model)"),xVe.forEach(t),ZUo=i(H),av=n(H,"LI",{});var $Ve=s(av);oFe=n($Ve,"STRONG",{});var VDt=s(oFe);KUo=r(VDt,"bloom"),VDt.forEach(t),eHo=r($Ve," \u2014 "),XW=n($Ve,"A",{href:!0});var XDt=s(XW);oHo=r(XDt,"BloomForCausalLM"),XDt.forEach(t),rHo=r($Ve," (BLOOM model)"),$Ve.forEach(t),tHo=i(H),nv=n(H,"LI",{});var kVe=s(nv);rFe=n(kVe,"STRONG",{});var zDt=s(rFe);aHo=r(zDt,"camembert"),zDt.forEach(t),nHo=r(kVe," \u2014 "),zW=n(kVe,"A",{href:!0});var QDt=s(zW);sHo=r(QDt,"CamembertForCausalLM"),QDt.forEach(t),lHo=r(kVe," (CamemBERT model)"),kVe.forEach(t),iHo=i(H),sv=n(H,"LI",{});var SVe=s(sv);tFe=n(SVe,"STRONG",{});var WDt=s(tFe);dHo=r(WDt,"codegen"),WDt.forEach(t),cHo=r(SVe," \u2014 "),QW=n(SVe,"A",{href:!0});var UDt=s(QW);mHo=r(UDt,"CodeGenForCausalLM"),UDt.forEach(t),fHo=r(SVe," (CodeGen model)"),SVe.forEach(t),gHo=i(H),lv=n(H,"LI",{});var RVe=s(lv);aFe=n(RVe,"STRONG",{});var HDt=s(aFe);hHo=r(HDt,"ctrl"),HDt.forEach(t),uHo=r(RVe," \u2014 "),WW=n(RVe,"A",{href:!0});var JDt=s(WW);pHo=r(JDt,"CTRLLMHeadModel"),JDt.forEach(t),_Ho=r(RVe," (CTRL model)"),RVe.forEach(t),bHo=i(H),iv=n(H,"LI",{});var PVe=s(iv);nFe=n(PVe,"STRONG",{});var YDt=s(nFe);vHo=r(YDt,"data2vec-text"),YDt.forEach(t),FHo=r(PVe," \u2014 "),UW=n(PVe,"A",{href:!0});var ZDt=s(UW);THo=r(ZDt,"Data2VecTextForCausalLM"),ZDt.forEach(t),MHo=r(PVe," (Data2VecText model)"),PVe.forEach(t),EHo=i(H),dv=n(H,"LI",{});var BVe=s(dv);sFe=n(BVe,"STRONG",{});var KDt=s(sFe);CHo=r(KDt,"electra"),KDt.forEach(t),wHo=r(BVe," \u2014 "),HW=n(BVe,"A",{href:!0});var eGt=s(HW);AHo=r(eGt,"ElectraForCausalLM"),eGt.forEach(t),LHo=r(BVe," (ELECTRA model)"),BVe.forEach(t),yHo=i(H),cv=n(H,"LI",{});var IVe=s(cv);lFe=n(IVe,"STRONG",{});var oGt=s(lFe);xHo=r(oGt,"ernie"),oGt.forEach(t),$Ho=r(IVe," \u2014 "),JW=n(IVe,"A",{href:!0});var rGt=s(JW);kHo=r(rGt,"ErnieForCausalLM"),rGt.forEach(t),SHo=r(IVe," (ERNIE model)"),IVe.forEach(t),RHo=i(H),mv=n(H,"LI",{});var NVe=s(mv);iFe=n(NVe,"STRONG",{});var tGt=s(iFe);PHo=r(tGt,"gpt2"),tGt.forEach(t),BHo=r(NVe," \u2014 "),YW=n(NVe,"A",{href:!0});var aGt=s(YW);IHo=r(aGt,"GPT2LMHeadModel"),aGt.forEach(t),NHo=r(NVe," (OpenAI GPT-2 model)"),NVe.forEach(t),qHo=i(H),fv=n(H,"LI",{});var qVe=s(fv);dFe=n(qVe,"STRONG",{});var nGt=s(dFe);jHo=r(nGt,"gpt_neo"),nGt.forEach(t),DHo=r(qVe," \u2014 "),ZW=n(qVe,"A",{href:!0});var sGt=s(ZW);GHo=r(sGt,"GPTNeoForCausalLM"),sGt.forEach(t),OHo=r(qVe," (GPT Neo model)"),qVe.forEach(t),VHo=i(H),gv=n(H,"LI",{});var jVe=s(gv);cFe=n(jVe,"STRONG",{});var lGt=s(cFe);XHo=r(lGt,"gpt_neox"),lGt.forEach(t),zHo=r(jVe," \u2014 "),KW=n(jVe,"A",{href:!0});var iGt=s(KW);QHo=r(iGt,"GPTNeoXForCausalLM"),iGt.forEach(t),WHo=r(jVe," (GPT NeoX model)"),jVe.forEach(t),UHo=i(H),hv=n(H,"LI",{});var DVe=s(hv);mFe=n(DVe,"STRONG",{});var dGt=s(mFe);HHo=r(dGt,"gpt_neox_japanese"),dGt.forEach(t),JHo=r(DVe," \u2014 "),eU=n(DVe,"A",{href:!0});var cGt=s(eU);YHo=r(cGt,"GPTNeoXJapaneseForCausalLM"),cGt.forEach(t),ZHo=r(DVe," (GPT NeoX Japanese model)"),DVe.forEach(t),KHo=i(H),uv=n(H,"LI",{});var GVe=s(uv);fFe=n(GVe,"STRONG",{});var mGt=s(fFe);eJo=r(mGt,"gptj"),mGt.forEach(t),oJo=r(GVe," \u2014 "),oU=n(GVe,"A",{href:!0});var fGt=s(oU);rJo=r(fGt,"GPTJForCausalLM"),fGt.forEach(t),tJo=r(GVe," (GPT-J model)"),GVe.forEach(t),aJo=i(H),pv=n(H,"LI",{});var OVe=s(pv);gFe=n(OVe,"STRONG",{});var gGt=s(gFe);nJo=r(gGt,"marian"),gGt.forEach(t),sJo=r(OVe," \u2014 "),rU=n(OVe,"A",{href:!0});var hGt=s(rU);lJo=r(hGt,"MarianForCausalLM"),hGt.forEach(t),iJo=r(OVe," (Marian model)"),OVe.forEach(t),dJo=i(H),_v=n(H,"LI",{});var VVe=s(_v);hFe=n(VVe,"STRONG",{});var uGt=s(hFe);cJo=r(uGt,"mbart"),uGt.forEach(t),mJo=r(VVe," \u2014 "),tU=n(VVe,"A",{href:!0});var pGt=s(tU);fJo=r(pGt,"MBartForCausalLM"),pGt.forEach(t),gJo=r(VVe," (mBART model)"),VVe.forEach(t),hJo=i(H),bv=n(H,"LI",{});var XVe=s(bv);uFe=n(XVe,"STRONG",{});var _Gt=s(uFe);uJo=r(_Gt,"megatron-bert"),_Gt.forEach(t),pJo=r(XVe," \u2014 "),aU=n(XVe,"A",{href:!0});var bGt=s(aU);_Jo=r(bGt,"MegatronBertForCausalLM"),bGt.forEach(t),bJo=r(XVe," (Megatron-BERT model)"),XVe.forEach(t),vJo=i(H),vv=n(H,"LI",{});var zVe=s(vv);pFe=n(zVe,"STRONG",{});var vGt=s(pFe);FJo=r(vGt,"mvp"),vGt.forEach(t),TJo=r(zVe," \u2014 "),nU=n(zVe,"A",{href:!0});var FGt=s(nU);MJo=r(FGt,"MvpForCausalLM"),FGt.forEach(t),EJo=r(zVe," (MVP model)"),zVe.forEach(t),CJo=i(H),Fv=n(H,"LI",{});var QVe=s(Fv);_Fe=n(QVe,"STRONG",{});var TGt=s(_Fe);wJo=r(TGt,"openai-gpt"),TGt.forEach(t),AJo=r(QVe," \u2014 "),sU=n(QVe,"A",{href:!0});var MGt=s(sU);LJo=r(MGt,"OpenAIGPTLMHeadModel"),MGt.forEach(t),yJo=r(QVe," (OpenAI GPT model)"),QVe.forEach(t),xJo=i(H),Tv=n(H,"LI",{});var WVe=s(Tv);bFe=n(WVe,"STRONG",{});var EGt=s(bFe);$Jo=r(EGt,"opt"),EGt.forEach(t),kJo=r(WVe," \u2014 "),lU=n(WVe,"A",{href:!0});var CGt=s(lU);SJo=r(CGt,"OPTForCausalLM"),CGt.forEach(t),RJo=r(WVe," (OPT model)"),WVe.forEach(t),PJo=i(H),Mv=n(H,"LI",{});var UVe=s(Mv);vFe=n(UVe,"STRONG",{});var wGt=s(vFe);BJo=r(wGt,"pegasus"),wGt.forEach(t),IJo=r(UVe," \u2014 "),iU=n(UVe,"A",{href:!0});var AGt=s(iU);NJo=r(AGt,"PegasusForCausalLM"),AGt.forEach(t),qJo=r(UVe," (Pegasus model)"),UVe.forEach(t),jJo=i(H),Ev=n(H,"LI",{});var HVe=s(Ev);FFe=n(HVe,"STRONG",{});var LGt=s(FFe);DJo=r(LGt,"plbart"),LGt.forEach(t),GJo=r(HVe," \u2014 "),dU=n(HVe,"A",{href:!0});var yGt=s(dU);OJo=r(yGt,"PLBartForCausalLM"),yGt.forEach(t),VJo=r(HVe," (PLBart model)"),HVe.forEach(t),XJo=i(H),Cv=n(H,"LI",{});var JVe=s(Cv);TFe=n(JVe,"STRONG",{});var xGt=s(TFe);zJo=r(xGt,"prophetnet"),xGt.forEach(t),QJo=r(JVe," \u2014 "),cU=n(JVe,"A",{href:!0});var $Gt=s(cU);WJo=r($Gt,"ProphetNetForCausalLM"),$Gt.forEach(t),UJo=r(JVe," (ProphetNet model)"),JVe.forEach(t),HJo=i(H),wv=n(H,"LI",{});var YVe=s(wv);MFe=n(YVe,"STRONG",{});var kGt=s(MFe);JJo=r(kGt,"qdqbert"),kGt.forEach(t),YJo=r(YVe," \u2014 "),mU=n(YVe,"A",{href:!0});var SGt=s(mU);ZJo=r(SGt,"QDQBertLMHeadModel"),SGt.forEach(t),KJo=r(YVe," (QDQBert model)"),YVe.forEach(t),eYo=i(H),Av=n(H,"LI",{});var ZVe=s(Av);EFe=n(ZVe,"STRONG",{});var RGt=s(EFe);oYo=r(RGt,"reformer"),RGt.forEach(t),rYo=r(ZVe," \u2014 "),fU=n(ZVe,"A",{href:!0});var PGt=s(fU);tYo=r(PGt,"ReformerModelWithLMHead"),PGt.forEach(t),aYo=r(ZVe," (Reformer model)"),ZVe.forEach(t),nYo=i(H),Lv=n(H,"LI",{});var KVe=s(Lv);CFe=n(KVe,"STRONG",{});var BGt=s(CFe);sYo=r(BGt,"rembert"),BGt.forEach(t),lYo=r(KVe," \u2014 "),gU=n(KVe,"A",{href:!0});var IGt=s(gU);iYo=r(IGt,"RemBertForCausalLM"),IGt.forEach(t),dYo=r(KVe," (RemBERT model)"),KVe.forEach(t),cYo=i(H),yv=n(H,"LI",{});var eXe=s(yv);wFe=n(eXe,"STRONG",{});var NGt=s(wFe);mYo=r(NGt,"roberta"),NGt.forEach(t),fYo=r(eXe," \u2014 "),hU=n(eXe,"A",{href:!0});var qGt=s(hU);gYo=r(qGt,"RobertaForCausalLM"),qGt.forEach(t),hYo=r(eXe," (RoBERTa model)"),eXe.forEach(t),uYo=i(H),xv=n(H,"LI",{});var oXe=s(xv);AFe=n(oXe,"STRONG",{});var jGt=s(AFe);pYo=r(jGt,"roformer"),jGt.forEach(t),_Yo=r(oXe," \u2014 "),uU=n(oXe,"A",{href:!0});var DGt=s(uU);bYo=r(DGt,"RoFormerForCausalLM"),DGt.forEach(t),vYo=r(oXe," (RoFormer model)"),oXe.forEach(t),FYo=i(H),$v=n(H,"LI",{});var rXe=s($v);LFe=n(rXe,"STRONG",{});var GGt=s(LFe);TYo=r(GGt,"speech_to_text_2"),GGt.forEach(t),MYo=r(rXe," \u2014 "),pU=n(rXe,"A",{href:!0});var OGt=s(pU);EYo=r(OGt,"Speech2Text2ForCausalLM"),OGt.forEach(t),CYo=r(rXe," (Speech2Text2 model)"),rXe.forEach(t),wYo=i(H),kv=n(H,"LI",{});var tXe=s(kv);yFe=n(tXe,"STRONG",{});var VGt=s(yFe);AYo=r(VGt,"transfo-xl"),VGt.forEach(t),LYo=r(tXe," \u2014 "),_U=n(tXe,"A",{href:!0});var XGt=s(_U);yYo=r(XGt,"TransfoXLLMHeadModel"),XGt.forEach(t),xYo=r(tXe," (Transformer-XL model)"),tXe.forEach(t),$Yo=i(H),Sv=n(H,"LI",{});var aXe=s(Sv);xFe=n(aXe,"STRONG",{});var zGt=s(xFe);kYo=r(zGt,"trocr"),zGt.forEach(t),SYo=r(aXe," \u2014 "),bU=n(aXe,"A",{href:!0});var QGt=s(bU);RYo=r(QGt,"TrOCRForCausalLM"),QGt.forEach(t),PYo=r(aXe," (TrOCR model)"),aXe.forEach(t),BYo=i(H),Rv=n(H,"LI",{});var nXe=s(Rv);$Fe=n(nXe,"STRONG",{});var WGt=s($Fe);IYo=r(WGt,"xglm"),WGt.forEach(t),NYo=r(nXe," \u2014 "),vU=n(nXe,"A",{href:!0});var UGt=s(vU);qYo=r(UGt,"XGLMForCausalLM"),UGt.forEach(t),jYo=r(nXe," (XGLM model)"),nXe.forEach(t),DYo=i(H),Pv=n(H,"LI",{});var sXe=s(Pv);kFe=n(sXe,"STRONG",{});var HGt=s(kFe);GYo=r(HGt,"xlm"),HGt.forEach(t),OYo=r(sXe," \u2014 "),FU=n(sXe,"A",{href:!0});var JGt=s(FU);VYo=r(JGt,"XLMWithLMHeadModel"),JGt.forEach(t),XYo=r(sXe," (XLM model)"),sXe.forEach(t),zYo=i(H),Bv=n(H,"LI",{});var lXe=s(Bv);SFe=n(lXe,"STRONG",{});var YGt=s(SFe);QYo=r(YGt,"xlm-prophetnet"),YGt.forEach(t),WYo=r(lXe," \u2014 "),TU=n(lXe,"A",{href:!0});var ZGt=s(TU);UYo=r(ZGt,"XLMProphetNetForCausalLM"),ZGt.forEach(t),HYo=r(lXe," (XLM-ProphetNet model)"),lXe.forEach(t),JYo=i(H),Iv=n(H,"LI",{});var iXe=s(Iv);RFe=n(iXe,"STRONG",{});var KGt=s(RFe);YYo=r(KGt,"xlm-roberta"),KGt.forEach(t),ZYo=r(iXe," \u2014 "),MU=n(iXe,"A",{href:!0});var eOt=s(MU);KYo=r(eOt,"XLMRobertaForCausalLM"),eOt.forEach(t),eZo=r(iXe," (XLM-RoBERTa model)"),iXe.forEach(t),oZo=i(H),Nv=n(H,"LI",{});var dXe=s(Nv);PFe=n(dXe,"STRONG",{});var oOt=s(PFe);rZo=r(oOt,"xlm-roberta-xl"),oOt.forEach(t),tZo=r(dXe," \u2014 "),EU=n(dXe,"A",{href:!0});var rOt=s(EU);aZo=r(rOt,"XLMRobertaXLForCausalLM"),rOt.forEach(t),nZo=r(dXe," (XLM-RoBERTa-XL model)"),dXe.forEach(t),sZo=i(H),qv=n(H,"LI",{});var cXe=s(qv);BFe=n(cXe,"STRONG",{});var tOt=s(BFe);lZo=r(tOt,"xlnet"),tOt.forEach(t),iZo=r(cXe," \u2014 "),CU=n(cXe,"A",{href:!0});var aOt=s(CU);dZo=r(aOt,"XLNetLMHeadModel"),aOt.forEach(t),cZo=r(cXe," (XLNet model)"),cXe.forEach(t),H.forEach(t),mZo=i(ya),jv=n(ya,"P",{});var mXe=s(jv);fZo=r(mXe,"The model is set in evaluation mode by default using "),IFe=n(mXe,"CODE",{});var nOt=s(IFe);gZo=r(nOt,"model.eval()"),nOt.forEach(t),hZo=r(mXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NFe=n(mXe,"CODE",{});var sOt=s(NFe);uZo=r(sOt,"model.train()"),sOt.forEach(t),mXe.forEach(t),pZo=i(ya),T(Dv.$$.fragment,ya),ya.forEach(t),jl.forEach(t),lto=i(m),jd=n(m,"H2",{class:!0});var wno=s(jd);Gv=n(wno,"A",{id:!0,class:!0,href:!0});var lOt=s(Gv);qFe=n(lOt,"SPAN",{});var iOt=s(qFe);T(G$.$$.fragment,iOt),iOt.forEach(t),lOt.forEach(t),_Zo=i(wno),jFe=n(wno,"SPAN",{});var dOt=s(jFe);bZo=r(dOt,"AutoModelForDepthEstimation"),dOt.forEach(t),wno.forEach(t),ito=i(m),jo=n(m,"DIV",{class:!0});var Dl=s(jo);T(O$.$$.fragment,Dl),vZo=i(Dl),Dd=n(Dl,"P",{});var Xde=s(Dd);FZo=r(Xde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),wU=n(Xde,"A",{href:!0});var cOt=s(wU);TZo=r(cOt,"from_pretrained()"),cOt.forEach(t),MZo=r(Xde," class method or the "),AU=n(Xde,"A",{href:!0});var mOt=s(AU);EZo=r(mOt,"from_config()"),mOt.forEach(t),CZo=r(Xde,` class
method.`),Xde.forEach(t),wZo=i(Dl),V$=n(Dl,"P",{});var Ano=s(V$);AZo=r(Ano,"This class cannot be instantiated directly using "),DFe=n(Ano,"CODE",{});var fOt=s(DFe);LZo=r(fOt,"__init__()"),fOt.forEach(t),yZo=r(Ano," (throws an error)."),Ano.forEach(t),xZo=i(Dl),Ct=n(Dl,"DIV",{class:!0});var Jy=s(Ct);T(X$.$$.fragment,Jy),$Zo=i(Jy),GFe=n(Jy,"P",{});var gOt=s(GFe);kZo=r(gOt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),gOt.forEach(t),SZo=i(Jy),Gd=n(Jy,"P",{});var zde=s(Gd);RZo=r(zde,`Note:
Loading a model from its configuration file does `),OFe=n(zde,"STRONG",{});var hOt=s(OFe);PZo=r(hOt,"not"),hOt.forEach(t),BZo=r(zde,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(zde,"A",{href:!0});var uOt=s(LU);IZo=r(uOt,"from_pretrained()"),uOt.forEach(t),NZo=r(zde," to load the model weights."),zde.forEach(t),qZo=i(Jy),T(Ov.$$.fragment,Jy),Jy.forEach(t),jZo=i(Dl),ro=n(Dl,"DIV",{class:!0});var xa=s(ro);T(z$.$$.fragment,xa),DZo=i(xa),VFe=n(xa,"P",{});var pOt=s(VFe);GZo=r(pOt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),pOt.forEach(t),OZo=i(xa),ln=n(xa,"P",{});var Yy=s(ln);VZo=r(Yy,"The model class to instantiate is selected based on the "),XFe=n(Yy,"CODE",{});var _Ot=s(XFe);XZo=r(_Ot,"model_type"),_Ot.forEach(t),zZo=r(Yy,` property of the config object (either
passed as an argument or loaded from `),zFe=n(Yy,"CODE",{});var bOt=s(zFe);QZo=r(bOt,"pretrained_model_name_or_path"),bOt.forEach(t),WZo=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=n(Yy,"CODE",{});var vOt=s(QFe);UZo=r(vOt,"pretrained_model_name_or_path"),vOt.forEach(t),HZo=r(Yy,":"),Yy.forEach(t),JZo=i(xa),Q$=n(xa,"UL",{});var Lno=s(Q$);Vv=n(Lno,"LI",{});var fXe=s(Vv);WFe=n(fXe,"STRONG",{});var FOt=s(WFe);YZo=r(FOt,"dpt"),FOt.forEach(t),ZZo=r(fXe," \u2014 "),yU=n(fXe,"A",{href:!0});var TOt=s(yU);KZo=r(TOt,"DPTForDepthEstimation"),TOt.forEach(t),eKo=r(fXe," (DPT model)"),fXe.forEach(t),oKo=i(Lno),Xv=n(Lno,"LI",{});var gXe=s(Xv);UFe=n(gXe,"STRONG",{});var MOt=s(UFe);rKo=r(MOt,"glpn"),MOt.forEach(t),tKo=r(gXe," \u2014 "),xU=n(gXe,"A",{href:!0});var EOt=s(xU);aKo=r(EOt,"GLPNForDepthEstimation"),EOt.forEach(t),nKo=r(gXe," (GLPN model)"),gXe.forEach(t),Lno.forEach(t),sKo=i(xa),zv=n(xa,"P",{});var hXe=s(zv);lKo=r(hXe,"The model is set in evaluation mode by default using "),HFe=n(hXe,"CODE",{});var COt=s(HFe);iKo=r(COt,"model.eval()"),COt.forEach(t),dKo=r(hXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JFe=n(hXe,"CODE",{});var wOt=s(JFe);cKo=r(wOt,"model.train()"),wOt.forEach(t),hXe.forEach(t),mKo=i(xa),T(Qv.$$.fragment,xa),xa.forEach(t),Dl.forEach(t),dto=i(m),Od=n(m,"H2",{class:!0});var yno=s(Od);Wv=n(yno,"A",{id:!0,class:!0,href:!0});var AOt=s(Wv);YFe=n(AOt,"SPAN",{});var LOt=s(YFe);T(W$.$$.fragment,LOt),LOt.forEach(t),AOt.forEach(t),fKo=i(yno),ZFe=n(yno,"SPAN",{});var yOt=s(ZFe);gKo=r(yOt,"AutoModelForMaskedLM"),yOt.forEach(t),yno.forEach(t),cto=i(m),Do=n(m,"DIV",{class:!0});var Gl=s(Do);T(U$.$$.fragment,Gl),hKo=i(Gl),Vd=n(Gl,"P",{});var Qde=s(Vd);uKo=r(Qde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),$U=n(Qde,"A",{href:!0});var xOt=s($U);pKo=r(xOt,"from_pretrained()"),xOt.forEach(t),_Ko=r(Qde," class method or the "),kU=n(Qde,"A",{href:!0});var $Ot=s(kU);bKo=r($Ot,"from_config()"),$Ot.forEach(t),vKo=r(Qde,` class
method.`),Qde.forEach(t),FKo=i(Gl),H$=n(Gl,"P",{});var xno=s(H$);TKo=r(xno,"This class cannot be instantiated directly using "),KFe=n(xno,"CODE",{});var kOt=s(KFe);MKo=r(kOt,"__init__()"),kOt.forEach(t),EKo=r(xno," (throws an error)."),xno.forEach(t),CKo=i(Gl),wt=n(Gl,"DIV",{class:!0});var Zy=s(wt);T(J$.$$.fragment,Zy),wKo=i(Zy),eTe=n(Zy,"P",{});var SOt=s(eTe);AKo=r(SOt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),SOt.forEach(t),LKo=i(Zy),Xd=n(Zy,"P",{});var Wde=s(Xd);yKo=r(Wde,`Note:
Loading a model from its configuration file does `),oTe=n(Wde,"STRONG",{});var ROt=s(oTe);xKo=r(ROt,"not"),ROt.forEach(t),$Ko=r(Wde,` load the model weights. It only affects the
model\u2019s configuration. Use `),SU=n(Wde,"A",{href:!0});var POt=s(SU);kKo=r(POt,"from_pretrained()"),POt.forEach(t),SKo=r(Wde," to load the model weights."),Wde.forEach(t),RKo=i(Zy),T(Uv.$$.fragment,Zy),Zy.forEach(t),PKo=i(Gl),to=n(Gl,"DIV",{class:!0});var $a=s(to);T(Y$.$$.fragment,$a),BKo=i($a),rTe=n($a,"P",{});var BOt=s(rTe);IKo=r(BOt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),BOt.forEach(t),NKo=i($a),dn=n($a,"P",{});var Ky=s(dn);qKo=r(Ky,"The model class to instantiate is selected based on the "),tTe=n(Ky,"CODE",{});var IOt=s(tTe);jKo=r(IOt,"model_type"),IOt.forEach(t),DKo=r(Ky,` property of the config object (either
passed as an argument or loaded from `),aTe=n(Ky,"CODE",{});var NOt=s(aTe);GKo=r(NOt,"pretrained_model_name_or_path"),NOt.forEach(t),OKo=r(Ky,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nTe=n(Ky,"CODE",{});var qOt=s(nTe);VKo=r(qOt,"pretrained_model_name_or_path"),qOt.forEach(t),XKo=r(Ky,":"),Ky.forEach(t),zKo=i($a),Y=n($a,"UL",{});var Z=s(Y);Hv=n(Z,"LI",{});var uXe=s(Hv);sTe=n(uXe,"STRONG",{});var jOt=s(sTe);QKo=r(jOt,"albert"),jOt.forEach(t),WKo=r(uXe," \u2014 "),RU=n(uXe,"A",{href:!0});var DOt=s(RU);UKo=r(DOt,"AlbertForMaskedLM"),DOt.forEach(t),HKo=r(uXe," (ALBERT model)"),uXe.forEach(t),JKo=i(Z),Jv=n(Z,"LI",{});var pXe=s(Jv);lTe=n(pXe,"STRONG",{});var GOt=s(lTe);YKo=r(GOt,"bart"),GOt.forEach(t),ZKo=r(pXe," \u2014 "),PU=n(pXe,"A",{href:!0});var OOt=s(PU);KKo=r(OOt,"BartForConditionalGeneration"),OOt.forEach(t),eer=r(pXe," (BART model)"),pXe.forEach(t),oer=i(Z),Yv=n(Z,"LI",{});var _Xe=s(Yv);iTe=n(_Xe,"STRONG",{});var VOt=s(iTe);rer=r(VOt,"bert"),VOt.forEach(t),ter=r(_Xe," \u2014 "),BU=n(_Xe,"A",{href:!0});var XOt=s(BU);aer=r(XOt,"BertForMaskedLM"),XOt.forEach(t),ner=r(_Xe," (BERT model)"),_Xe.forEach(t),ser=i(Z),Zv=n(Z,"LI",{});var bXe=s(Zv);dTe=n(bXe,"STRONG",{});var zOt=s(dTe);ler=r(zOt,"big_bird"),zOt.forEach(t),ier=r(bXe," \u2014 "),IU=n(bXe,"A",{href:!0});var QOt=s(IU);der=r(QOt,"BigBirdForMaskedLM"),QOt.forEach(t),cer=r(bXe," (BigBird model)"),bXe.forEach(t),mer=i(Z),Kv=n(Z,"LI",{});var vXe=s(Kv);cTe=n(vXe,"STRONG",{});var WOt=s(cTe);fer=r(WOt,"camembert"),WOt.forEach(t),ger=r(vXe," \u2014 "),NU=n(vXe,"A",{href:!0});var UOt=s(NU);her=r(UOt,"CamembertForMaskedLM"),UOt.forEach(t),uer=r(vXe," (CamemBERT model)"),vXe.forEach(t),per=i(Z),eF=n(Z,"LI",{});var FXe=s(eF);mTe=n(FXe,"STRONG",{});var HOt=s(mTe);_er=r(HOt,"convbert"),HOt.forEach(t),ber=r(FXe," \u2014 "),qU=n(FXe,"A",{href:!0});var JOt=s(qU);ver=r(JOt,"ConvBertForMaskedLM"),JOt.forEach(t),Fer=r(FXe," (ConvBERT model)"),FXe.forEach(t),Ter=i(Z),oF=n(Z,"LI",{});var TXe=s(oF);fTe=n(TXe,"STRONG",{});var YOt=s(fTe);Mer=r(YOt,"data2vec-text"),YOt.forEach(t),Eer=r(TXe," \u2014 "),jU=n(TXe,"A",{href:!0});var ZOt=s(jU);Cer=r(ZOt,"Data2VecTextForMaskedLM"),ZOt.forEach(t),wer=r(TXe," (Data2VecText model)"),TXe.forEach(t),Aer=i(Z),rF=n(Z,"LI",{});var MXe=s(rF);gTe=n(MXe,"STRONG",{});var KOt=s(gTe);Ler=r(KOt,"deberta"),KOt.forEach(t),yer=r(MXe," \u2014 "),DU=n(MXe,"A",{href:!0});var eVt=s(DU);xer=r(eVt,"DebertaForMaskedLM"),eVt.forEach(t),$er=r(MXe," (DeBERTa model)"),MXe.forEach(t),ker=i(Z),tF=n(Z,"LI",{});var EXe=s(tF);hTe=n(EXe,"STRONG",{});var oVt=s(hTe);Ser=r(oVt,"deberta-v2"),oVt.forEach(t),Rer=r(EXe," \u2014 "),GU=n(EXe,"A",{href:!0});var rVt=s(GU);Per=r(rVt,"DebertaV2ForMaskedLM"),rVt.forEach(t),Ber=r(EXe," (DeBERTa-v2 model)"),EXe.forEach(t),Ier=i(Z),aF=n(Z,"LI",{});var CXe=s(aF);uTe=n(CXe,"STRONG",{});var tVt=s(uTe);Ner=r(tVt,"distilbert"),tVt.forEach(t),qer=r(CXe," \u2014 "),OU=n(CXe,"A",{href:!0});var aVt=s(OU);jer=r(aVt,"DistilBertForMaskedLM"),aVt.forEach(t),Der=r(CXe," (DistilBERT model)"),CXe.forEach(t),Ger=i(Z),nF=n(Z,"LI",{});var wXe=s(nF);pTe=n(wXe,"STRONG",{});var nVt=s(pTe);Oer=r(nVt,"electra"),nVt.forEach(t),Ver=r(wXe," \u2014 "),VU=n(wXe,"A",{href:!0});var sVt=s(VU);Xer=r(sVt,"ElectraForMaskedLM"),sVt.forEach(t),zer=r(wXe," (ELECTRA model)"),wXe.forEach(t),Qer=i(Z),sF=n(Z,"LI",{});var AXe=s(sF);_Te=n(AXe,"STRONG",{});var lVt=s(_Te);Wer=r(lVt,"ernie"),lVt.forEach(t),Uer=r(AXe," \u2014 "),XU=n(AXe,"A",{href:!0});var iVt=s(XU);Her=r(iVt,"ErnieForMaskedLM"),iVt.forEach(t),Jer=r(AXe," (ERNIE model)"),AXe.forEach(t),Yer=i(Z),lF=n(Z,"LI",{});var LXe=s(lF);bTe=n(LXe,"STRONG",{});var dVt=s(bTe);Zer=r(dVt,"flaubert"),dVt.forEach(t),Ker=r(LXe," \u2014 "),zU=n(LXe,"A",{href:!0});var cVt=s(zU);eor=r(cVt,"FlaubertWithLMHeadModel"),cVt.forEach(t),oor=r(LXe," (FlauBERT model)"),LXe.forEach(t),ror=i(Z),iF=n(Z,"LI",{});var yXe=s(iF);vTe=n(yXe,"STRONG",{});var mVt=s(vTe);tor=r(mVt,"fnet"),mVt.forEach(t),aor=r(yXe," \u2014 "),QU=n(yXe,"A",{href:!0});var fVt=s(QU);nor=r(fVt,"FNetForMaskedLM"),fVt.forEach(t),sor=r(yXe," (FNet model)"),yXe.forEach(t),lor=i(Z),dF=n(Z,"LI",{});var xXe=s(dF);FTe=n(xXe,"STRONG",{});var gVt=s(FTe);ior=r(gVt,"funnel"),gVt.forEach(t),dor=r(xXe," \u2014 "),WU=n(xXe,"A",{href:!0});var hVt=s(WU);cor=r(hVt,"FunnelForMaskedLM"),hVt.forEach(t),mor=r(xXe," (Funnel Transformer model)"),xXe.forEach(t),gor=i(Z),cF=n(Z,"LI",{});var $Xe=s(cF);TTe=n($Xe,"STRONG",{});var uVt=s(TTe);hor=r(uVt,"ibert"),uVt.forEach(t),uor=r($Xe," \u2014 "),UU=n($Xe,"A",{href:!0});var pVt=s(UU);por=r(pVt,"IBertForMaskedLM"),pVt.forEach(t),_or=r($Xe," (I-BERT model)"),$Xe.forEach(t),bor=i(Z),mF=n(Z,"LI",{});var kXe=s(mF);MTe=n(kXe,"STRONG",{});var _Vt=s(MTe);vor=r(_Vt,"layoutlm"),_Vt.forEach(t),For=r(kXe," \u2014 "),HU=n(kXe,"A",{href:!0});var bVt=s(HU);Tor=r(bVt,"LayoutLMForMaskedLM"),bVt.forEach(t),Mor=r(kXe," (LayoutLM model)"),kXe.forEach(t),Eor=i(Z),fF=n(Z,"LI",{});var SXe=s(fF);ETe=n(SXe,"STRONG",{});var vVt=s(ETe);Cor=r(vVt,"longformer"),vVt.forEach(t),wor=r(SXe," \u2014 "),JU=n(SXe,"A",{href:!0});var FVt=s(JU);Aor=r(FVt,"LongformerForMaskedLM"),FVt.forEach(t),Lor=r(SXe," (Longformer model)"),SXe.forEach(t),yor=i(Z),gF=n(Z,"LI",{});var RXe=s(gF);CTe=n(RXe,"STRONG",{});var TVt=s(CTe);xor=r(TVt,"luke"),TVt.forEach(t),$or=r(RXe," \u2014 "),YU=n(RXe,"A",{href:!0});var MVt=s(YU);kor=r(MVt,"LukeForMaskedLM"),MVt.forEach(t),Sor=r(RXe," (LUKE model)"),RXe.forEach(t),Ror=i(Z),hF=n(Z,"LI",{});var PXe=s(hF);wTe=n(PXe,"STRONG",{});var EVt=s(wTe);Por=r(EVt,"mbart"),EVt.forEach(t),Bor=r(PXe," \u2014 "),ZU=n(PXe,"A",{href:!0});var CVt=s(ZU);Ior=r(CVt,"MBartForConditionalGeneration"),CVt.forEach(t),Nor=r(PXe," (mBART model)"),PXe.forEach(t),qor=i(Z),uF=n(Z,"LI",{});var BXe=s(uF);ATe=n(BXe,"STRONG",{});var wVt=s(ATe);jor=r(wVt,"megatron-bert"),wVt.forEach(t),Dor=r(BXe," \u2014 "),KU=n(BXe,"A",{href:!0});var AVt=s(KU);Gor=r(AVt,"MegatronBertForMaskedLM"),AVt.forEach(t),Oor=r(BXe," (Megatron-BERT model)"),BXe.forEach(t),Vor=i(Z),pF=n(Z,"LI",{});var IXe=s(pF);LTe=n(IXe,"STRONG",{});var LVt=s(LTe);Xor=r(LVt,"mobilebert"),LVt.forEach(t),zor=r(IXe," \u2014 "),eH=n(IXe,"A",{href:!0});var yVt=s(eH);Qor=r(yVt,"MobileBertForMaskedLM"),yVt.forEach(t),Wor=r(IXe," (MobileBERT model)"),IXe.forEach(t),Uor=i(Z),_F=n(Z,"LI",{});var NXe=s(_F);yTe=n(NXe,"STRONG",{});var xVt=s(yTe);Hor=r(xVt,"mpnet"),xVt.forEach(t),Jor=r(NXe," \u2014 "),oH=n(NXe,"A",{href:!0});var $Vt=s(oH);Yor=r($Vt,"MPNetForMaskedLM"),$Vt.forEach(t),Zor=r(NXe," (MPNet model)"),NXe.forEach(t),Kor=i(Z),bF=n(Z,"LI",{});var qXe=s(bF);xTe=n(qXe,"STRONG",{});var kVt=s(xTe);err=r(kVt,"mvp"),kVt.forEach(t),orr=r(qXe," \u2014 "),rH=n(qXe,"A",{href:!0});var SVt=s(rH);rrr=r(SVt,"MvpForConditionalGeneration"),SVt.forEach(t),trr=r(qXe," (MVP model)"),qXe.forEach(t),arr=i(Z),vF=n(Z,"LI",{});var jXe=s(vF);$Te=n(jXe,"STRONG",{});var RVt=s($Te);nrr=r(RVt,"nezha"),RVt.forEach(t),srr=r(jXe," \u2014 "),tH=n(jXe,"A",{href:!0});var PVt=s(tH);lrr=r(PVt,"NezhaForMaskedLM"),PVt.forEach(t),irr=r(jXe," (Nezha model)"),jXe.forEach(t),drr=i(Z),FF=n(Z,"LI",{});var DXe=s(FF);kTe=n(DXe,"STRONG",{});var BVt=s(kTe);crr=r(BVt,"nystromformer"),BVt.forEach(t),mrr=r(DXe," \u2014 "),aH=n(DXe,"A",{href:!0});var IVt=s(aH);frr=r(IVt,"NystromformerForMaskedLM"),IVt.forEach(t),grr=r(DXe," (Nystr\xF6mformer model)"),DXe.forEach(t),hrr=i(Z),TF=n(Z,"LI",{});var GXe=s(TF);STe=n(GXe,"STRONG",{});var NVt=s(STe);urr=r(NVt,"perceiver"),NVt.forEach(t),prr=r(GXe," \u2014 "),nH=n(GXe,"A",{href:!0});var qVt=s(nH);_rr=r(qVt,"PerceiverForMaskedLM"),qVt.forEach(t),brr=r(GXe," (Perceiver model)"),GXe.forEach(t),vrr=i(Z),MF=n(Z,"LI",{});var OXe=s(MF);RTe=n(OXe,"STRONG",{});var jVt=s(RTe);Frr=r(jVt,"qdqbert"),jVt.forEach(t),Trr=r(OXe," \u2014 "),sH=n(OXe,"A",{href:!0});var DVt=s(sH);Mrr=r(DVt,"QDQBertForMaskedLM"),DVt.forEach(t),Err=r(OXe," (QDQBert model)"),OXe.forEach(t),Crr=i(Z),EF=n(Z,"LI",{});var VXe=s(EF);PTe=n(VXe,"STRONG",{});var GVt=s(PTe);wrr=r(GVt,"reformer"),GVt.forEach(t),Arr=r(VXe," \u2014 "),lH=n(VXe,"A",{href:!0});var OVt=s(lH);Lrr=r(OVt,"ReformerForMaskedLM"),OVt.forEach(t),yrr=r(VXe," (Reformer model)"),VXe.forEach(t),xrr=i(Z),CF=n(Z,"LI",{});var XXe=s(CF);BTe=n(XXe,"STRONG",{});var VVt=s(BTe);$rr=r(VVt,"rembert"),VVt.forEach(t),krr=r(XXe," \u2014 "),iH=n(XXe,"A",{href:!0});var XVt=s(iH);Srr=r(XVt,"RemBertForMaskedLM"),XVt.forEach(t),Rrr=r(XXe," (RemBERT model)"),XXe.forEach(t),Prr=i(Z),wF=n(Z,"LI",{});var zXe=s(wF);ITe=n(zXe,"STRONG",{});var zVt=s(ITe);Brr=r(zVt,"roberta"),zVt.forEach(t),Irr=r(zXe," \u2014 "),dH=n(zXe,"A",{href:!0});var QVt=s(dH);Nrr=r(QVt,"RobertaForMaskedLM"),QVt.forEach(t),qrr=r(zXe," (RoBERTa model)"),zXe.forEach(t),jrr=i(Z),AF=n(Z,"LI",{});var QXe=s(AF);NTe=n(QXe,"STRONG",{});var WVt=s(NTe);Drr=r(WVt,"roformer"),WVt.forEach(t),Grr=r(QXe," \u2014 "),cH=n(QXe,"A",{href:!0});var UVt=s(cH);Orr=r(UVt,"RoFormerForMaskedLM"),UVt.forEach(t),Vrr=r(QXe," (RoFormer model)"),QXe.forEach(t),Xrr=i(Z),LF=n(Z,"LI",{});var WXe=s(LF);qTe=n(WXe,"STRONG",{});var HVt=s(qTe);zrr=r(HVt,"squeezebert"),HVt.forEach(t),Qrr=r(WXe," \u2014 "),mH=n(WXe,"A",{href:!0});var JVt=s(mH);Wrr=r(JVt,"SqueezeBertForMaskedLM"),JVt.forEach(t),Urr=r(WXe," (SqueezeBERT model)"),WXe.forEach(t),Hrr=i(Z),yF=n(Z,"LI",{});var UXe=s(yF);jTe=n(UXe,"STRONG",{});var YVt=s(jTe);Jrr=r(YVt,"tapas"),YVt.forEach(t),Yrr=r(UXe," \u2014 "),fH=n(UXe,"A",{href:!0});var ZVt=s(fH);Zrr=r(ZVt,"TapasForMaskedLM"),ZVt.forEach(t),Krr=r(UXe," (TAPAS model)"),UXe.forEach(t),etr=i(Z),xF=n(Z,"LI",{});var HXe=s(xF);DTe=n(HXe,"STRONG",{});var KVt=s(DTe);otr=r(KVt,"wav2vec2"),KVt.forEach(t),rtr=r(HXe," \u2014 "),GTe=n(HXe,"CODE",{});var eXt=s(GTe);ttr=r(eXt,"Wav2Vec2ForMaskedLM"),eXt.forEach(t),atr=r(HXe," (Wav2Vec2 model)"),HXe.forEach(t),ntr=i(Z),$F=n(Z,"LI",{});var JXe=s($F);OTe=n(JXe,"STRONG",{});var oXt=s(OTe);str=r(oXt,"xlm"),oXt.forEach(t),ltr=r(JXe," \u2014 "),gH=n(JXe,"A",{href:!0});var rXt=s(gH);itr=r(rXt,"XLMWithLMHeadModel"),rXt.forEach(t),dtr=r(JXe," (XLM model)"),JXe.forEach(t),ctr=i(Z),kF=n(Z,"LI",{});var YXe=s(kF);VTe=n(YXe,"STRONG",{});var tXt=s(VTe);mtr=r(tXt,"xlm-roberta"),tXt.forEach(t),ftr=r(YXe," \u2014 "),hH=n(YXe,"A",{href:!0});var aXt=s(hH);gtr=r(aXt,"XLMRobertaForMaskedLM"),aXt.forEach(t),htr=r(YXe," (XLM-RoBERTa model)"),YXe.forEach(t),utr=i(Z),SF=n(Z,"LI",{});var ZXe=s(SF);XTe=n(ZXe,"STRONG",{});var nXt=s(XTe);ptr=r(nXt,"xlm-roberta-xl"),nXt.forEach(t),_tr=r(ZXe," \u2014 "),uH=n(ZXe,"A",{href:!0});var sXt=s(uH);btr=r(sXt,"XLMRobertaXLForMaskedLM"),sXt.forEach(t),vtr=r(ZXe," (XLM-RoBERTa-XL model)"),ZXe.forEach(t),Ftr=i(Z),RF=n(Z,"LI",{});var KXe=s(RF);zTe=n(KXe,"STRONG",{});var lXt=s(zTe);Ttr=r(lXt,"yoso"),lXt.forEach(t),Mtr=r(KXe," \u2014 "),pH=n(KXe,"A",{href:!0});var iXt=s(pH);Etr=r(iXt,"YosoForMaskedLM"),iXt.forEach(t),Ctr=r(KXe," (YOSO model)"),KXe.forEach(t),Z.forEach(t),wtr=i($a),PF=n($a,"P",{});var eze=s(PF);Atr=r(eze,"The model is set in evaluation mode by default using "),QTe=n(eze,"CODE",{});var dXt=s(QTe);Ltr=r(dXt,"model.eval()"),dXt.forEach(t),ytr=r(eze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WTe=n(eze,"CODE",{});var cXt=s(WTe);xtr=r(cXt,"model.train()"),cXt.forEach(t),eze.forEach(t),$tr=i($a),T(BF.$$.fragment,$a),$a.forEach(t),Gl.forEach(t),mto=i(m),zd=n(m,"H2",{class:!0});var $no=s(zd);IF=n($no,"A",{id:!0,class:!0,href:!0});var mXt=s(IF);UTe=n(mXt,"SPAN",{});var fXt=s(UTe);T(Z$.$$.fragment,fXt),fXt.forEach(t),mXt.forEach(t),ktr=i($no),HTe=n($no,"SPAN",{});var gXt=s(HTe);Str=r(gXt,"AutoModelForSeq2SeqLM"),gXt.forEach(t),$no.forEach(t),fto=i(m),Go=n(m,"DIV",{class:!0});var Ol=s(Go);T(K$.$$.fragment,Ol),Rtr=i(Ol),Qd=n(Ol,"P",{});var Ude=s(Qd);Ptr=r(Ude,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_H=n(Ude,"A",{href:!0});var hXt=s(_H);Btr=r(hXt,"from_pretrained()"),hXt.forEach(t),Itr=r(Ude," class method or the "),bH=n(Ude,"A",{href:!0});var uXt=s(bH);Ntr=r(uXt,"from_config()"),uXt.forEach(t),qtr=r(Ude,` class
method.`),Ude.forEach(t),jtr=i(Ol),ek=n(Ol,"P",{});var kno=s(ek);Dtr=r(kno,"This class cannot be instantiated directly using "),JTe=n(kno,"CODE",{});var pXt=s(JTe);Gtr=r(pXt,"__init__()"),pXt.forEach(t),Otr=r(kno," (throws an error)."),kno.forEach(t),Vtr=i(Ol),At=n(Ol,"DIV",{class:!0});var e9=s(At);T(ok.$$.fragment,e9),Xtr=i(e9),YTe=n(e9,"P",{});var _Xt=s(YTe);ztr=r(_Xt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_Xt.forEach(t),Qtr=i(e9),Wd=n(e9,"P",{});var Hde=s(Wd);Wtr=r(Hde,`Note:
Loading a model from its configuration file does `),ZTe=n(Hde,"STRONG",{});var bXt=s(ZTe);Utr=r(bXt,"not"),bXt.forEach(t),Htr=r(Hde,` load the model weights. It only affects the
model\u2019s configuration. Use `),vH=n(Hde,"A",{href:!0});var vXt=s(vH);Jtr=r(vXt,"from_pretrained()"),vXt.forEach(t),Ytr=r(Hde," to load the model weights."),Hde.forEach(t),Ztr=i(e9),T(NF.$$.fragment,e9),e9.forEach(t),Ktr=i(Ol),ao=n(Ol,"DIV",{class:!0});var ka=s(ao);T(rk.$$.fragment,ka),ear=i(ka),KTe=n(ka,"P",{});var FXt=s(KTe);oar=r(FXt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),FXt.forEach(t),rar=i(ka),cn=n(ka,"P",{});var o9=s(cn);tar=r(o9,"The model class to instantiate is selected based on the "),eMe=n(o9,"CODE",{});var TXt=s(eMe);aar=r(TXt,"model_type"),TXt.forEach(t),nar=r(o9,` property of the config object (either
passed as an argument or loaded from `),oMe=n(o9,"CODE",{});var MXt=s(oMe);sar=r(MXt,"pretrained_model_name_or_path"),MXt.forEach(t),lar=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rMe=n(o9,"CODE",{});var EXt=s(rMe);iar=r(EXt,"pretrained_model_name_or_path"),EXt.forEach(t),dar=r(o9,":"),o9.forEach(t),car=i(ka),fe=n(ka,"UL",{});var pe=s(fe);qF=n(pe,"LI",{});var oze=s(qF);tMe=n(oze,"STRONG",{});var CXt=s(tMe);mar=r(CXt,"bart"),CXt.forEach(t),far=r(oze," \u2014 "),FH=n(oze,"A",{href:!0});var wXt=s(FH);gar=r(wXt,"BartForConditionalGeneration"),wXt.forEach(t),har=r(oze," (BART model)"),oze.forEach(t),uar=i(pe),jF=n(pe,"LI",{});var rze=s(jF);aMe=n(rze,"STRONG",{});var AXt=s(aMe);par=r(AXt,"bigbird_pegasus"),AXt.forEach(t),_ar=r(rze," \u2014 "),TH=n(rze,"A",{href:!0});var LXt=s(TH);bar=r(LXt,"BigBirdPegasusForConditionalGeneration"),LXt.forEach(t),Far=r(rze," (BigBird-Pegasus model)"),rze.forEach(t),Tar=i(pe),DF=n(pe,"LI",{});var tze=s(DF);nMe=n(tze,"STRONG",{});var yXt=s(nMe);Mar=r(yXt,"blenderbot"),yXt.forEach(t),Ear=r(tze," \u2014 "),MH=n(tze,"A",{href:!0});var xXt=s(MH);Car=r(xXt,"BlenderbotForConditionalGeneration"),xXt.forEach(t),war=r(tze," (Blenderbot model)"),tze.forEach(t),Aar=i(pe),GF=n(pe,"LI",{});var aze=s(GF);sMe=n(aze,"STRONG",{});var $Xt=s(sMe);Lar=r($Xt,"blenderbot-small"),$Xt.forEach(t),yar=r(aze," \u2014 "),EH=n(aze,"A",{href:!0});var kXt=s(EH);xar=r(kXt,"BlenderbotSmallForConditionalGeneration"),kXt.forEach(t),$ar=r(aze," (BlenderbotSmall model)"),aze.forEach(t),kar=i(pe),OF=n(pe,"LI",{});var nze=s(OF);lMe=n(nze,"STRONG",{});var SXt=s(lMe);Sar=r(SXt,"encoder-decoder"),SXt.forEach(t),Rar=r(nze," \u2014 "),CH=n(nze,"A",{href:!0});var RXt=s(CH);Par=r(RXt,"EncoderDecoderModel"),RXt.forEach(t),Bar=r(nze," (Encoder decoder model)"),nze.forEach(t),Iar=i(pe),VF=n(pe,"LI",{});var sze=s(VF);iMe=n(sze,"STRONG",{});var PXt=s(iMe);Nar=r(PXt,"fsmt"),PXt.forEach(t),qar=r(sze," \u2014 "),wH=n(sze,"A",{href:!0});var BXt=s(wH);jar=r(BXt,"FSMTForConditionalGeneration"),BXt.forEach(t),Dar=r(sze," (FairSeq Machine-Translation model)"),sze.forEach(t),Gar=i(pe),XF=n(pe,"LI",{});var lze=s(XF);dMe=n(lze,"STRONG",{});var IXt=s(dMe);Oar=r(IXt,"led"),IXt.forEach(t),Var=r(lze," \u2014 "),AH=n(lze,"A",{href:!0});var NXt=s(AH);Xar=r(NXt,"LEDForConditionalGeneration"),NXt.forEach(t),zar=r(lze," (LED model)"),lze.forEach(t),Qar=i(pe),zF=n(pe,"LI",{});var ize=s(zF);cMe=n(ize,"STRONG",{});var qXt=s(cMe);War=r(qXt,"longt5"),qXt.forEach(t),Uar=r(ize," \u2014 "),LH=n(ize,"A",{href:!0});var jXt=s(LH);Har=r(jXt,"LongT5ForConditionalGeneration"),jXt.forEach(t),Jar=r(ize," (LongT5 model)"),ize.forEach(t),Yar=i(pe),QF=n(pe,"LI",{});var dze=s(QF);mMe=n(dze,"STRONG",{});var DXt=s(mMe);Zar=r(DXt,"m2m_100"),DXt.forEach(t),Kar=r(dze," \u2014 "),yH=n(dze,"A",{href:!0});var GXt=s(yH);enr=r(GXt,"M2M100ForConditionalGeneration"),GXt.forEach(t),onr=r(dze," (M2M100 model)"),dze.forEach(t),rnr=i(pe),WF=n(pe,"LI",{});var cze=s(WF);fMe=n(cze,"STRONG",{});var OXt=s(fMe);tnr=r(OXt,"marian"),OXt.forEach(t),anr=r(cze," \u2014 "),xH=n(cze,"A",{href:!0});var VXt=s(xH);nnr=r(VXt,"MarianMTModel"),VXt.forEach(t),snr=r(cze," (Marian model)"),cze.forEach(t),lnr=i(pe),UF=n(pe,"LI",{});var mze=s(UF);gMe=n(mze,"STRONG",{});var XXt=s(gMe);inr=r(XXt,"mbart"),XXt.forEach(t),dnr=r(mze," \u2014 "),$H=n(mze,"A",{href:!0});var zXt=s($H);cnr=r(zXt,"MBartForConditionalGeneration"),zXt.forEach(t),mnr=r(mze," (mBART model)"),mze.forEach(t),fnr=i(pe),HF=n(pe,"LI",{});var fze=s(HF);hMe=n(fze,"STRONG",{});var QXt=s(hMe);gnr=r(QXt,"mt5"),QXt.forEach(t),hnr=r(fze," \u2014 "),kH=n(fze,"A",{href:!0});var WXt=s(kH);unr=r(WXt,"MT5ForConditionalGeneration"),WXt.forEach(t),pnr=r(fze," (MT5 model)"),fze.forEach(t),_nr=i(pe),JF=n(pe,"LI",{});var gze=s(JF);uMe=n(gze,"STRONG",{});var UXt=s(uMe);bnr=r(UXt,"mvp"),UXt.forEach(t),vnr=r(gze," \u2014 "),SH=n(gze,"A",{href:!0});var HXt=s(SH);Fnr=r(HXt,"MvpForConditionalGeneration"),HXt.forEach(t),Tnr=r(gze," (MVP model)"),gze.forEach(t),Mnr=i(pe),YF=n(pe,"LI",{});var hze=s(YF);pMe=n(hze,"STRONG",{});var JXt=s(pMe);Enr=r(JXt,"nllb"),JXt.forEach(t),Cnr=r(hze," \u2014 "),RH=n(hze,"A",{href:!0});var YXt=s(RH);wnr=r(YXt,"M2M100ForConditionalGeneration"),YXt.forEach(t),Anr=r(hze," (NLLB model)"),hze.forEach(t),Lnr=i(pe),ZF=n(pe,"LI",{});var uze=s(ZF);_Me=n(uze,"STRONG",{});var ZXt=s(_Me);ynr=r(ZXt,"pegasus"),ZXt.forEach(t),xnr=r(uze," \u2014 "),PH=n(uze,"A",{href:!0});var KXt=s(PH);$nr=r(KXt,"PegasusForConditionalGeneration"),KXt.forEach(t),knr=r(uze," (Pegasus model)"),uze.forEach(t),Snr=i(pe),KF=n(pe,"LI",{});var pze=s(KF);bMe=n(pze,"STRONG",{});var ezt=s(bMe);Rnr=r(ezt,"pegasus_x"),ezt.forEach(t),Pnr=r(pze," \u2014 "),BH=n(pze,"A",{href:!0});var ozt=s(BH);Bnr=r(ozt,"PegasusXForConditionalGeneration"),ozt.forEach(t),Inr=r(pze," (PEGASUS-X model)"),pze.forEach(t),Nnr=i(pe),eT=n(pe,"LI",{});var _ze=s(eT);vMe=n(_ze,"STRONG",{});var rzt=s(vMe);qnr=r(rzt,"plbart"),rzt.forEach(t),jnr=r(_ze," \u2014 "),IH=n(_ze,"A",{href:!0});var tzt=s(IH);Dnr=r(tzt,"PLBartForConditionalGeneration"),tzt.forEach(t),Gnr=r(_ze," (PLBart model)"),_ze.forEach(t),Onr=i(pe),oT=n(pe,"LI",{});var bze=s(oT);FMe=n(bze,"STRONG",{});var azt=s(FMe);Vnr=r(azt,"prophetnet"),azt.forEach(t),Xnr=r(bze," \u2014 "),NH=n(bze,"A",{href:!0});var nzt=s(NH);znr=r(nzt,"ProphetNetForConditionalGeneration"),nzt.forEach(t),Qnr=r(bze," (ProphetNet model)"),bze.forEach(t),Wnr=i(pe),rT=n(pe,"LI",{});var vze=s(rT);TMe=n(vze,"STRONG",{});var szt=s(TMe);Unr=r(szt,"t5"),szt.forEach(t),Hnr=r(vze," \u2014 "),qH=n(vze,"A",{href:!0});var lzt=s(qH);Jnr=r(lzt,"T5ForConditionalGeneration"),lzt.forEach(t),Ynr=r(vze," (T5 model)"),vze.forEach(t),Znr=i(pe),tT=n(pe,"LI",{});var Fze=s(tT);MMe=n(Fze,"STRONG",{});var izt=s(MMe);Knr=r(izt,"xlm-prophetnet"),izt.forEach(t),esr=r(Fze," \u2014 "),jH=n(Fze,"A",{href:!0});var dzt=s(jH);osr=r(dzt,"XLMProphetNetForConditionalGeneration"),dzt.forEach(t),rsr=r(Fze," (XLM-ProphetNet model)"),Fze.forEach(t),pe.forEach(t),tsr=i(ka),aT=n(ka,"P",{});var Tze=s(aT);asr=r(Tze,"The model is set in evaluation mode by default using "),EMe=n(Tze,"CODE",{});var czt=s(EMe);nsr=r(czt,"model.eval()"),czt.forEach(t),ssr=r(Tze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CMe=n(Tze,"CODE",{});var mzt=s(CMe);lsr=r(mzt,"model.train()"),mzt.forEach(t),Tze.forEach(t),isr=i(ka),T(nT.$$.fragment,ka),ka.forEach(t),Ol.forEach(t),gto=i(m),Ud=n(m,"H2",{class:!0});var Sno=s(Ud);sT=n(Sno,"A",{id:!0,class:!0,href:!0});var fzt=s(sT);wMe=n(fzt,"SPAN",{});var gzt=s(wMe);T(tk.$$.fragment,gzt),gzt.forEach(t),fzt.forEach(t),dsr=i(Sno),AMe=n(Sno,"SPAN",{});var hzt=s(AMe);csr=r(hzt,"AutoModelForSequenceClassification"),hzt.forEach(t),Sno.forEach(t),hto=i(m),Oo=n(m,"DIV",{class:!0});var Vl=s(Oo);T(ak.$$.fragment,Vl),msr=i(Vl),Hd=n(Vl,"P",{});var Jde=s(Hd);fsr=r(Jde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),DH=n(Jde,"A",{href:!0});var uzt=s(DH);gsr=r(uzt,"from_pretrained()"),uzt.forEach(t),hsr=r(Jde," class method or the "),GH=n(Jde,"A",{href:!0});var pzt=s(GH);usr=r(pzt,"from_config()"),pzt.forEach(t),psr=r(Jde,` class
method.`),Jde.forEach(t),_sr=i(Vl),nk=n(Vl,"P",{});var Rno=s(nk);bsr=r(Rno,"This class cannot be instantiated directly using "),LMe=n(Rno,"CODE",{});var _zt=s(LMe);vsr=r(_zt,"__init__()"),_zt.forEach(t),Fsr=r(Rno," (throws an error)."),Rno.forEach(t),Tsr=i(Vl),Lt=n(Vl,"DIV",{class:!0});var r9=s(Lt);T(sk.$$.fragment,r9),Msr=i(r9),yMe=n(r9,"P",{});var bzt=s(yMe);Esr=r(bzt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),bzt.forEach(t),Csr=i(r9),Jd=n(r9,"P",{});var Yde=s(Jd);wsr=r(Yde,`Note:
Loading a model from its configuration file does `),xMe=n(Yde,"STRONG",{});var vzt=s(xMe);Asr=r(vzt,"not"),vzt.forEach(t),Lsr=r(Yde,` load the model weights. It only affects the
model\u2019s configuration. Use `),OH=n(Yde,"A",{href:!0});var Fzt=s(OH);ysr=r(Fzt,"from_pretrained()"),Fzt.forEach(t),xsr=r(Yde," to load the model weights."),Yde.forEach(t),$sr=i(r9),T(lT.$$.fragment,r9),r9.forEach(t),ksr=i(Vl),no=n(Vl,"DIV",{class:!0});var Sa=s(no);T(lk.$$.fragment,Sa),Ssr=i(Sa),$Me=n(Sa,"P",{});var Tzt=s($Me);Rsr=r(Tzt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Tzt.forEach(t),Psr=i(Sa),mn=n(Sa,"P",{});var t9=s(mn);Bsr=r(t9,"The model class to instantiate is selected based on the "),kMe=n(t9,"CODE",{});var Mzt=s(kMe);Isr=r(Mzt,"model_type"),Mzt.forEach(t),Nsr=r(t9,` property of the config object (either
passed as an argument or loaded from `),SMe=n(t9,"CODE",{});var Ezt=s(SMe);qsr=r(Ezt,"pretrained_model_name_or_path"),Ezt.forEach(t),jsr=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RMe=n(t9,"CODE",{});var Czt=s(RMe);Dsr=r(Czt,"pretrained_model_name_or_path"),Czt.forEach(t),Gsr=r(t9,":"),t9.forEach(t),Osr=i(Sa),q=n(Sa,"UL",{});var D=s(q);iT=n(D,"LI",{});var Mze=s(iT);PMe=n(Mze,"STRONG",{});var wzt=s(PMe);Vsr=r(wzt,"albert"),wzt.forEach(t),Xsr=r(Mze," \u2014 "),VH=n(Mze,"A",{href:!0});var Azt=s(VH);zsr=r(Azt,"AlbertForSequenceClassification"),Azt.forEach(t),Qsr=r(Mze," (ALBERT model)"),Mze.forEach(t),Wsr=i(D),dT=n(D,"LI",{});var Eze=s(dT);BMe=n(Eze,"STRONG",{});var Lzt=s(BMe);Usr=r(Lzt,"bart"),Lzt.forEach(t),Hsr=r(Eze," \u2014 "),XH=n(Eze,"A",{href:!0});var yzt=s(XH);Jsr=r(yzt,"BartForSequenceClassification"),yzt.forEach(t),Ysr=r(Eze," (BART model)"),Eze.forEach(t),Zsr=i(D),cT=n(D,"LI",{});var Cze=s(cT);IMe=n(Cze,"STRONG",{});var xzt=s(IMe);Ksr=r(xzt,"bert"),xzt.forEach(t),elr=r(Cze," \u2014 "),zH=n(Cze,"A",{href:!0});var $zt=s(zH);olr=r($zt,"BertForSequenceClassification"),$zt.forEach(t),rlr=r(Cze," (BERT model)"),Cze.forEach(t),tlr=i(D),mT=n(D,"LI",{});var wze=s(mT);NMe=n(wze,"STRONG",{});var kzt=s(NMe);alr=r(kzt,"big_bird"),kzt.forEach(t),nlr=r(wze," \u2014 "),QH=n(wze,"A",{href:!0});var Szt=s(QH);slr=r(Szt,"BigBirdForSequenceClassification"),Szt.forEach(t),llr=r(wze," (BigBird model)"),wze.forEach(t),ilr=i(D),fT=n(D,"LI",{});var Aze=s(fT);qMe=n(Aze,"STRONG",{});var Rzt=s(qMe);dlr=r(Rzt,"bigbird_pegasus"),Rzt.forEach(t),clr=r(Aze," \u2014 "),WH=n(Aze,"A",{href:!0});var Pzt=s(WH);mlr=r(Pzt,"BigBirdPegasusForSequenceClassification"),Pzt.forEach(t),flr=r(Aze," (BigBird-Pegasus model)"),Aze.forEach(t),glr=i(D),gT=n(D,"LI",{});var Lze=s(gT);jMe=n(Lze,"STRONG",{});var Bzt=s(jMe);hlr=r(Bzt,"bloom"),Bzt.forEach(t),ulr=r(Lze," \u2014 "),UH=n(Lze,"A",{href:!0});var Izt=s(UH);plr=r(Izt,"BloomForSequenceClassification"),Izt.forEach(t),_lr=r(Lze," (BLOOM model)"),Lze.forEach(t),blr=i(D),hT=n(D,"LI",{});var yze=s(hT);DMe=n(yze,"STRONG",{});var Nzt=s(DMe);vlr=r(Nzt,"camembert"),Nzt.forEach(t),Flr=r(yze," \u2014 "),HH=n(yze,"A",{href:!0});var qzt=s(HH);Tlr=r(qzt,"CamembertForSequenceClassification"),qzt.forEach(t),Mlr=r(yze," (CamemBERT model)"),yze.forEach(t),Elr=i(D),uT=n(D,"LI",{});var xze=s(uT);GMe=n(xze,"STRONG",{});var jzt=s(GMe);Clr=r(jzt,"canine"),jzt.forEach(t),wlr=r(xze," \u2014 "),JH=n(xze,"A",{href:!0});var Dzt=s(JH);Alr=r(Dzt,"CanineForSequenceClassification"),Dzt.forEach(t),Llr=r(xze," (CANINE model)"),xze.forEach(t),ylr=i(D),pT=n(D,"LI",{});var $ze=s(pT);OMe=n($ze,"STRONG",{});var Gzt=s(OMe);xlr=r(Gzt,"convbert"),Gzt.forEach(t),$lr=r($ze," \u2014 "),YH=n($ze,"A",{href:!0});var Ozt=s(YH);klr=r(Ozt,"ConvBertForSequenceClassification"),Ozt.forEach(t),Slr=r($ze," (ConvBERT model)"),$ze.forEach(t),Rlr=i(D),_T=n(D,"LI",{});var kze=s(_T);VMe=n(kze,"STRONG",{});var Vzt=s(VMe);Plr=r(Vzt,"ctrl"),Vzt.forEach(t),Blr=r(kze," \u2014 "),ZH=n(kze,"A",{href:!0});var Xzt=s(ZH);Ilr=r(Xzt,"CTRLForSequenceClassification"),Xzt.forEach(t),Nlr=r(kze," (CTRL model)"),kze.forEach(t),qlr=i(D),bT=n(D,"LI",{});var Sze=s(bT);XMe=n(Sze,"STRONG",{});var zzt=s(XMe);jlr=r(zzt,"data2vec-text"),zzt.forEach(t),Dlr=r(Sze," \u2014 "),KH=n(Sze,"A",{href:!0});var Qzt=s(KH);Glr=r(Qzt,"Data2VecTextForSequenceClassification"),Qzt.forEach(t),Olr=r(Sze," (Data2VecText model)"),Sze.forEach(t),Vlr=i(D),vT=n(D,"LI",{});var Rze=s(vT);zMe=n(Rze,"STRONG",{});var Wzt=s(zMe);Xlr=r(Wzt,"deberta"),Wzt.forEach(t),zlr=r(Rze," \u2014 "),eJ=n(Rze,"A",{href:!0});var Uzt=s(eJ);Qlr=r(Uzt,"DebertaForSequenceClassification"),Uzt.forEach(t),Wlr=r(Rze," (DeBERTa model)"),Rze.forEach(t),Ulr=i(D),FT=n(D,"LI",{});var Pze=s(FT);QMe=n(Pze,"STRONG",{});var Hzt=s(QMe);Hlr=r(Hzt,"deberta-v2"),Hzt.forEach(t),Jlr=r(Pze," \u2014 "),oJ=n(Pze,"A",{href:!0});var Jzt=s(oJ);Ylr=r(Jzt,"DebertaV2ForSequenceClassification"),Jzt.forEach(t),Zlr=r(Pze," (DeBERTa-v2 model)"),Pze.forEach(t),Klr=i(D),TT=n(D,"LI",{});var Bze=s(TT);WMe=n(Bze,"STRONG",{});var Yzt=s(WMe);eir=r(Yzt,"distilbert"),Yzt.forEach(t),oir=r(Bze," \u2014 "),rJ=n(Bze,"A",{href:!0});var Zzt=s(rJ);rir=r(Zzt,"DistilBertForSequenceClassification"),Zzt.forEach(t),tir=r(Bze," (DistilBERT model)"),Bze.forEach(t),air=i(D),MT=n(D,"LI",{});var Ize=s(MT);UMe=n(Ize,"STRONG",{});var Kzt=s(UMe);nir=r(Kzt,"electra"),Kzt.forEach(t),sir=r(Ize," \u2014 "),tJ=n(Ize,"A",{href:!0});var eQt=s(tJ);lir=r(eQt,"ElectraForSequenceClassification"),eQt.forEach(t),iir=r(Ize," (ELECTRA model)"),Ize.forEach(t),dir=i(D),ET=n(D,"LI",{});var Nze=s(ET);HMe=n(Nze,"STRONG",{});var oQt=s(HMe);cir=r(oQt,"ernie"),oQt.forEach(t),mir=r(Nze," \u2014 "),aJ=n(Nze,"A",{href:!0});var rQt=s(aJ);fir=r(rQt,"ErnieForSequenceClassification"),rQt.forEach(t),gir=r(Nze," (ERNIE model)"),Nze.forEach(t),hir=i(D),CT=n(D,"LI",{});var qze=s(CT);JMe=n(qze,"STRONG",{});var tQt=s(JMe);uir=r(tQt,"esm"),tQt.forEach(t),pir=r(qze," \u2014 "),nJ=n(qze,"A",{href:!0});var aQt=s(nJ);_ir=r(aQt,"EsmForSequenceClassification"),aQt.forEach(t),bir=r(qze," (ESM model)"),qze.forEach(t),vir=i(D),wT=n(D,"LI",{});var jze=s(wT);YMe=n(jze,"STRONG",{});var nQt=s(YMe);Fir=r(nQt,"flaubert"),nQt.forEach(t),Tir=r(jze," \u2014 "),sJ=n(jze,"A",{href:!0});var sQt=s(sJ);Mir=r(sQt,"FlaubertForSequenceClassification"),sQt.forEach(t),Eir=r(jze," (FlauBERT model)"),jze.forEach(t),Cir=i(D),AT=n(D,"LI",{});var Dze=s(AT);ZMe=n(Dze,"STRONG",{});var lQt=s(ZMe);wir=r(lQt,"fnet"),lQt.forEach(t),Air=r(Dze," \u2014 "),lJ=n(Dze,"A",{href:!0});var iQt=s(lJ);Lir=r(iQt,"FNetForSequenceClassification"),iQt.forEach(t),yir=r(Dze," (FNet model)"),Dze.forEach(t),xir=i(D),LT=n(D,"LI",{});var Gze=s(LT);KMe=n(Gze,"STRONG",{});var dQt=s(KMe);$ir=r(dQt,"funnel"),dQt.forEach(t),kir=r(Gze," \u2014 "),iJ=n(Gze,"A",{href:!0});var cQt=s(iJ);Sir=r(cQt,"FunnelForSequenceClassification"),cQt.forEach(t),Rir=r(Gze," (Funnel Transformer model)"),Gze.forEach(t),Pir=i(D),yT=n(D,"LI",{});var Oze=s(yT);eEe=n(Oze,"STRONG",{});var mQt=s(eEe);Bir=r(mQt,"gpt2"),mQt.forEach(t),Iir=r(Oze," \u2014 "),dJ=n(Oze,"A",{href:!0});var fQt=s(dJ);Nir=r(fQt,"GPT2ForSequenceClassification"),fQt.forEach(t),qir=r(Oze," (OpenAI GPT-2 model)"),Oze.forEach(t),jir=i(D),xT=n(D,"LI",{});var Vze=s(xT);oEe=n(Vze,"STRONG",{});var gQt=s(oEe);Dir=r(gQt,"gpt_neo"),gQt.forEach(t),Gir=r(Vze," \u2014 "),cJ=n(Vze,"A",{href:!0});var hQt=s(cJ);Oir=r(hQt,"GPTNeoForSequenceClassification"),hQt.forEach(t),Vir=r(Vze," (GPT Neo model)"),Vze.forEach(t),Xir=i(D),$T=n(D,"LI",{});var Xze=s($T);rEe=n(Xze,"STRONG",{});var uQt=s(rEe);zir=r(uQt,"gptj"),uQt.forEach(t),Qir=r(Xze," \u2014 "),mJ=n(Xze,"A",{href:!0});var pQt=s(mJ);Wir=r(pQt,"GPTJForSequenceClassification"),pQt.forEach(t),Uir=r(Xze," (GPT-J model)"),Xze.forEach(t),Hir=i(D),kT=n(D,"LI",{});var zze=s(kT);tEe=n(zze,"STRONG",{});var _Qt=s(tEe);Jir=r(_Qt,"ibert"),_Qt.forEach(t),Yir=r(zze," \u2014 "),fJ=n(zze,"A",{href:!0});var bQt=s(fJ);Zir=r(bQt,"IBertForSequenceClassification"),bQt.forEach(t),Kir=r(zze," (I-BERT model)"),zze.forEach(t),edr=i(D),ST=n(D,"LI",{});var Qze=s(ST);aEe=n(Qze,"STRONG",{});var vQt=s(aEe);odr=r(vQt,"layoutlm"),vQt.forEach(t),rdr=r(Qze," \u2014 "),gJ=n(Qze,"A",{href:!0});var FQt=s(gJ);tdr=r(FQt,"LayoutLMForSequenceClassification"),FQt.forEach(t),adr=r(Qze," (LayoutLM model)"),Qze.forEach(t),ndr=i(D),RT=n(D,"LI",{});var Wze=s(RT);nEe=n(Wze,"STRONG",{});var TQt=s(nEe);sdr=r(TQt,"layoutlmv2"),TQt.forEach(t),ldr=r(Wze," \u2014 "),hJ=n(Wze,"A",{href:!0});var MQt=s(hJ);idr=r(MQt,"LayoutLMv2ForSequenceClassification"),MQt.forEach(t),ddr=r(Wze," (LayoutLMv2 model)"),Wze.forEach(t),cdr=i(D),PT=n(D,"LI",{});var Uze=s(PT);sEe=n(Uze,"STRONG",{});var EQt=s(sEe);mdr=r(EQt,"layoutlmv3"),EQt.forEach(t),fdr=r(Uze," \u2014 "),uJ=n(Uze,"A",{href:!0});var CQt=s(uJ);gdr=r(CQt,"LayoutLMv3ForSequenceClassification"),CQt.forEach(t),hdr=r(Uze," (LayoutLMv3 model)"),Uze.forEach(t),udr=i(D),BT=n(D,"LI",{});var Hze=s(BT);lEe=n(Hze,"STRONG",{});var wQt=s(lEe);pdr=r(wQt,"led"),wQt.forEach(t),_dr=r(Hze," \u2014 "),pJ=n(Hze,"A",{href:!0});var AQt=s(pJ);bdr=r(AQt,"LEDForSequenceClassification"),AQt.forEach(t),vdr=r(Hze," (LED model)"),Hze.forEach(t),Fdr=i(D),IT=n(D,"LI",{});var Jze=s(IT);iEe=n(Jze,"STRONG",{});var LQt=s(iEe);Tdr=r(LQt,"lilt"),LQt.forEach(t),Mdr=r(Jze," \u2014 "),_J=n(Jze,"A",{href:!0});var yQt=s(_J);Edr=r(yQt,"LiltForSequenceClassification"),yQt.forEach(t),Cdr=r(Jze," (LiLT model)"),Jze.forEach(t),wdr=i(D),NT=n(D,"LI",{});var Yze=s(NT);dEe=n(Yze,"STRONG",{});var xQt=s(dEe);Adr=r(xQt,"longformer"),xQt.forEach(t),Ldr=r(Yze," \u2014 "),bJ=n(Yze,"A",{href:!0});var $Qt=s(bJ);ydr=r($Qt,"LongformerForSequenceClassification"),$Qt.forEach(t),xdr=r(Yze," (Longformer model)"),Yze.forEach(t),$dr=i(D),qT=n(D,"LI",{});var Zze=s(qT);cEe=n(Zze,"STRONG",{});var kQt=s(cEe);kdr=r(kQt,"luke"),kQt.forEach(t),Sdr=r(Zze," \u2014 "),vJ=n(Zze,"A",{href:!0});var SQt=s(vJ);Rdr=r(SQt,"LukeForSequenceClassification"),SQt.forEach(t),Pdr=r(Zze," (LUKE model)"),Zze.forEach(t),Bdr=i(D),jT=n(D,"LI",{});var Kze=s(jT);mEe=n(Kze,"STRONG",{});var RQt=s(mEe);Idr=r(RQt,"markuplm"),RQt.forEach(t),Ndr=r(Kze," \u2014 "),FJ=n(Kze,"A",{href:!0});var PQt=s(FJ);qdr=r(PQt,"MarkupLMForSequenceClassification"),PQt.forEach(t),jdr=r(Kze," (MarkupLM model)"),Kze.forEach(t),Ddr=i(D),DT=n(D,"LI",{});var eQe=s(DT);fEe=n(eQe,"STRONG",{});var BQt=s(fEe);Gdr=r(BQt,"mbart"),BQt.forEach(t),Odr=r(eQe," \u2014 "),TJ=n(eQe,"A",{href:!0});var IQt=s(TJ);Vdr=r(IQt,"MBartForSequenceClassification"),IQt.forEach(t),Xdr=r(eQe," (mBART model)"),eQe.forEach(t),zdr=i(D),GT=n(D,"LI",{});var oQe=s(GT);gEe=n(oQe,"STRONG",{});var NQt=s(gEe);Qdr=r(NQt,"megatron-bert"),NQt.forEach(t),Wdr=r(oQe," \u2014 "),MJ=n(oQe,"A",{href:!0});var qQt=s(MJ);Udr=r(qQt,"MegatronBertForSequenceClassification"),qQt.forEach(t),Hdr=r(oQe," (Megatron-BERT model)"),oQe.forEach(t),Jdr=i(D),OT=n(D,"LI",{});var rQe=s(OT);hEe=n(rQe,"STRONG",{});var jQt=s(hEe);Ydr=r(jQt,"mobilebert"),jQt.forEach(t),Zdr=r(rQe," \u2014 "),EJ=n(rQe,"A",{href:!0});var DQt=s(EJ);Kdr=r(DQt,"MobileBertForSequenceClassification"),DQt.forEach(t),ecr=r(rQe," (MobileBERT model)"),rQe.forEach(t),ocr=i(D),VT=n(D,"LI",{});var tQe=s(VT);uEe=n(tQe,"STRONG",{});var GQt=s(uEe);rcr=r(GQt,"mpnet"),GQt.forEach(t),tcr=r(tQe," \u2014 "),CJ=n(tQe,"A",{href:!0});var OQt=s(CJ);acr=r(OQt,"MPNetForSequenceClassification"),OQt.forEach(t),ncr=r(tQe," (MPNet model)"),tQe.forEach(t),scr=i(D),XT=n(D,"LI",{});var aQe=s(XT);pEe=n(aQe,"STRONG",{});var VQt=s(pEe);lcr=r(VQt,"mvp"),VQt.forEach(t),icr=r(aQe," \u2014 "),wJ=n(aQe,"A",{href:!0});var XQt=s(wJ);dcr=r(XQt,"MvpForSequenceClassification"),XQt.forEach(t),ccr=r(aQe," (MVP model)"),aQe.forEach(t),mcr=i(D),zT=n(D,"LI",{});var nQe=s(zT);_Ee=n(nQe,"STRONG",{});var zQt=s(_Ee);fcr=r(zQt,"nezha"),zQt.forEach(t),gcr=r(nQe," \u2014 "),AJ=n(nQe,"A",{href:!0});var QQt=s(AJ);hcr=r(QQt,"NezhaForSequenceClassification"),QQt.forEach(t),ucr=r(nQe," (Nezha model)"),nQe.forEach(t),pcr=i(D),QT=n(D,"LI",{});var sQe=s(QT);bEe=n(sQe,"STRONG",{});var WQt=s(bEe);_cr=r(WQt,"nystromformer"),WQt.forEach(t),bcr=r(sQe," \u2014 "),LJ=n(sQe,"A",{href:!0});var UQt=s(LJ);vcr=r(UQt,"NystromformerForSequenceClassification"),UQt.forEach(t),Fcr=r(sQe," (Nystr\xF6mformer model)"),sQe.forEach(t),Tcr=i(D),WT=n(D,"LI",{});var lQe=s(WT);vEe=n(lQe,"STRONG",{});var HQt=s(vEe);Mcr=r(HQt,"openai-gpt"),HQt.forEach(t),Ecr=r(lQe," \u2014 "),yJ=n(lQe,"A",{href:!0});var JQt=s(yJ);Ccr=r(JQt,"OpenAIGPTForSequenceClassification"),JQt.forEach(t),wcr=r(lQe," (OpenAI GPT model)"),lQe.forEach(t),Acr=i(D),UT=n(D,"LI",{});var iQe=s(UT);FEe=n(iQe,"STRONG",{});var YQt=s(FEe);Lcr=r(YQt,"opt"),YQt.forEach(t),ycr=r(iQe," \u2014 "),xJ=n(iQe,"A",{href:!0});var ZQt=s(xJ);xcr=r(ZQt,"OPTForSequenceClassification"),ZQt.forEach(t),$cr=r(iQe," (OPT model)"),iQe.forEach(t),kcr=i(D),HT=n(D,"LI",{});var dQe=s(HT);TEe=n(dQe,"STRONG",{});var KQt=s(TEe);Scr=r(KQt,"perceiver"),KQt.forEach(t),Rcr=r(dQe," \u2014 "),$J=n(dQe,"A",{href:!0});var eWt=s($J);Pcr=r(eWt,"PerceiverForSequenceClassification"),eWt.forEach(t),Bcr=r(dQe," (Perceiver model)"),dQe.forEach(t),Icr=i(D),JT=n(D,"LI",{});var cQe=s(JT);MEe=n(cQe,"STRONG",{});var oWt=s(MEe);Ncr=r(oWt,"plbart"),oWt.forEach(t),qcr=r(cQe," \u2014 "),kJ=n(cQe,"A",{href:!0});var rWt=s(kJ);jcr=r(rWt,"PLBartForSequenceClassification"),rWt.forEach(t),Dcr=r(cQe," (PLBart model)"),cQe.forEach(t),Gcr=i(D),YT=n(D,"LI",{});var mQe=s(YT);EEe=n(mQe,"STRONG",{});var tWt=s(EEe);Ocr=r(tWt,"qdqbert"),tWt.forEach(t),Vcr=r(mQe," \u2014 "),SJ=n(mQe,"A",{href:!0});var aWt=s(SJ);Xcr=r(aWt,"QDQBertForSequenceClassification"),aWt.forEach(t),zcr=r(mQe," (QDQBert model)"),mQe.forEach(t),Qcr=i(D),ZT=n(D,"LI",{});var fQe=s(ZT);CEe=n(fQe,"STRONG",{});var nWt=s(CEe);Wcr=r(nWt,"reformer"),nWt.forEach(t),Ucr=r(fQe," \u2014 "),RJ=n(fQe,"A",{href:!0});var sWt=s(RJ);Hcr=r(sWt,"ReformerForSequenceClassification"),sWt.forEach(t),Jcr=r(fQe," (Reformer model)"),fQe.forEach(t),Ycr=i(D),KT=n(D,"LI",{});var gQe=s(KT);wEe=n(gQe,"STRONG",{});var lWt=s(wEe);Zcr=r(lWt,"rembert"),lWt.forEach(t),Kcr=r(gQe," \u2014 "),PJ=n(gQe,"A",{href:!0});var iWt=s(PJ);emr=r(iWt,"RemBertForSequenceClassification"),iWt.forEach(t),omr=r(gQe," (RemBERT model)"),gQe.forEach(t),rmr=i(D),eM=n(D,"LI",{});var hQe=s(eM);AEe=n(hQe,"STRONG",{});var dWt=s(AEe);tmr=r(dWt,"roberta"),dWt.forEach(t),amr=r(hQe," \u2014 "),BJ=n(hQe,"A",{href:!0});var cWt=s(BJ);nmr=r(cWt,"RobertaForSequenceClassification"),cWt.forEach(t),smr=r(hQe," (RoBERTa model)"),hQe.forEach(t),lmr=i(D),oM=n(D,"LI",{});var uQe=s(oM);LEe=n(uQe,"STRONG",{});var mWt=s(LEe);imr=r(mWt,"roformer"),mWt.forEach(t),dmr=r(uQe," \u2014 "),IJ=n(uQe,"A",{href:!0});var fWt=s(IJ);cmr=r(fWt,"RoFormerForSequenceClassification"),fWt.forEach(t),mmr=r(uQe," (RoFormer model)"),uQe.forEach(t),fmr=i(D),rM=n(D,"LI",{});var pQe=s(rM);yEe=n(pQe,"STRONG",{});var gWt=s(yEe);gmr=r(gWt,"squeezebert"),gWt.forEach(t),hmr=r(pQe," \u2014 "),NJ=n(pQe,"A",{href:!0});var hWt=s(NJ);umr=r(hWt,"SqueezeBertForSequenceClassification"),hWt.forEach(t),pmr=r(pQe," (SqueezeBERT model)"),pQe.forEach(t),_mr=i(D),tM=n(D,"LI",{});var _Qe=s(tM);xEe=n(_Qe,"STRONG",{});var uWt=s(xEe);bmr=r(uWt,"tapas"),uWt.forEach(t),vmr=r(_Qe," \u2014 "),qJ=n(_Qe,"A",{href:!0});var pWt=s(qJ);Fmr=r(pWt,"TapasForSequenceClassification"),pWt.forEach(t),Tmr=r(_Qe," (TAPAS model)"),_Qe.forEach(t),Mmr=i(D),aM=n(D,"LI",{});var bQe=s(aM);$Ee=n(bQe,"STRONG",{});var _Wt=s($Ee);Emr=r(_Wt,"transfo-xl"),_Wt.forEach(t),Cmr=r(bQe," \u2014 "),jJ=n(bQe,"A",{href:!0});var bWt=s(jJ);wmr=r(bWt,"TransfoXLForSequenceClassification"),bWt.forEach(t),Amr=r(bQe," (Transformer-XL model)"),bQe.forEach(t),Lmr=i(D),nM=n(D,"LI",{});var vQe=s(nM);kEe=n(vQe,"STRONG",{});var vWt=s(kEe);ymr=r(vWt,"xlm"),vWt.forEach(t),xmr=r(vQe," \u2014 "),DJ=n(vQe,"A",{href:!0});var FWt=s(DJ);$mr=r(FWt,"XLMForSequenceClassification"),FWt.forEach(t),kmr=r(vQe," (XLM model)"),vQe.forEach(t),Smr=i(D),sM=n(D,"LI",{});var FQe=s(sM);SEe=n(FQe,"STRONG",{});var TWt=s(SEe);Rmr=r(TWt,"xlm-roberta"),TWt.forEach(t),Pmr=r(FQe," \u2014 "),GJ=n(FQe,"A",{href:!0});var MWt=s(GJ);Bmr=r(MWt,"XLMRobertaForSequenceClassification"),MWt.forEach(t),Imr=r(FQe," (XLM-RoBERTa model)"),FQe.forEach(t),Nmr=i(D),lM=n(D,"LI",{});var TQe=s(lM);REe=n(TQe,"STRONG",{});var EWt=s(REe);qmr=r(EWt,"xlm-roberta-xl"),EWt.forEach(t),jmr=r(TQe," \u2014 "),OJ=n(TQe,"A",{href:!0});var CWt=s(OJ);Dmr=r(CWt,"XLMRobertaXLForSequenceClassification"),CWt.forEach(t),Gmr=r(TQe," (XLM-RoBERTa-XL model)"),TQe.forEach(t),Omr=i(D),iM=n(D,"LI",{});var MQe=s(iM);PEe=n(MQe,"STRONG",{});var wWt=s(PEe);Vmr=r(wWt,"xlnet"),wWt.forEach(t),Xmr=r(MQe," \u2014 "),VJ=n(MQe,"A",{href:!0});var AWt=s(VJ);zmr=r(AWt,"XLNetForSequenceClassification"),AWt.forEach(t),Qmr=r(MQe," (XLNet model)"),MQe.forEach(t),Wmr=i(D),dM=n(D,"LI",{});var EQe=s(dM);BEe=n(EQe,"STRONG",{});var LWt=s(BEe);Umr=r(LWt,"yoso"),LWt.forEach(t),Hmr=r(EQe," \u2014 "),XJ=n(EQe,"A",{href:!0});var yWt=s(XJ);Jmr=r(yWt,"YosoForSequenceClassification"),yWt.forEach(t),Ymr=r(EQe," (YOSO model)"),EQe.forEach(t),D.forEach(t),Zmr=i(Sa),cM=n(Sa,"P",{});var CQe=s(cM);Kmr=r(CQe,"The model is set in evaluation mode by default using "),IEe=n(CQe,"CODE",{});var xWt=s(IEe);efr=r(xWt,"model.eval()"),xWt.forEach(t),ofr=r(CQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NEe=n(CQe,"CODE",{});var $Wt=s(NEe);rfr=r($Wt,"model.train()"),$Wt.forEach(t),CQe.forEach(t),tfr=i(Sa),T(mM.$$.fragment,Sa),Sa.forEach(t),Vl.forEach(t),uto=i(m),Yd=n(m,"H2",{class:!0});var Pno=s(Yd);fM=n(Pno,"A",{id:!0,class:!0,href:!0});var kWt=s(fM);qEe=n(kWt,"SPAN",{});var SWt=s(qEe);T(ik.$$.fragment,SWt),SWt.forEach(t),kWt.forEach(t),afr=i(Pno),jEe=n(Pno,"SPAN",{});var RWt=s(jEe);nfr=r(RWt,"AutoModelForMultipleChoice"),RWt.forEach(t),Pno.forEach(t),pto=i(m),Vo=n(m,"DIV",{class:!0});var Xl=s(Vo);T(dk.$$.fragment,Xl),sfr=i(Xl),Zd=n(Xl,"P",{});var Zde=s(Zd);lfr=r(Zde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zJ=n(Zde,"A",{href:!0});var PWt=s(zJ);ifr=r(PWt,"from_pretrained()"),PWt.forEach(t),dfr=r(Zde," class method or the "),QJ=n(Zde,"A",{href:!0});var BWt=s(QJ);cfr=r(BWt,"from_config()"),BWt.forEach(t),mfr=r(Zde,` class
method.`),Zde.forEach(t),ffr=i(Xl),ck=n(Xl,"P",{});var Bno=s(ck);gfr=r(Bno,"This class cannot be instantiated directly using "),DEe=n(Bno,"CODE",{});var IWt=s(DEe);hfr=r(IWt,"__init__()"),IWt.forEach(t),ufr=r(Bno," (throws an error)."),Bno.forEach(t),pfr=i(Xl),yt=n(Xl,"DIV",{class:!0});var a9=s(yt);T(mk.$$.fragment,a9),_fr=i(a9),GEe=n(a9,"P",{});var NWt=s(GEe);bfr=r(NWt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),NWt.forEach(t),vfr=i(a9),Kd=n(a9,"P",{});var Kde=s(Kd);Ffr=r(Kde,`Note:
Loading a model from its configuration file does `),OEe=n(Kde,"STRONG",{});var qWt=s(OEe);Tfr=r(qWt,"not"),qWt.forEach(t),Mfr=r(Kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=n(Kde,"A",{href:!0});var jWt=s(WJ);Efr=r(jWt,"from_pretrained()"),jWt.forEach(t),Cfr=r(Kde," to load the model weights."),Kde.forEach(t),wfr=i(a9),T(gM.$$.fragment,a9),a9.forEach(t),Afr=i(Xl),so=n(Xl,"DIV",{class:!0});var Ra=s(so);T(fk.$$.fragment,Ra),Lfr=i(Ra),VEe=n(Ra,"P",{});var DWt=s(VEe);yfr=r(DWt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),DWt.forEach(t),xfr=i(Ra),fn=n(Ra,"P",{});var n9=s(fn);$fr=r(n9,"The model class to instantiate is selected based on the "),XEe=n(n9,"CODE",{});var GWt=s(XEe);kfr=r(GWt,"model_type"),GWt.forEach(t),Sfr=r(n9,` property of the config object (either
passed as an argument or loaded from `),zEe=n(n9,"CODE",{});var OWt=s(zEe);Rfr=r(OWt,"pretrained_model_name_or_path"),OWt.forEach(t),Pfr=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=n(n9,"CODE",{});var VWt=s(QEe);Bfr=r(VWt,"pretrained_model_name_or_path"),VWt.forEach(t),Ifr=r(n9,":"),n9.forEach(t),Nfr=i(Ra),K=n(Ra,"UL",{});var ee=s(K);hM=n(ee,"LI",{});var wQe=s(hM);WEe=n(wQe,"STRONG",{});var XWt=s(WEe);qfr=r(XWt,"albert"),XWt.forEach(t),jfr=r(wQe," \u2014 "),UJ=n(wQe,"A",{href:!0});var zWt=s(UJ);Dfr=r(zWt,"AlbertForMultipleChoice"),zWt.forEach(t),Gfr=r(wQe," (ALBERT model)"),wQe.forEach(t),Ofr=i(ee),uM=n(ee,"LI",{});var AQe=s(uM);UEe=n(AQe,"STRONG",{});var QWt=s(UEe);Vfr=r(QWt,"bert"),QWt.forEach(t),Xfr=r(AQe," \u2014 "),HJ=n(AQe,"A",{href:!0});var WWt=s(HJ);zfr=r(WWt,"BertForMultipleChoice"),WWt.forEach(t),Qfr=r(AQe," (BERT model)"),AQe.forEach(t),Wfr=i(ee),pM=n(ee,"LI",{});var LQe=s(pM);HEe=n(LQe,"STRONG",{});var UWt=s(HEe);Ufr=r(UWt,"big_bird"),UWt.forEach(t),Hfr=r(LQe," \u2014 "),JJ=n(LQe,"A",{href:!0});var HWt=s(JJ);Jfr=r(HWt,"BigBirdForMultipleChoice"),HWt.forEach(t),Yfr=r(LQe," (BigBird model)"),LQe.forEach(t),Zfr=i(ee),_M=n(ee,"LI",{});var yQe=s(_M);JEe=n(yQe,"STRONG",{});var JWt=s(JEe);Kfr=r(JWt,"camembert"),JWt.forEach(t),egr=r(yQe," \u2014 "),YJ=n(yQe,"A",{href:!0});var YWt=s(YJ);ogr=r(YWt,"CamembertForMultipleChoice"),YWt.forEach(t),rgr=r(yQe," (CamemBERT model)"),yQe.forEach(t),tgr=i(ee),bM=n(ee,"LI",{});var xQe=s(bM);YEe=n(xQe,"STRONG",{});var ZWt=s(YEe);agr=r(ZWt,"canine"),ZWt.forEach(t),ngr=r(xQe," \u2014 "),ZJ=n(xQe,"A",{href:!0});var KWt=s(ZJ);sgr=r(KWt,"CanineForMultipleChoice"),KWt.forEach(t),lgr=r(xQe," (CANINE model)"),xQe.forEach(t),igr=i(ee),vM=n(ee,"LI",{});var $Qe=s(vM);ZEe=n($Qe,"STRONG",{});var eUt=s(ZEe);dgr=r(eUt,"convbert"),eUt.forEach(t),cgr=r($Qe," \u2014 "),KJ=n($Qe,"A",{href:!0});var oUt=s(KJ);mgr=r(oUt,"ConvBertForMultipleChoice"),oUt.forEach(t),fgr=r($Qe," (ConvBERT model)"),$Qe.forEach(t),ggr=i(ee),FM=n(ee,"LI",{});var kQe=s(FM);KEe=n(kQe,"STRONG",{});var rUt=s(KEe);hgr=r(rUt,"data2vec-text"),rUt.forEach(t),ugr=r(kQe," \u2014 "),eY=n(kQe,"A",{href:!0});var tUt=s(eY);pgr=r(tUt,"Data2VecTextForMultipleChoice"),tUt.forEach(t),_gr=r(kQe," (Data2VecText model)"),kQe.forEach(t),bgr=i(ee),TM=n(ee,"LI",{});var SQe=s(TM);e4e=n(SQe,"STRONG",{});var aUt=s(e4e);vgr=r(aUt,"deberta-v2"),aUt.forEach(t),Fgr=r(SQe," \u2014 "),oY=n(SQe,"A",{href:!0});var nUt=s(oY);Tgr=r(nUt,"DebertaV2ForMultipleChoice"),nUt.forEach(t),Mgr=r(SQe," (DeBERTa-v2 model)"),SQe.forEach(t),Egr=i(ee),MM=n(ee,"LI",{});var RQe=s(MM);o4e=n(RQe,"STRONG",{});var sUt=s(o4e);Cgr=r(sUt,"distilbert"),sUt.forEach(t),wgr=r(RQe," \u2014 "),rY=n(RQe,"A",{href:!0});var lUt=s(rY);Agr=r(lUt,"DistilBertForMultipleChoice"),lUt.forEach(t),Lgr=r(RQe," (DistilBERT model)"),RQe.forEach(t),ygr=i(ee),EM=n(ee,"LI",{});var PQe=s(EM);r4e=n(PQe,"STRONG",{});var iUt=s(r4e);xgr=r(iUt,"electra"),iUt.forEach(t),$gr=r(PQe," \u2014 "),tY=n(PQe,"A",{href:!0});var dUt=s(tY);kgr=r(dUt,"ElectraForMultipleChoice"),dUt.forEach(t),Sgr=r(PQe," (ELECTRA model)"),PQe.forEach(t),Rgr=i(ee),CM=n(ee,"LI",{});var BQe=s(CM);t4e=n(BQe,"STRONG",{});var cUt=s(t4e);Pgr=r(cUt,"ernie"),cUt.forEach(t),Bgr=r(BQe," \u2014 "),aY=n(BQe,"A",{href:!0});var mUt=s(aY);Igr=r(mUt,"ErnieForMultipleChoice"),mUt.forEach(t),Ngr=r(BQe," (ERNIE model)"),BQe.forEach(t),qgr=i(ee),wM=n(ee,"LI",{});var IQe=s(wM);a4e=n(IQe,"STRONG",{});var fUt=s(a4e);jgr=r(fUt,"flaubert"),fUt.forEach(t),Dgr=r(IQe," \u2014 "),nY=n(IQe,"A",{href:!0});var gUt=s(nY);Ggr=r(gUt,"FlaubertForMultipleChoice"),gUt.forEach(t),Ogr=r(IQe," (FlauBERT model)"),IQe.forEach(t),Vgr=i(ee),AM=n(ee,"LI",{});var NQe=s(AM);n4e=n(NQe,"STRONG",{});var hUt=s(n4e);Xgr=r(hUt,"fnet"),hUt.forEach(t),zgr=r(NQe," \u2014 "),sY=n(NQe,"A",{href:!0});var uUt=s(sY);Qgr=r(uUt,"FNetForMultipleChoice"),uUt.forEach(t),Wgr=r(NQe," (FNet model)"),NQe.forEach(t),Ugr=i(ee),LM=n(ee,"LI",{});var qQe=s(LM);s4e=n(qQe,"STRONG",{});var pUt=s(s4e);Hgr=r(pUt,"funnel"),pUt.forEach(t),Jgr=r(qQe," \u2014 "),lY=n(qQe,"A",{href:!0});var _Ut=s(lY);Ygr=r(_Ut,"FunnelForMultipleChoice"),_Ut.forEach(t),Zgr=r(qQe," (Funnel Transformer model)"),qQe.forEach(t),Kgr=i(ee),yM=n(ee,"LI",{});var jQe=s(yM);l4e=n(jQe,"STRONG",{});var bUt=s(l4e);ehr=r(bUt,"ibert"),bUt.forEach(t),ohr=r(jQe," \u2014 "),iY=n(jQe,"A",{href:!0});var vUt=s(iY);rhr=r(vUt,"IBertForMultipleChoice"),vUt.forEach(t),thr=r(jQe," (I-BERT model)"),jQe.forEach(t),ahr=i(ee),xM=n(ee,"LI",{});var DQe=s(xM);i4e=n(DQe,"STRONG",{});var FUt=s(i4e);nhr=r(FUt,"longformer"),FUt.forEach(t),shr=r(DQe," \u2014 "),dY=n(DQe,"A",{href:!0});var TUt=s(dY);lhr=r(TUt,"LongformerForMultipleChoice"),TUt.forEach(t),ihr=r(DQe," (Longformer model)"),DQe.forEach(t),dhr=i(ee),$M=n(ee,"LI",{});var GQe=s($M);d4e=n(GQe,"STRONG",{});var MUt=s(d4e);chr=r(MUt,"luke"),MUt.forEach(t),mhr=r(GQe," \u2014 "),cY=n(GQe,"A",{href:!0});var EUt=s(cY);fhr=r(EUt,"LukeForMultipleChoice"),EUt.forEach(t),ghr=r(GQe," (LUKE model)"),GQe.forEach(t),hhr=i(ee),kM=n(ee,"LI",{});var OQe=s(kM);c4e=n(OQe,"STRONG",{});var CUt=s(c4e);uhr=r(CUt,"megatron-bert"),CUt.forEach(t),phr=r(OQe," \u2014 "),mY=n(OQe,"A",{href:!0});var wUt=s(mY);_hr=r(wUt,"MegatronBertForMultipleChoice"),wUt.forEach(t),bhr=r(OQe," (Megatron-BERT model)"),OQe.forEach(t),vhr=i(ee),SM=n(ee,"LI",{});var VQe=s(SM);m4e=n(VQe,"STRONG",{});var AUt=s(m4e);Fhr=r(AUt,"mobilebert"),AUt.forEach(t),Thr=r(VQe," \u2014 "),fY=n(VQe,"A",{href:!0});var LUt=s(fY);Mhr=r(LUt,"MobileBertForMultipleChoice"),LUt.forEach(t),Ehr=r(VQe," (MobileBERT model)"),VQe.forEach(t),Chr=i(ee),RM=n(ee,"LI",{});var XQe=s(RM);f4e=n(XQe,"STRONG",{});var yUt=s(f4e);whr=r(yUt,"mpnet"),yUt.forEach(t),Ahr=r(XQe," \u2014 "),gY=n(XQe,"A",{href:!0});var xUt=s(gY);Lhr=r(xUt,"MPNetForMultipleChoice"),xUt.forEach(t),yhr=r(XQe," (MPNet model)"),XQe.forEach(t),xhr=i(ee),PM=n(ee,"LI",{});var zQe=s(PM);g4e=n(zQe,"STRONG",{});var $Ut=s(g4e);$hr=r($Ut,"nezha"),$Ut.forEach(t),khr=r(zQe," \u2014 "),hY=n(zQe,"A",{href:!0});var kUt=s(hY);Shr=r(kUt,"NezhaForMultipleChoice"),kUt.forEach(t),Rhr=r(zQe," (Nezha model)"),zQe.forEach(t),Phr=i(ee),BM=n(ee,"LI",{});var QQe=s(BM);h4e=n(QQe,"STRONG",{});var SUt=s(h4e);Bhr=r(SUt,"nystromformer"),SUt.forEach(t),Ihr=r(QQe," \u2014 "),uY=n(QQe,"A",{href:!0});var RUt=s(uY);Nhr=r(RUt,"NystromformerForMultipleChoice"),RUt.forEach(t),qhr=r(QQe," (Nystr\xF6mformer model)"),QQe.forEach(t),jhr=i(ee),IM=n(ee,"LI",{});var WQe=s(IM);u4e=n(WQe,"STRONG",{});var PUt=s(u4e);Dhr=r(PUt,"qdqbert"),PUt.forEach(t),Ghr=r(WQe," \u2014 "),pY=n(WQe,"A",{href:!0});var BUt=s(pY);Ohr=r(BUt,"QDQBertForMultipleChoice"),BUt.forEach(t),Vhr=r(WQe," (QDQBert model)"),WQe.forEach(t),Xhr=i(ee),NM=n(ee,"LI",{});var UQe=s(NM);p4e=n(UQe,"STRONG",{});var IUt=s(p4e);zhr=r(IUt,"rembert"),IUt.forEach(t),Qhr=r(UQe," \u2014 "),_Y=n(UQe,"A",{href:!0});var NUt=s(_Y);Whr=r(NUt,"RemBertForMultipleChoice"),NUt.forEach(t),Uhr=r(UQe," (RemBERT model)"),UQe.forEach(t),Hhr=i(ee),qM=n(ee,"LI",{});var HQe=s(qM);_4e=n(HQe,"STRONG",{});var qUt=s(_4e);Jhr=r(qUt,"roberta"),qUt.forEach(t),Yhr=r(HQe," \u2014 "),bY=n(HQe,"A",{href:!0});var jUt=s(bY);Zhr=r(jUt,"RobertaForMultipleChoice"),jUt.forEach(t),Khr=r(HQe," (RoBERTa model)"),HQe.forEach(t),eur=i(ee),jM=n(ee,"LI",{});var JQe=s(jM);b4e=n(JQe,"STRONG",{});var DUt=s(b4e);our=r(DUt,"roformer"),DUt.forEach(t),rur=r(JQe," \u2014 "),vY=n(JQe,"A",{href:!0});var GUt=s(vY);tur=r(GUt,"RoFormerForMultipleChoice"),GUt.forEach(t),aur=r(JQe," (RoFormer model)"),JQe.forEach(t),nur=i(ee),DM=n(ee,"LI",{});var YQe=s(DM);v4e=n(YQe,"STRONG",{});var OUt=s(v4e);sur=r(OUt,"squeezebert"),OUt.forEach(t),lur=r(YQe," \u2014 "),FY=n(YQe,"A",{href:!0});var VUt=s(FY);iur=r(VUt,"SqueezeBertForMultipleChoice"),VUt.forEach(t),dur=r(YQe," (SqueezeBERT model)"),YQe.forEach(t),cur=i(ee),GM=n(ee,"LI",{});var ZQe=s(GM);F4e=n(ZQe,"STRONG",{});var XUt=s(F4e);mur=r(XUt,"xlm"),XUt.forEach(t),fur=r(ZQe," \u2014 "),TY=n(ZQe,"A",{href:!0});var zUt=s(TY);gur=r(zUt,"XLMForMultipleChoice"),zUt.forEach(t),hur=r(ZQe," (XLM model)"),ZQe.forEach(t),uur=i(ee),OM=n(ee,"LI",{});var KQe=s(OM);T4e=n(KQe,"STRONG",{});var QUt=s(T4e);pur=r(QUt,"xlm-roberta"),QUt.forEach(t),_ur=r(KQe," \u2014 "),MY=n(KQe,"A",{href:!0});var WUt=s(MY);bur=r(WUt,"XLMRobertaForMultipleChoice"),WUt.forEach(t),vur=r(KQe," (XLM-RoBERTa model)"),KQe.forEach(t),Fur=i(ee),VM=n(ee,"LI",{});var eWe=s(VM);M4e=n(eWe,"STRONG",{});var UUt=s(M4e);Tur=r(UUt,"xlm-roberta-xl"),UUt.forEach(t),Mur=r(eWe," \u2014 "),EY=n(eWe,"A",{href:!0});var HUt=s(EY);Eur=r(HUt,"XLMRobertaXLForMultipleChoice"),HUt.forEach(t),Cur=r(eWe," (XLM-RoBERTa-XL model)"),eWe.forEach(t),wur=i(ee),XM=n(ee,"LI",{});var oWe=s(XM);E4e=n(oWe,"STRONG",{});var JUt=s(E4e);Aur=r(JUt,"xlnet"),JUt.forEach(t),Lur=r(oWe," \u2014 "),CY=n(oWe,"A",{href:!0});var YUt=s(CY);yur=r(YUt,"XLNetForMultipleChoice"),YUt.forEach(t),xur=r(oWe," (XLNet model)"),oWe.forEach(t),$ur=i(ee),zM=n(ee,"LI",{});var rWe=s(zM);C4e=n(rWe,"STRONG",{});var ZUt=s(C4e);kur=r(ZUt,"yoso"),ZUt.forEach(t),Sur=r(rWe," \u2014 "),wY=n(rWe,"A",{href:!0});var KUt=s(wY);Rur=r(KUt,"YosoForMultipleChoice"),KUt.forEach(t),Pur=r(rWe," (YOSO model)"),rWe.forEach(t),ee.forEach(t),Bur=i(Ra),QM=n(Ra,"P",{});var tWe=s(QM);Iur=r(tWe,"The model is set in evaluation mode by default using "),w4e=n(tWe,"CODE",{});var eHt=s(w4e);Nur=r(eHt,"model.eval()"),eHt.forEach(t),qur=r(tWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A4e=n(tWe,"CODE",{});var oHt=s(A4e);jur=r(oHt,"model.train()"),oHt.forEach(t),tWe.forEach(t),Dur=i(Ra),T(WM.$$.fragment,Ra),Ra.forEach(t),Xl.forEach(t),_to=i(m),ec=n(m,"H2",{class:!0});var Ino=s(ec);UM=n(Ino,"A",{id:!0,class:!0,href:!0});var rHt=s(UM);L4e=n(rHt,"SPAN",{});var tHt=s(L4e);T(gk.$$.fragment,tHt),tHt.forEach(t),rHt.forEach(t),Gur=i(Ino),y4e=n(Ino,"SPAN",{});var aHt=s(y4e);Our=r(aHt,"AutoModelForNextSentencePrediction"),aHt.forEach(t),Ino.forEach(t),bto=i(m),Xo=n(m,"DIV",{class:!0});var zl=s(Xo);T(hk.$$.fragment,zl),Vur=i(zl),oc=n(zl,"P",{});var ece=s(oc);Xur=r(ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),AY=n(ece,"A",{href:!0});var nHt=s(AY);zur=r(nHt,"from_pretrained()"),nHt.forEach(t),Qur=r(ece," class method or the "),LY=n(ece,"A",{href:!0});var sHt=s(LY);Wur=r(sHt,"from_config()"),sHt.forEach(t),Uur=r(ece,` class
method.`),ece.forEach(t),Hur=i(zl),uk=n(zl,"P",{});var Nno=s(uk);Jur=r(Nno,"This class cannot be instantiated directly using "),x4e=n(Nno,"CODE",{});var lHt=s(x4e);Yur=r(lHt,"__init__()"),lHt.forEach(t),Zur=r(Nno," (throws an error)."),Nno.forEach(t),Kur=i(zl),xt=n(zl,"DIV",{class:!0});var s9=s(xt);T(pk.$$.fragment,s9),epr=i(s9),$4e=n(s9,"P",{});var iHt=s($4e);opr=r(iHt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),iHt.forEach(t),rpr=i(s9),rc=n(s9,"P",{});var oce=s(rc);tpr=r(oce,`Note:
Loading a model from its configuration file does `),k4e=n(oce,"STRONG",{});var dHt=s(k4e);apr=r(dHt,"not"),dHt.forEach(t),npr=r(oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=n(oce,"A",{href:!0});var cHt=s(yY);spr=r(cHt,"from_pretrained()"),cHt.forEach(t),lpr=r(oce," to load the model weights."),oce.forEach(t),ipr=i(s9),T(HM.$$.fragment,s9),s9.forEach(t),dpr=i(zl),lo=n(zl,"DIV",{class:!0});var Pa=s(lo);T(_k.$$.fragment,Pa),cpr=i(Pa),S4e=n(Pa,"P",{});var mHt=s(S4e);mpr=r(mHt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),mHt.forEach(t),fpr=i(Pa),gn=n(Pa,"P",{});var l9=s(gn);gpr=r(l9,"The model class to instantiate is selected based on the "),R4e=n(l9,"CODE",{});var fHt=s(R4e);hpr=r(fHt,"model_type"),fHt.forEach(t),upr=r(l9,` property of the config object (either
passed as an argument or loaded from `),P4e=n(l9,"CODE",{});var gHt=s(P4e);ppr=r(gHt,"pretrained_model_name_or_path"),gHt.forEach(t),_pr=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=n(l9,"CODE",{});var hHt=s(B4e);bpr=r(hHt,"pretrained_model_name_or_path"),hHt.forEach(t),vpr=r(l9,":"),l9.forEach(t),Fpr=i(Pa),Ue=n(Pa,"UL",{});var ht=s(Ue);JM=n(ht,"LI",{});var aWe=s(JM);I4e=n(aWe,"STRONG",{});var uHt=s(I4e);Tpr=r(uHt,"bert"),uHt.forEach(t),Mpr=r(aWe," \u2014 "),xY=n(aWe,"A",{href:!0});var pHt=s(xY);Epr=r(pHt,"BertForNextSentencePrediction"),pHt.forEach(t),Cpr=r(aWe," (BERT model)"),aWe.forEach(t),wpr=i(ht),YM=n(ht,"LI",{});var nWe=s(YM);N4e=n(nWe,"STRONG",{});var _Ht=s(N4e);Apr=r(_Ht,"ernie"),_Ht.forEach(t),Lpr=r(nWe," \u2014 "),$Y=n(nWe,"A",{href:!0});var bHt=s($Y);ypr=r(bHt,"ErnieForNextSentencePrediction"),bHt.forEach(t),xpr=r(nWe," (ERNIE model)"),nWe.forEach(t),$pr=i(ht),ZM=n(ht,"LI",{});var sWe=s(ZM);q4e=n(sWe,"STRONG",{});var vHt=s(q4e);kpr=r(vHt,"fnet"),vHt.forEach(t),Spr=r(sWe," \u2014 "),kY=n(sWe,"A",{href:!0});var FHt=s(kY);Rpr=r(FHt,"FNetForNextSentencePrediction"),FHt.forEach(t),Ppr=r(sWe," (FNet model)"),sWe.forEach(t),Bpr=i(ht),KM=n(ht,"LI",{});var lWe=s(KM);j4e=n(lWe,"STRONG",{});var THt=s(j4e);Ipr=r(THt,"megatron-bert"),THt.forEach(t),Npr=r(lWe," \u2014 "),SY=n(lWe,"A",{href:!0});var MHt=s(SY);qpr=r(MHt,"MegatronBertForNextSentencePrediction"),MHt.forEach(t),jpr=r(lWe," (Megatron-BERT model)"),lWe.forEach(t),Dpr=i(ht),eE=n(ht,"LI",{});var iWe=s(eE);D4e=n(iWe,"STRONG",{});var EHt=s(D4e);Gpr=r(EHt,"mobilebert"),EHt.forEach(t),Opr=r(iWe," \u2014 "),RY=n(iWe,"A",{href:!0});var CHt=s(RY);Vpr=r(CHt,"MobileBertForNextSentencePrediction"),CHt.forEach(t),Xpr=r(iWe," (MobileBERT model)"),iWe.forEach(t),zpr=i(ht),oE=n(ht,"LI",{});var dWe=s(oE);G4e=n(dWe,"STRONG",{});var wHt=s(G4e);Qpr=r(wHt,"nezha"),wHt.forEach(t),Wpr=r(dWe," \u2014 "),PY=n(dWe,"A",{href:!0});var AHt=s(PY);Upr=r(AHt,"NezhaForNextSentencePrediction"),AHt.forEach(t),Hpr=r(dWe," (Nezha model)"),dWe.forEach(t),Jpr=i(ht),rE=n(ht,"LI",{});var cWe=s(rE);O4e=n(cWe,"STRONG",{});var LHt=s(O4e);Ypr=r(LHt,"qdqbert"),LHt.forEach(t),Zpr=r(cWe," \u2014 "),BY=n(cWe,"A",{href:!0});var yHt=s(BY);Kpr=r(yHt,"QDQBertForNextSentencePrediction"),yHt.forEach(t),e_r=r(cWe," (QDQBert model)"),cWe.forEach(t),ht.forEach(t),o_r=i(Pa),tE=n(Pa,"P",{});var mWe=s(tE);r_r=r(mWe,"The model is set in evaluation mode by default using "),V4e=n(mWe,"CODE",{});var xHt=s(V4e);t_r=r(xHt,"model.eval()"),xHt.forEach(t),a_r=r(mWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X4e=n(mWe,"CODE",{});var $Ht=s(X4e);n_r=r($Ht,"model.train()"),$Ht.forEach(t),mWe.forEach(t),s_r=i(Pa),T(aE.$$.fragment,Pa),Pa.forEach(t),zl.forEach(t),vto=i(m),tc=n(m,"H2",{class:!0});var qno=s(tc);nE=n(qno,"A",{id:!0,class:!0,href:!0});var kHt=s(nE);z4e=n(kHt,"SPAN",{});var SHt=s(z4e);T(bk.$$.fragment,SHt),SHt.forEach(t),kHt.forEach(t),l_r=i(qno),Q4e=n(qno,"SPAN",{});var RHt=s(Q4e);i_r=r(RHt,"AutoModelForTokenClassification"),RHt.forEach(t),qno.forEach(t),Fto=i(m),zo=n(m,"DIV",{class:!0});var Ql=s(zo);T(vk.$$.fragment,Ql),d_r=i(Ql),ac=n(Ql,"P",{});var rce=s(ac);c_r=r(rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),IY=n(rce,"A",{href:!0});var PHt=s(IY);m_r=r(PHt,"from_pretrained()"),PHt.forEach(t),f_r=r(rce," class method or the "),NY=n(rce,"A",{href:!0});var BHt=s(NY);g_r=r(BHt,"from_config()"),BHt.forEach(t),h_r=r(rce,` class
method.`),rce.forEach(t),u_r=i(Ql),Fk=n(Ql,"P",{});var jno=s(Fk);p_r=r(jno,"This class cannot be instantiated directly using "),W4e=n(jno,"CODE",{});var IHt=s(W4e);__r=r(IHt,"__init__()"),IHt.forEach(t),b_r=r(jno," (throws an error)."),jno.forEach(t),v_r=i(Ql),$t=n(Ql,"DIV",{class:!0});var i9=s($t);T(Tk.$$.fragment,i9),F_r=i(i9),U4e=n(i9,"P",{});var NHt=s(U4e);T_r=r(NHt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),NHt.forEach(t),M_r=i(i9),nc=n(i9,"P",{});var tce=s(nc);E_r=r(tce,`Note:
Loading a model from its configuration file does `),H4e=n(tce,"STRONG",{});var qHt=s(H4e);C_r=r(qHt,"not"),qHt.forEach(t),w_r=r(tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),qY=n(tce,"A",{href:!0});var jHt=s(qY);A_r=r(jHt,"from_pretrained()"),jHt.forEach(t),L_r=r(tce," to load the model weights."),tce.forEach(t),y_r=i(i9),T(sE.$$.fragment,i9),i9.forEach(t),x_r=i(Ql),io=n(Ql,"DIV",{class:!0});var Ba=s(io);T(Mk.$$.fragment,Ba),$_r=i(Ba),J4e=n(Ba,"P",{});var DHt=s(J4e);k_r=r(DHt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),DHt.forEach(t),S_r=i(Ba),hn=n(Ba,"P",{});var d9=s(hn);R_r=r(d9,"The model class to instantiate is selected based on the "),Y4e=n(d9,"CODE",{});var GHt=s(Y4e);P_r=r(GHt,"model_type"),GHt.forEach(t),B_r=r(d9,` property of the config object (either
passed as an argument or loaded from `),Z4e=n(d9,"CODE",{});var OHt=s(Z4e);I_r=r(OHt,"pretrained_model_name_or_path"),OHt.forEach(t),N_r=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=n(d9,"CODE",{});var VHt=s(K4e);q_r=r(VHt,"pretrained_model_name_or_path"),VHt.forEach(t),j_r=r(d9,":"),d9.forEach(t),D_r=i(Ba),U=n(Ba,"UL",{});var J=s(U);lE=n(J,"LI",{});var fWe=s(lE);eCe=n(fWe,"STRONG",{});var XHt=s(eCe);G_r=r(XHt,"albert"),XHt.forEach(t),O_r=r(fWe," \u2014 "),jY=n(fWe,"A",{href:!0});var zHt=s(jY);V_r=r(zHt,"AlbertForTokenClassification"),zHt.forEach(t),X_r=r(fWe," (ALBERT model)"),fWe.forEach(t),z_r=i(J),iE=n(J,"LI",{});var gWe=s(iE);oCe=n(gWe,"STRONG",{});var QHt=s(oCe);Q_r=r(QHt,"bert"),QHt.forEach(t),W_r=r(gWe," \u2014 "),DY=n(gWe,"A",{href:!0});var WHt=s(DY);U_r=r(WHt,"BertForTokenClassification"),WHt.forEach(t),H_r=r(gWe," (BERT model)"),gWe.forEach(t),J_r=i(J),dE=n(J,"LI",{});var hWe=s(dE);rCe=n(hWe,"STRONG",{});var UHt=s(rCe);Y_r=r(UHt,"big_bird"),UHt.forEach(t),Z_r=r(hWe," \u2014 "),GY=n(hWe,"A",{href:!0});var HHt=s(GY);K_r=r(HHt,"BigBirdForTokenClassification"),HHt.forEach(t),e1r=r(hWe," (BigBird model)"),hWe.forEach(t),o1r=i(J),cE=n(J,"LI",{});var uWe=s(cE);tCe=n(uWe,"STRONG",{});var JHt=s(tCe);r1r=r(JHt,"bloom"),JHt.forEach(t),t1r=r(uWe," \u2014 "),OY=n(uWe,"A",{href:!0});var YHt=s(OY);a1r=r(YHt,"BloomForTokenClassification"),YHt.forEach(t),n1r=r(uWe," (BLOOM model)"),uWe.forEach(t),s1r=i(J),mE=n(J,"LI",{});var pWe=s(mE);aCe=n(pWe,"STRONG",{});var ZHt=s(aCe);l1r=r(ZHt,"camembert"),ZHt.forEach(t),i1r=r(pWe," \u2014 "),VY=n(pWe,"A",{href:!0});var KHt=s(VY);d1r=r(KHt,"CamembertForTokenClassification"),KHt.forEach(t),c1r=r(pWe," (CamemBERT model)"),pWe.forEach(t),m1r=i(J),fE=n(J,"LI",{});var _We=s(fE);nCe=n(_We,"STRONG",{});var eJt=s(nCe);f1r=r(eJt,"canine"),eJt.forEach(t),g1r=r(_We," \u2014 "),XY=n(_We,"A",{href:!0});var oJt=s(XY);h1r=r(oJt,"CanineForTokenClassification"),oJt.forEach(t),u1r=r(_We," (CANINE model)"),_We.forEach(t),p1r=i(J),gE=n(J,"LI",{});var bWe=s(gE);sCe=n(bWe,"STRONG",{});var rJt=s(sCe);_1r=r(rJt,"convbert"),rJt.forEach(t),b1r=r(bWe," \u2014 "),zY=n(bWe,"A",{href:!0});var tJt=s(zY);v1r=r(tJt,"ConvBertForTokenClassification"),tJt.forEach(t),F1r=r(bWe," (ConvBERT model)"),bWe.forEach(t),T1r=i(J),hE=n(J,"LI",{});var vWe=s(hE);lCe=n(vWe,"STRONG",{});var aJt=s(lCe);M1r=r(aJt,"data2vec-text"),aJt.forEach(t),E1r=r(vWe," \u2014 "),QY=n(vWe,"A",{href:!0});var nJt=s(QY);C1r=r(nJt,"Data2VecTextForTokenClassification"),nJt.forEach(t),w1r=r(vWe," (Data2VecText model)"),vWe.forEach(t),A1r=i(J),uE=n(J,"LI",{});var FWe=s(uE);iCe=n(FWe,"STRONG",{});var sJt=s(iCe);L1r=r(sJt,"deberta"),sJt.forEach(t),y1r=r(FWe," \u2014 "),WY=n(FWe,"A",{href:!0});var lJt=s(WY);x1r=r(lJt,"DebertaForTokenClassification"),lJt.forEach(t),$1r=r(FWe," (DeBERTa model)"),FWe.forEach(t),k1r=i(J),pE=n(J,"LI",{});var TWe=s(pE);dCe=n(TWe,"STRONG",{});var iJt=s(dCe);S1r=r(iJt,"deberta-v2"),iJt.forEach(t),R1r=r(TWe," \u2014 "),UY=n(TWe,"A",{href:!0});var dJt=s(UY);P1r=r(dJt,"DebertaV2ForTokenClassification"),dJt.forEach(t),B1r=r(TWe," (DeBERTa-v2 model)"),TWe.forEach(t),I1r=i(J),_E=n(J,"LI",{});var MWe=s(_E);cCe=n(MWe,"STRONG",{});var cJt=s(cCe);N1r=r(cJt,"distilbert"),cJt.forEach(t),q1r=r(MWe," \u2014 "),HY=n(MWe,"A",{href:!0});var mJt=s(HY);j1r=r(mJt,"DistilBertForTokenClassification"),mJt.forEach(t),D1r=r(MWe," (DistilBERT model)"),MWe.forEach(t),G1r=i(J),bE=n(J,"LI",{});var EWe=s(bE);mCe=n(EWe,"STRONG",{});var fJt=s(mCe);O1r=r(fJt,"electra"),fJt.forEach(t),V1r=r(EWe," \u2014 "),JY=n(EWe,"A",{href:!0});var gJt=s(JY);X1r=r(gJt,"ElectraForTokenClassification"),gJt.forEach(t),z1r=r(EWe," (ELECTRA model)"),EWe.forEach(t),Q1r=i(J),vE=n(J,"LI",{});var CWe=s(vE);fCe=n(CWe,"STRONG",{});var hJt=s(fCe);W1r=r(hJt,"ernie"),hJt.forEach(t),U1r=r(CWe," \u2014 "),YY=n(CWe,"A",{href:!0});var uJt=s(YY);H1r=r(uJt,"ErnieForTokenClassification"),uJt.forEach(t),J1r=r(CWe," (ERNIE model)"),CWe.forEach(t),Y1r=i(J),FE=n(J,"LI",{});var wWe=s(FE);gCe=n(wWe,"STRONG",{});var pJt=s(gCe);Z1r=r(pJt,"esm"),pJt.forEach(t),K1r=r(wWe," \u2014 "),ZY=n(wWe,"A",{href:!0});var _Jt=s(ZY);e2r=r(_Jt,"EsmForTokenClassification"),_Jt.forEach(t),o2r=r(wWe," (ESM model)"),wWe.forEach(t),r2r=i(J),TE=n(J,"LI",{});var AWe=s(TE);hCe=n(AWe,"STRONG",{});var bJt=s(hCe);t2r=r(bJt,"flaubert"),bJt.forEach(t),a2r=r(AWe," \u2014 "),KY=n(AWe,"A",{href:!0});var vJt=s(KY);n2r=r(vJt,"FlaubertForTokenClassification"),vJt.forEach(t),s2r=r(AWe," (FlauBERT model)"),AWe.forEach(t),l2r=i(J),ME=n(J,"LI",{});var LWe=s(ME);uCe=n(LWe,"STRONG",{});var FJt=s(uCe);i2r=r(FJt,"fnet"),FJt.forEach(t),d2r=r(LWe," \u2014 "),eZ=n(LWe,"A",{href:!0});var TJt=s(eZ);c2r=r(TJt,"FNetForTokenClassification"),TJt.forEach(t),m2r=r(LWe," (FNet model)"),LWe.forEach(t),f2r=i(J),EE=n(J,"LI",{});var yWe=s(EE);pCe=n(yWe,"STRONG",{});var MJt=s(pCe);g2r=r(MJt,"funnel"),MJt.forEach(t),h2r=r(yWe," \u2014 "),oZ=n(yWe,"A",{href:!0});var EJt=s(oZ);u2r=r(EJt,"FunnelForTokenClassification"),EJt.forEach(t),p2r=r(yWe," (Funnel Transformer model)"),yWe.forEach(t),_2r=i(J),CE=n(J,"LI",{});var xWe=s(CE);_Ce=n(xWe,"STRONG",{});var CJt=s(_Ce);b2r=r(CJt,"gpt2"),CJt.forEach(t),v2r=r(xWe," \u2014 "),rZ=n(xWe,"A",{href:!0});var wJt=s(rZ);F2r=r(wJt,"GPT2ForTokenClassification"),wJt.forEach(t),T2r=r(xWe," (OpenAI GPT-2 model)"),xWe.forEach(t),M2r=i(J),wE=n(J,"LI",{});var $We=s(wE);bCe=n($We,"STRONG",{});var AJt=s(bCe);E2r=r(AJt,"ibert"),AJt.forEach(t),C2r=r($We," \u2014 "),tZ=n($We,"A",{href:!0});var LJt=s(tZ);w2r=r(LJt,"IBertForTokenClassification"),LJt.forEach(t),A2r=r($We," (I-BERT model)"),$We.forEach(t),L2r=i(J),AE=n(J,"LI",{});var kWe=s(AE);vCe=n(kWe,"STRONG",{});var yJt=s(vCe);y2r=r(yJt,"layoutlm"),yJt.forEach(t),x2r=r(kWe," \u2014 "),aZ=n(kWe,"A",{href:!0});var xJt=s(aZ);$2r=r(xJt,"LayoutLMForTokenClassification"),xJt.forEach(t),k2r=r(kWe," (LayoutLM model)"),kWe.forEach(t),S2r=i(J),LE=n(J,"LI",{});var SWe=s(LE);FCe=n(SWe,"STRONG",{});var $Jt=s(FCe);R2r=r($Jt,"layoutlmv2"),$Jt.forEach(t),P2r=r(SWe," \u2014 "),nZ=n(SWe,"A",{href:!0});var kJt=s(nZ);B2r=r(kJt,"LayoutLMv2ForTokenClassification"),kJt.forEach(t),I2r=r(SWe," (LayoutLMv2 model)"),SWe.forEach(t),N2r=i(J),yE=n(J,"LI",{});var RWe=s(yE);TCe=n(RWe,"STRONG",{});var SJt=s(TCe);q2r=r(SJt,"layoutlmv3"),SJt.forEach(t),j2r=r(RWe," \u2014 "),sZ=n(RWe,"A",{href:!0});var RJt=s(sZ);D2r=r(RJt,"LayoutLMv3ForTokenClassification"),RJt.forEach(t),G2r=r(RWe," (LayoutLMv3 model)"),RWe.forEach(t),O2r=i(J),xE=n(J,"LI",{});var PWe=s(xE);MCe=n(PWe,"STRONG",{});var PJt=s(MCe);V2r=r(PJt,"lilt"),PJt.forEach(t),X2r=r(PWe," \u2014 "),lZ=n(PWe,"A",{href:!0});var BJt=s(lZ);z2r=r(BJt,"LiltForTokenClassification"),BJt.forEach(t),Q2r=r(PWe," (LiLT model)"),PWe.forEach(t),W2r=i(J),$E=n(J,"LI",{});var BWe=s($E);ECe=n(BWe,"STRONG",{});var IJt=s(ECe);U2r=r(IJt,"longformer"),IJt.forEach(t),H2r=r(BWe," \u2014 "),iZ=n(BWe,"A",{href:!0});var NJt=s(iZ);J2r=r(NJt,"LongformerForTokenClassification"),NJt.forEach(t),Y2r=r(BWe," (Longformer model)"),BWe.forEach(t),Z2r=i(J),kE=n(J,"LI",{});var IWe=s(kE);CCe=n(IWe,"STRONG",{});var qJt=s(CCe);K2r=r(qJt,"luke"),qJt.forEach(t),ebr=r(IWe," \u2014 "),dZ=n(IWe,"A",{href:!0});var jJt=s(dZ);obr=r(jJt,"LukeForTokenClassification"),jJt.forEach(t),rbr=r(IWe," (LUKE model)"),IWe.forEach(t),tbr=i(J),SE=n(J,"LI",{});var NWe=s(SE);wCe=n(NWe,"STRONG",{});var DJt=s(wCe);abr=r(DJt,"markuplm"),DJt.forEach(t),nbr=r(NWe," \u2014 "),cZ=n(NWe,"A",{href:!0});var GJt=s(cZ);sbr=r(GJt,"MarkupLMForTokenClassification"),GJt.forEach(t),lbr=r(NWe," (MarkupLM model)"),NWe.forEach(t),ibr=i(J),RE=n(J,"LI",{});var qWe=s(RE);ACe=n(qWe,"STRONG",{});var OJt=s(ACe);dbr=r(OJt,"megatron-bert"),OJt.forEach(t),cbr=r(qWe," \u2014 "),mZ=n(qWe,"A",{href:!0});var VJt=s(mZ);mbr=r(VJt,"MegatronBertForTokenClassification"),VJt.forEach(t),fbr=r(qWe," (Megatron-BERT model)"),qWe.forEach(t),gbr=i(J),PE=n(J,"LI",{});var jWe=s(PE);LCe=n(jWe,"STRONG",{});var XJt=s(LCe);hbr=r(XJt,"mobilebert"),XJt.forEach(t),ubr=r(jWe," \u2014 "),fZ=n(jWe,"A",{href:!0});var zJt=s(fZ);pbr=r(zJt,"MobileBertForTokenClassification"),zJt.forEach(t),_br=r(jWe," (MobileBERT model)"),jWe.forEach(t),bbr=i(J),BE=n(J,"LI",{});var DWe=s(BE);yCe=n(DWe,"STRONG",{});var QJt=s(yCe);vbr=r(QJt,"mpnet"),QJt.forEach(t),Fbr=r(DWe," \u2014 "),gZ=n(DWe,"A",{href:!0});var WJt=s(gZ);Tbr=r(WJt,"MPNetForTokenClassification"),WJt.forEach(t),Mbr=r(DWe," (MPNet model)"),DWe.forEach(t),Ebr=i(J),IE=n(J,"LI",{});var GWe=s(IE);xCe=n(GWe,"STRONG",{});var UJt=s(xCe);Cbr=r(UJt,"nezha"),UJt.forEach(t),wbr=r(GWe," \u2014 "),hZ=n(GWe,"A",{href:!0});var HJt=s(hZ);Abr=r(HJt,"NezhaForTokenClassification"),HJt.forEach(t),Lbr=r(GWe," (Nezha model)"),GWe.forEach(t),ybr=i(J),NE=n(J,"LI",{});var OWe=s(NE);$Ce=n(OWe,"STRONG",{});var JJt=s($Ce);xbr=r(JJt,"nystromformer"),JJt.forEach(t),$br=r(OWe," \u2014 "),uZ=n(OWe,"A",{href:!0});var YJt=s(uZ);kbr=r(YJt,"NystromformerForTokenClassification"),YJt.forEach(t),Sbr=r(OWe," (Nystr\xF6mformer model)"),OWe.forEach(t),Rbr=i(J),qE=n(J,"LI",{});var VWe=s(qE);kCe=n(VWe,"STRONG",{});var ZJt=s(kCe);Pbr=r(ZJt,"qdqbert"),ZJt.forEach(t),Bbr=r(VWe," \u2014 "),pZ=n(VWe,"A",{href:!0});var KJt=s(pZ);Ibr=r(KJt,"QDQBertForTokenClassification"),KJt.forEach(t),Nbr=r(VWe," (QDQBert model)"),VWe.forEach(t),qbr=i(J),jE=n(J,"LI",{});var XWe=s(jE);SCe=n(XWe,"STRONG",{});var eYt=s(SCe);jbr=r(eYt,"rembert"),eYt.forEach(t),Dbr=r(XWe," \u2014 "),_Z=n(XWe,"A",{href:!0});var oYt=s(_Z);Gbr=r(oYt,"RemBertForTokenClassification"),oYt.forEach(t),Obr=r(XWe," (RemBERT model)"),XWe.forEach(t),Vbr=i(J),DE=n(J,"LI",{});var zWe=s(DE);RCe=n(zWe,"STRONG",{});var rYt=s(RCe);Xbr=r(rYt,"roberta"),rYt.forEach(t),zbr=r(zWe," \u2014 "),bZ=n(zWe,"A",{href:!0});var tYt=s(bZ);Qbr=r(tYt,"RobertaForTokenClassification"),tYt.forEach(t),Wbr=r(zWe," (RoBERTa model)"),zWe.forEach(t),Ubr=i(J),GE=n(J,"LI",{});var QWe=s(GE);PCe=n(QWe,"STRONG",{});var aYt=s(PCe);Hbr=r(aYt,"roformer"),aYt.forEach(t),Jbr=r(QWe," \u2014 "),vZ=n(QWe,"A",{href:!0});var nYt=s(vZ);Ybr=r(nYt,"RoFormerForTokenClassification"),nYt.forEach(t),Zbr=r(QWe," (RoFormer model)"),QWe.forEach(t),Kbr=i(J),OE=n(J,"LI",{});var WWe=s(OE);BCe=n(WWe,"STRONG",{});var sYt=s(BCe);evr=r(sYt,"squeezebert"),sYt.forEach(t),ovr=r(WWe," \u2014 "),FZ=n(WWe,"A",{href:!0});var lYt=s(FZ);rvr=r(lYt,"SqueezeBertForTokenClassification"),lYt.forEach(t),tvr=r(WWe," (SqueezeBERT model)"),WWe.forEach(t),avr=i(J),VE=n(J,"LI",{});var UWe=s(VE);ICe=n(UWe,"STRONG",{});var iYt=s(ICe);nvr=r(iYt,"xlm"),iYt.forEach(t),svr=r(UWe," \u2014 "),TZ=n(UWe,"A",{href:!0});var dYt=s(TZ);lvr=r(dYt,"XLMForTokenClassification"),dYt.forEach(t),ivr=r(UWe," (XLM model)"),UWe.forEach(t),dvr=i(J),XE=n(J,"LI",{});var HWe=s(XE);NCe=n(HWe,"STRONG",{});var cYt=s(NCe);cvr=r(cYt,"xlm-roberta"),cYt.forEach(t),mvr=r(HWe," \u2014 "),MZ=n(HWe,"A",{href:!0});var mYt=s(MZ);fvr=r(mYt,"XLMRobertaForTokenClassification"),mYt.forEach(t),gvr=r(HWe," (XLM-RoBERTa model)"),HWe.forEach(t),hvr=i(J),zE=n(J,"LI",{});var JWe=s(zE);qCe=n(JWe,"STRONG",{});var fYt=s(qCe);uvr=r(fYt,"xlm-roberta-xl"),fYt.forEach(t),pvr=r(JWe," \u2014 "),EZ=n(JWe,"A",{href:!0});var gYt=s(EZ);_vr=r(gYt,"XLMRobertaXLForTokenClassification"),gYt.forEach(t),bvr=r(JWe," (XLM-RoBERTa-XL model)"),JWe.forEach(t),vvr=i(J),QE=n(J,"LI",{});var YWe=s(QE);jCe=n(YWe,"STRONG",{});var hYt=s(jCe);Fvr=r(hYt,"xlnet"),hYt.forEach(t),Tvr=r(YWe," \u2014 "),CZ=n(YWe,"A",{href:!0});var uYt=s(CZ);Mvr=r(uYt,"XLNetForTokenClassification"),uYt.forEach(t),Evr=r(YWe," (XLNet model)"),YWe.forEach(t),Cvr=i(J),WE=n(J,"LI",{});var ZWe=s(WE);DCe=n(ZWe,"STRONG",{});var pYt=s(DCe);wvr=r(pYt,"yoso"),pYt.forEach(t),Avr=r(ZWe," \u2014 "),wZ=n(ZWe,"A",{href:!0});var _Yt=s(wZ);Lvr=r(_Yt,"YosoForTokenClassification"),_Yt.forEach(t),yvr=r(ZWe," (YOSO model)"),ZWe.forEach(t),J.forEach(t),xvr=i(Ba),UE=n(Ba,"P",{});var KWe=s(UE);$vr=r(KWe,"The model is set in evaluation mode by default using "),GCe=n(KWe,"CODE",{});var bYt=s(GCe);kvr=r(bYt,"model.eval()"),bYt.forEach(t),Svr=r(KWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),OCe=n(KWe,"CODE",{});var vYt=s(OCe);Rvr=r(vYt,"model.train()"),vYt.forEach(t),KWe.forEach(t),Pvr=i(Ba),T(HE.$$.fragment,Ba),Ba.forEach(t),Ql.forEach(t),Tto=i(m),sc=n(m,"H2",{class:!0});var Dno=s(sc);JE=n(Dno,"A",{id:!0,class:!0,href:!0});var FYt=s(JE);VCe=n(FYt,"SPAN",{});var TYt=s(VCe);T(Ek.$$.fragment,TYt),TYt.forEach(t),FYt.forEach(t),Bvr=i(Dno),XCe=n(Dno,"SPAN",{});var MYt=s(XCe);Ivr=r(MYt,"AutoModelForQuestionAnswering"),MYt.forEach(t),Dno.forEach(t),Mto=i(m),Qo=n(m,"DIV",{class:!0});var Wl=s(Qo);T(Ck.$$.fragment,Wl),Nvr=i(Wl),lc=n(Wl,"P",{});var ace=s(lc);qvr=r(ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),AZ=n(ace,"A",{href:!0});var EYt=s(AZ);jvr=r(EYt,"from_pretrained()"),EYt.forEach(t),Dvr=r(ace," class method or the "),LZ=n(ace,"A",{href:!0});var CYt=s(LZ);Gvr=r(CYt,"from_config()"),CYt.forEach(t),Ovr=r(ace,` class
method.`),ace.forEach(t),Vvr=i(Wl),wk=n(Wl,"P",{});var Gno=s(wk);Xvr=r(Gno,"This class cannot be instantiated directly using "),zCe=n(Gno,"CODE",{});var wYt=s(zCe);zvr=r(wYt,"__init__()"),wYt.forEach(t),Qvr=r(Gno," (throws an error)."),Gno.forEach(t),Wvr=i(Wl),kt=n(Wl,"DIV",{class:!0});var c9=s(kt);T(Ak.$$.fragment,c9),Uvr=i(c9),QCe=n(c9,"P",{});var AYt=s(QCe);Hvr=r(AYt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),AYt.forEach(t),Jvr=i(c9),ic=n(c9,"P",{});var nce=s(ic);Yvr=r(nce,`Note:
Loading a model from its configuration file does `),WCe=n(nce,"STRONG",{});var LYt=s(WCe);Zvr=r(LYt,"not"),LYt.forEach(t),Kvr=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),yZ=n(nce,"A",{href:!0});var yYt=s(yZ);eFr=r(yYt,"from_pretrained()"),yYt.forEach(t),oFr=r(nce," to load the model weights."),nce.forEach(t),rFr=i(c9),T(YE.$$.fragment,c9),c9.forEach(t),tFr=i(Wl),co=n(Wl,"DIV",{class:!0});var Ia=s(co);T(Lk.$$.fragment,Ia),aFr=i(Ia),UCe=n(Ia,"P",{});var xYt=s(UCe);nFr=r(xYt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),xYt.forEach(t),sFr=i(Ia),un=n(Ia,"P",{});var m9=s(un);lFr=r(m9,"The model class to instantiate is selected based on the "),HCe=n(m9,"CODE",{});var $Yt=s(HCe);iFr=r($Yt,"model_type"),$Yt.forEach(t),dFr=r(m9,` property of the config object (either
passed as an argument or loaded from `),JCe=n(m9,"CODE",{});var kYt=s(JCe);cFr=r(kYt,"pretrained_model_name_or_path"),kYt.forEach(t),mFr=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YCe=n(m9,"CODE",{});var SYt=s(YCe);fFr=r(SYt,"pretrained_model_name_or_path"),SYt.forEach(t),gFr=r(m9,":"),m9.forEach(t),hFr=i(Ia),O=n(Ia,"UL",{});var X=s(O);ZE=n(X,"LI",{});var eUe=s(ZE);ZCe=n(eUe,"STRONG",{});var RYt=s(ZCe);uFr=r(RYt,"albert"),RYt.forEach(t),pFr=r(eUe," \u2014 "),xZ=n(eUe,"A",{href:!0});var PYt=s(xZ);_Fr=r(PYt,"AlbertForQuestionAnswering"),PYt.forEach(t),bFr=r(eUe," (ALBERT model)"),eUe.forEach(t),vFr=i(X),KE=n(X,"LI",{});var oUe=s(KE);KCe=n(oUe,"STRONG",{});var BYt=s(KCe);FFr=r(BYt,"bart"),BYt.forEach(t),TFr=r(oUe," \u2014 "),$Z=n(oUe,"A",{href:!0});var IYt=s($Z);MFr=r(IYt,"BartForQuestionAnswering"),IYt.forEach(t),EFr=r(oUe," (BART model)"),oUe.forEach(t),CFr=i(X),e4=n(X,"LI",{});var rUe=s(e4);e3e=n(rUe,"STRONG",{});var NYt=s(e3e);wFr=r(NYt,"bert"),NYt.forEach(t),AFr=r(rUe," \u2014 "),kZ=n(rUe,"A",{href:!0});var qYt=s(kZ);LFr=r(qYt,"BertForQuestionAnswering"),qYt.forEach(t),yFr=r(rUe," (BERT model)"),rUe.forEach(t),xFr=i(X),o4=n(X,"LI",{});var tUe=s(o4);o3e=n(tUe,"STRONG",{});var jYt=s(o3e);$Fr=r(jYt,"big_bird"),jYt.forEach(t),kFr=r(tUe," \u2014 "),SZ=n(tUe,"A",{href:!0});var DYt=s(SZ);SFr=r(DYt,"BigBirdForQuestionAnswering"),DYt.forEach(t),RFr=r(tUe," (BigBird model)"),tUe.forEach(t),PFr=i(X),r4=n(X,"LI",{});var aUe=s(r4);r3e=n(aUe,"STRONG",{});var GYt=s(r3e);BFr=r(GYt,"bigbird_pegasus"),GYt.forEach(t),IFr=r(aUe," \u2014 "),RZ=n(aUe,"A",{href:!0});var OYt=s(RZ);NFr=r(OYt,"BigBirdPegasusForQuestionAnswering"),OYt.forEach(t),qFr=r(aUe," (BigBird-Pegasus model)"),aUe.forEach(t),jFr=i(X),t4=n(X,"LI",{});var nUe=s(t4);t3e=n(nUe,"STRONG",{});var VYt=s(t3e);DFr=r(VYt,"bloom"),VYt.forEach(t),GFr=r(nUe," \u2014 "),PZ=n(nUe,"A",{href:!0});var XYt=s(PZ);OFr=r(XYt,"BloomForQuestionAnswering"),XYt.forEach(t),VFr=r(nUe," (BLOOM model)"),nUe.forEach(t),XFr=i(X),a4=n(X,"LI",{});var sUe=s(a4);a3e=n(sUe,"STRONG",{});var zYt=s(a3e);zFr=r(zYt,"camembert"),zYt.forEach(t),QFr=r(sUe," \u2014 "),BZ=n(sUe,"A",{href:!0});var QYt=s(BZ);WFr=r(QYt,"CamembertForQuestionAnswering"),QYt.forEach(t),UFr=r(sUe," (CamemBERT model)"),sUe.forEach(t),HFr=i(X),n4=n(X,"LI",{});var lUe=s(n4);n3e=n(lUe,"STRONG",{});var WYt=s(n3e);JFr=r(WYt,"canine"),WYt.forEach(t),YFr=r(lUe," \u2014 "),IZ=n(lUe,"A",{href:!0});var UYt=s(IZ);ZFr=r(UYt,"CanineForQuestionAnswering"),UYt.forEach(t),KFr=r(lUe," (CANINE model)"),lUe.forEach(t),eTr=i(X),s4=n(X,"LI",{});var iUe=s(s4);s3e=n(iUe,"STRONG",{});var HYt=s(s3e);oTr=r(HYt,"convbert"),HYt.forEach(t),rTr=r(iUe," \u2014 "),NZ=n(iUe,"A",{href:!0});var JYt=s(NZ);tTr=r(JYt,"ConvBertForQuestionAnswering"),JYt.forEach(t),aTr=r(iUe," (ConvBERT model)"),iUe.forEach(t),nTr=i(X),l4=n(X,"LI",{});var dUe=s(l4);l3e=n(dUe,"STRONG",{});var YYt=s(l3e);sTr=r(YYt,"data2vec-text"),YYt.forEach(t),lTr=r(dUe," \u2014 "),qZ=n(dUe,"A",{href:!0});var ZYt=s(qZ);iTr=r(ZYt,"Data2VecTextForQuestionAnswering"),ZYt.forEach(t),dTr=r(dUe," (Data2VecText model)"),dUe.forEach(t),cTr=i(X),i4=n(X,"LI",{});var cUe=s(i4);i3e=n(cUe,"STRONG",{});var KYt=s(i3e);mTr=r(KYt,"deberta"),KYt.forEach(t),fTr=r(cUe," \u2014 "),jZ=n(cUe,"A",{href:!0});var eZt=s(jZ);gTr=r(eZt,"DebertaForQuestionAnswering"),eZt.forEach(t),hTr=r(cUe," (DeBERTa model)"),cUe.forEach(t),uTr=i(X),d4=n(X,"LI",{});var mUe=s(d4);d3e=n(mUe,"STRONG",{});var oZt=s(d3e);pTr=r(oZt,"deberta-v2"),oZt.forEach(t),_Tr=r(mUe," \u2014 "),DZ=n(mUe,"A",{href:!0});var rZt=s(DZ);bTr=r(rZt,"DebertaV2ForQuestionAnswering"),rZt.forEach(t),vTr=r(mUe," (DeBERTa-v2 model)"),mUe.forEach(t),FTr=i(X),c4=n(X,"LI",{});var fUe=s(c4);c3e=n(fUe,"STRONG",{});var tZt=s(c3e);TTr=r(tZt,"distilbert"),tZt.forEach(t),MTr=r(fUe," \u2014 "),GZ=n(fUe,"A",{href:!0});var aZt=s(GZ);ETr=r(aZt,"DistilBertForQuestionAnswering"),aZt.forEach(t),CTr=r(fUe," (DistilBERT model)"),fUe.forEach(t),wTr=i(X),m4=n(X,"LI",{});var gUe=s(m4);m3e=n(gUe,"STRONG",{});var nZt=s(m3e);ATr=r(nZt,"electra"),nZt.forEach(t),LTr=r(gUe," \u2014 "),OZ=n(gUe,"A",{href:!0});var sZt=s(OZ);yTr=r(sZt,"ElectraForQuestionAnswering"),sZt.forEach(t),xTr=r(gUe," (ELECTRA model)"),gUe.forEach(t),$Tr=i(X),f4=n(X,"LI",{});var hUe=s(f4);f3e=n(hUe,"STRONG",{});var lZt=s(f3e);kTr=r(lZt,"ernie"),lZt.forEach(t),STr=r(hUe," \u2014 "),VZ=n(hUe,"A",{href:!0});var iZt=s(VZ);RTr=r(iZt,"ErnieForQuestionAnswering"),iZt.forEach(t),PTr=r(hUe," (ERNIE model)"),hUe.forEach(t),BTr=i(X),g4=n(X,"LI",{});var uUe=s(g4);g3e=n(uUe,"STRONG",{});var dZt=s(g3e);ITr=r(dZt,"flaubert"),dZt.forEach(t),NTr=r(uUe," \u2014 "),XZ=n(uUe,"A",{href:!0});var cZt=s(XZ);qTr=r(cZt,"FlaubertForQuestionAnsweringSimple"),cZt.forEach(t),jTr=r(uUe," (FlauBERT model)"),uUe.forEach(t),DTr=i(X),h4=n(X,"LI",{});var pUe=s(h4);h3e=n(pUe,"STRONG",{});var mZt=s(h3e);GTr=r(mZt,"fnet"),mZt.forEach(t),OTr=r(pUe," \u2014 "),zZ=n(pUe,"A",{href:!0});var fZt=s(zZ);VTr=r(fZt,"FNetForQuestionAnswering"),fZt.forEach(t),XTr=r(pUe," (FNet model)"),pUe.forEach(t),zTr=i(X),u4=n(X,"LI",{});var _Ue=s(u4);u3e=n(_Ue,"STRONG",{});var gZt=s(u3e);QTr=r(gZt,"funnel"),gZt.forEach(t),WTr=r(_Ue," \u2014 "),QZ=n(_Ue,"A",{href:!0});var hZt=s(QZ);UTr=r(hZt,"FunnelForQuestionAnswering"),hZt.forEach(t),HTr=r(_Ue," (Funnel Transformer model)"),_Ue.forEach(t),JTr=i(X),p4=n(X,"LI",{});var bUe=s(p4);p3e=n(bUe,"STRONG",{});var uZt=s(p3e);YTr=r(uZt,"gptj"),uZt.forEach(t),ZTr=r(bUe," \u2014 "),WZ=n(bUe,"A",{href:!0});var pZt=s(WZ);KTr=r(pZt,"GPTJForQuestionAnswering"),pZt.forEach(t),eMr=r(bUe," (GPT-J model)"),bUe.forEach(t),oMr=i(X),_4=n(X,"LI",{});var vUe=s(_4);_3e=n(vUe,"STRONG",{});var _Zt=s(_3e);rMr=r(_Zt,"ibert"),_Zt.forEach(t),tMr=r(vUe," \u2014 "),UZ=n(vUe,"A",{href:!0});var bZt=s(UZ);aMr=r(bZt,"IBertForQuestionAnswering"),bZt.forEach(t),nMr=r(vUe," (I-BERT model)"),vUe.forEach(t),sMr=i(X),b4=n(X,"LI",{});var FUe=s(b4);b3e=n(FUe,"STRONG",{});var vZt=s(b3e);lMr=r(vZt,"layoutlmv2"),vZt.forEach(t),iMr=r(FUe," \u2014 "),HZ=n(FUe,"A",{href:!0});var FZt=s(HZ);dMr=r(FZt,"LayoutLMv2ForQuestionAnswering"),FZt.forEach(t),cMr=r(FUe," (LayoutLMv2 model)"),FUe.forEach(t),mMr=i(X),v4=n(X,"LI",{});var TUe=s(v4);v3e=n(TUe,"STRONG",{});var TZt=s(v3e);fMr=r(TZt,"layoutlmv3"),TZt.forEach(t),gMr=r(TUe," \u2014 "),JZ=n(TUe,"A",{href:!0});var MZt=s(JZ);hMr=r(MZt,"LayoutLMv3ForQuestionAnswering"),MZt.forEach(t),uMr=r(TUe," (LayoutLMv3 model)"),TUe.forEach(t),pMr=i(X),F4=n(X,"LI",{});var MUe=s(F4);F3e=n(MUe,"STRONG",{});var EZt=s(F3e);_Mr=r(EZt,"led"),EZt.forEach(t),bMr=r(MUe," \u2014 "),YZ=n(MUe,"A",{href:!0});var CZt=s(YZ);vMr=r(CZt,"LEDForQuestionAnswering"),CZt.forEach(t),FMr=r(MUe," (LED model)"),MUe.forEach(t),TMr=i(X),T4=n(X,"LI",{});var EUe=s(T4);T3e=n(EUe,"STRONG",{});var wZt=s(T3e);MMr=r(wZt,"lilt"),wZt.forEach(t),EMr=r(EUe," \u2014 "),ZZ=n(EUe,"A",{href:!0});var AZt=s(ZZ);CMr=r(AZt,"LiltForQuestionAnswering"),AZt.forEach(t),wMr=r(EUe," (LiLT model)"),EUe.forEach(t),AMr=i(X),M4=n(X,"LI",{});var CUe=s(M4);M3e=n(CUe,"STRONG",{});var LZt=s(M3e);LMr=r(LZt,"longformer"),LZt.forEach(t),yMr=r(CUe," \u2014 "),KZ=n(CUe,"A",{href:!0});var yZt=s(KZ);xMr=r(yZt,"LongformerForQuestionAnswering"),yZt.forEach(t),$Mr=r(CUe," (Longformer model)"),CUe.forEach(t),kMr=i(X),E4=n(X,"LI",{});var wUe=s(E4);E3e=n(wUe,"STRONG",{});var xZt=s(E3e);SMr=r(xZt,"luke"),xZt.forEach(t),RMr=r(wUe," \u2014 "),eK=n(wUe,"A",{href:!0});var $Zt=s(eK);PMr=r($Zt,"LukeForQuestionAnswering"),$Zt.forEach(t),BMr=r(wUe," (LUKE model)"),wUe.forEach(t),IMr=i(X),C4=n(X,"LI",{});var AUe=s(C4);C3e=n(AUe,"STRONG",{});var kZt=s(C3e);NMr=r(kZt,"lxmert"),kZt.forEach(t),qMr=r(AUe," \u2014 "),oK=n(AUe,"A",{href:!0});var SZt=s(oK);jMr=r(SZt,"LxmertForQuestionAnswering"),SZt.forEach(t),DMr=r(AUe," (LXMERT model)"),AUe.forEach(t),GMr=i(X),w4=n(X,"LI",{});var LUe=s(w4);w3e=n(LUe,"STRONG",{});var RZt=s(w3e);OMr=r(RZt,"markuplm"),RZt.forEach(t),VMr=r(LUe," \u2014 "),rK=n(LUe,"A",{href:!0});var PZt=s(rK);XMr=r(PZt,"MarkupLMForQuestionAnswering"),PZt.forEach(t),zMr=r(LUe," (MarkupLM model)"),LUe.forEach(t),QMr=i(X),A4=n(X,"LI",{});var yUe=s(A4);A3e=n(yUe,"STRONG",{});var BZt=s(A3e);WMr=r(BZt,"mbart"),BZt.forEach(t),UMr=r(yUe," \u2014 "),tK=n(yUe,"A",{href:!0});var IZt=s(tK);HMr=r(IZt,"MBartForQuestionAnswering"),IZt.forEach(t),JMr=r(yUe," (mBART model)"),yUe.forEach(t),YMr=i(X),L4=n(X,"LI",{});var xUe=s(L4);L3e=n(xUe,"STRONG",{});var NZt=s(L3e);ZMr=r(NZt,"megatron-bert"),NZt.forEach(t),KMr=r(xUe," \u2014 "),aK=n(xUe,"A",{href:!0});var qZt=s(aK);eEr=r(qZt,"MegatronBertForQuestionAnswering"),qZt.forEach(t),oEr=r(xUe," (Megatron-BERT model)"),xUe.forEach(t),rEr=i(X),y4=n(X,"LI",{});var $Ue=s(y4);y3e=n($Ue,"STRONG",{});var jZt=s(y3e);tEr=r(jZt,"mobilebert"),jZt.forEach(t),aEr=r($Ue," \u2014 "),nK=n($Ue,"A",{href:!0});var DZt=s(nK);nEr=r(DZt,"MobileBertForQuestionAnswering"),DZt.forEach(t),sEr=r($Ue," (MobileBERT model)"),$Ue.forEach(t),lEr=i(X),x4=n(X,"LI",{});var kUe=s(x4);x3e=n(kUe,"STRONG",{});var GZt=s(x3e);iEr=r(GZt,"mpnet"),GZt.forEach(t),dEr=r(kUe," \u2014 "),sK=n(kUe,"A",{href:!0});var OZt=s(sK);cEr=r(OZt,"MPNetForQuestionAnswering"),OZt.forEach(t),mEr=r(kUe," (MPNet model)"),kUe.forEach(t),fEr=i(X),$4=n(X,"LI",{});var SUe=s($4);$3e=n(SUe,"STRONG",{});var VZt=s($3e);gEr=r(VZt,"mvp"),VZt.forEach(t),hEr=r(SUe," \u2014 "),lK=n(SUe,"A",{href:!0});var XZt=s(lK);uEr=r(XZt,"MvpForQuestionAnswering"),XZt.forEach(t),pEr=r(SUe," (MVP model)"),SUe.forEach(t),_Er=i(X),k4=n(X,"LI",{});var RUe=s(k4);k3e=n(RUe,"STRONG",{});var zZt=s(k3e);bEr=r(zZt,"nezha"),zZt.forEach(t),vEr=r(RUe," \u2014 "),iK=n(RUe,"A",{href:!0});var QZt=s(iK);FEr=r(QZt,"NezhaForQuestionAnswering"),QZt.forEach(t),TEr=r(RUe," (Nezha model)"),RUe.forEach(t),MEr=i(X),S4=n(X,"LI",{});var PUe=s(S4);S3e=n(PUe,"STRONG",{});var WZt=s(S3e);EEr=r(WZt,"nystromformer"),WZt.forEach(t),CEr=r(PUe," \u2014 "),dK=n(PUe,"A",{href:!0});var UZt=s(dK);wEr=r(UZt,"NystromformerForQuestionAnswering"),UZt.forEach(t),AEr=r(PUe," (Nystr\xF6mformer model)"),PUe.forEach(t),LEr=i(X),R4=n(X,"LI",{});var BUe=s(R4);R3e=n(BUe,"STRONG",{});var HZt=s(R3e);yEr=r(HZt,"opt"),HZt.forEach(t),xEr=r(BUe," \u2014 "),cK=n(BUe,"A",{href:!0});var JZt=s(cK);$Er=r(JZt,"OPTForQuestionAnswering"),JZt.forEach(t),kEr=r(BUe," (OPT model)"),BUe.forEach(t),SEr=i(X),P4=n(X,"LI",{});var IUe=s(P4);P3e=n(IUe,"STRONG",{});var YZt=s(P3e);REr=r(YZt,"qdqbert"),YZt.forEach(t),PEr=r(IUe," \u2014 "),mK=n(IUe,"A",{href:!0});var ZZt=s(mK);BEr=r(ZZt,"QDQBertForQuestionAnswering"),ZZt.forEach(t),IEr=r(IUe," (QDQBert model)"),IUe.forEach(t),NEr=i(X),B4=n(X,"LI",{});var NUe=s(B4);B3e=n(NUe,"STRONG",{});var KZt=s(B3e);qEr=r(KZt,"reformer"),KZt.forEach(t),jEr=r(NUe," \u2014 "),fK=n(NUe,"A",{href:!0});var eKt=s(fK);DEr=r(eKt,"ReformerForQuestionAnswering"),eKt.forEach(t),GEr=r(NUe," (Reformer model)"),NUe.forEach(t),OEr=i(X),I4=n(X,"LI",{});var qUe=s(I4);I3e=n(qUe,"STRONG",{});var oKt=s(I3e);VEr=r(oKt,"rembert"),oKt.forEach(t),XEr=r(qUe," \u2014 "),gK=n(qUe,"A",{href:!0});var rKt=s(gK);zEr=r(rKt,"RemBertForQuestionAnswering"),rKt.forEach(t),QEr=r(qUe," (RemBERT model)"),qUe.forEach(t),WEr=i(X),N4=n(X,"LI",{});var jUe=s(N4);N3e=n(jUe,"STRONG",{});var tKt=s(N3e);UEr=r(tKt,"roberta"),tKt.forEach(t),HEr=r(jUe," \u2014 "),hK=n(jUe,"A",{href:!0});var aKt=s(hK);JEr=r(aKt,"RobertaForQuestionAnswering"),aKt.forEach(t),YEr=r(jUe," (RoBERTa model)"),jUe.forEach(t),ZEr=i(X),q4=n(X,"LI",{});var DUe=s(q4);q3e=n(DUe,"STRONG",{});var nKt=s(q3e);KEr=r(nKt,"roformer"),nKt.forEach(t),e4r=r(DUe," \u2014 "),uK=n(DUe,"A",{href:!0});var sKt=s(uK);o4r=r(sKt,"RoFormerForQuestionAnswering"),sKt.forEach(t),r4r=r(DUe," (RoFormer model)"),DUe.forEach(t),t4r=i(X),j4=n(X,"LI",{});var GUe=s(j4);j3e=n(GUe,"STRONG",{});var lKt=s(j3e);a4r=r(lKt,"splinter"),lKt.forEach(t),n4r=r(GUe," \u2014 "),pK=n(GUe,"A",{href:!0});var iKt=s(pK);s4r=r(iKt,"SplinterForQuestionAnswering"),iKt.forEach(t),l4r=r(GUe," (Splinter model)"),GUe.forEach(t),i4r=i(X),D4=n(X,"LI",{});var OUe=s(D4);D3e=n(OUe,"STRONG",{});var dKt=s(D3e);d4r=r(dKt,"squeezebert"),dKt.forEach(t),c4r=r(OUe," \u2014 "),_K=n(OUe,"A",{href:!0});var cKt=s(_K);m4r=r(cKt,"SqueezeBertForQuestionAnswering"),cKt.forEach(t),f4r=r(OUe," (SqueezeBERT model)"),OUe.forEach(t),g4r=i(X),G4=n(X,"LI",{});var VUe=s(G4);G3e=n(VUe,"STRONG",{});var mKt=s(G3e);h4r=r(mKt,"xlm"),mKt.forEach(t),u4r=r(VUe," \u2014 "),bK=n(VUe,"A",{href:!0});var fKt=s(bK);p4r=r(fKt,"XLMForQuestionAnsweringSimple"),fKt.forEach(t),_4r=r(VUe," (XLM model)"),VUe.forEach(t),b4r=i(X),O4=n(X,"LI",{});var XUe=s(O4);O3e=n(XUe,"STRONG",{});var gKt=s(O3e);v4r=r(gKt,"xlm-roberta"),gKt.forEach(t),F4r=r(XUe," \u2014 "),vK=n(XUe,"A",{href:!0});var hKt=s(vK);T4r=r(hKt,"XLMRobertaForQuestionAnswering"),hKt.forEach(t),M4r=r(XUe," (XLM-RoBERTa model)"),XUe.forEach(t),E4r=i(X),V4=n(X,"LI",{});var zUe=s(V4);V3e=n(zUe,"STRONG",{});var uKt=s(V3e);C4r=r(uKt,"xlm-roberta-xl"),uKt.forEach(t),w4r=r(zUe," \u2014 "),FK=n(zUe,"A",{href:!0});var pKt=s(FK);A4r=r(pKt,"XLMRobertaXLForQuestionAnswering"),pKt.forEach(t),L4r=r(zUe," (XLM-RoBERTa-XL model)"),zUe.forEach(t),y4r=i(X),X4=n(X,"LI",{});var QUe=s(X4);X3e=n(QUe,"STRONG",{});var _Kt=s(X3e);x4r=r(_Kt,"xlnet"),_Kt.forEach(t),$4r=r(QUe," \u2014 "),TK=n(QUe,"A",{href:!0});var bKt=s(TK);k4r=r(bKt,"XLNetForQuestionAnsweringSimple"),bKt.forEach(t),S4r=r(QUe," (XLNet model)"),QUe.forEach(t),R4r=i(X),z4=n(X,"LI",{});var WUe=s(z4);z3e=n(WUe,"STRONG",{});var vKt=s(z3e);P4r=r(vKt,"yoso"),vKt.forEach(t),B4r=r(WUe," \u2014 "),MK=n(WUe,"A",{href:!0});var FKt=s(MK);I4r=r(FKt,"YosoForQuestionAnswering"),FKt.forEach(t),N4r=r(WUe," (YOSO model)"),WUe.forEach(t),X.forEach(t),q4r=i(Ia),Q4=n(Ia,"P",{});var UUe=s(Q4);j4r=r(UUe,"The model is set in evaluation mode by default using "),Q3e=n(UUe,"CODE",{});var TKt=s(Q3e);D4r=r(TKt,"model.eval()"),TKt.forEach(t),G4r=r(UUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W3e=n(UUe,"CODE",{});var MKt=s(W3e);O4r=r(MKt,"model.train()"),MKt.forEach(t),UUe.forEach(t),V4r=i(Ia),T(W4.$$.fragment,Ia),Ia.forEach(t),Wl.forEach(t),Eto=i(m),dc=n(m,"H2",{class:!0});var Ono=s(dc);U4=n(Ono,"A",{id:!0,class:!0,href:!0});var EKt=s(U4);U3e=n(EKt,"SPAN",{});var CKt=s(U3e);T(yk.$$.fragment,CKt),CKt.forEach(t),EKt.forEach(t),X4r=i(Ono),H3e=n(Ono,"SPAN",{});var wKt=s(H3e);z4r=r(wKt,"AutoModelForTableQuestionAnswering"),wKt.forEach(t),Ono.forEach(t),Cto=i(m),Wo=n(m,"DIV",{class:!0});var Ul=s(Wo);T(xk.$$.fragment,Ul),Q4r=i(Ul),cc=n(Ul,"P",{});var sce=s(cc);W4r=r(sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),EK=n(sce,"A",{href:!0});var AKt=s(EK);U4r=r(AKt,"from_pretrained()"),AKt.forEach(t),H4r=r(sce," class method or the "),CK=n(sce,"A",{href:!0});var LKt=s(CK);J4r=r(LKt,"from_config()"),LKt.forEach(t),Y4r=r(sce,` class
method.`),sce.forEach(t),Z4r=i(Ul),$k=n(Ul,"P",{});var Vno=s($k);K4r=r(Vno,"This class cannot be instantiated directly using "),J3e=n(Vno,"CODE",{});var yKt=s(J3e);eCr=r(yKt,"__init__()"),yKt.forEach(t),oCr=r(Vno," (throws an error)."),Vno.forEach(t),rCr=i(Ul),St=n(Ul,"DIV",{class:!0});var f9=s(St);T(kk.$$.fragment,f9),tCr=i(f9),Y3e=n(f9,"P",{});var xKt=s(Y3e);aCr=r(xKt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),xKt.forEach(t),nCr=i(f9),mc=n(f9,"P",{});var lce=s(mc);sCr=r(lce,`Note:
Loading a model from its configuration file does `),Z3e=n(lce,"STRONG",{});var $Kt=s(Z3e);lCr=r($Kt,"not"),$Kt.forEach(t),iCr=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=n(lce,"A",{href:!0});var kKt=s(wK);dCr=r(kKt,"from_pretrained()"),kKt.forEach(t),cCr=r(lce," to load the model weights."),lce.forEach(t),mCr=i(f9),T(H4.$$.fragment,f9),f9.forEach(t),fCr=i(Ul),mo=n(Ul,"DIV",{class:!0});var Na=s(mo);T(Sk.$$.fragment,Na),gCr=i(Na),K3e=n(Na,"P",{});var SKt=s(K3e);hCr=r(SKt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),SKt.forEach(t),uCr=i(Na),pn=n(Na,"P",{});var g9=s(pn);pCr=r(g9,"The model class to instantiate is selected based on the "),e5e=n(g9,"CODE",{});var RKt=s(e5e);_Cr=r(RKt,"model_type"),RKt.forEach(t),bCr=r(g9,` property of the config object (either
passed as an argument or loaded from `),o5e=n(g9,"CODE",{});var PKt=s(o5e);vCr=r(PKt,"pretrained_model_name_or_path"),PKt.forEach(t),FCr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r5e=n(g9,"CODE",{});var BKt=s(r5e);TCr=r(BKt,"pretrained_model_name_or_path"),BKt.forEach(t),MCr=r(g9,":"),g9.forEach(t),ECr=i(Na),t5e=n(Na,"UL",{});var IKt=s(t5e);J4=n(IKt,"LI",{});var HUe=s(J4);a5e=n(HUe,"STRONG",{});var NKt=s(a5e);CCr=r(NKt,"tapas"),NKt.forEach(t),wCr=r(HUe," \u2014 "),AK=n(HUe,"A",{href:!0});var qKt=s(AK);ACr=r(qKt,"TapasForQuestionAnswering"),qKt.forEach(t),LCr=r(HUe," (TAPAS model)"),HUe.forEach(t),IKt.forEach(t),yCr=i(Na),Y4=n(Na,"P",{});var JUe=s(Y4);xCr=r(JUe,"The model is set in evaluation mode by default using "),n5e=n(JUe,"CODE",{});var jKt=s(n5e);$Cr=r(jKt,"model.eval()"),jKt.forEach(t),kCr=r(JUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s5e=n(JUe,"CODE",{});var DKt=s(s5e);SCr=r(DKt,"model.train()"),DKt.forEach(t),JUe.forEach(t),RCr=i(Na),T(Z4.$$.fragment,Na),Na.forEach(t),Ul.forEach(t),wto=i(m),fc=n(m,"H2",{class:!0});var Xno=s(fc);K4=n(Xno,"A",{id:!0,class:!0,href:!0});var GKt=s(K4);l5e=n(GKt,"SPAN",{});var OKt=s(l5e);T(Rk.$$.fragment,OKt),OKt.forEach(t),GKt.forEach(t),PCr=i(Xno),i5e=n(Xno,"SPAN",{});var VKt=s(i5e);BCr=r(VKt,"AutoModelForDocumentQuestionAnswering"),VKt.forEach(t),Xno.forEach(t),Ato=i(m),Uo=n(m,"DIV",{class:!0});var Hl=s(Uo);T(Pk.$$.fragment,Hl),ICr=i(Hl),gc=n(Hl,"P",{});var ice=s(gc);NCr=r(ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),LK=n(ice,"A",{href:!0});var XKt=s(LK);qCr=r(XKt,"from_pretrained()"),XKt.forEach(t),jCr=r(ice," class method or the "),yK=n(ice,"A",{href:!0});var zKt=s(yK);DCr=r(zKt,"from_config()"),zKt.forEach(t),GCr=r(ice,` class
method.`),ice.forEach(t),OCr=i(Hl),Bk=n(Hl,"P",{});var zno=s(Bk);VCr=r(zno,"This class cannot be instantiated directly using "),d5e=n(zno,"CODE",{});var QKt=s(d5e);XCr=r(QKt,"__init__()"),QKt.forEach(t),zCr=r(zno," (throws an error)."),zno.forEach(t),QCr=i(Hl),Rt=n(Hl,"DIV",{class:!0});var h9=s(Rt);T(Ik.$$.fragment,h9),WCr=i(h9),c5e=n(h9,"P",{});var WKt=s(c5e);UCr=r(WKt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),WKt.forEach(t),HCr=i(h9),hc=n(h9,"P",{});var dce=s(hc);JCr=r(dce,`Note:
Loading a model from its configuration file does `),m5e=n(dce,"STRONG",{});var UKt=s(m5e);YCr=r(UKt,"not"),UKt.forEach(t),ZCr=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=n(dce,"A",{href:!0});var HKt=s(xK);KCr=r(HKt,"from_pretrained()"),HKt.forEach(t),e3r=r(dce," to load the model weights."),dce.forEach(t),o3r=i(h9),T(eC.$$.fragment,h9),h9.forEach(t),r3r=i(Hl),fo=n(Hl,"DIV",{class:!0});var qa=s(fo);T(Nk.$$.fragment,qa),t3r=i(qa),f5e=n(qa,"P",{});var JKt=s(f5e);a3r=r(JKt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),JKt.forEach(t),n3r=i(qa),_n=n(qa,"P",{});var u9=s(_n);s3r=r(u9,"The model class to instantiate is selected based on the "),g5e=n(u9,"CODE",{});var YKt=s(g5e);l3r=r(YKt,"model_type"),YKt.forEach(t),i3r=r(u9,` property of the config object (either
passed as an argument or loaded from `),h5e=n(u9,"CODE",{});var ZKt=s(h5e);d3r=r(ZKt,"pretrained_model_name_or_path"),ZKt.forEach(t),c3r=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u5e=n(u9,"CODE",{});var KKt=s(u5e);m3r=r(KKt,"pretrained_model_name_or_path"),KKt.forEach(t),f3r=r(u9,":"),u9.forEach(t),g3r=i(qa),uc=n(qa,"UL",{});var cce=s(uc);oC=n(cce,"LI",{});var YUe=s(oC);p5e=n(YUe,"STRONG",{});var eea=s(p5e);h3r=r(eea,"layoutlm"),eea.forEach(t),u3r=r(YUe," \u2014 "),$K=n(YUe,"A",{href:!0});var oea=s($K);p3r=r(oea,"LayoutLMForQuestionAnswering"),oea.forEach(t),_3r=r(YUe," (LayoutLM model)"),YUe.forEach(t),b3r=i(cce),rC=n(cce,"LI",{});var ZUe=s(rC);_5e=n(ZUe,"STRONG",{});var rea=s(_5e);v3r=r(rea,"layoutlmv2"),rea.forEach(t),F3r=r(ZUe," \u2014 "),kK=n(ZUe,"A",{href:!0});var tea=s(kK);T3r=r(tea,"LayoutLMv2ForQuestionAnswering"),tea.forEach(t),M3r=r(ZUe," (LayoutLMv2 model)"),ZUe.forEach(t),E3r=i(cce),tC=n(cce,"LI",{});var KUe=s(tC);b5e=n(KUe,"STRONG",{});var aea=s(b5e);C3r=r(aea,"layoutlmv3"),aea.forEach(t),w3r=r(KUe," \u2014 "),SK=n(KUe,"A",{href:!0});var nea=s(SK);A3r=r(nea,"LayoutLMv3ForQuestionAnswering"),nea.forEach(t),L3r=r(KUe," (LayoutLMv3 model)"),KUe.forEach(t),cce.forEach(t),y3r=i(qa),aC=n(qa,"P",{});var eHe=s(aC);x3r=r(eHe,"The model is set in evaluation mode by default using "),v5e=n(eHe,"CODE",{});var sea=s(v5e);$3r=r(sea,"model.eval()"),sea.forEach(t),k3r=r(eHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=n(eHe,"CODE",{});var lea=s(F5e);S3r=r(lea,"model.train()"),lea.forEach(t),eHe.forEach(t),R3r=i(qa),T(nC.$$.fragment,qa),qa.forEach(t),Hl.forEach(t),Lto=i(m),pc=n(m,"H2",{class:!0});var Qno=s(pc);sC=n(Qno,"A",{id:!0,class:!0,href:!0});var iea=s(sC);T5e=n(iea,"SPAN",{});var dea=s(T5e);T(qk.$$.fragment,dea),dea.forEach(t),iea.forEach(t),P3r=i(Qno),M5e=n(Qno,"SPAN",{});var cea=s(M5e);B3r=r(cea,"AutoModelForImageClassification"),cea.forEach(t),Qno.forEach(t),yto=i(m),Ho=n(m,"DIV",{class:!0});var Jl=s(Ho);T(jk.$$.fragment,Jl),I3r=i(Jl),_c=n(Jl,"P",{});var mce=s(_c);N3r=r(mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),RK=n(mce,"A",{href:!0});var mea=s(RK);q3r=r(mea,"from_pretrained()"),mea.forEach(t),j3r=r(mce," class method or the "),PK=n(mce,"A",{href:!0});var fea=s(PK);D3r=r(fea,"from_config()"),fea.forEach(t),G3r=r(mce,` class
method.`),mce.forEach(t),O3r=i(Jl),Dk=n(Jl,"P",{});var Wno=s(Dk);V3r=r(Wno,"This class cannot be instantiated directly using "),E5e=n(Wno,"CODE",{});var gea=s(E5e);X3r=r(gea,"__init__()"),gea.forEach(t),z3r=r(Wno," (throws an error)."),Wno.forEach(t),Q3r=i(Jl),Pt=n(Jl,"DIV",{class:!0});var p9=s(Pt);T(Gk.$$.fragment,p9),W3r=i(p9),C5e=n(p9,"P",{});var hea=s(C5e);U3r=r(hea,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),hea.forEach(t),H3r=i(p9),bc=n(p9,"P",{});var fce=s(bc);J3r=r(fce,`Note:
Loading a model from its configuration file does `),w5e=n(fce,"STRONG",{});var uea=s(w5e);Y3r=r(uea,"not"),uea.forEach(t),Z3r=r(fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),BK=n(fce,"A",{href:!0});var pea=s(BK);K3r=r(pea,"from_pretrained()"),pea.forEach(t),e5r=r(fce," to load the model weights."),fce.forEach(t),o5r=i(p9),T(lC.$$.fragment,p9),p9.forEach(t),r5r=i(Jl),go=n(Jl,"DIV",{class:!0});var ja=s(go);T(Ok.$$.fragment,ja),t5r=i(ja),A5e=n(ja,"P",{});var _ea=s(A5e);a5r=r(_ea,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_ea.forEach(t),n5r=i(ja),bn=n(ja,"P",{});var _9=s(bn);s5r=r(_9,"The model class to instantiate is selected based on the "),L5e=n(_9,"CODE",{});var bea=s(L5e);l5r=r(bea,"model_type"),bea.forEach(t),i5r=r(_9,` property of the config object (either
passed as an argument or loaded from `),y5e=n(_9,"CODE",{});var vea=s(y5e);d5r=r(vea,"pretrained_model_name_or_path"),vea.forEach(t),c5r=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(_9,"CODE",{});var Fea=s(x5e);m5r=r(Fea,"pretrained_model_name_or_path"),Fea.forEach(t),f5r=r(_9,":"),_9.forEach(t),g5r=i(ja),be=n(ja,"UL",{});var Fe=s(be);iC=n(Fe,"LI",{});var oHe=s(iC);$5e=n(oHe,"STRONG",{});var Tea=s($5e);h5r=r(Tea,"beit"),Tea.forEach(t),u5r=r(oHe," \u2014 "),IK=n(oHe,"A",{href:!0});var Mea=s(IK);p5r=r(Mea,"BeitForImageClassification"),Mea.forEach(t),_5r=r(oHe," (BEiT model)"),oHe.forEach(t),b5r=i(Fe),dC=n(Fe,"LI",{});var rHe=s(dC);k5e=n(rHe,"STRONG",{});var Eea=s(k5e);v5r=r(Eea,"convnext"),Eea.forEach(t),F5r=r(rHe," \u2014 "),NK=n(rHe,"A",{href:!0});var Cea=s(NK);T5r=r(Cea,"ConvNextForImageClassification"),Cea.forEach(t),M5r=r(rHe," (ConvNeXT model)"),rHe.forEach(t),E5r=i(Fe),cC=n(Fe,"LI",{});var tHe=s(cC);S5e=n(tHe,"STRONG",{});var wea=s(S5e);C5r=r(wea,"cvt"),wea.forEach(t),w5r=r(tHe," \u2014 "),qK=n(tHe,"A",{href:!0});var Aea=s(qK);A5r=r(Aea,"CvtForImageClassification"),Aea.forEach(t),L5r=r(tHe," (CvT model)"),tHe.forEach(t),y5r=i(Fe),mC=n(Fe,"LI",{});var aHe=s(mC);R5e=n(aHe,"STRONG",{});var Lea=s(R5e);x5r=r(Lea,"data2vec-vision"),Lea.forEach(t),$5r=r(aHe," \u2014 "),jK=n(aHe,"A",{href:!0});var yea=s(jK);k5r=r(yea,"Data2VecVisionForImageClassification"),yea.forEach(t),S5r=r(aHe," (Data2VecVision model)"),aHe.forEach(t),R5r=i(Fe),xl=n(Fe,"LI",{});var iN=s(xl);P5e=n(iN,"STRONG",{});var xea=s(P5e);P5r=r(xea,"deit"),xea.forEach(t),B5r=r(iN," \u2014 "),DK=n(iN,"A",{href:!0});var $ea=s(DK);I5r=r($ea,"DeiTForImageClassification"),$ea.forEach(t),N5r=r(iN," or "),GK=n(iN,"A",{href:!0});var kea=s(GK);q5r=r(kea,"DeiTForImageClassificationWithTeacher"),kea.forEach(t),j5r=r(iN," (DeiT model)"),iN.forEach(t),D5r=i(Fe),fC=n(Fe,"LI",{});var nHe=s(fC);B5e=n(nHe,"STRONG",{});var Sea=s(B5e);G5r=r(Sea,"imagegpt"),Sea.forEach(t),O5r=r(nHe," \u2014 "),OK=n(nHe,"A",{href:!0});var Rea=s(OK);V5r=r(Rea,"ImageGPTForImageClassification"),Rea.forEach(t),X5r=r(nHe," (ImageGPT model)"),nHe.forEach(t),z5r=i(Fe),$l=n(Fe,"LI",{});var dN=s($l);I5e=n(dN,"STRONG",{});var Pea=s(I5e);Q5r=r(Pea,"levit"),Pea.forEach(t),W5r=r(dN," \u2014 "),VK=n(dN,"A",{href:!0});var Bea=s(VK);U5r=r(Bea,"LevitForImageClassification"),Bea.forEach(t),H5r=r(dN," or "),XK=n(dN,"A",{href:!0});var Iea=s(XK);J5r=r(Iea,"LevitForImageClassificationWithTeacher"),Iea.forEach(t),Y5r=r(dN," (LeViT model)"),dN.forEach(t),Z5r=i(Fe),gC=n(Fe,"LI",{});var sHe=s(gC);N5e=n(sHe,"STRONG",{});var Nea=s(N5e);K5r=r(Nea,"mobilevit"),Nea.forEach(t),e0r=r(sHe," \u2014 "),zK=n(sHe,"A",{href:!0});var qea=s(zK);o0r=r(qea,"MobileViTForImageClassification"),qea.forEach(t),r0r=r(sHe," (MobileViT model)"),sHe.forEach(t),t0r=i(Fe),Bt=n(Fe,"LI",{});var Of=s(Bt);q5e=n(Of,"STRONG",{});var jea=s(q5e);a0r=r(jea,"perceiver"),jea.forEach(t),n0r=r(Of," \u2014 "),QK=n(Of,"A",{href:!0});var Dea=s(QK);s0r=r(Dea,"PerceiverForImageClassificationLearned"),Dea.forEach(t),l0r=r(Of," or "),WK=n(Of,"A",{href:!0});var Gea=s(WK);i0r=r(Gea,"PerceiverForImageClassificationFourier"),Gea.forEach(t),d0r=r(Of," or "),UK=n(Of,"A",{href:!0});var Oea=s(UK);c0r=r(Oea,"PerceiverForImageClassificationConvProcessing"),Oea.forEach(t),m0r=r(Of," (Perceiver model)"),Of.forEach(t),f0r=i(Fe),hC=n(Fe,"LI",{});var lHe=s(hC);j5e=n(lHe,"STRONG",{});var Vea=s(j5e);g0r=r(Vea,"poolformer"),Vea.forEach(t),h0r=r(lHe," \u2014 "),HK=n(lHe,"A",{href:!0});var Xea=s(HK);u0r=r(Xea,"PoolFormerForImageClassification"),Xea.forEach(t),p0r=r(lHe," (PoolFormer model)"),lHe.forEach(t),_0r=i(Fe),uC=n(Fe,"LI",{});var iHe=s(uC);D5e=n(iHe,"STRONG",{});var zea=s(D5e);b0r=r(zea,"regnet"),zea.forEach(t),v0r=r(iHe," \u2014 "),JK=n(iHe,"A",{href:!0});var Qea=s(JK);F0r=r(Qea,"RegNetForImageClassification"),Qea.forEach(t),T0r=r(iHe," (RegNet model)"),iHe.forEach(t),M0r=i(Fe),pC=n(Fe,"LI",{});var dHe=s(pC);G5e=n(dHe,"STRONG",{});var Wea=s(G5e);E0r=r(Wea,"resnet"),Wea.forEach(t),C0r=r(dHe," \u2014 "),YK=n(dHe,"A",{href:!0});var Uea=s(YK);w0r=r(Uea,"ResNetForImageClassification"),Uea.forEach(t),A0r=r(dHe," (ResNet model)"),dHe.forEach(t),L0r=i(Fe),_C=n(Fe,"LI",{});var cHe=s(_C);O5e=n(cHe,"STRONG",{});var Hea=s(O5e);y0r=r(Hea,"segformer"),Hea.forEach(t),x0r=r(cHe," \u2014 "),ZK=n(cHe,"A",{href:!0});var Jea=s(ZK);$0r=r(Jea,"SegformerForImageClassification"),Jea.forEach(t),k0r=r(cHe," (SegFormer model)"),cHe.forEach(t),S0r=i(Fe),bC=n(Fe,"LI",{});var mHe=s(bC);V5e=n(mHe,"STRONG",{});var Yea=s(V5e);R0r=r(Yea,"swin"),Yea.forEach(t),P0r=r(mHe," \u2014 "),KK=n(mHe,"A",{href:!0});var Zea=s(KK);B0r=r(Zea,"SwinForImageClassification"),Zea.forEach(t),I0r=r(mHe," (Swin Transformer model)"),mHe.forEach(t),N0r=i(Fe),vC=n(Fe,"LI",{});var fHe=s(vC);X5e=n(fHe,"STRONG",{});var Kea=s(X5e);q0r=r(Kea,"swinv2"),Kea.forEach(t),j0r=r(fHe," \u2014 "),eee=n(fHe,"A",{href:!0});var eoa=s(eee);D0r=r(eoa,"Swinv2ForImageClassification"),eoa.forEach(t),G0r=r(fHe," (Swin Transformer V2 model)"),fHe.forEach(t),O0r=i(Fe),FC=n(Fe,"LI",{});var gHe=s(FC);z5e=n(gHe,"STRONG",{});var ooa=s(z5e);V0r=r(ooa,"van"),ooa.forEach(t),X0r=r(gHe," \u2014 "),oee=n(gHe,"A",{href:!0});var roa=s(oee);z0r=r(roa,"VanForImageClassification"),roa.forEach(t),Q0r=r(gHe," (VAN model)"),gHe.forEach(t),W0r=i(Fe),TC=n(Fe,"LI",{});var hHe=s(TC);Q5e=n(hHe,"STRONG",{});var toa=s(Q5e);U0r=r(toa,"vit"),toa.forEach(t),H0r=r(hHe," \u2014 "),ree=n(hHe,"A",{href:!0});var aoa=s(ree);J0r=r(aoa,"ViTForImageClassification"),aoa.forEach(t),Y0r=r(hHe," (ViT model)"),hHe.forEach(t),Z0r=i(Fe),MC=n(Fe,"LI",{});var uHe=s(MC);W5e=n(uHe,"STRONG",{});var noa=s(W5e);K0r=r(noa,"vit_msn"),noa.forEach(t),ewr=r(uHe," \u2014 "),tee=n(uHe,"A",{href:!0});var soa=s(tee);owr=r(soa,"ViTMSNForImageClassification"),soa.forEach(t),rwr=r(uHe," (ViTMSN model)"),uHe.forEach(t),Fe.forEach(t),twr=i(ja),EC=n(ja,"P",{});var pHe=s(EC);awr=r(pHe,"The model is set in evaluation mode by default using "),U5e=n(pHe,"CODE",{});var loa=s(U5e);nwr=r(loa,"model.eval()"),loa.forEach(t),swr=r(pHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H5e=n(pHe,"CODE",{});var ioa=s(H5e);lwr=r(ioa,"model.train()"),ioa.forEach(t),pHe.forEach(t),iwr=i(ja),T(CC.$$.fragment,ja),ja.forEach(t),Jl.forEach(t),xto=i(m),vc=n(m,"H2",{class:!0});var Uno=s(vc);wC=n(Uno,"A",{id:!0,class:!0,href:!0});var doa=s(wC);J5e=n(doa,"SPAN",{});var coa=s(J5e);T(Vk.$$.fragment,coa),coa.forEach(t),doa.forEach(t),dwr=i(Uno),Y5e=n(Uno,"SPAN",{});var moa=s(Y5e);cwr=r(moa,"AutoModelForVideoClassification"),moa.forEach(t),Uno.forEach(t),$to=i(m),Jo=n(m,"DIV",{class:!0});var Yl=s(Jo);T(Xk.$$.fragment,Yl),mwr=i(Yl),Fc=n(Yl,"P",{});var gce=s(Fc);fwr=r(gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),aee=n(gce,"A",{href:!0});var foa=s(aee);gwr=r(foa,"from_pretrained()"),foa.forEach(t),hwr=r(gce," class method or the "),nee=n(gce,"A",{href:!0});var goa=s(nee);uwr=r(goa,"from_config()"),goa.forEach(t),pwr=r(gce,` class
method.`),gce.forEach(t),_wr=i(Yl),zk=n(Yl,"P",{});var Hno=s(zk);bwr=r(Hno,"This class cannot be instantiated directly using "),Z5e=n(Hno,"CODE",{});var hoa=s(Z5e);vwr=r(hoa,"__init__()"),hoa.forEach(t),Fwr=r(Hno," (throws an error)."),Hno.forEach(t),Twr=i(Yl),It=n(Yl,"DIV",{class:!0});var b9=s(It);T(Qk.$$.fragment,b9),Mwr=i(b9),K5e=n(b9,"P",{});var uoa=s(K5e);Ewr=r(uoa,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),uoa.forEach(t),Cwr=i(b9),Tc=n(b9,"P",{});var hce=s(Tc);wwr=r(hce,`Note:
Loading a model from its configuration file does `),e0e=n(hce,"STRONG",{});var poa=s(e0e);Awr=r(poa,"not"),poa.forEach(t),Lwr=r(hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),see=n(hce,"A",{href:!0});var _oa=s(see);ywr=r(_oa,"from_pretrained()"),_oa.forEach(t),xwr=r(hce," to load the model weights."),hce.forEach(t),$wr=i(b9),T(AC.$$.fragment,b9),b9.forEach(t),kwr=i(Yl),ho=n(Yl,"DIV",{class:!0});var Da=s(ho);T(Wk.$$.fragment,Da),Swr=i(Da),o0e=n(Da,"P",{});var boa=s(o0e);Rwr=r(boa,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),boa.forEach(t),Pwr=i(Da),vn=n(Da,"P",{});var v9=s(vn);Bwr=r(v9,"The model class to instantiate is selected based on the "),r0e=n(v9,"CODE",{});var voa=s(r0e);Iwr=r(voa,"model_type"),voa.forEach(t),Nwr=r(v9,` property of the config object (either
passed as an argument or loaded from `),t0e=n(v9,"CODE",{});var Foa=s(t0e);qwr=r(Foa,"pretrained_model_name_or_path"),Foa.forEach(t),jwr=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=n(v9,"CODE",{});var Toa=s(a0e);Dwr=r(Toa,"pretrained_model_name_or_path"),Toa.forEach(t),Gwr=r(v9,":"),v9.forEach(t),Owr=i(Da),n0e=n(Da,"UL",{});var Moa=s(n0e);LC=n(Moa,"LI",{});var _He=s(LC);s0e=n(_He,"STRONG",{});var Eoa=s(s0e);Vwr=r(Eoa,"videomae"),Eoa.forEach(t),Xwr=r(_He," \u2014 "),lee=n(_He,"A",{href:!0});var Coa=s(lee);zwr=r(Coa,"VideoMAEForVideoClassification"),Coa.forEach(t),Qwr=r(_He," (VideoMAE model)"),_He.forEach(t),Moa.forEach(t),Wwr=i(Da),yC=n(Da,"P",{});var bHe=s(yC);Uwr=r(bHe,"The model is set in evaluation mode by default using "),l0e=n(bHe,"CODE",{});var woa=s(l0e);Hwr=r(woa,"model.eval()"),woa.forEach(t),Jwr=r(bHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),i0e=n(bHe,"CODE",{});var Aoa=s(i0e);Ywr=r(Aoa,"model.train()"),Aoa.forEach(t),bHe.forEach(t),Zwr=i(Da),T(xC.$$.fragment,Da),Da.forEach(t),Yl.forEach(t),kto=i(m),Mc=n(m,"H2",{class:!0});var Jno=s(Mc);$C=n(Jno,"A",{id:!0,class:!0,href:!0});var Loa=s($C);d0e=n(Loa,"SPAN",{});var yoa=s(d0e);T(Uk.$$.fragment,yoa),yoa.forEach(t),Loa.forEach(t),Kwr=i(Jno),c0e=n(Jno,"SPAN",{});var xoa=s(c0e);eAr=r(xoa,"AutoModelForVision2Seq"),xoa.forEach(t),Jno.forEach(t),Sto=i(m),Yo=n(m,"DIV",{class:!0});var Zl=s(Yo);T(Hk.$$.fragment,Zl),oAr=i(Zl),Ec=n(Zl,"P",{});var uce=s(Ec);rAr=r(uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),iee=n(uce,"A",{href:!0});var $oa=s(iee);tAr=r($oa,"from_pretrained()"),$oa.forEach(t),aAr=r(uce," class method or the "),dee=n(uce,"A",{href:!0});var koa=s(dee);nAr=r(koa,"from_config()"),koa.forEach(t),sAr=r(uce,` class
method.`),uce.forEach(t),lAr=i(Zl),Jk=n(Zl,"P",{});var Yno=s(Jk);iAr=r(Yno,"This class cannot be instantiated directly using "),m0e=n(Yno,"CODE",{});var Soa=s(m0e);dAr=r(Soa,"__init__()"),Soa.forEach(t),cAr=r(Yno," (throws an error)."),Yno.forEach(t),mAr=i(Zl),Nt=n(Zl,"DIV",{class:!0});var F9=s(Nt);T(Yk.$$.fragment,F9),fAr=i(F9),f0e=n(F9,"P",{});var Roa=s(f0e);gAr=r(Roa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Roa.forEach(t),hAr=i(F9),Cc=n(F9,"P",{});var pce=s(Cc);uAr=r(pce,`Note:
Loading a model from its configuration file does `),g0e=n(pce,"STRONG",{});var Poa=s(g0e);pAr=r(Poa,"not"),Poa.forEach(t),_Ar=r(pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),cee=n(pce,"A",{href:!0});var Boa=s(cee);bAr=r(Boa,"from_pretrained()"),Boa.forEach(t),vAr=r(pce," to load the model weights."),pce.forEach(t),FAr=i(F9),T(kC.$$.fragment,F9),F9.forEach(t),TAr=i(Zl),uo=n(Zl,"DIV",{class:!0});var Ga=s(uo);T(Zk.$$.fragment,Ga),MAr=i(Ga),h0e=n(Ga,"P",{});var Ioa=s(h0e);EAr=r(Ioa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ioa.forEach(t),CAr=i(Ga),Fn=n(Ga,"P",{});var T9=s(Fn);wAr=r(T9,"The model class to instantiate is selected based on the "),u0e=n(T9,"CODE",{});var Noa=s(u0e);AAr=r(Noa,"model_type"),Noa.forEach(t),LAr=r(T9,` property of the config object (either
passed as an argument or loaded from `),p0e=n(T9,"CODE",{});var qoa=s(p0e);yAr=r(qoa,"pretrained_model_name_or_path"),qoa.forEach(t),xAr=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=n(T9,"CODE",{});var joa=s(_0e);$Ar=r(joa,"pretrained_model_name_or_path"),joa.forEach(t),kAr=r(T9,":"),T9.forEach(t),SAr=i(Ga),b0e=n(Ga,"UL",{});var Doa=s(b0e);SC=n(Doa,"LI",{});var vHe=s(SC);v0e=n(vHe,"STRONG",{});var Goa=s(v0e);RAr=r(Goa,"vision-encoder-decoder"),Goa.forEach(t),PAr=r(vHe," \u2014 "),mee=n(vHe,"A",{href:!0});var Ooa=s(mee);BAr=r(Ooa,"VisionEncoderDecoderModel"),Ooa.forEach(t),IAr=r(vHe," (Vision Encoder decoder model)"),vHe.forEach(t),Doa.forEach(t),NAr=i(Ga),RC=n(Ga,"P",{});var FHe=s(RC);qAr=r(FHe,"The model is set in evaluation mode by default using "),F0e=n(FHe,"CODE",{});var Voa=s(F0e);jAr=r(Voa,"model.eval()"),Voa.forEach(t),DAr=r(FHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T0e=n(FHe,"CODE",{});var Xoa=s(T0e);GAr=r(Xoa,"model.train()"),Xoa.forEach(t),FHe.forEach(t),OAr=i(Ga),T(PC.$$.fragment,Ga),Ga.forEach(t),Zl.forEach(t),Rto=i(m),wc=n(m,"H2",{class:!0});var Zno=s(wc);BC=n(Zno,"A",{id:!0,class:!0,href:!0});var zoa=s(BC);M0e=n(zoa,"SPAN",{});var Qoa=s(M0e);T(Kk.$$.fragment,Qoa),Qoa.forEach(t),zoa.forEach(t),VAr=i(Zno),E0e=n(Zno,"SPAN",{});var Woa=s(E0e);XAr=r(Woa,"AutoModelForVisualQuestionAnswering"),Woa.forEach(t),Zno.forEach(t),Pto=i(m),Zo=n(m,"DIV",{class:!0});var Kl=s(Zo);T(eS.$$.fragment,Kl),zAr=i(Kl),Ac=n(Kl,"P",{});var _ce=s(Ac);QAr=r(_ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),fee=n(_ce,"A",{href:!0});var Uoa=s(fee);WAr=r(Uoa,"from_pretrained()"),Uoa.forEach(t),UAr=r(_ce," class method or the "),gee=n(_ce,"A",{href:!0});var Hoa=s(gee);HAr=r(Hoa,"from_config()"),Hoa.forEach(t),JAr=r(_ce,` class
method.`),_ce.forEach(t),YAr=i(Kl),oS=n(Kl,"P",{});var Kno=s(oS);ZAr=r(Kno,"This class cannot be instantiated directly using "),C0e=n(Kno,"CODE",{});var Joa=s(C0e);KAr=r(Joa,"__init__()"),Joa.forEach(t),e6r=r(Kno," (throws an error)."),Kno.forEach(t),o6r=i(Kl),qt=n(Kl,"DIV",{class:!0});var M9=s(qt);T(rS.$$.fragment,M9),r6r=i(M9),w0e=n(M9,"P",{});var Yoa=s(w0e);t6r=r(Yoa,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Yoa.forEach(t),a6r=i(M9),Lc=n(M9,"P",{});var bce=s(Lc);n6r=r(bce,`Note:
Loading a model from its configuration file does `),A0e=n(bce,"STRONG",{});var Zoa=s(A0e);s6r=r(Zoa,"not"),Zoa.forEach(t),l6r=r(bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),hee=n(bce,"A",{href:!0});var Koa=s(hee);i6r=r(Koa,"from_pretrained()"),Koa.forEach(t),d6r=r(bce," to load the model weights."),bce.forEach(t),c6r=i(M9),T(IC.$$.fragment,M9),M9.forEach(t),m6r=i(Kl),po=n(Kl,"DIV",{class:!0});var Oa=s(po);T(tS.$$.fragment,Oa),f6r=i(Oa),L0e=n(Oa,"P",{});var era=s(L0e);g6r=r(era,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),era.forEach(t),h6r=i(Oa),Tn=n(Oa,"P",{});var E9=s(Tn);u6r=r(E9,"The model class to instantiate is selected based on the "),y0e=n(E9,"CODE",{});var ora=s(y0e);p6r=r(ora,"model_type"),ora.forEach(t),_6r=r(E9,` property of the config object (either
passed as an argument or loaded from `),x0e=n(E9,"CODE",{});var rra=s(x0e);b6r=r(rra,"pretrained_model_name_or_path"),rra.forEach(t),v6r=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$0e=n(E9,"CODE",{});var tra=s($0e);F6r=r(tra,"pretrained_model_name_or_path"),tra.forEach(t),T6r=r(E9,":"),E9.forEach(t),M6r=i(Oa),k0e=n(Oa,"UL",{});var ara=s(k0e);NC=n(ara,"LI",{});var THe=s(NC);S0e=n(THe,"STRONG",{});var nra=s(S0e);E6r=r(nra,"vilt"),nra.forEach(t),C6r=r(THe," \u2014 "),uee=n(THe,"A",{href:!0});var sra=s(uee);w6r=r(sra,"ViltForQuestionAnswering"),sra.forEach(t),A6r=r(THe," (ViLT model)"),THe.forEach(t),ara.forEach(t),L6r=i(Oa),qC=n(Oa,"P",{});var MHe=s(qC);y6r=r(MHe,"The model is set in evaluation mode by default using "),R0e=n(MHe,"CODE",{});var lra=s(R0e);x6r=r(lra,"model.eval()"),lra.forEach(t),$6r=r(MHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P0e=n(MHe,"CODE",{});var ira=s(P0e);k6r=r(ira,"model.train()"),ira.forEach(t),MHe.forEach(t),S6r=i(Oa),T(jC.$$.fragment,Oa),Oa.forEach(t),Kl.forEach(t),Bto=i(m),yc=n(m,"H2",{class:!0});var eso=s(yc);DC=n(eso,"A",{id:!0,class:!0,href:!0});var dra=s(DC);B0e=n(dra,"SPAN",{});var cra=s(B0e);T(aS.$$.fragment,cra),cra.forEach(t),dra.forEach(t),R6r=i(eso),I0e=n(eso,"SPAN",{});var mra=s(I0e);P6r=r(mra,"AutoModelForAudioClassification"),mra.forEach(t),eso.forEach(t),Ito=i(m),Ko=n(m,"DIV",{class:!0});var ei=s(Ko);T(nS.$$.fragment,ei),B6r=i(ei),xc=n(ei,"P",{});var vce=s(xc);I6r=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),pee=n(vce,"A",{href:!0});var fra=s(pee);N6r=r(fra,"from_pretrained()"),fra.forEach(t),q6r=r(vce," class method or the "),_ee=n(vce,"A",{href:!0});var gra=s(_ee);j6r=r(gra,"from_config()"),gra.forEach(t),D6r=r(vce,` class
method.`),vce.forEach(t),G6r=i(ei),sS=n(ei,"P",{});var oso=s(sS);O6r=r(oso,"This class cannot be instantiated directly using "),N0e=n(oso,"CODE",{});var hra=s(N0e);V6r=r(hra,"__init__()"),hra.forEach(t),X6r=r(oso," (throws an error)."),oso.forEach(t),z6r=i(ei),jt=n(ei,"DIV",{class:!0});var C9=s(jt);T(lS.$$.fragment,C9),Q6r=i(C9),q0e=n(C9,"P",{});var ura=s(q0e);W6r=r(ura,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),ura.forEach(t),U6r=i(C9),$c=n(C9,"P",{});var Fce=s($c);H6r=r(Fce,`Note:
Loading a model from its configuration file does `),j0e=n(Fce,"STRONG",{});var pra=s(j0e);J6r=r(pra,"not"),pra.forEach(t),Y6r=r(Fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),bee=n(Fce,"A",{href:!0});var _ra=s(bee);Z6r=r(_ra,"from_pretrained()"),_ra.forEach(t),K6r=r(Fce," to load the model weights."),Fce.forEach(t),e7r=i(C9),T(GC.$$.fragment,C9),C9.forEach(t),o7r=i(ei),_o=n(ei,"DIV",{class:!0});var Va=s(_o);T(iS.$$.fragment,Va),r7r=i(Va),D0e=n(Va,"P",{});var bra=s(D0e);t7r=r(bra,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),bra.forEach(t),a7r=i(Va),Mn=n(Va,"P",{});var w9=s(Mn);n7r=r(w9,"The model class to instantiate is selected based on the "),G0e=n(w9,"CODE",{});var vra=s(G0e);s7r=r(vra,"model_type"),vra.forEach(t),l7r=r(w9,` property of the config object (either
passed as an argument or loaded from `),O0e=n(w9,"CODE",{});var Fra=s(O0e);i7r=r(Fra,"pretrained_model_name_or_path"),Fra.forEach(t),d7r=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V0e=n(w9,"CODE",{});var Tra=s(V0e);c7r=r(Tra,"pretrained_model_name_or_path"),Tra.forEach(t),m7r=r(w9,":"),w9.forEach(t),f7r=i(Va),Be=n(Va,"UL",{});var We=s(Be);OC=n(We,"LI",{});var EHe=s(OC);X0e=n(EHe,"STRONG",{});var Mra=s(X0e);g7r=r(Mra,"data2vec-audio"),Mra.forEach(t),h7r=r(EHe," \u2014 "),vee=n(EHe,"A",{href:!0});var Era=s(vee);u7r=r(Era,"Data2VecAudioForSequenceClassification"),Era.forEach(t),p7r=r(EHe," (Data2VecAudio model)"),EHe.forEach(t),_7r=i(We),VC=n(We,"LI",{});var CHe=s(VC);z0e=n(CHe,"STRONG",{});var Cra=s(z0e);b7r=r(Cra,"hubert"),Cra.forEach(t),v7r=r(CHe," \u2014 "),Fee=n(CHe,"A",{href:!0});var wra=s(Fee);F7r=r(wra,"HubertForSequenceClassification"),wra.forEach(t),T7r=r(CHe," (Hubert model)"),CHe.forEach(t),M7r=i(We),XC=n(We,"LI",{});var wHe=s(XC);Q0e=n(wHe,"STRONG",{});var Ara=s(Q0e);E7r=r(Ara,"sew"),Ara.forEach(t),C7r=r(wHe," \u2014 "),Tee=n(wHe,"A",{href:!0});var Lra=s(Tee);w7r=r(Lra,"SEWForSequenceClassification"),Lra.forEach(t),A7r=r(wHe," (SEW model)"),wHe.forEach(t),L7r=i(We),zC=n(We,"LI",{});var AHe=s(zC);W0e=n(AHe,"STRONG",{});var yra=s(W0e);y7r=r(yra,"sew-d"),yra.forEach(t),x7r=r(AHe," \u2014 "),Mee=n(AHe,"A",{href:!0});var xra=s(Mee);$7r=r(xra,"SEWDForSequenceClassification"),xra.forEach(t),k7r=r(AHe," (SEW-D model)"),AHe.forEach(t),S7r=i(We),QC=n(We,"LI",{});var LHe=s(QC);U0e=n(LHe,"STRONG",{});var $ra=s(U0e);R7r=r($ra,"unispeech"),$ra.forEach(t),P7r=r(LHe," \u2014 "),Eee=n(LHe,"A",{href:!0});var kra=s(Eee);B7r=r(kra,"UniSpeechForSequenceClassification"),kra.forEach(t),I7r=r(LHe," (UniSpeech model)"),LHe.forEach(t),N7r=i(We),WC=n(We,"LI",{});var yHe=s(WC);H0e=n(yHe,"STRONG",{});var Sra=s(H0e);q7r=r(Sra,"unispeech-sat"),Sra.forEach(t),j7r=r(yHe," \u2014 "),Cee=n(yHe,"A",{href:!0});var Rra=s(Cee);D7r=r(Rra,"UniSpeechSatForSequenceClassification"),Rra.forEach(t),G7r=r(yHe," (UniSpeechSat model)"),yHe.forEach(t),O7r=i(We),UC=n(We,"LI",{});var xHe=s(UC);J0e=n(xHe,"STRONG",{});var Pra=s(J0e);V7r=r(Pra,"wav2vec2"),Pra.forEach(t),X7r=r(xHe," \u2014 "),wee=n(xHe,"A",{href:!0});var Bra=s(wee);z7r=r(Bra,"Wav2Vec2ForSequenceClassification"),Bra.forEach(t),Q7r=r(xHe," (Wav2Vec2 model)"),xHe.forEach(t),W7r=i(We),HC=n(We,"LI",{});var $He=s(HC);Y0e=n($He,"STRONG",{});var Ira=s(Y0e);U7r=r(Ira,"wav2vec2-conformer"),Ira.forEach(t),H7r=r($He," \u2014 "),Aee=n($He,"A",{href:!0});var Nra=s(Aee);J7r=r(Nra,"Wav2Vec2ConformerForSequenceClassification"),Nra.forEach(t),Y7r=r($He," (Wav2Vec2-Conformer model)"),$He.forEach(t),Z7r=i(We),JC=n(We,"LI",{});var kHe=s(JC);Z0e=n(kHe,"STRONG",{});var qra=s(Z0e);K7r=r(qra,"wavlm"),qra.forEach(t),eLr=r(kHe," \u2014 "),Lee=n(kHe,"A",{href:!0});var jra=s(Lee);oLr=r(jra,"WavLMForSequenceClassification"),jra.forEach(t),rLr=r(kHe," (WavLM model)"),kHe.forEach(t),We.forEach(t),tLr=i(Va),YC=n(Va,"P",{});var SHe=s(YC);aLr=r(SHe,"The model is set in evaluation mode by default using "),K0e=n(SHe,"CODE",{});var Dra=s(K0e);nLr=r(Dra,"model.eval()"),Dra.forEach(t),sLr=r(SHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ewe=n(SHe,"CODE",{});var Gra=s(ewe);lLr=r(Gra,"model.train()"),Gra.forEach(t),SHe.forEach(t),iLr=i(Va),T(ZC.$$.fragment,Va),Va.forEach(t),ei.forEach(t),Nto=i(m),kc=n(m,"H2",{class:!0});var rso=s(kc);KC=n(rso,"A",{id:!0,class:!0,href:!0});var Ora=s(KC);owe=n(Ora,"SPAN",{});var Vra=s(owe);T(dS.$$.fragment,Vra),Vra.forEach(t),Ora.forEach(t),dLr=i(rso),rwe=n(rso,"SPAN",{});var Xra=s(rwe);cLr=r(Xra,"AutoModelForAudioFrameClassification"),Xra.forEach(t),rso.forEach(t),qto=i(m),er=n(m,"DIV",{class:!0});var oi=s(er);T(cS.$$.fragment,oi),mLr=i(oi),Sc=n(oi,"P",{});var Tce=s(Sc);fLr=r(Tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),yee=n(Tce,"A",{href:!0});var zra=s(yee);gLr=r(zra,"from_pretrained()"),zra.forEach(t),hLr=r(Tce," class method or the "),xee=n(Tce,"A",{href:!0});var Qra=s(xee);uLr=r(Qra,"from_config()"),Qra.forEach(t),pLr=r(Tce,` class
method.`),Tce.forEach(t),_Lr=i(oi),mS=n(oi,"P",{});var tso=s(mS);bLr=r(tso,"This class cannot be instantiated directly using "),twe=n(tso,"CODE",{});var Wra=s(twe);vLr=r(Wra,"__init__()"),Wra.forEach(t),FLr=r(tso," (throws an error)."),tso.forEach(t),TLr=i(oi),Dt=n(oi,"DIV",{class:!0});var A9=s(Dt);T(fS.$$.fragment,A9),MLr=i(A9),awe=n(A9,"P",{});var Ura=s(awe);ELr=r(Ura,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Ura.forEach(t),CLr=i(A9),Rc=n(A9,"P",{});var Mce=s(Rc);wLr=r(Mce,`Note:
Loading a model from its configuration file does `),nwe=n(Mce,"STRONG",{});var Hra=s(nwe);ALr=r(Hra,"not"),Hra.forEach(t),LLr=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ee=n(Mce,"A",{href:!0});var Jra=s($ee);yLr=r(Jra,"from_pretrained()"),Jra.forEach(t),xLr=r(Mce," to load the model weights."),Mce.forEach(t),$Lr=i(A9),T(e3.$$.fragment,A9),A9.forEach(t),kLr=i(oi),bo=n(oi,"DIV",{class:!0});var Xa=s(bo);T(gS.$$.fragment,Xa),SLr=i(Xa),swe=n(Xa,"P",{});var Yra=s(swe);RLr=r(Yra,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Yra.forEach(t),PLr=i(Xa),En=n(Xa,"P",{});var L9=s(En);BLr=r(L9,"The model class to instantiate is selected based on the "),lwe=n(L9,"CODE",{});var Zra=s(lwe);ILr=r(Zra,"model_type"),Zra.forEach(t),NLr=r(L9,` property of the config object (either
passed as an argument or loaded from `),iwe=n(L9,"CODE",{});var Kra=s(iwe);qLr=r(Kra,"pretrained_model_name_or_path"),Kra.forEach(t),jLr=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=n(L9,"CODE",{});var eta=s(dwe);DLr=r(eta,"pretrained_model_name_or_path"),eta.forEach(t),GLr=r(L9,":"),L9.forEach(t),OLr=i(Xa),ut=n(Xa,"UL",{});var ri=s(ut);o3=n(ri,"LI",{});var RHe=s(o3);cwe=n(RHe,"STRONG",{});var ota=s(cwe);VLr=r(ota,"data2vec-audio"),ota.forEach(t),XLr=r(RHe," \u2014 "),kee=n(RHe,"A",{href:!0});var rta=s(kee);zLr=r(rta,"Data2VecAudioForAudioFrameClassification"),rta.forEach(t),QLr=r(RHe," (Data2VecAudio model)"),RHe.forEach(t),WLr=i(ri),r3=n(ri,"LI",{});var PHe=s(r3);mwe=n(PHe,"STRONG",{});var tta=s(mwe);ULr=r(tta,"unispeech-sat"),tta.forEach(t),HLr=r(PHe," \u2014 "),See=n(PHe,"A",{href:!0});var ata=s(See);JLr=r(ata,"UniSpeechSatForAudioFrameClassification"),ata.forEach(t),YLr=r(PHe," (UniSpeechSat model)"),PHe.forEach(t),ZLr=i(ri),t3=n(ri,"LI",{});var BHe=s(t3);fwe=n(BHe,"STRONG",{});var nta=s(fwe);KLr=r(nta,"wav2vec2"),nta.forEach(t),e8r=r(BHe," \u2014 "),Ree=n(BHe,"A",{href:!0});var sta=s(Ree);o8r=r(sta,"Wav2Vec2ForAudioFrameClassification"),sta.forEach(t),r8r=r(BHe," (Wav2Vec2 model)"),BHe.forEach(t),t8r=i(ri),a3=n(ri,"LI",{});var IHe=s(a3);gwe=n(IHe,"STRONG",{});var lta=s(gwe);a8r=r(lta,"wav2vec2-conformer"),lta.forEach(t),n8r=r(IHe," \u2014 "),Pee=n(IHe,"A",{href:!0});var ita=s(Pee);s8r=r(ita,"Wav2Vec2ConformerForAudioFrameClassification"),ita.forEach(t),l8r=r(IHe," (Wav2Vec2-Conformer model)"),IHe.forEach(t),i8r=i(ri),n3=n(ri,"LI",{});var NHe=s(n3);hwe=n(NHe,"STRONG",{});var dta=s(hwe);d8r=r(dta,"wavlm"),dta.forEach(t),c8r=r(NHe," \u2014 "),Bee=n(NHe,"A",{href:!0});var cta=s(Bee);m8r=r(cta,"WavLMForAudioFrameClassification"),cta.forEach(t),f8r=r(NHe," (WavLM model)"),NHe.forEach(t),ri.forEach(t),g8r=i(Xa),s3=n(Xa,"P",{});var qHe=s(s3);h8r=r(qHe,"The model is set in evaluation mode by default using "),uwe=n(qHe,"CODE",{});var mta=s(uwe);u8r=r(mta,"model.eval()"),mta.forEach(t),p8r=r(qHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pwe=n(qHe,"CODE",{});var fta=s(pwe);_8r=r(fta,"model.train()"),fta.forEach(t),qHe.forEach(t),b8r=i(Xa),T(l3.$$.fragment,Xa),Xa.forEach(t),oi.forEach(t),jto=i(m),Pc=n(m,"H2",{class:!0});var aso=s(Pc);i3=n(aso,"A",{id:!0,class:!0,href:!0});var gta=s(i3);_we=n(gta,"SPAN",{});var hta=s(_we);T(hS.$$.fragment,hta),hta.forEach(t),gta.forEach(t),v8r=i(aso),bwe=n(aso,"SPAN",{});var uta=s(bwe);F8r=r(uta,"AutoModelForCTC"),uta.forEach(t),aso.forEach(t),Dto=i(m),or=n(m,"DIV",{class:!0});var ti=s(or);T(uS.$$.fragment,ti),T8r=i(ti),Bc=n(ti,"P",{});var Ece=s(Bc);M8r=r(Ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Iee=n(Ece,"A",{href:!0});var pta=s(Iee);E8r=r(pta,"from_pretrained()"),pta.forEach(t),C8r=r(Ece," class method or the "),Nee=n(Ece,"A",{href:!0});var _ta=s(Nee);w8r=r(_ta,"from_config()"),_ta.forEach(t),A8r=r(Ece,` class
method.`),Ece.forEach(t),L8r=i(ti),pS=n(ti,"P",{});var nso=s(pS);y8r=r(nso,"This class cannot be instantiated directly using "),vwe=n(nso,"CODE",{});var bta=s(vwe);x8r=r(bta,"__init__()"),bta.forEach(t),$8r=r(nso," (throws an error)."),nso.forEach(t),k8r=i(ti),Gt=n(ti,"DIV",{class:!0});var y9=s(Gt);T(_S.$$.fragment,y9),S8r=i(y9),Fwe=n(y9,"P",{});var vta=s(Fwe);R8r=r(vta,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),vta.forEach(t),P8r=i(y9),Ic=n(y9,"P",{});var Cce=s(Ic);B8r=r(Cce,`Note:
Loading a model from its configuration file does `),Twe=n(Cce,"STRONG",{});var Fta=s(Twe);I8r=r(Fta,"not"),Fta.forEach(t),N8r=r(Cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),qee=n(Cce,"A",{href:!0});var Tta=s(qee);q8r=r(Tta,"from_pretrained()"),Tta.forEach(t),j8r=r(Cce," to load the model weights."),Cce.forEach(t),D8r=i(y9),T(d3.$$.fragment,y9),y9.forEach(t),G8r=i(ti),vo=n(ti,"DIV",{class:!0});var za=s(vo);T(bS.$$.fragment,za),O8r=i(za),Mwe=n(za,"P",{});var Mta=s(Mwe);V8r=r(Mta,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Mta.forEach(t),X8r=i(za),Cn=n(za,"P",{});var x9=s(Cn);z8r=r(x9,"The model class to instantiate is selected based on the "),Ewe=n(x9,"CODE",{});var Eta=s(Ewe);Q8r=r(Eta,"model_type"),Eta.forEach(t),W8r=r(x9,` property of the config object (either
passed as an argument or loaded from `),Cwe=n(x9,"CODE",{});var Cta=s(Cwe);U8r=r(Cta,"pretrained_model_name_or_path"),Cta.forEach(t),H8r=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wwe=n(x9,"CODE",{});var wta=s(wwe);J8r=r(wta,"pretrained_model_name_or_path"),wta.forEach(t),Y8r=r(x9,":"),x9.forEach(t),Z8r=i(za),Le=n(za,"UL",{});var Ie=s(Le);c3=n(Ie,"LI",{});var jHe=s(c3);Awe=n(jHe,"STRONG",{});var Ata=s(Awe);K8r=r(Ata,"data2vec-audio"),Ata.forEach(t),eyr=r(jHe," \u2014 "),jee=n(jHe,"A",{href:!0});var Lta=s(jee);oyr=r(Lta,"Data2VecAudioForCTC"),Lta.forEach(t),ryr=r(jHe," (Data2VecAudio model)"),jHe.forEach(t),tyr=i(Ie),m3=n(Ie,"LI",{});var DHe=s(m3);Lwe=n(DHe,"STRONG",{});var yta=s(Lwe);ayr=r(yta,"hubert"),yta.forEach(t),nyr=r(DHe," \u2014 "),Dee=n(DHe,"A",{href:!0});var xta=s(Dee);syr=r(xta,"HubertForCTC"),xta.forEach(t),lyr=r(DHe," (Hubert model)"),DHe.forEach(t),iyr=i(Ie),f3=n(Ie,"LI",{});var GHe=s(f3);ywe=n(GHe,"STRONG",{});var $ta=s(ywe);dyr=r($ta,"mctct"),$ta.forEach(t),cyr=r(GHe," \u2014 "),Gee=n(GHe,"A",{href:!0});var kta=s(Gee);myr=r(kta,"MCTCTForCTC"),kta.forEach(t),fyr=r(GHe," (M-CTC-T model)"),GHe.forEach(t),gyr=i(Ie),g3=n(Ie,"LI",{});var OHe=s(g3);xwe=n(OHe,"STRONG",{});var Sta=s(xwe);hyr=r(Sta,"sew"),Sta.forEach(t),uyr=r(OHe," \u2014 "),Oee=n(OHe,"A",{href:!0});var Rta=s(Oee);pyr=r(Rta,"SEWForCTC"),Rta.forEach(t),_yr=r(OHe," (SEW model)"),OHe.forEach(t),byr=i(Ie),h3=n(Ie,"LI",{});var VHe=s(h3);$we=n(VHe,"STRONG",{});var Pta=s($we);vyr=r(Pta,"sew-d"),Pta.forEach(t),Fyr=r(VHe," \u2014 "),Vee=n(VHe,"A",{href:!0});var Bta=s(Vee);Tyr=r(Bta,"SEWDForCTC"),Bta.forEach(t),Myr=r(VHe," (SEW-D model)"),VHe.forEach(t),Eyr=i(Ie),u3=n(Ie,"LI",{});var XHe=s(u3);kwe=n(XHe,"STRONG",{});var Ita=s(kwe);Cyr=r(Ita,"unispeech"),Ita.forEach(t),wyr=r(XHe," \u2014 "),Xee=n(XHe,"A",{href:!0});var Nta=s(Xee);Ayr=r(Nta,"UniSpeechForCTC"),Nta.forEach(t),Lyr=r(XHe," (UniSpeech model)"),XHe.forEach(t),yyr=i(Ie),p3=n(Ie,"LI",{});var zHe=s(p3);Swe=n(zHe,"STRONG",{});var qta=s(Swe);xyr=r(qta,"unispeech-sat"),qta.forEach(t),$yr=r(zHe," \u2014 "),zee=n(zHe,"A",{href:!0});var jta=s(zee);kyr=r(jta,"UniSpeechSatForCTC"),jta.forEach(t),Syr=r(zHe," (UniSpeechSat model)"),zHe.forEach(t),Ryr=i(Ie),_3=n(Ie,"LI",{});var QHe=s(_3);Rwe=n(QHe,"STRONG",{});var Dta=s(Rwe);Pyr=r(Dta,"wav2vec2"),Dta.forEach(t),Byr=r(QHe," \u2014 "),Qee=n(QHe,"A",{href:!0});var Gta=s(Qee);Iyr=r(Gta,"Wav2Vec2ForCTC"),Gta.forEach(t),Nyr=r(QHe," (Wav2Vec2 model)"),QHe.forEach(t),qyr=i(Ie),b3=n(Ie,"LI",{});var WHe=s(b3);Pwe=n(WHe,"STRONG",{});var Ota=s(Pwe);jyr=r(Ota,"wav2vec2-conformer"),Ota.forEach(t),Dyr=r(WHe," \u2014 "),Wee=n(WHe,"A",{href:!0});var Vta=s(Wee);Gyr=r(Vta,"Wav2Vec2ConformerForCTC"),Vta.forEach(t),Oyr=r(WHe," (Wav2Vec2-Conformer model)"),WHe.forEach(t),Vyr=i(Ie),v3=n(Ie,"LI",{});var UHe=s(v3);Bwe=n(UHe,"STRONG",{});var Xta=s(Bwe);Xyr=r(Xta,"wavlm"),Xta.forEach(t),zyr=r(UHe," \u2014 "),Uee=n(UHe,"A",{href:!0});var zta=s(Uee);Qyr=r(zta,"WavLMForCTC"),zta.forEach(t),Wyr=r(UHe," (WavLM model)"),UHe.forEach(t),Ie.forEach(t),Uyr=i(za),F3=n(za,"P",{});var HHe=s(F3);Hyr=r(HHe,"The model is set in evaluation mode by default using "),Iwe=n(HHe,"CODE",{});var Qta=s(Iwe);Jyr=r(Qta,"model.eval()"),Qta.forEach(t),Yyr=r(HHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nwe=n(HHe,"CODE",{});var Wta=s(Nwe);Zyr=r(Wta,"model.train()"),Wta.forEach(t),HHe.forEach(t),Kyr=i(za),T(T3.$$.fragment,za),za.forEach(t),ti.forEach(t),Gto=i(m),Nc=n(m,"H2",{class:!0});var sso=s(Nc);M3=n(sso,"A",{id:!0,class:!0,href:!0});var Uta=s(M3);qwe=n(Uta,"SPAN",{});var Hta=s(qwe);T(vS.$$.fragment,Hta),Hta.forEach(t),Uta.forEach(t),e9r=i(sso),jwe=n(sso,"SPAN",{});var Jta=s(jwe);o9r=r(Jta,"AutoModelForSpeechSeq2Seq"),Jta.forEach(t),sso.forEach(t),Oto=i(m),rr=n(m,"DIV",{class:!0});var ai=s(rr);T(FS.$$.fragment,ai),r9r=i(ai),qc=n(ai,"P",{});var wce=s(qc);t9r=r(wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Hee=n(wce,"A",{href:!0});var Yta=s(Hee);a9r=r(Yta,"from_pretrained()"),Yta.forEach(t),n9r=r(wce," class method or the "),Jee=n(wce,"A",{href:!0});var Zta=s(Jee);s9r=r(Zta,"from_config()"),Zta.forEach(t),l9r=r(wce,` class
method.`),wce.forEach(t),i9r=i(ai),TS=n(ai,"P",{});var lso=s(TS);d9r=r(lso,"This class cannot be instantiated directly using "),Dwe=n(lso,"CODE",{});var Kta=s(Dwe);c9r=r(Kta,"__init__()"),Kta.forEach(t),m9r=r(lso," (throws an error)."),lso.forEach(t),f9r=i(ai),Ot=n(ai,"DIV",{class:!0});var $9=s(Ot);T(MS.$$.fragment,$9),g9r=i($9),Gwe=n($9,"P",{});var eaa=s(Gwe);h9r=r(eaa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eaa.forEach(t),u9r=i($9),jc=n($9,"P",{});var Ace=s(jc);p9r=r(Ace,`Note:
Loading a model from its configuration file does `),Owe=n(Ace,"STRONG",{});var oaa=s(Owe);_9r=r(oaa,"not"),oaa.forEach(t),b9r=r(Ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=n(Ace,"A",{href:!0});var raa=s(Yee);v9r=r(raa,"from_pretrained()"),raa.forEach(t),F9r=r(Ace," to load the model weights."),Ace.forEach(t),T9r=i($9),T(E3.$$.fragment,$9),$9.forEach(t),M9r=i(ai),Fo=n(ai,"DIV",{class:!0});var Qa=s(Fo);T(ES.$$.fragment,Qa),E9r=i(Qa),Vwe=n(Qa,"P",{});var taa=s(Vwe);C9r=r(taa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),taa.forEach(t),w9r=i(Qa),wn=n(Qa,"P",{});var k9=s(wn);A9r=r(k9,"The model class to instantiate is selected based on the "),Xwe=n(k9,"CODE",{});var aaa=s(Xwe);L9r=r(aaa,"model_type"),aaa.forEach(t),y9r=r(k9,` property of the config object (either
passed as an argument or loaded from `),zwe=n(k9,"CODE",{});var naa=s(zwe);x9r=r(naa,"pretrained_model_name_or_path"),naa.forEach(t),$9r=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qwe=n(k9,"CODE",{});var saa=s(Qwe);k9r=r(saa,"pretrained_model_name_or_path"),saa.forEach(t),S9r=r(k9,":"),k9.forEach(t),R9r=i(Qa),Dc=n(Qa,"UL",{});var Lce=s(Dc);C3=n(Lce,"LI",{});var JHe=s(C3);Wwe=n(JHe,"STRONG",{});var laa=s(Wwe);P9r=r(laa,"speech-encoder-decoder"),laa.forEach(t),B9r=r(JHe," \u2014 "),Zee=n(JHe,"A",{href:!0});var iaa=s(Zee);I9r=r(iaa,"SpeechEncoderDecoderModel"),iaa.forEach(t),N9r=r(JHe," (Speech Encoder decoder model)"),JHe.forEach(t),q9r=i(Lce),w3=n(Lce,"LI",{});var YHe=s(w3);Uwe=n(YHe,"STRONG",{});var daa=s(Uwe);j9r=r(daa,"speech_to_text"),daa.forEach(t),D9r=r(YHe," \u2014 "),Kee=n(YHe,"A",{href:!0});var caa=s(Kee);G9r=r(caa,"Speech2TextForConditionalGeneration"),caa.forEach(t),O9r=r(YHe," (Speech2Text model)"),YHe.forEach(t),V9r=i(Lce),A3=n(Lce,"LI",{});var ZHe=s(A3);Hwe=n(ZHe,"STRONG",{});var maa=s(Hwe);X9r=r(maa,"whisper"),maa.forEach(t),z9r=r(ZHe," \u2014 "),eoe=n(ZHe,"A",{href:!0});var faa=s(eoe);Q9r=r(faa,"WhisperForConditionalGeneration"),faa.forEach(t),W9r=r(ZHe," (Whisper model)"),ZHe.forEach(t),Lce.forEach(t),U9r=i(Qa),L3=n(Qa,"P",{});var KHe=s(L3);H9r=r(KHe,"The model is set in evaluation mode by default using "),Jwe=n(KHe,"CODE",{});var gaa=s(Jwe);J9r=r(gaa,"model.eval()"),gaa.forEach(t),Y9r=r(KHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ywe=n(KHe,"CODE",{});var haa=s(Ywe);Z9r=r(haa,"model.train()"),haa.forEach(t),KHe.forEach(t),K9r=i(Qa),T(y3.$$.fragment,Qa),Qa.forEach(t),ai.forEach(t),Vto=i(m),Gc=n(m,"H2",{class:!0});var iso=s(Gc);x3=n(iso,"A",{id:!0,class:!0,href:!0});var uaa=s(x3);Zwe=n(uaa,"SPAN",{});var paa=s(Zwe);T(CS.$$.fragment,paa),paa.forEach(t),uaa.forEach(t),exr=i(iso),Kwe=n(iso,"SPAN",{});var _aa=s(Kwe);oxr=r(_aa,"AutoModelForAudioXVector"),_aa.forEach(t),iso.forEach(t),Xto=i(m),tr=n(m,"DIV",{class:!0});var ni=s(tr);T(wS.$$.fragment,ni),rxr=i(ni),Oc=n(ni,"P",{});var yce=s(Oc);txr=r(yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),ooe=n(yce,"A",{href:!0});var baa=s(ooe);axr=r(baa,"from_pretrained()"),baa.forEach(t),nxr=r(yce," class method or the "),roe=n(yce,"A",{href:!0});var vaa=s(roe);sxr=r(vaa,"from_config()"),vaa.forEach(t),lxr=r(yce,` class
method.`),yce.forEach(t),ixr=i(ni),AS=n(ni,"P",{});var dso=s(AS);dxr=r(dso,"This class cannot be instantiated directly using "),eAe=n(dso,"CODE",{});var Faa=s(eAe);cxr=r(Faa,"__init__()"),Faa.forEach(t),mxr=r(dso," (throws an error)."),dso.forEach(t),fxr=i(ni),Vt=n(ni,"DIV",{class:!0});var S9=s(Vt);T(LS.$$.fragment,S9),gxr=i(S9),oAe=n(S9,"P",{});var Taa=s(oAe);hxr=r(Taa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Taa.forEach(t),uxr=i(S9),Vc=n(S9,"P",{});var xce=s(Vc);pxr=r(xce,`Note:
Loading a model from its configuration file does `),rAe=n(xce,"STRONG",{});var Maa=s(rAe);_xr=r(Maa,"not"),Maa.forEach(t),bxr=r(xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=n(xce,"A",{href:!0});var Eaa=s(toe);vxr=r(Eaa,"from_pretrained()"),Eaa.forEach(t),Fxr=r(xce," to load the model weights."),xce.forEach(t),Txr=i(S9),T($3.$$.fragment,S9),S9.forEach(t),Mxr=i(ni),To=n(ni,"DIV",{class:!0});var Wa=s(To);T(yS.$$.fragment,Wa),Exr=i(Wa),tAe=n(Wa,"P",{});var Caa=s(tAe);Cxr=r(Caa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Caa.forEach(t),wxr=i(Wa),An=n(Wa,"P",{});var R9=s(An);Axr=r(R9,"The model class to instantiate is selected based on the "),aAe=n(R9,"CODE",{});var waa=s(aAe);Lxr=r(waa,"model_type"),waa.forEach(t),yxr=r(R9,` property of the config object (either
passed as an argument or loaded from `),nAe=n(R9,"CODE",{});var Aaa=s(nAe);xxr=r(Aaa,"pretrained_model_name_or_path"),Aaa.forEach(t),$xr=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sAe=n(R9,"CODE",{});var Laa=s(sAe);kxr=r(Laa,"pretrained_model_name_or_path"),Laa.forEach(t),Sxr=r(R9,":"),R9.forEach(t),Rxr=i(Wa),pt=n(Wa,"UL",{});var si=s(pt);k3=n(si,"LI",{});var eJe=s(k3);lAe=n(eJe,"STRONG",{});var yaa=s(lAe);Pxr=r(yaa,"data2vec-audio"),yaa.forEach(t),Bxr=r(eJe," \u2014 "),aoe=n(eJe,"A",{href:!0});var xaa=s(aoe);Ixr=r(xaa,"Data2VecAudioForXVector"),xaa.forEach(t),Nxr=r(eJe," (Data2VecAudio model)"),eJe.forEach(t),qxr=i(si),S3=n(si,"LI",{});var oJe=s(S3);iAe=n(oJe,"STRONG",{});var $aa=s(iAe);jxr=r($aa,"unispeech-sat"),$aa.forEach(t),Dxr=r(oJe," \u2014 "),noe=n(oJe,"A",{href:!0});var kaa=s(noe);Gxr=r(kaa,"UniSpeechSatForXVector"),kaa.forEach(t),Oxr=r(oJe," (UniSpeechSat model)"),oJe.forEach(t),Vxr=i(si),R3=n(si,"LI",{});var rJe=s(R3);dAe=n(rJe,"STRONG",{});var Saa=s(dAe);Xxr=r(Saa,"wav2vec2"),Saa.forEach(t),zxr=r(rJe," \u2014 "),soe=n(rJe,"A",{href:!0});var Raa=s(soe);Qxr=r(Raa,"Wav2Vec2ForXVector"),Raa.forEach(t),Wxr=r(rJe," (Wav2Vec2 model)"),rJe.forEach(t),Uxr=i(si),P3=n(si,"LI",{});var tJe=s(P3);cAe=n(tJe,"STRONG",{});var Paa=s(cAe);Hxr=r(Paa,"wav2vec2-conformer"),Paa.forEach(t),Jxr=r(tJe," \u2014 "),loe=n(tJe,"A",{href:!0});var Baa=s(loe);Yxr=r(Baa,"Wav2Vec2ConformerForXVector"),Baa.forEach(t),Zxr=r(tJe," (Wav2Vec2-Conformer model)"),tJe.forEach(t),Kxr=i(si),B3=n(si,"LI",{});var aJe=s(B3);mAe=n(aJe,"STRONG",{});var Iaa=s(mAe);e$r=r(Iaa,"wavlm"),Iaa.forEach(t),o$r=r(aJe," \u2014 "),ioe=n(aJe,"A",{href:!0});var Naa=s(ioe);r$r=r(Naa,"WavLMForXVector"),Naa.forEach(t),t$r=r(aJe," (WavLM model)"),aJe.forEach(t),si.forEach(t),a$r=i(Wa),I3=n(Wa,"P",{});var nJe=s(I3);n$r=r(nJe,"The model is set in evaluation mode by default using "),fAe=n(nJe,"CODE",{});var qaa=s(fAe);s$r=r(qaa,"model.eval()"),qaa.forEach(t),l$r=r(nJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gAe=n(nJe,"CODE",{});var jaa=s(gAe);i$r=r(jaa,"model.train()"),jaa.forEach(t),nJe.forEach(t),d$r=i(Wa),T(N3.$$.fragment,Wa),Wa.forEach(t),ni.forEach(t),zto=i(m),Xc=n(m,"H2",{class:!0});var cso=s(Xc);q3=n(cso,"A",{id:!0,class:!0,href:!0});var Daa=s(q3);hAe=n(Daa,"SPAN",{});var Gaa=s(hAe);T(xS.$$.fragment,Gaa),Gaa.forEach(t),Daa.forEach(t),c$r=i(cso),uAe=n(cso,"SPAN",{});var Oaa=s(uAe);m$r=r(Oaa,"AutoModelForMaskedImageModeling"),Oaa.forEach(t),cso.forEach(t),Qto=i(m),ar=n(m,"DIV",{class:!0});var li=s(ar);T($S.$$.fragment,li),f$r=i(li),zc=n(li,"P",{});var $ce=s(zc);g$r=r($ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),doe=n($ce,"A",{href:!0});var Vaa=s(doe);h$r=r(Vaa,"from_pretrained()"),Vaa.forEach(t),u$r=r($ce," class method or the "),coe=n($ce,"A",{href:!0});var Xaa=s(coe);p$r=r(Xaa,"from_config()"),Xaa.forEach(t),_$r=r($ce,` class
method.`),$ce.forEach(t),b$r=i(li),kS=n(li,"P",{});var mso=s(kS);v$r=r(mso,"This class cannot be instantiated directly using "),pAe=n(mso,"CODE",{});var zaa=s(pAe);F$r=r(zaa,"__init__()"),zaa.forEach(t),T$r=r(mso," (throws an error)."),mso.forEach(t),M$r=i(li),Xt=n(li,"DIV",{class:!0});var P9=s(Xt);T(SS.$$.fragment,P9),E$r=i(P9),_Ae=n(P9,"P",{});var Qaa=s(_Ae);C$r=r(Qaa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Qaa.forEach(t),w$r=i(P9),Qc=n(P9,"P",{});var kce=s(Qc);A$r=r(kce,`Note:
Loading a model from its configuration file does `),bAe=n(kce,"STRONG",{});var Waa=s(bAe);L$r=r(Waa,"not"),Waa.forEach(t),y$r=r(kce,` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=n(kce,"A",{href:!0});var Uaa=s(moe);x$r=r(Uaa,"from_pretrained()"),Uaa.forEach(t),$$r=r(kce," to load the model weights."),kce.forEach(t),k$r=i(P9),T(j3.$$.fragment,P9),P9.forEach(t),S$r=i(li),Mo=n(li,"DIV",{class:!0});var Ua=s(Mo);T(RS.$$.fragment,Ua),R$r=i(Ua),vAe=n(Ua,"P",{});var Haa=s(vAe);P$r=r(Haa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Haa.forEach(t),B$r=i(Ua),Ln=n(Ua,"P",{});var B9=s(Ln);I$r=r(B9,"The model class to instantiate is selected based on the "),FAe=n(B9,"CODE",{});var Jaa=s(FAe);N$r=r(Jaa,"model_type"),Jaa.forEach(t),q$r=r(B9,` property of the config object (either
passed as an argument or loaded from `),TAe=n(B9,"CODE",{});var Yaa=s(TAe);j$r=r(Yaa,"pretrained_model_name_or_path"),Yaa.forEach(t),D$r=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MAe=n(B9,"CODE",{});var Zaa=s(MAe);G$r=r(Zaa,"pretrained_model_name_or_path"),Zaa.forEach(t),O$r=r(B9,":"),B9.forEach(t),V$r=i(Ua),yn=n(Ua,"UL",{});var I9=s(yn);D3=n(I9,"LI",{});var sJe=s(D3);EAe=n(sJe,"STRONG",{});var Kaa=s(EAe);X$r=r(Kaa,"deit"),Kaa.forEach(t),z$r=r(sJe," \u2014 "),foe=n(sJe,"A",{href:!0});var ena=s(foe);Q$r=r(ena,"DeiTForMaskedImageModeling"),ena.forEach(t),W$r=r(sJe," (DeiT model)"),sJe.forEach(t),U$r=i(I9),G3=n(I9,"LI",{});var lJe=s(G3);CAe=n(lJe,"STRONG",{});var ona=s(CAe);H$r=r(ona,"swin"),ona.forEach(t),J$r=r(lJe," \u2014 "),goe=n(lJe,"A",{href:!0});var rna=s(goe);Y$r=r(rna,"SwinForMaskedImageModeling"),rna.forEach(t),Z$r=r(lJe," (Swin Transformer model)"),lJe.forEach(t),K$r=i(I9),O3=n(I9,"LI",{});var iJe=s(O3);wAe=n(iJe,"STRONG",{});var tna=s(wAe);ekr=r(tna,"swinv2"),tna.forEach(t),okr=r(iJe," \u2014 "),hoe=n(iJe,"A",{href:!0});var ana=s(hoe);rkr=r(ana,"Swinv2ForMaskedImageModeling"),ana.forEach(t),tkr=r(iJe," (Swin Transformer V2 model)"),iJe.forEach(t),akr=i(I9),V3=n(I9,"LI",{});var dJe=s(V3);AAe=n(dJe,"STRONG",{});var nna=s(AAe);nkr=r(nna,"vit"),nna.forEach(t),skr=r(dJe," \u2014 "),uoe=n(dJe,"A",{href:!0});var sna=s(uoe);lkr=r(sna,"ViTForMaskedImageModeling"),sna.forEach(t),ikr=r(dJe," (ViT model)"),dJe.forEach(t),I9.forEach(t),dkr=i(Ua),X3=n(Ua,"P",{});var cJe=s(X3);ckr=r(cJe,"The model is set in evaluation mode by default using "),LAe=n(cJe,"CODE",{});var lna=s(LAe);mkr=r(lna,"model.eval()"),lna.forEach(t),fkr=r(cJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yAe=n(cJe,"CODE",{});var ina=s(yAe);gkr=r(ina,"model.train()"),ina.forEach(t),cJe.forEach(t),hkr=i(Ua),T(z3.$$.fragment,Ua),Ua.forEach(t),li.forEach(t),Wto=i(m),Wc=n(m,"H2",{class:!0});var fso=s(Wc);Q3=n(fso,"A",{id:!0,class:!0,href:!0});var dna=s(Q3);xAe=n(dna,"SPAN",{});var cna=s(xAe);T(PS.$$.fragment,cna),cna.forEach(t),dna.forEach(t),ukr=i(fso),$Ae=n(fso,"SPAN",{});var mna=s($Ae);pkr=r(mna,"AutoModelForObjectDetection"),mna.forEach(t),fso.forEach(t),Uto=i(m),nr=n(m,"DIV",{class:!0});var ii=s(nr);T(BS.$$.fragment,ii),_kr=i(ii),Uc=n(ii,"P",{});var Sce=s(Uc);bkr=r(Sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),poe=n(Sce,"A",{href:!0});var fna=s(poe);vkr=r(fna,"from_pretrained()"),fna.forEach(t),Fkr=r(Sce," class method or the "),_oe=n(Sce,"A",{href:!0});var gna=s(_oe);Tkr=r(gna,"from_config()"),gna.forEach(t),Mkr=r(Sce,` class
method.`),Sce.forEach(t),Ekr=i(ii),IS=n(ii,"P",{});var gso=s(IS);Ckr=r(gso,"This class cannot be instantiated directly using "),kAe=n(gso,"CODE",{});var hna=s(kAe);wkr=r(hna,"__init__()"),hna.forEach(t),Akr=r(gso," (throws an error)."),gso.forEach(t),Lkr=i(ii),zt=n(ii,"DIV",{class:!0});var N9=s(zt);T(NS.$$.fragment,N9),ykr=i(N9),SAe=n(N9,"P",{});var una=s(SAe);xkr=r(una,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),una.forEach(t),$kr=i(N9),Hc=n(N9,"P",{});var Rce=s(Hc);kkr=r(Rce,`Note:
Loading a model from its configuration file does `),RAe=n(Rce,"STRONG",{});var pna=s(RAe);Skr=r(pna,"not"),pna.forEach(t),Rkr=r(Rce,` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=n(Rce,"A",{href:!0});var _na=s(boe);Pkr=r(_na,"from_pretrained()"),_na.forEach(t),Bkr=r(Rce," to load the model weights."),Rce.forEach(t),Ikr=i(N9),T(W3.$$.fragment,N9),N9.forEach(t),Nkr=i(ii),Eo=n(ii,"DIV",{class:!0});var Ha=s(Eo);T(qS.$$.fragment,Ha),qkr=i(Ha),PAe=n(Ha,"P",{});var bna=s(PAe);jkr=r(bna,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),bna.forEach(t),Dkr=i(Ha),xn=n(Ha,"P",{});var q9=s(xn);Gkr=r(q9,"The model class to instantiate is selected based on the "),BAe=n(q9,"CODE",{});var vna=s(BAe);Okr=r(vna,"model_type"),vna.forEach(t),Vkr=r(q9,` property of the config object (either
passed as an argument or loaded from `),IAe=n(q9,"CODE",{});var Fna=s(IAe);Xkr=r(Fna,"pretrained_model_name_or_path"),Fna.forEach(t),zkr=r(q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NAe=n(q9,"CODE",{});var Tna=s(NAe);Qkr=r(Tna,"pretrained_model_name_or_path"),Tna.forEach(t),Wkr=r(q9,":"),q9.forEach(t),Ukr=i(Ha),$n=n(Ha,"UL",{});var j9=s($n);U3=n(j9,"LI",{});var mJe=s(U3);qAe=n(mJe,"STRONG",{});var Mna=s(qAe);Hkr=r(Mna,"conditional_detr"),Mna.forEach(t),Jkr=r(mJe," \u2014 "),voe=n(mJe,"A",{href:!0});var Ena=s(voe);Ykr=r(Ena,"ConditionalDetrForObjectDetection"),Ena.forEach(t),Zkr=r(mJe," (Conditional DETR model)"),mJe.forEach(t),Kkr=i(j9),H3=n(j9,"LI",{});var fJe=s(H3);jAe=n(fJe,"STRONG",{});var Cna=s(jAe);eSr=r(Cna,"deformable_detr"),Cna.forEach(t),oSr=r(fJe," \u2014 "),Foe=n(fJe,"A",{href:!0});var wna=s(Foe);rSr=r(wna,"DeformableDetrForObjectDetection"),wna.forEach(t),tSr=r(fJe," (Deformable DETR model)"),fJe.forEach(t),aSr=i(j9),J3=n(j9,"LI",{});var gJe=s(J3);DAe=n(gJe,"STRONG",{});var Ana=s(DAe);nSr=r(Ana,"detr"),Ana.forEach(t),sSr=r(gJe," \u2014 "),Toe=n(gJe,"A",{href:!0});var Lna=s(Toe);lSr=r(Lna,"DetrForObjectDetection"),Lna.forEach(t),iSr=r(gJe," (DETR model)"),gJe.forEach(t),dSr=i(j9),Y3=n(j9,"LI",{});var hJe=s(Y3);GAe=n(hJe,"STRONG",{});var yna=s(GAe);cSr=r(yna,"yolos"),yna.forEach(t),mSr=r(hJe," \u2014 "),Moe=n(hJe,"A",{href:!0});var xna=s(Moe);fSr=r(xna,"YolosForObjectDetection"),xna.forEach(t),gSr=r(hJe," (YOLOS model)"),hJe.forEach(t),j9.forEach(t),hSr=i(Ha),Z3=n(Ha,"P",{});var uJe=s(Z3);uSr=r(uJe,"The model is set in evaluation mode by default using "),OAe=n(uJe,"CODE",{});var $na=s(OAe);pSr=r($na,"model.eval()"),$na.forEach(t),_Sr=r(uJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VAe=n(uJe,"CODE",{});var kna=s(VAe);bSr=r(kna,"model.train()"),kna.forEach(t),uJe.forEach(t),vSr=i(Ha),T(K3.$$.fragment,Ha),Ha.forEach(t),ii.forEach(t),Hto=i(m),Jc=n(m,"H2",{class:!0});var hso=s(Jc);e5=n(hso,"A",{id:!0,class:!0,href:!0});var Sna=s(e5);XAe=n(Sna,"SPAN",{});var Rna=s(XAe);T(jS.$$.fragment,Rna),Rna.forEach(t),Sna.forEach(t),FSr=i(hso),zAe=n(hso,"SPAN",{});var Pna=s(zAe);TSr=r(Pna,"AutoModelForImageSegmentation"),Pna.forEach(t),hso.forEach(t),Jto=i(m),sr=n(m,"DIV",{class:!0});var di=s(sr);T(DS.$$.fragment,di),MSr=i(di),Yc=n(di,"P",{});var Pce=s(Yc);ESr=r(Pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Eoe=n(Pce,"A",{href:!0});var Bna=s(Eoe);CSr=r(Bna,"from_pretrained()"),Bna.forEach(t),wSr=r(Pce," class method or the "),Coe=n(Pce,"A",{href:!0});var Ina=s(Coe);ASr=r(Ina,"from_config()"),Ina.forEach(t),LSr=r(Pce,` class
method.`),Pce.forEach(t),ySr=i(di),GS=n(di,"P",{});var uso=s(GS);xSr=r(uso,"This class cannot be instantiated directly using "),QAe=n(uso,"CODE",{});var Nna=s(QAe);$Sr=r(Nna,"__init__()"),Nna.forEach(t),kSr=r(uso," (throws an error)."),uso.forEach(t),SSr=i(di),Qt=n(di,"DIV",{class:!0});var D9=s(Qt);T(OS.$$.fragment,D9),RSr=i(D9),WAe=n(D9,"P",{});var qna=s(WAe);PSr=r(qna,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),qna.forEach(t),BSr=i(D9),Zc=n(D9,"P",{});var Bce=s(Zc);ISr=r(Bce,`Note:
Loading a model from its configuration file does `),UAe=n(Bce,"STRONG",{});var jna=s(UAe);NSr=r(jna,"not"),jna.forEach(t),qSr=r(Bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),woe=n(Bce,"A",{href:!0});var Dna=s(woe);jSr=r(Dna,"from_pretrained()"),Dna.forEach(t),DSr=r(Bce," to load the model weights."),Bce.forEach(t),GSr=i(D9),T(o5.$$.fragment,D9),D9.forEach(t),OSr=i(di),Co=n(di,"DIV",{class:!0});var Ja=s(Co);T(VS.$$.fragment,Ja),VSr=i(Ja),HAe=n(Ja,"P",{});var Gna=s(HAe);XSr=r(Gna,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Gna.forEach(t),zSr=i(Ja),kn=n(Ja,"P",{});var G9=s(kn);QSr=r(G9,"The model class to instantiate is selected based on the "),JAe=n(G9,"CODE",{});var Ona=s(JAe);WSr=r(Ona,"model_type"),Ona.forEach(t),USr=r(G9,` property of the config object (either
passed as an argument or loaded from `),YAe=n(G9,"CODE",{});var Vna=s(YAe);HSr=r(Vna,"pretrained_model_name_or_path"),Vna.forEach(t),JSr=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZAe=n(G9,"CODE",{});var Xna=s(ZAe);YSr=r(Xna,"pretrained_model_name_or_path"),Xna.forEach(t),ZSr=r(G9,":"),G9.forEach(t),KSr=i(Ja),KAe=n(Ja,"UL",{});var zna=s(KAe);r5=n(zna,"LI",{});var pJe=s(r5);e6e=n(pJe,"STRONG",{});var Qna=s(e6e);eRr=r(Qna,"detr"),Qna.forEach(t),oRr=r(pJe," \u2014 "),Aoe=n(pJe,"A",{href:!0});var Wna=s(Aoe);rRr=r(Wna,"DetrForSegmentation"),Wna.forEach(t),tRr=r(pJe," (DETR model)"),pJe.forEach(t),zna.forEach(t),aRr=i(Ja),t5=n(Ja,"P",{});var _Je=s(t5);nRr=r(_Je,"The model is set in evaluation mode by default using "),o6e=n(_Je,"CODE",{});var Una=s(o6e);sRr=r(Una,"model.eval()"),Una.forEach(t),lRr=r(_Je,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r6e=n(_Je,"CODE",{});var Hna=s(r6e);iRr=r(Hna,"model.train()"),Hna.forEach(t),_Je.forEach(t),dRr=i(Ja),T(a5.$$.fragment,Ja),Ja.forEach(t),di.forEach(t),Yto=i(m),Kc=n(m,"H2",{class:!0});var pso=s(Kc);n5=n(pso,"A",{id:!0,class:!0,href:!0});var Jna=s(n5);t6e=n(Jna,"SPAN",{});var Yna=s(t6e);T(XS.$$.fragment,Yna),Yna.forEach(t),Jna.forEach(t),cRr=i(pso),a6e=n(pso,"SPAN",{});var Zna=s(a6e);mRr=r(Zna,"AutoModelForSemanticSegmentation"),Zna.forEach(t),pso.forEach(t),Zto=i(m),lr=n(m,"DIV",{class:!0});var ci=s(lr);T(zS.$$.fragment,ci),fRr=i(ci),em=n(ci,"P",{});var Ice=s(em);gRr=r(Ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Loe=n(Ice,"A",{href:!0});var Kna=s(Loe);hRr=r(Kna,"from_pretrained()"),Kna.forEach(t),uRr=r(Ice," class method or the "),yoe=n(Ice,"A",{href:!0});var esa=s(yoe);pRr=r(esa,"from_config()"),esa.forEach(t),_Rr=r(Ice,` class
method.`),Ice.forEach(t),bRr=i(ci),QS=n(ci,"P",{});var _so=s(QS);vRr=r(_so,"This class cannot be instantiated directly using "),n6e=n(_so,"CODE",{});var osa=s(n6e);FRr=r(osa,"__init__()"),osa.forEach(t),TRr=r(_so," (throws an error)."),_so.forEach(t),MRr=i(ci),Wt=n(ci,"DIV",{class:!0});var O9=s(Wt);T(WS.$$.fragment,O9),ERr=i(O9),s6e=n(O9,"P",{});var rsa=s(s6e);CRr=r(rsa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),rsa.forEach(t),wRr=i(O9),om=n(O9,"P",{});var Nce=s(om);ARr=r(Nce,`Note:
Loading a model from its configuration file does `),l6e=n(Nce,"STRONG",{});var tsa=s(l6e);LRr=r(tsa,"not"),tsa.forEach(t),yRr=r(Nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xoe=n(Nce,"A",{href:!0});var asa=s(xoe);xRr=r(asa,"from_pretrained()"),asa.forEach(t),$Rr=r(Nce," to load the model weights."),Nce.forEach(t),kRr=i(O9),T(s5.$$.fragment,O9),O9.forEach(t),SRr=i(ci),wo=n(ci,"DIV",{class:!0});var Ya=s(wo);T(US.$$.fragment,Ya),RRr=i(Ya),i6e=n(Ya,"P",{});var nsa=s(i6e);PRr=r(nsa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),nsa.forEach(t),BRr=i(Ya),Sn=n(Ya,"P",{});var V9=s(Sn);IRr=r(V9,"The model class to instantiate is selected based on the "),d6e=n(V9,"CODE",{});var ssa=s(d6e);NRr=r(ssa,"model_type"),ssa.forEach(t),qRr=r(V9,` property of the config object (either
passed as an argument or loaded from `),c6e=n(V9,"CODE",{});var lsa=s(c6e);jRr=r(lsa,"pretrained_model_name_or_path"),lsa.forEach(t),DRr=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=n(V9,"CODE",{});var isa=s(m6e);GRr=r(isa,"pretrained_model_name_or_path"),isa.forEach(t),ORr=r(V9,":"),V9.forEach(t),VRr=i(Ya),_t=n(Ya,"UL",{});var mi=s(_t);l5=n(mi,"LI",{});var bJe=s(l5);f6e=n(bJe,"STRONG",{});var dsa=s(f6e);XRr=r(dsa,"beit"),dsa.forEach(t),zRr=r(bJe," \u2014 "),$oe=n(bJe,"A",{href:!0});var csa=s($oe);QRr=r(csa,"BeitForSemanticSegmentation"),csa.forEach(t),WRr=r(bJe," (BEiT model)"),bJe.forEach(t),URr=i(mi),i5=n(mi,"LI",{});var vJe=s(i5);g6e=n(vJe,"STRONG",{});var msa=s(g6e);HRr=r(msa,"data2vec-vision"),msa.forEach(t),JRr=r(vJe," \u2014 "),koe=n(vJe,"A",{href:!0});var fsa=s(koe);YRr=r(fsa,"Data2VecVisionForSemanticSegmentation"),fsa.forEach(t),ZRr=r(vJe," (Data2VecVision model)"),vJe.forEach(t),KRr=i(mi),d5=n(mi,"LI",{});var FJe=s(d5);h6e=n(FJe,"STRONG",{});var gsa=s(h6e);ePr=r(gsa,"dpt"),gsa.forEach(t),oPr=r(FJe," \u2014 "),Soe=n(FJe,"A",{href:!0});var hsa=s(Soe);rPr=r(hsa,"DPTForSemanticSegmentation"),hsa.forEach(t),tPr=r(FJe," (DPT model)"),FJe.forEach(t),aPr=i(mi),c5=n(mi,"LI",{});var TJe=s(c5);u6e=n(TJe,"STRONG",{});var usa=s(u6e);nPr=r(usa,"mobilevit"),usa.forEach(t),sPr=r(TJe," \u2014 "),Roe=n(TJe,"A",{href:!0});var psa=s(Roe);lPr=r(psa,"MobileViTForSemanticSegmentation"),psa.forEach(t),iPr=r(TJe," (MobileViT model)"),TJe.forEach(t),dPr=i(mi),m5=n(mi,"LI",{});var MJe=s(m5);p6e=n(MJe,"STRONG",{});var _sa=s(p6e);cPr=r(_sa,"segformer"),_sa.forEach(t),mPr=r(MJe," \u2014 "),Poe=n(MJe,"A",{href:!0});var bsa=s(Poe);fPr=r(bsa,"SegformerForSemanticSegmentation"),bsa.forEach(t),gPr=r(MJe," (SegFormer model)"),MJe.forEach(t),mi.forEach(t),hPr=i(Ya),f5=n(Ya,"P",{});var EJe=s(f5);uPr=r(EJe,"The model is set in evaluation mode by default using "),_6e=n(EJe,"CODE",{});var vsa=s(_6e);pPr=r(vsa,"model.eval()"),vsa.forEach(t),_Pr=r(EJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b6e=n(EJe,"CODE",{});var Fsa=s(b6e);bPr=r(Fsa,"model.train()"),Fsa.forEach(t),EJe.forEach(t),vPr=i(Ya),T(g5.$$.fragment,Ya),Ya.forEach(t),ci.forEach(t),Kto=i(m),rm=n(m,"H2",{class:!0});var bso=s(rm);h5=n(bso,"A",{id:!0,class:!0,href:!0});var Tsa=s(h5);v6e=n(Tsa,"SPAN",{});var Msa=s(v6e);T(HS.$$.fragment,Msa),Msa.forEach(t),Tsa.forEach(t),FPr=i(bso),F6e=n(bso,"SPAN",{});var Esa=s(F6e);TPr=r(Esa,"AutoModelForInstanceSegmentation"),Esa.forEach(t),bso.forEach(t),eao=i(m),ir=n(m,"DIV",{class:!0});var fi=s(ir);T(JS.$$.fragment,fi),MPr=i(fi),tm=n(fi,"P",{});var qce=s(tm);EPr=r(qce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Boe=n(qce,"A",{href:!0});var Csa=s(Boe);CPr=r(Csa,"from_pretrained()"),Csa.forEach(t),wPr=r(qce," class method or the "),Ioe=n(qce,"A",{href:!0});var wsa=s(Ioe);APr=r(wsa,"from_config()"),wsa.forEach(t),LPr=r(qce,` class
method.`),qce.forEach(t),yPr=i(fi),YS=n(fi,"P",{});var vso=s(YS);xPr=r(vso,"This class cannot be instantiated directly using "),T6e=n(vso,"CODE",{});var Asa=s(T6e);$Pr=r(Asa,"__init__()"),Asa.forEach(t),kPr=r(vso," (throws an error)."),vso.forEach(t),SPr=i(fi),Ut=n(fi,"DIV",{class:!0});var X9=s(Ut);T(ZS.$$.fragment,X9),RPr=i(X9),M6e=n(X9,"P",{});var Lsa=s(M6e);PPr=r(Lsa,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Lsa.forEach(t),BPr=i(X9),am=n(X9,"P",{});var jce=s(am);IPr=r(jce,`Note:
Loading a model from its configuration file does `),E6e=n(jce,"STRONG",{});var ysa=s(E6e);NPr=r(ysa,"not"),ysa.forEach(t),qPr=r(jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Noe=n(jce,"A",{href:!0});var xsa=s(Noe);jPr=r(xsa,"from_pretrained()"),xsa.forEach(t),DPr=r(jce," to load the model weights."),jce.forEach(t),GPr=i(X9),T(u5.$$.fragment,X9),X9.forEach(t),OPr=i(fi),Ao=n(fi,"DIV",{class:!0});var Za=s(Ao);T(KS.$$.fragment,Za),VPr=i(Za),C6e=n(Za,"P",{});var $sa=s(C6e);XPr=r($sa,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),$sa.forEach(t),zPr=i(Za),Rn=n(Za,"P",{});var z9=s(Rn);QPr=r(z9,"The model class to instantiate is selected based on the "),w6e=n(z9,"CODE",{});var ksa=s(w6e);WPr=r(ksa,"model_type"),ksa.forEach(t),UPr=r(z9,` property of the config object (either
passed as an argument or loaded from `),A6e=n(z9,"CODE",{});var Ssa=s(A6e);HPr=r(Ssa,"pretrained_model_name_or_path"),Ssa.forEach(t),JPr=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L6e=n(z9,"CODE",{});var Rsa=s(L6e);YPr=r(Rsa,"pretrained_model_name_or_path"),Rsa.forEach(t),ZPr=r(z9,":"),z9.forEach(t),KPr=i(Za),y6e=n(Za,"UL",{});var Psa=s(y6e);p5=n(Psa,"LI",{});var CJe=s(p5);x6e=n(CJe,"STRONG",{});var Bsa=s(x6e);eBr=r(Bsa,"maskformer"),Bsa.forEach(t),oBr=r(CJe," \u2014 "),qoe=n(CJe,"A",{href:!0});var Isa=s(qoe);rBr=r(Isa,"MaskFormerForInstanceSegmentation"),Isa.forEach(t),tBr=r(CJe," (MaskFormer model)"),CJe.forEach(t),Psa.forEach(t),aBr=i(Za),_5=n(Za,"P",{});var wJe=s(_5);nBr=r(wJe,"The model is set in evaluation mode by default using "),$6e=n(wJe,"CODE",{});var Nsa=s($6e);sBr=r(Nsa,"model.eval()"),Nsa.forEach(t),lBr=r(wJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k6e=n(wJe,"CODE",{});var qsa=s(k6e);iBr=r(qsa,"model.train()"),qsa.forEach(t),wJe.forEach(t),dBr=i(Za),T(b5.$$.fragment,Za),Za.forEach(t),fi.forEach(t),oao=i(m),nm=n(m,"H2",{class:!0});var Fso=s(nm);v5=n(Fso,"A",{id:!0,class:!0,href:!0});var jsa=s(v5);S6e=n(jsa,"SPAN",{});var Dsa=s(S6e);T(eR.$$.fragment,Dsa),Dsa.forEach(t),jsa.forEach(t),cBr=i(Fso),R6e=n(Fso,"SPAN",{});var Gsa=s(R6e);mBr=r(Gsa,"AutoModelForZeroShotObjectDetection"),Gsa.forEach(t),Fso.forEach(t),rao=i(m),dr=n(m,"DIV",{class:!0});var gi=s(dr);T(oR.$$.fragment,gi),fBr=i(gi),sm=n(gi,"P",{});var Dce=s(sm);gBr=r(Dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),joe=n(Dce,"A",{href:!0});var Osa=s(joe);hBr=r(Osa,"from_pretrained()"),Osa.forEach(t),uBr=r(Dce," class method or the "),Doe=n(Dce,"A",{href:!0});var Vsa=s(Doe);pBr=r(Vsa,"from_config()"),Vsa.forEach(t),_Br=r(Dce,` class
method.`),Dce.forEach(t),bBr=i(gi),rR=n(gi,"P",{});var Tso=s(rR);vBr=r(Tso,"This class cannot be instantiated directly using "),P6e=n(Tso,"CODE",{});var Xsa=s(P6e);FBr=r(Xsa,"__init__()"),Xsa.forEach(t),TBr=r(Tso," (throws an error)."),Tso.forEach(t),MBr=i(gi),Ht=n(gi,"DIV",{class:!0});var Q9=s(Ht);T(tR.$$.fragment,Q9),EBr=i(Q9),B6e=n(Q9,"P",{});var zsa=s(B6e);CBr=r(zsa,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),zsa.forEach(t),wBr=i(Q9),lm=n(Q9,"P",{});var Gce=s(lm);ABr=r(Gce,`Note:
Loading a model from its configuration file does `),I6e=n(Gce,"STRONG",{});var Qsa=s(I6e);LBr=r(Qsa,"not"),Qsa.forEach(t),yBr=r(Gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=n(Gce,"A",{href:!0});var Wsa=s(Goe);xBr=r(Wsa,"from_pretrained()"),Wsa.forEach(t),$Br=r(Gce," to load the model weights."),Gce.forEach(t),kBr=i(Q9),T(F5.$$.fragment,Q9),Q9.forEach(t),SBr=i(gi),Lo=n(gi,"DIV",{class:!0});var Ka=s(Lo);T(aR.$$.fragment,Ka),RBr=i(Ka),N6e=n(Ka,"P",{});var Usa=s(N6e);PBr=r(Usa,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Usa.forEach(t),BBr=i(Ka),Pn=n(Ka,"P",{});var W9=s(Pn);IBr=r(W9,"The model class to instantiate is selected based on the "),q6e=n(W9,"CODE",{});var Hsa=s(q6e);NBr=r(Hsa,"model_type"),Hsa.forEach(t),qBr=r(W9,` property of the config object (either
passed as an argument or loaded from `),j6e=n(W9,"CODE",{});var Jsa=s(j6e);jBr=r(Jsa,"pretrained_model_name_or_path"),Jsa.forEach(t),DBr=r(W9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=n(W9,"CODE",{});var Ysa=s(D6e);GBr=r(Ysa,"pretrained_model_name_or_path"),Ysa.forEach(t),OBr=r(W9,":"),W9.forEach(t),VBr=i(Ka),G6e=n(Ka,"UL",{});var Zsa=s(G6e);T5=n(Zsa,"LI",{});var AJe=s(T5);O6e=n(AJe,"STRONG",{});var Ksa=s(O6e);XBr=r(Ksa,"owlvit"),Ksa.forEach(t),zBr=r(AJe," \u2014 "),Ooe=n(AJe,"A",{href:!0});var ela=s(Ooe);QBr=r(ela,"OwlViTForObjectDetection"),ela.forEach(t),WBr=r(AJe," (OWL-ViT model)"),AJe.forEach(t),Zsa.forEach(t),UBr=i(Ka),M5=n(Ka,"P",{});var LJe=s(M5);HBr=r(LJe,"The model is set in evaluation mode by default using "),V6e=n(LJe,"CODE",{});var ola=s(V6e);JBr=r(ola,"model.eval()"),ola.forEach(t),YBr=r(LJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X6e=n(LJe,"CODE",{});var rla=s(X6e);ZBr=r(rla,"model.train()"),rla.forEach(t),LJe.forEach(t),KBr=i(Ka),T(E5.$$.fragment,Ka),Ka.forEach(t),gi.forEach(t),tao=i(m),im=n(m,"H2",{class:!0});var Mso=s(im);C5=n(Mso,"A",{id:!0,class:!0,href:!0});var tla=s(C5);z6e=n(tla,"SPAN",{});var ala=s(z6e);T(nR.$$.fragment,ala),ala.forEach(t),tla.forEach(t),eIr=i(Mso),Q6e=n(Mso,"SPAN",{});var nla=s(Q6e);oIr=r(nla,"TFAutoModel"),nla.forEach(t),Mso.forEach(t),aao=i(m),cr=n(m,"DIV",{class:!0});var hi=s(cr);T(sR.$$.fragment,hi),rIr=i(hi),dm=n(hi,"P",{});var Oce=s(dm);tIr=r(Oce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Voe=n(Oce,"A",{href:!0});var sla=s(Voe);aIr=r(sla,"from_pretrained()"),sla.forEach(t),nIr=r(Oce," class method or the "),Xoe=n(Oce,"A",{href:!0});var lla=s(Xoe);sIr=r(lla,"from_config()"),lla.forEach(t),lIr=r(Oce,` class
method.`),Oce.forEach(t),iIr=i(hi),lR=n(hi,"P",{});var Eso=s(lR);dIr=r(Eso,"This class cannot be instantiated directly using "),W6e=n(Eso,"CODE",{});var ila=s(W6e);cIr=r(ila,"__init__()"),ila.forEach(t),mIr=r(Eso," (throws an error)."),Eso.forEach(t),fIr=i(hi),Jt=n(hi,"DIV",{class:!0});var U9=s(Jt);T(iR.$$.fragment,U9),gIr=i(U9),U6e=n(U9,"P",{});var dla=s(U6e);hIr=r(dla,"Instantiates one of the base model classes of the library from a configuration."),dla.forEach(t),uIr=i(U9),cm=n(U9,"P",{});var Vce=s(cm);pIr=r(Vce,`Note:
Loading a model from its configuration file does `),H6e=n(Vce,"STRONG",{});var cla=s(H6e);_Ir=r(cla,"not"),cla.forEach(t),bIr=r(Vce,` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=n(Vce,"A",{href:!0});var mla=s(zoe);vIr=r(mla,"from_pretrained()"),mla.forEach(t),FIr=r(Vce," to load the model weights."),Vce.forEach(t),TIr=i(U9),T(w5.$$.fragment,U9),U9.forEach(t),MIr=i(hi),Dr=n(hi,"DIV",{class:!0});var ui=s(Dr);T(dR.$$.fragment,ui),EIr=i(ui),J6e=n(ui,"P",{});var fla=s(J6e);CIr=r(fla,"Instantiate one of the base model classes of the library from a pretrained model."),fla.forEach(t),wIr=i(ui),Bn=n(ui,"P",{});var H9=s(Bn);AIr=r(H9,"The model class to instantiate is selected based on the "),Y6e=n(H9,"CODE",{});var gla=s(Y6e);LIr=r(gla,"model_type"),gla.forEach(t),yIr=r(H9,` property of the config object (either
passed as an argument or loaded from `),Z6e=n(H9,"CODE",{});var hla=s(Z6e);xIr=r(hla,"pretrained_model_name_or_path"),hla.forEach(t),$Ir=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K6e=n(H9,"CODE",{});var ula=s(K6e);kIr=r(ula,"pretrained_model_name_or_path"),ula.forEach(t),SIr=r(H9,":"),H9.forEach(t),RIr=i(ui),B=n(ui,"UL",{});var j=s(B);A5=n(j,"LI",{});var yJe=s(A5);e7e=n(yJe,"STRONG",{});var pla=s(e7e);PIr=r(pla,"albert"),pla.forEach(t),BIr=r(yJe," \u2014 "),Qoe=n(yJe,"A",{href:!0});var _la=s(Qoe);IIr=r(_la,"TFAlbertModel"),_la.forEach(t),NIr=r(yJe," (ALBERT model)"),yJe.forEach(t),qIr=i(j),L5=n(j,"LI",{});var xJe=s(L5);o7e=n(xJe,"STRONG",{});var bla=s(o7e);jIr=r(bla,"bart"),bla.forEach(t),DIr=r(xJe," \u2014 "),Woe=n(xJe,"A",{href:!0});var vla=s(Woe);GIr=r(vla,"TFBartModel"),vla.forEach(t),OIr=r(xJe," (BART model)"),xJe.forEach(t),VIr=i(j),y5=n(j,"LI",{});var $Je=s(y5);r7e=n($Je,"STRONG",{});var Fla=s(r7e);XIr=r(Fla,"bert"),Fla.forEach(t),zIr=r($Je," \u2014 "),Uoe=n($Je,"A",{href:!0});var Tla=s(Uoe);QIr=r(Tla,"TFBertModel"),Tla.forEach(t),WIr=r($Je," (BERT model)"),$Je.forEach(t),UIr=i(j),x5=n(j,"LI",{});var kJe=s(x5);t7e=n(kJe,"STRONG",{});var Mla=s(t7e);HIr=r(Mla,"blenderbot"),Mla.forEach(t),JIr=r(kJe," \u2014 "),Hoe=n(kJe,"A",{href:!0});var Ela=s(Hoe);YIr=r(Ela,"TFBlenderbotModel"),Ela.forEach(t),ZIr=r(kJe," (Blenderbot model)"),kJe.forEach(t),KIr=i(j),$5=n(j,"LI",{});var SJe=s($5);a7e=n(SJe,"STRONG",{});var Cla=s(a7e);eNr=r(Cla,"blenderbot-small"),Cla.forEach(t),oNr=r(SJe," \u2014 "),Joe=n(SJe,"A",{href:!0});var wla=s(Joe);rNr=r(wla,"TFBlenderbotSmallModel"),wla.forEach(t),tNr=r(SJe," (BlenderbotSmall model)"),SJe.forEach(t),aNr=i(j),k5=n(j,"LI",{});var RJe=s(k5);n7e=n(RJe,"STRONG",{});var Ala=s(n7e);nNr=r(Ala,"camembert"),Ala.forEach(t),sNr=r(RJe," \u2014 "),Yoe=n(RJe,"A",{href:!0});var Lla=s(Yoe);lNr=r(Lla,"TFCamembertModel"),Lla.forEach(t),iNr=r(RJe," (CamemBERT model)"),RJe.forEach(t),dNr=i(j),S5=n(j,"LI",{});var PJe=s(S5);s7e=n(PJe,"STRONG",{});var yla=s(s7e);cNr=r(yla,"clip"),yla.forEach(t),mNr=r(PJe," \u2014 "),Zoe=n(PJe,"A",{href:!0});var xla=s(Zoe);fNr=r(xla,"TFCLIPModel"),xla.forEach(t),gNr=r(PJe," (CLIP model)"),PJe.forEach(t),hNr=i(j),R5=n(j,"LI",{});var BJe=s(R5);l7e=n(BJe,"STRONG",{});var $la=s(l7e);uNr=r($la,"convbert"),$la.forEach(t),pNr=r(BJe," \u2014 "),Koe=n(BJe,"A",{href:!0});var kla=s(Koe);_Nr=r(kla,"TFConvBertModel"),kla.forEach(t),bNr=r(BJe," (ConvBERT model)"),BJe.forEach(t),vNr=i(j),P5=n(j,"LI",{});var IJe=s(P5);i7e=n(IJe,"STRONG",{});var Sla=s(i7e);FNr=r(Sla,"convnext"),Sla.forEach(t),TNr=r(IJe," \u2014 "),ere=n(IJe,"A",{href:!0});var Rla=s(ere);MNr=r(Rla,"TFConvNextModel"),Rla.forEach(t),ENr=r(IJe," (ConvNeXT model)"),IJe.forEach(t),CNr=i(j),B5=n(j,"LI",{});var NJe=s(B5);d7e=n(NJe,"STRONG",{});var Pla=s(d7e);wNr=r(Pla,"ctrl"),Pla.forEach(t),ANr=r(NJe," \u2014 "),ore=n(NJe,"A",{href:!0});var Bla=s(ore);LNr=r(Bla,"TFCTRLModel"),Bla.forEach(t),yNr=r(NJe," (CTRL model)"),NJe.forEach(t),xNr=i(j),I5=n(j,"LI",{});var qJe=s(I5);c7e=n(qJe,"STRONG",{});var Ila=s(c7e);$Nr=r(Ila,"cvt"),Ila.forEach(t),kNr=r(qJe," \u2014 "),rre=n(qJe,"A",{href:!0});var Nla=s(rre);SNr=r(Nla,"TFCvtModel"),Nla.forEach(t),RNr=r(qJe," (CvT model)"),qJe.forEach(t),PNr=i(j),N5=n(j,"LI",{});var jJe=s(N5);m7e=n(jJe,"STRONG",{});var qla=s(m7e);BNr=r(qla,"data2vec-vision"),qla.forEach(t),INr=r(jJe," \u2014 "),tre=n(jJe,"A",{href:!0});var jla=s(tre);NNr=r(jla,"TFData2VecVisionModel"),jla.forEach(t),qNr=r(jJe," (Data2VecVision model)"),jJe.forEach(t),jNr=i(j),q5=n(j,"LI",{});var DJe=s(q5);f7e=n(DJe,"STRONG",{});var Dla=s(f7e);DNr=r(Dla,"deberta"),Dla.forEach(t),GNr=r(DJe," \u2014 "),are=n(DJe,"A",{href:!0});var Gla=s(are);ONr=r(Gla,"TFDebertaModel"),Gla.forEach(t),VNr=r(DJe," (DeBERTa model)"),DJe.forEach(t),XNr=i(j),j5=n(j,"LI",{});var GJe=s(j5);g7e=n(GJe,"STRONG",{});var Ola=s(g7e);zNr=r(Ola,"deberta-v2"),Ola.forEach(t),QNr=r(GJe," \u2014 "),nre=n(GJe,"A",{href:!0});var Vla=s(nre);WNr=r(Vla,"TFDebertaV2Model"),Vla.forEach(t),UNr=r(GJe," (DeBERTa-v2 model)"),GJe.forEach(t),HNr=i(j),D5=n(j,"LI",{});var OJe=s(D5);h7e=n(OJe,"STRONG",{});var Xla=s(h7e);JNr=r(Xla,"deit"),Xla.forEach(t),YNr=r(OJe," \u2014 "),sre=n(OJe,"A",{href:!0});var zla=s(sre);ZNr=r(zla,"TFDeiTModel"),zla.forEach(t),KNr=r(OJe," (DeiT model)"),OJe.forEach(t),eqr=i(j),G5=n(j,"LI",{});var VJe=s(G5);u7e=n(VJe,"STRONG",{});var Qla=s(u7e);oqr=r(Qla,"distilbert"),Qla.forEach(t),rqr=r(VJe," \u2014 "),lre=n(VJe,"A",{href:!0});var Wla=s(lre);tqr=r(Wla,"TFDistilBertModel"),Wla.forEach(t),aqr=r(VJe," (DistilBERT model)"),VJe.forEach(t),nqr=i(j),O5=n(j,"LI",{});var XJe=s(O5);p7e=n(XJe,"STRONG",{});var Ula=s(p7e);sqr=r(Ula,"dpr"),Ula.forEach(t),lqr=r(XJe," \u2014 "),ire=n(XJe,"A",{href:!0});var Hla=s(ire);iqr=r(Hla,"TFDPRQuestionEncoder"),Hla.forEach(t),dqr=r(XJe," (DPR model)"),XJe.forEach(t),cqr=i(j),V5=n(j,"LI",{});var zJe=s(V5);_7e=n(zJe,"STRONG",{});var Jla=s(_7e);mqr=r(Jla,"electra"),Jla.forEach(t),fqr=r(zJe," \u2014 "),dre=n(zJe,"A",{href:!0});var Yla=s(dre);gqr=r(Yla,"TFElectraModel"),Yla.forEach(t),hqr=r(zJe," (ELECTRA model)"),zJe.forEach(t),uqr=i(j),X5=n(j,"LI",{});var QJe=s(X5);b7e=n(QJe,"STRONG",{});var Zla=s(b7e);pqr=r(Zla,"flaubert"),Zla.forEach(t),_qr=r(QJe," \u2014 "),cre=n(QJe,"A",{href:!0});var Kla=s(cre);bqr=r(Kla,"TFFlaubertModel"),Kla.forEach(t),vqr=r(QJe," (FlauBERT model)"),QJe.forEach(t),Fqr=i(j),kl=n(j,"LI",{});var cN=s(kl);v7e=n(cN,"STRONG",{});var eia=s(v7e);Tqr=r(eia,"funnel"),eia.forEach(t),Mqr=r(cN," \u2014 "),mre=n(cN,"A",{href:!0});var oia=s(mre);Eqr=r(oia,"TFFunnelModel"),oia.forEach(t),Cqr=r(cN," or "),fre=n(cN,"A",{href:!0});var ria=s(fre);wqr=r(ria,"TFFunnelBaseModel"),ria.forEach(t),Aqr=r(cN," (Funnel Transformer model)"),cN.forEach(t),Lqr=i(j),z5=n(j,"LI",{});var WJe=s(z5);F7e=n(WJe,"STRONG",{});var tia=s(F7e);yqr=r(tia,"gpt2"),tia.forEach(t),xqr=r(WJe," \u2014 "),gre=n(WJe,"A",{href:!0});var aia=s(gre);$qr=r(aia,"TFGPT2Model"),aia.forEach(t),kqr=r(WJe," (OpenAI GPT-2 model)"),WJe.forEach(t),Sqr=i(j),Q5=n(j,"LI",{});var UJe=s(Q5);T7e=n(UJe,"STRONG",{});var nia=s(T7e);Rqr=r(nia,"gptj"),nia.forEach(t),Pqr=r(UJe," \u2014 "),hre=n(UJe,"A",{href:!0});var sia=s(hre);Bqr=r(sia,"TFGPTJModel"),sia.forEach(t),Iqr=r(UJe," (GPT-J model)"),UJe.forEach(t),Nqr=i(j),W5=n(j,"LI",{});var HJe=s(W5);M7e=n(HJe,"STRONG",{});var lia=s(M7e);qqr=r(lia,"groupvit"),lia.forEach(t),jqr=r(HJe," \u2014 "),ure=n(HJe,"A",{href:!0});var iia=s(ure);Dqr=r(iia,"TFGroupViTModel"),iia.forEach(t),Gqr=r(HJe," (GroupViT model)"),HJe.forEach(t),Oqr=i(j),U5=n(j,"LI",{});var JJe=s(U5);E7e=n(JJe,"STRONG",{});var dia=s(E7e);Vqr=r(dia,"hubert"),dia.forEach(t),Xqr=r(JJe," \u2014 "),pre=n(JJe,"A",{href:!0});var cia=s(pre);zqr=r(cia,"TFHubertModel"),cia.forEach(t),Qqr=r(JJe," (Hubert model)"),JJe.forEach(t),Wqr=i(j),H5=n(j,"LI",{});var YJe=s(H5);C7e=n(YJe,"STRONG",{});var mia=s(C7e);Uqr=r(mia,"layoutlm"),mia.forEach(t),Hqr=r(YJe," \u2014 "),_re=n(YJe,"A",{href:!0});var fia=s(_re);Jqr=r(fia,"TFLayoutLMModel"),fia.forEach(t),Yqr=r(YJe," (LayoutLM model)"),YJe.forEach(t),Zqr=i(j),J5=n(j,"LI",{});var ZJe=s(J5);w7e=n(ZJe,"STRONG",{});var gia=s(w7e);Kqr=r(gia,"layoutlmv3"),gia.forEach(t),ejr=r(ZJe," \u2014 "),bre=n(ZJe,"A",{href:!0});var hia=s(bre);ojr=r(hia,"TFLayoutLMv3Model"),hia.forEach(t),rjr=r(ZJe," (LayoutLMv3 model)"),ZJe.forEach(t),tjr=i(j),Y5=n(j,"LI",{});var KJe=s(Y5);A7e=n(KJe,"STRONG",{});var uia=s(A7e);ajr=r(uia,"led"),uia.forEach(t),njr=r(KJe," \u2014 "),vre=n(KJe,"A",{href:!0});var pia=s(vre);sjr=r(pia,"TFLEDModel"),pia.forEach(t),ljr=r(KJe," (LED model)"),KJe.forEach(t),ijr=i(j),Z5=n(j,"LI",{});var eYe=s(Z5);L7e=n(eYe,"STRONG",{});var _ia=s(L7e);djr=r(_ia,"longformer"),_ia.forEach(t),cjr=r(eYe," \u2014 "),Fre=n(eYe,"A",{href:!0});var bia=s(Fre);mjr=r(bia,"TFLongformerModel"),bia.forEach(t),fjr=r(eYe," (Longformer model)"),eYe.forEach(t),gjr=i(j),K5=n(j,"LI",{});var oYe=s(K5);y7e=n(oYe,"STRONG",{});var via=s(y7e);hjr=r(via,"lxmert"),via.forEach(t),ujr=r(oYe," \u2014 "),Tre=n(oYe,"A",{href:!0});var Fia=s(Tre);pjr=r(Fia,"TFLxmertModel"),Fia.forEach(t),_jr=r(oYe," (LXMERT model)"),oYe.forEach(t),bjr=i(j),e0=n(j,"LI",{});var rYe=s(e0);x7e=n(rYe,"STRONG",{});var Tia=s(x7e);vjr=r(Tia,"marian"),Tia.forEach(t),Fjr=r(rYe," \u2014 "),Mre=n(rYe,"A",{href:!0});var Mia=s(Mre);Tjr=r(Mia,"TFMarianModel"),Mia.forEach(t),Mjr=r(rYe," (Marian model)"),rYe.forEach(t),Ejr=i(j),o0=n(j,"LI",{});var tYe=s(o0);$7e=n(tYe,"STRONG",{});var Eia=s($7e);Cjr=r(Eia,"mbart"),Eia.forEach(t),wjr=r(tYe," \u2014 "),Ere=n(tYe,"A",{href:!0});var Cia=s(Ere);Ajr=r(Cia,"TFMBartModel"),Cia.forEach(t),Ljr=r(tYe," (mBART model)"),tYe.forEach(t),yjr=i(j),r0=n(j,"LI",{});var aYe=s(r0);k7e=n(aYe,"STRONG",{});var wia=s(k7e);xjr=r(wia,"mobilebert"),wia.forEach(t),$jr=r(aYe," \u2014 "),Cre=n(aYe,"A",{href:!0});var Aia=s(Cre);kjr=r(Aia,"TFMobileBertModel"),Aia.forEach(t),Sjr=r(aYe," (MobileBERT model)"),aYe.forEach(t),Rjr=i(j),t0=n(j,"LI",{});var nYe=s(t0);S7e=n(nYe,"STRONG",{});var Lia=s(S7e);Pjr=r(Lia,"mobilevit"),Lia.forEach(t),Bjr=r(nYe," \u2014 "),wre=n(nYe,"A",{href:!0});var yia=s(wre);Ijr=r(yia,"TFMobileViTModel"),yia.forEach(t),Njr=r(nYe," (MobileViT model)"),nYe.forEach(t),qjr=i(j),a0=n(j,"LI",{});var sYe=s(a0);R7e=n(sYe,"STRONG",{});var xia=s(R7e);jjr=r(xia,"mpnet"),xia.forEach(t),Djr=r(sYe," \u2014 "),Are=n(sYe,"A",{href:!0});var $ia=s(Are);Gjr=r($ia,"TFMPNetModel"),$ia.forEach(t),Ojr=r(sYe," (MPNet model)"),sYe.forEach(t),Vjr=i(j),n0=n(j,"LI",{});var lYe=s(n0);P7e=n(lYe,"STRONG",{});var kia=s(P7e);Xjr=r(kia,"mt5"),kia.forEach(t),zjr=r(lYe," \u2014 "),Lre=n(lYe,"A",{href:!0});var Sia=s(Lre);Qjr=r(Sia,"TFMT5Model"),Sia.forEach(t),Wjr=r(lYe," (MT5 model)"),lYe.forEach(t),Ujr=i(j),s0=n(j,"LI",{});var iYe=s(s0);B7e=n(iYe,"STRONG",{});var Ria=s(B7e);Hjr=r(Ria,"openai-gpt"),Ria.forEach(t),Jjr=r(iYe," \u2014 "),yre=n(iYe,"A",{href:!0});var Pia=s(yre);Yjr=r(Pia,"TFOpenAIGPTModel"),Pia.forEach(t),Zjr=r(iYe," (OpenAI GPT model)"),iYe.forEach(t),Kjr=i(j),l0=n(j,"LI",{});var dYe=s(l0);I7e=n(dYe,"STRONG",{});var Bia=s(I7e);eDr=r(Bia,"opt"),Bia.forEach(t),oDr=r(dYe," \u2014 "),xre=n(dYe,"A",{href:!0});var Iia=s(xre);rDr=r(Iia,"TFOPTModel"),Iia.forEach(t),tDr=r(dYe," (OPT model)"),dYe.forEach(t),aDr=i(j),i0=n(j,"LI",{});var cYe=s(i0);N7e=n(cYe,"STRONG",{});var Nia=s(N7e);nDr=r(Nia,"pegasus"),Nia.forEach(t),sDr=r(cYe," \u2014 "),$re=n(cYe,"A",{href:!0});var qia=s($re);lDr=r(qia,"TFPegasusModel"),qia.forEach(t),iDr=r(cYe," (Pegasus model)"),cYe.forEach(t),dDr=i(j),d0=n(j,"LI",{});var mYe=s(d0);q7e=n(mYe,"STRONG",{});var jia=s(q7e);cDr=r(jia,"regnet"),jia.forEach(t),mDr=r(mYe," \u2014 "),kre=n(mYe,"A",{href:!0});var Dia=s(kre);fDr=r(Dia,"TFRegNetModel"),Dia.forEach(t),gDr=r(mYe," (RegNet model)"),mYe.forEach(t),hDr=i(j),c0=n(j,"LI",{});var fYe=s(c0);j7e=n(fYe,"STRONG",{});var Gia=s(j7e);uDr=r(Gia,"rembert"),Gia.forEach(t),pDr=r(fYe," \u2014 "),Sre=n(fYe,"A",{href:!0});var Oia=s(Sre);_Dr=r(Oia,"TFRemBertModel"),Oia.forEach(t),bDr=r(fYe," (RemBERT model)"),fYe.forEach(t),vDr=i(j),m0=n(j,"LI",{});var gYe=s(m0);D7e=n(gYe,"STRONG",{});var Via=s(D7e);FDr=r(Via,"resnet"),Via.forEach(t),TDr=r(gYe," \u2014 "),Rre=n(gYe,"A",{href:!0});var Xia=s(Rre);MDr=r(Xia,"TFResNetModel"),Xia.forEach(t),EDr=r(gYe," (ResNet model)"),gYe.forEach(t),CDr=i(j),f0=n(j,"LI",{});var hYe=s(f0);G7e=n(hYe,"STRONG",{});var zia=s(G7e);wDr=r(zia,"roberta"),zia.forEach(t),ADr=r(hYe," \u2014 "),Pre=n(hYe,"A",{href:!0});var Qia=s(Pre);LDr=r(Qia,"TFRobertaModel"),Qia.forEach(t),yDr=r(hYe," (RoBERTa model)"),hYe.forEach(t),xDr=i(j),g0=n(j,"LI",{});var uYe=s(g0);O7e=n(uYe,"STRONG",{});var Wia=s(O7e);$Dr=r(Wia,"roformer"),Wia.forEach(t),kDr=r(uYe," \u2014 "),Bre=n(uYe,"A",{href:!0});var Uia=s(Bre);SDr=r(Uia,"TFRoFormerModel"),Uia.forEach(t),RDr=r(uYe," (RoFormer model)"),uYe.forEach(t),PDr=i(j),h0=n(j,"LI",{});var pYe=s(h0);V7e=n(pYe,"STRONG",{});var Hia=s(V7e);BDr=r(Hia,"segformer"),Hia.forEach(t),IDr=r(pYe," \u2014 "),Ire=n(pYe,"A",{href:!0});var Jia=s(Ire);NDr=r(Jia,"TFSegformerModel"),Jia.forEach(t),qDr=r(pYe," (SegFormer model)"),pYe.forEach(t),jDr=i(j),u0=n(j,"LI",{});var _Ye=s(u0);X7e=n(_Ye,"STRONG",{});var Yia=s(X7e);DDr=r(Yia,"speech_to_text"),Yia.forEach(t),GDr=r(_Ye," \u2014 "),Nre=n(_Ye,"A",{href:!0});var Zia=s(Nre);ODr=r(Zia,"TFSpeech2TextModel"),Zia.forEach(t),VDr=r(_Ye," (Speech2Text model)"),_Ye.forEach(t),XDr=i(j),p0=n(j,"LI",{});var bYe=s(p0);z7e=n(bYe,"STRONG",{});var Kia=s(z7e);zDr=r(Kia,"swin"),Kia.forEach(t),QDr=r(bYe," \u2014 "),qre=n(bYe,"A",{href:!0});var eda=s(qre);WDr=r(eda,"TFSwinModel"),eda.forEach(t),UDr=r(bYe," (Swin Transformer model)"),bYe.forEach(t),HDr=i(j),_0=n(j,"LI",{});var vYe=s(_0);Q7e=n(vYe,"STRONG",{});var oda=s(Q7e);JDr=r(oda,"t5"),oda.forEach(t),YDr=r(vYe," \u2014 "),jre=n(vYe,"A",{href:!0});var rda=s(jre);ZDr=r(rda,"TFT5Model"),rda.forEach(t),KDr=r(vYe," (T5 model)"),vYe.forEach(t),eGr=i(j),b0=n(j,"LI",{});var FYe=s(b0);W7e=n(FYe,"STRONG",{});var tda=s(W7e);oGr=r(tda,"tapas"),tda.forEach(t),rGr=r(FYe," \u2014 "),Dre=n(FYe,"A",{href:!0});var ada=s(Dre);tGr=r(ada,"TFTapasModel"),ada.forEach(t),aGr=r(FYe," (TAPAS model)"),FYe.forEach(t),nGr=i(j),v0=n(j,"LI",{});var TYe=s(v0);U7e=n(TYe,"STRONG",{});var nda=s(U7e);sGr=r(nda,"transfo-xl"),nda.forEach(t),lGr=r(TYe," \u2014 "),Gre=n(TYe,"A",{href:!0});var sda=s(Gre);iGr=r(sda,"TFTransfoXLModel"),sda.forEach(t),dGr=r(TYe," (Transformer-XL model)"),TYe.forEach(t),cGr=i(j),F0=n(j,"LI",{});var MYe=s(F0);H7e=n(MYe,"STRONG",{});var lda=s(H7e);mGr=r(lda,"vit"),lda.forEach(t),fGr=r(MYe," \u2014 "),Ore=n(MYe,"A",{href:!0});var ida=s(Ore);gGr=r(ida,"TFViTModel"),ida.forEach(t),hGr=r(MYe," (ViT model)"),MYe.forEach(t),uGr=i(j),T0=n(j,"LI",{});var EYe=s(T0);J7e=n(EYe,"STRONG",{});var dda=s(J7e);pGr=r(dda,"vit_mae"),dda.forEach(t),_Gr=r(EYe," \u2014 "),Vre=n(EYe,"A",{href:!0});var cda=s(Vre);bGr=r(cda,"TFViTMAEModel"),cda.forEach(t),vGr=r(EYe," (ViTMAE model)"),EYe.forEach(t),FGr=i(j),M0=n(j,"LI",{});var CYe=s(M0);Y7e=n(CYe,"STRONG",{});var mda=s(Y7e);TGr=r(mda,"wav2vec2"),mda.forEach(t),MGr=r(CYe," \u2014 "),Xre=n(CYe,"A",{href:!0});var fda=s(Xre);EGr=r(fda,"TFWav2Vec2Model"),fda.forEach(t),CGr=r(CYe," (Wav2Vec2 model)"),CYe.forEach(t),wGr=i(j),E0=n(j,"LI",{});var wYe=s(E0);Z7e=n(wYe,"STRONG",{});var gda=s(Z7e);AGr=r(gda,"whisper"),gda.forEach(t),LGr=r(wYe," \u2014 "),zre=n(wYe,"A",{href:!0});var hda=s(zre);yGr=r(hda,"TFWhisperModel"),hda.forEach(t),xGr=r(wYe," (Whisper model)"),wYe.forEach(t),$Gr=i(j),C0=n(j,"LI",{});var AYe=s(C0);K7e=n(AYe,"STRONG",{});var uda=s(K7e);kGr=r(uda,"xglm"),uda.forEach(t),SGr=r(AYe," \u2014 "),Qre=n(AYe,"A",{href:!0});var pda=s(Qre);RGr=r(pda,"TFXGLMModel"),pda.forEach(t),PGr=r(AYe," (XGLM model)"),AYe.forEach(t),BGr=i(j),w0=n(j,"LI",{});var LYe=s(w0);eLe=n(LYe,"STRONG",{});var _da=s(eLe);IGr=r(_da,"xlm"),_da.forEach(t),NGr=r(LYe," \u2014 "),Wre=n(LYe,"A",{href:!0});var bda=s(Wre);qGr=r(bda,"TFXLMModel"),bda.forEach(t),jGr=r(LYe," (XLM model)"),LYe.forEach(t),DGr=i(j),A0=n(j,"LI",{});var yYe=s(A0);oLe=n(yYe,"STRONG",{});var vda=s(oLe);GGr=r(vda,"xlm-roberta"),vda.forEach(t),OGr=r(yYe," \u2014 "),Ure=n(yYe,"A",{href:!0});var Fda=s(Ure);VGr=r(Fda,"TFXLMRobertaModel"),Fda.forEach(t),XGr=r(yYe," (XLM-RoBERTa model)"),yYe.forEach(t),zGr=i(j),L0=n(j,"LI",{});var xYe=s(L0);rLe=n(xYe,"STRONG",{});var Tda=s(rLe);QGr=r(Tda,"xlnet"),Tda.forEach(t),WGr=r(xYe," \u2014 "),Hre=n(xYe,"A",{href:!0});var Mda=s(Hre);UGr=r(Mda,"TFXLNetModel"),Mda.forEach(t),HGr=r(xYe," (XLNet model)"),xYe.forEach(t),j.forEach(t),JGr=i(ui),T(y0.$$.fragment,ui),ui.forEach(t),hi.forEach(t),nao=i(m),mm=n(m,"H2",{class:!0});var Cso=s(mm);x0=n(Cso,"A",{id:!0,class:!0,href:!0});var Eda=s(x0);tLe=n(Eda,"SPAN",{});var Cda=s(tLe);T(cR.$$.fragment,Cda),Cda.forEach(t),Eda.forEach(t),YGr=i(Cso),aLe=n(Cso,"SPAN",{});var wda=s(aLe);ZGr=r(wda,"TFAutoModelForPreTraining"),wda.forEach(t),Cso.forEach(t),sao=i(m),mr=n(m,"DIV",{class:!0});var pi=s(mr);T(mR.$$.fragment,pi),KGr=i(pi),fm=n(pi,"P",{});var Xce=s(fm);eOr=r(Xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Jre=n(Xce,"A",{href:!0});var Ada=s(Jre);oOr=r(Ada,"from_pretrained()"),Ada.forEach(t),rOr=r(Xce," class method or the "),Yre=n(Xce,"A",{href:!0});var Lda=s(Yre);tOr=r(Lda,"from_config()"),Lda.forEach(t),aOr=r(Xce,` class
method.`),Xce.forEach(t),nOr=i(pi),fR=n(pi,"P",{});var wso=s(fR);sOr=r(wso,"This class cannot be instantiated directly using "),nLe=n(wso,"CODE",{});var yda=s(nLe);lOr=r(yda,"__init__()"),yda.forEach(t),iOr=r(wso," (throws an error)."),wso.forEach(t),dOr=i(pi),Yt=n(pi,"DIV",{class:!0});var J9=s(Yt);T(gR.$$.fragment,J9),cOr=i(J9),sLe=n(J9,"P",{});var xda=s(sLe);mOr=r(xda,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xda.forEach(t),fOr=i(J9),gm=n(J9,"P",{});var zce=s(gm);gOr=r(zce,`Note:
Loading a model from its configuration file does `),lLe=n(zce,"STRONG",{});var $da=s(lLe);hOr=r($da,"not"),$da.forEach(t),uOr=r(zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=n(zce,"A",{href:!0});var kda=s(Zre);pOr=r(kda,"from_pretrained()"),kda.forEach(t),_Or=r(zce," to load the model weights."),zce.forEach(t),bOr=i(J9),T($0.$$.fragment,J9),J9.forEach(t),vOr=i(pi),Gr=n(pi,"DIV",{class:!0});var _i=s(Gr);T(hR.$$.fragment,_i),FOr=i(_i),iLe=n(_i,"P",{});var Sda=s(iLe);TOr=r(Sda,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Sda.forEach(t),MOr=i(_i),In=n(_i,"P",{});var Y9=s(In);EOr=r(Y9,"The model class to instantiate is selected based on the "),dLe=n(Y9,"CODE",{});var Rda=s(dLe);COr=r(Rda,"model_type"),Rda.forEach(t),wOr=r(Y9,` property of the config object (either
passed as an argument or loaded from `),cLe=n(Y9,"CODE",{});var Pda=s(cLe);AOr=r(Pda,"pretrained_model_name_or_path"),Pda.forEach(t),LOr=r(Y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mLe=n(Y9,"CODE",{});var Bda=s(mLe);yOr=r(Bda,"pretrained_model_name_or_path"),Bda.forEach(t),xOr=r(Y9,":"),Y9.forEach(t),$Or=i(_i),le=n(_i,"UL",{});var de=s(le);k0=n(de,"LI",{});var $Ye=s(k0);fLe=n($Ye,"STRONG",{});var Ida=s(fLe);kOr=r(Ida,"albert"),Ida.forEach(t),SOr=r($Ye," \u2014 "),Kre=n($Ye,"A",{href:!0});var Nda=s(Kre);ROr=r(Nda,"TFAlbertForPreTraining"),Nda.forEach(t),POr=r($Ye," (ALBERT model)"),$Ye.forEach(t),BOr=i(de),S0=n(de,"LI",{});var kYe=s(S0);gLe=n(kYe,"STRONG",{});var qda=s(gLe);IOr=r(qda,"bart"),qda.forEach(t),NOr=r(kYe," \u2014 "),ete=n(kYe,"A",{href:!0});var jda=s(ete);qOr=r(jda,"TFBartForConditionalGeneration"),jda.forEach(t),jOr=r(kYe," (BART model)"),kYe.forEach(t),DOr=i(de),R0=n(de,"LI",{});var SYe=s(R0);hLe=n(SYe,"STRONG",{});var Dda=s(hLe);GOr=r(Dda,"bert"),Dda.forEach(t),OOr=r(SYe," \u2014 "),ote=n(SYe,"A",{href:!0});var Gda=s(ote);VOr=r(Gda,"TFBertForPreTraining"),Gda.forEach(t),XOr=r(SYe," (BERT model)"),SYe.forEach(t),zOr=i(de),P0=n(de,"LI",{});var RYe=s(P0);uLe=n(RYe,"STRONG",{});var Oda=s(uLe);QOr=r(Oda,"camembert"),Oda.forEach(t),WOr=r(RYe," \u2014 "),rte=n(RYe,"A",{href:!0});var Vda=s(rte);UOr=r(Vda,"TFCamembertForMaskedLM"),Vda.forEach(t),HOr=r(RYe," (CamemBERT model)"),RYe.forEach(t),JOr=i(de),B0=n(de,"LI",{});var PYe=s(B0);pLe=n(PYe,"STRONG",{});var Xda=s(pLe);YOr=r(Xda,"ctrl"),Xda.forEach(t),ZOr=r(PYe," \u2014 "),tte=n(PYe,"A",{href:!0});var zda=s(tte);KOr=r(zda,"TFCTRLLMHeadModel"),zda.forEach(t),eVr=r(PYe," (CTRL model)"),PYe.forEach(t),oVr=i(de),I0=n(de,"LI",{});var BYe=s(I0);_Le=n(BYe,"STRONG",{});var Qda=s(_Le);rVr=r(Qda,"distilbert"),Qda.forEach(t),tVr=r(BYe," \u2014 "),ate=n(BYe,"A",{href:!0});var Wda=s(ate);aVr=r(Wda,"TFDistilBertForMaskedLM"),Wda.forEach(t),nVr=r(BYe," (DistilBERT model)"),BYe.forEach(t),sVr=i(de),N0=n(de,"LI",{});var IYe=s(N0);bLe=n(IYe,"STRONG",{});var Uda=s(bLe);lVr=r(Uda,"electra"),Uda.forEach(t),iVr=r(IYe," \u2014 "),nte=n(IYe,"A",{href:!0});var Hda=s(nte);dVr=r(Hda,"TFElectraForPreTraining"),Hda.forEach(t),cVr=r(IYe," (ELECTRA model)"),IYe.forEach(t),mVr=i(de),q0=n(de,"LI",{});var NYe=s(q0);vLe=n(NYe,"STRONG",{});var Jda=s(vLe);fVr=r(Jda,"flaubert"),Jda.forEach(t),gVr=r(NYe," \u2014 "),ste=n(NYe,"A",{href:!0});var Yda=s(ste);hVr=r(Yda,"TFFlaubertWithLMHeadModel"),Yda.forEach(t),uVr=r(NYe," (FlauBERT model)"),NYe.forEach(t),pVr=i(de),j0=n(de,"LI",{});var qYe=s(j0);FLe=n(qYe,"STRONG",{});var Zda=s(FLe);_Vr=r(Zda,"funnel"),Zda.forEach(t),bVr=r(qYe," \u2014 "),lte=n(qYe,"A",{href:!0});var Kda=s(lte);vVr=r(Kda,"TFFunnelForPreTraining"),Kda.forEach(t),FVr=r(qYe," (Funnel Transformer model)"),qYe.forEach(t),TVr=i(de),D0=n(de,"LI",{});var jYe=s(D0);TLe=n(jYe,"STRONG",{});var eca=s(TLe);MVr=r(eca,"gpt2"),eca.forEach(t),EVr=r(jYe," \u2014 "),ite=n(jYe,"A",{href:!0});var oca=s(ite);CVr=r(oca,"TFGPT2LMHeadModel"),oca.forEach(t),wVr=r(jYe," (OpenAI GPT-2 model)"),jYe.forEach(t),AVr=i(de),G0=n(de,"LI",{});var DYe=s(G0);MLe=n(DYe,"STRONG",{});var rca=s(MLe);LVr=r(rca,"layoutlm"),rca.forEach(t),yVr=r(DYe," \u2014 "),dte=n(DYe,"A",{href:!0});var tca=s(dte);xVr=r(tca,"TFLayoutLMForMaskedLM"),tca.forEach(t),$Vr=r(DYe," (LayoutLM model)"),DYe.forEach(t),kVr=i(de),O0=n(de,"LI",{});var GYe=s(O0);ELe=n(GYe,"STRONG",{});var aca=s(ELe);SVr=r(aca,"lxmert"),aca.forEach(t),RVr=r(GYe," \u2014 "),cte=n(GYe,"A",{href:!0});var nca=s(cte);PVr=r(nca,"TFLxmertForPreTraining"),nca.forEach(t),BVr=r(GYe," (LXMERT model)"),GYe.forEach(t),IVr=i(de),V0=n(de,"LI",{});var OYe=s(V0);CLe=n(OYe,"STRONG",{});var sca=s(CLe);NVr=r(sca,"mobilebert"),sca.forEach(t),qVr=r(OYe," \u2014 "),mte=n(OYe,"A",{href:!0});var lca=s(mte);jVr=r(lca,"TFMobileBertForPreTraining"),lca.forEach(t),DVr=r(OYe," (MobileBERT model)"),OYe.forEach(t),GVr=i(de),X0=n(de,"LI",{});var VYe=s(X0);wLe=n(VYe,"STRONG",{});var ica=s(wLe);OVr=r(ica,"mpnet"),ica.forEach(t),VVr=r(VYe," \u2014 "),fte=n(VYe,"A",{href:!0});var dca=s(fte);XVr=r(dca,"TFMPNetForMaskedLM"),dca.forEach(t),zVr=r(VYe," (MPNet model)"),VYe.forEach(t),QVr=i(de),z0=n(de,"LI",{});var XYe=s(z0);ALe=n(XYe,"STRONG",{});var cca=s(ALe);WVr=r(cca,"openai-gpt"),cca.forEach(t),UVr=r(XYe," \u2014 "),gte=n(XYe,"A",{href:!0});var mca=s(gte);HVr=r(mca,"TFOpenAIGPTLMHeadModel"),mca.forEach(t),JVr=r(XYe," (OpenAI GPT model)"),XYe.forEach(t),YVr=i(de),Q0=n(de,"LI",{});var zYe=s(Q0);LLe=n(zYe,"STRONG",{});var fca=s(LLe);ZVr=r(fca,"roberta"),fca.forEach(t),KVr=r(zYe," \u2014 "),hte=n(zYe,"A",{href:!0});var gca=s(hte);eXr=r(gca,"TFRobertaForMaskedLM"),gca.forEach(t),oXr=r(zYe," (RoBERTa model)"),zYe.forEach(t),rXr=i(de),W0=n(de,"LI",{});var QYe=s(W0);yLe=n(QYe,"STRONG",{});var hca=s(yLe);tXr=r(hca,"t5"),hca.forEach(t),aXr=r(QYe," \u2014 "),ute=n(QYe,"A",{href:!0});var uca=s(ute);nXr=r(uca,"TFT5ForConditionalGeneration"),uca.forEach(t),sXr=r(QYe," (T5 model)"),QYe.forEach(t),lXr=i(de),U0=n(de,"LI",{});var WYe=s(U0);xLe=n(WYe,"STRONG",{});var pca=s(xLe);iXr=r(pca,"tapas"),pca.forEach(t),dXr=r(WYe," \u2014 "),pte=n(WYe,"A",{href:!0});var _ca=s(pte);cXr=r(_ca,"TFTapasForMaskedLM"),_ca.forEach(t),mXr=r(WYe," (TAPAS model)"),WYe.forEach(t),fXr=i(de),H0=n(de,"LI",{});var UYe=s(H0);$Le=n(UYe,"STRONG",{});var bca=s($Le);gXr=r(bca,"transfo-xl"),bca.forEach(t),hXr=r(UYe," \u2014 "),_te=n(UYe,"A",{href:!0});var vca=s(_te);uXr=r(vca,"TFTransfoXLLMHeadModel"),vca.forEach(t),pXr=r(UYe," (Transformer-XL model)"),UYe.forEach(t),_Xr=i(de),J0=n(de,"LI",{});var HYe=s(J0);kLe=n(HYe,"STRONG",{});var Fca=s(kLe);bXr=r(Fca,"vit_mae"),Fca.forEach(t),vXr=r(HYe," \u2014 "),bte=n(HYe,"A",{href:!0});var Tca=s(bte);FXr=r(Tca,"TFViTMAEForPreTraining"),Tca.forEach(t),TXr=r(HYe," (ViTMAE model)"),HYe.forEach(t),MXr=i(de),Y0=n(de,"LI",{});var JYe=s(Y0);SLe=n(JYe,"STRONG",{});var Mca=s(SLe);EXr=r(Mca,"xlm"),Mca.forEach(t),CXr=r(JYe," \u2014 "),vte=n(JYe,"A",{href:!0});var Eca=s(vte);wXr=r(Eca,"TFXLMWithLMHeadModel"),Eca.forEach(t),AXr=r(JYe," (XLM model)"),JYe.forEach(t),LXr=i(de),Z0=n(de,"LI",{});var YYe=s(Z0);RLe=n(YYe,"STRONG",{});var Cca=s(RLe);yXr=r(Cca,"xlm-roberta"),Cca.forEach(t),xXr=r(YYe," \u2014 "),Fte=n(YYe,"A",{href:!0});var wca=s(Fte);$Xr=r(wca,"TFXLMRobertaForMaskedLM"),wca.forEach(t),kXr=r(YYe," (XLM-RoBERTa model)"),YYe.forEach(t),SXr=i(de),K0=n(de,"LI",{});var ZYe=s(K0);PLe=n(ZYe,"STRONG",{});var Aca=s(PLe);RXr=r(Aca,"xlnet"),Aca.forEach(t),PXr=r(ZYe," \u2014 "),Tte=n(ZYe,"A",{href:!0});var Lca=s(Tte);BXr=r(Lca,"TFXLNetLMHeadModel"),Lca.forEach(t),IXr=r(ZYe," (XLNet model)"),ZYe.forEach(t),de.forEach(t),NXr=i(_i),T(ew.$$.fragment,_i),_i.forEach(t),pi.forEach(t),lao=i(m),hm=n(m,"H2",{class:!0});var Aso=s(hm);ow=n(Aso,"A",{id:!0,class:!0,href:!0});var yca=s(ow);BLe=n(yca,"SPAN",{});var xca=s(BLe);T(uR.$$.fragment,xca),xca.forEach(t),yca.forEach(t),qXr=i(Aso),ILe=n(Aso,"SPAN",{});var $ca=s(ILe);jXr=r($ca,"TFAutoModelForCausalLM"),$ca.forEach(t),Aso.forEach(t),iao=i(m),fr=n(m,"DIV",{class:!0});var bi=s(fr);T(pR.$$.fragment,bi),DXr=i(bi),um=n(bi,"P",{});var Qce=s(um);GXr=r(Qce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Mte=n(Qce,"A",{href:!0});var kca=s(Mte);OXr=r(kca,"from_pretrained()"),kca.forEach(t),VXr=r(Qce," class method or the "),Ete=n(Qce,"A",{href:!0});var Sca=s(Ete);XXr=r(Sca,"from_config()"),Sca.forEach(t),zXr=r(Qce,` class
method.`),Qce.forEach(t),QXr=i(bi),_R=n(bi,"P",{});var Lso=s(_R);WXr=r(Lso,"This class cannot be instantiated directly using "),NLe=n(Lso,"CODE",{});var Rca=s(NLe);UXr=r(Rca,"__init__()"),Rca.forEach(t),HXr=r(Lso," (throws an error)."),Lso.forEach(t),JXr=i(bi),Zt=n(bi,"DIV",{class:!0});var Z9=s(Zt);T(bR.$$.fragment,Z9),YXr=i(Z9),qLe=n(Z9,"P",{});var Pca=s(qLe);ZXr=r(Pca,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Pca.forEach(t),KXr=i(Z9),pm=n(Z9,"P",{});var Wce=s(pm);ezr=r(Wce,`Note:
Loading a model from its configuration file does `),jLe=n(Wce,"STRONG",{});var Bca=s(jLe);ozr=r(Bca,"not"),Bca.forEach(t),rzr=r(Wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cte=n(Wce,"A",{href:!0});var Ica=s(Cte);tzr=r(Ica,"from_pretrained()"),Ica.forEach(t),azr=r(Wce," to load the model weights."),Wce.forEach(t),nzr=i(Z9),T(rw.$$.fragment,Z9),Z9.forEach(t),szr=i(bi),Or=n(bi,"DIV",{class:!0});var vi=s(Or);T(vR.$$.fragment,vi),lzr=i(vi),DLe=n(vi,"P",{});var Nca=s(DLe);izr=r(Nca,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Nca.forEach(t),dzr=i(vi),Nn=n(vi,"P",{});var K9=s(Nn);czr=r(K9,"The model class to instantiate is selected based on the "),GLe=n(K9,"CODE",{});var qca=s(GLe);mzr=r(qca,"model_type"),qca.forEach(t),fzr=r(K9,` property of the config object (either
passed as an argument or loaded from `),OLe=n(K9,"CODE",{});var jca=s(OLe);gzr=r(jca,"pretrained_model_name_or_path"),jca.forEach(t),hzr=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VLe=n(K9,"CODE",{});var Dca=s(VLe);uzr=r(Dca,"pretrained_model_name_or_path"),Dca.forEach(t),pzr=r(K9,":"),K9.forEach(t),_zr=i(vi),Me=n(vi,"UL",{});var Ce=s(Me);tw=n(Ce,"LI",{});var KYe=s(tw);XLe=n(KYe,"STRONG",{});var Gca=s(XLe);bzr=r(Gca,"bert"),Gca.forEach(t),vzr=r(KYe," \u2014 "),wte=n(KYe,"A",{href:!0});var Oca=s(wte);Fzr=r(Oca,"TFBertLMHeadModel"),Oca.forEach(t),Tzr=r(KYe," (BERT model)"),KYe.forEach(t),Mzr=i(Ce),aw=n(Ce,"LI",{});var eZe=s(aw);zLe=n(eZe,"STRONG",{});var Vca=s(zLe);Ezr=r(Vca,"camembert"),Vca.forEach(t),Czr=r(eZe," \u2014 "),Ate=n(eZe,"A",{href:!0});var Xca=s(Ate);wzr=r(Xca,"TFCamembertForCausalLM"),Xca.forEach(t),Azr=r(eZe," (CamemBERT model)"),eZe.forEach(t),Lzr=i(Ce),nw=n(Ce,"LI",{});var oZe=s(nw);QLe=n(oZe,"STRONG",{});var zca=s(QLe);yzr=r(zca,"ctrl"),zca.forEach(t),xzr=r(oZe," \u2014 "),Lte=n(oZe,"A",{href:!0});var Qca=s(Lte);$zr=r(Qca,"TFCTRLLMHeadModel"),Qca.forEach(t),kzr=r(oZe," (CTRL model)"),oZe.forEach(t),Szr=i(Ce),sw=n(Ce,"LI",{});var rZe=s(sw);WLe=n(rZe,"STRONG",{});var Wca=s(WLe);Rzr=r(Wca,"gpt2"),Wca.forEach(t),Pzr=r(rZe," \u2014 "),yte=n(rZe,"A",{href:!0});var Uca=s(yte);Bzr=r(Uca,"TFGPT2LMHeadModel"),Uca.forEach(t),Izr=r(rZe," (OpenAI GPT-2 model)"),rZe.forEach(t),Nzr=i(Ce),lw=n(Ce,"LI",{});var tZe=s(lw);ULe=n(tZe,"STRONG",{});var Hca=s(ULe);qzr=r(Hca,"gptj"),Hca.forEach(t),jzr=r(tZe," \u2014 "),xte=n(tZe,"A",{href:!0});var Jca=s(xte);Dzr=r(Jca,"TFGPTJForCausalLM"),Jca.forEach(t),Gzr=r(tZe," (GPT-J model)"),tZe.forEach(t),Ozr=i(Ce),iw=n(Ce,"LI",{});var aZe=s(iw);HLe=n(aZe,"STRONG",{});var Yca=s(HLe);Vzr=r(Yca,"openai-gpt"),Yca.forEach(t),Xzr=r(aZe," \u2014 "),$te=n(aZe,"A",{href:!0});var Zca=s($te);zzr=r(Zca,"TFOpenAIGPTLMHeadModel"),Zca.forEach(t),Qzr=r(aZe," (OpenAI GPT model)"),aZe.forEach(t),Wzr=i(Ce),dw=n(Ce,"LI",{});var nZe=s(dw);JLe=n(nZe,"STRONG",{});var Kca=s(JLe);Uzr=r(Kca,"opt"),Kca.forEach(t),Hzr=r(nZe," \u2014 "),kte=n(nZe,"A",{href:!0});var ema=s(kte);Jzr=r(ema,"TFOPTForCausalLM"),ema.forEach(t),Yzr=r(nZe," (OPT model)"),nZe.forEach(t),Zzr=i(Ce),cw=n(Ce,"LI",{});var sZe=s(cw);YLe=n(sZe,"STRONG",{});var oma=s(YLe);Kzr=r(oma,"rembert"),oma.forEach(t),eQr=r(sZe," \u2014 "),Ste=n(sZe,"A",{href:!0});var rma=s(Ste);oQr=r(rma,"TFRemBertForCausalLM"),rma.forEach(t),rQr=r(sZe," (RemBERT model)"),sZe.forEach(t),tQr=i(Ce),mw=n(Ce,"LI",{});var lZe=s(mw);ZLe=n(lZe,"STRONG",{});var tma=s(ZLe);aQr=r(tma,"roberta"),tma.forEach(t),nQr=r(lZe," \u2014 "),Rte=n(lZe,"A",{href:!0});var ama=s(Rte);sQr=r(ama,"TFRobertaForCausalLM"),ama.forEach(t),lQr=r(lZe," (RoBERTa model)"),lZe.forEach(t),iQr=i(Ce),fw=n(Ce,"LI",{});var iZe=s(fw);KLe=n(iZe,"STRONG",{});var nma=s(KLe);dQr=r(nma,"roformer"),nma.forEach(t),cQr=r(iZe," \u2014 "),Pte=n(iZe,"A",{href:!0});var sma=s(Pte);mQr=r(sma,"TFRoFormerForCausalLM"),sma.forEach(t),fQr=r(iZe," (RoFormer model)"),iZe.forEach(t),gQr=i(Ce),gw=n(Ce,"LI",{});var dZe=s(gw);e8e=n(dZe,"STRONG",{});var lma=s(e8e);hQr=r(lma,"transfo-xl"),lma.forEach(t),uQr=r(dZe," \u2014 "),Bte=n(dZe,"A",{href:!0});var ima=s(Bte);pQr=r(ima,"TFTransfoXLLMHeadModel"),ima.forEach(t),_Qr=r(dZe," (Transformer-XL model)"),dZe.forEach(t),bQr=i(Ce),hw=n(Ce,"LI",{});var cZe=s(hw);o8e=n(cZe,"STRONG",{});var dma=s(o8e);vQr=r(dma,"xglm"),dma.forEach(t),FQr=r(cZe," \u2014 "),Ite=n(cZe,"A",{href:!0});var cma=s(Ite);TQr=r(cma,"TFXGLMForCausalLM"),cma.forEach(t),MQr=r(cZe," (XGLM model)"),cZe.forEach(t),EQr=i(Ce),uw=n(Ce,"LI",{});var mZe=s(uw);r8e=n(mZe,"STRONG",{});var mma=s(r8e);CQr=r(mma,"xlm"),mma.forEach(t),wQr=r(mZe," \u2014 "),Nte=n(mZe,"A",{href:!0});var fma=s(Nte);AQr=r(fma,"TFXLMWithLMHeadModel"),fma.forEach(t),LQr=r(mZe," (XLM model)"),mZe.forEach(t),yQr=i(Ce),pw=n(Ce,"LI",{});var fZe=s(pw);t8e=n(fZe,"STRONG",{});var gma=s(t8e);xQr=r(gma,"xlnet"),gma.forEach(t),$Qr=r(fZe," \u2014 "),qte=n(fZe,"A",{href:!0});var hma=s(qte);kQr=r(hma,"TFXLNetLMHeadModel"),hma.forEach(t),SQr=r(fZe," (XLNet model)"),fZe.forEach(t),Ce.forEach(t),RQr=i(vi),T(_w.$$.fragment,vi),vi.forEach(t),bi.forEach(t),dao=i(m),_m=n(m,"H2",{class:!0});var yso=s(_m);bw=n(yso,"A",{id:!0,class:!0,href:!0});var uma=s(bw);a8e=n(uma,"SPAN",{});var pma=s(a8e);T(FR.$$.fragment,pma),pma.forEach(t),uma.forEach(t),PQr=i(yso),n8e=n(yso,"SPAN",{});var _ma=s(n8e);BQr=r(_ma,"TFAutoModelForImageClassification"),_ma.forEach(t),yso.forEach(t),cao=i(m),gr=n(m,"DIV",{class:!0});var Fi=s(gr);T(TR.$$.fragment,Fi),IQr=i(Fi),bm=n(Fi,"P",{});var Uce=s(bm);NQr=r(Uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jte=n(Uce,"A",{href:!0});var bma=s(jte);qQr=r(bma,"from_pretrained()"),bma.forEach(t),jQr=r(Uce," class method or the "),Dte=n(Uce,"A",{href:!0});var vma=s(Dte);DQr=r(vma,"from_config()"),vma.forEach(t),GQr=r(Uce,` class
method.`),Uce.forEach(t),OQr=i(Fi),MR=n(Fi,"P",{});var xso=s(MR);VQr=r(xso,"This class cannot be instantiated directly using "),s8e=n(xso,"CODE",{});var Fma=s(s8e);XQr=r(Fma,"__init__()"),Fma.forEach(t),zQr=r(xso," (throws an error)."),xso.forEach(t),QQr=i(Fi),Kt=n(Fi,"DIV",{class:!0});var ex=s(Kt);T(ER.$$.fragment,ex),WQr=i(ex),l8e=n(ex,"P",{});var Tma=s(l8e);UQr=r(Tma,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Tma.forEach(t),HQr=i(ex),vm=n(ex,"P",{});var Hce=s(vm);JQr=r(Hce,`Note:
Loading a model from its configuration file does `),i8e=n(Hce,"STRONG",{});var Mma=s(i8e);YQr=r(Mma,"not"),Mma.forEach(t),ZQr=r(Hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(Hce,"A",{href:!0});var Ema=s(Gte);KQr=r(Ema,"from_pretrained()"),Ema.forEach(t),eWr=r(Hce," to load the model weights."),Hce.forEach(t),oWr=i(ex),T(vw.$$.fragment,ex),ex.forEach(t),rWr=i(Fi),Vr=n(Fi,"DIV",{class:!0});var Ti=s(Vr);T(CR.$$.fragment,Ti),tWr=i(Ti),d8e=n(Ti,"P",{});var Cma=s(d8e);aWr=r(Cma,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Cma.forEach(t),nWr=i(Ti),qn=n(Ti,"P",{});var ox=s(qn);sWr=r(ox,"The model class to instantiate is selected based on the "),c8e=n(ox,"CODE",{});var wma=s(c8e);lWr=r(wma,"model_type"),wma.forEach(t),iWr=r(ox,` property of the config object (either
passed as an argument or loaded from `),m8e=n(ox,"CODE",{});var Ama=s(m8e);dWr=r(Ama,"pretrained_model_name_or_path"),Ama.forEach(t),cWr=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f8e=n(ox,"CODE",{});var Lma=s(f8e);mWr=r(Lma,"pretrained_model_name_or_path"),Lma.forEach(t),fWr=r(ox,":"),ox.forEach(t),gWr=i(Ti),ye=n(Ti,"UL",{});var Ne=s(ye);Fw=n(Ne,"LI",{});var gZe=s(Fw);g8e=n(gZe,"STRONG",{});var yma=s(g8e);hWr=r(yma,"convnext"),yma.forEach(t),uWr=r(gZe," \u2014 "),Ote=n(gZe,"A",{href:!0});var xma=s(Ote);pWr=r(xma,"TFConvNextForImageClassification"),xma.forEach(t),_Wr=r(gZe," (ConvNeXT model)"),gZe.forEach(t),bWr=i(Ne),Tw=n(Ne,"LI",{});var hZe=s(Tw);h8e=n(hZe,"STRONG",{});var $ma=s(h8e);vWr=r($ma,"cvt"),$ma.forEach(t),FWr=r(hZe," \u2014 "),Vte=n(hZe,"A",{href:!0});var kma=s(Vte);TWr=r(kma,"TFCvtForImageClassification"),kma.forEach(t),MWr=r(hZe," (CvT model)"),hZe.forEach(t),EWr=i(Ne),Mw=n(Ne,"LI",{});var uZe=s(Mw);u8e=n(uZe,"STRONG",{});var Sma=s(u8e);CWr=r(Sma,"data2vec-vision"),Sma.forEach(t),wWr=r(uZe," \u2014 "),Xte=n(uZe,"A",{href:!0});var Rma=s(Xte);AWr=r(Rma,"TFData2VecVisionForImageClassification"),Rma.forEach(t),LWr=r(uZe," (Data2VecVision model)"),uZe.forEach(t),yWr=i(Ne),Sl=n(Ne,"LI",{});var mN=s(Sl);p8e=n(mN,"STRONG",{});var Pma=s(p8e);xWr=r(Pma,"deit"),Pma.forEach(t),$Wr=r(mN," \u2014 "),zte=n(mN,"A",{href:!0});var Bma=s(zte);kWr=r(Bma,"TFDeiTForImageClassification"),Bma.forEach(t),SWr=r(mN," or "),Qte=n(mN,"A",{href:!0});var Ima=s(Qte);RWr=r(Ima,"TFDeiTForImageClassificationWithTeacher"),Ima.forEach(t),PWr=r(mN," (DeiT model)"),mN.forEach(t),BWr=i(Ne),Ew=n(Ne,"LI",{});var pZe=s(Ew);_8e=n(pZe,"STRONG",{});var Nma=s(_8e);IWr=r(Nma,"mobilevit"),Nma.forEach(t),NWr=r(pZe," \u2014 "),Wte=n(pZe,"A",{href:!0});var qma=s(Wte);qWr=r(qma,"TFMobileViTForImageClassification"),qma.forEach(t),jWr=r(pZe," (MobileViT model)"),pZe.forEach(t),DWr=i(Ne),Cw=n(Ne,"LI",{});var _Ze=s(Cw);b8e=n(_Ze,"STRONG",{});var jma=s(b8e);GWr=r(jma,"regnet"),jma.forEach(t),OWr=r(_Ze," \u2014 "),Ute=n(_Ze,"A",{href:!0});var Dma=s(Ute);VWr=r(Dma,"TFRegNetForImageClassification"),Dma.forEach(t),XWr=r(_Ze," (RegNet model)"),_Ze.forEach(t),zWr=i(Ne),ww=n(Ne,"LI",{});var bZe=s(ww);v8e=n(bZe,"STRONG",{});var Gma=s(v8e);QWr=r(Gma,"resnet"),Gma.forEach(t),WWr=r(bZe," \u2014 "),Hte=n(bZe,"A",{href:!0});var Oma=s(Hte);UWr=r(Oma,"TFResNetForImageClassification"),Oma.forEach(t),HWr=r(bZe," (ResNet model)"),bZe.forEach(t),JWr=i(Ne),Aw=n(Ne,"LI",{});var vZe=s(Aw);F8e=n(vZe,"STRONG",{});var Vma=s(F8e);YWr=r(Vma,"segformer"),Vma.forEach(t),ZWr=r(vZe," \u2014 "),Jte=n(vZe,"A",{href:!0});var Xma=s(Jte);KWr=r(Xma,"TFSegformerForImageClassification"),Xma.forEach(t),eUr=r(vZe," (SegFormer model)"),vZe.forEach(t),oUr=i(Ne),Lw=n(Ne,"LI",{});var FZe=s(Lw);T8e=n(FZe,"STRONG",{});var zma=s(T8e);rUr=r(zma,"swin"),zma.forEach(t),tUr=r(FZe," \u2014 "),Yte=n(FZe,"A",{href:!0});var Qma=s(Yte);aUr=r(Qma,"TFSwinForImageClassification"),Qma.forEach(t),nUr=r(FZe," (Swin Transformer model)"),FZe.forEach(t),sUr=i(Ne),yw=n(Ne,"LI",{});var TZe=s(yw);M8e=n(TZe,"STRONG",{});var Wma=s(M8e);lUr=r(Wma,"vit"),Wma.forEach(t),iUr=r(TZe," \u2014 "),Zte=n(TZe,"A",{href:!0});var Uma=s(Zte);dUr=r(Uma,"TFViTForImageClassification"),Uma.forEach(t),cUr=r(TZe," (ViT model)"),TZe.forEach(t),Ne.forEach(t),mUr=i(Ti),T(xw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),mao=i(m),Fm=n(m,"H2",{class:!0});var $so=s(Fm);$w=n($so,"A",{id:!0,class:!0,href:!0});var Hma=s($w);E8e=n(Hma,"SPAN",{});var Jma=s(E8e);T(wR.$$.fragment,Jma),Jma.forEach(t),Hma.forEach(t),fUr=i($so),C8e=n($so,"SPAN",{});var Yma=s(C8e);gUr=r(Yma,"TFAutoModelForSemanticSegmentation"),Yma.forEach(t),$so.forEach(t),fao=i(m),hr=n(m,"DIV",{class:!0});var Mi=s(hr);T(AR.$$.fragment,Mi),hUr=i(Mi),Tm=n(Mi,"P",{});var Jce=s(Tm);uUr=r(Jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Kte=n(Jce,"A",{href:!0});var Zma=s(Kte);pUr=r(Zma,"from_pretrained()"),Zma.forEach(t),_Ur=r(Jce," class method or the "),eae=n(Jce,"A",{href:!0});var Kma=s(eae);bUr=r(Kma,"from_config()"),Kma.forEach(t),vUr=r(Jce,` class
method.`),Jce.forEach(t),FUr=i(Mi),LR=n(Mi,"P",{});var kso=s(LR);TUr=r(kso,"This class cannot be instantiated directly using "),w8e=n(kso,"CODE",{});var efa=s(w8e);MUr=r(efa,"__init__()"),efa.forEach(t),EUr=r(kso," (throws an error)."),kso.forEach(t),CUr=i(Mi),ea=n(Mi,"DIV",{class:!0});var rx=s(ea);T(yR.$$.fragment,rx),wUr=i(rx),A8e=n(rx,"P",{});var ofa=s(A8e);AUr=r(ofa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),ofa.forEach(t),LUr=i(rx),Mm=n(rx,"P",{});var Yce=s(Mm);yUr=r(Yce,`Note:
Loading a model from its configuration file does `),L8e=n(Yce,"STRONG",{});var rfa=s(L8e);xUr=r(rfa,"not"),rfa.forEach(t),$Ur=r(Yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),oae=n(Yce,"A",{href:!0});var tfa=s(oae);kUr=r(tfa,"from_pretrained()"),tfa.forEach(t),SUr=r(Yce," to load the model weights."),Yce.forEach(t),RUr=i(rx),T(kw.$$.fragment,rx),rx.forEach(t),PUr=i(Mi),Xr=n(Mi,"DIV",{class:!0});var Ei=s(Xr);T(xR.$$.fragment,Ei),BUr=i(Ei),y8e=n(Ei,"P",{});var afa=s(y8e);IUr=r(afa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),afa.forEach(t),NUr=i(Ei),jn=n(Ei,"P",{});var tx=s(jn);qUr=r(tx,"The model class to instantiate is selected based on the "),x8e=n(tx,"CODE",{});var nfa=s(x8e);jUr=r(nfa,"model_type"),nfa.forEach(t),DUr=r(tx,` property of the config object (either
passed as an argument or loaded from `),$8e=n(tx,"CODE",{});var sfa=s($8e);GUr=r(sfa,"pretrained_model_name_or_path"),sfa.forEach(t),OUr=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k8e=n(tx,"CODE",{});var lfa=s(k8e);VUr=r(lfa,"pretrained_model_name_or_path"),lfa.forEach(t),XUr=r(tx,":"),tx.forEach(t),zUr=i(Ei),Em=n(Ei,"UL",{});var Zce=s(Em);Sw=n(Zce,"LI",{});var MZe=s(Sw);S8e=n(MZe,"STRONG",{});var ifa=s(S8e);QUr=r(ifa,"data2vec-vision"),ifa.forEach(t),WUr=r(MZe," \u2014 "),rae=n(MZe,"A",{href:!0});var dfa=s(rae);UUr=r(dfa,"TFData2VecVisionForSemanticSegmentation"),dfa.forEach(t),HUr=r(MZe," (Data2VecVision model)"),MZe.forEach(t),JUr=i(Zce),Rw=n(Zce,"LI",{});var EZe=s(Rw);R8e=n(EZe,"STRONG",{});var cfa=s(R8e);YUr=r(cfa,"mobilevit"),cfa.forEach(t),ZUr=r(EZe," \u2014 "),tae=n(EZe,"A",{href:!0});var mfa=s(tae);KUr=r(mfa,"TFMobileViTForSemanticSegmentation"),mfa.forEach(t),eHr=r(EZe," (MobileViT model)"),EZe.forEach(t),oHr=i(Zce),Pw=n(Zce,"LI",{});var CZe=s(Pw);P8e=n(CZe,"STRONG",{});var ffa=s(P8e);rHr=r(ffa,"segformer"),ffa.forEach(t),tHr=r(CZe," \u2014 "),aae=n(CZe,"A",{href:!0});var gfa=s(aae);aHr=r(gfa,"TFSegformerForSemanticSegmentation"),gfa.forEach(t),nHr=r(CZe," (SegFormer model)"),CZe.forEach(t),Zce.forEach(t),sHr=i(Ei),T(Bw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),gao=i(m),Cm=n(m,"H2",{class:!0});var Sso=s(Cm);Iw=n(Sso,"A",{id:!0,class:!0,href:!0});var hfa=s(Iw);B8e=n(hfa,"SPAN",{});var ufa=s(B8e);T($R.$$.fragment,ufa),ufa.forEach(t),hfa.forEach(t),lHr=i(Sso),I8e=n(Sso,"SPAN",{});var pfa=s(I8e);iHr=r(pfa,"TFAutoModelForMaskedLM"),pfa.forEach(t),Sso.forEach(t),hao=i(m),ur=n(m,"DIV",{class:!0});var Ci=s(ur);T(kR.$$.fragment,Ci),dHr=i(Ci),wm=n(Ci,"P",{});var Kce=s(wm);cHr=r(Kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),nae=n(Kce,"A",{href:!0});var _fa=s(nae);mHr=r(_fa,"from_pretrained()"),_fa.forEach(t),fHr=r(Kce," class method or the "),sae=n(Kce,"A",{href:!0});var bfa=s(sae);gHr=r(bfa,"from_config()"),bfa.forEach(t),hHr=r(Kce,` class
method.`),Kce.forEach(t),uHr=i(Ci),SR=n(Ci,"P",{});var Rso=s(SR);pHr=r(Rso,"This class cannot be instantiated directly using "),N8e=n(Rso,"CODE",{});var vfa=s(N8e);_Hr=r(vfa,"__init__()"),vfa.forEach(t),bHr=r(Rso," (throws an error)."),Rso.forEach(t),vHr=i(Ci),oa=n(Ci,"DIV",{class:!0});var ax=s(oa);T(RR.$$.fragment,ax),FHr=i(ax),q8e=n(ax,"P",{});var Ffa=s(q8e);THr=r(Ffa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ffa.forEach(t),MHr=i(ax),Am=n(ax,"P",{});var eme=s(Am);EHr=r(eme,`Note:
Loading a model from its configuration file does `),j8e=n(eme,"STRONG",{});var Tfa=s(j8e);CHr=r(Tfa,"not"),Tfa.forEach(t),wHr=r(eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),lae=n(eme,"A",{href:!0});var Mfa=s(lae);AHr=r(Mfa,"from_pretrained()"),Mfa.forEach(t),LHr=r(eme," to load the model weights."),eme.forEach(t),yHr=i(ax),T(Nw.$$.fragment,ax),ax.forEach(t),xHr=i(Ci),zr=n(Ci,"DIV",{class:!0});var wi=s(zr);T(PR.$$.fragment,wi),$Hr=i(wi),D8e=n(wi,"P",{});var Efa=s(D8e);kHr=r(Efa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Efa.forEach(t),SHr=i(wi),Dn=n(wi,"P",{});var nx=s(Dn);RHr=r(nx,"The model class to instantiate is selected based on the "),G8e=n(nx,"CODE",{});var Cfa=s(G8e);PHr=r(Cfa,"model_type"),Cfa.forEach(t),BHr=r(nx,` property of the config object (either
passed as an argument or loaded from `),O8e=n(nx,"CODE",{});var wfa=s(O8e);IHr=r(wfa,"pretrained_model_name_or_path"),wfa.forEach(t),NHr=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V8e=n(nx,"CODE",{});var Afa=s(V8e);qHr=r(Afa,"pretrained_model_name_or_path"),Afa.forEach(t),jHr=r(nx,":"),nx.forEach(t),DHr=i(wi),ge=n(wi,"UL",{});var _e=s(ge);qw=n(_e,"LI",{});var wZe=s(qw);X8e=n(wZe,"STRONG",{});var Lfa=s(X8e);GHr=r(Lfa,"albert"),Lfa.forEach(t),OHr=r(wZe," \u2014 "),iae=n(wZe,"A",{href:!0});var yfa=s(iae);VHr=r(yfa,"TFAlbertForMaskedLM"),yfa.forEach(t),XHr=r(wZe," (ALBERT model)"),wZe.forEach(t),zHr=i(_e),jw=n(_e,"LI",{});var AZe=s(jw);z8e=n(AZe,"STRONG",{});var xfa=s(z8e);QHr=r(xfa,"bert"),xfa.forEach(t),WHr=r(AZe," \u2014 "),dae=n(AZe,"A",{href:!0});var $fa=s(dae);UHr=r($fa,"TFBertForMaskedLM"),$fa.forEach(t),HHr=r(AZe," (BERT model)"),AZe.forEach(t),JHr=i(_e),Dw=n(_e,"LI",{});var LZe=s(Dw);Q8e=n(LZe,"STRONG",{});var kfa=s(Q8e);YHr=r(kfa,"camembert"),kfa.forEach(t),ZHr=r(LZe," \u2014 "),cae=n(LZe,"A",{href:!0});var Sfa=s(cae);KHr=r(Sfa,"TFCamembertForMaskedLM"),Sfa.forEach(t),eJr=r(LZe," (CamemBERT model)"),LZe.forEach(t),oJr=i(_e),Gw=n(_e,"LI",{});var yZe=s(Gw);W8e=n(yZe,"STRONG",{});var Rfa=s(W8e);rJr=r(Rfa,"convbert"),Rfa.forEach(t),tJr=r(yZe," \u2014 "),mae=n(yZe,"A",{href:!0});var Pfa=s(mae);aJr=r(Pfa,"TFConvBertForMaskedLM"),Pfa.forEach(t),nJr=r(yZe," (ConvBERT model)"),yZe.forEach(t),sJr=i(_e),Ow=n(_e,"LI",{});var xZe=s(Ow);U8e=n(xZe,"STRONG",{});var Bfa=s(U8e);lJr=r(Bfa,"deberta"),Bfa.forEach(t),iJr=r(xZe," \u2014 "),fae=n(xZe,"A",{href:!0});var Ifa=s(fae);dJr=r(Ifa,"TFDebertaForMaskedLM"),Ifa.forEach(t),cJr=r(xZe," (DeBERTa model)"),xZe.forEach(t),mJr=i(_e),Vw=n(_e,"LI",{});var $Ze=s(Vw);H8e=n($Ze,"STRONG",{});var Nfa=s(H8e);fJr=r(Nfa,"deberta-v2"),Nfa.forEach(t),gJr=r($Ze," \u2014 "),gae=n($Ze,"A",{href:!0});var qfa=s(gae);hJr=r(qfa,"TFDebertaV2ForMaskedLM"),qfa.forEach(t),uJr=r($Ze," (DeBERTa-v2 model)"),$Ze.forEach(t),pJr=i(_e),Xw=n(_e,"LI",{});var kZe=s(Xw);J8e=n(kZe,"STRONG",{});var jfa=s(J8e);_Jr=r(jfa,"distilbert"),jfa.forEach(t),bJr=r(kZe," \u2014 "),hae=n(kZe,"A",{href:!0});var Dfa=s(hae);vJr=r(Dfa,"TFDistilBertForMaskedLM"),Dfa.forEach(t),FJr=r(kZe," (DistilBERT model)"),kZe.forEach(t),TJr=i(_e),zw=n(_e,"LI",{});var SZe=s(zw);Y8e=n(SZe,"STRONG",{});var Gfa=s(Y8e);MJr=r(Gfa,"electra"),Gfa.forEach(t),EJr=r(SZe," \u2014 "),uae=n(SZe,"A",{href:!0});var Ofa=s(uae);CJr=r(Ofa,"TFElectraForMaskedLM"),Ofa.forEach(t),wJr=r(SZe," (ELECTRA model)"),SZe.forEach(t),AJr=i(_e),Qw=n(_e,"LI",{});var RZe=s(Qw);Z8e=n(RZe,"STRONG",{});var Vfa=s(Z8e);LJr=r(Vfa,"flaubert"),Vfa.forEach(t),yJr=r(RZe," \u2014 "),pae=n(RZe,"A",{href:!0});var Xfa=s(pae);xJr=r(Xfa,"TFFlaubertWithLMHeadModel"),Xfa.forEach(t),$Jr=r(RZe," (FlauBERT model)"),RZe.forEach(t),kJr=i(_e),Ww=n(_e,"LI",{});var PZe=s(Ww);K8e=n(PZe,"STRONG",{});var zfa=s(K8e);SJr=r(zfa,"funnel"),zfa.forEach(t),RJr=r(PZe," \u2014 "),_ae=n(PZe,"A",{href:!0});var Qfa=s(_ae);PJr=r(Qfa,"TFFunnelForMaskedLM"),Qfa.forEach(t),BJr=r(PZe," (Funnel Transformer model)"),PZe.forEach(t),IJr=i(_e),Uw=n(_e,"LI",{});var BZe=s(Uw);eye=n(BZe,"STRONG",{});var Wfa=s(eye);NJr=r(Wfa,"layoutlm"),Wfa.forEach(t),qJr=r(BZe," \u2014 "),bae=n(BZe,"A",{href:!0});var Ufa=s(bae);jJr=r(Ufa,"TFLayoutLMForMaskedLM"),Ufa.forEach(t),DJr=r(BZe," (LayoutLM model)"),BZe.forEach(t),GJr=i(_e),Hw=n(_e,"LI",{});var IZe=s(Hw);oye=n(IZe,"STRONG",{});var Hfa=s(oye);OJr=r(Hfa,"longformer"),Hfa.forEach(t),VJr=r(IZe," \u2014 "),vae=n(IZe,"A",{href:!0});var Jfa=s(vae);XJr=r(Jfa,"TFLongformerForMaskedLM"),Jfa.forEach(t),zJr=r(IZe," (Longformer model)"),IZe.forEach(t),QJr=i(_e),Jw=n(_e,"LI",{});var NZe=s(Jw);rye=n(NZe,"STRONG",{});var Yfa=s(rye);WJr=r(Yfa,"mobilebert"),Yfa.forEach(t),UJr=r(NZe," \u2014 "),Fae=n(NZe,"A",{href:!0});var Zfa=s(Fae);HJr=r(Zfa,"TFMobileBertForMaskedLM"),Zfa.forEach(t),JJr=r(NZe," (MobileBERT model)"),NZe.forEach(t),YJr=i(_e),Yw=n(_e,"LI",{});var qZe=s(Yw);tye=n(qZe,"STRONG",{});var Kfa=s(tye);ZJr=r(Kfa,"mpnet"),Kfa.forEach(t),KJr=r(qZe," \u2014 "),Tae=n(qZe,"A",{href:!0});var ega=s(Tae);eYr=r(ega,"TFMPNetForMaskedLM"),ega.forEach(t),oYr=r(qZe," (MPNet model)"),qZe.forEach(t),rYr=i(_e),Zw=n(_e,"LI",{});var jZe=s(Zw);aye=n(jZe,"STRONG",{});var oga=s(aye);tYr=r(oga,"rembert"),oga.forEach(t),aYr=r(jZe," \u2014 "),Mae=n(jZe,"A",{href:!0});var rga=s(Mae);nYr=r(rga,"TFRemBertForMaskedLM"),rga.forEach(t),sYr=r(jZe," (RemBERT model)"),jZe.forEach(t),lYr=i(_e),Kw=n(_e,"LI",{});var DZe=s(Kw);nye=n(DZe,"STRONG",{});var tga=s(nye);iYr=r(tga,"roberta"),tga.forEach(t),dYr=r(DZe," \u2014 "),Eae=n(DZe,"A",{href:!0});var aga=s(Eae);cYr=r(aga,"TFRobertaForMaskedLM"),aga.forEach(t),mYr=r(DZe," (RoBERTa model)"),DZe.forEach(t),fYr=i(_e),eA=n(_e,"LI",{});var GZe=s(eA);sye=n(GZe,"STRONG",{});var nga=s(sye);gYr=r(nga,"roformer"),nga.forEach(t),hYr=r(GZe," \u2014 "),Cae=n(GZe,"A",{href:!0});var sga=s(Cae);uYr=r(sga,"TFRoFormerForMaskedLM"),sga.forEach(t),pYr=r(GZe," (RoFormer model)"),GZe.forEach(t),_Yr=i(_e),oA=n(_e,"LI",{});var OZe=s(oA);lye=n(OZe,"STRONG",{});var lga=s(lye);bYr=r(lga,"tapas"),lga.forEach(t),vYr=r(OZe," \u2014 "),wae=n(OZe,"A",{href:!0});var iga=s(wae);FYr=r(iga,"TFTapasForMaskedLM"),iga.forEach(t),TYr=r(OZe," (TAPAS model)"),OZe.forEach(t),MYr=i(_e),rA=n(_e,"LI",{});var VZe=s(rA);iye=n(VZe,"STRONG",{});var dga=s(iye);EYr=r(dga,"xlm"),dga.forEach(t),CYr=r(VZe," \u2014 "),Aae=n(VZe,"A",{href:!0});var cga=s(Aae);wYr=r(cga,"TFXLMWithLMHeadModel"),cga.forEach(t),AYr=r(VZe," (XLM model)"),VZe.forEach(t),LYr=i(_e),tA=n(_e,"LI",{});var XZe=s(tA);dye=n(XZe,"STRONG",{});var mga=s(dye);yYr=r(mga,"xlm-roberta"),mga.forEach(t),xYr=r(XZe," \u2014 "),Lae=n(XZe,"A",{href:!0});var fga=s(Lae);$Yr=r(fga,"TFXLMRobertaForMaskedLM"),fga.forEach(t),kYr=r(XZe," (XLM-RoBERTa model)"),XZe.forEach(t),_e.forEach(t),SYr=i(wi),T(aA.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),uao=i(m),Lm=n(m,"H2",{class:!0});var Pso=s(Lm);nA=n(Pso,"A",{id:!0,class:!0,href:!0});var gga=s(nA);cye=n(gga,"SPAN",{});var hga=s(cye);T(BR.$$.fragment,hga),hga.forEach(t),gga.forEach(t),RYr=i(Pso),mye=n(Pso,"SPAN",{});var uga=s(mye);PYr=r(uga,"TFAutoModelForSeq2SeqLM"),uga.forEach(t),Pso.forEach(t),pao=i(m),pr=n(m,"DIV",{class:!0});var Ai=s(pr);T(IR.$$.fragment,Ai),BYr=i(Ai),ym=n(Ai,"P",{});var ome=s(ym);IYr=r(ome,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),yae=n(ome,"A",{href:!0});var pga=s(yae);NYr=r(pga,"from_pretrained()"),pga.forEach(t),qYr=r(ome," class method or the "),xae=n(ome,"A",{href:!0});var _ga=s(xae);jYr=r(_ga,"from_config()"),_ga.forEach(t),DYr=r(ome,` class
method.`),ome.forEach(t),GYr=i(Ai),NR=n(Ai,"P",{});var Bso=s(NR);OYr=r(Bso,"This class cannot be instantiated directly using "),fye=n(Bso,"CODE",{});var bga=s(fye);VYr=r(bga,"__init__()"),bga.forEach(t),XYr=r(Bso," (throws an error)."),Bso.forEach(t),zYr=i(Ai),ra=n(Ai,"DIV",{class:!0});var sx=s(ra);T(qR.$$.fragment,sx),QYr=i(sx),gye=n(sx,"P",{});var vga=s(gye);WYr=r(vga,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vga.forEach(t),UYr=i(sx),xm=n(sx,"P",{});var rme=s(xm);HYr=r(rme,`Note:
Loading a model from its configuration file does `),hye=n(rme,"STRONG",{});var Fga=s(hye);JYr=r(Fga,"not"),Fga.forEach(t),YYr=r(rme,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ae=n(rme,"A",{href:!0});var Tga=s($ae);ZYr=r(Tga,"from_pretrained()"),Tga.forEach(t),KYr=r(rme," to load the model weights."),rme.forEach(t),eZr=i(sx),T(sA.$$.fragment,sx),sx.forEach(t),oZr=i(Ai),Qr=n(Ai,"DIV",{class:!0});var Li=s(Qr);T(jR.$$.fragment,Li),rZr=i(Li),uye=n(Li,"P",{});var Mga=s(uye);tZr=r(Mga,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Mga.forEach(t),aZr=i(Li),Gn=n(Li,"P",{});var lx=s(Gn);nZr=r(lx,"The model class to instantiate is selected based on the "),pye=n(lx,"CODE",{});var Ega=s(pye);sZr=r(Ega,"model_type"),Ega.forEach(t),lZr=r(lx,` property of the config object (either
passed as an argument or loaded from `),_ye=n(lx,"CODE",{});var Cga=s(_ye);iZr=r(Cga,"pretrained_model_name_or_path"),Cga.forEach(t),dZr=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bye=n(lx,"CODE",{});var wga=s(bye);cZr=r(wga,"pretrained_model_name_or_path"),wga.forEach(t),mZr=r(lx,":"),lx.forEach(t),fZr=i(Li),xe=n(Li,"UL",{});var qe=s(xe);lA=n(qe,"LI",{});var zZe=s(lA);vye=n(zZe,"STRONG",{});var Aga=s(vye);gZr=r(Aga,"bart"),Aga.forEach(t),hZr=r(zZe," \u2014 "),kae=n(zZe,"A",{href:!0});var Lga=s(kae);uZr=r(Lga,"TFBartForConditionalGeneration"),Lga.forEach(t),pZr=r(zZe," (BART model)"),zZe.forEach(t),_Zr=i(qe),iA=n(qe,"LI",{});var QZe=s(iA);Fye=n(QZe,"STRONG",{});var yga=s(Fye);bZr=r(yga,"blenderbot"),yga.forEach(t),vZr=r(QZe," \u2014 "),Sae=n(QZe,"A",{href:!0});var xga=s(Sae);FZr=r(xga,"TFBlenderbotForConditionalGeneration"),xga.forEach(t),TZr=r(QZe," (Blenderbot model)"),QZe.forEach(t),MZr=i(qe),dA=n(qe,"LI",{});var WZe=s(dA);Tye=n(WZe,"STRONG",{});var $ga=s(Tye);EZr=r($ga,"blenderbot-small"),$ga.forEach(t),CZr=r(WZe," \u2014 "),Rae=n(WZe,"A",{href:!0});var kga=s(Rae);wZr=r(kga,"TFBlenderbotSmallForConditionalGeneration"),kga.forEach(t),AZr=r(WZe," (BlenderbotSmall model)"),WZe.forEach(t),LZr=i(qe),cA=n(qe,"LI",{});var UZe=s(cA);Mye=n(UZe,"STRONG",{});var Sga=s(Mye);yZr=r(Sga,"encoder-decoder"),Sga.forEach(t),xZr=r(UZe," \u2014 "),Pae=n(UZe,"A",{href:!0});var Rga=s(Pae);$Zr=r(Rga,"TFEncoderDecoderModel"),Rga.forEach(t),kZr=r(UZe," (Encoder decoder model)"),UZe.forEach(t),SZr=i(qe),mA=n(qe,"LI",{});var HZe=s(mA);Eye=n(HZe,"STRONG",{});var Pga=s(Eye);RZr=r(Pga,"led"),Pga.forEach(t),PZr=r(HZe," \u2014 "),Bae=n(HZe,"A",{href:!0});var Bga=s(Bae);BZr=r(Bga,"TFLEDForConditionalGeneration"),Bga.forEach(t),IZr=r(HZe," (LED model)"),HZe.forEach(t),NZr=i(qe),fA=n(qe,"LI",{});var JZe=s(fA);Cye=n(JZe,"STRONG",{});var Iga=s(Cye);qZr=r(Iga,"marian"),Iga.forEach(t),jZr=r(JZe," \u2014 "),Iae=n(JZe,"A",{href:!0});var Nga=s(Iae);DZr=r(Nga,"TFMarianMTModel"),Nga.forEach(t),GZr=r(JZe," (Marian model)"),JZe.forEach(t),OZr=i(qe),gA=n(qe,"LI",{});var YZe=s(gA);wye=n(YZe,"STRONG",{});var qga=s(wye);VZr=r(qga,"mbart"),qga.forEach(t),XZr=r(YZe," \u2014 "),Nae=n(YZe,"A",{href:!0});var jga=s(Nae);zZr=r(jga,"TFMBartForConditionalGeneration"),jga.forEach(t),QZr=r(YZe," (mBART model)"),YZe.forEach(t),WZr=i(qe),hA=n(qe,"LI",{});var ZZe=s(hA);Aye=n(ZZe,"STRONG",{});var Dga=s(Aye);UZr=r(Dga,"mt5"),Dga.forEach(t),HZr=r(ZZe," \u2014 "),qae=n(ZZe,"A",{href:!0});var Gga=s(qae);JZr=r(Gga,"TFMT5ForConditionalGeneration"),Gga.forEach(t),YZr=r(ZZe," (MT5 model)"),ZZe.forEach(t),ZZr=i(qe),uA=n(qe,"LI",{});var KZe=s(uA);Lye=n(KZe,"STRONG",{});var Oga=s(Lye);KZr=r(Oga,"pegasus"),Oga.forEach(t),eKr=r(KZe," \u2014 "),jae=n(KZe,"A",{href:!0});var Vga=s(jae);oKr=r(Vga,"TFPegasusForConditionalGeneration"),Vga.forEach(t),rKr=r(KZe," (Pegasus model)"),KZe.forEach(t),tKr=i(qe),pA=n(qe,"LI",{});var eKe=s(pA);yye=n(eKe,"STRONG",{});var Xga=s(yye);aKr=r(Xga,"t5"),Xga.forEach(t),nKr=r(eKe," \u2014 "),Dae=n(eKe,"A",{href:!0});var zga=s(Dae);sKr=r(zga,"TFT5ForConditionalGeneration"),zga.forEach(t),lKr=r(eKe," (T5 model)"),eKe.forEach(t),qe.forEach(t),iKr=i(Li),T(_A.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),_ao=i(m),$m=n(m,"H2",{class:!0});var Iso=s($m);bA=n(Iso,"A",{id:!0,class:!0,href:!0});var Qga=s(bA);xye=n(Qga,"SPAN",{});var Wga=s(xye);T(DR.$$.fragment,Wga),Wga.forEach(t),Qga.forEach(t),dKr=i(Iso),$ye=n(Iso,"SPAN",{});var Uga=s($ye);cKr=r(Uga,"TFAutoModelForSequenceClassification"),Uga.forEach(t),Iso.forEach(t),bao=i(m),_r=n(m,"DIV",{class:!0});var yi=s(_r);T(GR.$$.fragment,yi),mKr=i(yi),km=n(yi,"P",{});var tme=s(km);fKr=r(tme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Gae=n(tme,"A",{href:!0});var Hga=s(Gae);gKr=r(Hga,"from_pretrained()"),Hga.forEach(t),hKr=r(tme," class method or the "),Oae=n(tme,"A",{href:!0});var Jga=s(Oae);uKr=r(Jga,"from_config()"),Jga.forEach(t),pKr=r(tme,` class
method.`),tme.forEach(t),_Kr=i(yi),OR=n(yi,"P",{});var Nso=s(OR);bKr=r(Nso,"This class cannot be instantiated directly using "),kye=n(Nso,"CODE",{});var Yga=s(kye);vKr=r(Yga,"__init__()"),Yga.forEach(t),FKr=r(Nso," (throws an error)."),Nso.forEach(t),TKr=i(yi),ta=n(yi,"DIV",{class:!0});var ix=s(ta);T(VR.$$.fragment,ix),MKr=i(ix),Sye=n(ix,"P",{});var Zga=s(Sye);EKr=r(Zga,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Zga.forEach(t),CKr=i(ix),Sm=n(ix,"P",{});var ame=s(Sm);wKr=r(ame,`Note:
Loading a model from its configuration file does `),Rye=n(ame,"STRONG",{});var Kga=s(Rye);AKr=r(Kga,"not"),Kga.forEach(t),LKr=r(ame,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vae=n(ame,"A",{href:!0});var eha=s(Vae);yKr=r(eha,"from_pretrained()"),eha.forEach(t),xKr=r(ame," to load the model weights."),ame.forEach(t),$Kr=i(ix),T(vA.$$.fragment,ix),ix.forEach(t),kKr=i(yi),Wr=n(yi,"DIV",{class:!0});var xi=s(Wr);T(XR.$$.fragment,xi),SKr=i(xi),Pye=n(xi,"P",{});var oha=s(Pye);RKr=r(oha,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oha.forEach(t),PKr=i(xi),On=n(xi,"P",{});var dx=s(On);BKr=r(dx,"The model class to instantiate is selected based on the "),Bye=n(dx,"CODE",{});var rha=s(Bye);IKr=r(rha,"model_type"),rha.forEach(t),NKr=r(dx,` property of the config object (either
passed as an argument or loaded from `),Iye=n(dx,"CODE",{});var tha=s(Iye);qKr=r(tha,"pretrained_model_name_or_path"),tha.forEach(t),jKr=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nye=n(dx,"CODE",{});var aha=s(Nye);DKr=r(aha,"pretrained_model_name_or_path"),aha.forEach(t),GKr=r(dx,":"),dx.forEach(t),OKr=i(xi),re=n(xi,"UL",{});var ae=s(re);FA=n(ae,"LI",{});var oKe=s(FA);qye=n(oKe,"STRONG",{});var nha=s(qye);VKr=r(nha,"albert"),nha.forEach(t),XKr=r(oKe," \u2014 "),Xae=n(oKe,"A",{href:!0});var sha=s(Xae);zKr=r(sha,"TFAlbertForSequenceClassification"),sha.forEach(t),QKr=r(oKe," (ALBERT model)"),oKe.forEach(t),WKr=i(ae),TA=n(ae,"LI",{});var rKe=s(TA);jye=n(rKe,"STRONG",{});var lha=s(jye);UKr=r(lha,"bert"),lha.forEach(t),HKr=r(rKe," \u2014 "),zae=n(rKe,"A",{href:!0});var iha=s(zae);JKr=r(iha,"TFBertForSequenceClassification"),iha.forEach(t),YKr=r(rKe," (BERT model)"),rKe.forEach(t),ZKr=i(ae),MA=n(ae,"LI",{});var tKe=s(MA);Dye=n(tKe,"STRONG",{});var dha=s(Dye);KKr=r(dha,"camembert"),dha.forEach(t),eet=r(tKe," \u2014 "),Qae=n(tKe,"A",{href:!0});var cha=s(Qae);oet=r(cha,"TFCamembertForSequenceClassification"),cha.forEach(t),ret=r(tKe," (CamemBERT model)"),tKe.forEach(t),tet=i(ae),EA=n(ae,"LI",{});var aKe=s(EA);Gye=n(aKe,"STRONG",{});var mha=s(Gye);aet=r(mha,"convbert"),mha.forEach(t),net=r(aKe," \u2014 "),Wae=n(aKe,"A",{href:!0});var fha=s(Wae);set=r(fha,"TFConvBertForSequenceClassification"),fha.forEach(t),iet=r(aKe," (ConvBERT model)"),aKe.forEach(t),det=i(ae),CA=n(ae,"LI",{});var nKe=s(CA);Oye=n(nKe,"STRONG",{});var gha=s(Oye);cet=r(gha,"ctrl"),gha.forEach(t),met=r(nKe," \u2014 "),Uae=n(nKe,"A",{href:!0});var hha=s(Uae);fet=r(hha,"TFCTRLForSequenceClassification"),hha.forEach(t),get=r(nKe," (CTRL model)"),nKe.forEach(t),het=i(ae),wA=n(ae,"LI",{});var sKe=s(wA);Vye=n(sKe,"STRONG",{});var uha=s(Vye);uet=r(uha,"deberta"),uha.forEach(t),pet=r(sKe," \u2014 "),Hae=n(sKe,"A",{href:!0});var pha=s(Hae);_et=r(pha,"TFDebertaForSequenceClassification"),pha.forEach(t),bet=r(sKe," (DeBERTa model)"),sKe.forEach(t),vet=i(ae),AA=n(ae,"LI",{});var lKe=s(AA);Xye=n(lKe,"STRONG",{});var _ha=s(Xye);Fet=r(_ha,"deberta-v2"),_ha.forEach(t),Tet=r(lKe," \u2014 "),Jae=n(lKe,"A",{href:!0});var bha=s(Jae);Met=r(bha,"TFDebertaV2ForSequenceClassification"),bha.forEach(t),Eet=r(lKe," (DeBERTa-v2 model)"),lKe.forEach(t),Cet=i(ae),LA=n(ae,"LI",{});var iKe=s(LA);zye=n(iKe,"STRONG",{});var vha=s(zye);wet=r(vha,"distilbert"),vha.forEach(t),Aet=r(iKe," \u2014 "),Yae=n(iKe,"A",{href:!0});var Fha=s(Yae);Let=r(Fha,"TFDistilBertForSequenceClassification"),Fha.forEach(t),yet=r(iKe," (DistilBERT model)"),iKe.forEach(t),xet=i(ae),yA=n(ae,"LI",{});var dKe=s(yA);Qye=n(dKe,"STRONG",{});var Tha=s(Qye);$et=r(Tha,"electra"),Tha.forEach(t),ket=r(dKe," \u2014 "),Zae=n(dKe,"A",{href:!0});var Mha=s(Zae);Set=r(Mha,"TFElectraForSequenceClassification"),Mha.forEach(t),Ret=r(dKe," (ELECTRA model)"),dKe.forEach(t),Pet=i(ae),xA=n(ae,"LI",{});var cKe=s(xA);Wye=n(cKe,"STRONG",{});var Eha=s(Wye);Bet=r(Eha,"flaubert"),Eha.forEach(t),Iet=r(cKe," \u2014 "),Kae=n(cKe,"A",{href:!0});var Cha=s(Kae);Net=r(Cha,"TFFlaubertForSequenceClassification"),Cha.forEach(t),qet=r(cKe," (FlauBERT model)"),cKe.forEach(t),jet=i(ae),$A=n(ae,"LI",{});var mKe=s($A);Uye=n(mKe,"STRONG",{});var wha=s(Uye);Det=r(wha,"funnel"),wha.forEach(t),Get=r(mKe," \u2014 "),ene=n(mKe,"A",{href:!0});var Aha=s(ene);Oet=r(Aha,"TFFunnelForSequenceClassification"),Aha.forEach(t),Vet=r(mKe," (Funnel Transformer model)"),mKe.forEach(t),Xet=i(ae),kA=n(ae,"LI",{});var fKe=s(kA);Hye=n(fKe,"STRONG",{});var Lha=s(Hye);zet=r(Lha,"gpt2"),Lha.forEach(t),Qet=r(fKe," \u2014 "),one=n(fKe,"A",{href:!0});var yha=s(one);Wet=r(yha,"TFGPT2ForSequenceClassification"),yha.forEach(t),Uet=r(fKe," (OpenAI GPT-2 model)"),fKe.forEach(t),Het=i(ae),SA=n(ae,"LI",{});var gKe=s(SA);Jye=n(gKe,"STRONG",{});var xha=s(Jye);Jet=r(xha,"gptj"),xha.forEach(t),Yet=r(gKe," \u2014 "),rne=n(gKe,"A",{href:!0});var $ha=s(rne);Zet=r($ha,"TFGPTJForSequenceClassification"),$ha.forEach(t),Ket=r(gKe," (GPT-J model)"),gKe.forEach(t),eot=i(ae),RA=n(ae,"LI",{});var hKe=s(RA);Yye=n(hKe,"STRONG",{});var kha=s(Yye);oot=r(kha,"layoutlm"),kha.forEach(t),rot=r(hKe," \u2014 "),tne=n(hKe,"A",{href:!0});var Sha=s(tne);tot=r(Sha,"TFLayoutLMForSequenceClassification"),Sha.forEach(t),aot=r(hKe," (LayoutLM model)"),hKe.forEach(t),not=i(ae),PA=n(ae,"LI",{});var uKe=s(PA);Zye=n(uKe,"STRONG",{});var Rha=s(Zye);sot=r(Rha,"layoutlmv3"),Rha.forEach(t),lot=r(uKe," \u2014 "),ane=n(uKe,"A",{href:!0});var Pha=s(ane);iot=r(Pha,"TFLayoutLMv3ForSequenceClassification"),Pha.forEach(t),dot=r(uKe," (LayoutLMv3 model)"),uKe.forEach(t),cot=i(ae),BA=n(ae,"LI",{});var pKe=s(BA);Kye=n(pKe,"STRONG",{});var Bha=s(Kye);mot=r(Bha,"longformer"),Bha.forEach(t),fot=r(pKe," \u2014 "),nne=n(pKe,"A",{href:!0});var Iha=s(nne);got=r(Iha,"TFLongformerForSequenceClassification"),Iha.forEach(t),hot=r(pKe," (Longformer model)"),pKe.forEach(t),uot=i(ae),IA=n(ae,"LI",{});var _Ke=s(IA);e9e=n(_Ke,"STRONG",{});var Nha=s(e9e);pot=r(Nha,"mobilebert"),Nha.forEach(t),_ot=r(_Ke," \u2014 "),sne=n(_Ke,"A",{href:!0});var qha=s(sne);bot=r(qha,"TFMobileBertForSequenceClassification"),qha.forEach(t),vot=r(_Ke," (MobileBERT model)"),_Ke.forEach(t),Fot=i(ae),NA=n(ae,"LI",{});var bKe=s(NA);o9e=n(bKe,"STRONG",{});var jha=s(o9e);Tot=r(jha,"mpnet"),jha.forEach(t),Mot=r(bKe," \u2014 "),lne=n(bKe,"A",{href:!0});var Dha=s(lne);Eot=r(Dha,"TFMPNetForSequenceClassification"),Dha.forEach(t),Cot=r(bKe," (MPNet model)"),bKe.forEach(t),wot=i(ae),qA=n(ae,"LI",{});var vKe=s(qA);r9e=n(vKe,"STRONG",{});var Gha=s(r9e);Aot=r(Gha,"openai-gpt"),Gha.forEach(t),Lot=r(vKe," \u2014 "),ine=n(vKe,"A",{href:!0});var Oha=s(ine);yot=r(Oha,"TFOpenAIGPTForSequenceClassification"),Oha.forEach(t),xot=r(vKe," (OpenAI GPT model)"),vKe.forEach(t),$ot=i(ae),jA=n(ae,"LI",{});var FKe=s(jA);t9e=n(FKe,"STRONG",{});var Vha=s(t9e);kot=r(Vha,"rembert"),Vha.forEach(t),Sot=r(FKe," \u2014 "),dne=n(FKe,"A",{href:!0});var Xha=s(dne);Rot=r(Xha,"TFRemBertForSequenceClassification"),Xha.forEach(t),Pot=r(FKe," (RemBERT model)"),FKe.forEach(t),Bot=i(ae),DA=n(ae,"LI",{});var TKe=s(DA);a9e=n(TKe,"STRONG",{});var zha=s(a9e);Iot=r(zha,"roberta"),zha.forEach(t),Not=r(TKe," \u2014 "),cne=n(TKe,"A",{href:!0});var Qha=s(cne);qot=r(Qha,"TFRobertaForSequenceClassification"),Qha.forEach(t),jot=r(TKe," (RoBERTa model)"),TKe.forEach(t),Dot=i(ae),GA=n(ae,"LI",{});var MKe=s(GA);n9e=n(MKe,"STRONG",{});var Wha=s(n9e);Got=r(Wha,"roformer"),Wha.forEach(t),Oot=r(MKe," \u2014 "),mne=n(MKe,"A",{href:!0});var Uha=s(mne);Vot=r(Uha,"TFRoFormerForSequenceClassification"),Uha.forEach(t),Xot=r(MKe," (RoFormer model)"),MKe.forEach(t),zot=i(ae),OA=n(ae,"LI",{});var EKe=s(OA);s9e=n(EKe,"STRONG",{});var Hha=s(s9e);Qot=r(Hha,"tapas"),Hha.forEach(t),Wot=r(EKe," \u2014 "),fne=n(EKe,"A",{href:!0});var Jha=s(fne);Uot=r(Jha,"TFTapasForSequenceClassification"),Jha.forEach(t),Hot=r(EKe," (TAPAS model)"),EKe.forEach(t),Jot=i(ae),VA=n(ae,"LI",{});var CKe=s(VA);l9e=n(CKe,"STRONG",{});var Yha=s(l9e);Yot=r(Yha,"transfo-xl"),Yha.forEach(t),Zot=r(CKe," \u2014 "),gne=n(CKe,"A",{href:!0});var Zha=s(gne);Kot=r(Zha,"TFTransfoXLForSequenceClassification"),Zha.forEach(t),ert=r(CKe," (Transformer-XL model)"),CKe.forEach(t),ort=i(ae),XA=n(ae,"LI",{});var wKe=s(XA);i9e=n(wKe,"STRONG",{});var Kha=s(i9e);rrt=r(Kha,"xlm"),Kha.forEach(t),trt=r(wKe," \u2014 "),hne=n(wKe,"A",{href:!0});var eua=s(hne);art=r(eua,"TFXLMForSequenceClassification"),eua.forEach(t),nrt=r(wKe," (XLM model)"),wKe.forEach(t),srt=i(ae),zA=n(ae,"LI",{});var AKe=s(zA);d9e=n(AKe,"STRONG",{});var oua=s(d9e);lrt=r(oua,"xlm-roberta"),oua.forEach(t),irt=r(AKe," \u2014 "),une=n(AKe,"A",{href:!0});var rua=s(une);drt=r(rua,"TFXLMRobertaForSequenceClassification"),rua.forEach(t),crt=r(AKe," (XLM-RoBERTa model)"),AKe.forEach(t),mrt=i(ae),QA=n(ae,"LI",{});var LKe=s(QA);c9e=n(LKe,"STRONG",{});var tua=s(c9e);frt=r(tua,"xlnet"),tua.forEach(t),grt=r(LKe," \u2014 "),pne=n(LKe,"A",{href:!0});var aua=s(pne);hrt=r(aua,"TFXLNetForSequenceClassification"),aua.forEach(t),urt=r(LKe," (XLNet model)"),LKe.forEach(t),ae.forEach(t),prt=i(xi),T(WA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),vao=i(m),Rm=n(m,"H2",{class:!0});var qso=s(Rm);UA=n(qso,"A",{id:!0,class:!0,href:!0});var nua=s(UA);m9e=n(nua,"SPAN",{});var sua=s(m9e);T(zR.$$.fragment,sua),sua.forEach(t),nua.forEach(t),_rt=i(qso),f9e=n(qso,"SPAN",{});var lua=s(f9e);brt=r(lua,"TFAutoModelForMultipleChoice"),lua.forEach(t),qso.forEach(t),Fao=i(m),br=n(m,"DIV",{class:!0});var $i=s(br);T(QR.$$.fragment,$i),vrt=i($i),Pm=n($i,"P",{});var nme=s(Pm);Frt=r(nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_ne=n(nme,"A",{href:!0});var iua=s(_ne);Trt=r(iua,"from_pretrained()"),iua.forEach(t),Mrt=r(nme," class method or the "),bne=n(nme,"A",{href:!0});var dua=s(bne);Ert=r(dua,"from_config()"),dua.forEach(t),Crt=r(nme,` class
method.`),nme.forEach(t),wrt=i($i),WR=n($i,"P",{});var jso=s(WR);Art=r(jso,"This class cannot be instantiated directly using "),g9e=n(jso,"CODE",{});var cua=s(g9e);Lrt=r(cua,"__init__()"),cua.forEach(t),yrt=r(jso," (throws an error)."),jso.forEach(t),xrt=i($i),aa=n($i,"DIV",{class:!0});var cx=s(aa);T(UR.$$.fragment,cx),$rt=i(cx),h9e=n(cx,"P",{});var mua=s(h9e);krt=r(mua,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),mua.forEach(t),Srt=i(cx),Bm=n(cx,"P",{});var sme=s(Bm);Rrt=r(sme,`Note:
Loading a model from its configuration file does `),u9e=n(sme,"STRONG",{});var fua=s(u9e);Prt=r(fua,"not"),fua.forEach(t),Brt=r(sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),vne=n(sme,"A",{href:!0});var gua=s(vne);Irt=r(gua,"from_pretrained()"),gua.forEach(t),Nrt=r(sme," to load the model weights."),sme.forEach(t),qrt=i(cx),T(HA.$$.fragment,cx),cx.forEach(t),jrt=i($i),Ur=n($i,"DIV",{class:!0});var ki=s(Ur);T(HR.$$.fragment,ki),Drt=i(ki),p9e=n(ki,"P",{});var hua=s(p9e);Grt=r(hua,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),hua.forEach(t),Ort=i(ki),Vn=n(ki,"P",{});var mx=s(Vn);Vrt=r(mx,"The model class to instantiate is selected based on the "),_9e=n(mx,"CODE",{});var uua=s(_9e);Xrt=r(uua,"model_type"),uua.forEach(t),zrt=r(mx,` property of the config object (either
passed as an argument or loaded from `),b9e=n(mx,"CODE",{});var pua=s(b9e);Qrt=r(pua,"pretrained_model_name_or_path"),pua.forEach(t),Wrt=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v9e=n(mx,"CODE",{});var _ua=s(v9e);Urt=r(_ua,"pretrained_model_name_or_path"),_ua.forEach(t),Hrt=r(mx,":"),mx.forEach(t),Jrt=i(ki),ve=n(ki,"UL",{});var Te=s(ve);JA=n(Te,"LI",{});var yKe=s(JA);F9e=n(yKe,"STRONG",{});var bua=s(F9e);Yrt=r(bua,"albert"),bua.forEach(t),Zrt=r(yKe," \u2014 "),Fne=n(yKe,"A",{href:!0});var vua=s(Fne);Krt=r(vua,"TFAlbertForMultipleChoice"),vua.forEach(t),ett=r(yKe," (ALBERT model)"),yKe.forEach(t),ott=i(Te),YA=n(Te,"LI",{});var xKe=s(YA);T9e=n(xKe,"STRONG",{});var Fua=s(T9e);rtt=r(Fua,"bert"),Fua.forEach(t),ttt=r(xKe," \u2014 "),Tne=n(xKe,"A",{href:!0});var Tua=s(Tne);att=r(Tua,"TFBertForMultipleChoice"),Tua.forEach(t),ntt=r(xKe," (BERT model)"),xKe.forEach(t),stt=i(Te),ZA=n(Te,"LI",{});var $Ke=s(ZA);M9e=n($Ke,"STRONG",{});var Mua=s(M9e);ltt=r(Mua,"camembert"),Mua.forEach(t),itt=r($Ke," \u2014 "),Mne=n($Ke,"A",{href:!0});var Eua=s(Mne);dtt=r(Eua,"TFCamembertForMultipleChoice"),Eua.forEach(t),ctt=r($Ke," (CamemBERT model)"),$Ke.forEach(t),mtt=i(Te),KA=n(Te,"LI",{});var kKe=s(KA);E9e=n(kKe,"STRONG",{});var Cua=s(E9e);ftt=r(Cua,"convbert"),Cua.forEach(t),gtt=r(kKe," \u2014 "),Ene=n(kKe,"A",{href:!0});var wua=s(Ene);htt=r(wua,"TFConvBertForMultipleChoice"),wua.forEach(t),utt=r(kKe," (ConvBERT model)"),kKe.forEach(t),ptt=i(Te),e6=n(Te,"LI",{});var SKe=s(e6);C9e=n(SKe,"STRONG",{});var Aua=s(C9e);_tt=r(Aua,"distilbert"),Aua.forEach(t),btt=r(SKe," \u2014 "),Cne=n(SKe,"A",{href:!0});var Lua=s(Cne);vtt=r(Lua,"TFDistilBertForMultipleChoice"),Lua.forEach(t),Ftt=r(SKe," (DistilBERT model)"),SKe.forEach(t),Ttt=i(Te),o6=n(Te,"LI",{});var RKe=s(o6);w9e=n(RKe,"STRONG",{});var yua=s(w9e);Mtt=r(yua,"electra"),yua.forEach(t),Ett=r(RKe," \u2014 "),wne=n(RKe,"A",{href:!0});var xua=s(wne);Ctt=r(xua,"TFElectraForMultipleChoice"),xua.forEach(t),wtt=r(RKe," (ELECTRA model)"),RKe.forEach(t),Att=i(Te),r6=n(Te,"LI",{});var PKe=s(r6);A9e=n(PKe,"STRONG",{});var $ua=s(A9e);Ltt=r($ua,"flaubert"),$ua.forEach(t),ytt=r(PKe," \u2014 "),Ane=n(PKe,"A",{href:!0});var kua=s(Ane);xtt=r(kua,"TFFlaubertForMultipleChoice"),kua.forEach(t),$tt=r(PKe," (FlauBERT model)"),PKe.forEach(t),ktt=i(Te),t6=n(Te,"LI",{});var BKe=s(t6);L9e=n(BKe,"STRONG",{});var Sua=s(L9e);Stt=r(Sua,"funnel"),Sua.forEach(t),Rtt=r(BKe," \u2014 "),Lne=n(BKe,"A",{href:!0});var Rua=s(Lne);Ptt=r(Rua,"TFFunnelForMultipleChoice"),Rua.forEach(t),Btt=r(BKe," (Funnel Transformer model)"),BKe.forEach(t),Itt=i(Te),a6=n(Te,"LI",{});var IKe=s(a6);y9e=n(IKe,"STRONG",{});var Pua=s(y9e);Ntt=r(Pua,"longformer"),Pua.forEach(t),qtt=r(IKe," \u2014 "),yne=n(IKe,"A",{href:!0});var Bua=s(yne);jtt=r(Bua,"TFLongformerForMultipleChoice"),Bua.forEach(t),Dtt=r(IKe," (Longformer model)"),IKe.forEach(t),Gtt=i(Te),n6=n(Te,"LI",{});var NKe=s(n6);x9e=n(NKe,"STRONG",{});var Iua=s(x9e);Ott=r(Iua,"mobilebert"),Iua.forEach(t),Vtt=r(NKe," \u2014 "),xne=n(NKe,"A",{href:!0});var Nua=s(xne);Xtt=r(Nua,"TFMobileBertForMultipleChoice"),Nua.forEach(t),ztt=r(NKe," (MobileBERT model)"),NKe.forEach(t),Qtt=i(Te),s6=n(Te,"LI",{});var qKe=s(s6);$9e=n(qKe,"STRONG",{});var qua=s($9e);Wtt=r(qua,"mpnet"),qua.forEach(t),Utt=r(qKe," \u2014 "),$ne=n(qKe,"A",{href:!0});var jua=s($ne);Htt=r(jua,"TFMPNetForMultipleChoice"),jua.forEach(t),Jtt=r(qKe," (MPNet model)"),qKe.forEach(t),Ytt=i(Te),l6=n(Te,"LI",{});var jKe=s(l6);k9e=n(jKe,"STRONG",{});var Dua=s(k9e);Ztt=r(Dua,"rembert"),Dua.forEach(t),Ktt=r(jKe," \u2014 "),kne=n(jKe,"A",{href:!0});var Gua=s(kne);eat=r(Gua,"TFRemBertForMultipleChoice"),Gua.forEach(t),oat=r(jKe," (RemBERT model)"),jKe.forEach(t),rat=i(Te),i6=n(Te,"LI",{});var DKe=s(i6);S9e=n(DKe,"STRONG",{});var Oua=s(S9e);tat=r(Oua,"roberta"),Oua.forEach(t),aat=r(DKe," \u2014 "),Sne=n(DKe,"A",{href:!0});var Vua=s(Sne);nat=r(Vua,"TFRobertaForMultipleChoice"),Vua.forEach(t),sat=r(DKe," (RoBERTa model)"),DKe.forEach(t),lat=i(Te),d6=n(Te,"LI",{});var GKe=s(d6);R9e=n(GKe,"STRONG",{});var Xua=s(R9e);iat=r(Xua,"roformer"),Xua.forEach(t),dat=r(GKe," \u2014 "),Rne=n(GKe,"A",{href:!0});var zua=s(Rne);cat=r(zua,"TFRoFormerForMultipleChoice"),zua.forEach(t),mat=r(GKe," (RoFormer model)"),GKe.forEach(t),fat=i(Te),c6=n(Te,"LI",{});var OKe=s(c6);P9e=n(OKe,"STRONG",{});var Qua=s(P9e);gat=r(Qua,"xlm"),Qua.forEach(t),hat=r(OKe," \u2014 "),Pne=n(OKe,"A",{href:!0});var Wua=s(Pne);uat=r(Wua,"TFXLMForMultipleChoice"),Wua.forEach(t),pat=r(OKe," (XLM model)"),OKe.forEach(t),_at=i(Te),m6=n(Te,"LI",{});var VKe=s(m6);B9e=n(VKe,"STRONG",{});var Uua=s(B9e);bat=r(Uua,"xlm-roberta"),Uua.forEach(t),vat=r(VKe," \u2014 "),Bne=n(VKe,"A",{href:!0});var Hua=s(Bne);Fat=r(Hua,"TFXLMRobertaForMultipleChoice"),Hua.forEach(t),Tat=r(VKe," (XLM-RoBERTa model)"),VKe.forEach(t),Mat=i(Te),f6=n(Te,"LI",{});var XKe=s(f6);I9e=n(XKe,"STRONG",{});var Jua=s(I9e);Eat=r(Jua,"xlnet"),Jua.forEach(t),Cat=r(XKe," \u2014 "),Ine=n(XKe,"A",{href:!0});var Yua=s(Ine);wat=r(Yua,"TFXLNetForMultipleChoice"),Yua.forEach(t),Aat=r(XKe," (XLNet model)"),XKe.forEach(t),Te.forEach(t),Lat=i(ki),T(g6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),Tao=i(m),Im=n(m,"H2",{class:!0});var Dso=s(Im);h6=n(Dso,"A",{id:!0,class:!0,href:!0});var Zua=s(h6);N9e=n(Zua,"SPAN",{});var Kua=s(N9e);T(JR.$$.fragment,Kua),Kua.forEach(t),Zua.forEach(t),yat=i(Dso),q9e=n(Dso,"SPAN",{});var epa=s(q9e);xat=r(epa,"TFAutoModelForNextSentencePrediction"),epa.forEach(t),Dso.forEach(t),Mao=i(m),vr=n(m,"DIV",{class:!0});var Si=s(vr);T(YR.$$.fragment,Si),$at=i(Si),Nm=n(Si,"P",{});var lme=s(Nm);kat=r(lme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Nne=n(lme,"A",{href:!0});var opa=s(Nne);Sat=r(opa,"from_pretrained()"),opa.forEach(t),Rat=r(lme," class method or the "),qne=n(lme,"A",{href:!0});var rpa=s(qne);Pat=r(rpa,"from_config()"),rpa.forEach(t),Bat=r(lme,` class
method.`),lme.forEach(t),Iat=i(Si),ZR=n(Si,"P",{});var Gso=s(ZR);Nat=r(Gso,"This class cannot be instantiated directly using "),j9e=n(Gso,"CODE",{});var tpa=s(j9e);qat=r(tpa,"__init__()"),tpa.forEach(t),jat=r(Gso," (throws an error)."),Gso.forEach(t),Dat=i(Si),na=n(Si,"DIV",{class:!0});var fx=s(na);T(KR.$$.fragment,fx),Gat=i(fx),D9e=n(fx,"P",{});var apa=s(D9e);Oat=r(apa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),apa.forEach(t),Vat=i(fx),qm=n(fx,"P",{});var ime=s(qm);Xat=r(ime,`Note:
Loading a model from its configuration file does `),G9e=n(ime,"STRONG",{});var npa=s(G9e);zat=r(npa,"not"),npa.forEach(t),Qat=r(ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),jne=n(ime,"A",{href:!0});var spa=s(jne);Wat=r(spa,"from_pretrained()"),spa.forEach(t),Uat=r(ime," to load the model weights."),ime.forEach(t),Hat=i(fx),T(u6.$$.fragment,fx),fx.forEach(t),Jat=i(Si),Hr=n(Si,"DIV",{class:!0});var Ri=s(Hr);T(eP.$$.fragment,Ri),Yat=i(Ri),O9e=n(Ri,"P",{});var lpa=s(O9e);Zat=r(lpa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lpa.forEach(t),Kat=i(Ri),Xn=n(Ri,"P",{});var gx=s(Xn);ent=r(gx,"The model class to instantiate is selected based on the "),V9e=n(gx,"CODE",{});var ipa=s(V9e);ont=r(ipa,"model_type"),ipa.forEach(t),rnt=r(gx,` property of the config object (either
passed as an argument or loaded from `),X9e=n(gx,"CODE",{});var dpa=s(X9e);tnt=r(dpa,"pretrained_model_name_or_path"),dpa.forEach(t),ant=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=n(gx,"CODE",{});var cpa=s(z9e);nnt=r(cpa,"pretrained_model_name_or_path"),cpa.forEach(t),snt=r(gx,":"),gx.forEach(t),lnt=i(Ri),oP=n(Ri,"UL",{});var Oso=s(oP);p6=n(Oso,"LI",{});var zKe=s(p6);Q9e=n(zKe,"STRONG",{});var mpa=s(Q9e);int=r(mpa,"bert"),mpa.forEach(t),dnt=r(zKe," \u2014 "),Dne=n(zKe,"A",{href:!0});var fpa=s(Dne);cnt=r(fpa,"TFBertForNextSentencePrediction"),fpa.forEach(t),mnt=r(zKe," (BERT model)"),zKe.forEach(t),fnt=i(Oso),_6=n(Oso,"LI",{});var QKe=s(_6);W9e=n(QKe,"STRONG",{});var gpa=s(W9e);gnt=r(gpa,"mobilebert"),gpa.forEach(t),hnt=r(QKe," \u2014 "),Gne=n(QKe,"A",{href:!0});var hpa=s(Gne);unt=r(hpa,"TFMobileBertForNextSentencePrediction"),hpa.forEach(t),pnt=r(QKe," (MobileBERT model)"),QKe.forEach(t),Oso.forEach(t),_nt=i(Ri),T(b6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),Eao=i(m),jm=n(m,"H2",{class:!0});var Vso=s(jm);v6=n(Vso,"A",{id:!0,class:!0,href:!0});var upa=s(v6);U9e=n(upa,"SPAN",{});var ppa=s(U9e);T(rP.$$.fragment,ppa),ppa.forEach(t),upa.forEach(t),bnt=i(Vso),H9e=n(Vso,"SPAN",{});var _pa=s(H9e);vnt=r(_pa,"TFAutoModelForTableQuestionAnswering"),_pa.forEach(t),Vso.forEach(t),Cao=i(m),Fr=n(m,"DIV",{class:!0});var Pi=s(Fr);T(tP.$$.fragment,Pi),Fnt=i(Pi),Dm=n(Pi,"P",{});var dme=s(Dm);Tnt=r(dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),One=n(dme,"A",{href:!0});var bpa=s(One);Mnt=r(bpa,"from_pretrained()"),bpa.forEach(t),Ent=r(dme," class method or the "),Vne=n(dme,"A",{href:!0});var vpa=s(Vne);Cnt=r(vpa,"from_config()"),vpa.forEach(t),wnt=r(dme,` class
method.`),dme.forEach(t),Ant=i(Pi),aP=n(Pi,"P",{});var Xso=s(aP);Lnt=r(Xso,"This class cannot be instantiated directly using "),J9e=n(Xso,"CODE",{});var Fpa=s(J9e);ynt=r(Fpa,"__init__()"),Fpa.forEach(t),xnt=r(Xso," (throws an error)."),Xso.forEach(t),$nt=i(Pi),sa=n(Pi,"DIV",{class:!0});var hx=s(sa);T(nP.$$.fragment,hx),knt=i(hx),Y9e=n(hx,"P",{});var Tpa=s(Y9e);Snt=r(Tpa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Tpa.forEach(t),Rnt=i(hx),Gm=n(hx,"P",{});var cme=s(Gm);Pnt=r(cme,`Note:
Loading a model from its configuration file does `),Z9e=n(cme,"STRONG",{});var Mpa=s(Z9e);Bnt=r(Mpa,"not"),Mpa.forEach(t),Int=r(cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xne=n(cme,"A",{href:!0});var Epa=s(Xne);Nnt=r(Epa,"from_pretrained()"),Epa.forEach(t),qnt=r(cme," to load the model weights."),cme.forEach(t),jnt=i(hx),T(F6.$$.fragment,hx),hx.forEach(t),Dnt=i(Pi),Jr=n(Pi,"DIV",{class:!0});var Bi=s(Jr);T(sP.$$.fragment,Bi),Gnt=i(Bi),K9e=n(Bi,"P",{});var Cpa=s(K9e);Ont=r(Cpa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Cpa.forEach(t),Vnt=i(Bi),zn=n(Bi,"P",{});var ux=s(zn);Xnt=r(ux,"The model class to instantiate is selected based on the "),exe=n(ux,"CODE",{});var wpa=s(exe);znt=r(wpa,"model_type"),wpa.forEach(t),Qnt=r(ux,` property of the config object (either
passed as an argument or loaded from `),oxe=n(ux,"CODE",{});var Apa=s(oxe);Wnt=r(Apa,"pretrained_model_name_or_path"),Apa.forEach(t),Unt=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rxe=n(ux,"CODE",{});var Lpa=s(rxe);Hnt=r(Lpa,"pretrained_model_name_or_path"),Lpa.forEach(t),Jnt=r(ux,":"),ux.forEach(t),Ynt=i(Bi),txe=n(Bi,"UL",{});var ypa=s(txe);T6=n(ypa,"LI",{});var WKe=s(T6);axe=n(WKe,"STRONG",{});var xpa=s(axe);Znt=r(xpa,"tapas"),xpa.forEach(t),Knt=r(WKe," \u2014 "),zne=n(WKe,"A",{href:!0});var $pa=s(zne);est=r($pa,"TFTapasForQuestionAnswering"),$pa.forEach(t),ost=r(WKe," (TAPAS model)"),WKe.forEach(t),ypa.forEach(t),rst=i(Bi),T(M6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),wao=i(m),Om=n(m,"H2",{class:!0});var zso=s(Om);E6=n(zso,"A",{id:!0,class:!0,href:!0});var kpa=s(E6);nxe=n(kpa,"SPAN",{});var Spa=s(nxe);T(lP.$$.fragment,Spa),Spa.forEach(t),kpa.forEach(t),tst=i(zso),sxe=n(zso,"SPAN",{});var Rpa=s(sxe);ast=r(Rpa,"TFAutoModelForDocumentQuestionAnswering"),Rpa.forEach(t),zso.forEach(t),Aao=i(m),Tr=n(m,"DIV",{class:!0});var Ii=s(Tr);T(iP.$$.fragment,Ii),nst=i(Ii),Vm=n(Ii,"P",{});var mme=s(Vm);sst=r(mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Qne=n(mme,"A",{href:!0});var Ppa=s(Qne);lst=r(Ppa,"from_pretrained()"),Ppa.forEach(t),ist=r(mme," class method or the "),Wne=n(mme,"A",{href:!0});var Bpa=s(Wne);dst=r(Bpa,"from_config()"),Bpa.forEach(t),cst=r(mme,` class
method.`),mme.forEach(t),mst=i(Ii),dP=n(Ii,"P",{});var Qso=s(dP);fst=r(Qso,"This class cannot be instantiated directly using "),lxe=n(Qso,"CODE",{});var Ipa=s(lxe);gst=r(Ipa,"__init__()"),Ipa.forEach(t),hst=r(Qso," (throws an error)."),Qso.forEach(t),ust=i(Ii),la=n(Ii,"DIV",{class:!0});var px=s(la);T(cP.$$.fragment,px),pst=i(px),ixe=n(px,"P",{});var Npa=s(ixe);_st=r(Npa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Npa.forEach(t),bst=i(px),Xm=n(px,"P",{});var fme=s(Xm);vst=r(fme,`Note:
Loading a model from its configuration file does `),dxe=n(fme,"STRONG",{});var qpa=s(dxe);Fst=r(qpa,"not"),qpa.forEach(t),Tst=r(fme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=n(fme,"A",{href:!0});var jpa=s(Une);Mst=r(jpa,"from_pretrained()"),jpa.forEach(t),Est=r(fme," to load the model weights."),fme.forEach(t),Cst=i(px),T(C6.$$.fragment,px),px.forEach(t),wst=i(Ii),Yr=n(Ii,"DIV",{class:!0});var Ni=s(Yr);T(mP.$$.fragment,Ni),Ast=i(Ni),cxe=n(Ni,"P",{});var Dpa=s(cxe);Lst=r(Dpa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Dpa.forEach(t),yst=i(Ni),Qn=n(Ni,"P",{});var _x=s(Qn);xst=r(_x,"The model class to instantiate is selected based on the "),mxe=n(_x,"CODE",{});var Gpa=s(mxe);$st=r(Gpa,"model_type"),Gpa.forEach(t),kst=r(_x,` property of the config object (either
passed as an argument or loaded from `),fxe=n(_x,"CODE",{});var Opa=s(fxe);Sst=r(Opa,"pretrained_model_name_or_path"),Opa.forEach(t),Rst=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gxe=n(_x,"CODE",{});var Vpa=s(gxe);Pst=r(Vpa,"pretrained_model_name_or_path"),Vpa.forEach(t),Bst=r(_x,":"),_x.forEach(t),Ist=i(Ni),hxe=n(Ni,"UL",{});var Xpa=s(hxe);w6=n(Xpa,"LI",{});var UKe=s(w6);uxe=n(UKe,"STRONG",{});var zpa=s(uxe);Nst=r(zpa,"layoutlm"),zpa.forEach(t),qst=r(UKe," \u2014 "),Hne=n(UKe,"A",{href:!0});var Qpa=s(Hne);jst=r(Qpa,"TFLayoutLMForQuestionAnswering"),Qpa.forEach(t),Dst=r(UKe," (LayoutLM model)"),UKe.forEach(t),Xpa.forEach(t),Gst=i(Ni),T(A6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),Lao=i(m),zm=n(m,"H2",{class:!0});var Wso=s(zm);L6=n(Wso,"A",{id:!0,class:!0,href:!0});var Wpa=s(L6);pxe=n(Wpa,"SPAN",{});var Upa=s(pxe);T(fP.$$.fragment,Upa),Upa.forEach(t),Wpa.forEach(t),Ost=i(Wso),_xe=n(Wso,"SPAN",{});var Hpa=s(_xe);Vst=r(Hpa,"TFAutoModelForTokenClassification"),Hpa.forEach(t),Wso.forEach(t),yao=i(m),Mr=n(m,"DIV",{class:!0});var qi=s(Mr);T(gP.$$.fragment,qi),Xst=i(qi),Qm=n(qi,"P",{});var gme=s(Qm);zst=r(gme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Jne=n(gme,"A",{href:!0});var Jpa=s(Jne);Qst=r(Jpa,"from_pretrained()"),Jpa.forEach(t),Wst=r(gme," class method or the "),Yne=n(gme,"A",{href:!0});var Ypa=s(Yne);Ust=r(Ypa,"from_config()"),Ypa.forEach(t),Hst=r(gme,` class
method.`),gme.forEach(t),Jst=i(qi),hP=n(qi,"P",{});var Uso=s(hP);Yst=r(Uso,"This class cannot be instantiated directly using "),bxe=n(Uso,"CODE",{});var Zpa=s(bxe);Zst=r(Zpa,"__init__()"),Zpa.forEach(t),Kst=r(Uso," (throws an error)."),Uso.forEach(t),elt=i(qi),ia=n(qi,"DIV",{class:!0});var bx=s(ia);T(uP.$$.fragment,bx),olt=i(bx),vxe=n(bx,"P",{});var Kpa=s(vxe);rlt=r(Kpa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Kpa.forEach(t),tlt=i(bx),Wm=n(bx,"P",{});var hme=s(Wm);alt=r(hme,`Note:
Loading a model from its configuration file does `),Fxe=n(hme,"STRONG",{});var e_a=s(Fxe);nlt=r(e_a,"not"),e_a.forEach(t),slt=r(hme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zne=n(hme,"A",{href:!0});var o_a=s(Zne);llt=r(o_a,"from_pretrained()"),o_a.forEach(t),ilt=r(hme," to load the model weights."),hme.forEach(t),dlt=i(bx),T(y6.$$.fragment,bx),bx.forEach(t),clt=i(qi),Zr=n(qi,"DIV",{class:!0});var ji=s(Zr);T(pP.$$.fragment,ji),mlt=i(ji),Txe=n(ji,"P",{});var r_a=s(Txe);flt=r(r_a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),r_a.forEach(t),glt=i(ji),Wn=n(ji,"P",{});var vx=s(Wn);hlt=r(vx,"The model class to instantiate is selected based on the "),Mxe=n(vx,"CODE",{});var t_a=s(Mxe);ult=r(t_a,"model_type"),t_a.forEach(t),plt=r(vx,` property of the config object (either
passed as an argument or loaded from `),Exe=n(vx,"CODE",{});var a_a=s(Exe);_lt=r(a_a,"pretrained_model_name_or_path"),a_a.forEach(t),blt=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cxe=n(vx,"CODE",{});var n_a=s(Cxe);vlt=r(n_a,"pretrained_model_name_or_path"),n_a.forEach(t),Flt=r(vx,":"),vx.forEach(t),Tlt=i(ji),ce=n(ji,"UL",{});var he=s(ce);x6=n(he,"LI",{});var HKe=s(x6);wxe=n(HKe,"STRONG",{});var s_a=s(wxe);Mlt=r(s_a,"albert"),s_a.forEach(t),Elt=r(HKe," \u2014 "),Kne=n(HKe,"A",{href:!0});var l_a=s(Kne);Clt=r(l_a,"TFAlbertForTokenClassification"),l_a.forEach(t),wlt=r(HKe," (ALBERT model)"),HKe.forEach(t),Alt=i(he),$6=n(he,"LI",{});var JKe=s($6);Axe=n(JKe,"STRONG",{});var i_a=s(Axe);Llt=r(i_a,"bert"),i_a.forEach(t),ylt=r(JKe," \u2014 "),ese=n(JKe,"A",{href:!0});var d_a=s(ese);xlt=r(d_a,"TFBertForTokenClassification"),d_a.forEach(t),$lt=r(JKe," (BERT model)"),JKe.forEach(t),klt=i(he),k6=n(he,"LI",{});var YKe=s(k6);Lxe=n(YKe,"STRONG",{});var c_a=s(Lxe);Slt=r(c_a,"camembert"),c_a.forEach(t),Rlt=r(YKe," \u2014 "),ose=n(YKe,"A",{href:!0});var m_a=s(ose);Plt=r(m_a,"TFCamembertForTokenClassification"),m_a.forEach(t),Blt=r(YKe," (CamemBERT model)"),YKe.forEach(t),Ilt=i(he),S6=n(he,"LI",{});var ZKe=s(S6);yxe=n(ZKe,"STRONG",{});var f_a=s(yxe);Nlt=r(f_a,"convbert"),f_a.forEach(t),qlt=r(ZKe," \u2014 "),rse=n(ZKe,"A",{href:!0});var g_a=s(rse);jlt=r(g_a,"TFConvBertForTokenClassification"),g_a.forEach(t),Dlt=r(ZKe," (ConvBERT model)"),ZKe.forEach(t),Glt=i(he),R6=n(he,"LI",{});var KKe=s(R6);xxe=n(KKe,"STRONG",{});var h_a=s(xxe);Olt=r(h_a,"deberta"),h_a.forEach(t),Vlt=r(KKe," \u2014 "),tse=n(KKe,"A",{href:!0});var u_a=s(tse);Xlt=r(u_a,"TFDebertaForTokenClassification"),u_a.forEach(t),zlt=r(KKe," (DeBERTa model)"),KKe.forEach(t),Qlt=i(he),P6=n(he,"LI",{});var eeo=s(P6);$xe=n(eeo,"STRONG",{});var p_a=s($xe);Wlt=r(p_a,"deberta-v2"),p_a.forEach(t),Ult=r(eeo," \u2014 "),ase=n(eeo,"A",{href:!0});var __a=s(ase);Hlt=r(__a,"TFDebertaV2ForTokenClassification"),__a.forEach(t),Jlt=r(eeo," (DeBERTa-v2 model)"),eeo.forEach(t),Ylt=i(he),B6=n(he,"LI",{});var oeo=s(B6);kxe=n(oeo,"STRONG",{});var b_a=s(kxe);Zlt=r(b_a,"distilbert"),b_a.forEach(t),Klt=r(oeo," \u2014 "),nse=n(oeo,"A",{href:!0});var v_a=s(nse);eit=r(v_a,"TFDistilBertForTokenClassification"),v_a.forEach(t),oit=r(oeo," (DistilBERT model)"),oeo.forEach(t),rit=i(he),I6=n(he,"LI",{});var reo=s(I6);Sxe=n(reo,"STRONG",{});var F_a=s(Sxe);tit=r(F_a,"electra"),F_a.forEach(t),ait=r(reo," \u2014 "),sse=n(reo,"A",{href:!0});var T_a=s(sse);nit=r(T_a,"TFElectraForTokenClassification"),T_a.forEach(t),sit=r(reo," (ELECTRA model)"),reo.forEach(t),lit=i(he),N6=n(he,"LI",{});var teo=s(N6);Rxe=n(teo,"STRONG",{});var M_a=s(Rxe);iit=r(M_a,"flaubert"),M_a.forEach(t),dit=r(teo," \u2014 "),lse=n(teo,"A",{href:!0});var E_a=s(lse);cit=r(E_a,"TFFlaubertForTokenClassification"),E_a.forEach(t),mit=r(teo," (FlauBERT model)"),teo.forEach(t),fit=i(he),q6=n(he,"LI",{});var aeo=s(q6);Pxe=n(aeo,"STRONG",{});var C_a=s(Pxe);git=r(C_a,"funnel"),C_a.forEach(t),hit=r(aeo," \u2014 "),ise=n(aeo,"A",{href:!0});var w_a=s(ise);uit=r(w_a,"TFFunnelForTokenClassification"),w_a.forEach(t),pit=r(aeo," (Funnel Transformer model)"),aeo.forEach(t),_it=i(he),j6=n(he,"LI",{});var neo=s(j6);Bxe=n(neo,"STRONG",{});var A_a=s(Bxe);bit=r(A_a,"layoutlm"),A_a.forEach(t),vit=r(neo," \u2014 "),dse=n(neo,"A",{href:!0});var L_a=s(dse);Fit=r(L_a,"TFLayoutLMForTokenClassification"),L_a.forEach(t),Tit=r(neo," (LayoutLM model)"),neo.forEach(t),Mit=i(he),D6=n(he,"LI",{});var seo=s(D6);Ixe=n(seo,"STRONG",{});var y_a=s(Ixe);Eit=r(y_a,"layoutlmv3"),y_a.forEach(t),Cit=r(seo," \u2014 "),cse=n(seo,"A",{href:!0});var x_a=s(cse);wit=r(x_a,"TFLayoutLMv3ForTokenClassification"),x_a.forEach(t),Ait=r(seo," (LayoutLMv3 model)"),seo.forEach(t),Lit=i(he),G6=n(he,"LI",{});var leo=s(G6);Nxe=n(leo,"STRONG",{});var $_a=s(Nxe);yit=r($_a,"longformer"),$_a.forEach(t),xit=r(leo," \u2014 "),mse=n(leo,"A",{href:!0});var k_a=s(mse);$it=r(k_a,"TFLongformerForTokenClassification"),k_a.forEach(t),kit=r(leo," (Longformer model)"),leo.forEach(t),Sit=i(he),O6=n(he,"LI",{});var ieo=s(O6);qxe=n(ieo,"STRONG",{});var S_a=s(qxe);Rit=r(S_a,"mobilebert"),S_a.forEach(t),Pit=r(ieo," \u2014 "),fse=n(ieo,"A",{href:!0});var R_a=s(fse);Bit=r(R_a,"TFMobileBertForTokenClassification"),R_a.forEach(t),Iit=r(ieo," (MobileBERT model)"),ieo.forEach(t),Nit=i(he),V6=n(he,"LI",{});var deo=s(V6);jxe=n(deo,"STRONG",{});var P_a=s(jxe);qit=r(P_a,"mpnet"),P_a.forEach(t),jit=r(deo," \u2014 "),gse=n(deo,"A",{href:!0});var B_a=s(gse);Dit=r(B_a,"TFMPNetForTokenClassification"),B_a.forEach(t),Git=r(deo," (MPNet model)"),deo.forEach(t),Oit=i(he),X6=n(he,"LI",{});var ceo=s(X6);Dxe=n(ceo,"STRONG",{});var I_a=s(Dxe);Vit=r(I_a,"rembert"),I_a.forEach(t),Xit=r(ceo," \u2014 "),hse=n(ceo,"A",{href:!0});var N_a=s(hse);zit=r(N_a,"TFRemBertForTokenClassification"),N_a.forEach(t),Qit=r(ceo," (RemBERT model)"),ceo.forEach(t),Wit=i(he),z6=n(he,"LI",{});var meo=s(z6);Gxe=n(meo,"STRONG",{});var q_a=s(Gxe);Uit=r(q_a,"roberta"),q_a.forEach(t),Hit=r(meo," \u2014 "),use=n(meo,"A",{href:!0});var j_a=s(use);Jit=r(j_a,"TFRobertaForTokenClassification"),j_a.forEach(t),Yit=r(meo," (RoBERTa model)"),meo.forEach(t),Zit=i(he),Q6=n(he,"LI",{});var feo=s(Q6);Oxe=n(feo,"STRONG",{});var D_a=s(Oxe);Kit=r(D_a,"roformer"),D_a.forEach(t),edt=r(feo," \u2014 "),pse=n(feo,"A",{href:!0});var G_a=s(pse);odt=r(G_a,"TFRoFormerForTokenClassification"),G_a.forEach(t),rdt=r(feo," (RoFormer model)"),feo.forEach(t),tdt=i(he),W6=n(he,"LI",{});var geo=s(W6);Vxe=n(geo,"STRONG",{});var O_a=s(Vxe);adt=r(O_a,"xlm"),O_a.forEach(t),ndt=r(geo," \u2014 "),_se=n(geo,"A",{href:!0});var V_a=s(_se);sdt=r(V_a,"TFXLMForTokenClassification"),V_a.forEach(t),ldt=r(geo," (XLM model)"),geo.forEach(t),idt=i(he),U6=n(he,"LI",{});var heo=s(U6);Xxe=n(heo,"STRONG",{});var X_a=s(Xxe);ddt=r(X_a,"xlm-roberta"),X_a.forEach(t),cdt=r(heo," \u2014 "),bse=n(heo,"A",{href:!0});var z_a=s(bse);mdt=r(z_a,"TFXLMRobertaForTokenClassification"),z_a.forEach(t),fdt=r(heo," (XLM-RoBERTa model)"),heo.forEach(t),gdt=i(he),H6=n(he,"LI",{});var ueo=s(H6);zxe=n(ueo,"STRONG",{});var Q_a=s(zxe);hdt=r(Q_a,"xlnet"),Q_a.forEach(t),udt=r(ueo," \u2014 "),vse=n(ueo,"A",{href:!0});var W_a=s(vse);pdt=r(W_a,"TFXLNetForTokenClassification"),W_a.forEach(t),_dt=r(ueo," (XLNet model)"),ueo.forEach(t),he.forEach(t),bdt=i(ji),T(J6.$$.fragment,ji),ji.forEach(t),qi.forEach(t),xao=i(m),Um=n(m,"H2",{class:!0});var Hso=s(Um);Y6=n(Hso,"A",{id:!0,class:!0,href:!0});var U_a=s(Y6);Qxe=n(U_a,"SPAN",{});var H_a=s(Qxe);T(_P.$$.fragment,H_a),H_a.forEach(t),U_a.forEach(t),vdt=i(Hso),Wxe=n(Hso,"SPAN",{});var J_a=s(Wxe);Fdt=r(J_a,"TFAutoModelForQuestionAnswering"),J_a.forEach(t),Hso.forEach(t),$ao=i(m),Er=n(m,"DIV",{class:!0});var Di=s(Er);T(bP.$$.fragment,Di),Tdt=i(Di),Hm=n(Di,"P",{});var ume=s(Hm);Mdt=r(ume,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Fse=n(ume,"A",{href:!0});var Y_a=s(Fse);Edt=r(Y_a,"from_pretrained()"),Y_a.forEach(t),Cdt=r(ume," class method or the "),Tse=n(ume,"A",{href:!0});var Z_a=s(Tse);wdt=r(Z_a,"from_config()"),Z_a.forEach(t),Adt=r(ume,` class
method.`),ume.forEach(t),Ldt=i(Di),vP=n(Di,"P",{});var Jso=s(vP);ydt=r(Jso,"This class cannot be instantiated directly using "),Uxe=n(Jso,"CODE",{});var K_a=s(Uxe);xdt=r(K_a,"__init__()"),K_a.forEach(t),$dt=r(Jso," (throws an error)."),Jso.forEach(t),kdt=i(Di),da=n(Di,"DIV",{class:!0});var Fx=s(da);T(FP.$$.fragment,Fx),Sdt=i(Fx),Hxe=n(Fx,"P",{});var e1a=s(Hxe);Rdt=r(e1a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),e1a.forEach(t),Pdt=i(Fx),Jm=n(Fx,"P",{});var pme=s(Jm);Bdt=r(pme,`Note:
Loading a model from its configuration file does `),Jxe=n(pme,"STRONG",{});var o1a=s(Jxe);Idt=r(o1a,"not"),o1a.forEach(t),Ndt=r(pme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mse=n(pme,"A",{href:!0});var r1a=s(Mse);qdt=r(r1a,"from_pretrained()"),r1a.forEach(t),jdt=r(pme," to load the model weights."),pme.forEach(t),Ddt=i(Fx),T(Z6.$$.fragment,Fx),Fx.forEach(t),Gdt=i(Di),Kr=n(Di,"DIV",{class:!0});var Gi=s(Kr);T(TP.$$.fragment,Gi),Odt=i(Gi),Yxe=n(Gi,"P",{});var t1a=s(Yxe);Vdt=r(t1a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),t1a.forEach(t),Xdt=i(Gi),Un=n(Gi,"P",{});var Tx=s(Un);zdt=r(Tx,"The model class to instantiate is selected based on the "),Zxe=n(Tx,"CODE",{});var a1a=s(Zxe);Qdt=r(a1a,"model_type"),a1a.forEach(t),Wdt=r(Tx,` property of the config object (either
passed as an argument or loaded from `),Kxe=n(Tx,"CODE",{});var n1a=s(Kxe);Udt=r(n1a,"pretrained_model_name_or_path"),n1a.forEach(t),Hdt=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e$e=n(Tx,"CODE",{});var s1a=s(e$e);Jdt=r(s1a,"pretrained_model_name_or_path"),s1a.forEach(t),Ydt=r(Tx,":"),Tx.forEach(t),Zdt=i(Gi),me=n(Gi,"UL",{});var ue=s(me);K6=n(ue,"LI",{});var peo=s(K6);o$e=n(peo,"STRONG",{});var l1a=s(o$e);Kdt=r(l1a,"albert"),l1a.forEach(t),ect=r(peo," \u2014 "),Ese=n(peo,"A",{href:!0});var i1a=s(Ese);oct=r(i1a,"TFAlbertForQuestionAnswering"),i1a.forEach(t),rct=r(peo," (ALBERT model)"),peo.forEach(t),tct=i(ue),e7=n(ue,"LI",{});var _eo=s(e7);r$e=n(_eo,"STRONG",{});var d1a=s(r$e);act=r(d1a,"bert"),d1a.forEach(t),nct=r(_eo," \u2014 "),Cse=n(_eo,"A",{href:!0});var c1a=s(Cse);sct=r(c1a,"TFBertForQuestionAnswering"),c1a.forEach(t),lct=r(_eo," (BERT model)"),_eo.forEach(t),ict=i(ue),o7=n(ue,"LI",{});var beo=s(o7);t$e=n(beo,"STRONG",{});var m1a=s(t$e);dct=r(m1a,"camembert"),m1a.forEach(t),cct=r(beo," \u2014 "),wse=n(beo,"A",{href:!0});var f1a=s(wse);mct=r(f1a,"TFCamembertForQuestionAnswering"),f1a.forEach(t),fct=r(beo," (CamemBERT model)"),beo.forEach(t),gct=i(ue),r7=n(ue,"LI",{});var veo=s(r7);a$e=n(veo,"STRONG",{});var g1a=s(a$e);hct=r(g1a,"convbert"),g1a.forEach(t),uct=r(veo," \u2014 "),Ase=n(veo,"A",{href:!0});var h1a=s(Ase);pct=r(h1a,"TFConvBertForQuestionAnswering"),h1a.forEach(t),_ct=r(veo," (ConvBERT model)"),veo.forEach(t),bct=i(ue),t7=n(ue,"LI",{});var Feo=s(t7);n$e=n(Feo,"STRONG",{});var u1a=s(n$e);vct=r(u1a,"deberta"),u1a.forEach(t),Fct=r(Feo," \u2014 "),Lse=n(Feo,"A",{href:!0});var p1a=s(Lse);Tct=r(p1a,"TFDebertaForQuestionAnswering"),p1a.forEach(t),Mct=r(Feo," (DeBERTa model)"),Feo.forEach(t),Ect=i(ue),a7=n(ue,"LI",{});var Teo=s(a7);s$e=n(Teo,"STRONG",{});var _1a=s(s$e);Cct=r(_1a,"deberta-v2"),_1a.forEach(t),wct=r(Teo," \u2014 "),yse=n(Teo,"A",{href:!0});var b1a=s(yse);Act=r(b1a,"TFDebertaV2ForQuestionAnswering"),b1a.forEach(t),Lct=r(Teo," (DeBERTa-v2 model)"),Teo.forEach(t),yct=i(ue),n7=n(ue,"LI",{});var Meo=s(n7);l$e=n(Meo,"STRONG",{});var v1a=s(l$e);xct=r(v1a,"distilbert"),v1a.forEach(t),$ct=r(Meo," \u2014 "),xse=n(Meo,"A",{href:!0});var F1a=s(xse);kct=r(F1a,"TFDistilBertForQuestionAnswering"),F1a.forEach(t),Sct=r(Meo," (DistilBERT model)"),Meo.forEach(t),Rct=i(ue),s7=n(ue,"LI",{});var Eeo=s(s7);i$e=n(Eeo,"STRONG",{});var T1a=s(i$e);Pct=r(T1a,"electra"),T1a.forEach(t),Bct=r(Eeo," \u2014 "),$se=n(Eeo,"A",{href:!0});var M1a=s($se);Ict=r(M1a,"TFElectraForQuestionAnswering"),M1a.forEach(t),Nct=r(Eeo," (ELECTRA model)"),Eeo.forEach(t),qct=i(ue),l7=n(ue,"LI",{});var Ceo=s(l7);d$e=n(Ceo,"STRONG",{});var E1a=s(d$e);jct=r(E1a,"flaubert"),E1a.forEach(t),Dct=r(Ceo," \u2014 "),kse=n(Ceo,"A",{href:!0});var C1a=s(kse);Gct=r(C1a,"TFFlaubertForQuestionAnsweringSimple"),C1a.forEach(t),Oct=r(Ceo," (FlauBERT model)"),Ceo.forEach(t),Vct=i(ue),i7=n(ue,"LI",{});var weo=s(i7);c$e=n(weo,"STRONG",{});var w1a=s(c$e);Xct=r(w1a,"funnel"),w1a.forEach(t),zct=r(weo," \u2014 "),Sse=n(weo,"A",{href:!0});var A1a=s(Sse);Qct=r(A1a,"TFFunnelForQuestionAnswering"),A1a.forEach(t),Wct=r(weo," (Funnel Transformer model)"),weo.forEach(t),Uct=i(ue),d7=n(ue,"LI",{});var Aeo=s(d7);m$e=n(Aeo,"STRONG",{});var L1a=s(m$e);Hct=r(L1a,"gptj"),L1a.forEach(t),Jct=r(Aeo," \u2014 "),Rse=n(Aeo,"A",{href:!0});var y1a=s(Rse);Yct=r(y1a,"TFGPTJForQuestionAnswering"),y1a.forEach(t),Zct=r(Aeo," (GPT-J model)"),Aeo.forEach(t),Kct=i(ue),c7=n(ue,"LI",{});var Leo=s(c7);f$e=n(Leo,"STRONG",{});var x1a=s(f$e);emt=r(x1a,"layoutlmv3"),x1a.forEach(t),omt=r(Leo," \u2014 "),Pse=n(Leo,"A",{href:!0});var $1a=s(Pse);rmt=r($1a,"TFLayoutLMv3ForQuestionAnswering"),$1a.forEach(t),tmt=r(Leo," (LayoutLMv3 model)"),Leo.forEach(t),amt=i(ue),m7=n(ue,"LI",{});var yeo=s(m7);g$e=n(yeo,"STRONG",{});var k1a=s(g$e);nmt=r(k1a,"longformer"),k1a.forEach(t),smt=r(yeo," \u2014 "),Bse=n(yeo,"A",{href:!0});var S1a=s(Bse);lmt=r(S1a,"TFLongformerForQuestionAnswering"),S1a.forEach(t),imt=r(yeo," (Longformer model)"),yeo.forEach(t),dmt=i(ue),f7=n(ue,"LI",{});var xeo=s(f7);h$e=n(xeo,"STRONG",{});var R1a=s(h$e);cmt=r(R1a,"mobilebert"),R1a.forEach(t),mmt=r(xeo," \u2014 "),Ise=n(xeo,"A",{href:!0});var P1a=s(Ise);fmt=r(P1a,"TFMobileBertForQuestionAnswering"),P1a.forEach(t),gmt=r(xeo," (MobileBERT model)"),xeo.forEach(t),hmt=i(ue),g7=n(ue,"LI",{});var $eo=s(g7);u$e=n($eo,"STRONG",{});var B1a=s(u$e);umt=r(B1a,"mpnet"),B1a.forEach(t),pmt=r($eo," \u2014 "),Nse=n($eo,"A",{href:!0});var I1a=s(Nse);_mt=r(I1a,"TFMPNetForQuestionAnswering"),I1a.forEach(t),bmt=r($eo," (MPNet model)"),$eo.forEach(t),vmt=i(ue),h7=n(ue,"LI",{});var keo=s(h7);p$e=n(keo,"STRONG",{});var N1a=s(p$e);Fmt=r(N1a,"rembert"),N1a.forEach(t),Tmt=r(keo," \u2014 "),qse=n(keo,"A",{href:!0});var q1a=s(qse);Mmt=r(q1a,"TFRemBertForQuestionAnswering"),q1a.forEach(t),Emt=r(keo," (RemBERT model)"),keo.forEach(t),Cmt=i(ue),u7=n(ue,"LI",{});var Seo=s(u7);_$e=n(Seo,"STRONG",{});var j1a=s(_$e);wmt=r(j1a,"roberta"),j1a.forEach(t),Amt=r(Seo," \u2014 "),jse=n(Seo,"A",{href:!0});var D1a=s(jse);Lmt=r(D1a,"TFRobertaForQuestionAnswering"),D1a.forEach(t),ymt=r(Seo," (RoBERTa model)"),Seo.forEach(t),xmt=i(ue),p7=n(ue,"LI",{});var Reo=s(p7);b$e=n(Reo,"STRONG",{});var G1a=s(b$e);$mt=r(G1a,"roformer"),G1a.forEach(t),kmt=r(Reo," \u2014 "),Dse=n(Reo,"A",{href:!0});var O1a=s(Dse);Smt=r(O1a,"TFRoFormerForQuestionAnswering"),O1a.forEach(t),Rmt=r(Reo," (RoFormer model)"),Reo.forEach(t),Pmt=i(ue),_7=n(ue,"LI",{});var Peo=s(_7);v$e=n(Peo,"STRONG",{});var V1a=s(v$e);Bmt=r(V1a,"xlm"),V1a.forEach(t),Imt=r(Peo," \u2014 "),Gse=n(Peo,"A",{href:!0});var X1a=s(Gse);Nmt=r(X1a,"TFXLMForQuestionAnsweringSimple"),X1a.forEach(t),qmt=r(Peo," (XLM model)"),Peo.forEach(t),jmt=i(ue),b7=n(ue,"LI",{});var Beo=s(b7);F$e=n(Beo,"STRONG",{});var z1a=s(F$e);Dmt=r(z1a,"xlm-roberta"),z1a.forEach(t),Gmt=r(Beo," \u2014 "),Ose=n(Beo,"A",{href:!0});var Q1a=s(Ose);Omt=r(Q1a,"TFXLMRobertaForQuestionAnswering"),Q1a.forEach(t),Vmt=r(Beo," (XLM-RoBERTa model)"),Beo.forEach(t),Xmt=i(ue),v7=n(ue,"LI",{});var Ieo=s(v7);T$e=n(Ieo,"STRONG",{});var W1a=s(T$e);zmt=r(W1a,"xlnet"),W1a.forEach(t),Qmt=r(Ieo," \u2014 "),Vse=n(Ieo,"A",{href:!0});var U1a=s(Vse);Wmt=r(U1a,"TFXLNetForQuestionAnsweringSimple"),U1a.forEach(t),Umt=r(Ieo," (XLNet model)"),Ieo.forEach(t),ue.forEach(t),Hmt=i(Gi),T(F7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),kao=i(m),Ym=n(m,"H2",{class:!0});var Yso=s(Ym);T7=n(Yso,"A",{id:!0,class:!0,href:!0});var H1a=s(T7);M$e=n(H1a,"SPAN",{});var J1a=s(M$e);T(MP.$$.fragment,J1a),J1a.forEach(t),H1a.forEach(t),Jmt=i(Yso),E$e=n(Yso,"SPAN",{});var Y1a=s(E$e);Ymt=r(Y1a,"TFAutoModelForVision2Seq"),Y1a.forEach(t),Yso.forEach(t),Sao=i(m),Cr=n(m,"DIV",{class:!0});var Oi=s(Cr);T(EP.$$.fragment,Oi),Zmt=i(Oi),Zm=n(Oi,"P",{});var _me=s(Zm);Kmt=r(_me,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Xse=n(_me,"A",{href:!0});var Z1a=s(Xse);eft=r(Z1a,"from_pretrained()"),Z1a.forEach(t),oft=r(_me," class method or the "),zse=n(_me,"A",{href:!0});var K1a=s(zse);rft=r(K1a,"from_config()"),K1a.forEach(t),tft=r(_me,` class
method.`),_me.forEach(t),aft=i(Oi),CP=n(Oi,"P",{});var Zso=s(CP);nft=r(Zso,"This class cannot be instantiated directly using "),C$e=n(Zso,"CODE",{});var e2a=s(C$e);sft=r(e2a,"__init__()"),e2a.forEach(t),lft=r(Zso," (throws an error)."),Zso.forEach(t),ift=i(Oi),ca=n(Oi,"DIV",{class:!0});var Mx=s(ca);T(wP.$$.fragment,Mx),dft=i(Mx),w$e=n(Mx,"P",{});var o2a=s(w$e);cft=r(o2a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),o2a.forEach(t),mft=i(Mx),Km=n(Mx,"P",{});var bme=s(Km);fft=r(bme,`Note:
Loading a model from its configuration file does `),A$e=n(bme,"STRONG",{});var r2a=s(A$e);gft=r(r2a,"not"),r2a.forEach(t),hft=r(bme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qse=n(bme,"A",{href:!0});var t2a=s(Qse);uft=r(t2a,"from_pretrained()"),t2a.forEach(t),pft=r(bme," to load the model weights."),bme.forEach(t),_ft=i(Mx),T(M7.$$.fragment,Mx),Mx.forEach(t),bft=i(Oi),et=n(Oi,"DIV",{class:!0});var Vi=s(et);T(AP.$$.fragment,Vi),vft=i(Vi),L$e=n(Vi,"P",{});var a2a=s(L$e);Fft=r(a2a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),a2a.forEach(t),Tft=i(Vi),Hn=n(Vi,"P",{});var Ex=s(Hn);Mft=r(Ex,"The model class to instantiate is selected based on the "),y$e=n(Ex,"CODE",{});var n2a=s(y$e);Eft=r(n2a,"model_type"),n2a.forEach(t),Cft=r(Ex,` property of the config object (either
passed as an argument or loaded from `),x$e=n(Ex,"CODE",{});var s2a=s(x$e);wft=r(s2a,"pretrained_model_name_or_path"),s2a.forEach(t),Aft=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$$e=n(Ex,"CODE",{});var l2a=s($$e);Lft=r(l2a,"pretrained_model_name_or_path"),l2a.forEach(t),yft=r(Ex,":"),Ex.forEach(t),xft=i(Vi),k$e=n(Vi,"UL",{});var i2a=s(k$e);E7=n(i2a,"LI",{});var Neo=s(E7);S$e=n(Neo,"STRONG",{});var d2a=s(S$e);$ft=r(d2a,"vision-encoder-decoder"),d2a.forEach(t),kft=r(Neo," \u2014 "),Wse=n(Neo,"A",{href:!0});var c2a=s(Wse);Sft=r(c2a,"TFVisionEncoderDecoderModel"),c2a.forEach(t),Rft=r(Neo," (Vision Encoder decoder model)"),Neo.forEach(t),i2a.forEach(t),Pft=i(Vi),T(C7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),Rao=i(m),ef=n(m,"H2",{class:!0});var Kso=s(ef);w7=n(Kso,"A",{id:!0,class:!0,href:!0});var m2a=s(w7);R$e=n(m2a,"SPAN",{});var f2a=s(R$e);T(LP.$$.fragment,f2a),f2a.forEach(t),m2a.forEach(t),Bft=i(Kso),P$e=n(Kso,"SPAN",{});var g2a=s(P$e);Ift=r(g2a,"TFAutoModelForSpeechSeq2Seq"),g2a.forEach(t),Kso.forEach(t),Pao=i(m),wr=n(m,"DIV",{class:!0});var Xi=s(wr);T(yP.$$.fragment,Xi),Nft=i(Xi),of=n(Xi,"P",{});var vme=s(of);qft=r(vme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Use=n(vme,"A",{href:!0});var h2a=s(Use);jft=r(h2a,"from_pretrained()"),h2a.forEach(t),Dft=r(vme," class method or the "),Hse=n(vme,"A",{href:!0});var u2a=s(Hse);Gft=r(u2a,"from_config()"),u2a.forEach(t),Oft=r(vme,` class
method.`),vme.forEach(t),Vft=i(Xi),xP=n(Xi,"P",{});var elo=s(xP);Xft=r(elo,"This class cannot be instantiated directly using "),B$e=n(elo,"CODE",{});var p2a=s(B$e);zft=r(p2a,"__init__()"),p2a.forEach(t),Qft=r(elo," (throws an error)."),elo.forEach(t),Wft=i(Xi),ma=n(Xi,"DIV",{class:!0});var Cx=s(ma);T($P.$$.fragment,Cx),Uft=i(Cx),I$e=n(Cx,"P",{});var _2a=s(I$e);Hft=r(_2a,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),_2a.forEach(t),Jft=i(Cx),rf=n(Cx,"P",{});var Fme=s(rf);Yft=r(Fme,`Note:
Loading a model from its configuration file does `),N$e=n(Fme,"STRONG",{});var b2a=s(N$e);Zft=r(b2a,"not"),b2a.forEach(t),Kft=r(Fme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jse=n(Fme,"A",{href:!0});var v2a=s(Jse);egt=r(v2a,"from_pretrained()"),v2a.forEach(t),ogt=r(Fme," to load the model weights."),Fme.forEach(t),rgt=i(Cx),T(A7.$$.fragment,Cx),Cx.forEach(t),tgt=i(Xi),ot=n(Xi,"DIV",{class:!0});var zi=s(ot);T(kP.$$.fragment,zi),agt=i(zi),q$e=n(zi,"P",{});var F2a=s(q$e);ngt=r(F2a,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),F2a.forEach(t),sgt=i(zi),Jn=n(zi,"P",{});var wx=s(Jn);lgt=r(wx,"The model class to instantiate is selected based on the "),j$e=n(wx,"CODE",{});var T2a=s(j$e);igt=r(T2a,"model_type"),T2a.forEach(t),dgt=r(wx,` property of the config object (either
passed as an argument or loaded from `),D$e=n(wx,"CODE",{});var M2a=s(D$e);cgt=r(M2a,"pretrained_model_name_or_path"),M2a.forEach(t),mgt=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G$e=n(wx,"CODE",{});var E2a=s(G$e);fgt=r(E2a,"pretrained_model_name_or_path"),E2a.forEach(t),ggt=r(wx,":"),wx.forEach(t),hgt=i(zi),SP=n(zi,"UL",{});var olo=s(SP);L7=n(olo,"LI",{});var qeo=s(L7);O$e=n(qeo,"STRONG",{});var C2a=s(O$e);ugt=r(C2a,"speech_to_text"),C2a.forEach(t),pgt=r(qeo," \u2014 "),Yse=n(qeo,"A",{href:!0});var w2a=s(Yse);_gt=r(w2a,"TFSpeech2TextForConditionalGeneration"),w2a.forEach(t),bgt=r(qeo," (Speech2Text model)"),qeo.forEach(t),vgt=i(olo),y7=n(olo,"LI",{});var jeo=s(y7);V$e=n(jeo,"STRONG",{});var A2a=s(V$e);Fgt=r(A2a,"whisper"),A2a.forEach(t),Tgt=r(jeo," \u2014 "),Zse=n(jeo,"A",{href:!0});var L2a=s(Zse);Mgt=r(L2a,"TFWhisperForConditionalGeneration"),L2a.forEach(t),Egt=r(jeo," (Whisper model)"),jeo.forEach(t),olo.forEach(t),Cgt=i(zi),T(x7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),Bao=i(m),tf=n(m,"H2",{class:!0});var rlo=s(tf);$7=n(rlo,"A",{id:!0,class:!0,href:!0});var y2a=s($7);X$e=n(y2a,"SPAN",{});var x2a=s(X$e);T(RP.$$.fragment,x2a),x2a.forEach(t),y2a.forEach(t),wgt=i(rlo),z$e=n(rlo,"SPAN",{});var $2a=s(z$e);Agt=r($2a,"FlaxAutoModel"),$2a.forEach(t),rlo.forEach(t),Iao=i(m),Ar=n(m,"DIV",{class:!0});var Qi=s(Ar);T(PP.$$.fragment,Qi),Lgt=i(Qi),af=n(Qi,"P",{});var Tme=s(af);ygt=r(Tme,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Kse=n(Tme,"A",{href:!0});var k2a=s(Kse);xgt=r(k2a,"from_pretrained()"),k2a.forEach(t),$gt=r(Tme," class method or the "),ele=n(Tme,"A",{href:!0});var S2a=s(ele);kgt=r(S2a,"from_config()"),S2a.forEach(t),Sgt=r(Tme,` class
method.`),Tme.forEach(t),Rgt=i(Qi),BP=n(Qi,"P",{});var tlo=s(BP);Pgt=r(tlo,"This class cannot be instantiated directly using "),Q$e=n(tlo,"CODE",{});var R2a=s(Q$e);Bgt=r(R2a,"__init__()"),R2a.forEach(t),Igt=r(tlo," (throws an error)."),tlo.forEach(t),Ngt=i(Qi),fa=n(Qi,"DIV",{class:!0});var Ax=s(fa);T(IP.$$.fragment,Ax),qgt=i(Ax),W$e=n(Ax,"P",{});var P2a=s(W$e);jgt=r(P2a,"Instantiates one of the base model classes of the library from a configuration."),P2a.forEach(t),Dgt=i(Ax),nf=n(Ax,"P",{});var Mme=s(nf);Ggt=r(Mme,`Note:
Loading a model from its configuration file does `),U$e=n(Mme,"STRONG",{});var B2a=s(U$e);Ogt=r(B2a,"not"),B2a.forEach(t),Vgt=r(Mme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ole=n(Mme,"A",{href:!0});var I2a=s(ole);Xgt=r(I2a,"from_pretrained()"),I2a.forEach(t),zgt=r(Mme," to load the model weights."),Mme.forEach(t),Qgt=i(Ax),T(k7.$$.fragment,Ax),Ax.forEach(t),Wgt=i(Qi),rt=n(Qi,"DIV",{class:!0});var Wi=s(rt);T(NP.$$.fragment,Wi),Ugt=i(Wi),H$e=n(Wi,"P",{});var N2a=s(H$e);Hgt=r(N2a,"Instantiate one of the base model classes of the library from a pretrained model."),N2a.forEach(t),Jgt=i(Wi),Yn=n(Wi,"P",{});var Lx=s(Yn);Ygt=r(Lx,"The model class to instantiate is selected based on the "),J$e=n(Lx,"CODE",{});var q2a=s(J$e);Zgt=r(q2a,"model_type"),q2a.forEach(t),Kgt=r(Lx,` property of the config object (either
passed as an argument or loaded from `),Y$e=n(Lx,"CODE",{});var j2a=s(Y$e);eht=r(j2a,"pretrained_model_name_or_path"),j2a.forEach(t),oht=r(Lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z$e=n(Lx,"CODE",{});var D2a=s(Z$e);rht=r(D2a,"pretrained_model_name_or_path"),D2a.forEach(t),tht=r(Lx,":"),Lx.forEach(t),aht=i(Wi),te=n(Wi,"UL",{});var ne=s(te);S7=n(ne,"LI",{});var Deo=s(S7);K$e=n(Deo,"STRONG",{});var G2a=s(K$e);nht=r(G2a,"albert"),G2a.forEach(t),sht=r(Deo," \u2014 "),rle=n(Deo,"A",{href:!0});var O2a=s(rle);lht=r(O2a,"FlaxAlbertModel"),O2a.forEach(t),iht=r(Deo," (ALBERT model)"),Deo.forEach(t),dht=i(ne),R7=n(ne,"LI",{});var Geo=s(R7);eke=n(Geo,"STRONG",{});var V2a=s(eke);cht=r(V2a,"bart"),V2a.forEach(t),mht=r(Geo," \u2014 "),tle=n(Geo,"A",{href:!0});var X2a=s(tle);fht=r(X2a,"FlaxBartModel"),X2a.forEach(t),ght=r(Geo," (BART model)"),Geo.forEach(t),hht=i(ne),P7=n(ne,"LI",{});var Oeo=s(P7);oke=n(Oeo,"STRONG",{});var z2a=s(oke);uht=r(z2a,"beit"),z2a.forEach(t),pht=r(Oeo," \u2014 "),ale=n(Oeo,"A",{href:!0});var Q2a=s(ale);_ht=r(Q2a,"FlaxBeitModel"),Q2a.forEach(t),bht=r(Oeo," (BEiT model)"),Oeo.forEach(t),vht=i(ne),B7=n(ne,"LI",{});var Veo=s(B7);rke=n(Veo,"STRONG",{});var W2a=s(rke);Fht=r(W2a,"bert"),W2a.forEach(t),Tht=r(Veo," \u2014 "),nle=n(Veo,"A",{href:!0});var U2a=s(nle);Mht=r(U2a,"FlaxBertModel"),U2a.forEach(t),Eht=r(Veo," (BERT model)"),Veo.forEach(t),Cht=i(ne),I7=n(ne,"LI",{});var Xeo=s(I7);tke=n(Xeo,"STRONG",{});var H2a=s(tke);wht=r(H2a,"big_bird"),H2a.forEach(t),Aht=r(Xeo," \u2014 "),sle=n(Xeo,"A",{href:!0});var J2a=s(sle);Lht=r(J2a,"FlaxBigBirdModel"),J2a.forEach(t),yht=r(Xeo," (BigBird model)"),Xeo.forEach(t),xht=i(ne),N7=n(ne,"LI",{});var zeo=s(N7);ake=n(zeo,"STRONG",{});var Y2a=s(ake);$ht=r(Y2a,"blenderbot"),Y2a.forEach(t),kht=r(zeo," \u2014 "),lle=n(zeo,"A",{href:!0});var Z2a=s(lle);Sht=r(Z2a,"FlaxBlenderbotModel"),Z2a.forEach(t),Rht=r(zeo," (Blenderbot model)"),zeo.forEach(t),Pht=i(ne),q7=n(ne,"LI",{});var Qeo=s(q7);nke=n(Qeo,"STRONG",{});var K2a=s(nke);Bht=r(K2a,"blenderbot-small"),K2a.forEach(t),Iht=r(Qeo," \u2014 "),ile=n(Qeo,"A",{href:!0});var eba=s(ile);Nht=r(eba,"FlaxBlenderbotSmallModel"),eba.forEach(t),qht=r(Qeo," (BlenderbotSmall model)"),Qeo.forEach(t),jht=i(ne),j7=n(ne,"LI",{});var Weo=s(j7);ske=n(Weo,"STRONG",{});var oba=s(ske);Dht=r(oba,"clip"),oba.forEach(t),Ght=r(Weo," \u2014 "),dle=n(Weo,"A",{href:!0});var rba=s(dle);Oht=r(rba,"FlaxCLIPModel"),rba.forEach(t),Vht=r(Weo," (CLIP model)"),Weo.forEach(t),Xht=i(ne),D7=n(ne,"LI",{});var Ueo=s(D7);lke=n(Ueo,"STRONG",{});var tba=s(lke);zht=r(tba,"distilbert"),tba.forEach(t),Qht=r(Ueo," \u2014 "),cle=n(Ueo,"A",{href:!0});var aba=s(cle);Wht=r(aba,"FlaxDistilBertModel"),aba.forEach(t),Uht=r(Ueo," (DistilBERT model)"),Ueo.forEach(t),Hht=i(ne),G7=n(ne,"LI",{});var Heo=s(G7);ike=n(Heo,"STRONG",{});var nba=s(ike);Jht=r(nba,"electra"),nba.forEach(t),Yht=r(Heo," \u2014 "),mle=n(Heo,"A",{href:!0});var sba=s(mle);Zht=r(sba,"FlaxElectraModel"),sba.forEach(t),Kht=r(Heo," (ELECTRA model)"),Heo.forEach(t),eut=i(ne),O7=n(ne,"LI",{});var Jeo=s(O7);dke=n(Jeo,"STRONG",{});var lba=s(dke);out=r(lba,"gpt2"),lba.forEach(t),rut=r(Jeo," \u2014 "),fle=n(Jeo,"A",{href:!0});var iba=s(fle);tut=r(iba,"FlaxGPT2Model"),iba.forEach(t),aut=r(Jeo," (OpenAI GPT-2 model)"),Jeo.forEach(t),nut=i(ne),V7=n(ne,"LI",{});var Yeo=s(V7);cke=n(Yeo,"STRONG",{});var dba=s(cke);sut=r(dba,"gpt_neo"),dba.forEach(t),lut=r(Yeo," \u2014 "),gle=n(Yeo,"A",{href:!0});var cba=s(gle);iut=r(cba,"FlaxGPTNeoModel"),cba.forEach(t),dut=r(Yeo," (GPT Neo model)"),Yeo.forEach(t),cut=i(ne),X7=n(ne,"LI",{});var Zeo=s(X7);mke=n(Zeo,"STRONG",{});var mba=s(mke);mut=r(mba,"gptj"),mba.forEach(t),fut=r(Zeo," \u2014 "),hle=n(Zeo,"A",{href:!0});var fba=s(hle);gut=r(fba,"FlaxGPTJModel"),fba.forEach(t),hut=r(Zeo," (GPT-J model)"),Zeo.forEach(t),uut=i(ne),z7=n(ne,"LI",{});var Keo=s(z7);fke=n(Keo,"STRONG",{});var gba=s(fke);put=r(gba,"longt5"),gba.forEach(t),_ut=r(Keo," \u2014 "),ule=n(Keo,"A",{href:!0});var hba=s(ule);but=r(hba,"FlaxLongT5Model"),hba.forEach(t),vut=r(Keo," (LongT5 model)"),Keo.forEach(t),Fut=i(ne),Q7=n(ne,"LI",{});var eoo=s(Q7);gke=n(eoo,"STRONG",{});var uba=s(gke);Tut=r(uba,"marian"),uba.forEach(t),Mut=r(eoo," \u2014 "),ple=n(eoo,"A",{href:!0});var pba=s(ple);Eut=r(pba,"FlaxMarianModel"),pba.forEach(t),Cut=r(eoo," (Marian model)"),eoo.forEach(t),wut=i(ne),W7=n(ne,"LI",{});var ooo=s(W7);hke=n(ooo,"STRONG",{});var _ba=s(hke);Aut=r(_ba,"mbart"),_ba.forEach(t),Lut=r(ooo," \u2014 "),_le=n(ooo,"A",{href:!0});var bba=s(_le);yut=r(bba,"FlaxMBartModel"),bba.forEach(t),xut=r(ooo," (mBART model)"),ooo.forEach(t),$ut=i(ne),U7=n(ne,"LI",{});var roo=s(U7);uke=n(roo,"STRONG",{});var vba=s(uke);kut=r(vba,"mt5"),vba.forEach(t),Sut=r(roo," \u2014 "),ble=n(roo,"A",{href:!0});var Fba=s(ble);Rut=r(Fba,"FlaxMT5Model"),Fba.forEach(t),Put=r(roo," (MT5 model)"),roo.forEach(t),But=i(ne),H7=n(ne,"LI",{});var too=s(H7);pke=n(too,"STRONG",{});var Tba=s(pke);Iut=r(Tba,"opt"),Tba.forEach(t),Nut=r(too," \u2014 "),vle=n(too,"A",{href:!0});var Mba=s(vle);qut=r(Mba,"FlaxOPTModel"),Mba.forEach(t),jut=r(too," (OPT model)"),too.forEach(t),Dut=i(ne),J7=n(ne,"LI",{});var aoo=s(J7);_ke=n(aoo,"STRONG",{});var Eba=s(_ke);Gut=r(Eba,"pegasus"),Eba.forEach(t),Out=r(aoo," \u2014 "),Fle=n(aoo,"A",{href:!0});var Cba=s(Fle);Vut=r(Cba,"FlaxPegasusModel"),Cba.forEach(t),Xut=r(aoo," (Pegasus model)"),aoo.forEach(t),zut=i(ne),Y7=n(ne,"LI",{});var noo=s(Y7);bke=n(noo,"STRONG",{});var wba=s(bke);Qut=r(wba,"roberta"),wba.forEach(t),Wut=r(noo," \u2014 "),Tle=n(noo,"A",{href:!0});var Aba=s(Tle);Uut=r(Aba,"FlaxRobertaModel"),Aba.forEach(t),Hut=r(noo," (RoBERTa model)"),noo.forEach(t),Jut=i(ne),Z7=n(ne,"LI",{});var soo=s(Z7);vke=n(soo,"STRONG",{});var Lba=s(vke);Yut=r(Lba,"roformer"),Lba.forEach(t),Zut=r(soo," \u2014 "),Mle=n(soo,"A",{href:!0});var yba=s(Mle);Kut=r(yba,"FlaxRoFormerModel"),yba.forEach(t),ept=r(soo," (RoFormer model)"),soo.forEach(t),opt=i(ne),K7=n(ne,"LI",{});var loo=s(K7);Fke=n(loo,"STRONG",{});var xba=s(Fke);rpt=r(xba,"t5"),xba.forEach(t),tpt=r(loo," \u2014 "),Ele=n(loo,"A",{href:!0});var $ba=s(Ele);apt=r($ba,"FlaxT5Model"),$ba.forEach(t),npt=r(loo," (T5 model)"),loo.forEach(t),spt=i(ne),eL=n(ne,"LI",{});var ioo=s(eL);Tke=n(ioo,"STRONG",{});var kba=s(Tke);lpt=r(kba,"vision-text-dual-encoder"),kba.forEach(t),ipt=r(ioo," \u2014 "),Cle=n(ioo,"A",{href:!0});var Sba=s(Cle);dpt=r(Sba,"FlaxVisionTextDualEncoderModel"),Sba.forEach(t),cpt=r(ioo," (VisionTextDualEncoder model)"),ioo.forEach(t),mpt=i(ne),oL=n(ne,"LI",{});var doo=s(oL);Mke=n(doo,"STRONG",{});var Rba=s(Mke);fpt=r(Rba,"vit"),Rba.forEach(t),gpt=r(doo," \u2014 "),wle=n(doo,"A",{href:!0});var Pba=s(wle);hpt=r(Pba,"FlaxViTModel"),Pba.forEach(t),upt=r(doo," (ViT model)"),doo.forEach(t),ppt=i(ne),rL=n(ne,"LI",{});var coo=s(rL);Eke=n(coo,"STRONG",{});var Bba=s(Eke);_pt=r(Bba,"wav2vec2"),Bba.forEach(t),bpt=r(coo," \u2014 "),Ale=n(coo,"A",{href:!0});var Iba=s(Ale);vpt=r(Iba,"FlaxWav2Vec2Model"),Iba.forEach(t),Fpt=r(coo," (Wav2Vec2 model)"),coo.forEach(t),Tpt=i(ne),tL=n(ne,"LI",{});var moo=s(tL);Cke=n(moo,"STRONG",{});var Nba=s(Cke);Mpt=r(Nba,"xglm"),Nba.forEach(t),Ept=r(moo," \u2014 "),Lle=n(moo,"A",{href:!0});var qba=s(Lle);Cpt=r(qba,"FlaxXGLMModel"),qba.forEach(t),wpt=r(moo," (XGLM model)"),moo.forEach(t),Apt=i(ne),aL=n(ne,"LI",{});var foo=s(aL);wke=n(foo,"STRONG",{});var jba=s(wke);Lpt=r(jba,"xlm-roberta"),jba.forEach(t),ypt=r(foo," \u2014 "),yle=n(foo,"A",{href:!0});var Dba=s(yle);xpt=r(Dba,"FlaxXLMRobertaModel"),Dba.forEach(t),$pt=r(foo," (XLM-RoBERTa model)"),foo.forEach(t),ne.forEach(t),kpt=i(Wi),T(nL.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),Nao=i(m),sf=n(m,"H2",{class:!0});var alo=s(sf);sL=n(alo,"A",{id:!0,class:!0,href:!0});var Gba=s(sL);Ake=n(Gba,"SPAN",{});var Oba=s(Ake);T(qP.$$.fragment,Oba),Oba.forEach(t),Gba.forEach(t),Spt=i(alo),Lke=n(alo,"SPAN",{});var Vba=s(Lke);Rpt=r(Vba,"FlaxAutoModelForCausalLM"),Vba.forEach(t),alo.forEach(t),qao=i(m),Lr=n(m,"DIV",{class:!0});var Ui=s(Lr);T(jP.$$.fragment,Ui),Ppt=i(Ui),lf=n(Ui,"P",{});var Eme=s(lf);Bpt=r(Eme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),xle=n(Eme,"A",{href:!0});var Xba=s(xle);Ipt=r(Xba,"from_pretrained()"),Xba.forEach(t),Npt=r(Eme," class method or the "),$le=n(Eme,"A",{href:!0});var zba=s($le);qpt=r(zba,"from_config()"),zba.forEach(t),jpt=r(Eme,` class
method.`),Eme.forEach(t),Dpt=i(Ui),DP=n(Ui,"P",{});var nlo=s(DP);Gpt=r(nlo,"This class cannot be instantiated directly using "),yke=n(nlo,"CODE",{});var Qba=s(yke);Opt=r(Qba,"__init__()"),Qba.forEach(t),Vpt=r(nlo," (throws an error)."),nlo.forEach(t),Xpt=i(Ui),ga=n(Ui,"DIV",{class:!0});var yx=s(ga);T(GP.$$.fragment,yx),zpt=i(yx),xke=n(yx,"P",{});var Wba=s(xke);Qpt=r(Wba,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Wba.forEach(t),Wpt=i(yx),df=n(yx,"P",{});var Cme=s(df);Upt=r(Cme,`Note:
Loading a model from its configuration file does `),$ke=n(Cme,"STRONG",{});var Uba=s($ke);Hpt=r(Uba,"not"),Uba.forEach(t),Jpt=r(Cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),kle=n(Cme,"A",{href:!0});var Hba=s(kle);Ypt=r(Hba,"from_pretrained()"),Hba.forEach(t),Zpt=r(Cme," to load the model weights."),Cme.forEach(t),Kpt=i(yx),T(lL.$$.fragment,yx),yx.forEach(t),e_t=i(Ui),tt=n(Ui,"DIV",{class:!0});var Hi=s(tt);T(OP.$$.fragment,Hi),o_t=i(Hi),kke=n(Hi,"P",{});var Jba=s(kke);r_t=r(Jba,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Jba.forEach(t),t_t=i(Hi),Zn=n(Hi,"P",{});var xx=s(Zn);a_t=r(xx,"The model class to instantiate is selected based on the "),Ske=n(xx,"CODE",{});var Yba=s(Ske);n_t=r(Yba,"model_type"),Yba.forEach(t),s_t=r(xx,` property of the config object (either
passed as an argument or loaded from `),Rke=n(xx,"CODE",{});var Zba=s(Rke);l_t=r(Zba,"pretrained_model_name_or_path"),Zba.forEach(t),i_t=r(xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pke=n(xx,"CODE",{});var Kba=s(Pke);d_t=r(Kba,"pretrained_model_name_or_path"),Kba.forEach(t),c_t=r(xx,":"),xx.forEach(t),m_t=i(Hi),$e=n(Hi,"UL",{});var je=s($e);iL=n(je,"LI",{});var goo=s(iL);Bke=n(goo,"STRONG",{});var eva=s(Bke);f_t=r(eva,"bart"),eva.forEach(t),g_t=r(goo," \u2014 "),Sle=n(goo,"A",{href:!0});var ova=s(Sle);h_t=r(ova,"FlaxBartForCausalLM"),ova.forEach(t),u_t=r(goo," (BART model)"),goo.forEach(t),p_t=i(je),dL=n(je,"LI",{});var hoo=s(dL);Ike=n(hoo,"STRONG",{});var rva=s(Ike);__t=r(rva,"bert"),rva.forEach(t),b_t=r(hoo," \u2014 "),Rle=n(hoo,"A",{href:!0});var tva=s(Rle);v_t=r(tva,"FlaxBertForCausalLM"),tva.forEach(t),F_t=r(hoo," (BERT model)"),hoo.forEach(t),T_t=i(je),cL=n(je,"LI",{});var uoo=s(cL);Nke=n(uoo,"STRONG",{});var ava=s(Nke);M_t=r(ava,"big_bird"),ava.forEach(t),E_t=r(uoo," \u2014 "),Ple=n(uoo,"A",{href:!0});var nva=s(Ple);C_t=r(nva,"FlaxBigBirdForCausalLM"),nva.forEach(t),w_t=r(uoo," (BigBird model)"),uoo.forEach(t),A_t=i(je),mL=n(je,"LI",{});var poo=s(mL);qke=n(poo,"STRONG",{});var sva=s(qke);L_t=r(sva,"electra"),sva.forEach(t),y_t=r(poo," \u2014 "),Ble=n(poo,"A",{href:!0});var lva=s(Ble);x_t=r(lva,"FlaxElectraForCausalLM"),lva.forEach(t),$_t=r(poo," (ELECTRA model)"),poo.forEach(t),k_t=i(je),fL=n(je,"LI",{});var _oo=s(fL);jke=n(_oo,"STRONG",{});var iva=s(jke);S_t=r(iva,"gpt2"),iva.forEach(t),R_t=r(_oo," \u2014 "),Ile=n(_oo,"A",{href:!0});var dva=s(Ile);P_t=r(dva,"FlaxGPT2LMHeadModel"),dva.forEach(t),B_t=r(_oo," (OpenAI GPT-2 model)"),_oo.forEach(t),I_t=i(je),gL=n(je,"LI",{});var boo=s(gL);Dke=n(boo,"STRONG",{});var cva=s(Dke);N_t=r(cva,"gpt_neo"),cva.forEach(t),q_t=r(boo," \u2014 "),Nle=n(boo,"A",{href:!0});var mva=s(Nle);j_t=r(mva,"FlaxGPTNeoForCausalLM"),mva.forEach(t),D_t=r(boo," (GPT Neo model)"),boo.forEach(t),G_t=i(je),hL=n(je,"LI",{});var voo=s(hL);Gke=n(voo,"STRONG",{});var fva=s(Gke);O_t=r(fva,"gptj"),fva.forEach(t),V_t=r(voo," \u2014 "),qle=n(voo,"A",{href:!0});var gva=s(qle);X_t=r(gva,"FlaxGPTJForCausalLM"),gva.forEach(t),z_t=r(voo," (GPT-J model)"),voo.forEach(t),Q_t=i(je),uL=n(je,"LI",{});var Foo=s(uL);Oke=n(Foo,"STRONG",{});var hva=s(Oke);W_t=r(hva,"opt"),hva.forEach(t),U_t=r(Foo," \u2014 "),jle=n(Foo,"A",{href:!0});var uva=s(jle);H_t=r(uva,"FlaxOPTForCausalLM"),uva.forEach(t),J_t=r(Foo," (OPT model)"),Foo.forEach(t),Y_t=i(je),pL=n(je,"LI",{});var Too=s(pL);Vke=n(Too,"STRONG",{});var pva=s(Vke);Z_t=r(pva,"roberta"),pva.forEach(t),K_t=r(Too," \u2014 "),Dle=n(Too,"A",{href:!0});var _va=s(Dle);e1t=r(_va,"FlaxRobertaForCausalLM"),_va.forEach(t),o1t=r(Too," (RoBERTa model)"),Too.forEach(t),r1t=i(je),_L=n(je,"LI",{});var Moo=s(_L);Xke=n(Moo,"STRONG",{});var bva=s(Xke);t1t=r(bva,"xglm"),bva.forEach(t),a1t=r(Moo," \u2014 "),Gle=n(Moo,"A",{href:!0});var vva=s(Gle);n1t=r(vva,"FlaxXGLMForCausalLM"),vva.forEach(t),s1t=r(Moo," (XGLM model)"),Moo.forEach(t),je.forEach(t),l1t=i(Hi),T(bL.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),jao=i(m),cf=n(m,"H2",{class:!0});var slo=s(cf);vL=n(slo,"A",{id:!0,class:!0,href:!0});var Fva=s(vL);zke=n(Fva,"SPAN",{});var Tva=s(zke);T(VP.$$.fragment,Tva),Tva.forEach(t),Fva.forEach(t),i1t=i(slo),Qke=n(slo,"SPAN",{});var Mva=s(Qke);d1t=r(Mva,"FlaxAutoModelForPreTraining"),Mva.forEach(t),slo.forEach(t),Dao=i(m),yr=n(m,"DIV",{class:!0});var Ji=s(yr);T(XP.$$.fragment,Ji),c1t=i(Ji),mf=n(Ji,"P",{});var wme=s(mf);m1t=r(wme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Ole=n(wme,"A",{href:!0});var Eva=s(Ole);f1t=r(Eva,"from_pretrained()"),Eva.forEach(t),g1t=r(wme," class method or the "),Vle=n(wme,"A",{href:!0});var Cva=s(Vle);h1t=r(Cva,"from_config()"),Cva.forEach(t),u1t=r(wme,` class
method.`),wme.forEach(t),p1t=i(Ji),zP=n(Ji,"P",{});var llo=s(zP);_1t=r(llo,"This class cannot be instantiated directly using "),Wke=n(llo,"CODE",{});var wva=s(Wke);b1t=r(wva,"__init__()"),wva.forEach(t),v1t=r(llo," (throws an error)."),llo.forEach(t),F1t=i(Ji),ha=n(Ji,"DIV",{class:!0});var $x=s(ha);T(QP.$$.fragment,$x),T1t=i($x),Uke=n($x,"P",{});var Ava=s(Uke);M1t=r(Ava,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ava.forEach(t),E1t=i($x),ff=n($x,"P",{});var Ame=s(ff);C1t=r(Ame,`Note:
Loading a model from its configuration file does `),Hke=n(Ame,"STRONG",{});var Lva=s(Hke);w1t=r(Lva,"not"),Lva.forEach(t),A1t=r(Ame,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xle=n(Ame,"A",{href:!0});var yva=s(Xle);L1t=r(yva,"from_pretrained()"),yva.forEach(t),y1t=r(Ame," to load the model weights."),Ame.forEach(t),x1t=i($x),T(FL.$$.fragment,$x),$x.forEach(t),$1t=i(Ji),at=n(Ji,"DIV",{class:!0});var Yi=s(at);T(WP.$$.fragment,Yi),k1t=i(Yi),Jke=n(Yi,"P",{});var xva=s(Jke);S1t=r(xva,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),xva.forEach(t),R1t=i(Yi),Kn=n(Yi,"P",{});var kx=s(Kn);P1t=r(kx,"The model class to instantiate is selected based on the "),Yke=n(kx,"CODE",{});var $va=s(Yke);B1t=r($va,"model_type"),$va.forEach(t),I1t=r(kx,` property of the config object (either
passed as an argument or loaded from `),Zke=n(kx,"CODE",{});var kva=s(Zke);N1t=r(kva,"pretrained_model_name_or_path"),kva.forEach(t),q1t=r(kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kke=n(kx,"CODE",{});var Sva=s(Kke);j1t=r(Sva,"pretrained_model_name_or_path"),Sva.forEach(t),D1t=r(kx,":"),kx.forEach(t),G1t=i(Yi),Ee=n(Yi,"UL",{});var we=s(Ee);TL=n(we,"LI",{});var Eoo=s(TL);eSe=n(Eoo,"STRONG",{});var Rva=s(eSe);O1t=r(Rva,"albert"),Rva.forEach(t),V1t=r(Eoo," \u2014 "),zle=n(Eoo,"A",{href:!0});var Pva=s(zle);X1t=r(Pva,"FlaxAlbertForPreTraining"),Pva.forEach(t),z1t=r(Eoo," (ALBERT model)"),Eoo.forEach(t),Q1t=i(we),ML=n(we,"LI",{});var Coo=s(ML);oSe=n(Coo,"STRONG",{});var Bva=s(oSe);W1t=r(Bva,"bart"),Bva.forEach(t),U1t=r(Coo," \u2014 "),Qle=n(Coo,"A",{href:!0});var Iva=s(Qle);H1t=r(Iva,"FlaxBartForConditionalGeneration"),Iva.forEach(t),J1t=r(Coo," (BART model)"),Coo.forEach(t),Y1t=i(we),EL=n(we,"LI",{});var woo=s(EL);rSe=n(woo,"STRONG",{});var Nva=s(rSe);Z1t=r(Nva,"bert"),Nva.forEach(t),K1t=r(woo," \u2014 "),Wle=n(woo,"A",{href:!0});var qva=s(Wle);e2t=r(qva,"FlaxBertForPreTraining"),qva.forEach(t),o2t=r(woo," (BERT model)"),woo.forEach(t),r2t=i(we),CL=n(we,"LI",{});var Aoo=s(CL);tSe=n(Aoo,"STRONG",{});var jva=s(tSe);t2t=r(jva,"big_bird"),jva.forEach(t),a2t=r(Aoo," \u2014 "),Ule=n(Aoo,"A",{href:!0});var Dva=s(Ule);n2t=r(Dva,"FlaxBigBirdForPreTraining"),Dva.forEach(t),s2t=r(Aoo," (BigBird model)"),Aoo.forEach(t),l2t=i(we),wL=n(we,"LI",{});var Loo=s(wL);aSe=n(Loo,"STRONG",{});var Gva=s(aSe);i2t=r(Gva,"electra"),Gva.forEach(t),d2t=r(Loo," \u2014 "),Hle=n(Loo,"A",{href:!0});var Ova=s(Hle);c2t=r(Ova,"FlaxElectraForPreTraining"),Ova.forEach(t),m2t=r(Loo," (ELECTRA model)"),Loo.forEach(t),f2t=i(we),AL=n(we,"LI",{});var yoo=s(AL);nSe=n(yoo,"STRONG",{});var Vva=s(nSe);g2t=r(Vva,"longt5"),Vva.forEach(t),h2t=r(yoo," \u2014 "),Jle=n(yoo,"A",{href:!0});var Xva=s(Jle);u2t=r(Xva,"FlaxLongT5ForConditionalGeneration"),Xva.forEach(t),p2t=r(yoo," (LongT5 model)"),yoo.forEach(t),_2t=i(we),LL=n(we,"LI",{});var xoo=s(LL);sSe=n(xoo,"STRONG",{});var zva=s(sSe);b2t=r(zva,"mbart"),zva.forEach(t),v2t=r(xoo," \u2014 "),Yle=n(xoo,"A",{href:!0});var Qva=s(Yle);F2t=r(Qva,"FlaxMBartForConditionalGeneration"),Qva.forEach(t),T2t=r(xoo," (mBART model)"),xoo.forEach(t),M2t=i(we),yL=n(we,"LI",{});var $oo=s(yL);lSe=n($oo,"STRONG",{});var Wva=s(lSe);E2t=r(Wva,"mt5"),Wva.forEach(t),C2t=r($oo," \u2014 "),Zle=n($oo,"A",{href:!0});var Uva=s(Zle);w2t=r(Uva,"FlaxMT5ForConditionalGeneration"),Uva.forEach(t),A2t=r($oo," (MT5 model)"),$oo.forEach(t),L2t=i(we),xL=n(we,"LI",{});var koo=s(xL);iSe=n(koo,"STRONG",{});var Hva=s(iSe);y2t=r(Hva,"roberta"),Hva.forEach(t),x2t=r(koo," \u2014 "),Kle=n(koo,"A",{href:!0});var Jva=s(Kle);$2t=r(Jva,"FlaxRobertaForMaskedLM"),Jva.forEach(t),k2t=r(koo," (RoBERTa model)"),koo.forEach(t),S2t=i(we),$L=n(we,"LI",{});var Soo=s($L);dSe=n(Soo,"STRONG",{});var Yva=s(dSe);R2t=r(Yva,"roformer"),Yva.forEach(t),P2t=r(Soo," \u2014 "),eie=n(Soo,"A",{href:!0});var Zva=s(eie);B2t=r(Zva,"FlaxRoFormerForMaskedLM"),Zva.forEach(t),I2t=r(Soo," (RoFormer model)"),Soo.forEach(t),N2t=i(we),kL=n(we,"LI",{});var Roo=s(kL);cSe=n(Roo,"STRONG",{});var Kva=s(cSe);q2t=r(Kva,"t5"),Kva.forEach(t),j2t=r(Roo," \u2014 "),oie=n(Roo,"A",{href:!0});var eFa=s(oie);D2t=r(eFa,"FlaxT5ForConditionalGeneration"),eFa.forEach(t),G2t=r(Roo," (T5 model)"),Roo.forEach(t),O2t=i(we),SL=n(we,"LI",{});var Poo=s(SL);mSe=n(Poo,"STRONG",{});var oFa=s(mSe);V2t=r(oFa,"wav2vec2"),oFa.forEach(t),X2t=r(Poo," \u2014 "),rie=n(Poo,"A",{href:!0});var rFa=s(rie);z2t=r(rFa,"FlaxWav2Vec2ForPreTraining"),rFa.forEach(t),Q2t=r(Poo," (Wav2Vec2 model)"),Poo.forEach(t),W2t=i(we),RL=n(we,"LI",{});var Boo=s(RL);fSe=n(Boo,"STRONG",{});var tFa=s(fSe);U2t=r(tFa,"xlm-roberta"),tFa.forEach(t),H2t=r(Boo," \u2014 "),tie=n(Boo,"A",{href:!0});var aFa=s(tie);J2t=r(aFa,"FlaxXLMRobertaForMaskedLM"),aFa.forEach(t),Y2t=r(Boo," (XLM-RoBERTa model)"),Boo.forEach(t),we.forEach(t),Z2t=i(Yi),T(PL.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),Gao=i(m),gf=n(m,"H2",{class:!0});var ilo=s(gf);BL=n(ilo,"A",{id:!0,class:!0,href:!0});var nFa=s(BL);gSe=n(nFa,"SPAN",{});var sFa=s(gSe);T(UP.$$.fragment,sFa),sFa.forEach(t),nFa.forEach(t),K2t=i(ilo),hSe=n(ilo,"SPAN",{});var lFa=s(hSe);ebt=r(lFa,"FlaxAutoModelForMaskedLM"),lFa.forEach(t),ilo.forEach(t),Oao=i(m),xr=n(m,"DIV",{class:!0});var Zi=s(xr);T(HP.$$.fragment,Zi),obt=i(Zi),hf=n(Zi,"P",{});var Lme=s(hf);rbt=r(Lme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aie=n(Lme,"A",{href:!0});var iFa=s(aie);tbt=r(iFa,"from_pretrained()"),iFa.forEach(t),abt=r(Lme," class method or the "),nie=n(Lme,"A",{href:!0});var dFa=s(nie);nbt=r(dFa,"from_config()"),dFa.forEach(t),sbt=r(Lme,` class
method.`),Lme.forEach(t),lbt=i(Zi),JP=n(Zi,"P",{});var dlo=s(JP);ibt=r(dlo,"This class cannot be instantiated directly using "),uSe=n(dlo,"CODE",{});var cFa=s(uSe);dbt=r(cFa,"__init__()"),cFa.forEach(t),cbt=r(dlo," (throws an error)."),dlo.forEach(t),mbt=i(Zi),ua=n(Zi,"DIV",{class:!0});var Sx=s(ua);T(YP.$$.fragment,Sx),fbt=i(Sx),pSe=n(Sx,"P",{});var mFa=s(pSe);gbt=r(mFa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mFa.forEach(t),hbt=i(Sx),uf=n(Sx,"P",{});var yme=s(uf);ubt=r(yme,`Note:
Loading a model from its configuration file does `),_Se=n(yme,"STRONG",{});var fFa=s(_Se);pbt=r(fFa,"not"),fFa.forEach(t),_bt=r(yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=n(yme,"A",{href:!0});var gFa=s(sie);bbt=r(gFa,"from_pretrained()"),gFa.forEach(t),vbt=r(yme," to load the model weights."),yme.forEach(t),Fbt=i(Sx),T(IL.$$.fragment,Sx),Sx.forEach(t),Tbt=i(Zi),nt=n(Zi,"DIV",{class:!0});var Ki=s(nt);T(ZP.$$.fragment,Ki),Mbt=i(Ki),bSe=n(Ki,"P",{});var hFa=s(bSe);Ebt=r(hFa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hFa.forEach(t),Cbt=i(Ki),es=n(Ki,"P",{});var Rx=s(es);wbt=r(Rx,"The model class to instantiate is selected based on the "),vSe=n(Rx,"CODE",{});var uFa=s(vSe);Abt=r(uFa,"model_type"),uFa.forEach(t),Lbt=r(Rx,` property of the config object (either
passed as an argument or loaded from `),FSe=n(Rx,"CODE",{});var pFa=s(FSe);ybt=r(pFa,"pretrained_model_name_or_path"),pFa.forEach(t),xbt=r(Rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TSe=n(Rx,"CODE",{});var _Fa=s(TSe);$bt=r(_Fa,"pretrained_model_name_or_path"),_Fa.forEach(t),kbt=r(Rx,":"),Rx.forEach(t),Sbt=i(Ki),ke=n(Ki,"UL",{});var De=s(ke);NL=n(De,"LI",{});var Ioo=s(NL);MSe=n(Ioo,"STRONG",{});var bFa=s(MSe);Rbt=r(bFa,"albert"),bFa.forEach(t),Pbt=r(Ioo," \u2014 "),lie=n(Ioo,"A",{href:!0});var vFa=s(lie);Bbt=r(vFa,"FlaxAlbertForMaskedLM"),vFa.forEach(t),Ibt=r(Ioo," (ALBERT model)"),Ioo.forEach(t),Nbt=i(De),qL=n(De,"LI",{});var Noo=s(qL);ESe=n(Noo,"STRONG",{});var FFa=s(ESe);qbt=r(FFa,"bart"),FFa.forEach(t),jbt=r(Noo," \u2014 "),iie=n(Noo,"A",{href:!0});var TFa=s(iie);Dbt=r(TFa,"FlaxBartForConditionalGeneration"),TFa.forEach(t),Gbt=r(Noo," (BART model)"),Noo.forEach(t),Obt=i(De),jL=n(De,"LI",{});var qoo=s(jL);CSe=n(qoo,"STRONG",{});var MFa=s(CSe);Vbt=r(MFa,"bert"),MFa.forEach(t),Xbt=r(qoo," \u2014 "),die=n(qoo,"A",{href:!0});var EFa=s(die);zbt=r(EFa,"FlaxBertForMaskedLM"),EFa.forEach(t),Qbt=r(qoo," (BERT model)"),qoo.forEach(t),Wbt=i(De),DL=n(De,"LI",{});var joo=s(DL);wSe=n(joo,"STRONG",{});var CFa=s(wSe);Ubt=r(CFa,"big_bird"),CFa.forEach(t),Hbt=r(joo," \u2014 "),cie=n(joo,"A",{href:!0});var wFa=s(cie);Jbt=r(wFa,"FlaxBigBirdForMaskedLM"),wFa.forEach(t),Ybt=r(joo," (BigBird model)"),joo.forEach(t),Zbt=i(De),GL=n(De,"LI",{});var Doo=s(GL);ASe=n(Doo,"STRONG",{});var AFa=s(ASe);Kbt=r(AFa,"distilbert"),AFa.forEach(t),evt=r(Doo," \u2014 "),mie=n(Doo,"A",{href:!0});var LFa=s(mie);ovt=r(LFa,"FlaxDistilBertForMaskedLM"),LFa.forEach(t),rvt=r(Doo," (DistilBERT model)"),Doo.forEach(t),tvt=i(De),OL=n(De,"LI",{});var Goo=s(OL);LSe=n(Goo,"STRONG",{});var yFa=s(LSe);avt=r(yFa,"electra"),yFa.forEach(t),nvt=r(Goo," \u2014 "),fie=n(Goo,"A",{href:!0});var xFa=s(fie);svt=r(xFa,"FlaxElectraForMaskedLM"),xFa.forEach(t),lvt=r(Goo," (ELECTRA model)"),Goo.forEach(t),ivt=i(De),VL=n(De,"LI",{});var Ooo=s(VL);ySe=n(Ooo,"STRONG",{});var $Fa=s(ySe);dvt=r($Fa,"mbart"),$Fa.forEach(t),cvt=r(Ooo," \u2014 "),gie=n(Ooo,"A",{href:!0});var kFa=s(gie);mvt=r(kFa,"FlaxMBartForConditionalGeneration"),kFa.forEach(t),fvt=r(Ooo," (mBART model)"),Ooo.forEach(t),gvt=i(De),XL=n(De,"LI",{});var Voo=s(XL);xSe=n(Voo,"STRONG",{});var SFa=s(xSe);hvt=r(SFa,"roberta"),SFa.forEach(t),uvt=r(Voo," \u2014 "),hie=n(Voo,"A",{href:!0});var RFa=s(hie);pvt=r(RFa,"FlaxRobertaForMaskedLM"),RFa.forEach(t),_vt=r(Voo," (RoBERTa model)"),Voo.forEach(t),bvt=i(De),zL=n(De,"LI",{});var Xoo=s(zL);$Se=n(Xoo,"STRONG",{});var PFa=s($Se);vvt=r(PFa,"roformer"),PFa.forEach(t),Fvt=r(Xoo," \u2014 "),uie=n(Xoo,"A",{href:!0});var BFa=s(uie);Tvt=r(BFa,"FlaxRoFormerForMaskedLM"),BFa.forEach(t),Mvt=r(Xoo," (RoFormer model)"),Xoo.forEach(t),Evt=i(De),QL=n(De,"LI",{});var zoo=s(QL);kSe=n(zoo,"STRONG",{});var IFa=s(kSe);Cvt=r(IFa,"xlm-roberta"),IFa.forEach(t),wvt=r(zoo," \u2014 "),pie=n(zoo,"A",{href:!0});var NFa=s(pie);Avt=r(NFa,"FlaxXLMRobertaForMaskedLM"),NFa.forEach(t),Lvt=r(zoo," (XLM-RoBERTa model)"),zoo.forEach(t),De.forEach(t),yvt=i(Ki),T(WL.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),Vao=i(m),pf=n(m,"H2",{class:!0});var clo=s(pf);UL=n(clo,"A",{id:!0,class:!0,href:!0});var qFa=s(UL);SSe=n(qFa,"SPAN",{});var jFa=s(SSe);T(KP.$$.fragment,jFa),jFa.forEach(t),qFa.forEach(t),xvt=i(clo),RSe=n(clo,"SPAN",{});var DFa=s(RSe);$vt=r(DFa,"FlaxAutoModelForSeq2SeqLM"),DFa.forEach(t),clo.forEach(t),Xao=i(m),$r=n(m,"DIV",{class:!0});var ed=s($r);T(eB.$$.fragment,ed),kvt=i(ed),_f=n(ed,"P",{});var xme=s(_f);Svt=r(xme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),_ie=n(xme,"A",{href:!0});var GFa=s(_ie);Rvt=r(GFa,"from_pretrained()"),GFa.forEach(t),Pvt=r(xme," class method or the "),bie=n(xme,"A",{href:!0});var OFa=s(bie);Bvt=r(OFa,"from_config()"),OFa.forEach(t),Ivt=r(xme,` class
method.`),xme.forEach(t),Nvt=i(ed),oB=n(ed,"P",{});var mlo=s(oB);qvt=r(mlo,"This class cannot be instantiated directly using "),PSe=n(mlo,"CODE",{});var VFa=s(PSe);jvt=r(VFa,"__init__()"),VFa.forEach(t),Dvt=r(mlo," (throws an error)."),mlo.forEach(t),Gvt=i(ed),pa=n(ed,"DIV",{class:!0});var Px=s(pa);T(rB.$$.fragment,Px),Ovt=i(Px),BSe=n(Px,"P",{});var XFa=s(BSe);Vvt=r(XFa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),XFa.forEach(t),Xvt=i(Px),bf=n(Px,"P",{});var $me=s(bf);zvt=r($me,`Note:
Loading a model from its configuration file does `),ISe=n($me,"STRONG",{});var zFa=s(ISe);Qvt=r(zFa,"not"),zFa.forEach(t),Wvt=r($me,` load the model weights. It only affects the
model\u2019s configuration. Use `),vie=n($me,"A",{href:!0});var QFa=s(vie);Uvt=r(QFa,"from_pretrained()"),QFa.forEach(t),Hvt=r($me," to load the model weights."),$me.forEach(t),Jvt=i(Px),T(HL.$$.fragment,Px),Px.forEach(t),Yvt=i(ed),st=n(ed,"DIV",{class:!0});var od=s(st);T(tB.$$.fragment,od),Zvt=i(od),NSe=n(od,"P",{});var WFa=s(NSe);Kvt=r(WFa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),WFa.forEach(t),eFt=i(od),os=n(od,"P",{});var Bx=s(os);oFt=r(Bx,"The model class to instantiate is selected based on the "),qSe=n(Bx,"CODE",{});var UFa=s(qSe);rFt=r(UFa,"model_type"),UFa.forEach(t),tFt=r(Bx,` property of the config object (either
passed as an argument or loaded from `),jSe=n(Bx,"CODE",{});var HFa=s(jSe);aFt=r(HFa,"pretrained_model_name_or_path"),HFa.forEach(t),nFt=r(Bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DSe=n(Bx,"CODE",{});var JFa=s(DSe);sFt=r(JFa,"pretrained_model_name_or_path"),JFa.forEach(t),lFt=r(Bx,":"),Bx.forEach(t),iFt=i(od),Se=n(od,"UL",{});var Ge=s(Se);JL=n(Ge,"LI",{});var Qoo=s(JL);GSe=n(Qoo,"STRONG",{});var YFa=s(GSe);dFt=r(YFa,"bart"),YFa.forEach(t),cFt=r(Qoo," \u2014 "),Fie=n(Qoo,"A",{href:!0});var ZFa=s(Fie);mFt=r(ZFa,"FlaxBartForConditionalGeneration"),ZFa.forEach(t),fFt=r(Qoo," (BART model)"),Qoo.forEach(t),gFt=i(Ge),YL=n(Ge,"LI",{});var Woo=s(YL);OSe=n(Woo,"STRONG",{});var KFa=s(OSe);hFt=r(KFa,"blenderbot"),KFa.forEach(t),uFt=r(Woo," \u2014 "),Tie=n(Woo,"A",{href:!0});var eTa=s(Tie);pFt=r(eTa,"FlaxBlenderbotForConditionalGeneration"),eTa.forEach(t),_Ft=r(Woo," (Blenderbot model)"),Woo.forEach(t),bFt=i(Ge),ZL=n(Ge,"LI",{});var Uoo=s(ZL);VSe=n(Uoo,"STRONG",{});var oTa=s(VSe);vFt=r(oTa,"blenderbot-small"),oTa.forEach(t),FFt=r(Uoo," \u2014 "),Mie=n(Uoo,"A",{href:!0});var rTa=s(Mie);TFt=r(rTa,"FlaxBlenderbotSmallForConditionalGeneration"),rTa.forEach(t),MFt=r(Uoo," (BlenderbotSmall model)"),Uoo.forEach(t),EFt=i(Ge),KL=n(Ge,"LI",{});var Hoo=s(KL);XSe=n(Hoo,"STRONG",{});var tTa=s(XSe);CFt=r(tTa,"encoder-decoder"),tTa.forEach(t),wFt=r(Hoo," \u2014 "),Eie=n(Hoo,"A",{href:!0});var aTa=s(Eie);AFt=r(aTa,"FlaxEncoderDecoderModel"),aTa.forEach(t),LFt=r(Hoo," (Encoder decoder model)"),Hoo.forEach(t),yFt=i(Ge),e8=n(Ge,"LI",{});var Joo=s(e8);zSe=n(Joo,"STRONG",{});var nTa=s(zSe);xFt=r(nTa,"longt5"),nTa.forEach(t),$Ft=r(Joo," \u2014 "),Cie=n(Joo,"A",{href:!0});var sTa=s(Cie);kFt=r(sTa,"FlaxLongT5ForConditionalGeneration"),sTa.forEach(t),SFt=r(Joo," (LongT5 model)"),Joo.forEach(t),RFt=i(Ge),o8=n(Ge,"LI",{});var Yoo=s(o8);QSe=n(Yoo,"STRONG",{});var lTa=s(QSe);PFt=r(lTa,"marian"),lTa.forEach(t),BFt=r(Yoo," \u2014 "),wie=n(Yoo,"A",{href:!0});var iTa=s(wie);IFt=r(iTa,"FlaxMarianMTModel"),iTa.forEach(t),NFt=r(Yoo," (Marian model)"),Yoo.forEach(t),qFt=i(Ge),r8=n(Ge,"LI",{});var Zoo=s(r8);WSe=n(Zoo,"STRONG",{});var dTa=s(WSe);jFt=r(dTa,"mbart"),dTa.forEach(t),DFt=r(Zoo," \u2014 "),Aie=n(Zoo,"A",{href:!0});var cTa=s(Aie);GFt=r(cTa,"FlaxMBartForConditionalGeneration"),cTa.forEach(t),OFt=r(Zoo," (mBART model)"),Zoo.forEach(t),VFt=i(Ge),t8=n(Ge,"LI",{});var Koo=s(t8);USe=n(Koo,"STRONG",{});var mTa=s(USe);XFt=r(mTa,"mt5"),mTa.forEach(t),zFt=r(Koo," \u2014 "),Lie=n(Koo,"A",{href:!0});var fTa=s(Lie);QFt=r(fTa,"FlaxMT5ForConditionalGeneration"),fTa.forEach(t),WFt=r(Koo," (MT5 model)"),Koo.forEach(t),UFt=i(Ge),a8=n(Ge,"LI",{});var ero=s(a8);HSe=n(ero,"STRONG",{});var gTa=s(HSe);HFt=r(gTa,"pegasus"),gTa.forEach(t),JFt=r(ero," \u2014 "),yie=n(ero,"A",{href:!0});var hTa=s(yie);YFt=r(hTa,"FlaxPegasusForConditionalGeneration"),hTa.forEach(t),ZFt=r(ero," (Pegasus model)"),ero.forEach(t),KFt=i(Ge),n8=n(Ge,"LI",{});var oro=s(n8);JSe=n(oro,"STRONG",{});var uTa=s(JSe);eTt=r(uTa,"t5"),uTa.forEach(t),oTt=r(oro," \u2014 "),xie=n(oro,"A",{href:!0});var pTa=s(xie);rTt=r(pTa,"FlaxT5ForConditionalGeneration"),pTa.forEach(t),tTt=r(oro," (T5 model)"),oro.forEach(t),Ge.forEach(t),aTt=i(od),T(s8.$$.fragment,od),od.forEach(t),ed.forEach(t),zao=i(m),vf=n(m,"H2",{class:!0});var flo=s(vf);l8=n(flo,"A",{id:!0,class:!0,href:!0});var _Ta=s(l8);YSe=n(_Ta,"SPAN",{});var bTa=s(YSe);T(aB.$$.fragment,bTa),bTa.forEach(t),_Ta.forEach(t),nTt=i(flo),ZSe=n(flo,"SPAN",{});var vTa=s(ZSe);sTt=r(vTa,"FlaxAutoModelForSequenceClassification"),vTa.forEach(t),flo.forEach(t),Qao=i(m),kr=n(m,"DIV",{class:!0});var rd=s(kr);T(nB.$$.fragment,rd),lTt=i(rd),Ff=n(rd,"P",{});var kme=s(Ff);iTt=r(kme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$ie=n(kme,"A",{href:!0});var FTa=s($ie);dTt=r(FTa,"from_pretrained()"),FTa.forEach(t),cTt=r(kme," class method or the "),kie=n(kme,"A",{href:!0});var TTa=s(kie);mTt=r(TTa,"from_config()"),TTa.forEach(t),fTt=r(kme,` class
method.`),kme.forEach(t),gTt=i(rd),sB=n(rd,"P",{});var glo=s(sB);hTt=r(glo,"This class cannot be instantiated directly using "),KSe=n(glo,"CODE",{});var MTa=s(KSe);uTt=r(MTa,"__init__()"),MTa.forEach(t),pTt=r(glo," (throws an error)."),glo.forEach(t),_Tt=i(rd),_a=n(rd,"DIV",{class:!0});var Ix=s(_a);T(lB.$$.fragment,Ix),bTt=i(Ix),eRe=n(Ix,"P",{});var ETa=s(eRe);vTt=r(ETa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ETa.forEach(t),FTt=i(Ix),Tf=n(Ix,"P",{});var Sme=s(Tf);TTt=r(Sme,`Note:
Loading a model from its configuration file does `),oRe=n(Sme,"STRONG",{});var CTa=s(oRe);MTt=r(CTa,"not"),CTa.forEach(t),ETt=r(Sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sie=n(Sme,"A",{href:!0});var wTa=s(Sie);CTt=r(wTa,"from_pretrained()"),wTa.forEach(t),wTt=r(Sme," to load the model weights."),Sme.forEach(t),ATt=i(Ix),T(i8.$$.fragment,Ix),Ix.forEach(t),LTt=i(rd),lt=n(rd,"DIV",{class:!0});var td=s(lt);T(iB.$$.fragment,td),yTt=i(td),rRe=n(td,"P",{});var ATa=s(rRe);xTt=r(ATa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ATa.forEach(t),$Tt=i(td),rs=n(td,"P",{});var Nx=s(rs);kTt=r(Nx,"The model class to instantiate is selected based on the "),tRe=n(Nx,"CODE",{});var LTa=s(tRe);STt=r(LTa,"model_type"),LTa.forEach(t),RTt=r(Nx,` property of the config object (either
passed as an argument or loaded from `),aRe=n(Nx,"CODE",{});var yTa=s(aRe);PTt=r(yTa,"pretrained_model_name_or_path"),yTa.forEach(t),BTt=r(Nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nRe=n(Nx,"CODE",{});var xTa=s(nRe);ITt=r(xTa,"pretrained_model_name_or_path"),xTa.forEach(t),NTt=r(Nx,":"),Nx.forEach(t),qTt=i(td),Re=n(td,"UL",{});var Oe=s(Re);d8=n(Oe,"LI",{});var rro=s(d8);sRe=n(rro,"STRONG",{});var $Ta=s(sRe);jTt=r($Ta,"albert"),$Ta.forEach(t),DTt=r(rro," \u2014 "),Rie=n(rro,"A",{href:!0});var kTa=s(Rie);GTt=r(kTa,"FlaxAlbertForSequenceClassification"),kTa.forEach(t),OTt=r(rro," (ALBERT model)"),rro.forEach(t),VTt=i(Oe),c8=n(Oe,"LI",{});var tro=s(c8);lRe=n(tro,"STRONG",{});var STa=s(lRe);XTt=r(STa,"bart"),STa.forEach(t),zTt=r(tro," \u2014 "),Pie=n(tro,"A",{href:!0});var RTa=s(Pie);QTt=r(RTa,"FlaxBartForSequenceClassification"),RTa.forEach(t),WTt=r(tro," (BART model)"),tro.forEach(t),UTt=i(Oe),m8=n(Oe,"LI",{});var aro=s(m8);iRe=n(aro,"STRONG",{});var PTa=s(iRe);HTt=r(PTa,"bert"),PTa.forEach(t),JTt=r(aro," \u2014 "),Bie=n(aro,"A",{href:!0});var BTa=s(Bie);YTt=r(BTa,"FlaxBertForSequenceClassification"),BTa.forEach(t),ZTt=r(aro," (BERT model)"),aro.forEach(t),KTt=i(Oe),f8=n(Oe,"LI",{});var nro=s(f8);dRe=n(nro,"STRONG",{});var ITa=s(dRe);eMt=r(ITa,"big_bird"),ITa.forEach(t),oMt=r(nro," \u2014 "),Iie=n(nro,"A",{href:!0});var NTa=s(Iie);rMt=r(NTa,"FlaxBigBirdForSequenceClassification"),NTa.forEach(t),tMt=r(nro," (BigBird model)"),nro.forEach(t),aMt=i(Oe),g8=n(Oe,"LI",{});var sro=s(g8);cRe=n(sro,"STRONG",{});var qTa=s(cRe);nMt=r(qTa,"distilbert"),qTa.forEach(t),sMt=r(sro," \u2014 "),Nie=n(sro,"A",{href:!0});var jTa=s(Nie);lMt=r(jTa,"FlaxDistilBertForSequenceClassification"),jTa.forEach(t),iMt=r(sro," (DistilBERT model)"),sro.forEach(t),dMt=i(Oe),h8=n(Oe,"LI",{});var lro=s(h8);mRe=n(lro,"STRONG",{});var DTa=s(mRe);cMt=r(DTa,"electra"),DTa.forEach(t),mMt=r(lro," \u2014 "),qie=n(lro,"A",{href:!0});var GTa=s(qie);fMt=r(GTa,"FlaxElectraForSequenceClassification"),GTa.forEach(t),gMt=r(lro," (ELECTRA model)"),lro.forEach(t),hMt=i(Oe),u8=n(Oe,"LI",{});var iro=s(u8);fRe=n(iro,"STRONG",{});var OTa=s(fRe);uMt=r(OTa,"mbart"),OTa.forEach(t),pMt=r(iro," \u2014 "),jie=n(iro,"A",{href:!0});var VTa=s(jie);_Mt=r(VTa,"FlaxMBartForSequenceClassification"),VTa.forEach(t),bMt=r(iro," (mBART model)"),iro.forEach(t),vMt=i(Oe),p8=n(Oe,"LI",{});var dro=s(p8);gRe=n(dro,"STRONG",{});var XTa=s(gRe);FMt=r(XTa,"roberta"),XTa.forEach(t),TMt=r(dro," \u2014 "),Die=n(dro,"A",{href:!0});var zTa=s(Die);MMt=r(zTa,"FlaxRobertaForSequenceClassification"),zTa.forEach(t),EMt=r(dro," (RoBERTa model)"),dro.forEach(t),CMt=i(Oe),_8=n(Oe,"LI",{});var cro=s(_8);hRe=n(cro,"STRONG",{});var QTa=s(hRe);wMt=r(QTa,"roformer"),QTa.forEach(t),AMt=r(cro," \u2014 "),Gie=n(cro,"A",{href:!0});var WTa=s(Gie);LMt=r(WTa,"FlaxRoFormerForSequenceClassification"),WTa.forEach(t),yMt=r(cro," (RoFormer model)"),cro.forEach(t),xMt=i(Oe),b8=n(Oe,"LI",{});var mro=s(b8);uRe=n(mro,"STRONG",{});var UTa=s(uRe);$Mt=r(UTa,"xlm-roberta"),UTa.forEach(t),kMt=r(mro," \u2014 "),Oie=n(mro,"A",{href:!0});var HTa=s(Oie);SMt=r(HTa,"FlaxXLMRobertaForSequenceClassification"),HTa.forEach(t),RMt=r(mro," (XLM-RoBERTa model)"),mro.forEach(t),Oe.forEach(t),PMt=i(td),T(v8.$$.fragment,td),td.forEach(t),rd.forEach(t),Wao=i(m),Mf=n(m,"H2",{class:!0});var hlo=s(Mf);F8=n(hlo,"A",{id:!0,class:!0,href:!0});var JTa=s(F8);pRe=n(JTa,"SPAN",{});var YTa=s(pRe);T(dB.$$.fragment,YTa),YTa.forEach(t),JTa.forEach(t),BMt=i(hlo),_Re=n(hlo,"SPAN",{});var ZTa=s(_Re);IMt=r(ZTa,"FlaxAutoModelForQuestionAnswering"),ZTa.forEach(t),hlo.forEach(t),Uao=i(m),Sr=n(m,"DIV",{class:!0});var ad=s(Sr);T(cB.$$.fragment,ad),NMt=i(ad),Ef=n(ad,"P",{});var Rme=s(Ef);qMt=r(Rme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Vie=n(Rme,"A",{href:!0});var KTa=s(Vie);jMt=r(KTa,"from_pretrained()"),KTa.forEach(t),DMt=r(Rme," class method or the "),Xie=n(Rme,"A",{href:!0});var eMa=s(Xie);GMt=r(eMa,"from_config()"),eMa.forEach(t),OMt=r(Rme,` class
method.`),Rme.forEach(t),VMt=i(ad),mB=n(ad,"P",{});var ulo=s(mB);XMt=r(ulo,"This class cannot be instantiated directly using "),bRe=n(ulo,"CODE",{});var oMa=s(bRe);zMt=r(oMa,"__init__()"),oMa.forEach(t),QMt=r(ulo," (throws an error)."),ulo.forEach(t),WMt=i(ad),ba=n(ad,"DIV",{class:!0});var qx=s(ba);T(fB.$$.fragment,qx),UMt=i(qx),vRe=n(qx,"P",{});var rMa=s(vRe);HMt=r(rMa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),rMa.forEach(t),JMt=i(qx),Cf=n(qx,"P",{});var Pme=s(Cf);YMt=r(Pme,`Note:
Loading a model from its configuration file does `),FRe=n(Pme,"STRONG",{});var tMa=s(FRe);ZMt=r(tMa,"not"),tMa.forEach(t),KMt=r(Pme,` load the model weights. It only affects the
model\u2019s configuration. Use `),zie=n(Pme,"A",{href:!0});var aMa=s(zie);eEt=r(aMa,"from_pretrained()"),aMa.forEach(t),oEt=r(Pme," to load the model weights."),Pme.forEach(t),rEt=i(qx),T(T8.$$.fragment,qx),qx.forEach(t),tEt=i(ad),it=n(ad,"DIV",{class:!0});var nd=s(it);T(gB.$$.fragment,nd),aEt=i(nd),TRe=n(nd,"P",{});var nMa=s(TRe);nEt=r(nMa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),nMa.forEach(t),sEt=i(nd),ts=n(nd,"P",{});var jx=s(ts);lEt=r(jx,"The model class to instantiate is selected based on the "),MRe=n(jx,"CODE",{});var sMa=s(MRe);iEt=r(sMa,"model_type"),sMa.forEach(t),dEt=r(jx,` property of the config object (either
passed as an argument or loaded from `),ERe=n(jx,"CODE",{});var lMa=s(ERe);cEt=r(lMa,"pretrained_model_name_or_path"),lMa.forEach(t),mEt=r(jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CRe=n(jx,"CODE",{});var iMa=s(CRe);fEt=r(iMa,"pretrained_model_name_or_path"),iMa.forEach(t),gEt=r(jx,":"),jx.forEach(t),hEt=i(nd),Pe=n(nd,"UL",{});var Ve=s(Pe);M8=n(Ve,"LI",{});var fro=s(M8);wRe=n(fro,"STRONG",{});var dMa=s(wRe);uEt=r(dMa,"albert"),dMa.forEach(t),pEt=r(fro," \u2014 "),Qie=n(fro,"A",{href:!0});var cMa=s(Qie);_Et=r(cMa,"FlaxAlbertForQuestionAnswering"),cMa.forEach(t),bEt=r(fro," (ALBERT model)"),fro.forEach(t),vEt=i(Ve),E8=n(Ve,"LI",{});var gro=s(E8);ARe=n(gro,"STRONG",{});var mMa=s(ARe);FEt=r(mMa,"bart"),mMa.forEach(t),TEt=r(gro," \u2014 "),Wie=n(gro,"A",{href:!0});var fMa=s(Wie);MEt=r(fMa,"FlaxBartForQuestionAnswering"),fMa.forEach(t),EEt=r(gro," (BART model)"),gro.forEach(t),CEt=i(Ve),C8=n(Ve,"LI",{});var hro=s(C8);LRe=n(hro,"STRONG",{});var gMa=s(LRe);wEt=r(gMa,"bert"),gMa.forEach(t),AEt=r(hro," \u2014 "),Uie=n(hro,"A",{href:!0});var hMa=s(Uie);LEt=r(hMa,"FlaxBertForQuestionAnswering"),hMa.forEach(t),yEt=r(hro," (BERT model)"),hro.forEach(t),xEt=i(Ve),w8=n(Ve,"LI",{});var uro=s(w8);yRe=n(uro,"STRONG",{});var uMa=s(yRe);$Et=r(uMa,"big_bird"),uMa.forEach(t),kEt=r(uro," \u2014 "),Hie=n(uro,"A",{href:!0});var pMa=s(Hie);SEt=r(pMa,"FlaxBigBirdForQuestionAnswering"),pMa.forEach(t),REt=r(uro," (BigBird model)"),uro.forEach(t),PEt=i(Ve),A8=n(Ve,"LI",{});var pro=s(A8);xRe=n(pro,"STRONG",{});var _Ma=s(xRe);BEt=r(_Ma,"distilbert"),_Ma.forEach(t),IEt=r(pro," \u2014 "),Jie=n(pro,"A",{href:!0});var bMa=s(Jie);NEt=r(bMa,"FlaxDistilBertForQuestionAnswering"),bMa.forEach(t),qEt=r(pro," (DistilBERT model)"),pro.forEach(t),jEt=i(Ve),L8=n(Ve,"LI",{});var _ro=s(L8);$Re=n(_ro,"STRONG",{});var vMa=s($Re);DEt=r(vMa,"electra"),vMa.forEach(t),GEt=r(_ro," \u2014 "),Yie=n(_ro,"A",{href:!0});var FMa=s(Yie);OEt=r(FMa,"FlaxElectraForQuestionAnswering"),FMa.forEach(t),VEt=r(_ro," (ELECTRA model)"),_ro.forEach(t),XEt=i(Ve),y8=n(Ve,"LI",{});var bro=s(y8);kRe=n(bro,"STRONG",{});var TMa=s(kRe);zEt=r(TMa,"mbart"),TMa.forEach(t),QEt=r(bro," \u2014 "),Zie=n(bro,"A",{href:!0});var MMa=s(Zie);WEt=r(MMa,"FlaxMBartForQuestionAnswering"),MMa.forEach(t),UEt=r(bro," (mBART model)"),bro.forEach(t),HEt=i(Ve),x8=n(Ve,"LI",{});var vro=s(x8);SRe=n(vro,"STRONG",{});var EMa=s(SRe);JEt=r(EMa,"roberta"),EMa.forEach(t),YEt=r(vro," \u2014 "),Kie=n(vro,"A",{href:!0});var CMa=s(Kie);ZEt=r(CMa,"FlaxRobertaForQuestionAnswering"),CMa.forEach(t),KEt=r(vro," (RoBERTa model)"),vro.forEach(t),e4t=i(Ve),$8=n(Ve,"LI",{});var Fro=s($8);RRe=n(Fro,"STRONG",{});var wMa=s(RRe);o4t=r(wMa,"roformer"),wMa.forEach(t),r4t=r(Fro," \u2014 "),ede=n(Fro,"A",{href:!0});var AMa=s(ede);t4t=r(AMa,"FlaxRoFormerForQuestionAnswering"),AMa.forEach(t),a4t=r(Fro," (RoFormer model)"),Fro.forEach(t),n4t=i(Ve),k8=n(Ve,"LI",{});var Tro=s(k8);PRe=n(Tro,"STRONG",{});var LMa=s(PRe);s4t=r(LMa,"xlm-roberta"),LMa.forEach(t),l4t=r(Tro," \u2014 "),ode=n(Tro,"A",{href:!0});var yMa=s(ode);i4t=r(yMa,"FlaxXLMRobertaForQuestionAnswering"),yMa.forEach(t),d4t=r(Tro," (XLM-RoBERTa model)"),Tro.forEach(t),Ve.forEach(t),c4t=i(nd),T(S8.$$.fragment,nd),nd.forEach(t),ad.forEach(t),Hao=i(m),wf=n(m,"H2",{class:!0});var plo=s(wf);R8=n(plo,"A",{id:!0,class:!0,href:!0});var xMa=s(R8);BRe=n(xMa,"SPAN",{});var $Ma=s(BRe);T(hB.$$.fragment,$Ma),$Ma.forEach(t),xMa.forEach(t),m4t=i(plo),IRe=n(plo,"SPAN",{});var kMa=s(IRe);f4t=r(kMa,"FlaxAutoModelForTokenClassification"),kMa.forEach(t),plo.forEach(t),Jao=i(m),Rr=n(m,"DIV",{class:!0});var sd=s(Rr);T(uB.$$.fragment,sd),g4t=i(sd),Af=n(sd,"P",{});var Bme=s(Af);h4t=r(Bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),rde=n(Bme,"A",{href:!0});var SMa=s(rde);u4t=r(SMa,"from_pretrained()"),SMa.forEach(t),p4t=r(Bme," class method or the "),tde=n(Bme,"A",{href:!0});var RMa=s(tde);_4t=r(RMa,"from_config()"),RMa.forEach(t),b4t=r(Bme,` class
method.`),Bme.forEach(t),v4t=i(sd),pB=n(sd,"P",{});var _lo=s(pB);F4t=r(_lo,"This class cannot be instantiated directly using "),NRe=n(_lo,"CODE",{});var PMa=s(NRe);T4t=r(PMa,"__init__()"),PMa.forEach(t),M4t=r(_lo," (throws an error)."),_lo.forEach(t),E4t=i(sd),va=n(sd,"DIV",{class:!0});var Dx=s(va);T(_B.$$.fragment,Dx),C4t=i(Dx),qRe=n(Dx,"P",{});var BMa=s(qRe);w4t=r(BMa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),BMa.forEach(t),A4t=i(Dx),Lf=n(Dx,"P",{});var Ime=s(Lf);L4t=r(Ime,`Note:
Loading a model from its configuration file does `),jRe=n(Ime,"STRONG",{});var IMa=s(jRe);y4t=r(IMa,"not"),IMa.forEach(t),x4t=r(Ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),ade=n(Ime,"A",{href:!0});var NMa=s(ade);$4t=r(NMa,"from_pretrained()"),NMa.forEach(t),k4t=r(Ime," to load the model weights."),Ime.forEach(t),S4t=i(Dx),T(P8.$$.fragment,Dx),Dx.forEach(t),R4t=i(sd),dt=n(sd,"DIV",{class:!0});var ld=s(dt);T(bB.$$.fragment,ld),P4t=i(ld),DRe=n(ld,"P",{});var qMa=s(DRe);B4t=r(qMa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qMa.forEach(t),I4t=i(ld),as=n(ld,"P",{});var Gx=s(as);N4t=r(Gx,"The model class to instantiate is selected based on the "),GRe=n(Gx,"CODE",{});var jMa=s(GRe);q4t=r(jMa,"model_type"),jMa.forEach(t),j4t=r(Gx,` property of the config object (either
passed as an argument or loaded from `),ORe=n(Gx,"CODE",{});var DMa=s(ORe);D4t=r(DMa,"pretrained_model_name_or_path"),DMa.forEach(t),G4t=r(Gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VRe=n(Gx,"CODE",{});var GMa=s(VRe);O4t=r(GMa,"pretrained_model_name_or_path"),GMa.forEach(t),V4t=r(Gx,":"),Gx.forEach(t),X4t=i(ld),ze=n(ld,"UL",{});var yo=s(ze);B8=n(yo,"LI",{});var Mro=s(B8);XRe=n(Mro,"STRONG",{});var OMa=s(XRe);z4t=r(OMa,"albert"),OMa.forEach(t),Q4t=r(Mro," \u2014 "),nde=n(Mro,"A",{href:!0});var VMa=s(nde);W4t=r(VMa,"FlaxAlbertForTokenClassification"),VMa.forEach(t),U4t=r(Mro," (ALBERT model)"),Mro.forEach(t),H4t=i(yo),I8=n(yo,"LI",{});var Ero=s(I8);zRe=n(Ero,"STRONG",{});var XMa=s(zRe);J4t=r(XMa,"bert"),XMa.forEach(t),Y4t=r(Ero," \u2014 "),sde=n(Ero,"A",{href:!0});var zMa=s(sde);Z4t=r(zMa,"FlaxBertForTokenClassification"),zMa.forEach(t),K4t=r(Ero," (BERT model)"),Ero.forEach(t),eCt=i(yo),N8=n(yo,"LI",{});var Cro=s(N8);QRe=n(Cro,"STRONG",{});var QMa=s(QRe);oCt=r(QMa,"big_bird"),QMa.forEach(t),rCt=r(Cro," \u2014 "),lde=n(Cro,"A",{href:!0});var WMa=s(lde);tCt=r(WMa,"FlaxBigBirdForTokenClassification"),WMa.forEach(t),aCt=r(Cro," (BigBird model)"),Cro.forEach(t),nCt=i(yo),q8=n(yo,"LI",{});var wro=s(q8);WRe=n(wro,"STRONG",{});var UMa=s(WRe);sCt=r(UMa,"distilbert"),UMa.forEach(t),lCt=r(wro," \u2014 "),ide=n(wro,"A",{href:!0});var HMa=s(ide);iCt=r(HMa,"FlaxDistilBertForTokenClassification"),HMa.forEach(t),dCt=r(wro," (DistilBERT model)"),wro.forEach(t),cCt=i(yo),j8=n(yo,"LI",{});var Aro=s(j8);URe=n(Aro,"STRONG",{});var JMa=s(URe);mCt=r(JMa,"electra"),JMa.forEach(t),fCt=r(Aro," \u2014 "),dde=n(Aro,"A",{href:!0});var YMa=s(dde);gCt=r(YMa,"FlaxElectraForTokenClassification"),YMa.forEach(t),hCt=r(Aro," (ELECTRA model)"),Aro.forEach(t),uCt=i(yo),D8=n(yo,"LI",{});var Lro=s(D8);HRe=n(Lro,"STRONG",{});var ZMa=s(HRe);pCt=r(ZMa,"roberta"),ZMa.forEach(t),_Ct=r(Lro," \u2014 "),cde=n(Lro,"A",{href:!0});var KMa=s(cde);bCt=r(KMa,"FlaxRobertaForTokenClassification"),KMa.forEach(t),vCt=r(Lro," (RoBERTa model)"),Lro.forEach(t),FCt=i(yo),G8=n(yo,"LI",{});var yro=s(G8);JRe=n(yro,"STRONG",{});var eEa=s(JRe);TCt=r(eEa,"roformer"),eEa.forEach(t),MCt=r(yro," \u2014 "),mde=n(yro,"A",{href:!0});var oEa=s(mde);ECt=r(oEa,"FlaxRoFormerForTokenClassification"),oEa.forEach(t),CCt=r(yro," (RoFormer model)"),yro.forEach(t),wCt=i(yo),O8=n(yo,"LI",{});var xro=s(O8);YRe=n(xro,"STRONG",{});var rEa=s(YRe);ACt=r(rEa,"xlm-roberta"),rEa.forEach(t),LCt=r(xro," \u2014 "),fde=n(xro,"A",{href:!0});var tEa=s(fde);yCt=r(tEa,"FlaxXLMRobertaForTokenClassification"),tEa.forEach(t),xCt=r(xro," (XLM-RoBERTa model)"),xro.forEach(t),yo.forEach(t),$Ct=i(ld),T(V8.$$.fragment,ld),ld.forEach(t),sd.forEach(t),Yao=i(m),yf=n(m,"H2",{class:!0});var blo=s(yf);X8=n(blo,"A",{id:!0,class:!0,href:!0});var aEa=s(X8);ZRe=n(aEa,"SPAN",{});var nEa=s(ZRe);T(vB.$$.fragment,nEa),nEa.forEach(t),aEa.forEach(t),kCt=i(blo),KRe=n(blo,"SPAN",{});var sEa=s(KRe);SCt=r(sEa,"FlaxAutoModelForMultipleChoice"),sEa.forEach(t),blo.forEach(t),Zao=i(m),Pr=n(m,"DIV",{class:!0});var id=s(Pr);T(FB.$$.fragment,id),RCt=i(id),xf=n(id,"P",{});var Nme=s(xf);PCt=r(Nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),gde=n(Nme,"A",{href:!0});var lEa=s(gde);BCt=r(lEa,"from_pretrained()"),lEa.forEach(t),ICt=r(Nme," class method or the "),hde=n(Nme,"A",{href:!0});var iEa=s(hde);NCt=r(iEa,"from_config()"),iEa.forEach(t),qCt=r(Nme,` class
method.`),Nme.forEach(t),jCt=i(id),TB=n(id,"P",{});var vlo=s(TB);DCt=r(vlo,"This class cannot be instantiated directly using "),ePe=n(vlo,"CODE",{});var dEa=s(ePe);GCt=r(dEa,"__init__()"),dEa.forEach(t),OCt=r(vlo," (throws an error)."),vlo.forEach(t),VCt=i(id),Fa=n(id,"DIV",{class:!0});var Ox=s(Fa);T(MB.$$.fragment,Ox),XCt=i(Ox),oPe=n(Ox,"P",{});var cEa=s(oPe);zCt=r(cEa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),cEa.forEach(t),QCt=i(Ox),$f=n(Ox,"P",{});var qme=s($f);WCt=r(qme,`Note:
Loading a model from its configuration file does `),rPe=n(qme,"STRONG",{});var mEa=s(rPe);UCt=r(mEa,"not"),mEa.forEach(t),HCt=r(qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ude=n(qme,"A",{href:!0});var fEa=s(ude);JCt=r(fEa,"from_pretrained()"),fEa.forEach(t),YCt=r(qme," to load the model weights."),qme.forEach(t),ZCt=i(Ox),T(z8.$$.fragment,Ox),Ox.forEach(t),KCt=i(id),ct=n(id,"DIV",{class:!0});var dd=s(ct);T(EB.$$.fragment,dd),e3t=i(dd),tPe=n(dd,"P",{});var gEa=s(tPe);o3t=r(gEa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gEa.forEach(t),r3t=i(dd),ns=n(dd,"P",{});var Vx=s(ns);t3t=r(Vx,"The model class to instantiate is selected based on the "),aPe=n(Vx,"CODE",{});var hEa=s(aPe);a3t=r(hEa,"model_type"),hEa.forEach(t),n3t=r(Vx,` property of the config object (either
passed as an argument or loaded from `),nPe=n(Vx,"CODE",{});var uEa=s(nPe);s3t=r(uEa,"pretrained_model_name_or_path"),uEa.forEach(t),l3t=r(Vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sPe=n(Vx,"CODE",{});var pEa=s(sPe);i3t=r(pEa,"pretrained_model_name_or_path"),pEa.forEach(t),d3t=r(Vx,":"),Vx.forEach(t),c3t=i(dd),Qe=n(dd,"UL",{});var xo=s(Qe);Q8=n(xo,"LI",{});var $ro=s(Q8);lPe=n($ro,"STRONG",{});var _Ea=s(lPe);m3t=r(_Ea,"albert"),_Ea.forEach(t),f3t=r($ro," \u2014 "),pde=n($ro,"A",{href:!0});var bEa=s(pde);g3t=r(bEa,"FlaxAlbertForMultipleChoice"),bEa.forEach(t),h3t=r($ro," (ALBERT model)"),$ro.forEach(t),u3t=i(xo),W8=n(xo,"LI",{});var kro=s(W8);iPe=n(kro,"STRONG",{});var vEa=s(iPe);p3t=r(vEa,"bert"),vEa.forEach(t),_3t=r(kro," \u2014 "),_de=n(kro,"A",{href:!0});var FEa=s(_de);b3t=r(FEa,"FlaxBertForMultipleChoice"),FEa.forEach(t),v3t=r(kro," (BERT model)"),kro.forEach(t),F3t=i(xo),U8=n(xo,"LI",{});var Sro=s(U8);dPe=n(Sro,"STRONG",{});var TEa=s(dPe);T3t=r(TEa,"big_bird"),TEa.forEach(t),M3t=r(Sro," \u2014 "),bde=n(Sro,"A",{href:!0});var MEa=s(bde);E3t=r(MEa,"FlaxBigBirdForMultipleChoice"),MEa.forEach(t),C3t=r(Sro," (BigBird model)"),Sro.forEach(t),w3t=i(xo),H8=n(xo,"LI",{});var Rro=s(H8);cPe=n(Rro,"STRONG",{});var EEa=s(cPe);A3t=r(EEa,"distilbert"),EEa.forEach(t),L3t=r(Rro," \u2014 "),vde=n(Rro,"A",{href:!0});var CEa=s(vde);y3t=r(CEa,"FlaxDistilBertForMultipleChoice"),CEa.forEach(t),x3t=r(Rro," (DistilBERT model)"),Rro.forEach(t),$3t=i(xo),J8=n(xo,"LI",{});var Pro=s(J8);mPe=n(Pro,"STRONG",{});var wEa=s(mPe);k3t=r(wEa,"electra"),wEa.forEach(t),S3t=r(Pro," \u2014 "),Fde=n(Pro,"A",{href:!0});var AEa=s(Fde);R3t=r(AEa,"FlaxElectraForMultipleChoice"),AEa.forEach(t),P3t=r(Pro," (ELECTRA model)"),Pro.forEach(t),B3t=i(xo),Y8=n(xo,"LI",{});var Bro=s(Y8);fPe=n(Bro,"STRONG",{});var LEa=s(fPe);I3t=r(LEa,"roberta"),LEa.forEach(t),N3t=r(Bro," \u2014 "),Tde=n(Bro,"A",{href:!0});var yEa=s(Tde);q3t=r(yEa,"FlaxRobertaForMultipleChoice"),yEa.forEach(t),j3t=r(Bro," (RoBERTa model)"),Bro.forEach(t),D3t=i(xo),Z8=n(xo,"LI",{});var Iro=s(Z8);gPe=n(Iro,"STRONG",{});var xEa=s(gPe);G3t=r(xEa,"roformer"),xEa.forEach(t),O3t=r(Iro," \u2014 "),Mde=n(Iro,"A",{href:!0});var $Ea=s(Mde);V3t=r($Ea,"FlaxRoFormerForMultipleChoice"),$Ea.forEach(t),X3t=r(Iro," (RoFormer model)"),Iro.forEach(t),z3t=i(xo),K8=n(xo,"LI",{});var Nro=s(K8);hPe=n(Nro,"STRONG",{});var kEa=s(hPe);Q3t=r(kEa,"xlm-roberta"),kEa.forEach(t),W3t=r(Nro," \u2014 "),Ede=n(Nro,"A",{href:!0});var SEa=s(Ede);U3t=r(SEa,"FlaxXLMRobertaForMultipleChoice"),SEa.forEach(t),H3t=r(Nro," (XLM-RoBERTa model)"),Nro.forEach(t),xo.forEach(t),J3t=i(dd),T(ey.$$.fragment,dd),dd.forEach(t),id.forEach(t),Kao=i(m),kf=n(m,"H2",{class:!0});var Flo=s(kf);oy=n(Flo,"A",{id:!0,class:!0,href:!0});var REa=s(oy);uPe=n(REa,"SPAN",{});var PEa=s(uPe);T(CB.$$.fragment,PEa),PEa.forEach(t),REa.forEach(t),Y3t=i(Flo),pPe=n(Flo,"SPAN",{});var BEa=s(pPe);Z3t=r(BEa,"FlaxAutoModelForNextSentencePrediction"),BEa.forEach(t),Flo.forEach(t),eno=i(m),Br=n(m,"DIV",{class:!0});var cd=s(Br);T(wB.$$.fragment,cd),K3t=i(cd),Sf=n(cd,"P",{});var jme=s(Sf);e5t=r(jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Cde=n(jme,"A",{href:!0});var IEa=s(Cde);o5t=r(IEa,"from_pretrained()"),IEa.forEach(t),r5t=r(jme," class method or the "),wde=n(jme,"A",{href:!0});var NEa=s(wde);t5t=r(NEa,"from_config()"),NEa.forEach(t),a5t=r(jme,` class
method.`),jme.forEach(t),n5t=i(cd),AB=n(cd,"P",{});var Tlo=s(AB);s5t=r(Tlo,"This class cannot be instantiated directly using "),_Pe=n(Tlo,"CODE",{});var qEa=s(_Pe);l5t=r(qEa,"__init__()"),qEa.forEach(t),i5t=r(Tlo," (throws an error)."),Tlo.forEach(t),d5t=i(cd),Ta=n(cd,"DIV",{class:!0});var Xx=s(Ta);T(LB.$$.fragment,Xx),c5t=i(Xx),bPe=n(Xx,"P",{});var jEa=s(bPe);m5t=r(jEa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jEa.forEach(t),f5t=i(Xx),Rf=n(Xx,"P",{});var Dme=s(Rf);g5t=r(Dme,`Note:
Loading a model from its configuration file does `),vPe=n(Dme,"STRONG",{});var DEa=s(vPe);h5t=r(DEa,"not"),DEa.forEach(t),u5t=r(Dme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ade=n(Dme,"A",{href:!0});var GEa=s(Ade);p5t=r(GEa,"from_pretrained()"),GEa.forEach(t),_5t=r(Dme," to load the model weights."),Dme.forEach(t),b5t=i(Xx),T(ry.$$.fragment,Xx),Xx.forEach(t),v5t=i(cd),mt=n(cd,"DIV",{class:!0});var md=s(mt);T(yB.$$.fragment,md),F5t=i(md),FPe=n(md,"P",{});var OEa=s(FPe);T5t=r(OEa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),OEa.forEach(t),M5t=i(md),ss=n(md,"P",{});var zx=s(ss);E5t=r(zx,"The model class to instantiate is selected based on the "),TPe=n(zx,"CODE",{});var VEa=s(TPe);C5t=r(VEa,"model_type"),VEa.forEach(t),w5t=r(zx,` property of the config object (either
passed as an argument or loaded from `),MPe=n(zx,"CODE",{});var XEa=s(MPe);A5t=r(XEa,"pretrained_model_name_or_path"),XEa.forEach(t),L5t=r(zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EPe=n(zx,"CODE",{});var zEa=s(EPe);y5t=r(zEa,"pretrained_model_name_or_path"),zEa.forEach(t),x5t=r(zx,":"),zx.forEach(t),$5t=i(md),CPe=n(md,"UL",{});var QEa=s(CPe);ty=n(QEa,"LI",{});var qro=s(ty);wPe=n(qro,"STRONG",{});var WEa=s(wPe);k5t=r(WEa,"bert"),WEa.forEach(t),S5t=r(qro," \u2014 "),Lde=n(qro,"A",{href:!0});var UEa=s(Lde);R5t=r(UEa,"FlaxBertForNextSentencePrediction"),UEa.forEach(t),P5t=r(qro," (BERT model)"),qro.forEach(t),QEa.forEach(t),B5t=i(md),T(ay.$$.fragment,md),md.forEach(t),cd.forEach(t),ono=i(m),Pf=n(m,"H2",{class:!0});var Mlo=s(Pf);ny=n(Mlo,"A",{id:!0,class:!0,href:!0});var HEa=s(ny);APe=n(HEa,"SPAN",{});var JEa=s(APe);T(xB.$$.fragment,JEa),JEa.forEach(t),HEa.forEach(t),I5t=i(Mlo),LPe=n(Mlo,"SPAN",{});var YEa=s(LPe);N5t=r(YEa,"FlaxAutoModelForImageClassification"),YEa.forEach(t),Mlo.forEach(t),rno=i(m),Ir=n(m,"DIV",{class:!0});var fd=s(Ir);T($B.$$.fragment,fd),q5t=i(fd),Bf=n(fd,"P",{});var Gme=s(Bf);j5t=r(Gme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),yde=n(Gme,"A",{href:!0});var ZEa=s(yde);D5t=r(ZEa,"from_pretrained()"),ZEa.forEach(t),G5t=r(Gme," class method or the "),xde=n(Gme,"A",{href:!0});var KEa=s(xde);O5t=r(KEa,"from_config()"),KEa.forEach(t),V5t=r(Gme,` class
method.`),Gme.forEach(t),X5t=i(fd),kB=n(fd,"P",{});var Elo=s(kB);z5t=r(Elo,"This class cannot be instantiated directly using "),yPe=n(Elo,"CODE",{});var e4a=s(yPe);Q5t=r(e4a,"__init__()"),e4a.forEach(t),W5t=r(Elo," (throws an error)."),Elo.forEach(t),U5t=i(fd),Ma=n(fd,"DIV",{class:!0});var Qx=s(Ma);T(SB.$$.fragment,Qx),H5t=i(Qx),xPe=n(Qx,"P",{});var o4a=s(xPe);J5t=r(o4a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),o4a.forEach(t),Y5t=i(Qx),If=n(Qx,"P",{});var Ome=s(If);Z5t=r(Ome,`Note:
Loading a model from its configuration file does `),$Pe=n(Ome,"STRONG",{});var r4a=s($Pe);K5t=r(r4a,"not"),r4a.forEach(t),e0t=r(Ome,` load the model weights. It only affects the
model\u2019s configuration. Use `),$de=n(Ome,"A",{href:!0});var t4a=s($de);o0t=r(t4a,"from_pretrained()"),t4a.forEach(t),r0t=r(Ome," to load the model weights."),Ome.forEach(t),t0t=i(Qx),T(sy.$$.fragment,Qx),Qx.forEach(t),a0t=i(fd),ft=n(fd,"DIV",{class:!0});var gd=s(ft);T(RB.$$.fragment,gd),n0t=i(gd),kPe=n(gd,"P",{});var a4a=s(kPe);s0t=r(a4a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),a4a.forEach(t),l0t=i(gd),ls=n(gd,"P",{});var Wx=s(ls);i0t=r(Wx,"The model class to instantiate is selected based on the "),SPe=n(Wx,"CODE",{});var n4a=s(SPe);d0t=r(n4a,"model_type"),n4a.forEach(t),c0t=r(Wx,` property of the config object (either
passed as an argument or loaded from `),RPe=n(Wx,"CODE",{});var s4a=s(RPe);m0t=r(s4a,"pretrained_model_name_or_path"),s4a.forEach(t),f0t=r(Wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PPe=n(Wx,"CODE",{});var l4a=s(PPe);g0t=r(l4a,"pretrained_model_name_or_path"),l4a.forEach(t),h0t=r(Wx,":"),Wx.forEach(t),u0t=i(gd),PB=n(gd,"UL",{});var Clo=s(PB);ly=n(Clo,"LI",{});var jro=s(ly);BPe=n(jro,"STRONG",{});var i4a=s(BPe);p0t=r(i4a,"beit"),i4a.forEach(t),_0t=r(jro," \u2014 "),kde=n(jro,"A",{href:!0});var d4a=s(kde);b0t=r(d4a,"FlaxBeitForImageClassification"),d4a.forEach(t),v0t=r(jro," (BEiT model)"),jro.forEach(t),F0t=i(Clo),iy=n(Clo,"LI",{});var Dro=s(iy);IPe=n(Dro,"STRONG",{});var c4a=s(IPe);T0t=r(c4a,"vit"),c4a.forEach(t),M0t=r(Dro," \u2014 "),Sde=n(Dro,"A",{href:!0});var m4a=s(Sde);E0t=r(m4a,"FlaxViTForImageClassification"),m4a.forEach(t),C0t=r(Dro," (ViT model)"),Dro.forEach(t),Clo.forEach(t),w0t=i(gd),T(dy.$$.fragment,gd),gd.forEach(t),fd.forEach(t),tno=i(m),Nf=n(m,"H2",{class:!0});var wlo=s(Nf);cy=n(wlo,"A",{id:!0,class:!0,href:!0});var f4a=s(cy);NPe=n(f4a,"SPAN",{});var g4a=s(NPe);T(BB.$$.fragment,g4a),g4a.forEach(t),f4a.forEach(t),A0t=i(wlo),qPe=n(wlo,"SPAN",{});var h4a=s(qPe);L0t=r(h4a,"FlaxAutoModelForVision2Seq"),h4a.forEach(t),wlo.forEach(t),ano=i(m),Nr=n(m,"DIV",{class:!0});var hd=s(Nr);T(IB.$$.fragment,hd),y0t=i(hd),qf=n(hd,"P",{});var Vme=s(qf);x0t=r(Vme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Rde=n(Vme,"A",{href:!0});var u4a=s(Rde);$0t=r(u4a,"from_pretrained()"),u4a.forEach(t),k0t=r(Vme," class method or the "),Pde=n(Vme,"A",{href:!0});var p4a=s(Pde);S0t=r(p4a,"from_config()"),p4a.forEach(t),R0t=r(Vme,` class
method.`),Vme.forEach(t),P0t=i(hd),NB=n(hd,"P",{});var Alo=s(NB);B0t=r(Alo,"This class cannot be instantiated directly using "),jPe=n(Alo,"CODE",{});var _4a=s(jPe);I0t=r(_4a,"__init__()"),_4a.forEach(t),N0t=r(Alo," (throws an error)."),Alo.forEach(t),q0t=i(hd),Ea=n(hd,"DIV",{class:!0});var Ux=s(Ea);T(qB.$$.fragment,Ux),j0t=i(Ux),DPe=n(Ux,"P",{});var b4a=s(DPe);D0t=r(b4a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),b4a.forEach(t),G0t=i(Ux),jf=n(Ux,"P",{});var Xme=s(jf);O0t=r(Xme,`Note:
Loading a model from its configuration file does `),GPe=n(Xme,"STRONG",{});var v4a=s(GPe);V0t=r(v4a,"not"),v4a.forEach(t),X0t=r(Xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bde=n(Xme,"A",{href:!0});var F4a=s(Bde);z0t=r(F4a,"from_pretrained()"),F4a.forEach(t),Q0t=r(Xme," to load the model weights."),Xme.forEach(t),W0t=i(Ux),T(my.$$.fragment,Ux),Ux.forEach(t),U0t=i(hd),gt=n(hd,"DIV",{class:!0});var ud=s(gt);T(jB.$$.fragment,ud),H0t=i(ud),OPe=n(ud,"P",{});var T4a=s(OPe);J0t=r(T4a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),T4a.forEach(t),Y0t=i(ud),is=n(ud,"P",{});var Hx=s(is);Z0t=r(Hx,"The model class to instantiate is selected based on the "),VPe=n(Hx,"CODE",{});var M4a=s(VPe);K0t=r(M4a,"model_type"),M4a.forEach(t),ewt=r(Hx,` property of the config object (either
passed as an argument or loaded from `),XPe=n(Hx,"CODE",{});var E4a=s(XPe);owt=r(E4a,"pretrained_model_name_or_path"),E4a.forEach(t),rwt=r(Hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zPe=n(Hx,"CODE",{});var C4a=s(zPe);twt=r(C4a,"pretrained_model_name_or_path"),C4a.forEach(t),awt=r(Hx,":"),Hx.forEach(t),nwt=i(ud),QPe=n(ud,"UL",{});var w4a=s(QPe);fy=n(w4a,"LI",{});var Gro=s(fy);WPe=n(Gro,"STRONG",{});var A4a=s(WPe);swt=r(A4a,"vision-encoder-decoder"),A4a.forEach(t),lwt=r(Gro," \u2014 "),Ide=n(Gro,"A",{href:!0});var L4a=s(Ide);iwt=r(L4a,"FlaxVisionEncoderDecoderModel"),L4a.forEach(t),dwt=r(Gro," (Vision Encoder decoder model)"),Gro.forEach(t),w4a.forEach(t),cwt=i(ud),T(gy.$$.fragment,ud),ud.forEach(t),hd.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(z3a)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(cs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(Md,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(Wf,"id","extending-the-auto-classes"),c(Wf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wf,"href","#extending-the-auto-classes"),c(Ed,"class","relative group"),c(Hf,"id","transformers.AutoConfig"),c(Hf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hf,"href","#transformers.AutoConfig"),c(Cd,"class","relative group"),c(bN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(vN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(FN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(TN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(MN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(EN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(CN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(wN,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(AN,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(LN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(yN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(xN,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c($N,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(kN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(SN,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),c(RN,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),c(PN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(BN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(IN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(NN,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(qN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(jN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(DN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(GN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c(ON,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(VN,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(XN,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(zN,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(QN,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(WN,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c(UN,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),c(HN,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(JN,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(YN,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(ZN,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(KN,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),c(eq,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),c(oq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(rq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(tq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(aq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(nq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(sq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c(lq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(iq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(dq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(cq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),c(mq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c(fq,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),c(gq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(hq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(uq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(pq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(_q,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(bq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(vq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(Fq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(Tq,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),c(Mq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c(Eq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(Cq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(wq,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(Aq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(Lq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(yq,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),c(xq,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c($q,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(kq,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(Sq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(Rq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(Pq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(Bq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(Iq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(Nq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),c(qq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(jq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(Dq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(Gq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(Oq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),c(Vq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(Xq,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(zq,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(Qq,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(Wq,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(Uq,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(Hq,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(Jq,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(Yq,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(Zq,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(Kq,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c(ej,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(oj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(rj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(tj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(aj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(nj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(sj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(lj,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c(ij,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(dj,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(cj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(mj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(fj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(gj,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(hj,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),c(uj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(pj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(_j,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),c(bj,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(vj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(Fj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(Tj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(Mj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(Ej,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(Cj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),c(wj,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(Aj,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(Lj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(yj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(xj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c($j,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(kj,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),c(Sj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(Rj,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(Pj,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(Bj,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),c(Ij,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),c(Nj,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(qj,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(jj,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(Dj,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(Gj,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(Oj,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(Vj,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(Xj,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cu,"id","transformers.AutoTokenizer"),c(Cu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Cu,"href","#transformers.AutoTokenizer"),c(Ad,"class","relative group"),c(zj,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(Qj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(Wj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Uj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(Hj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(Jj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(Yj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(Zj,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(Kj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(eD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(oD,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(rD,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(tD,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(aD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(nD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(sD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(lD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(iD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(dD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(cD,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(mD,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(fD,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(gD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(hD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(uD,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(pD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(_D,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(bD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(vD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(FD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(TD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(MD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(ED,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(CD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(wD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(yD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(xD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c($D,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(kD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(SD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(RD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(PD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(BD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(ID,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(ND,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(qD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(jD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(DD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(GD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(OD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(VD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(XD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(zD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(QD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(WD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(UD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(HD,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(JD,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),c(YD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ZD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(KD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(eG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(oG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(rG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(tG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(aG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(nG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(sG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(lG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(iG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(dG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(cG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(mG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(fG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(gG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(hG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(uG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(pG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(_G,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(bG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(vG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(FG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(TG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(MG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(EG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(CG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(wG,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(AG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(LG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(yG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(xG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c($G,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(kG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(SG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(RG,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(PG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(BG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(IG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(NG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(qG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(jG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(DG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),c(GG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(OG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(VG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(XG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),c(zG,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(QG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(WG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(UG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(HG,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(JG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(YG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(ZG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(KG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(eO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(oO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(rO,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(tO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(aO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(nO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(sO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(lO,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(iO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(dO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c(cO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(mO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(fO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(gO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(hO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(uO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(pO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(_O,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(bO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(vO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(FO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(TO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(MO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(EO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(CO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(wO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(AO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(LO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(yO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(xO,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c($O,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(kO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(SO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(RO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(PO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(BO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(IO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(NO,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(qO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),c(jO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(DO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(GO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(OO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(VO,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(XO,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(zO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(QO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(WO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(UO,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(HO,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(JO,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(YO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(ZO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ip,"id","transformers.AutoFeatureExtractor"),c(ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ip,"href","#transformers.AutoFeatureExtractor"),c(Ld,"class","relative group"),c(KO,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(eV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(oV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(rV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),c(tV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(aV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(nV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(sV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),c(iV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(dV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(cV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(mV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(fV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(gV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(hV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(uV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(pV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(_V,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(bV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(vV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(FV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(TV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(MV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(EV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(CV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($V,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(SV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(RV,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(PV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(BV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(IV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(NV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(qV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(jV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(DV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),c(GV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(OV,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o_,"id","transformers.AutoProcessor"),c(o_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o_,"href","#transformers.AutoProcessor"),c(yd,"class","relative group"),c(VV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(XV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(zV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),c(QV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),c(WV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(UV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(HV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(JV,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(YV,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),c(ZV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(KV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(oX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(rX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(tX,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(aX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(nX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(sX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(lX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(iX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(dX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(cX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(mX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),c(fX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y_,"id","transformers.AutoModel"),c(y_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y_,"href","#transformers.AutoModel"),c($d,"class","relative group"),c(gX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(_X,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(bX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(vX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(FX,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(TX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(MX,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(EX,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(CX,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(wX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(AX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(LX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(yX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(xX,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),c($X,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),c(kX,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c(SX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(RX,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(PX,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(BX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(IX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(NX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(qX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(jX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(DX,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(GX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),c(OX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(VX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(XX,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c(zX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),c(QX,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(WX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(UX,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(HX,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),c(JX,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),c(YX,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(ZX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(KX,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(ez,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(oz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(rz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(tz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c(az,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(nz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(sz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(lz,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),c(iz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(dz,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),c(cz,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(mz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(fz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(gz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(hz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(uz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(pz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(_z,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(bz,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),c(vz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(Fz,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(Tz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(Mz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(Ez,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(Cz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(wz,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),c(Az,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Lz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(yz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(xz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c($z,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(kz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),c(Sz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(Rz,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(Pz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),c(Bz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c(Iz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(Nz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(qz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(jz,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(Dz,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),c(Gz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(Oz,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),c(Vz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(Xz,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(zz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(Qz,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Wz,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Uz,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(Hz,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(Jz,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(Yz,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(Zz,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(Kz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(eQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(oQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(rQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c(tQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(aQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(nQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(sQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(lQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(iQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),c(dQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(cQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c(mQ,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),c(fQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(gQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(hQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(uQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(pQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(_Q,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),c(bQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(vQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(FQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(TQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(MQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(EQ,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),c(CQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(wQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(AQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(LQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),c(yQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),c(xQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c($Q,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(kQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(SQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(RQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(PQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(BQ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(IQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y2,"id","transformers.AutoModelForPreTraining"),c(Y2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y2,"href","#transformers.AutoModelForPreTraining"),c(Rd,"class","relative group"),c(NQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(GQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(OQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(VQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(XQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(zQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(QQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(WQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(UQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(HQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(JQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(YQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(ZQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(KQ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(eW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(oW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(rW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(tW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(aW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(nW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(sW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(lW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(iW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(dW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(cW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(mW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(fW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(gW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(hW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(uW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(pW,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(_W,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(bW,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(vW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(FW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(TW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(MW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(EW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(CW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(wW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(AW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(LW,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(yW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(xW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c($W,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(kW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(SW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(RW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hb,"id","transformers.AutoModelForCausalLM"),c(Hb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hb,"href","#transformers.AutoModelForCausalLM"),c(Id,"class","relative group"),c(PW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(qW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c(jW,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(DW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(GW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(OW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(VW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(XW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(zW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(QW,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(WW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(UW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(HW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(JW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(YW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(ZW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(KW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(eU,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),c(oU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(rU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(tU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(aU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(nU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),c(sU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(lU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(iU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(dU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(cU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(mU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(fU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(gU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(hU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(uU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(pU,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(_U,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(bU,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(vU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(FU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(TU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(MU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(EU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(CU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gv,"id","transformers.AutoModelForDepthEstimation"),c(Gv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gv,"href","#transformers.AutoModelForDepthEstimation"),c(jd,"class","relative group"),c(wU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),c(xU,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wv,"id","transformers.AutoModelForMaskedLM"),c(Wv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wv,"href","#transformers.AutoModelForMaskedLM"),c(Od,"class","relative group"),c($U,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(PU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(BU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(IU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(NU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(qU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(jU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(DU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(GU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(OU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(VU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(XU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(zU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(QU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(WU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(UU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(HU,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(JU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(YU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(ZU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(KU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(eH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(oH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(rH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(tH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(aH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(nH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(sH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(lH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(iH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(dH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(cH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(mH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(fH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(gH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(hH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(uH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(pH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IF,"id","transformers.AutoModelForSeq2SeqLM"),c(IF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IF,"href","#transformers.AutoModelForSeq2SeqLM"),c(zd,"class","relative group"),c(_H,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(TH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(MH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(EH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(CH,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(wH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(AH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(LH,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(yH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(xH,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c($H,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(kH,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(SH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(RH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(PH,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(BH,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(IH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(NH,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(qH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(jH,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sT,"id","transformers.AutoModelForSequenceClassification"),c(sT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sT,"href","#transformers.AutoModelForSequenceClassification"),c(Ud,"class","relative group"),c(DH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(XH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c(zH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(QH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(WH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(UH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(HH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(JH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(YH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(ZH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(KH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(eJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(oJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(rJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(tJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(aJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(nJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),c(sJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(lJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(iJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(dJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(cJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(mJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(fJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(gJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(hJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(uJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(pJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(_J,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),c(bJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(vJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(FJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),c(TJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(MJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(EJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(CJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(wJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(AJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(LJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(yJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(xJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),c($J,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(kJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(SJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(RJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(PJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(BJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(IJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(NJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(qJ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(jJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(DJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(GJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(OJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(VJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(XJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fM,"id","transformers.AutoModelForMultipleChoice"),c(fM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fM,"href","#transformers.AutoModelForMultipleChoice"),c(Yd,"class","relative group"),c(zJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(HJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(JJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(YJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(ZJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(KJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(eY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(oY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(rY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(tY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(aY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(nY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(sY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(lY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(iY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(dY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(cY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(mY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(fY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(gY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(hY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(uY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(pY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(_Y,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(bY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(vY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(FY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(TY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(MY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(EY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(CY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(wY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UM,"id","transformers.AutoModelForNextSentencePrediction"),c(UM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UM,"href","#transformers.AutoModelForNextSentencePrediction"),c(ec,"class","relative group"),c(AY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c($Y,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(kY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(SY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(RY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(PY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(BY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nE,"id","transformers.AutoModelForTokenClassification"),c(nE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nE,"href","#transformers.AutoModelForTokenClassification"),c(tc,"class","relative group"),c(IY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(DY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(GY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(OY,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(VY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(XY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(zY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(QY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(WY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(UY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(HY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(JY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(YY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(ZY,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),c(KY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(eZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(oZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(rZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(tZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(aZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(nZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(sZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(lZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),c(iZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(dZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),c(cZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),c(mZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(fZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(gZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(hZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(uZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(pZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(_Z,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(bZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(vZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(FZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(TZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(MZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(EZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(CZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(wZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JE,"id","transformers.AutoModelForQuestionAnswering"),c(JE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JE,"href","#transformers.AutoModelForQuestionAnswering"),c(sc,"class","relative group"),c(AZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c($Z,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(kZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(SZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(RZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(PZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),c(BZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(IZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(NZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(qZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(jZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(DZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(GZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(OZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(VZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(XZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(zZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(QZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(WZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(UZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(HZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(JZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(YZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(ZZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),c(KZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(eK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(oK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(rK,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),c(tK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(aK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(nK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(sK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(lK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(iK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(dK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(cK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),c(mK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(fK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(gK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(hK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(uK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(pK,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(_K,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(bK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(vK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(FK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(TK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(MK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U4,"id","transformers.AutoModelForTableQuestionAnswering"),c(U4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U4,"href","#transformers.AutoModelForTableQuestionAnswering"),c(dc,"class","relative group"),c(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K4,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(K4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K4,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(fc,"class","relative group"),c(LK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($K,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(kK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(SK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sC,"id","transformers.AutoModelForImageClassification"),c(sC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sC,"href","#transformers.AutoModelForImageClassification"),c(pc,"class","relative group"),c(RK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(NK,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(qK,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(jK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(DK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(GK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(OK,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(VK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(XK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(zK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(QK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(WK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(UK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(HK,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(JK,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(YK,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(ZK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(KK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(eee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(oee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(ree,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(tee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wC,"id","transformers.AutoModelForVideoClassification"),c(wC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wC,"href","#transformers.AutoModelForVideoClassification"),c(vc,"class","relative group"),c(aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(see,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($C,"id","transformers.AutoModelForVision2Seq"),c($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($C,"href","#transformers.AutoModelForVision2Seq"),c(Mc,"class","relative group"),c(iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mee,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BC,"id","transformers.AutoModelForVisualQuestionAnswering"),c(BC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BC,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(wc,"class","relative group"),c(fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uee,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.AutoModelForAudioClassification"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.AutoModelForAudioClassification"),c(yc,"class","relative group"),c(pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(Fee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(Tee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(Mee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(Eee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(Cee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(wee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(Aee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(Lee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KC,"id","transformers.AutoModelForAudioFrameClassification"),c(KC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KC,"href","#transformers.AutoModelForAudioFrameClassification"),c(kc,"class","relative group"),c(yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(See,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(Ree,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(Pee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(Bee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i3,"id","transformers.AutoModelForCTC"),c(i3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i3,"href","#transformers.AutoModelForCTC"),c(Pc,"class","relative group"),c(Iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(Dee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(Gee,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(Oee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(Vee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(Xee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(zee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(Qee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(Wee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(Uee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M3,"id","transformers.AutoModelForSpeechSeq2Seq"),c(M3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M3,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Nc,"class","relative group"),c(Hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zee,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(Kee,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(eoe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x3,"id","transformers.AutoModelForAudioXVector"),c(x3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x3,"href","#transformers.AutoModelForAudioXVector"),c(Gc,"class","relative group"),c(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(toe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(noe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(soe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(loe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(ioe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q3,"id","transformers.AutoModelForMaskedImageModeling"),c(q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q3,"href","#transformers.AutoModelForMaskedImageModeling"),c(Xc,"class","relative group"),c(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(foe,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(goe,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(hoe,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(uoe,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q3,"id","transformers.AutoModelForObjectDetection"),c(Q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q3,"href","#transformers.AutoModelForObjectDetection"),c(Wc,"class","relative group"),c(poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(voe,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),c(Foe,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),c(Toe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Moe,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e5,"id","transformers.AutoModelForImageSegmentation"),c(e5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e5,"href","#transformers.AutoModelForImageSegmentation"),c(Jc,"class","relative group"),c(Eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aoe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n5,"id","transformers.AutoModelForSemanticSegmentation"),c(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n5,"href","#transformers.AutoModelForSemanticSegmentation"),c(Kc,"class","relative group"),c(Loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($oe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(koe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(Soe,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(Roe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(Poe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h5,"id","transformers.AutoModelForInstanceSegmentation"),c(h5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h5,"href","#transformers.AutoModelForInstanceSegmentation"),c(rm,"class","relative group"),c(Boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ioe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qoe,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v5,"id","transformers.AutoModelForZeroShotObjectDetection"),c(v5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v5,"href","#transformers.AutoModelForZeroShotObjectDetection"),c(nm,"class","relative group"),c(joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ooe,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C5,"id","transformers.TFAutoModel"),c(C5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C5,"href","#transformers.TFAutoModel"),c(im,"class","relative group"),c(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qoe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(Woe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(Uoe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(Hoe,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(Joe,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(Yoe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(Zoe,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(Koe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(ere,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(ore,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(rre,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),c(tre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(are,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(nre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(sre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),c(lre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(ire,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(dre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(cre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(mre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(fre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(gre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(hre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(ure,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),c(pre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(_re,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(bre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(vre,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(Fre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c(Tre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Mre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(Ere,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(Cre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(wre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(Are,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(Lre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(yre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(xre,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c($re,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(kre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),c(Sre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(Rre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),c(Pre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(Bre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(Ire,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),c(Nre,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(qre,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(jre,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(Dre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(Gre,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(Ore,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(Vre,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(Xre,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(zre,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),c(Qre,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),c(Wre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(Ure,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(Hre,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x0,"id","transformers.TFAutoModelForPreTraining"),c(x0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x0,"href","#transformers.TFAutoModelForPreTraining"),c(mm,"class","relative group"),c(Jre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(ete,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(ote,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(rte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(tte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(ate,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(nte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(ste,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(lte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(ite,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(dte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(cte,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(mte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(fte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(gte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(hte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(ute,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(pte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(_te,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(bte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(vte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Fte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Tte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ow,"id","transformers.TFAutoModelForCausalLM"),c(ow,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ow,"href","#transformers.TFAutoModelForCausalLM"),c(hm,"class","relative group"),c(Mte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ete,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(Ate,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(Lte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(yte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(xte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c($te,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(kte,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Ste,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Rte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(Pte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(Bte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Ite,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Nte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(qte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bw,"id","transformers.TFAutoModelForImageClassification"),c(bw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bw,"href","#transformers.TFAutoModelForImageClassification"),c(_m,"class","relative group"),c(jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ote,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(Vte,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),c(Xte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(zte,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(Qte,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(Wte,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(Ute,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(Hte,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(Jte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(Yte,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(Zte,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($w,"id","transformers.TFAutoModelForSemanticSegmentation"),c($w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($w,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(Fm,"class","relative group"),c(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(tae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(aae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iw,"id","transformers.TFAutoModelForMaskedLM"),c(Iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Iw,"href","#transformers.TFAutoModelForMaskedLM"),c(Cm,"class","relative group"),c(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(dae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(cae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(mae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(fae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(gae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(hae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(uae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(pae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(_ae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(bae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(vae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(Fae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(Tae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(Mae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Eae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Cae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(wae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Aae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Lae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nA,"id","transformers.TFAutoModelForSeq2SeqLM"),c(nA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nA,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Lm,"class","relative group"),c(yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Sae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Rae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Pae,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(Bae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(Iae,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(Nae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(qae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(jae,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Dae,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bA,"id","transformers.TFAutoModelForSequenceClassification"),c(bA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bA,"href","#transformers.TFAutoModelForSequenceClassification"),c($m,"class","relative group"),c(Gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(zae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(Qae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(Wae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(Uae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(Hae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(Jae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(Yae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(Zae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(Kae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(ene,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(one,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(rne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(tne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(ane,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(nne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(sne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(lne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(ine,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(dne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(cne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(mne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(fne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(gne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(hne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(une,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(pne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UA,"id","transformers.TFAutoModelForMultipleChoice"),c(UA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UA,"href","#transformers.TFAutoModelForMultipleChoice"),c(Rm,"class","relative group"),c(_ne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(Tne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(Mne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Ene,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Cne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(wne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(Ane,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(Lne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(yne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(xne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c($ne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(kne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Sne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Rne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Pne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(Bne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(Ine,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h6,"id","transformers.TFAutoModelForNextSentencePrediction"),c(h6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h6,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Im,"class","relative group"),c(Nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Gne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v6,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(v6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(jm,"class","relative group"),c(One,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Xne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(E6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Om,"class","relative group"),c(Qne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L6,"id","transformers.TFAutoModelForTokenClassification"),c(L6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L6,"href","#transformers.TFAutoModelForTokenClassification"),c(zm,"class","relative group"),c(Jne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(ese,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(ose,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(rse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(tse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(ase,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(nse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(sse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(lse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(ise,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(dse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(cse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(mse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(fse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(gse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(hse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(use,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(pse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(_se,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(bse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(vse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y6,"id","transformers.TFAutoModelForQuestionAnswering"),c(Y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y6,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Um,"class","relative group"),c(Fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ese,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Cse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(wse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Ase,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Lse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(yse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(xse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c($se,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(kse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Sse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Rse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Pse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(Bse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(Ise,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Nse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(qse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(jse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Dse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Gse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(Ose,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(Vse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T7,"id","transformers.TFAutoModelForVision2Seq"),c(T7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T7,"href","#transformers.TFAutoModelForVision2Seq"),c(Ym,"class","relative group"),c(Xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wse,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(w7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(ef,"class","relative group"),c(Use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Hse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yse,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Zse,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($7,"id","transformers.FlaxAutoModel"),c($7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($7,"href","#transformers.FlaxAutoModel"),c(tf,"class","relative group"),c(Kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(tle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(ale,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(nle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(sle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(lle,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(ile,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(dle,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(cle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(mle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(fle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(gle,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(hle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(ule,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(ple,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(_le,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(ble,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c(vle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(Fle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Tle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Mle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Ele,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(Cle,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(wle,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(Ale,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Lle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(yle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sL,"id","transformers.FlaxAutoModelForCausalLM"),c(sL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sL,"href","#transformers.FlaxAutoModelForCausalLM"),c(sf,"class","relative group"),c(xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Rle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Ple,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Ble,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(Ile,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(Nle,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(qle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(jle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(Dle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Gle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vL,"id","transformers.FlaxAutoModelForPreTraining"),c(vL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vL,"href","#transformers.FlaxAutoModelForPreTraining"),c(cf,"class","relative group"),c(Ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(Qle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Wle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(Ule,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(Hle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(Jle,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Yle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Zle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Kle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(eie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(oie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(tie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BL,"id","transformers.FlaxAutoModelForMaskedLM"),c(BL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BL,"href","#transformers.FlaxAutoModelForMaskedLM"),c(gf,"class","relative group"),c(aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(iie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(die,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(cie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(mie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(fie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(gie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(hie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(uie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(pie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(UL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(pf,"class","relative group"),c(_ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Tie,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Mie,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Eie,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Cie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(wie,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Aie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Lie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(yie,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(xie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l8,"id","transformers.FlaxAutoModelForSequenceClassification"),c(l8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l8,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(vf,"class","relative group"),c($ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Pie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Bie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Iie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Nie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(qie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(jie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Die,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Gie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Oie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F8,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(F8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F8,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Mf,"class","relative group"),c(Vie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(Wie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(Uie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Hie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Jie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Yie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Zie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Kie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(ede,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(ode,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R8,"id","transformers.FlaxAutoModelForTokenClassification"),c(R8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R8,"href","#transformers.FlaxAutoModelForTokenClassification"),c(wf,"class","relative group"),c(rde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ade,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(sde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(lde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(ide,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(dde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(cde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(mde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(fde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X8,"id","transformers.FlaxAutoModelForMultipleChoice"),c(X8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X8,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(yf,"class","relative group"),c(gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ude,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(_de,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(bde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(vde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Fde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Tde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Mde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Ede,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(oy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(kf,"class","relative group"),c(Cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ade,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ny,"id","transformers.FlaxAutoModelForImageClassification"),c(ny,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ny,"href","#transformers.FlaxAutoModelForImageClassification"),c(Pf,"class","relative group"),c(yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($de,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Sde,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cy,"id","transformers.FlaxAutoModelForVision2Seq"),c(cy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cy,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Nf,"class","relative group"),c(Rde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ide,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,$o),e($o,pd),b(m,Vf,_),b(m,Ft,_),e(Ft,_d),e(Ft,bd),e(bd,Jx),e(Ft,Xf),b(m,Xe,_),b(m,He,_),e(He,vd),e(He,cs),e(cs,Yx),e(He,ms),e(He,fs),e(fs,Zx),e(He,Fd),e(He,gs),e(gs,Kx),e(He,Td),b(m,zf,_),M(en,m,_),b(m,Je,_),b(m,Ae,_),e(Ae,fN),e(Ae,Md),e(Md,gN),e(Ae,hN),b(m,ko,_),b(m,on,_),e(on,uN),e(on,Qf),e(Qf,pN),e(on,Llo),b(m,Oro,_),b(m,Ed,_),e(Ed,Wf),e(Wf,zme),M(e$,zme,null),e(Ed,ylo),e(Ed,Qme),e(Qme,xlo),b(m,Vro,_),b(m,hs,_),e(hs,$lo),e(hs,Wme),e(Wme,klo),e(hs,Slo),e(hs,Ume),e(Ume,Rlo),e(hs,Plo),b(m,Xro,_),M(o$,m,_),b(m,zro,_),b(m,_N,_),e(_N,Blo),b(m,Qro,_),M(Uf,m,_),b(m,Wro,_),b(m,Cd,_),e(Cd,Hf),e(Hf,Hme),M(r$,Hme,null),e(Cd,Ilo),e(Cd,Jme),e(Jme,Nlo),b(m,Uro,_),b(m,So,_),M(t$,So,null),e(So,qlo),e(So,a$),e(a$,jlo),e(a$,bN),e(bN,Dlo),e(a$,Glo),e(So,Olo),e(So,n$),e(n$,Vlo),e(n$,Yme),e(Yme,Xlo),e(n$,zlo),e(So,Qlo),e(So,qr),M(s$,qr,null),e(qr,Wlo),e(qr,Zme),e(Zme,Ulo),e(qr,Hlo),e(qr,wd),e(wd,Jlo),e(wd,Kme),e(Kme,Ylo),e(wd,Zlo),e(wd,efe),e(efe,Klo),e(wd,eio),e(qr,oio),e(qr,A),e(A,Jf),e(Jf,ofe),e(ofe,rio),e(Jf,tio),e(Jf,vN),e(vN,aio),e(Jf,nio),e(A,sio),e(A,Yf),e(Yf,rfe),e(rfe,lio),e(Yf,iio),e(Yf,FN),e(FN,dio),e(Yf,cio),e(A,mio),e(A,Zf),e(Zf,tfe),e(tfe,fio),e(Zf,gio),e(Zf,TN),e(TN,hio),e(Zf,uio),e(A,pio),e(A,Kf),e(Kf,afe),e(afe,_io),e(Kf,bio),e(Kf,MN),e(MN,vio),e(Kf,Fio),e(A,Tio),e(A,eg),e(eg,nfe),e(nfe,Mio),e(eg,Eio),e(eg,EN),e(EN,Cio),e(eg,wio),e(A,Aio),e(A,og),e(og,sfe),e(sfe,Lio),e(og,yio),e(og,CN),e(CN,xio),e(og,$io),e(A,kio),e(A,rg),e(rg,lfe),e(lfe,Sio),e(rg,Rio),e(rg,wN),e(wN,Pio),e(rg,Bio),e(A,Iio),e(A,tg),e(tg,ife),e(ife,Nio),e(tg,qio),e(tg,AN),e(AN,jio),e(tg,Dio),e(A,Gio),e(A,ag),e(ag,dfe),e(dfe,Oio),e(ag,Vio),e(ag,LN),e(LN,Xio),e(ag,zio),e(A,Qio),e(A,ng),e(ng,cfe),e(cfe,Wio),e(ng,Uio),e(ng,yN),e(yN,Hio),e(ng,Jio),e(A,Yio),e(A,sg),e(sg,mfe),e(mfe,Zio),e(sg,Kio),e(sg,xN),e(xN,edo),e(sg,odo),e(A,rdo),e(A,lg),e(lg,ffe),e(ffe,tdo),e(lg,ado),e(lg,$N),e($N,ndo),e(lg,sdo),e(A,ldo),e(A,ig),e(ig,gfe),e(gfe,ido),e(ig,ddo),e(ig,kN),e(kN,cdo),e(ig,mdo),e(A,fdo),e(A,dg),e(dg,hfe),e(hfe,gdo),e(dg,hdo),e(dg,SN),e(SN,udo),e(dg,pdo),e(A,_do),e(A,cg),e(cg,ufe),e(ufe,bdo),e(cg,vdo),e(cg,RN),e(RN,Fdo),e(cg,Tdo),e(A,Mdo),e(A,mg),e(mg,pfe),e(pfe,Edo),e(mg,Cdo),e(mg,PN),e(PN,wdo),e(mg,Ado),e(A,Ldo),e(A,fg),e(fg,_fe),e(_fe,ydo),e(fg,xdo),e(fg,BN),e(BN,$do),e(fg,kdo),e(A,Sdo),e(A,gg),e(gg,bfe),e(bfe,Rdo),e(gg,Pdo),e(gg,IN),e(IN,Bdo),e(gg,Ido),e(A,Ndo),e(A,hg),e(hg,vfe),e(vfe,qdo),e(hg,jdo),e(hg,NN),e(NN,Ddo),e(hg,Gdo),e(A,Odo),e(A,ug),e(ug,Ffe),e(Ffe,Vdo),e(ug,Xdo),e(ug,qN),e(qN,zdo),e(ug,Qdo),e(A,Wdo),e(A,pg),e(pg,Tfe),e(Tfe,Udo),e(pg,Hdo),e(pg,jN),e(jN,Jdo),e(pg,Ydo),e(A,Zdo),e(A,_g),e(_g,Mfe),e(Mfe,Kdo),e(_g,eco),e(_g,DN),e(DN,oco),e(_g,rco),e(A,tco),e(A,bg),e(bg,Efe),e(Efe,aco),e(bg,nco),e(bg,GN),e(GN,sco),e(bg,lco),e(A,ico),e(A,vg),e(vg,Cfe),e(Cfe,dco),e(vg,cco),e(vg,ON),e(ON,mco),e(vg,fco),e(A,gco),e(A,Fg),e(Fg,wfe),e(wfe,hco),e(Fg,uco),e(Fg,VN),e(VN,pco),e(Fg,_co),e(A,bco),e(A,Tg),e(Tg,Afe),e(Afe,vco),e(Tg,Fco),e(Tg,XN),e(XN,Tco),e(Tg,Mco),e(A,Eco),e(A,Mg),e(Mg,Lfe),e(Lfe,Cco),e(Mg,wco),e(Mg,zN),e(zN,Aco),e(Mg,Lco),e(A,yco),e(A,Eg),e(Eg,yfe),e(yfe,xco),e(Eg,$co),e(Eg,QN),e(QN,kco),e(Eg,Sco),e(A,Rco),e(A,Cg),e(Cg,xfe),e(xfe,Pco),e(Cg,Bco),e(Cg,WN),e(WN,Ico),e(Cg,Nco),e(A,qco),e(A,wg),e(wg,$fe),e($fe,jco),e(wg,Dco),e(wg,UN),e(UN,Gco),e(wg,Oco),e(A,Vco),e(A,Ag),e(Ag,kfe),e(kfe,Xco),e(Ag,zco),e(Ag,HN),e(HN,Qco),e(Ag,Wco),e(A,Uco),e(A,Lg),e(Lg,Sfe),e(Sfe,Hco),e(Lg,Jco),e(Lg,JN),e(JN,Yco),e(Lg,Zco),e(A,Kco),e(A,yg),e(yg,Rfe),e(Rfe,emo),e(yg,omo),e(yg,YN),e(YN,rmo),e(yg,tmo),e(A,amo),e(A,xg),e(xg,Pfe),e(Pfe,nmo),e(xg,smo),e(xg,ZN),e(ZN,lmo),e(xg,imo),e(A,dmo),e(A,$g),e($g,Bfe),e(Bfe,cmo),e($g,mmo),e($g,KN),e(KN,fmo),e($g,gmo),e(A,hmo),e(A,kg),e(kg,Ife),e(Ife,umo),e(kg,pmo),e(kg,eq),e(eq,_mo),e(kg,bmo),e(A,vmo),e(A,Sg),e(Sg,Nfe),e(Nfe,Fmo),e(Sg,Tmo),e(Sg,oq),e(oq,Mmo),e(Sg,Emo),e(A,Cmo),e(A,Rg),e(Rg,qfe),e(qfe,wmo),e(Rg,Amo),e(Rg,rq),e(rq,Lmo),e(Rg,ymo),e(A,xmo),e(A,Pg),e(Pg,jfe),e(jfe,$mo),e(Pg,kmo),e(Pg,tq),e(tq,Smo),e(Pg,Rmo),e(A,Pmo),e(A,Bg),e(Bg,Dfe),e(Dfe,Bmo),e(Bg,Imo),e(Bg,aq),e(aq,Nmo),e(Bg,qmo),e(A,jmo),e(A,Ig),e(Ig,Gfe),e(Gfe,Dmo),e(Ig,Gmo),e(Ig,nq),e(nq,Omo),e(Ig,Vmo),e(A,Xmo),e(A,Ng),e(Ng,Ofe),e(Ofe,zmo),e(Ng,Qmo),e(Ng,sq),e(sq,Wmo),e(Ng,Umo),e(A,Hmo),e(A,qg),e(qg,Vfe),e(Vfe,Jmo),e(qg,Ymo),e(qg,lq),e(lq,Zmo),e(qg,Kmo),e(A,efo),e(A,jg),e(jg,Xfe),e(Xfe,ofo),e(jg,rfo),e(jg,iq),e(iq,tfo),e(jg,afo),e(A,nfo),e(A,Dg),e(Dg,zfe),e(zfe,sfo),e(Dg,lfo),e(Dg,dq),e(dq,ifo),e(Dg,dfo),e(A,cfo),e(A,Gg),e(Gg,Qfe),e(Qfe,mfo),e(Gg,ffo),e(Gg,cq),e(cq,gfo),e(Gg,hfo),e(A,ufo),e(A,Og),e(Og,Wfe),e(Wfe,pfo),e(Og,_fo),e(Og,mq),e(mq,bfo),e(Og,vfo),e(A,Ffo),e(A,Vg),e(Vg,Ufe),e(Ufe,Tfo),e(Vg,Mfo),e(Vg,fq),e(fq,Efo),e(Vg,Cfo),e(A,wfo),e(A,Xg),e(Xg,Hfe),e(Hfe,Afo),e(Xg,Lfo),e(Xg,gq),e(gq,yfo),e(Xg,xfo),e(A,$fo),e(A,zg),e(zg,Jfe),e(Jfe,kfo),e(zg,Sfo),e(zg,hq),e(hq,Rfo),e(zg,Pfo),e(A,Bfo),e(A,Qg),e(Qg,Yfe),e(Yfe,Ifo),e(Qg,Nfo),e(Qg,uq),e(uq,qfo),e(Qg,jfo),e(A,Dfo),e(A,Wg),e(Wg,Zfe),e(Zfe,Gfo),e(Wg,Ofo),e(Wg,pq),e(pq,Vfo),e(Wg,Xfo),e(A,zfo),e(A,Ug),e(Ug,Kfe),e(Kfe,Qfo),e(Ug,Wfo),e(Ug,_q),e(_q,Ufo),e(Ug,Hfo),e(A,Jfo),e(A,Hg),e(Hg,ege),e(ege,Yfo),e(Hg,Zfo),e(Hg,bq),e(bq,Kfo),e(Hg,ego),e(A,ogo),e(A,Jg),e(Jg,oge),e(oge,rgo),e(Jg,tgo),e(Jg,vq),e(vq,ago),e(Jg,ngo),e(A,sgo),e(A,Yg),e(Yg,rge),e(rge,lgo),e(Yg,igo),e(Yg,Fq),e(Fq,dgo),e(Yg,cgo),e(A,mgo),e(A,Zg),e(Zg,tge),e(tge,fgo),e(Zg,ggo),e(Zg,Tq),e(Tq,hgo),e(Zg,ugo),e(A,pgo),e(A,Kg),e(Kg,age),e(age,_go),e(Kg,bgo),e(Kg,Mq),e(Mq,vgo),e(Kg,Fgo),e(A,Tgo),e(A,eh),e(eh,nge),e(nge,Mgo),e(eh,Ego),e(eh,Eq),e(Eq,Cgo),e(eh,wgo),e(A,Ago),e(A,oh),e(oh,sge),e(sge,Lgo),e(oh,ygo),e(oh,Cq),e(Cq,xgo),e(oh,$go),e(A,kgo),e(A,rh),e(rh,lge),e(lge,Sgo),e(rh,Rgo),e(rh,wq),e(wq,Pgo),e(rh,Bgo),e(A,Igo),e(A,th),e(th,ige),e(ige,Ngo),e(th,qgo),e(th,Aq),e(Aq,jgo),e(th,Dgo),e(A,Ggo),e(A,ah),e(ah,dge),e(dge,Ogo),e(ah,Vgo),e(ah,Lq),e(Lq,Xgo),e(ah,zgo),e(A,Qgo),e(A,nh),e(nh,cge),e(cge,Wgo),e(nh,Ugo),e(nh,yq),e(yq,Hgo),e(nh,Jgo),e(A,Ygo),e(A,sh),e(sh,mge),e(mge,Zgo),e(sh,Kgo),e(sh,xq),e(xq,eho),e(sh,oho),e(A,rho),e(A,lh),e(lh,fge),e(fge,tho),e(lh,aho),e(lh,$q),e($q,nho),e(lh,sho),e(A,lho),e(A,ih),e(ih,gge),e(gge,iho),e(ih,dho),e(ih,kq),e(kq,cho),e(ih,mho),e(A,fho),e(A,dh),e(dh,hge),e(hge,gho),e(dh,hho),e(dh,Sq),e(Sq,uho),e(dh,pho),e(A,_ho),e(A,ch),e(ch,uge),e(uge,bho),e(ch,vho),e(ch,Rq),e(Rq,Fho),e(ch,Tho),e(A,Mho),e(A,mh),e(mh,pge),e(pge,Eho),e(mh,Cho),e(mh,Pq),e(Pq,who),e(mh,Aho),e(A,Lho),e(A,fh),e(fh,_ge),e(_ge,yho),e(fh,xho),e(fh,Bq),e(Bq,$ho),e(fh,kho),e(A,Sho),e(A,gh),e(gh,bge),e(bge,Rho),e(gh,Pho),e(gh,Iq),e(Iq,Bho),e(gh,Iho),e(A,Nho),e(A,hh),e(hh,vge),e(vge,qho),e(hh,jho),e(hh,Nq),e(Nq,Dho),e(hh,Gho),e(A,Oho),e(A,uh),e(uh,Fge),e(Fge,Vho),e(uh,Xho),e(uh,qq),e(qq,zho),e(uh,Qho),e(A,Who),e(A,ph),e(ph,Tge),e(Tge,Uho),e(ph,Hho),e(ph,jq),e(jq,Jho),e(ph,Yho),e(A,Zho),e(A,_h),e(_h,Mge),e(Mge,Kho),e(_h,euo),e(_h,Dq),e(Dq,ouo),e(_h,ruo),e(A,tuo),e(A,bh),e(bh,Ege),e(Ege,auo),e(bh,nuo),e(bh,Gq),e(Gq,suo),e(bh,luo),e(A,iuo),e(A,vh),e(vh,Cge),e(Cge,duo),e(vh,cuo),e(vh,Oq),e(Oq,muo),e(vh,fuo),e(A,guo),e(A,Fh),e(Fh,wge),e(wge,huo),e(Fh,uuo),e(Fh,Vq),e(Vq,puo),e(Fh,_uo),e(A,buo),e(A,Th),e(Th,Age),e(Age,vuo),e(Th,Fuo),e(Th,Xq),e(Xq,Tuo),e(Th,Muo),e(A,Euo),e(A,Mh),e(Mh,Lge),e(Lge,Cuo),e(Mh,wuo),e(Mh,zq),e(zq,Auo),e(Mh,Luo),e(A,yuo),e(A,Eh),e(Eh,yge),e(yge,xuo),e(Eh,$uo),e(Eh,Qq),e(Qq,kuo),e(Eh,Suo),e(A,Ruo),e(A,Ch),e(Ch,xge),e(xge,Puo),e(Ch,Buo),e(Ch,Wq),e(Wq,Iuo),e(Ch,Nuo),e(A,quo),e(A,wh),e(wh,$ge),e($ge,juo),e(wh,Duo),e(wh,Uq),e(Uq,Guo),e(wh,Ouo),e(A,Vuo),e(A,Ah),e(Ah,kge),e(kge,Xuo),e(Ah,zuo),e(Ah,Hq),e(Hq,Quo),e(Ah,Wuo),e(A,Uuo),e(A,Lh),e(Lh,Sge),e(Sge,Huo),e(Lh,Juo),e(Lh,Jq),e(Jq,Yuo),e(Lh,Zuo),e(A,Kuo),e(A,yh),e(yh,Rge),e(Rge,epo),e(yh,opo),e(yh,Yq),e(Yq,rpo),e(yh,tpo),e(A,apo),e(A,xh),e(xh,Pge),e(Pge,npo),e(xh,spo),e(xh,Zq),e(Zq,lpo),e(xh,ipo),e(A,dpo),e(A,$h),e($h,Bge),e(Bge,cpo),e($h,mpo),e($h,Kq),e(Kq,fpo),e($h,gpo),e(A,hpo),e(A,kh),e(kh,Ige),e(Ige,upo),e(kh,ppo),e(kh,ej),e(ej,_po),e(kh,bpo),e(A,vpo),e(A,Sh),e(Sh,Nge),e(Nge,Fpo),e(Sh,Tpo),e(Sh,oj),e(oj,Mpo),e(Sh,Epo),e(A,Cpo),e(A,Rh),e(Rh,qge),e(qge,wpo),e(Rh,Apo),e(Rh,rj),e(rj,Lpo),e(Rh,ypo),e(A,xpo),e(A,Ph),e(Ph,jge),e(jge,$po),e(Ph,kpo),e(Ph,tj),e(tj,Spo),e(Ph,Rpo),e(A,Ppo),e(A,Bh),e(Bh,Dge),e(Dge,Bpo),e(Bh,Ipo),e(Bh,aj),e(aj,Npo),e(Bh,qpo),e(A,jpo),e(A,Ih),e(Ih,Gge),e(Gge,Dpo),e(Ih,Gpo),e(Ih,nj),e(nj,Opo),e(Ih,Vpo),e(A,Xpo),e(A,Nh),e(Nh,Oge),e(Oge,zpo),e(Nh,Qpo),e(Nh,sj),e(sj,Wpo),e(Nh,Upo),e(A,Hpo),e(A,qh),e(qh,Vge),e(Vge,Jpo),e(qh,Ypo),e(qh,lj),e(lj,Zpo),e(qh,Kpo),e(A,e_o),e(A,jh),e(jh,Xge),e(Xge,o_o),e(jh,r_o),e(jh,ij),e(ij,t_o),e(jh,a_o),e(A,n_o),e(A,Dh),e(Dh,zge),e(zge,s_o),e(Dh,l_o),e(Dh,dj),e(dj,i_o),e(Dh,d_o),e(A,c_o),e(A,Gh),e(Gh,Qge),e(Qge,m_o),e(Gh,f_o),e(Gh,cj),e(cj,g_o),e(Gh,h_o),e(A,u_o),e(A,Oh),e(Oh,Wge),e(Wge,p_o),e(Oh,__o),e(Oh,mj),e(mj,b_o),e(Oh,v_o),e(A,F_o),e(A,Vh),e(Vh,Uge),e(Uge,T_o),e(Vh,M_o),e(Vh,fj),e(fj,E_o),e(Vh,C_o),e(A,w_o),e(A,Xh),e(Xh,Hge),e(Hge,A_o),e(Xh,L_o),e(Xh,gj),e(gj,y_o),e(Xh,x_o),e(A,$_o),e(A,zh),e(zh,Jge),e(Jge,k_o),e(zh,S_o),e(zh,hj),e(hj,R_o),e(zh,P_o),e(A,B_o),e(A,Qh),e(Qh,Yge),e(Yge,I_o),e(Qh,N_o),e(Qh,uj),e(uj,q_o),e(Qh,j_o),e(A,D_o),e(A,Wh),e(Wh,Zge),e(Zge,G_o),e(Wh,O_o),e(Wh,pj),e(pj,V_o),e(Wh,X_o),e(A,z_o),e(A,Uh),e(Uh,Kge),e(Kge,Q_o),e(Uh,W_o),e(Uh,_j),e(_j,U_o),e(Uh,H_o),e(A,J_o),e(A,Hh),e(Hh,ehe),e(ehe,Y_o),e(Hh,Z_o),e(Hh,bj),e(bj,K_o),e(Hh,e1o),e(A,o1o),e(A,Jh),e(Jh,ohe),e(ohe,r1o),e(Jh,t1o),e(Jh,vj),e(vj,a1o),e(Jh,n1o),e(A,s1o),e(A,Yh),e(Yh,rhe),e(rhe,l1o),e(Yh,i1o),e(Yh,Fj),e(Fj,d1o),e(Yh,c1o),e(A,m1o),e(A,Zh),e(Zh,the),e(the,f1o),e(Zh,g1o),e(Zh,Tj),e(Tj,h1o),e(Zh,u1o),e(A,p1o),e(A,Kh),e(Kh,ahe),e(ahe,_1o),e(Kh,b1o),e(Kh,Mj),e(Mj,v1o),e(Kh,F1o),e(A,T1o),e(A,eu),e(eu,nhe),e(nhe,M1o),e(eu,E1o),e(eu,Ej),e(Ej,C1o),e(eu,w1o),e(A,A1o),e(A,ou),e(ou,she),e(she,L1o),e(ou,y1o),e(ou,Cj),e(Cj,x1o),e(ou,$1o),e(A,k1o),e(A,ru),e(ru,lhe),e(lhe,S1o),e(ru,R1o),e(ru,wj),e(wj,P1o),e(ru,B1o),e(A,I1o),e(A,tu),e(tu,ihe),e(ihe,N1o),e(tu,q1o),e(tu,Aj),e(Aj,j1o),e(tu,D1o),e(A,G1o),e(A,au),e(au,dhe),e(dhe,O1o),e(au,V1o),e(au,Lj),e(Lj,X1o),e(au,z1o),e(A,Q1o),e(A,nu),e(nu,che),e(che,W1o),e(nu,U1o),e(nu,yj),e(yj,H1o),e(nu,J1o),e(A,Y1o),e(A,su),e(su,mhe),e(mhe,Z1o),e(su,K1o),e(su,xj),e(xj,e2o),e(su,o2o),e(A,r2o),e(A,lu),e(lu,fhe),e(fhe,t2o),e(lu,a2o),e(lu,$j),e($j,n2o),e(lu,s2o),e(A,l2o),e(A,iu),e(iu,ghe),e(ghe,i2o),e(iu,d2o),e(iu,kj),e(kj,c2o),e(iu,m2o),e(A,f2o),e(A,du),e(du,hhe),e(hhe,g2o),e(du,h2o),e(du,Sj),e(Sj,u2o),e(du,p2o),e(A,_2o),e(A,cu),e(cu,uhe),e(uhe,b2o),e(cu,v2o),e(cu,Rj),e(Rj,F2o),e(cu,T2o),e(A,M2o),e(A,mu),e(mu,phe),e(phe,E2o),e(mu,C2o),e(mu,Pj),e(Pj,w2o),e(mu,A2o),e(A,L2o),e(A,fu),e(fu,_he),e(_he,y2o),e(fu,x2o),e(fu,Bj),e(Bj,$2o),e(fu,k2o),e(A,S2o),e(A,gu),e(gu,bhe),e(bhe,R2o),e(gu,P2o),e(gu,Ij),e(Ij,B2o),e(gu,I2o),e(A,N2o),e(A,hu),e(hu,vhe),e(vhe,q2o),e(hu,j2o),e(hu,Nj),e(Nj,D2o),e(hu,G2o),e(A,O2o),e(A,uu),e(uu,Fhe),e(Fhe,V2o),e(uu,X2o),e(uu,qj),e(qj,z2o),e(uu,Q2o),e(A,W2o),e(A,pu),e(pu,The),e(The,U2o),e(pu,H2o),e(pu,jj),e(jj,J2o),e(pu,Y2o),e(A,Z2o),e(A,_u),e(_u,Mhe),e(Mhe,K2o),e(_u,ebo),e(_u,Dj),e(Dj,obo),e(_u,rbo),e(A,tbo),e(A,bu),e(bu,Ehe),e(Ehe,abo),e(bu,nbo),e(bu,Gj),e(Gj,sbo),e(bu,lbo),e(A,ibo),e(A,vu),e(vu,Che),e(Che,dbo),e(vu,cbo),e(vu,Oj),e(Oj,mbo),e(vu,fbo),e(A,gbo),e(A,Fu),e(Fu,whe),e(whe,hbo),e(Fu,ubo),e(Fu,Vj),e(Vj,pbo),e(Fu,_bo),e(A,bbo),e(A,Tu),e(Tu,Ahe),e(Ahe,vbo),e(Tu,Fbo),e(Tu,Xj),e(Xj,Tbo),e(Tu,Mbo),e(qr,Ebo),M(Mu,qr,null),e(So,Cbo),e(So,Eu),M(l$,Eu,null),e(Eu,wbo),e(Eu,Lhe),e(Lhe,Abo),b(m,Hro,_),b(m,Ad,_),e(Ad,Cu),e(Cu,yhe),M(i$,yhe,null),e(Ad,Lbo),e(Ad,xhe),e(xhe,ybo),b(m,Jro,_),b(m,Ro,_),M(d$,Ro,null),e(Ro,xbo),e(Ro,c$),e(c$,$bo),e(c$,zj),e(zj,kbo),e(c$,Sbo),e(Ro,Rbo),e(Ro,m$),e(m$,Pbo),e(m$,$he),e($he,Bbo),e(m$,Ibo),e(Ro,Nbo),e(Ro,jr),M(f$,jr,null),e(jr,qbo),e(jr,khe),e(khe,jbo),e(jr,Dbo),e(jr,rn),e(rn,Gbo),e(rn,She),e(She,Obo),e(rn,Vbo),e(rn,Rhe),e(Rhe,Xbo),e(rn,zbo),e(rn,Phe),e(Phe,Qbo),e(rn,Wbo),e(jr,Ubo),e(jr,k),e(k,us),e(us,Bhe),e(Bhe,Hbo),e(us,Jbo),e(us,Qj),e(Qj,Ybo),e(us,Zbo),e(us,Wj),e(Wj,Kbo),e(us,evo),e(k,ovo),e(k,ps),e(ps,Ihe),e(Ihe,rvo),e(ps,tvo),e(ps,Uj),e(Uj,avo),e(ps,nvo),e(ps,Hj),e(Hj,svo),e(ps,lvo),e(k,ivo),e(k,_s),e(_s,Nhe),e(Nhe,dvo),e(_s,cvo),e(_s,Jj),e(Jj,mvo),e(_s,fvo),e(_s,Yj),e(Yj,gvo),e(_s,hvo),e(k,uvo),e(k,wu),e(wu,qhe),e(qhe,pvo),e(wu,_vo),e(wu,Zj),e(Zj,bvo),e(wu,vvo),e(k,Fvo),e(k,bs),e(bs,jhe),e(jhe,Tvo),e(bs,Mvo),e(bs,Kj),e(Kj,Evo),e(bs,Cvo),e(bs,eD),e(eD,wvo),e(bs,Avo),e(k,Lvo),e(k,Au),e(Au,Dhe),e(Dhe,yvo),e(Au,xvo),e(Au,oD),e(oD,$vo),e(Au,kvo),e(k,Svo),e(k,Lu),e(Lu,Ghe),e(Ghe,Rvo),e(Lu,Pvo),e(Lu,rD),e(rD,Bvo),e(Lu,Ivo),e(k,Nvo),e(k,yu),e(yu,Ohe),e(Ohe,qvo),e(yu,jvo),e(yu,tD),e(tD,Dvo),e(yu,Gvo),e(k,Ovo),e(k,vs),e(vs,Vhe),e(Vhe,Vvo),e(vs,Xvo),e(vs,aD),e(aD,zvo),e(vs,Qvo),e(vs,nD),e(nD,Wvo),e(vs,Uvo),e(k,Hvo),e(k,Fs),e(Fs,Xhe),e(Xhe,Jvo),e(Fs,Yvo),e(Fs,sD),e(sD,Zvo),e(Fs,Kvo),e(Fs,lD),e(lD,eFo),e(Fs,oFo),e(k,rFo),e(k,Ts),e(Ts,zhe),e(zhe,tFo),e(Ts,aFo),e(Ts,iD),e(iD,nFo),e(Ts,sFo),e(Ts,dD),e(dD,lFo),e(Ts,iFo),e(k,dFo),e(k,xu),e(xu,Qhe),e(Qhe,cFo),e(xu,mFo),e(xu,cD),e(cD,fFo),e(xu,gFo),e(k,hFo),e(k,$u),e($u,Whe),e(Whe,uFo),e($u,pFo),e($u,mD),e(mD,_Fo),e($u,bFo),e(k,vFo),e(k,ku),e(ku,Uhe),e(Uhe,FFo),e(ku,TFo),e(ku,fD),e(fD,MFo),e(ku,EFo),e(k,CFo),e(k,Ms),e(Ms,Hhe),e(Hhe,wFo),e(Ms,AFo),e(Ms,gD),e(gD,LFo),e(Ms,yFo),e(Ms,hD),e(hD,xFo),e(Ms,$Fo),e(k,kFo),e(k,Su),e(Su,Jhe),e(Jhe,SFo),e(Su,RFo),e(Su,uD),e(uD,PFo),e(Su,BFo),e(k,IFo),e(k,Es),e(Es,Yhe),e(Yhe,NFo),e(Es,qFo),e(Es,pD),e(pD,jFo),e(Es,DFo),e(Es,_D),e(_D,GFo),e(Es,OFo),e(k,VFo),e(k,Cs),e(Cs,Zhe),e(Zhe,XFo),e(Cs,zFo),e(Cs,bD),e(bD,QFo),e(Cs,WFo),e(Cs,vD),e(vD,UFo),e(Cs,HFo),e(k,JFo),e(k,ws),e(ws,Khe),e(Khe,YFo),e(ws,ZFo),e(ws,FD),e(FD,KFo),e(ws,eTo),e(ws,TD),e(TD,oTo),e(ws,rTo),e(k,tTo),e(k,As),e(As,eue),e(eue,aTo),e(As,nTo),e(As,MD),e(MD,sTo),e(As,lTo),e(As,ED),e(ED,iTo),e(As,dTo),e(k,cTo),e(k,Ru),e(Ru,oue),e(oue,mTo),e(Ru,fTo),e(Ru,CD),e(CD,gTo),e(Ru,hTo),e(k,uTo),e(k,Ls),e(Ls,rue),e(rue,pTo),e(Ls,_To),e(Ls,wD),e(wD,bTo),e(Ls,vTo),e(Ls,AD),e(AD,FTo),e(Ls,TTo),e(k,MTo),e(k,ys),e(ys,tue),e(tue,ETo),e(ys,CTo),e(ys,LD),e(LD,wTo),e(ys,ATo),e(ys,yD),e(yD,LTo),e(ys,yTo),e(k,xTo),e(k,xs),e(xs,aue),e(aue,$To),e(xs,kTo),e(xs,xD),e(xD,STo),e(xs,RTo),e(xs,$D),e($D,PTo),e(xs,BTo),e(k,ITo),e(k,$s),e($s,nue),e(nue,NTo),e($s,qTo),e($s,kD),e(kD,jTo),e($s,DTo),e($s,SD),e(SD,GTo),e($s,OTo),e(k,VTo),e(k,ks),e(ks,sue),e(sue,XTo),e(ks,zTo),e(ks,RD),e(RD,QTo),e(ks,WTo),e(ks,PD),e(PD,UTo),e(ks,HTo),e(k,JTo),e(k,Ss),e(Ss,lue),e(lue,YTo),e(Ss,ZTo),e(Ss,BD),e(BD,KTo),e(Ss,eMo),e(Ss,ID),e(ID,oMo),e(Ss,rMo),e(k,tMo),e(k,Rs),e(Rs,iue),e(iue,aMo),e(Rs,nMo),e(Rs,ND),e(ND,sMo),e(Rs,lMo),e(Rs,qD),e(qD,iMo),e(Rs,dMo),e(k,cMo),e(k,Pu),e(Pu,due),e(due,mMo),e(Pu,fMo),e(Pu,jD),e(jD,gMo),e(Pu,hMo),e(k,uMo),e(k,Ps),e(Ps,cue),e(cue,pMo),e(Ps,_Mo),e(Ps,DD),e(DD,bMo),e(Ps,vMo),e(Ps,GD),e(GD,FMo),e(Ps,TMo),e(k,MMo),e(k,Bu),e(Bu,mue),e(mue,EMo),e(Bu,CMo),e(Bu,OD),e(OD,wMo),e(Bu,AMo),e(k,LMo),e(k,Bs),e(Bs,fue),e(fue,yMo),e(Bs,xMo),e(Bs,VD),e(VD,$Mo),e(Bs,kMo),e(Bs,XD),e(XD,SMo),e(Bs,RMo),e(k,PMo),e(k,Is),e(Is,gue),e(gue,BMo),e(Is,IMo),e(Is,zD),e(zD,NMo),e(Is,qMo),e(Is,QD),e(QD,jMo),e(Is,DMo),e(k,GMo),e(k,Ns),e(Ns,hue),e(hue,OMo),e(Ns,VMo),e(Ns,WD),e(WD,XMo),e(Ns,zMo),e(Ns,UD),e(UD,QMo),e(Ns,WMo),e(k,UMo),e(k,Iu),e(Iu,uue),e(uue,HMo),e(Iu,JMo),e(Iu,HD),e(HD,YMo),e(Iu,ZMo),e(k,KMo),e(k,Nu),e(Nu,pue),e(pue,eEo),e(Nu,oEo),e(Nu,JD),e(JD,rEo),e(Nu,tEo),e(k,aEo),e(k,qs),e(qs,_ue),e(_ue,nEo),e(qs,sEo),e(qs,YD),e(YD,lEo),e(qs,iEo),e(qs,ZD),e(ZD,dEo),e(qs,cEo),e(k,mEo),e(k,js),e(js,bue),e(bue,fEo),e(js,gEo),e(js,KD),e(KD,hEo),e(js,uEo),e(js,eG),e(eG,pEo),e(js,_Eo),e(k,bEo),e(k,Ds),e(Ds,vue),e(vue,vEo),e(Ds,FEo),e(Ds,oG),e(oG,TEo),e(Ds,MEo),e(Ds,rG),e(rG,EEo),e(Ds,CEo),e(k,wEo),e(k,qu),e(qu,Fue),e(Fue,AEo),e(qu,LEo),e(qu,tG),e(tG,yEo),e(qu,xEo),e(k,$Eo),e(k,Gs),e(Gs,Tue),e(Tue,kEo),e(Gs,SEo),e(Gs,aG),e(aG,REo),e(Gs,PEo),e(Gs,nG),e(nG,BEo),e(Gs,IEo),e(k,NEo),e(k,Os),e(Os,Mue),e(Mue,qEo),e(Os,jEo),e(Os,sG),e(sG,DEo),e(Os,GEo),e(Os,lG),e(lG,OEo),e(Os,VEo),e(k,XEo),e(k,Vs),e(Vs,Eue),e(Eue,zEo),e(Vs,QEo),e(Vs,iG),e(iG,WEo),e(Vs,UEo),e(Vs,dG),e(dG,HEo),e(Vs,JEo),e(k,YEo),e(k,Xs),e(Xs,Cue),e(Cue,ZEo),e(Xs,KEo),e(Xs,cG),e(cG,e4o),e(Xs,o4o),e(Xs,mG),e(mG,r4o),e(Xs,t4o),e(k,a4o),e(k,zs),e(zs,wue),e(wue,n4o),e(zs,s4o),e(zs,fG),e(fG,l4o),e(zs,i4o),e(zs,gG),e(gG,d4o),e(zs,c4o),e(k,m4o),e(k,Qs),e(Qs,Aue),e(Aue,f4o),e(Qs,g4o),e(Qs,hG),e(hG,h4o),e(Qs,u4o),e(Qs,uG),e(uG,p4o),e(Qs,_4o),e(k,b4o),e(k,Ws),e(Ws,Lue),e(Lue,v4o),e(Ws,F4o),e(Ws,pG),e(pG,T4o),e(Ws,M4o),e(Ws,_G),e(_G,E4o),e(Ws,C4o),e(k,w4o),e(k,Us),e(Us,yue),e(yue,A4o),e(Us,L4o),e(Us,bG),e(bG,y4o),e(Us,x4o),e(Us,vG),e(vG,$4o),e(Us,k4o),e(k,S4o),e(k,Hs),e(Hs,xue),e(xue,R4o),e(Hs,P4o),e(Hs,FG),e(FG,B4o),e(Hs,I4o),e(Hs,TG),e(TG,N4o),e(Hs,q4o),e(k,j4o),e(k,ju),e(ju,$ue),e($ue,D4o),e(ju,G4o),e(ju,MG),e(MG,O4o),e(ju,V4o),e(k,X4o),e(k,Js),e(Js,kue),e(kue,z4o),e(Js,Q4o),e(Js,EG),e(EG,W4o),e(Js,U4o),e(Js,CG),e(CG,H4o),e(Js,J4o),e(k,Y4o),e(k,Du),e(Du,Sue),e(Sue,Z4o),e(Du,K4o),e(Du,wG),e(wG,eCo),e(Du,oCo),e(k,rCo),e(k,Gu),e(Gu,Rue),e(Rue,tCo),e(Gu,aCo),e(Gu,AG),e(AG,nCo),e(Gu,sCo),e(k,lCo),e(k,Ys),e(Ys,Pue),e(Pue,iCo),e(Ys,dCo),e(Ys,LG),e(LG,cCo),e(Ys,mCo),e(Ys,yG),e(yG,fCo),e(Ys,gCo),e(k,hCo),e(k,Zs),e(Zs,Bue),e(Bue,uCo),e(Zs,pCo),e(Zs,xG),e(xG,_Co),e(Zs,bCo),e(Zs,$G),e($G,vCo),e(Zs,FCo),e(k,TCo),e(k,Ks),e(Ks,Iue),e(Iue,MCo),e(Ks,ECo),e(Ks,kG),e(kG,CCo),e(Ks,wCo),e(Ks,SG),e(SG,ACo),e(Ks,LCo),e(k,yCo),e(k,Ou),e(Ou,Nue),e(Nue,xCo),e(Ou,$Co),e(Ou,RG),e(RG,kCo),e(Ou,SCo),e(k,RCo),e(k,el),e(el,que),e(que,PCo),e(el,BCo),e(el,PG),e(PG,ICo),e(el,NCo),e(el,BG),e(BG,qCo),e(el,jCo),e(k,DCo),e(k,ol),e(ol,jue),e(jue,GCo),e(ol,OCo),e(ol,IG),e(IG,VCo),e(ol,XCo),e(ol,NG),e(NG,zCo),e(ol,QCo),e(k,WCo),e(k,rl),e(rl,Due),e(Due,UCo),e(rl,HCo),e(rl,qG),e(qG,JCo),e(rl,YCo),e(rl,jG),e(jG,ZCo),e(rl,KCo),e(k,e3o),e(k,tl),e(tl,Gue),e(Gue,o3o),e(tl,r3o),e(tl,DG),e(DG,t3o),e(tl,a3o),e(tl,GG),e(GG,n3o),e(tl,s3o),e(k,l3o),e(k,al),e(al,Oue),e(Oue,i3o),e(al,d3o),e(al,OG),e(OG,c3o),e(al,m3o),e(al,VG),e(VG,f3o),e(al,g3o),e(k,h3o),e(k,nl),e(nl,Vue),e(Vue,u3o),e(nl,p3o),e(nl,XG),e(XG,_3o),e(nl,b3o),e(nl,zG),e(zG,v3o),e(nl,F3o),e(k,T3o),e(k,sl),e(sl,Xue),e(Xue,M3o),e(sl,E3o),e(sl,QG),e(QG,C3o),e(sl,w3o),e(sl,WG),e(WG,A3o),e(sl,L3o),e(k,y3o),e(k,ll),e(ll,zue),e(zue,x3o),e(ll,$3o),e(ll,UG),e(UG,k3o),e(ll,S3o),e(ll,HG),e(HG,R3o),e(ll,P3o),e(k,B3o),e(k,Vu),e(Vu,Que),e(Que,I3o),e(Vu,N3o),e(Vu,JG),e(JG,q3o),e(Vu,j3o),e(k,D3o),e(k,il),e(il,Wue),e(Wue,G3o),e(il,O3o),e(il,YG),e(YG,V3o),e(il,X3o),e(il,ZG),e(ZG,z3o),e(il,Q3o),e(k,W3o),e(k,dl),e(dl,Uue),e(Uue,U3o),e(dl,H3o),e(dl,KG),e(KG,J3o),e(dl,Y3o),e(dl,eO),e(eO,Z3o),e(dl,K3o),e(k,e5o),e(k,Xu),e(Xu,Hue),e(Hue,o5o),e(Xu,r5o),e(Xu,oO),e(oO,t5o),e(Xu,a5o),e(k,n5o),e(k,zu),e(zu,Jue),e(Jue,s5o),e(zu,l5o),e(zu,rO),e(rO,i5o),e(zu,d5o),e(k,c5o),e(k,Qu),e(Qu,Yue),e(Yue,m5o),e(Qu,f5o),e(Qu,tO),e(tO,g5o),e(Qu,h5o),e(k,u5o),e(k,Wu),e(Wu,Zue),e(Zue,p5o),e(Wu,_5o),e(Wu,aO),e(aO,b5o),e(Wu,v5o),e(k,F5o),e(k,cl),e(cl,Kue),e(Kue,T5o),e(cl,M5o),e(cl,nO),e(nO,E5o),e(cl,C5o),e(cl,sO),e(sO,w5o),e(cl,A5o),e(k,L5o),e(k,Uu),e(Uu,epe),e(epe,y5o),e(Uu,x5o),e(Uu,lO),e(lO,$5o),e(Uu,k5o),e(k,S5o),e(k,ml),e(ml,ope),e(ope,R5o),e(ml,P5o),e(ml,iO),e(iO,B5o),e(ml,I5o),e(ml,dO),e(dO,N5o),e(ml,q5o),e(k,j5o),e(k,fl),e(fl,rpe),e(rpe,D5o),e(fl,G5o),e(fl,cO),e(cO,O5o),e(fl,V5o),e(fl,mO),e(mO,X5o),e(fl,z5o),e(k,Q5o),e(k,gl),e(gl,tpe),e(tpe,W5o),e(gl,U5o),e(gl,fO),e(fO,H5o),e(gl,J5o),e(gl,gO),e(gO,Y5o),e(gl,Z5o),e(k,K5o),e(k,hl),e(hl,ape),e(ape,e0o),e(hl,o0o),e(hl,hO),e(hO,r0o),e(hl,t0o),e(hl,uO),e(uO,a0o),e(hl,n0o),e(k,s0o),e(k,ul),e(ul,npe),e(npe,l0o),e(ul,i0o),e(ul,pO),e(pO,d0o),e(ul,c0o),e(ul,_O),e(_O,m0o),e(ul,f0o),e(k,g0o),e(k,pl),e(pl,spe),e(spe,h0o),e(pl,u0o),e(pl,bO),e(bO,p0o),e(pl,_0o),e(pl,vO),e(vO,b0o),e(pl,v0o),e(k,F0o),e(k,Hu),e(Hu,lpe),e(lpe,T0o),e(Hu,M0o),e(Hu,FO),e(FO,E0o),e(Hu,C0o),e(k,w0o),e(k,Ju),e(Ju,ipe),e(ipe,A0o),e(Ju,L0o),e(Ju,TO),e(TO,y0o),e(Ju,x0o),e(k,$0o),e(k,_l),e(_l,dpe),e(dpe,k0o),e(_l,S0o),e(_l,MO),e(MO,R0o),e(_l,P0o),e(_l,EO),e(EO,B0o),e(_l,I0o),e(k,N0o),e(k,bl),e(bl,cpe),e(cpe,q0o),e(bl,j0o),e(bl,CO),e(CO,D0o),e(bl,G0o),e(bl,wO),e(wO,O0o),e(bl,V0o),e(k,X0o),e(k,vl),e(vl,mpe),e(mpe,z0o),e(vl,Q0o),e(vl,AO),e(AO,W0o),e(vl,U0o),e(vl,LO),e(LO,H0o),e(vl,J0o),e(k,Y0o),e(k,Yu),e(Yu,fpe),e(fpe,Z0o),e(Yu,K0o),e(Yu,yO),e(yO,ewo),e(Yu,owo),e(k,rwo),e(k,Zu),e(Zu,gpe),e(gpe,two),e(Zu,awo),e(Zu,xO),e(xO,nwo),e(Zu,swo),e(k,lwo),e(k,Ku),e(Ku,hpe),e(hpe,iwo),e(Ku,dwo),e(Ku,$O),e($O,cwo),e(Ku,mwo),e(k,fwo),e(k,Fl),e(Fl,upe),e(upe,gwo),e(Fl,hwo),e(Fl,kO),e(kO,uwo),e(Fl,pwo),e(Fl,SO),e(SO,_wo),e(Fl,bwo),e(k,vwo),e(k,Tl),e(Tl,ppe),e(ppe,Fwo),e(Tl,Two),e(Tl,RO),e(RO,Mwo),e(Tl,Ewo),e(Tl,PO),e(PO,Cwo),e(Tl,wwo),e(k,Awo),e(k,ep),e(ep,_pe),e(_pe,Lwo),e(ep,ywo),e(ep,BO),e(BO,xwo),e(ep,$wo),e(k,kwo),e(k,op),e(op,bpe),e(bpe,Swo),e(op,Rwo),e(op,IO),e(IO,Pwo),e(op,Bwo),e(k,Iwo),e(k,rp),e(rp,vpe),e(vpe,Nwo),e(rp,qwo),e(rp,NO),e(NO,jwo),e(rp,Dwo),e(k,Gwo),e(k,tp),e(tp,Fpe),e(Fpe,Owo),e(tp,Vwo),e(tp,qO),e(qO,Xwo),e(tp,zwo),e(k,Qwo),e(k,Ml),e(Ml,Tpe),e(Tpe,Wwo),e(Ml,Uwo),e(Ml,jO),e(jO,Hwo),e(Ml,Jwo),e(Ml,DO),e(DO,Ywo),e(Ml,Zwo),e(k,Kwo),e(k,El),e(El,Mpe),e(Mpe,eAo),e(El,oAo),e(El,GO),e(GO,rAo),e(El,tAo),e(El,OO),e(OO,aAo),e(El,nAo),e(k,sAo),e(k,ap),e(ap,Epe),e(Epe,lAo),e(ap,iAo),e(ap,VO),e(VO,dAo),e(ap,cAo),e(k,mAo),e(k,np),e(np,Cpe),e(Cpe,fAo),e(np,gAo),e(np,XO),e(XO,hAo),e(np,uAo),e(k,pAo),e(k,Cl),e(Cl,wpe),e(wpe,_Ao),e(Cl,bAo),e(Cl,zO),e(zO,vAo),e(Cl,FAo),e(Cl,QO),e(QO,TAo),e(Cl,MAo),e(k,EAo),e(k,wl),e(wl,Ape),e(Ape,CAo),e(wl,wAo),e(wl,WO),e(WO,AAo),e(wl,LAo),e(wl,UO),e(UO,yAo),e(wl,xAo),e(k,$Ao),e(k,Al),e(Al,Lpe),e(Lpe,kAo),e(Al,SAo),e(Al,HO),e(HO,RAo),e(Al,PAo),e(Al,JO),e(JO,BAo),e(Al,IAo),e(k,NAo),e(k,Ll),e(Ll,ype),e(ype,qAo),e(Ll,jAo),e(Ll,YO),e(YO,DAo),e(Ll,GAo),e(Ll,ZO),e(ZO,OAo),e(Ll,VAo),e(jr,XAo),M(sp,jr,null),e(Ro,zAo),e(Ro,lp),M(g$,lp,null),e(lp,QAo),e(lp,xpe),e(xpe,WAo),b(m,Yro,_),b(m,Ld,_),e(Ld,ip),e(ip,$pe),M(h$,$pe,null),e(Ld,UAo),e(Ld,kpe),e(kpe,HAo),b(m,Zro,_),b(m,Po,_),M(u$,Po,null),e(Po,JAo),e(Po,p$),e(p$,YAo),e(p$,KO),e(KO,ZAo),e(p$,KAo),e(Po,e6o),e(Po,_$),e(_$,o6o),e(_$,Spe),e(Spe,r6o),e(_$,t6o),e(Po,a6o),e(Po,Ye),M(b$,Ye,null),e(Ye,n6o),e(Ye,Rpe),e(Rpe,s6o),e(Ye,l6o),e(Ye,tn),e(tn,i6o),e(tn,Ppe),e(Ppe,d6o),e(tn,c6o),e(tn,Bpe),e(Bpe,m6o),e(tn,f6o),e(tn,Ipe),e(Ipe,g6o),e(tn,h6o),e(Ye,u6o),e(Ye,z),e(z,dp),e(dp,Npe),e(Npe,p6o),e(dp,_6o),e(dp,eV),e(eV,b6o),e(dp,v6o),e(z,F6o),e(z,cp),e(cp,qpe),e(qpe,T6o),e(cp,M6o),e(cp,oV),e(oV,E6o),e(cp,C6o),e(z,w6o),e(z,mp),e(mp,jpe),e(jpe,A6o),e(mp,L6o),e(mp,rV),e(rV,y6o),e(mp,x6o),e(z,$6o),e(z,fp),e(fp,Dpe),e(Dpe,k6o),e(fp,S6o),e(fp,tV),e(tV,R6o),e(fp,P6o),e(z,B6o),e(z,gp),e(gp,Gpe),e(Gpe,I6o),e(gp,N6o),e(gp,aV),e(aV,q6o),e(gp,j6o),e(z,D6o),e(z,hp),e(hp,Ope),e(Ope,G6o),e(hp,O6o),e(hp,nV),e(nV,V6o),e(hp,X6o),e(z,z6o),e(z,up),e(up,Vpe),e(Vpe,Q6o),e(up,W6o),e(up,sV),e(sV,U6o),e(up,H6o),e(z,J6o),e(z,pp),e(pp,Xpe),e(Xpe,Y6o),e(pp,Z6o),e(pp,lV),e(lV,K6o),e(pp,e7o),e(z,o7o),e(z,_p),e(_p,zpe),e(zpe,r7o),e(_p,t7o),e(_p,iV),e(iV,a7o),e(_p,n7o),e(z,s7o),e(z,bp),e(bp,Qpe),e(Qpe,l7o),e(bp,i7o),e(bp,dV),e(dV,d7o),e(bp,c7o),e(z,m7o),e(z,vp),e(vp,Wpe),e(Wpe,f7o),e(vp,g7o),e(vp,cV),e(cV,h7o),e(vp,u7o),e(z,p7o),e(z,Fp),e(Fp,Upe),e(Upe,_7o),e(Fp,b7o),e(Fp,mV),e(mV,v7o),e(Fp,F7o),e(z,T7o),e(z,Tp),e(Tp,Hpe),e(Hpe,M7o),e(Tp,E7o),e(Tp,fV),e(fV,C7o),e(Tp,w7o),e(z,A7o),e(z,Mp),e(Mp,Jpe),e(Jpe,L7o),e(Mp,y7o),e(Mp,gV),e(gV,x7o),e(Mp,$7o),e(z,k7o),e(z,Ep),e(Ep,Ype),e(Ype,S7o),e(Ep,R7o),e(Ep,hV),e(hV,P7o),e(Ep,B7o),e(z,I7o),e(z,Cp),e(Cp,Zpe),e(Zpe,N7o),e(Cp,q7o),e(Cp,uV),e(uV,j7o),e(Cp,D7o),e(z,G7o),e(z,wp),e(wp,Kpe),e(Kpe,O7o),e(wp,V7o),e(wp,pV),e(pV,X7o),e(wp,z7o),e(z,Q7o),e(z,Ap),e(Ap,e_e),e(e_e,W7o),e(Ap,U7o),e(Ap,_V),e(_V,H7o),e(Ap,J7o),e(z,Y7o),e(z,Lp),e(Lp,o_e),e(o_e,Z7o),e(Lp,K7o),e(Lp,bV),e(bV,eLo),e(Lp,oLo),e(z,rLo),e(z,yp),e(yp,r_e),e(r_e,tLo),e(yp,aLo),e(yp,vV),e(vV,nLo),e(yp,sLo),e(z,lLo),e(z,xp),e(xp,t_e),e(t_e,iLo),e(xp,dLo),e(xp,FV),e(FV,cLo),e(xp,mLo),e(z,fLo),e(z,$p),e($p,a_e),e(a_e,gLo),e($p,hLo),e($p,TV),e(TV,uLo),e($p,pLo),e(z,_Lo),e(z,kp),e(kp,n_e),e(n_e,bLo),e(kp,vLo),e(kp,MV),e(MV,FLo),e(kp,TLo),e(z,MLo),e(z,Sp),e(Sp,s_e),e(s_e,ELo),e(Sp,CLo),e(Sp,EV),e(EV,wLo),e(Sp,ALo),e(z,LLo),e(z,Rp),e(Rp,l_e),e(l_e,yLo),e(Rp,xLo),e(Rp,CV),e(CV,$Lo),e(Rp,kLo),e(z,SLo),e(z,Pp),e(Pp,i_e),e(i_e,RLo),e(Pp,PLo),e(Pp,wV),e(wV,BLo),e(Pp,ILo),e(z,NLo),e(z,Bp),e(Bp,d_e),e(d_e,qLo),e(Bp,jLo),e(Bp,AV),e(AV,DLo),e(Bp,GLo),e(z,OLo),e(z,Ip),e(Ip,c_e),e(c_e,VLo),e(Ip,XLo),e(Ip,LV),e(LV,zLo),e(Ip,QLo),e(z,WLo),e(z,Np),e(Np,m_e),e(m_e,ULo),e(Np,HLo),e(Np,yV),e(yV,JLo),e(Np,YLo),e(z,ZLo),e(z,qp),e(qp,f_e),e(f_e,KLo),e(qp,e8o),e(qp,xV),e(xV,o8o),e(qp,r8o),e(z,t8o),e(z,jp),e(jp,g_e),e(g_e,a8o),e(jp,n8o),e(jp,$V),e($V,s8o),e(jp,l8o),e(z,i8o),e(z,Dp),e(Dp,h_e),e(h_e,d8o),e(Dp,c8o),e(Dp,kV),e(kV,m8o),e(Dp,f8o),e(z,g8o),e(z,Gp),e(Gp,u_e),e(u_e,h8o),e(Gp,u8o),e(Gp,SV),e(SV,p8o),e(Gp,_8o),e(z,b8o),e(z,Op),e(Op,p_e),e(p_e,v8o),e(Op,F8o),e(Op,RV),e(RV,T8o),e(Op,M8o),e(z,E8o),e(z,Vp),e(Vp,__e),e(__e,C8o),e(Vp,w8o),e(Vp,PV),e(PV,A8o),e(Vp,L8o),e(z,y8o),e(z,Xp),e(Xp,b_e),e(b_e,x8o),e(Xp,$8o),e(Xp,BV),e(BV,k8o),e(Xp,S8o),e(z,R8o),e(z,zp),e(zp,v_e),e(v_e,P8o),e(zp,B8o),e(zp,IV),e(IV,I8o),e(zp,N8o),e(z,q8o),e(z,Qp),e(Qp,F_e),e(F_e,j8o),e(Qp,D8o),e(Qp,NV),e(NV,G8o),e(Qp,O8o),e(z,V8o),e(z,Wp),e(Wp,T_e),e(T_e,X8o),e(Wp,z8o),e(Wp,qV),e(qV,Q8o),e(Wp,W8o),e(z,U8o),e(z,Up),e(Up,M_e),e(M_e,H8o),e(Up,J8o),e(Up,jV),e(jV,Y8o),e(Up,Z8o),e(z,K8o),e(z,Hp),e(Hp,E_e),e(E_e,eyo),e(Hp,oyo),e(Hp,DV),e(DV,ryo),e(Hp,tyo),e(z,ayo),e(z,Jp),e(Jp,C_e),e(C_e,nyo),e(Jp,syo),e(Jp,GV),e(GV,lyo),e(Jp,iyo),e(z,dyo),e(z,Yp),e(Yp,w_e),e(w_e,cyo),e(Yp,myo),e(Yp,OV),e(OV,fyo),e(Yp,gyo),e(Ye,hyo),M(Zp,Ye,null),e(Ye,uyo),M(Kp,Ye,null),e(Po,pyo),e(Po,e_),M(v$,e_,null),e(e_,_yo),e(e_,A_e),e(A_e,byo),b(m,Kro,_),b(m,yd,_),e(yd,o_),e(o_,L_e),M(F$,L_e,null),e(yd,vyo),e(yd,y_e),e(y_e,Fyo),b(m,eto,_),b(m,Bo,_),M(T$,Bo,null),e(Bo,Tyo),e(Bo,M$),e(M$,Myo),e(M$,VV),e(VV,Eyo),e(M$,Cyo),e(Bo,wyo),e(Bo,E$),e(E$,Ayo),e(E$,x_e),e(x_e,Lyo),e(E$,yyo),e(Bo,xyo),e(Bo,Ze),M(C$,Ze,null),e(Ze,$yo),e(Ze,$_e),e($_e,kyo),e(Ze,Syo),e(Ze,xd),e(xd,Ryo),e(xd,k_e),e(k_e,Pyo),e(xd,Byo),e(xd,S_e),e(S_e,Iyo),e(xd,Nyo),e(Ze,qyo),e(Ze,se),e(se,r_),e(r_,R_e),e(R_e,jyo),e(r_,Dyo),e(r_,XV),e(XV,Gyo),e(r_,Oyo),e(se,Vyo),e(se,t_),e(t_,P_e),e(P_e,Xyo),e(t_,zyo),e(t_,zV),e(zV,Qyo),e(t_,Wyo),e(se,Uyo),e(se,a_),e(a_,B_e),e(B_e,Hyo),e(a_,Jyo),e(a_,QV),e(QV,Yyo),e(a_,Zyo),e(se,Kyo),e(se,n_),e(n_,I_e),e(I_e,e9o),e(n_,o9o),e(n_,WV),e(WV,r9o),e(n_,t9o),e(se,a9o),e(se,s_),e(s_,N_e),e(N_e,n9o),e(s_,s9o),e(s_,UV),e(UV,l9o),e(s_,i9o),e(se,d9o),e(se,l_),e(l_,q_e),e(q_e,c9o),e(l_,m9o),e(l_,HV),e(HV,f9o),e(l_,g9o),e(se,h9o),e(se,i_),e(i_,j_e),e(j_e,u9o),e(i_,p9o),e(i_,JV),e(JV,_9o),e(i_,b9o),e(se,v9o),e(se,d_),e(d_,D_e),e(D_e,F9o),e(d_,T9o),e(d_,YV),e(YV,M9o),e(d_,E9o),e(se,C9o),e(se,c_),e(c_,G_e),e(G_e,w9o),e(c_,A9o),e(c_,ZV),e(ZV,L9o),e(c_,y9o),e(se,x9o),e(se,m_),e(m_,O_e),e(O_e,$9o),e(m_,k9o),e(m_,KV),e(KV,S9o),e(m_,R9o),e(se,P9o),e(se,f_),e(f_,V_e),e(V_e,B9o),e(f_,I9o),e(f_,eX),e(eX,N9o),e(f_,q9o),e(se,j9o),e(se,g_),e(g_,X_e),e(X_e,D9o),e(g_,G9o),e(g_,oX),e(oX,O9o),e(g_,V9o),e(se,X9o),e(se,h_),e(h_,z_e),e(z_e,z9o),e(h_,Q9o),e(h_,rX),e(rX,W9o),e(h_,U9o),e(se,H9o),e(se,u_),e(u_,Q_e),e(Q_e,J9o),e(u_,Y9o),e(u_,tX),e(tX,Z9o),e(u_,K9o),e(se,exo),e(se,p_),e(p_,W_e),e(W_e,oxo),e(p_,rxo),e(p_,aX),e(aX,txo),e(p_,axo),e(se,nxo),e(se,__),e(__,U_e),e(U_e,sxo),e(__,lxo),e(__,nX),e(nX,ixo),e(__,dxo),e(se,cxo),e(se,b_),e(b_,H_e),e(H_e,mxo),e(b_,fxo),e(b_,sX),e(sX,gxo),e(b_,hxo),e(se,uxo),e(se,v_),e(v_,J_e),e(J_e,pxo),e(v_,_xo),e(v_,lX),e(lX,bxo),e(v_,vxo),e(se,Fxo),e(se,F_),e(F_,Y_e),e(Y_e,Txo),e(F_,Mxo),e(F_,iX),e(iX,Exo),e(F_,Cxo),e(se,wxo),e(se,T_),e(T_,Z_e),e(Z_e,Axo),e(T_,Lxo),e(T_,dX),e(dX,yxo),e(T_,xxo),e(se,$xo),e(se,M_),e(M_,K_e),e(K_e,kxo),e(M_,Sxo),e(M_,cX),e(cX,Rxo),e(M_,Pxo),e(se,Bxo),e(se,E_),e(E_,e1e),e(e1e,Ixo),e(E_,Nxo),e(E_,mX),e(mX,qxo),e(E_,jxo),e(se,Dxo),e(se,C_),e(C_,o1e),e(o1e,Gxo),e(C_,Oxo),e(C_,fX),e(fX,Vxo),e(C_,Xxo),e(Ze,zxo),M(w_,Ze,null),e(Ze,Qxo),M(A_,Ze,null),e(Bo,Wxo),e(Bo,L_),M(w$,L_,null),e(L_,Uxo),e(L_,r1e),e(r1e,Hxo),b(m,oto,_),b(m,$d,_),e($d,y_),e(y_,t1e),M(A$,t1e,null),e($d,Jxo),e($d,a1e),e(a1e,Yxo),b(m,rto,_),b(m,Io,_),M(L$,Io,null),e(Io,Zxo),e(Io,kd),e(kd,Kxo),e(kd,gX),e(gX,e$o),e(kd,o$o),e(kd,hX),e(hX,r$o),e(kd,t$o),e(Io,a$o),e(Io,y$),e(y$,n$o),e(y$,n1e),e(n1e,s$o),e(y$,l$o),e(Io,i$o),e(Io,Tt),M(x$,Tt,null),e(Tt,d$o),e(Tt,s1e),e(s1e,c$o),e(Tt,m$o),e(Tt,Sd),e(Sd,f$o),e(Sd,l1e),e(l1e,g$o),e(Sd,h$o),e(Sd,uX),e(uX,u$o),e(Sd,p$o),e(Tt,_$o),M(x_,Tt,null),e(Io,b$o),e(Io,Ke),M($$,Ke,null),e(Ke,v$o),e(Ke,i1e),e(i1e,F$o),e(Ke,T$o),e(Ke,an),e(an,M$o),e(an,d1e),e(d1e,E$o),e(an,C$o),e(an,c1e),e(c1e,w$o),e(an,A$o),e(an,m1e),e(m1e,L$o),e(an,y$o),e(Ke,x$o),e(Ke,y),e(y,$_),e($_,f1e),e(f1e,$$o),e($_,k$o),e($_,pX),e(pX,S$o),e($_,R$o),e(y,P$o),e(y,k_),e(k_,g1e),e(g1e,B$o),e(k_,I$o),e(k_,_X),e(_X,N$o),e(k_,q$o),e(y,j$o),e(y,S_),e(S_,h1e),e(h1e,D$o),e(S_,G$o),e(S_,bX),e(bX,O$o),e(S_,V$o),e(y,X$o),e(y,R_),e(R_,u1e),e(u1e,z$o),e(R_,Q$o),e(R_,vX),e(vX,W$o),e(R_,U$o),e(y,H$o),e(y,P_),e(P_,p1e),e(p1e,J$o),e(P_,Y$o),e(P_,FX),e(FX,Z$o),e(P_,K$o),e(y,eko),e(y,B_),e(B_,_1e),e(_1e,oko),e(B_,rko),e(B_,TX),e(TX,tko),e(B_,ako),e(y,nko),e(y,I_),e(I_,b1e),e(b1e,sko),e(I_,lko),e(I_,MX),e(MX,iko),e(I_,dko),e(y,cko),e(y,N_),e(N_,v1e),e(v1e,mko),e(N_,fko),e(N_,EX),e(EX,gko),e(N_,hko),e(y,uko),e(y,q_),e(q_,F1e),e(F1e,pko),e(q_,_ko),e(q_,CX),e(CX,bko),e(q_,vko),e(y,Fko),e(y,j_),e(j_,T1e),e(T1e,Tko),e(j_,Mko),e(j_,wX),e(wX,Eko),e(j_,Cko),e(y,wko),e(y,D_),e(D_,M1e),e(M1e,Ako),e(D_,Lko),e(D_,AX),e(AX,yko),e(D_,xko),e(y,$ko),e(y,G_),e(G_,E1e),e(E1e,kko),e(G_,Sko),e(G_,LX),e(LX,Rko),e(G_,Pko),e(y,Bko),e(y,O_),e(O_,C1e),e(C1e,Iko),e(O_,Nko),e(O_,yX),e(yX,qko),e(O_,jko),e(y,Dko),e(y,V_),e(V_,w1e),e(w1e,Gko),e(V_,Oko),e(V_,xX),e(xX,Vko),e(V_,Xko),e(y,zko),e(y,X_),e(X_,A1e),e(A1e,Qko),e(X_,Wko),e(X_,$X),e($X,Uko),e(X_,Hko),e(y,Jko),e(y,z_),e(z_,L1e),e(L1e,Yko),e(z_,Zko),e(z_,kX),e(kX,Kko),e(z_,eSo),e(y,oSo),e(y,Q_),e(Q_,y1e),e(y1e,rSo),e(Q_,tSo),e(Q_,SX),e(SX,aSo),e(Q_,nSo),e(y,sSo),e(y,W_),e(W_,x1e),e(x1e,lSo),e(W_,iSo),e(W_,RX),e(RX,dSo),e(W_,cSo),e(y,mSo),e(y,U_),e(U_,$1e),e($1e,fSo),e(U_,gSo),e(U_,PX),e(PX,hSo),e(U_,uSo),e(y,pSo),e(y,H_),e(H_,k1e),e(k1e,_So),e(H_,bSo),e(H_,BX),e(BX,vSo),e(H_,FSo),e(y,TSo),e(y,J_),e(J_,S1e),e(S1e,MSo),e(J_,ESo),e(J_,IX),e(IX,CSo),e(J_,wSo),e(y,ASo),e(y,Y_),e(Y_,R1e),e(R1e,LSo),e(Y_,ySo),e(Y_,NX),e(NX,xSo),e(Y_,$So),e(y,kSo),e(y,Z_),e(Z_,P1e),e(P1e,SSo),e(Z_,RSo),e(Z_,qX),e(qX,PSo),e(Z_,BSo),e(y,ISo),e(y,K_),e(K_,B1e),e(B1e,NSo),e(K_,qSo),e(K_,jX),e(jX,jSo),e(K_,DSo),e(y,GSo),e(y,e1),e(e1,I1e),e(I1e,OSo),e(e1,VSo),e(e1,DX),e(DX,XSo),e(e1,zSo),e(y,QSo),e(y,o1),e(o1,N1e),e(N1e,WSo),e(o1,USo),e(o1,GX),e(GX,HSo),e(o1,JSo),e(y,YSo),e(y,r1),e(r1,q1e),e(q1e,ZSo),e(r1,KSo),e(r1,OX),e(OX,eRo),e(r1,oRo),e(y,rRo),e(y,t1),e(t1,j1e),e(j1e,tRo),e(t1,aRo),e(t1,VX),e(VX,nRo),e(t1,sRo),e(y,lRo),e(y,a1),e(a1,D1e),e(D1e,iRo),e(a1,dRo),e(a1,XX),e(XX,cRo),e(a1,mRo),e(y,fRo),e(y,n1),e(n1,G1e),e(G1e,gRo),e(n1,hRo),e(n1,zX),e(zX,uRo),e(n1,pRo),e(y,_Ro),e(y,s1),e(s1,O1e),e(O1e,bRo),e(s1,vRo),e(s1,QX),e(QX,FRo),e(s1,TRo),e(y,MRo),e(y,l1),e(l1,V1e),e(V1e,ERo),e(l1,CRo),e(l1,WX),e(WX,wRo),e(l1,ARo),e(y,LRo),e(y,i1),e(i1,X1e),e(X1e,yRo),e(i1,xRo),e(i1,UX),e(UX,$Ro),e(i1,kRo),e(y,SRo),e(y,d1),e(d1,z1e),e(z1e,RRo),e(d1,PRo),e(d1,HX),e(HX,BRo),e(d1,IRo),e(y,NRo),e(y,c1),e(c1,Q1e),e(Q1e,qRo),e(c1,jRo),e(c1,JX),e(JX,DRo),e(c1,GRo),e(y,ORo),e(y,m1),e(m1,W1e),e(W1e,VRo),e(m1,XRo),e(m1,YX),e(YX,zRo),e(m1,QRo),e(y,WRo),e(y,f1),e(f1,U1e),e(U1e,URo),e(f1,HRo),e(f1,ZX),e(ZX,JRo),e(f1,YRo),e(y,ZRo),e(y,g1),e(g1,H1e),e(H1e,KRo),e(g1,ePo),e(g1,KX),e(KX,oPo),e(g1,rPo),e(y,tPo),e(y,h1),e(h1,J1e),e(J1e,aPo),e(h1,nPo),e(h1,ez),e(ez,sPo),e(h1,lPo),e(y,iPo),e(y,yl),e(yl,Y1e),e(Y1e,dPo),e(yl,cPo),e(yl,oz),e(oz,mPo),e(yl,fPo),e(yl,rz),e(rz,gPo),e(yl,hPo),e(y,uPo),e(y,u1),e(u1,Z1e),e(Z1e,pPo),e(u1,_Po),e(u1,tz),e(tz,bPo),e(u1,vPo),e(y,FPo),e(y,p1),e(p1,K1e),e(K1e,TPo),e(p1,MPo),e(p1,az),e(az,EPo),e(p1,CPo),e(y,wPo),e(y,_1),e(_1,e2e),e(e2e,APo),e(_1,LPo),e(_1,nz),e(nz,yPo),e(_1,xPo),e(y,$Po),e(y,b1),e(b1,o2e),e(o2e,kPo),e(b1,SPo),e(b1,sz),e(sz,RPo),e(b1,PPo),e(y,BPo),e(y,v1),e(v1,r2e),e(r2e,IPo),e(v1,NPo),e(v1,lz),e(lz,qPo),e(v1,jPo),e(y,DPo),e(y,F1),e(F1,t2e),e(t2e,GPo),e(F1,OPo),e(F1,iz),e(iz,VPo),e(F1,XPo),e(y,zPo),e(y,T1),e(T1,a2e),e(a2e,QPo),e(T1,WPo),e(T1,dz),e(dz,UPo),e(T1,HPo),e(y,JPo),e(y,M1),e(M1,n2e),e(n2e,YPo),e(M1,ZPo),e(M1,cz),e(cz,KPo),e(M1,eBo),e(y,oBo),e(y,E1),e(E1,s2e),e(s2e,rBo),e(E1,tBo),e(E1,mz),e(mz,aBo),e(E1,nBo),e(y,sBo),e(y,C1),e(C1,l2e),e(l2e,lBo),e(C1,iBo),e(C1,fz),e(fz,dBo),e(C1,cBo),e(y,mBo),e(y,w1),e(w1,i2e),e(i2e,fBo),e(w1,gBo),e(w1,gz),e(gz,hBo),e(w1,uBo),e(y,pBo),e(y,A1),e(A1,d2e),e(d2e,_Bo),e(A1,bBo),e(A1,hz),e(hz,vBo),e(A1,FBo),e(y,TBo),e(y,L1),e(L1,c2e),e(c2e,MBo),e(L1,EBo),e(L1,uz),e(uz,CBo),e(L1,wBo),e(y,ABo),e(y,y1),e(y1,m2e),e(m2e,LBo),e(y1,yBo),e(y1,pz),e(pz,xBo),e(y1,$Bo),e(y,kBo),e(y,x1),e(x1,f2e),e(f2e,SBo),e(x1,RBo),e(x1,_z),e(_z,PBo),e(x1,BBo),e(y,IBo),e(y,$1),e($1,g2e),e(g2e,NBo),e($1,qBo),e($1,bz),e(bz,jBo),e($1,DBo),e(y,GBo),e(y,k1),e(k1,h2e),e(h2e,OBo),e(k1,VBo),e(k1,vz),e(vz,XBo),e(k1,zBo),e(y,QBo),e(y,S1),e(S1,u2e),e(u2e,WBo),e(S1,UBo),e(S1,Fz),e(Fz,HBo),e(S1,JBo),e(y,YBo),e(y,R1),e(R1,p2e),e(p2e,ZBo),e(R1,KBo),e(R1,Tz),e(Tz,eIo),e(R1,oIo),e(y,rIo),e(y,P1),e(P1,_2e),e(_2e,tIo),e(P1,aIo),e(P1,Mz),e(Mz,nIo),e(P1,sIo),e(y,lIo),e(y,B1),e(B1,b2e),e(b2e,iIo),e(B1,dIo),e(B1,Ez),e(Ez,cIo),e(B1,mIo),e(y,fIo),e(y,I1),e(I1,v2e),e(v2e,gIo),e(I1,hIo),e(I1,Cz),e(Cz,uIo),e(I1,pIo),e(y,_Io),e(y,N1),e(N1,F2e),e(F2e,bIo),e(N1,vIo),e(N1,wz),e(wz,FIo),e(N1,TIo),e(y,MIo),e(y,q1),e(q1,T2e),e(T2e,EIo),e(q1,CIo),e(q1,Az),e(Az,wIo),e(q1,AIo),e(y,LIo),e(y,j1),e(j1,M2e),e(M2e,yIo),e(j1,xIo),e(j1,Lz),e(Lz,$Io),e(j1,kIo),e(y,SIo),e(y,D1),e(D1,E2e),e(E2e,RIo),e(D1,PIo),e(D1,yz),e(yz,BIo),e(D1,IIo),e(y,NIo),e(y,G1),e(G1,C2e),e(C2e,qIo),e(G1,jIo),e(G1,xz),e(xz,DIo),e(G1,GIo),e(y,OIo),e(y,O1),e(O1,w2e),e(w2e,VIo),e(O1,XIo),e(O1,$z),e($z,zIo),e(O1,QIo),e(y,WIo),e(y,V1),e(V1,A2e),e(A2e,UIo),e(V1,HIo),e(V1,kz),e(kz,JIo),e(V1,YIo),e(y,ZIo),e(y,X1),e(X1,L2e),e(L2e,KIo),e(X1,eNo),e(X1,Sz),e(Sz,oNo),e(X1,rNo),e(y,tNo),e(y,z1),e(z1,y2e),e(y2e,aNo),e(z1,nNo),e(z1,Rz),e(Rz,sNo),e(z1,lNo),e(y,iNo),e(y,Q1),e(Q1,x2e),e(x2e,dNo),e(Q1,cNo),e(Q1,Pz),e(Pz,mNo),e(Q1,fNo),e(y,gNo),e(y,W1),e(W1,$2e),e($2e,hNo),e(W1,uNo),e(W1,Bz),e(Bz,pNo),e(W1,_No),e(y,bNo),e(y,U1),e(U1,k2e),e(k2e,vNo),e(U1,FNo),e(U1,Iz),e(Iz,TNo),e(U1,MNo),e(y,ENo),e(y,H1),e(H1,S2e),e(S2e,CNo),e(H1,wNo),e(H1,Nz),e(Nz,ANo),e(H1,LNo),e(y,yNo),e(y,J1),e(J1,R2e),e(R2e,xNo),e(J1,$No),e(J1,qz),e(qz,kNo),e(J1,SNo),e(y,RNo),e(y,Y1),e(Y1,P2e),e(P2e,PNo),e(Y1,BNo),e(Y1,jz),e(jz,INo),e(Y1,NNo),e(y,qNo),e(y,Z1),e(Z1,B2e),e(B2e,jNo),e(Z1,DNo),e(Z1,Dz),e(Dz,GNo),e(Z1,ONo),e(y,VNo),e(y,K1),e(K1,I2e),e(I2e,XNo),e(K1,zNo),e(K1,Gz),e(Gz,QNo),e(K1,WNo),e(y,UNo),e(y,e2),e(e2,N2e),e(N2e,HNo),e(e2,JNo),e(e2,Oz),e(Oz,YNo),e(e2,ZNo),e(y,KNo),e(y,o2),e(o2,q2e),e(q2e,eqo),e(o2,oqo),e(o2,Vz),e(Vz,rqo),e(o2,tqo),e(y,aqo),e(y,r2),e(r2,j2e),e(j2e,nqo),e(r2,sqo),e(r2,Xz),e(Xz,lqo),e(r2,iqo),e(y,dqo),e(y,t2),e(t2,D2e),e(D2e,cqo),e(t2,mqo),e(t2,zz),e(zz,fqo),e(t2,gqo),e(y,hqo),e(y,a2),e(a2,G2e),e(G2e,uqo),e(a2,pqo),e(a2,Qz),e(Qz,_qo),e(a2,bqo),e(y,vqo),e(y,n2),e(n2,O2e),e(O2e,Fqo),e(n2,Tqo),e(n2,Wz),e(Wz,Mqo),e(n2,Eqo),e(y,Cqo),e(y,s2),e(s2,V2e),e(V2e,wqo),e(s2,Aqo),e(s2,Uz),e(Uz,Lqo),e(s2,yqo),e(y,xqo),e(y,l2),e(l2,X2e),e(X2e,$qo),e(l2,kqo),e(l2,Hz),e(Hz,Sqo),e(l2,Rqo),e(y,Pqo),e(y,i2),e(i2,z2e),e(z2e,Bqo),e(i2,Iqo),e(i2,Jz),e(Jz,Nqo),e(i2,qqo),e(y,jqo),e(y,d2),e(d2,Q2e),e(Q2e,Dqo),e(d2,Gqo),e(d2,Yz),e(Yz,Oqo),e(d2,Vqo),e(y,Xqo),e(y,c2),e(c2,W2e),e(W2e,zqo),e(c2,Qqo),e(c2,Zz),e(Zz,Wqo),e(c2,Uqo),e(y,Hqo),e(y,m2),e(m2,U2e),e(U2e,Jqo),e(m2,Yqo),e(m2,Kz),e(Kz,Zqo),e(m2,Kqo),e(y,ejo),e(y,f2),e(f2,H2e),e(H2e,ojo),e(f2,rjo),e(f2,eQ),e(eQ,tjo),e(f2,ajo),e(y,njo),e(y,g2),e(g2,J2e),e(J2e,sjo),e(g2,ljo),e(g2,oQ),e(oQ,ijo),e(g2,djo),e(y,cjo),e(y,h2),e(h2,Y2e),e(Y2e,mjo),e(h2,fjo),e(h2,rQ),e(rQ,gjo),e(h2,hjo),e(y,ujo),e(y,u2),e(u2,Z2e),e(Z2e,pjo),e(u2,_jo),e(u2,tQ),e(tQ,bjo),e(u2,vjo),e(y,Fjo),e(y,p2),e(p2,K2e),e(K2e,Tjo),e(p2,Mjo),e(p2,aQ),e(aQ,Ejo),e(p2,Cjo),e(y,wjo),e(y,_2),e(_2,ebe),e(ebe,Ajo),e(_2,Ljo),e(_2,nQ),e(nQ,yjo),e(_2,xjo),e(y,$jo),e(y,b2),e(b2,obe),e(obe,kjo),e(b2,Sjo),e(b2,sQ),e(sQ,Rjo),e(b2,Pjo),e(y,Bjo),e(y,v2),e(v2,rbe),e(rbe,Ijo),e(v2,Njo),e(v2,lQ),e(lQ,qjo),e(v2,jjo),e(y,Djo),e(y,F2),e(F2,tbe),e(tbe,Gjo),e(F2,Ojo),e(F2,iQ),e(iQ,Vjo),e(F2,Xjo),e(y,zjo),e(y,T2),e(T2,abe),e(abe,Qjo),e(T2,Wjo),e(T2,dQ),e(dQ,Ujo),e(T2,Hjo),e(y,Jjo),e(y,M2),e(M2,nbe),e(nbe,Yjo),e(M2,Zjo),e(M2,cQ),e(cQ,Kjo),e(M2,eDo),e(y,oDo),e(y,E2),e(E2,sbe),e(sbe,rDo),e(E2,tDo),e(E2,mQ),e(mQ,aDo),e(E2,nDo),e(y,sDo),e(y,C2),e(C2,lbe),e(lbe,lDo),e(C2,iDo),e(C2,fQ),e(fQ,dDo),e(C2,cDo),e(y,mDo),e(y,w2),e(w2,ibe),e(ibe,fDo),e(w2,gDo),e(w2,gQ),e(gQ,hDo),e(w2,uDo),e(y,pDo),e(y,A2),e(A2,dbe),e(dbe,_Do),e(A2,bDo),e(A2,hQ),e(hQ,vDo),e(A2,FDo),e(y,TDo),e(y,L2),e(L2,cbe),e(cbe,MDo),e(L2,EDo),e(L2,uQ),e(uQ,CDo),e(L2,wDo),e(y,ADo),e(y,y2),e(y2,mbe),e(mbe,LDo),e(y2,yDo),e(y2,pQ),e(pQ,xDo),e(y2,$Do),e(y,kDo),e(y,x2),e(x2,fbe),e(fbe,SDo),e(x2,RDo),e(x2,_Q),e(_Q,PDo),e(x2,BDo),e(y,IDo),e(y,$2),e($2,gbe),e(gbe,NDo),e($2,qDo),e($2,bQ),e(bQ,jDo),e($2,DDo),e(y,GDo),e(y,k2),e(k2,hbe),e(hbe,ODo),e(k2,VDo),e(k2,vQ),e(vQ,XDo),e(k2,zDo),e(y,QDo),e(y,S2),e(S2,ube),e(ube,WDo),e(S2,UDo),e(S2,FQ),e(FQ,HDo),e(S2,JDo),e(y,YDo),e(y,R2),e(R2,pbe),e(pbe,ZDo),e(R2,KDo),e(R2,TQ),e(TQ,eGo),e(R2,oGo),e(y,rGo),e(y,P2),e(P2,_be),e(_be,tGo),e(P2,aGo),e(P2,MQ),e(MQ,nGo),e(P2,sGo),e(y,lGo),e(y,B2),e(B2,bbe),e(bbe,iGo),e(B2,dGo),e(B2,EQ),e(EQ,cGo),e(B2,mGo),e(y,fGo),e(y,I2),e(I2,vbe),e(vbe,gGo),e(I2,hGo),e(I2,CQ),e(CQ,uGo),e(I2,pGo),e(y,_Go),e(y,N2),e(N2,Fbe),e(Fbe,bGo),e(N2,vGo),e(N2,wQ),e(wQ,FGo),e(N2,TGo),e(y,MGo),e(y,q2),e(q2,Tbe),e(Tbe,EGo),e(q2,CGo),e(q2,AQ),e(AQ,wGo),e(q2,AGo),e(y,LGo),e(y,j2),e(j2,Mbe),e(Mbe,yGo),e(j2,xGo),e(j2,LQ),e(LQ,$Go),e(j2,kGo),e(y,SGo),e(y,D2),e(D2,Ebe),e(Ebe,RGo),e(D2,PGo),e(D2,yQ),e(yQ,BGo),e(D2,IGo),e(y,NGo),e(y,G2),e(G2,Cbe),e(Cbe,qGo),e(G2,jGo),e(G2,xQ),e(xQ,DGo),e(G2,GGo),e(y,OGo),e(y,O2),e(O2,wbe),e(wbe,VGo),e(O2,XGo),e(O2,$Q),e($Q,zGo),e(O2,QGo),e(y,WGo),e(y,V2),e(V2,Abe),e(Abe,UGo),e(V2,HGo),e(V2,kQ),e(kQ,JGo),e(V2,YGo),e(y,ZGo),e(y,X2),e(X2,Lbe),e(Lbe,KGo),e(X2,eOo),e(X2,SQ),e(SQ,oOo),e(X2,rOo),e(y,tOo),e(y,z2),e(z2,ybe),e(ybe,aOo),e(z2,nOo),e(z2,RQ),e(RQ,sOo),e(z2,lOo),e(y,iOo),e(y,Q2),e(Q2,xbe),e(xbe,dOo),e(Q2,cOo),e(Q2,PQ),e(PQ,mOo),e(Q2,fOo),e(y,gOo),e(y,W2),e(W2,$be),e($be,hOo),e(W2,uOo),e(W2,BQ),e(BQ,pOo),e(W2,_Oo),e(y,bOo),e(y,U2),e(U2,kbe),e(kbe,vOo),e(U2,FOo),e(U2,IQ),e(IQ,TOo),e(U2,MOo),e(Ke,EOo),e(Ke,H2),e(H2,COo),e(H2,Sbe),e(Sbe,wOo),e(H2,AOo),e(H2,Rbe),e(Rbe,LOo),e(Ke,yOo),M(J2,Ke,null),b(m,tto,_),b(m,Rd,_),e(Rd,Y2),e(Y2,Pbe),M(k$,Pbe,null),e(Rd,xOo),e(Rd,Bbe),e(Bbe,$Oo),b(m,ato,_),b(m,No,_),M(S$,No,null),e(No,kOo),e(No,Pd),e(Pd,SOo),e(Pd,NQ),e(NQ,ROo),e(Pd,POo),e(Pd,qQ),e(qQ,BOo),e(Pd,IOo),e(No,NOo),e(No,R$),e(R$,qOo),e(R$,Ibe),e(Ibe,jOo),e(R$,DOo),e(No,GOo),e(No,Mt),M(P$,Mt,null),e(Mt,OOo),e(Mt,Nbe),e(Nbe,VOo),e(Mt,XOo),e(Mt,Bd),e(Bd,zOo),e(Bd,qbe),e(qbe,QOo),e(Bd,WOo),e(Bd,jQ),e(jQ,UOo),e(Bd,HOo),e(Mt,JOo),M(Z2,Mt,null),e(No,YOo),e(No,eo),M(B$,eo,null),e(eo,ZOo),e(eo,jbe),e(jbe,KOo),e(eo,eVo),e(eo,nn),e(nn,oVo),e(nn,Dbe),e(Dbe,rVo),e(nn,tVo),e(nn,Gbe),e(Gbe,aVo),e(nn,nVo),e(nn,Obe),e(Obe,sVo),e(nn,lVo),e(eo,iVo),e(eo,G),e(G,K2),e(K2,Vbe),e(Vbe,dVo),e(K2,cVo),e(K2,DQ),e(DQ,mVo),e(K2,fVo),e(G,gVo),e(G,eb),e(eb,Xbe),e(Xbe,hVo),e(eb,uVo),e(eb,GQ),e(GQ,pVo),e(eb,_Vo),e(G,bVo),e(G,ob),e(ob,zbe),e(zbe,vVo),e(ob,FVo),e(ob,OQ),e(OQ,TVo),e(ob,MVo),e(G,EVo),e(G,rb),e(rb,Qbe),e(Qbe,CVo),e(rb,wVo),e(rb,VQ),e(VQ,AVo),e(rb,LVo),e(G,yVo),e(G,tb),e(tb,Wbe),e(Wbe,xVo),e(tb,$Vo),e(tb,XQ),e(XQ,kVo),e(tb,SVo),e(G,RVo),e(G,ab),e(ab,Ube),e(Ube,PVo),e(ab,BVo),e(ab,zQ),e(zQ,IVo),e(ab,NVo),e(G,qVo),e(G,nb),e(nb,Hbe),e(Hbe,jVo),e(nb,DVo),e(nb,QQ),e(QQ,GVo),e(nb,OVo),e(G,VVo),e(G,sb),e(sb,Jbe),e(Jbe,XVo),e(sb,zVo),e(sb,WQ),e(WQ,QVo),e(sb,WVo),e(G,UVo),e(G,lb),e(lb,Ybe),e(Ybe,HVo),e(lb,JVo),e(lb,UQ),e(UQ,YVo),e(lb,ZVo),e(G,KVo),e(G,ib),e(ib,Zbe),e(Zbe,eXo),e(ib,oXo),e(ib,HQ),e(HQ,rXo),e(ib,tXo),e(G,aXo),e(G,db),e(db,Kbe),e(Kbe,nXo),e(db,sXo),e(db,JQ),e(JQ,lXo),e(db,iXo),e(G,dXo),e(G,cb),e(cb,eve),e(eve,cXo),e(cb,mXo),e(cb,YQ),e(YQ,fXo),e(cb,gXo),e(G,hXo),e(G,mb),e(mb,ove),e(ove,uXo),e(mb,pXo),e(mb,ZQ),e(ZQ,_Xo),e(mb,bXo),e(G,vXo),e(G,fb),e(fb,rve),e(rve,FXo),e(fb,TXo),e(fb,KQ),e(KQ,MXo),e(fb,EXo),e(G,CXo),e(G,gb),e(gb,tve),e(tve,wXo),e(gb,AXo),e(gb,eW),e(eW,LXo),e(gb,yXo),e(G,xXo),e(G,hb),e(hb,ave),e(ave,$Xo),e(hb,kXo),e(hb,oW),e(oW,SXo),e(hb,RXo),e(G,PXo),e(G,ub),e(ub,nve),e(nve,BXo),e(ub,IXo),e(ub,rW),e(rW,NXo),e(ub,qXo),e(G,jXo),e(G,pb),e(pb,sve),e(sve,DXo),e(pb,GXo),e(pb,tW),e(tW,OXo),e(pb,VXo),e(G,XXo),e(G,_b),e(_b,lve),e(lve,zXo),e(_b,QXo),e(_b,aW),e(aW,WXo),e(_b,UXo),e(G,HXo),e(G,bb),e(bb,ive),e(ive,JXo),e(bb,YXo),e(bb,nW),e(nW,ZXo),e(bb,KXo),e(G,ezo),e(G,vb),e(vb,dve),e(dve,ozo),e(vb,rzo),e(vb,sW),e(sW,tzo),e(vb,azo),e(G,nzo),e(G,Fb),e(Fb,cve),e(cve,szo),e(Fb,lzo),e(Fb,lW),e(lW,izo),e(Fb,dzo),e(G,czo),e(G,Tb),e(Tb,mve),e(mve,mzo),e(Tb,fzo),e(Tb,iW),e(iW,gzo),e(Tb,hzo),e(G,uzo),e(G,Mb),e(Mb,fve),e(fve,pzo),e(Mb,_zo),e(Mb,dW),e(dW,bzo),e(Mb,vzo),e(G,Fzo),e(G,Eb),e(Eb,gve),e(gve,Tzo),e(Eb,Mzo),e(Eb,cW),e(cW,Ezo),e(Eb,Czo),e(G,wzo),e(G,Cb),e(Cb,hve),e(hve,Azo),e(Cb,Lzo),e(Cb,mW),e(mW,yzo),e(Cb,xzo),e(G,$zo),e(G,wb),e(wb,uve),e(uve,kzo),e(wb,Szo),e(wb,fW),e(fW,Rzo),e(wb,Pzo),e(G,Bzo),e(G,Ab),e(Ab,pve),e(pve,Izo),e(Ab,Nzo),e(Ab,gW),e(gW,qzo),e(Ab,jzo),e(G,Dzo),e(G,Lb),e(Lb,_ve),e(_ve,Gzo),e(Lb,Ozo),e(Lb,hW),e(hW,Vzo),e(Lb,Xzo),e(G,zzo),e(G,yb),e(yb,bve),e(bve,Qzo),e(yb,Wzo),e(yb,uW),e(uW,Uzo),e(yb,Hzo),e(G,Jzo),e(G,xb),e(xb,vve),e(vve,Yzo),e(xb,Zzo),e(xb,pW),e(pW,Kzo),e(xb,eQo),e(G,oQo),e(G,$b),e($b,Fve),e(Fve,rQo),e($b,tQo),e($b,_W),e(_W,aQo),e($b,nQo),e(G,sQo),e(G,kb),e(kb,Tve),e(Tve,lQo),e(kb,iQo),e(kb,bW),e(bW,dQo),e(kb,cQo),e(G,mQo),e(G,Sb),e(Sb,Mve),e(Mve,fQo),e(Sb,gQo),e(Sb,vW),e(vW,hQo),e(Sb,uQo),e(G,pQo),e(G,Rb),e(Rb,Eve),e(Eve,_Qo),e(Rb,bQo),e(Rb,FW),e(FW,vQo),e(Rb,FQo),e(G,TQo),e(G,Pb),e(Pb,Cve),e(Cve,MQo),e(Pb,EQo),e(Pb,TW),e(TW,CQo),e(Pb,wQo),e(G,AQo),e(G,Bb),e(Bb,wve),e(wve,LQo),e(Bb,yQo),e(Bb,MW),e(MW,xQo),e(Bb,$Qo),e(G,kQo),e(G,Ib),e(Ib,Ave),e(Ave,SQo),e(Ib,RQo),e(Ib,EW),e(EW,PQo),e(Ib,BQo),e(G,IQo),e(G,Nb),e(Nb,Lve),e(Lve,NQo),e(Nb,qQo),e(Nb,CW),e(CW,jQo),e(Nb,DQo),e(G,GQo),e(G,qb),e(qb,yve),e(yve,OQo),e(qb,VQo),e(qb,wW),e(wW,XQo),e(qb,zQo),e(G,QQo),e(G,jb),e(jb,xve),e(xve,WQo),e(jb,UQo),e(jb,AW),e(AW,HQo),e(jb,JQo),e(G,YQo),e(G,Db),e(Db,$ve),e($ve,ZQo),e(Db,KQo),e(Db,LW),e(LW,eWo),e(Db,oWo),e(G,rWo),e(G,Gb),e(Gb,kve),e(kve,tWo),e(Gb,aWo),e(Gb,yW),e(yW,nWo),e(Gb,sWo),e(G,lWo),e(G,Ob),e(Ob,Sve),e(Sve,iWo),e(Ob,dWo),e(Ob,xW),e(xW,cWo),e(Ob,mWo),e(G,fWo),e(G,Vb),e(Vb,Rve),e(Rve,gWo),e(Vb,hWo),e(Vb,$W),e($W,uWo),e(Vb,pWo),e(G,_Wo),e(G,Xb),e(Xb,Pve),e(Pve,bWo),e(Xb,vWo),e(Xb,kW),e(kW,FWo),e(Xb,TWo),e(G,MWo),e(G,zb),e(zb,Bve),e(Bve,EWo),e(zb,CWo),e(zb,SW),e(SW,wWo),e(zb,AWo),e(G,LWo),e(G,Qb),e(Qb,Ive),e(Ive,yWo),e(Qb,xWo),e(Qb,RW),e(RW,$Wo),e(Qb,kWo),e(eo,SWo),e(eo,Wb),e(Wb,RWo),e(Wb,Nve),e(Nve,PWo),e(Wb,BWo),e(Wb,qve),e(qve,IWo),e(eo,NWo),M(Ub,eo,null),b(m,nto,_),b(m,Id,_),e(Id,Hb),e(Hb,jve),M(I$,jve,null),e(Id,qWo),e(Id,Dve),e(Dve,jWo),b(m,sto,_),b(m,qo,_),M(N$,qo,null),e(qo,DWo),e(qo,Nd),e(Nd,GWo),e(Nd,PW),e(PW,OWo),e(Nd,VWo),e(Nd,BW),e(BW,XWo),e(Nd,zWo),e(qo,QWo),e(qo,q$),e(q$,WWo),e(q$,Gve),e(Gve,UWo),e(q$,HWo),e(qo,JWo),e(qo,Et),M(j$,Et,null),e(Et,YWo),e(Et,Ove),e(Ove,ZWo),e(Et,KWo),e(Et,qd),e(qd,eUo),e(qd,Vve),e(Vve,oUo),e(qd,rUo),e(qd,IW),e(IW,tUo),e(qd,aUo),e(Et,nUo),M(Jb,Et,null),e(qo,sUo),e(qo,oo),M(D$,oo,null),e(oo,lUo),e(oo,Xve),e(Xve,iUo),e(oo,dUo),e(oo,sn),e(sn,cUo),e(sn,zve),e(zve,mUo),e(sn,fUo),e(sn,Qve),e(Qve,gUo),e(sn,hUo),e(sn,Wve),e(Wve,uUo),e(sn,pUo),e(oo,_Uo),e(oo,Q),e(Q,Yb),e(Yb,Uve),e(Uve,bUo),e(Yb,vUo),e(Yb,NW),e(NW,FUo),e(Yb,TUo),e(Q,MUo),e(Q,Zb),e(Zb,Hve),e(Hve,EUo),e(Zb,CUo),e(Zb,qW),e(qW,wUo),e(Zb,AUo),e(Q,LUo),e(Q,Kb),e(Kb,Jve),e(Jve,yUo),e(Kb,xUo),e(Kb,jW),e(jW,$Uo),e(Kb,kUo),e(Q,SUo),e(Q,ev),e(ev,Yve),e(Yve,RUo),e(ev,PUo),e(ev,DW),e(DW,BUo),e(ev,IUo),e(Q,NUo),e(Q,ov),e(ov,Zve),e(Zve,qUo),e(ov,jUo),e(ov,GW),e(GW,DUo),e(ov,GUo),e(Q,OUo),e(Q,rv),e(rv,Kve),e(Kve,VUo),e(rv,XUo),e(rv,OW),e(OW,zUo),e(rv,QUo),e(Q,WUo),e(Q,tv),e(tv,eFe),e(eFe,UUo),e(tv,HUo),e(tv,VW),e(VW,JUo),e(tv,YUo),e(Q,ZUo),e(Q,av),e(av,oFe),e(oFe,KUo),e(av,eHo),e(av,XW),e(XW,oHo),e(av,rHo),e(Q,tHo),e(Q,nv),e(nv,rFe),e(rFe,aHo),e(nv,nHo),e(nv,zW),e(zW,sHo),e(nv,lHo),e(Q,iHo),e(Q,sv),e(sv,tFe),e(tFe,dHo),e(sv,cHo),e(sv,QW),e(QW,mHo),e(sv,fHo),e(Q,gHo),e(Q,lv),e(lv,aFe),e(aFe,hHo),e(lv,uHo),e(lv,WW),e(WW,pHo),e(lv,_Ho),e(Q,bHo),e(Q,iv),e(iv,nFe),e(nFe,vHo),e(iv,FHo),e(iv,UW),e(UW,THo),e(iv,MHo),e(Q,EHo),e(Q,dv),e(dv,sFe),e(sFe,CHo),e(dv,wHo),e(dv,HW),e(HW,AHo),e(dv,LHo),e(Q,yHo),e(Q,cv),e(cv,lFe),e(lFe,xHo),e(cv,$Ho),e(cv,JW),e(JW,kHo),e(cv,SHo),e(Q,RHo),e(Q,mv),e(mv,iFe),e(iFe,PHo),e(mv,BHo),e(mv,YW),e(YW,IHo),e(mv,NHo),e(Q,qHo),e(Q,fv),e(fv,dFe),e(dFe,jHo),e(fv,DHo),e(fv,ZW),e(ZW,GHo),e(fv,OHo),e(Q,VHo),e(Q,gv),e(gv,cFe),e(cFe,XHo),e(gv,zHo),e(gv,KW),e(KW,QHo),e(gv,WHo),e(Q,UHo),e(Q,hv),e(hv,mFe),e(mFe,HHo),e(hv,JHo),e(hv,eU),e(eU,YHo),e(hv,ZHo),e(Q,KHo),e(Q,uv),e(uv,fFe),e(fFe,eJo),e(uv,oJo),e(uv,oU),e(oU,rJo),e(uv,tJo),e(Q,aJo),e(Q,pv),e(pv,gFe),e(gFe,nJo),e(pv,sJo),e(pv,rU),e(rU,lJo),e(pv,iJo),e(Q,dJo),e(Q,_v),e(_v,hFe),e(hFe,cJo),e(_v,mJo),e(_v,tU),e(tU,fJo),e(_v,gJo),e(Q,hJo),e(Q,bv),e(bv,uFe),e(uFe,uJo),e(bv,pJo),e(bv,aU),e(aU,_Jo),e(bv,bJo),e(Q,vJo),e(Q,vv),e(vv,pFe),e(pFe,FJo),e(vv,TJo),e(vv,nU),e(nU,MJo),e(vv,EJo),e(Q,CJo),e(Q,Fv),e(Fv,_Fe),e(_Fe,wJo),e(Fv,AJo),e(Fv,sU),e(sU,LJo),e(Fv,yJo),e(Q,xJo),e(Q,Tv),e(Tv,bFe),e(bFe,$Jo),e(Tv,kJo),e(Tv,lU),e(lU,SJo),e(Tv,RJo),e(Q,PJo),e(Q,Mv),e(Mv,vFe),e(vFe,BJo),e(Mv,IJo),e(Mv,iU),e(iU,NJo),e(Mv,qJo),e(Q,jJo),e(Q,Ev),e(Ev,FFe),e(FFe,DJo),e(Ev,GJo),e(Ev,dU),e(dU,OJo),e(Ev,VJo),e(Q,XJo),e(Q,Cv),e(Cv,TFe),e(TFe,zJo),e(Cv,QJo),e(Cv,cU),e(cU,WJo),e(Cv,UJo),e(Q,HJo),e(Q,wv),e(wv,MFe),e(MFe,JJo),e(wv,YJo),e(wv,mU),e(mU,ZJo),e(wv,KJo),e(Q,eYo),e(Q,Av),e(Av,EFe),e(EFe,oYo),e(Av,rYo),e(Av,fU),e(fU,tYo),e(Av,aYo),e(Q,nYo),e(Q,Lv),e(Lv,CFe),e(CFe,sYo),e(Lv,lYo),e(Lv,gU),e(gU,iYo),e(Lv,dYo),e(Q,cYo),e(Q,yv),e(yv,wFe),e(wFe,mYo),e(yv,fYo),e(yv,hU),e(hU,gYo),e(yv,hYo),e(Q,uYo),e(Q,xv),e(xv,AFe),e(AFe,pYo),e(xv,_Yo),e(xv,uU),e(uU,bYo),e(xv,vYo),e(Q,FYo),e(Q,$v),e($v,LFe),e(LFe,TYo),e($v,MYo),e($v,pU),e(pU,EYo),e($v,CYo),e(Q,wYo),e(Q,kv),e(kv,yFe),e(yFe,AYo),e(kv,LYo),e(kv,_U),e(_U,yYo),e(kv,xYo),e(Q,$Yo),e(Q,Sv),e(Sv,xFe),e(xFe,kYo),e(Sv,SYo),e(Sv,bU),e(bU,RYo),e(Sv,PYo),e(Q,BYo),e(Q,Rv),e(Rv,$Fe),e($Fe,IYo),e(Rv,NYo),e(Rv,vU),e(vU,qYo),e(Rv,jYo),e(Q,DYo),e(Q,Pv),e(Pv,kFe),e(kFe,GYo),e(Pv,OYo),e(Pv,FU),e(FU,VYo),e(Pv,XYo),e(Q,zYo),e(Q,Bv),e(Bv,SFe),e(SFe,QYo),e(Bv,WYo),e(Bv,TU),e(TU,UYo),e(Bv,HYo),e(Q,JYo),e(Q,Iv),e(Iv,RFe),e(RFe,YYo),e(Iv,ZYo),e(Iv,MU),e(MU,KYo),e(Iv,eZo),e(Q,oZo),e(Q,Nv),e(Nv,PFe),e(PFe,rZo),e(Nv,tZo),e(Nv,EU),e(EU,aZo),e(Nv,nZo),e(Q,sZo),e(Q,qv),e(qv,BFe),e(BFe,lZo),e(qv,iZo),e(qv,CU),e(CU,dZo),e(qv,cZo),e(oo,mZo),e(oo,jv),e(jv,fZo),e(jv,IFe),e(IFe,gZo),e(jv,hZo),e(jv,NFe),e(NFe,uZo),e(oo,pZo),M(Dv,oo,null),b(m,lto,_),b(m,jd,_),e(jd,Gv),e(Gv,qFe),M(G$,qFe,null),e(jd,_Zo),e(jd,jFe),e(jFe,bZo),b(m,ito,_),b(m,jo,_),M(O$,jo,null),e(jo,vZo),e(jo,Dd),e(Dd,FZo),e(Dd,wU),e(wU,TZo),e(Dd,MZo),e(Dd,AU),e(AU,EZo),e(Dd,CZo),e(jo,wZo),e(jo,V$),e(V$,AZo),e(V$,DFe),e(DFe,LZo),e(V$,yZo),e(jo,xZo),e(jo,Ct),M(X$,Ct,null),e(Ct,$Zo),e(Ct,GFe),e(GFe,kZo),e(Ct,SZo),e(Ct,Gd),e(Gd,RZo),e(Gd,OFe),e(OFe,PZo),e(Gd,BZo),e(Gd,LU),e(LU,IZo),e(Gd,NZo),e(Ct,qZo),M(Ov,Ct,null),e(jo,jZo),e(jo,ro),M(z$,ro,null),e(ro,DZo),e(ro,VFe),e(VFe,GZo),e(ro,OZo),e(ro,ln),e(ln,VZo),e(ln,XFe),e(XFe,XZo),e(ln,zZo),e(ln,zFe),e(zFe,QZo),e(ln,WZo),e(ln,QFe),e(QFe,UZo),e(ln,HZo),e(ro,JZo),e(ro,Q$),e(Q$,Vv),e(Vv,WFe),e(WFe,YZo),e(Vv,ZZo),e(Vv,yU),e(yU,KZo),e(Vv,eKo),e(Q$,oKo),e(Q$,Xv),e(Xv,UFe),e(UFe,rKo),e(Xv,tKo),e(Xv,xU),e(xU,aKo),e(Xv,nKo),e(ro,sKo),e(ro,zv),e(zv,lKo),e(zv,HFe),e(HFe,iKo),e(zv,dKo),e(zv,JFe),e(JFe,cKo),e(ro,mKo),M(Qv,ro,null),b(m,dto,_),b(m,Od,_),e(Od,Wv),e(Wv,YFe),M(W$,YFe,null),e(Od,fKo),e(Od,ZFe),e(ZFe,gKo),b(m,cto,_),b(m,Do,_),M(U$,Do,null),e(Do,hKo),e(Do,Vd),e(Vd,uKo),e(Vd,$U),e($U,pKo),e(Vd,_Ko),e(Vd,kU),e(kU,bKo),e(Vd,vKo),e(Do,FKo),e(Do,H$),e(H$,TKo),e(H$,KFe),e(KFe,MKo),e(H$,EKo),e(Do,CKo),e(Do,wt),M(J$,wt,null),e(wt,wKo),e(wt,eTe),e(eTe,AKo),e(wt,LKo),e(wt,Xd),e(Xd,yKo),e(Xd,oTe),e(oTe,xKo),e(Xd,$Ko),e(Xd,SU),e(SU,kKo),e(Xd,SKo),e(wt,RKo),M(Uv,wt,null),e(Do,PKo),e(Do,to),M(Y$,to,null),e(to,BKo),e(to,rTe),e(rTe,IKo),e(to,NKo),e(to,dn),e(dn,qKo),e(dn,tTe),e(tTe,jKo),e(dn,DKo),e(dn,aTe),e(aTe,GKo),e(dn,OKo),e(dn,nTe),e(nTe,VKo),e(dn,XKo),e(to,zKo),e(to,Y),e(Y,Hv),e(Hv,sTe),e(sTe,QKo),e(Hv,WKo),e(Hv,RU),e(RU,UKo),e(Hv,HKo),e(Y,JKo),e(Y,Jv),e(Jv,lTe),e(lTe,YKo),e(Jv,ZKo),e(Jv,PU),e(PU,KKo),e(Jv,eer),e(Y,oer),e(Y,Yv),e(Yv,iTe),e(iTe,rer),e(Yv,ter),e(Yv,BU),e(BU,aer),e(Yv,ner),e(Y,ser),e(Y,Zv),e(Zv,dTe),e(dTe,ler),e(Zv,ier),e(Zv,IU),e(IU,der),e(Zv,cer),e(Y,mer),e(Y,Kv),e(Kv,cTe),e(cTe,fer),e(Kv,ger),e(Kv,NU),e(NU,her),e(Kv,uer),e(Y,per),e(Y,eF),e(eF,mTe),e(mTe,_er),e(eF,ber),e(eF,qU),e(qU,ver),e(eF,Fer),e(Y,Ter),e(Y,oF),e(oF,fTe),e(fTe,Mer),e(oF,Eer),e(oF,jU),e(jU,Cer),e(oF,wer),e(Y,Aer),e(Y,rF),e(rF,gTe),e(gTe,Ler),e(rF,yer),e(rF,DU),e(DU,xer),e(rF,$er),e(Y,ker),e(Y,tF),e(tF,hTe),e(hTe,Ser),e(tF,Rer),e(tF,GU),e(GU,Per),e(tF,Ber),e(Y,Ier),e(Y,aF),e(aF,uTe),e(uTe,Ner),e(aF,qer),e(aF,OU),e(OU,jer),e(aF,Der),e(Y,Ger),e(Y,nF),e(nF,pTe),e(pTe,Oer),e(nF,Ver),e(nF,VU),e(VU,Xer),e(nF,zer),e(Y,Qer),e(Y,sF),e(sF,_Te),e(_Te,Wer),e(sF,Uer),e(sF,XU),e(XU,Her),e(sF,Jer),e(Y,Yer),e(Y,lF),e(lF,bTe),e(bTe,Zer),e(lF,Ker),e(lF,zU),e(zU,eor),e(lF,oor),e(Y,ror),e(Y,iF),e(iF,vTe),e(vTe,tor),e(iF,aor),e(iF,QU),e(QU,nor),e(iF,sor),e(Y,lor),e(Y,dF),e(dF,FTe),e(FTe,ior),e(dF,dor),e(dF,WU),e(WU,cor),e(dF,mor),e(Y,gor),e(Y,cF),e(cF,TTe),e(TTe,hor),e(cF,uor),e(cF,UU),e(UU,por),e(cF,_or),e(Y,bor),e(Y,mF),e(mF,MTe),e(MTe,vor),e(mF,For),e(mF,HU),e(HU,Tor),e(mF,Mor),e(Y,Eor),e(Y,fF),e(fF,ETe),e(ETe,Cor),e(fF,wor),e(fF,JU),e(JU,Aor),e(fF,Lor),e(Y,yor),e(Y,gF),e(gF,CTe),e(CTe,xor),e(gF,$or),e(gF,YU),e(YU,kor),e(gF,Sor),e(Y,Ror),e(Y,hF),e(hF,wTe),e(wTe,Por),e(hF,Bor),e(hF,ZU),e(ZU,Ior),e(hF,Nor),e(Y,qor),e(Y,uF),e(uF,ATe),e(ATe,jor),e(uF,Dor),e(uF,KU),e(KU,Gor),e(uF,Oor),e(Y,Vor),e(Y,pF),e(pF,LTe),e(LTe,Xor),e(pF,zor),e(pF,eH),e(eH,Qor),e(pF,Wor),e(Y,Uor),e(Y,_F),e(_F,yTe),e(yTe,Hor),e(_F,Jor),e(_F,oH),e(oH,Yor),e(_F,Zor),e(Y,Kor),e(Y,bF),e(bF,xTe),e(xTe,err),e(bF,orr),e(bF,rH),e(rH,rrr),e(bF,trr),e(Y,arr),e(Y,vF),e(vF,$Te),e($Te,nrr),e(vF,srr),e(vF,tH),e(tH,lrr),e(vF,irr),e(Y,drr),e(Y,FF),e(FF,kTe),e(kTe,crr),e(FF,mrr),e(FF,aH),e(aH,frr),e(FF,grr),e(Y,hrr),e(Y,TF),e(TF,STe),e(STe,urr),e(TF,prr),e(TF,nH),e(nH,_rr),e(TF,brr),e(Y,vrr),e(Y,MF),e(MF,RTe),e(RTe,Frr),e(MF,Trr),e(MF,sH),e(sH,Mrr),e(MF,Err),e(Y,Crr),e(Y,EF),e(EF,PTe),e(PTe,wrr),e(EF,Arr),e(EF,lH),e(lH,Lrr),e(EF,yrr),e(Y,xrr),e(Y,CF),e(CF,BTe),e(BTe,$rr),e(CF,krr),e(CF,iH),e(iH,Srr),e(CF,Rrr),e(Y,Prr),e(Y,wF),e(wF,ITe),e(ITe,Brr),e(wF,Irr),e(wF,dH),e(dH,Nrr),e(wF,qrr),e(Y,jrr),e(Y,AF),e(AF,NTe),e(NTe,Drr),e(AF,Grr),e(AF,cH),e(cH,Orr),e(AF,Vrr),e(Y,Xrr),e(Y,LF),e(LF,qTe),e(qTe,zrr),e(LF,Qrr),e(LF,mH),e(mH,Wrr),e(LF,Urr),e(Y,Hrr),e(Y,yF),e(yF,jTe),e(jTe,Jrr),e(yF,Yrr),e(yF,fH),e(fH,Zrr),e(yF,Krr),e(Y,etr),e(Y,xF),e(xF,DTe),e(DTe,otr),e(xF,rtr),e(xF,GTe),e(GTe,ttr),e(xF,atr),e(Y,ntr),e(Y,$F),e($F,OTe),e(OTe,str),e($F,ltr),e($F,gH),e(gH,itr),e($F,dtr),e(Y,ctr),e(Y,kF),e(kF,VTe),e(VTe,mtr),e(kF,ftr),e(kF,hH),e(hH,gtr),e(kF,htr),e(Y,utr),e(Y,SF),e(SF,XTe),e(XTe,ptr),e(SF,_tr),e(SF,uH),e(uH,btr),e(SF,vtr),e(Y,Ftr),e(Y,RF),e(RF,zTe),e(zTe,Ttr),e(RF,Mtr),e(RF,pH),e(pH,Etr),e(RF,Ctr),e(to,wtr),e(to,PF),e(PF,Atr),e(PF,QTe),e(QTe,Ltr),e(PF,ytr),e(PF,WTe),e(WTe,xtr),e(to,$tr),M(BF,to,null),b(m,mto,_),b(m,zd,_),e(zd,IF),e(IF,UTe),M(Z$,UTe,null),e(zd,ktr),e(zd,HTe),e(HTe,Str),b(m,fto,_),b(m,Go,_),M(K$,Go,null),e(Go,Rtr),e(Go,Qd),e(Qd,Ptr),e(Qd,_H),e(_H,Btr),e(Qd,Itr),e(Qd,bH),e(bH,Ntr),e(Qd,qtr),e(Go,jtr),e(Go,ek),e(ek,Dtr),e(ek,JTe),e(JTe,Gtr),e(ek,Otr),e(Go,Vtr),e(Go,At),M(ok,At,null),e(At,Xtr),e(At,YTe),e(YTe,ztr),e(At,Qtr),e(At,Wd),e(Wd,Wtr),e(Wd,ZTe),e(ZTe,Utr),e(Wd,Htr),e(Wd,vH),e(vH,Jtr),e(Wd,Ytr),e(At,Ztr),M(NF,At,null),e(Go,Ktr),e(Go,ao),M(rk,ao,null),e(ao,ear),e(ao,KTe),e(KTe,oar),e(ao,rar),e(ao,cn),e(cn,tar),e(cn,eMe),e(eMe,aar),e(cn,nar),e(cn,oMe),e(oMe,sar),e(cn,lar),e(cn,rMe),e(rMe,iar),e(cn,dar),e(ao,car),e(ao,fe),e(fe,qF),e(qF,tMe),e(tMe,mar),e(qF,far),e(qF,FH),e(FH,gar),e(qF,har),e(fe,uar),e(fe,jF),e(jF,aMe),e(aMe,par),e(jF,_ar),e(jF,TH),e(TH,bar),e(jF,Far),e(fe,Tar),e(fe,DF),e(DF,nMe),e(nMe,Mar),e(DF,Ear),e(DF,MH),e(MH,Car),e(DF,war),e(fe,Aar),e(fe,GF),e(GF,sMe),e(sMe,Lar),e(GF,yar),e(GF,EH),e(EH,xar),e(GF,$ar),e(fe,kar),e(fe,OF),e(OF,lMe),e(lMe,Sar),e(OF,Rar),e(OF,CH),e(CH,Par),e(OF,Bar),e(fe,Iar),e(fe,VF),e(VF,iMe),e(iMe,Nar),e(VF,qar),e(VF,wH),e(wH,jar),e(VF,Dar),e(fe,Gar),e(fe,XF),e(XF,dMe),e(dMe,Oar),e(XF,Var),e(XF,AH),e(AH,Xar),e(XF,zar),e(fe,Qar),e(fe,zF),e(zF,cMe),e(cMe,War),e(zF,Uar),e(zF,LH),e(LH,Har),e(zF,Jar),e(fe,Yar),e(fe,QF),e(QF,mMe),e(mMe,Zar),e(QF,Kar),e(QF,yH),e(yH,enr),e(QF,onr),e(fe,rnr),e(fe,WF),e(WF,fMe),e(fMe,tnr),e(WF,anr),e(WF,xH),e(xH,nnr),e(WF,snr),e(fe,lnr),e(fe,UF),e(UF,gMe),e(gMe,inr),e(UF,dnr),e(UF,$H),e($H,cnr),e(UF,mnr),e(fe,fnr),e(fe,HF),e(HF,hMe),e(hMe,gnr),e(HF,hnr),e(HF,kH),e(kH,unr),e(HF,pnr),e(fe,_nr),e(fe,JF),e(JF,uMe),e(uMe,bnr),e(JF,vnr),e(JF,SH),e(SH,Fnr),e(JF,Tnr),e(fe,Mnr),e(fe,YF),e(YF,pMe),e(pMe,Enr),e(YF,Cnr),e(YF,RH),e(RH,wnr),e(YF,Anr),e(fe,Lnr),e(fe,ZF),e(ZF,_Me),e(_Me,ynr),e(ZF,xnr),e(ZF,PH),e(PH,$nr),e(ZF,knr),e(fe,Snr),e(fe,KF),e(KF,bMe),e(bMe,Rnr),e(KF,Pnr),e(KF,BH),e(BH,Bnr),e(KF,Inr),e(fe,Nnr),e(fe,eT),e(eT,vMe),e(vMe,qnr),e(eT,jnr),e(eT,IH),e(IH,Dnr),e(eT,Gnr),e(fe,Onr),e(fe,oT),e(oT,FMe),e(FMe,Vnr),e(oT,Xnr),e(oT,NH),e(NH,znr),e(oT,Qnr),e(fe,Wnr),e(fe,rT),e(rT,TMe),e(TMe,Unr),e(rT,Hnr),e(rT,qH),e(qH,Jnr),e(rT,Ynr),e(fe,Znr),e(fe,tT),e(tT,MMe),e(MMe,Knr),e(tT,esr),e(tT,jH),e(jH,osr),e(tT,rsr),e(ao,tsr),e(ao,aT),e(aT,asr),e(aT,EMe),e(EMe,nsr),e(aT,ssr),e(aT,CMe),e(CMe,lsr),e(ao,isr),M(nT,ao,null),b(m,gto,_),b(m,Ud,_),e(Ud,sT),e(sT,wMe),M(tk,wMe,null),e(Ud,dsr),e(Ud,AMe),e(AMe,csr),b(m,hto,_),b(m,Oo,_),M(ak,Oo,null),e(Oo,msr),e(Oo,Hd),e(Hd,fsr),e(Hd,DH),e(DH,gsr),e(Hd,hsr),e(Hd,GH),e(GH,usr),e(Hd,psr),e(Oo,_sr),e(Oo,nk),e(nk,bsr),e(nk,LMe),e(LMe,vsr),e(nk,Fsr),e(Oo,Tsr),e(Oo,Lt),M(sk,Lt,null),e(Lt,Msr),e(Lt,yMe),e(yMe,Esr),e(Lt,Csr),e(Lt,Jd),e(Jd,wsr),e(Jd,xMe),e(xMe,Asr),e(Jd,Lsr),e(Jd,OH),e(OH,ysr),e(Jd,xsr),e(Lt,$sr),M(lT,Lt,null),e(Oo,ksr),e(Oo,no),M(lk,no,null),e(no,Ssr),e(no,$Me),e($Me,Rsr),e(no,Psr),e(no,mn),e(mn,Bsr),e(mn,kMe),e(kMe,Isr),e(mn,Nsr),e(mn,SMe),e(SMe,qsr),e(mn,jsr),e(mn,RMe),e(RMe,Dsr),e(mn,Gsr),e(no,Osr),e(no,q),e(q,iT),e(iT,PMe),e(PMe,Vsr),e(iT,Xsr),e(iT,VH),e(VH,zsr),e(iT,Qsr),e(q,Wsr),e(q,dT),e(dT,BMe),e(BMe,Usr),e(dT,Hsr),e(dT,XH),e(XH,Jsr),e(dT,Ysr),e(q,Zsr),e(q,cT),e(cT,IMe),e(IMe,Ksr),e(cT,elr),e(cT,zH),e(zH,olr),e(cT,rlr),e(q,tlr),e(q,mT),e(mT,NMe),e(NMe,alr),e(mT,nlr),e(mT,QH),e(QH,slr),e(mT,llr),e(q,ilr),e(q,fT),e(fT,qMe),e(qMe,dlr),e(fT,clr),e(fT,WH),e(WH,mlr),e(fT,flr),e(q,glr),e(q,gT),e(gT,jMe),e(jMe,hlr),e(gT,ulr),e(gT,UH),e(UH,plr),e(gT,_lr),e(q,blr),e(q,hT),e(hT,DMe),e(DMe,vlr),e(hT,Flr),e(hT,HH),e(HH,Tlr),e(hT,Mlr),e(q,Elr),e(q,uT),e(uT,GMe),e(GMe,Clr),e(uT,wlr),e(uT,JH),e(JH,Alr),e(uT,Llr),e(q,ylr),e(q,pT),e(pT,OMe),e(OMe,xlr),e(pT,$lr),e(pT,YH),e(YH,klr),e(pT,Slr),e(q,Rlr),e(q,_T),e(_T,VMe),e(VMe,Plr),e(_T,Blr),e(_T,ZH),e(ZH,Ilr),e(_T,Nlr),e(q,qlr),e(q,bT),e(bT,XMe),e(XMe,jlr),e(bT,Dlr),e(bT,KH),e(KH,Glr),e(bT,Olr),e(q,Vlr),e(q,vT),e(vT,zMe),e(zMe,Xlr),e(vT,zlr),e(vT,eJ),e(eJ,Qlr),e(vT,Wlr),e(q,Ulr),e(q,FT),e(FT,QMe),e(QMe,Hlr),e(FT,Jlr),e(FT,oJ),e(oJ,Ylr),e(FT,Zlr),e(q,Klr),e(q,TT),e(TT,WMe),e(WMe,eir),e(TT,oir),e(TT,rJ),e(rJ,rir),e(TT,tir),e(q,air),e(q,MT),e(MT,UMe),e(UMe,nir),e(MT,sir),e(MT,tJ),e(tJ,lir),e(MT,iir),e(q,dir),e(q,ET),e(ET,HMe),e(HMe,cir),e(ET,mir),e(ET,aJ),e(aJ,fir),e(ET,gir),e(q,hir),e(q,CT),e(CT,JMe),e(JMe,uir),e(CT,pir),e(CT,nJ),e(nJ,_ir),e(CT,bir),e(q,vir),e(q,wT),e(wT,YMe),e(YMe,Fir),e(wT,Tir),e(wT,sJ),e(sJ,Mir),e(wT,Eir),e(q,Cir),e(q,AT),e(AT,ZMe),e(ZMe,wir),e(AT,Air),e(AT,lJ),e(lJ,Lir),e(AT,yir),e(q,xir),e(q,LT),e(LT,KMe),e(KMe,$ir),e(LT,kir),e(LT,iJ),e(iJ,Sir),e(LT,Rir),e(q,Pir),e(q,yT),e(yT,eEe),e(eEe,Bir),e(yT,Iir),e(yT,dJ),e(dJ,Nir),e(yT,qir),e(q,jir),e(q,xT),e(xT,oEe),e(oEe,Dir),e(xT,Gir),e(xT,cJ),e(cJ,Oir),e(xT,Vir),e(q,Xir),e(q,$T),e($T,rEe),e(rEe,zir),e($T,Qir),e($T,mJ),e(mJ,Wir),e($T,Uir),e(q,Hir),e(q,kT),e(kT,tEe),e(tEe,Jir),e(kT,Yir),e(kT,fJ),e(fJ,Zir),e(kT,Kir),e(q,edr),e(q,ST),e(ST,aEe),e(aEe,odr),e(ST,rdr),e(ST,gJ),e(gJ,tdr),e(ST,adr),e(q,ndr),e(q,RT),e(RT,nEe),e(nEe,sdr),e(RT,ldr),e(RT,hJ),e(hJ,idr),e(RT,ddr),e(q,cdr),e(q,PT),e(PT,sEe),e(sEe,mdr),e(PT,fdr),e(PT,uJ),e(uJ,gdr),e(PT,hdr),e(q,udr),e(q,BT),e(BT,lEe),e(lEe,pdr),e(BT,_dr),e(BT,pJ),e(pJ,bdr),e(BT,vdr),e(q,Fdr),e(q,IT),e(IT,iEe),e(iEe,Tdr),e(IT,Mdr),e(IT,_J),e(_J,Edr),e(IT,Cdr),e(q,wdr),e(q,NT),e(NT,dEe),e(dEe,Adr),e(NT,Ldr),e(NT,bJ),e(bJ,ydr),e(NT,xdr),e(q,$dr),e(q,qT),e(qT,cEe),e(cEe,kdr),e(qT,Sdr),e(qT,vJ),e(vJ,Rdr),e(qT,Pdr),e(q,Bdr),e(q,jT),e(jT,mEe),e(mEe,Idr),e(jT,Ndr),e(jT,FJ),e(FJ,qdr),e(jT,jdr),e(q,Ddr),e(q,DT),e(DT,fEe),e(fEe,Gdr),e(DT,Odr),e(DT,TJ),e(TJ,Vdr),e(DT,Xdr),e(q,zdr),e(q,GT),e(GT,gEe),e(gEe,Qdr),e(GT,Wdr),e(GT,MJ),e(MJ,Udr),e(GT,Hdr),e(q,Jdr),e(q,OT),e(OT,hEe),e(hEe,Ydr),e(OT,Zdr),e(OT,EJ),e(EJ,Kdr),e(OT,ecr),e(q,ocr),e(q,VT),e(VT,uEe),e(uEe,rcr),e(VT,tcr),e(VT,CJ),e(CJ,acr),e(VT,ncr),e(q,scr),e(q,XT),e(XT,pEe),e(pEe,lcr),e(XT,icr),e(XT,wJ),e(wJ,dcr),e(XT,ccr),e(q,mcr),e(q,zT),e(zT,_Ee),e(_Ee,fcr),e(zT,gcr),e(zT,AJ),e(AJ,hcr),e(zT,ucr),e(q,pcr),e(q,QT),e(QT,bEe),e(bEe,_cr),e(QT,bcr),e(QT,LJ),e(LJ,vcr),e(QT,Fcr),e(q,Tcr),e(q,WT),e(WT,vEe),e(vEe,Mcr),e(WT,Ecr),e(WT,yJ),e(yJ,Ccr),e(WT,wcr),e(q,Acr),e(q,UT),e(UT,FEe),e(FEe,Lcr),e(UT,ycr),e(UT,xJ),e(xJ,xcr),e(UT,$cr),e(q,kcr),e(q,HT),e(HT,TEe),e(TEe,Scr),e(HT,Rcr),e(HT,$J),e($J,Pcr),e(HT,Bcr),e(q,Icr),e(q,JT),e(JT,MEe),e(MEe,Ncr),e(JT,qcr),e(JT,kJ),e(kJ,jcr),e(JT,Dcr),e(q,Gcr),e(q,YT),e(YT,EEe),e(EEe,Ocr),e(YT,Vcr),e(YT,SJ),e(SJ,Xcr),e(YT,zcr),e(q,Qcr),e(q,ZT),e(ZT,CEe),e(CEe,Wcr),e(ZT,Ucr),e(ZT,RJ),e(RJ,Hcr),e(ZT,Jcr),e(q,Ycr),e(q,KT),e(KT,wEe),e(wEe,Zcr),e(KT,Kcr),e(KT,PJ),e(PJ,emr),e(KT,omr),e(q,rmr),e(q,eM),e(eM,AEe),e(AEe,tmr),e(eM,amr),e(eM,BJ),e(BJ,nmr),e(eM,smr),e(q,lmr),e(q,oM),e(oM,LEe),e(LEe,imr),e(oM,dmr),e(oM,IJ),e(IJ,cmr),e(oM,mmr),e(q,fmr),e(q,rM),e(rM,yEe),e(yEe,gmr),e(rM,hmr),e(rM,NJ),e(NJ,umr),e(rM,pmr),e(q,_mr),e(q,tM),e(tM,xEe),e(xEe,bmr),e(tM,vmr),e(tM,qJ),e(qJ,Fmr),e(tM,Tmr),e(q,Mmr),e(q,aM),e(aM,$Ee),e($Ee,Emr),e(aM,Cmr),e(aM,jJ),e(jJ,wmr),e(aM,Amr),e(q,Lmr),e(q,nM),e(nM,kEe),e(kEe,ymr),e(nM,xmr),e(nM,DJ),e(DJ,$mr),e(nM,kmr),e(q,Smr),e(q,sM),e(sM,SEe),e(SEe,Rmr),e(sM,Pmr),e(sM,GJ),e(GJ,Bmr),e(sM,Imr),e(q,Nmr),e(q,lM),e(lM,REe),e(REe,qmr),e(lM,jmr),e(lM,OJ),e(OJ,Dmr),e(lM,Gmr),e(q,Omr),e(q,iM),e(iM,PEe),e(PEe,Vmr),e(iM,Xmr),e(iM,VJ),e(VJ,zmr),e(iM,Qmr),e(q,Wmr),e(q,dM),e(dM,BEe),e(BEe,Umr),e(dM,Hmr),e(dM,XJ),e(XJ,Jmr),e(dM,Ymr),e(no,Zmr),e(no,cM),e(cM,Kmr),e(cM,IEe),e(IEe,efr),e(cM,ofr),e(cM,NEe),e(NEe,rfr),e(no,tfr),M(mM,no,null),b(m,uto,_),b(m,Yd,_),e(Yd,fM),e(fM,qEe),M(ik,qEe,null),e(Yd,afr),e(Yd,jEe),e(jEe,nfr),b(m,pto,_),b(m,Vo,_),M(dk,Vo,null),e(Vo,sfr),e(Vo,Zd),e(Zd,lfr),e(Zd,zJ),e(zJ,ifr),e(Zd,dfr),e(Zd,QJ),e(QJ,cfr),e(Zd,mfr),e(Vo,ffr),e(Vo,ck),e(ck,gfr),e(ck,DEe),e(DEe,hfr),e(ck,ufr),e(Vo,pfr),e(Vo,yt),M(mk,yt,null),e(yt,_fr),e(yt,GEe),e(GEe,bfr),e(yt,vfr),e(yt,Kd),e(Kd,Ffr),e(Kd,OEe),e(OEe,Tfr),e(Kd,Mfr),e(Kd,WJ),e(WJ,Efr),e(Kd,Cfr),e(yt,wfr),M(gM,yt,null),e(Vo,Afr),e(Vo,so),M(fk,so,null),e(so,Lfr),e(so,VEe),e(VEe,yfr),e(so,xfr),e(so,fn),e(fn,$fr),e(fn,XEe),e(XEe,kfr),e(fn,Sfr),e(fn,zEe),e(zEe,Rfr),e(fn,Pfr),e(fn,QEe),e(QEe,Bfr),e(fn,Ifr),e(so,Nfr),e(so,K),e(K,hM),e(hM,WEe),e(WEe,qfr),e(hM,jfr),e(hM,UJ),e(UJ,Dfr),e(hM,Gfr),e(K,Ofr),e(K,uM),e(uM,UEe),e(UEe,Vfr),e(uM,Xfr),e(uM,HJ),e(HJ,zfr),e(uM,Qfr),e(K,Wfr),e(K,pM),e(pM,HEe),e(HEe,Ufr),e(pM,Hfr),e(pM,JJ),e(JJ,Jfr),e(pM,Yfr),e(K,Zfr),e(K,_M),e(_M,JEe),e(JEe,Kfr),e(_M,egr),e(_M,YJ),e(YJ,ogr),e(_M,rgr),e(K,tgr),e(K,bM),e(bM,YEe),e(YEe,agr),e(bM,ngr),e(bM,ZJ),e(ZJ,sgr),e(bM,lgr),e(K,igr),e(K,vM),e(vM,ZEe),e(ZEe,dgr),e(vM,cgr),e(vM,KJ),e(KJ,mgr),e(vM,fgr),e(K,ggr),e(K,FM),e(FM,KEe),e(KEe,hgr),e(FM,ugr),e(FM,eY),e(eY,pgr),e(FM,_gr),e(K,bgr),e(K,TM),e(TM,e4e),e(e4e,vgr),e(TM,Fgr),e(TM,oY),e(oY,Tgr),e(TM,Mgr),e(K,Egr),e(K,MM),e(MM,o4e),e(o4e,Cgr),e(MM,wgr),e(MM,rY),e(rY,Agr),e(MM,Lgr),e(K,ygr),e(K,EM),e(EM,r4e),e(r4e,xgr),e(EM,$gr),e(EM,tY),e(tY,kgr),e(EM,Sgr),e(K,Rgr),e(K,CM),e(CM,t4e),e(t4e,Pgr),e(CM,Bgr),e(CM,aY),e(aY,Igr),e(CM,Ngr),e(K,qgr),e(K,wM),e(wM,a4e),e(a4e,jgr),e(wM,Dgr),e(wM,nY),e(nY,Ggr),e(wM,Ogr),e(K,Vgr),e(K,AM),e(AM,n4e),e(n4e,Xgr),e(AM,zgr),e(AM,sY),e(sY,Qgr),e(AM,Wgr),e(K,Ugr),e(K,LM),e(LM,s4e),e(s4e,Hgr),e(LM,Jgr),e(LM,lY),e(lY,Ygr),e(LM,Zgr),e(K,Kgr),e(K,yM),e(yM,l4e),e(l4e,ehr),e(yM,ohr),e(yM,iY),e(iY,rhr),e(yM,thr),e(K,ahr),e(K,xM),e(xM,i4e),e(i4e,nhr),e(xM,shr),e(xM,dY),e(dY,lhr),e(xM,ihr),e(K,dhr),e(K,$M),e($M,d4e),e(d4e,chr),e($M,mhr),e($M,cY),e(cY,fhr),e($M,ghr),e(K,hhr),e(K,kM),e(kM,c4e),e(c4e,uhr),e(kM,phr),e(kM,mY),e(mY,_hr),e(kM,bhr),e(K,vhr),e(K,SM),e(SM,m4e),e(m4e,Fhr),e(SM,Thr),e(SM,fY),e(fY,Mhr),e(SM,Ehr),e(K,Chr),e(K,RM),e(RM,f4e),e(f4e,whr),e(RM,Ahr),e(RM,gY),e(gY,Lhr),e(RM,yhr),e(K,xhr),e(K,PM),e(PM,g4e),e(g4e,$hr),e(PM,khr),e(PM,hY),e(hY,Shr),e(PM,Rhr),e(K,Phr),e(K,BM),e(BM,h4e),e(h4e,Bhr),e(BM,Ihr),e(BM,uY),e(uY,Nhr),e(BM,qhr),e(K,jhr),e(K,IM),e(IM,u4e),e(u4e,Dhr),e(IM,Ghr),e(IM,pY),e(pY,Ohr),e(IM,Vhr),e(K,Xhr),e(K,NM),e(NM,p4e),e(p4e,zhr),e(NM,Qhr),e(NM,_Y),e(_Y,Whr),e(NM,Uhr),e(K,Hhr),e(K,qM),e(qM,_4e),e(_4e,Jhr),e(qM,Yhr),e(qM,bY),e(bY,Zhr),e(qM,Khr),e(K,eur),e(K,jM),e(jM,b4e),e(b4e,our),e(jM,rur),e(jM,vY),e(vY,tur),e(jM,aur),e(K,nur),e(K,DM),e(DM,v4e),e(v4e,sur),e(DM,lur),e(DM,FY),e(FY,iur),e(DM,dur),e(K,cur),e(K,GM),e(GM,F4e),e(F4e,mur),e(GM,fur),e(GM,TY),e(TY,gur),e(GM,hur),e(K,uur),e(K,OM),e(OM,T4e),e(T4e,pur),e(OM,_ur),e(OM,MY),e(MY,bur),e(OM,vur),e(K,Fur),e(K,VM),e(VM,M4e),e(M4e,Tur),e(VM,Mur),e(VM,EY),e(EY,Eur),e(VM,Cur),e(K,wur),e(K,XM),e(XM,E4e),e(E4e,Aur),e(XM,Lur),e(XM,CY),e(CY,yur),e(XM,xur),e(K,$ur),e(K,zM),e(zM,C4e),e(C4e,kur),e(zM,Sur),e(zM,wY),e(wY,Rur),e(zM,Pur),e(so,Bur),e(so,QM),e(QM,Iur),e(QM,w4e),e(w4e,Nur),e(QM,qur),e(QM,A4e),e(A4e,jur),e(so,Dur),M(WM,so,null),b(m,_to,_),b(m,ec,_),e(ec,UM),e(UM,L4e),M(gk,L4e,null),e(ec,Gur),e(ec,y4e),e(y4e,Our),b(m,bto,_),b(m,Xo,_),M(hk,Xo,null),e(Xo,Vur),e(Xo,oc),e(oc,Xur),e(oc,AY),e(AY,zur),e(oc,Qur),e(oc,LY),e(LY,Wur),e(oc,Uur),e(Xo,Hur),e(Xo,uk),e(uk,Jur),e(uk,x4e),e(x4e,Yur),e(uk,Zur),e(Xo,Kur),e(Xo,xt),M(pk,xt,null),e(xt,epr),e(xt,$4e),e($4e,opr),e(xt,rpr),e(xt,rc),e(rc,tpr),e(rc,k4e),e(k4e,apr),e(rc,npr),e(rc,yY),e(yY,spr),e(rc,lpr),e(xt,ipr),M(HM,xt,null),e(Xo,dpr),e(Xo,lo),M(_k,lo,null),e(lo,cpr),e(lo,S4e),e(S4e,mpr),e(lo,fpr),e(lo,gn),e(gn,gpr),e(gn,R4e),e(R4e,hpr),e(gn,upr),e(gn,P4e),e(P4e,ppr),e(gn,_pr),e(gn,B4e),e(B4e,bpr),e(gn,vpr),e(lo,Fpr),e(lo,Ue),e(Ue,JM),e(JM,I4e),e(I4e,Tpr),e(JM,Mpr),e(JM,xY),e(xY,Epr),e(JM,Cpr),e(Ue,wpr),e(Ue,YM),e(YM,N4e),e(N4e,Apr),e(YM,Lpr),e(YM,$Y),e($Y,ypr),e(YM,xpr),e(Ue,$pr),e(Ue,ZM),e(ZM,q4e),e(q4e,kpr),e(ZM,Spr),e(ZM,kY),e(kY,Rpr),e(ZM,Ppr),e(Ue,Bpr),e(Ue,KM),e(KM,j4e),e(j4e,Ipr),e(KM,Npr),e(KM,SY),e(SY,qpr),e(KM,jpr),e(Ue,Dpr),e(Ue,eE),e(eE,D4e),e(D4e,Gpr),e(eE,Opr),e(eE,RY),e(RY,Vpr),e(eE,Xpr),e(Ue,zpr),e(Ue,oE),e(oE,G4e),e(G4e,Qpr),e(oE,Wpr),e(oE,PY),e(PY,Upr),e(oE,Hpr),e(Ue,Jpr),e(Ue,rE),e(rE,O4e),e(O4e,Ypr),e(rE,Zpr),e(rE,BY),e(BY,Kpr),e(rE,e_r),e(lo,o_r),e(lo,tE),e(tE,r_r),e(tE,V4e),e(V4e,t_r),e(tE,a_r),e(tE,X4e),e(X4e,n_r),e(lo,s_r),M(aE,lo,null),b(m,vto,_),b(m,tc,_),e(tc,nE),e(nE,z4e),M(bk,z4e,null),e(tc,l_r),e(tc,Q4e),e(Q4e,i_r),b(m,Fto,_),b(m,zo,_),M(vk,zo,null),e(zo,d_r),e(zo,ac),e(ac,c_r),e(ac,IY),e(IY,m_r),e(ac,f_r),e(ac,NY),e(NY,g_r),e(ac,h_r),e(zo,u_r),e(zo,Fk),e(Fk,p_r),e(Fk,W4e),e(W4e,__r),e(Fk,b_r),e(zo,v_r),e(zo,$t),M(Tk,$t,null),e($t,F_r),e($t,U4e),e(U4e,T_r),e($t,M_r),e($t,nc),e(nc,E_r),e(nc,H4e),e(H4e,C_r),e(nc,w_r),e(nc,qY),e(qY,A_r),e(nc,L_r),e($t,y_r),M(sE,$t,null),e(zo,x_r),e(zo,io),M(Mk,io,null),e(io,$_r),e(io,J4e),e(J4e,k_r),e(io,S_r),e(io,hn),e(hn,R_r),e(hn,Y4e),e(Y4e,P_r),e(hn,B_r),e(hn,Z4e),e(Z4e,I_r),e(hn,N_r),e(hn,K4e),e(K4e,q_r),e(hn,j_r),e(io,D_r),e(io,U),e(U,lE),e(lE,eCe),e(eCe,G_r),e(lE,O_r),e(lE,jY),e(jY,V_r),e(lE,X_r),e(U,z_r),e(U,iE),e(iE,oCe),e(oCe,Q_r),e(iE,W_r),e(iE,DY),e(DY,U_r),e(iE,H_r),e(U,J_r),e(U,dE),e(dE,rCe),e(rCe,Y_r),e(dE,Z_r),e(dE,GY),e(GY,K_r),e(dE,e1r),e(U,o1r),e(U,cE),e(cE,tCe),e(tCe,r1r),e(cE,t1r),e(cE,OY),e(OY,a1r),e(cE,n1r),e(U,s1r),e(U,mE),e(mE,aCe),e(aCe,l1r),e(mE,i1r),e(mE,VY),e(VY,d1r),e(mE,c1r),e(U,m1r),e(U,fE),e(fE,nCe),e(nCe,f1r),e(fE,g1r),e(fE,XY),e(XY,h1r),e(fE,u1r),e(U,p1r),e(U,gE),e(gE,sCe),e(sCe,_1r),e(gE,b1r),e(gE,zY),e(zY,v1r),e(gE,F1r),e(U,T1r),e(U,hE),e(hE,lCe),e(lCe,M1r),e(hE,E1r),e(hE,QY),e(QY,C1r),e(hE,w1r),e(U,A1r),e(U,uE),e(uE,iCe),e(iCe,L1r),e(uE,y1r),e(uE,WY),e(WY,x1r),e(uE,$1r),e(U,k1r),e(U,pE),e(pE,dCe),e(dCe,S1r),e(pE,R1r),e(pE,UY),e(UY,P1r),e(pE,B1r),e(U,I1r),e(U,_E),e(_E,cCe),e(cCe,N1r),e(_E,q1r),e(_E,HY),e(HY,j1r),e(_E,D1r),e(U,G1r),e(U,bE),e(bE,mCe),e(mCe,O1r),e(bE,V1r),e(bE,JY),e(JY,X1r),e(bE,z1r),e(U,Q1r),e(U,vE),e(vE,fCe),e(fCe,W1r),e(vE,U1r),e(vE,YY),e(YY,H1r),e(vE,J1r),e(U,Y1r),e(U,FE),e(FE,gCe),e(gCe,Z1r),e(FE,K1r),e(FE,ZY),e(ZY,e2r),e(FE,o2r),e(U,r2r),e(U,TE),e(TE,hCe),e(hCe,t2r),e(TE,a2r),e(TE,KY),e(KY,n2r),e(TE,s2r),e(U,l2r),e(U,ME),e(ME,uCe),e(uCe,i2r),e(ME,d2r),e(ME,eZ),e(eZ,c2r),e(ME,m2r),e(U,f2r),e(U,EE),e(EE,pCe),e(pCe,g2r),e(EE,h2r),e(EE,oZ),e(oZ,u2r),e(EE,p2r),e(U,_2r),e(U,CE),e(CE,_Ce),e(_Ce,b2r),e(CE,v2r),e(CE,rZ),e(rZ,F2r),e(CE,T2r),e(U,M2r),e(U,wE),e(wE,bCe),e(bCe,E2r),e(wE,C2r),e(wE,tZ),e(tZ,w2r),e(wE,A2r),e(U,L2r),e(U,AE),e(AE,vCe),e(vCe,y2r),e(AE,x2r),e(AE,aZ),e(aZ,$2r),e(AE,k2r),e(U,S2r),e(U,LE),e(LE,FCe),e(FCe,R2r),e(LE,P2r),e(LE,nZ),e(nZ,B2r),e(LE,I2r),e(U,N2r),e(U,yE),e(yE,TCe),e(TCe,q2r),e(yE,j2r),e(yE,sZ),e(sZ,D2r),e(yE,G2r),e(U,O2r),e(U,xE),e(xE,MCe),e(MCe,V2r),e(xE,X2r),e(xE,lZ),e(lZ,z2r),e(xE,Q2r),e(U,W2r),e(U,$E),e($E,ECe),e(ECe,U2r),e($E,H2r),e($E,iZ),e(iZ,J2r),e($E,Y2r),e(U,Z2r),e(U,kE),e(kE,CCe),e(CCe,K2r),e(kE,ebr),e(kE,dZ),e(dZ,obr),e(kE,rbr),e(U,tbr),e(U,SE),e(SE,wCe),e(wCe,abr),e(SE,nbr),e(SE,cZ),e(cZ,sbr),e(SE,lbr),e(U,ibr),e(U,RE),e(RE,ACe),e(ACe,dbr),e(RE,cbr),e(RE,mZ),e(mZ,mbr),e(RE,fbr),e(U,gbr),e(U,PE),e(PE,LCe),e(LCe,hbr),e(PE,ubr),e(PE,fZ),e(fZ,pbr),e(PE,_br),e(U,bbr),e(U,BE),e(BE,yCe),e(yCe,vbr),e(BE,Fbr),e(BE,gZ),e(gZ,Tbr),e(BE,Mbr),e(U,Ebr),e(U,IE),e(IE,xCe),e(xCe,Cbr),e(IE,wbr),e(IE,hZ),e(hZ,Abr),e(IE,Lbr),e(U,ybr),e(U,NE),e(NE,$Ce),e($Ce,xbr),e(NE,$br),e(NE,uZ),e(uZ,kbr),e(NE,Sbr),e(U,Rbr),e(U,qE),e(qE,kCe),e(kCe,Pbr),e(qE,Bbr),e(qE,pZ),e(pZ,Ibr),e(qE,Nbr),e(U,qbr),e(U,jE),e(jE,SCe),e(SCe,jbr),e(jE,Dbr),e(jE,_Z),e(_Z,Gbr),e(jE,Obr),e(U,Vbr),e(U,DE),e(DE,RCe),e(RCe,Xbr),e(DE,zbr),e(DE,bZ),e(bZ,Qbr),e(DE,Wbr),e(U,Ubr),e(U,GE),e(GE,PCe),e(PCe,Hbr),e(GE,Jbr),e(GE,vZ),e(vZ,Ybr),e(GE,Zbr),e(U,Kbr),e(U,OE),e(OE,BCe),e(BCe,evr),e(OE,ovr),e(OE,FZ),e(FZ,rvr),e(OE,tvr),e(U,avr),e(U,VE),e(VE,ICe),e(ICe,nvr),e(VE,svr),e(VE,TZ),e(TZ,lvr),e(VE,ivr),e(U,dvr),e(U,XE),e(XE,NCe),e(NCe,cvr),e(XE,mvr),e(XE,MZ),e(MZ,fvr),e(XE,gvr),e(U,hvr),e(U,zE),e(zE,qCe),e(qCe,uvr),e(zE,pvr),e(zE,EZ),e(EZ,_vr),e(zE,bvr),e(U,vvr),e(U,QE),e(QE,jCe),e(jCe,Fvr),e(QE,Tvr),e(QE,CZ),e(CZ,Mvr),e(QE,Evr),e(U,Cvr),e(U,WE),e(WE,DCe),e(DCe,wvr),e(WE,Avr),e(WE,wZ),e(wZ,Lvr),e(WE,yvr),e(io,xvr),e(io,UE),e(UE,$vr),e(UE,GCe),e(GCe,kvr),e(UE,Svr),e(UE,OCe),e(OCe,Rvr),e(io,Pvr),M(HE,io,null),b(m,Tto,_),b(m,sc,_),e(sc,JE),e(JE,VCe),M(Ek,VCe,null),e(sc,Bvr),e(sc,XCe),e(XCe,Ivr),b(m,Mto,_),b(m,Qo,_),M(Ck,Qo,null),e(Qo,Nvr),e(Qo,lc),e(lc,qvr),e(lc,AZ),e(AZ,jvr),e(lc,Dvr),e(lc,LZ),e(LZ,Gvr),e(lc,Ovr),e(Qo,Vvr),e(Qo,wk),e(wk,Xvr),e(wk,zCe),e(zCe,zvr),e(wk,Qvr),e(Qo,Wvr),e(Qo,kt),M(Ak,kt,null),e(kt,Uvr),e(kt,QCe),e(QCe,Hvr),e(kt,Jvr),e(kt,ic),e(ic,Yvr),e(ic,WCe),e(WCe,Zvr),e(ic,Kvr),e(ic,yZ),e(yZ,eFr),e(ic,oFr),e(kt,rFr),M(YE,kt,null),e(Qo,tFr),e(Qo,co),M(Lk,co,null),e(co,aFr),e(co,UCe),e(UCe,nFr),e(co,sFr),e(co,un),e(un,lFr),e(un,HCe),e(HCe,iFr),e(un,dFr),e(un,JCe),e(JCe,cFr),e(un,mFr),e(un,YCe),e(YCe,fFr),e(un,gFr),e(co,hFr),e(co,O),e(O,ZE),e(ZE,ZCe),e(ZCe,uFr),e(ZE,pFr),e(ZE,xZ),e(xZ,_Fr),e(ZE,bFr),e(O,vFr),e(O,KE),e(KE,KCe),e(KCe,FFr),e(KE,TFr),e(KE,$Z),e($Z,MFr),e(KE,EFr),e(O,CFr),e(O,e4),e(e4,e3e),e(e3e,wFr),e(e4,AFr),e(e4,kZ),e(kZ,LFr),e(e4,yFr),e(O,xFr),e(O,o4),e(o4,o3e),e(o3e,$Fr),e(o4,kFr),e(o4,SZ),e(SZ,SFr),e(o4,RFr),e(O,PFr),e(O,r4),e(r4,r3e),e(r3e,BFr),e(r4,IFr),e(r4,RZ),e(RZ,NFr),e(r4,qFr),e(O,jFr),e(O,t4),e(t4,t3e),e(t3e,DFr),e(t4,GFr),e(t4,PZ),e(PZ,OFr),e(t4,VFr),e(O,XFr),e(O,a4),e(a4,a3e),e(a3e,zFr),e(a4,QFr),e(a4,BZ),e(BZ,WFr),e(a4,UFr),e(O,HFr),e(O,n4),e(n4,n3e),e(n3e,JFr),e(n4,YFr),e(n4,IZ),e(IZ,ZFr),e(n4,KFr),e(O,eTr),e(O,s4),e(s4,s3e),e(s3e,oTr),e(s4,rTr),e(s4,NZ),e(NZ,tTr),e(s4,aTr),e(O,nTr),e(O,l4),e(l4,l3e),e(l3e,sTr),e(l4,lTr),e(l4,qZ),e(qZ,iTr),e(l4,dTr),e(O,cTr),e(O,i4),e(i4,i3e),e(i3e,mTr),e(i4,fTr),e(i4,jZ),e(jZ,gTr),e(i4,hTr),e(O,uTr),e(O,d4),e(d4,d3e),e(d3e,pTr),e(d4,_Tr),e(d4,DZ),e(DZ,bTr),e(d4,vTr),e(O,FTr),e(O,c4),e(c4,c3e),e(c3e,TTr),e(c4,MTr),e(c4,GZ),e(GZ,ETr),e(c4,CTr),e(O,wTr),e(O,m4),e(m4,m3e),e(m3e,ATr),e(m4,LTr),e(m4,OZ),e(OZ,yTr),e(m4,xTr),e(O,$Tr),e(O,f4),e(f4,f3e),e(f3e,kTr),e(f4,STr),e(f4,VZ),e(VZ,RTr),e(f4,PTr),e(O,BTr),e(O,g4),e(g4,g3e),e(g3e,ITr),e(g4,NTr),e(g4,XZ),e(XZ,qTr),e(g4,jTr),e(O,DTr),e(O,h4),e(h4,h3e),e(h3e,GTr),e(h4,OTr),e(h4,zZ),e(zZ,VTr),e(h4,XTr),e(O,zTr),e(O,u4),e(u4,u3e),e(u3e,QTr),e(u4,WTr),e(u4,QZ),e(QZ,UTr),e(u4,HTr),e(O,JTr),e(O,p4),e(p4,p3e),e(p3e,YTr),e(p4,ZTr),e(p4,WZ),e(WZ,KTr),e(p4,eMr),e(O,oMr),e(O,_4),e(_4,_3e),e(_3e,rMr),e(_4,tMr),e(_4,UZ),e(UZ,aMr),e(_4,nMr),e(O,sMr),e(O,b4),e(b4,b3e),e(b3e,lMr),e(b4,iMr),e(b4,HZ),e(HZ,dMr),e(b4,cMr),e(O,mMr),e(O,v4),e(v4,v3e),e(v3e,fMr),e(v4,gMr),e(v4,JZ),e(JZ,hMr),e(v4,uMr),e(O,pMr),e(O,F4),e(F4,F3e),e(F3e,_Mr),e(F4,bMr),e(F4,YZ),e(YZ,vMr),e(F4,FMr),e(O,TMr),e(O,T4),e(T4,T3e),e(T3e,MMr),e(T4,EMr),e(T4,ZZ),e(ZZ,CMr),e(T4,wMr),e(O,AMr),e(O,M4),e(M4,M3e),e(M3e,LMr),e(M4,yMr),e(M4,KZ),e(KZ,xMr),e(M4,$Mr),e(O,kMr),e(O,E4),e(E4,E3e),e(E3e,SMr),e(E4,RMr),e(E4,eK),e(eK,PMr),e(E4,BMr),e(O,IMr),e(O,C4),e(C4,C3e),e(C3e,NMr),e(C4,qMr),e(C4,oK),e(oK,jMr),e(C4,DMr),e(O,GMr),e(O,w4),e(w4,w3e),e(w3e,OMr),e(w4,VMr),e(w4,rK),e(rK,XMr),e(w4,zMr),e(O,QMr),e(O,A4),e(A4,A3e),e(A3e,WMr),e(A4,UMr),e(A4,tK),e(tK,HMr),e(A4,JMr),e(O,YMr),e(O,L4),e(L4,L3e),e(L3e,ZMr),e(L4,KMr),e(L4,aK),e(aK,eEr),e(L4,oEr),e(O,rEr),e(O,y4),e(y4,y3e),e(y3e,tEr),e(y4,aEr),e(y4,nK),e(nK,nEr),e(y4,sEr),e(O,lEr),e(O,x4),e(x4,x3e),e(x3e,iEr),e(x4,dEr),e(x4,sK),e(sK,cEr),e(x4,mEr),e(O,fEr),e(O,$4),e($4,$3e),e($3e,gEr),e($4,hEr),e($4,lK),e(lK,uEr),e($4,pEr),e(O,_Er),e(O,k4),e(k4,k3e),e(k3e,bEr),e(k4,vEr),e(k4,iK),e(iK,FEr),e(k4,TEr),e(O,MEr),e(O,S4),e(S4,S3e),e(S3e,EEr),e(S4,CEr),e(S4,dK),e(dK,wEr),e(S4,AEr),e(O,LEr),e(O,R4),e(R4,R3e),e(R3e,yEr),e(R4,xEr),e(R4,cK),e(cK,$Er),e(R4,kEr),e(O,SEr),e(O,P4),e(P4,P3e),e(P3e,REr),e(P4,PEr),e(P4,mK),e(mK,BEr),e(P4,IEr),e(O,NEr),e(O,B4),e(B4,B3e),e(B3e,qEr),e(B4,jEr),e(B4,fK),e(fK,DEr),e(B4,GEr),e(O,OEr),e(O,I4),e(I4,I3e),e(I3e,VEr),e(I4,XEr),e(I4,gK),e(gK,zEr),e(I4,QEr),e(O,WEr),e(O,N4),e(N4,N3e),e(N3e,UEr),e(N4,HEr),e(N4,hK),e(hK,JEr),e(N4,YEr),e(O,ZEr),e(O,q4),e(q4,q3e),e(q3e,KEr),e(q4,e4r),e(q4,uK),e(uK,o4r),e(q4,r4r),e(O,t4r),e(O,j4),e(j4,j3e),e(j3e,a4r),e(j4,n4r),e(j4,pK),e(pK,s4r),e(j4,l4r),e(O,i4r),e(O,D4),e(D4,D3e),e(D3e,d4r),e(D4,c4r),e(D4,_K),e(_K,m4r),e(D4,f4r),e(O,g4r),e(O,G4),e(G4,G3e),e(G3e,h4r),e(G4,u4r),e(G4,bK),e(bK,p4r),e(G4,_4r),e(O,b4r),e(O,O4),e(O4,O3e),e(O3e,v4r),e(O4,F4r),e(O4,vK),e(vK,T4r),e(O4,M4r),e(O,E4r),e(O,V4),e(V4,V3e),e(V3e,C4r),e(V4,w4r),e(V4,FK),e(FK,A4r),e(V4,L4r),e(O,y4r),e(O,X4),e(X4,X3e),e(X3e,x4r),e(X4,$4r),e(X4,TK),e(TK,k4r),e(X4,S4r),e(O,R4r),e(O,z4),e(z4,z3e),e(z3e,P4r),e(z4,B4r),e(z4,MK),e(MK,I4r),e(z4,N4r),e(co,q4r),e(co,Q4),e(Q4,j4r),e(Q4,Q3e),e(Q3e,D4r),e(Q4,G4r),e(Q4,W3e),e(W3e,O4r),e(co,V4r),M(W4,co,null),b(m,Eto,_),b(m,dc,_),e(dc,U4),e(U4,U3e),M(yk,U3e,null),e(dc,X4r),e(dc,H3e),e(H3e,z4r),b(m,Cto,_),b(m,Wo,_),M(xk,Wo,null),e(Wo,Q4r),e(Wo,cc),e(cc,W4r),e(cc,EK),e(EK,U4r),e(cc,H4r),e(cc,CK),e(CK,J4r),e(cc,Y4r),e(Wo,Z4r),e(Wo,$k),e($k,K4r),e($k,J3e),e(J3e,eCr),e($k,oCr),e(Wo,rCr),e(Wo,St),M(kk,St,null),e(St,tCr),e(St,Y3e),e(Y3e,aCr),e(St,nCr),e(St,mc),e(mc,sCr),e(mc,Z3e),e(Z3e,lCr),e(mc,iCr),e(mc,wK),e(wK,dCr),e(mc,cCr),e(St,mCr),M(H4,St,null),e(Wo,fCr),e(Wo,mo),M(Sk,mo,null),e(mo,gCr),e(mo,K3e),e(K3e,hCr),e(mo,uCr),e(mo,pn),e(pn,pCr),e(pn,e5e),e(e5e,_Cr),e(pn,bCr),e(pn,o5e),e(o5e,vCr),e(pn,FCr),e(pn,r5e),e(r5e,TCr),e(pn,MCr),e(mo,ECr),e(mo,t5e),e(t5e,J4),e(J4,a5e),e(a5e,CCr),e(J4,wCr),e(J4,AK),e(AK,ACr),e(J4,LCr),e(mo,yCr),e(mo,Y4),e(Y4,xCr),e(Y4,n5e),e(n5e,$Cr),e(Y4,kCr),e(Y4,s5e),e(s5e,SCr),e(mo,RCr),M(Z4,mo,null),b(m,wto,_),b(m,fc,_),e(fc,K4),e(K4,l5e),M(Rk,l5e,null),e(fc,PCr),e(fc,i5e),e(i5e,BCr),b(m,Ato,_),b(m,Uo,_),M(Pk,Uo,null),e(Uo,ICr),e(Uo,gc),e(gc,NCr),e(gc,LK),e(LK,qCr),e(gc,jCr),e(gc,yK),e(yK,DCr),e(gc,GCr),e(Uo,OCr),e(Uo,Bk),e(Bk,VCr),e(Bk,d5e),e(d5e,XCr),e(Bk,zCr),e(Uo,QCr),e(Uo,Rt),M(Ik,Rt,null),e(Rt,WCr),e(Rt,c5e),e(c5e,UCr),e(Rt,HCr),e(Rt,hc),e(hc,JCr),e(hc,m5e),e(m5e,YCr),e(hc,ZCr),e(hc,xK),e(xK,KCr),e(hc,e3r),e(Rt,o3r),M(eC,Rt,null),e(Uo,r3r),e(Uo,fo),M(Nk,fo,null),e(fo,t3r),e(fo,f5e),e(f5e,a3r),e(fo,n3r),e(fo,_n),e(_n,s3r),e(_n,g5e),e(g5e,l3r),e(_n,i3r),e(_n,h5e),e(h5e,d3r),e(_n,c3r),e(_n,u5e),e(u5e,m3r),e(_n,f3r),e(fo,g3r),e(fo,uc),e(uc,oC),e(oC,p5e),e(p5e,h3r),e(oC,u3r),e(oC,$K),e($K,p3r),e(oC,_3r),e(uc,b3r),e(uc,rC),e(rC,_5e),e(_5e,v3r),e(rC,F3r),e(rC,kK),e(kK,T3r),e(rC,M3r),e(uc,E3r),e(uc,tC),e(tC,b5e),e(b5e,C3r),e(tC,w3r),e(tC,SK),e(SK,A3r),e(tC,L3r),e(fo,y3r),e(fo,aC),e(aC,x3r),e(aC,v5e),e(v5e,$3r),e(aC,k3r),e(aC,F5e),e(F5e,S3r),e(fo,R3r),M(nC,fo,null),b(m,Lto,_),b(m,pc,_),e(pc,sC),e(sC,T5e),M(qk,T5e,null),e(pc,P3r),e(pc,M5e),e(M5e,B3r),b(m,yto,_),b(m,Ho,_),M(jk,Ho,null),e(Ho,I3r),e(Ho,_c),e(_c,N3r),e(_c,RK),e(RK,q3r),e(_c,j3r),e(_c,PK),e(PK,D3r),e(_c,G3r),e(Ho,O3r),e(Ho,Dk),e(Dk,V3r),e(Dk,E5e),e(E5e,X3r),e(Dk,z3r),e(Ho,Q3r),e(Ho,Pt),M(Gk,Pt,null),e(Pt,W3r),e(Pt,C5e),e(C5e,U3r),e(Pt,H3r),e(Pt,bc),e(bc,J3r),e(bc,w5e),e(w5e,Y3r),e(bc,Z3r),e(bc,BK),e(BK,K3r),e(bc,e5r),e(Pt,o5r),M(lC,Pt,null),e(Ho,r5r),e(Ho,go),M(Ok,go,null),e(go,t5r),e(go,A5e),e(A5e,a5r),e(go,n5r),e(go,bn),e(bn,s5r),e(bn,L5e),e(L5e,l5r),e(bn,i5r),e(bn,y5e),e(y5e,d5r),e(bn,c5r),e(bn,x5e),e(x5e,m5r),e(bn,f5r),e(go,g5r),e(go,be),e(be,iC),e(iC,$5e),e($5e,h5r),e(iC,u5r),e(iC,IK),e(IK,p5r),e(iC,_5r),e(be,b5r),e(be,dC),e(dC,k5e),e(k5e,v5r),e(dC,F5r),e(dC,NK),e(NK,T5r),e(dC,M5r),e(be,E5r),e(be,cC),e(cC,S5e),e(S5e,C5r),e(cC,w5r),e(cC,qK),e(qK,A5r),e(cC,L5r),e(be,y5r),e(be,mC),e(mC,R5e),e(R5e,x5r),e(mC,$5r),e(mC,jK),e(jK,k5r),e(mC,S5r),e(be,R5r),e(be,xl),e(xl,P5e),e(P5e,P5r),e(xl,B5r),e(xl,DK),e(DK,I5r),e(xl,N5r),e(xl,GK),e(GK,q5r),e(xl,j5r),e(be,D5r),e(be,fC),e(fC,B5e),e(B5e,G5r),e(fC,O5r),e(fC,OK),e(OK,V5r),e(fC,X5r),e(be,z5r),e(be,$l),e($l,I5e),e(I5e,Q5r),e($l,W5r),e($l,VK),e(VK,U5r),e($l,H5r),e($l,XK),e(XK,J5r),e($l,Y5r),e(be,Z5r),e(be,gC),e(gC,N5e),e(N5e,K5r),e(gC,e0r),e(gC,zK),e(zK,o0r),e(gC,r0r),e(be,t0r),e(be,Bt),e(Bt,q5e),e(q5e,a0r),e(Bt,n0r),e(Bt,QK),e(QK,s0r),e(Bt,l0r),e(Bt,WK),e(WK,i0r),e(Bt,d0r),e(Bt,UK),e(UK,c0r),e(Bt,m0r),e(be,f0r),e(be,hC),e(hC,j5e),e(j5e,g0r),e(hC,h0r),e(hC,HK),e(HK,u0r),e(hC,p0r),e(be,_0r),e(be,uC),e(uC,D5e),e(D5e,b0r),e(uC,v0r),e(uC,JK),e(JK,F0r),e(uC,T0r),e(be,M0r),e(be,pC),e(pC,G5e),e(G5e,E0r),e(pC,C0r),e(pC,YK),e(YK,w0r),e(pC,A0r),e(be,L0r),e(be,_C),e(_C,O5e),e(O5e,y0r),e(_C,x0r),e(_C,ZK),e(ZK,$0r),e(_C,k0r),e(be,S0r),e(be,bC),e(bC,V5e),e(V5e,R0r),e(bC,P0r),e(bC,KK),e(KK,B0r),e(bC,I0r),e(be,N0r),e(be,vC),e(vC,X5e),e(X5e,q0r),e(vC,j0r),e(vC,eee),e(eee,D0r),e(vC,G0r),e(be,O0r),e(be,FC),e(FC,z5e),e(z5e,V0r),e(FC,X0r),e(FC,oee),e(oee,z0r),e(FC,Q0r),e(be,W0r),e(be,TC),e(TC,Q5e),e(Q5e,U0r),e(TC,H0r),e(TC,ree),e(ree,J0r),e(TC,Y0r),e(be,Z0r),e(be,MC),e(MC,W5e),e(W5e,K0r),e(MC,ewr),e(MC,tee),e(tee,owr),e(MC,rwr),e(go,twr),e(go,EC),e(EC,awr),e(EC,U5e),e(U5e,nwr),e(EC,swr),e(EC,H5e),e(H5e,lwr),e(go,iwr),M(CC,go,null),b(m,xto,_),b(m,vc,_),e(vc,wC),e(wC,J5e),M(Vk,J5e,null),e(vc,dwr),e(vc,Y5e),e(Y5e,cwr),b(m,$to,_),b(m,Jo,_),M(Xk,Jo,null),e(Jo,mwr),e(Jo,Fc),e(Fc,fwr),e(Fc,aee),e(aee,gwr),e(Fc,hwr),e(Fc,nee),e(nee,uwr),e(Fc,pwr),e(Jo,_wr),e(Jo,zk),e(zk,bwr),e(zk,Z5e),e(Z5e,vwr),e(zk,Fwr),e(Jo,Twr),e(Jo,It),M(Qk,It,null),e(It,Mwr),e(It,K5e),e(K5e,Ewr),e(It,Cwr),e(It,Tc),e(Tc,wwr),e(Tc,e0e),e(e0e,Awr),e(Tc,Lwr),e(Tc,see),e(see,ywr),e(Tc,xwr),e(It,$wr),M(AC,It,null),e(Jo,kwr),e(Jo,ho),M(Wk,ho,null),e(ho,Swr),e(ho,o0e),e(o0e,Rwr),e(ho,Pwr),e(ho,vn),e(vn,Bwr),e(vn,r0e),e(r0e,Iwr),e(vn,Nwr),e(vn,t0e),e(t0e,qwr),e(vn,jwr),e(vn,a0e),e(a0e,Dwr),e(vn,Gwr),e(ho,Owr),e(ho,n0e),e(n0e,LC),e(LC,s0e),e(s0e,Vwr),e(LC,Xwr),e(LC,lee),e(lee,zwr),e(LC,Qwr),e(ho,Wwr),e(ho,yC),e(yC,Uwr),e(yC,l0e),e(l0e,Hwr),e(yC,Jwr),e(yC,i0e),e(i0e,Ywr),e(ho,Zwr),M(xC,ho,null),b(m,kto,_),b(m,Mc,_),e(Mc,$C),e($C,d0e),M(Uk,d0e,null),e(Mc,Kwr),e(Mc,c0e),e(c0e,eAr),b(m,Sto,_),b(m,Yo,_),M(Hk,Yo,null),e(Yo,oAr),e(Yo,Ec),e(Ec,rAr),e(Ec,iee),e(iee,tAr),e(Ec,aAr),e(Ec,dee),e(dee,nAr),e(Ec,sAr),e(Yo,lAr),e(Yo,Jk),e(Jk,iAr),e(Jk,m0e),e(m0e,dAr),e(Jk,cAr),e(Yo,mAr),e(Yo,Nt),M(Yk,Nt,null),e(Nt,fAr),e(Nt,f0e),e(f0e,gAr),e(Nt,hAr),e(Nt,Cc),e(Cc,uAr),e(Cc,g0e),e(g0e,pAr),e(Cc,_Ar),e(Cc,cee),e(cee,bAr),e(Cc,vAr),e(Nt,FAr),M(kC,Nt,null),e(Yo,TAr),e(Yo,uo),M(Zk,uo,null),e(uo,MAr),e(uo,h0e),e(h0e,EAr),e(uo,CAr),e(uo,Fn),e(Fn,wAr),e(Fn,u0e),e(u0e,AAr),e(Fn,LAr),e(Fn,p0e),e(p0e,yAr),e(Fn,xAr),e(Fn,_0e),e(_0e,$Ar),e(Fn,kAr),e(uo,SAr),e(uo,b0e),e(b0e,SC),e(SC,v0e),e(v0e,RAr),e(SC,PAr),e(SC,mee),e(mee,BAr),e(SC,IAr),e(uo,NAr),e(uo,RC),e(RC,qAr),e(RC,F0e),e(F0e,jAr),e(RC,DAr),e(RC,T0e),e(T0e,GAr),e(uo,OAr),M(PC,uo,null),b(m,Rto,_),b(m,wc,_),e(wc,BC),e(BC,M0e),M(Kk,M0e,null),e(wc,VAr),e(wc,E0e),e(E0e,XAr),b(m,Pto,_),b(m,Zo,_),M(eS,Zo,null),e(Zo,zAr),e(Zo,Ac),e(Ac,QAr),e(Ac,fee),e(fee,WAr),e(Ac,UAr),e(Ac,gee),e(gee,HAr),e(Ac,JAr),e(Zo,YAr),e(Zo,oS),e(oS,ZAr),e(oS,C0e),e(C0e,KAr),e(oS,e6r),e(Zo,o6r),e(Zo,qt),M(rS,qt,null),e(qt,r6r),e(qt,w0e),e(w0e,t6r),e(qt,a6r),e(qt,Lc),e(Lc,n6r),e(Lc,A0e),e(A0e,s6r),e(Lc,l6r),e(Lc,hee),e(hee,i6r),e(Lc,d6r),e(qt,c6r),M(IC,qt,null),e(Zo,m6r),e(Zo,po),M(tS,po,null),e(po,f6r),e(po,L0e),e(L0e,g6r),e(po,h6r),e(po,Tn),e(Tn,u6r),e(Tn,y0e),e(y0e,p6r),e(Tn,_6r),e(Tn,x0e),e(x0e,b6r),e(Tn,v6r),e(Tn,$0e),e($0e,F6r),e(Tn,T6r),e(po,M6r),e(po,k0e),e(k0e,NC),e(NC,S0e),e(S0e,E6r),e(NC,C6r),e(NC,uee),e(uee,w6r),e(NC,A6r),e(po,L6r),e(po,qC),e(qC,y6r),e(qC,R0e),e(R0e,x6r),e(qC,$6r),e(qC,P0e),e(P0e,k6r),e(po,S6r),M(jC,po,null),b(m,Bto,_),b(m,yc,_),e(yc,DC),e(DC,B0e),M(aS,B0e,null),e(yc,R6r),e(yc,I0e),e(I0e,P6r),b(m,Ito,_),b(m,Ko,_),M(nS,Ko,null),e(Ko,B6r),e(Ko,xc),e(xc,I6r),e(xc,pee),e(pee,N6r),e(xc,q6r),e(xc,_ee),e(_ee,j6r),e(xc,D6r),e(Ko,G6r),e(Ko,sS),e(sS,O6r),e(sS,N0e),e(N0e,V6r),e(sS,X6r),e(Ko,z6r),e(Ko,jt),M(lS,jt,null),e(jt,Q6r),e(jt,q0e),e(q0e,W6r),e(jt,U6r),e(jt,$c),e($c,H6r),e($c,j0e),e(j0e,J6r),e($c,Y6r),e($c,bee),e(bee,Z6r),e($c,K6r),e(jt,e7r),M(GC,jt,null),e(Ko,o7r),e(Ko,_o),M(iS,_o,null),e(_o,r7r),e(_o,D0e),e(D0e,t7r),e(_o,a7r),e(_o,Mn),e(Mn,n7r),e(Mn,G0e),e(G0e,s7r),e(Mn,l7r),e(Mn,O0e),e(O0e,i7r),e(Mn,d7r),e(Mn,V0e),e(V0e,c7r),e(Mn,m7r),e(_o,f7r),e(_o,Be),e(Be,OC),e(OC,X0e),e(X0e,g7r),e(OC,h7r),e(OC,vee),e(vee,u7r),e(OC,p7r),e(Be,_7r),e(Be,VC),e(VC,z0e),e(z0e,b7r),e(VC,v7r),e(VC,Fee),e(Fee,F7r),e(VC,T7r),e(Be,M7r),e(Be,XC),e(XC,Q0e),e(Q0e,E7r),e(XC,C7r),e(XC,Tee),e(Tee,w7r),e(XC,A7r),e(Be,L7r),e(Be,zC),e(zC,W0e),e(W0e,y7r),e(zC,x7r),e(zC,Mee),e(Mee,$7r),e(zC,k7r),e(Be,S7r),e(Be,QC),e(QC,U0e),e(U0e,R7r),e(QC,P7r),e(QC,Eee),e(Eee,B7r),e(QC,I7r),e(Be,N7r),e(Be,WC),e(WC,H0e),e(H0e,q7r),e(WC,j7r),e(WC,Cee),e(Cee,D7r),e(WC,G7r),e(Be,O7r),e(Be,UC),e(UC,J0e),e(J0e,V7r),e(UC,X7r),e(UC,wee),e(wee,z7r),e(UC,Q7r),e(Be,W7r),e(Be,HC),e(HC,Y0e),e(Y0e,U7r),e(HC,H7r),e(HC,Aee),e(Aee,J7r),e(HC,Y7r),e(Be,Z7r),e(Be,JC),e(JC,Z0e),e(Z0e,K7r),e(JC,eLr),e(JC,Lee),e(Lee,oLr),e(JC,rLr),e(_o,tLr),e(_o,YC),e(YC,aLr),e(YC,K0e),e(K0e,nLr),e(YC,sLr),e(YC,ewe),e(ewe,lLr),e(_o,iLr),M(ZC,_o,null),b(m,Nto,_),b(m,kc,_),e(kc,KC),e(KC,owe),M(dS,owe,null),e(kc,dLr),e(kc,rwe),e(rwe,cLr),b(m,qto,_),b(m,er,_),M(cS,er,null),e(er,mLr),e(er,Sc),e(Sc,fLr),e(Sc,yee),e(yee,gLr),e(Sc,hLr),e(Sc,xee),e(xee,uLr),e(Sc,pLr),e(er,_Lr),e(er,mS),e(mS,bLr),e(mS,twe),e(twe,vLr),e(mS,FLr),e(er,TLr),e(er,Dt),M(fS,Dt,null),e(Dt,MLr),e(Dt,awe),e(awe,ELr),e(Dt,CLr),e(Dt,Rc),e(Rc,wLr),e(Rc,nwe),e(nwe,ALr),e(Rc,LLr),e(Rc,$ee),e($ee,yLr),e(Rc,xLr),e(Dt,$Lr),M(e3,Dt,null),e(er,kLr),e(er,bo),M(gS,bo,null),e(bo,SLr),e(bo,swe),e(swe,RLr),e(bo,PLr),e(bo,En),e(En,BLr),e(En,lwe),e(lwe,ILr),e(En,NLr),e(En,iwe),e(iwe,qLr),e(En,jLr),e(En,dwe),e(dwe,DLr),e(En,GLr),e(bo,OLr),e(bo,ut),e(ut,o3),e(o3,cwe),e(cwe,VLr),e(o3,XLr),e(o3,kee),e(kee,zLr),e(o3,QLr),e(ut,WLr),e(ut,r3),e(r3,mwe),e(mwe,ULr),e(r3,HLr),e(r3,See),e(See,JLr),e(r3,YLr),e(ut,ZLr),e(ut,t3),e(t3,fwe),e(fwe,KLr),e(t3,e8r),e(t3,Ree),e(Ree,o8r),e(t3,r8r),e(ut,t8r),e(ut,a3),e(a3,gwe),e(gwe,a8r),e(a3,n8r),e(a3,Pee),e(Pee,s8r),e(a3,l8r),e(ut,i8r),e(ut,n3),e(n3,hwe),e(hwe,d8r),e(n3,c8r),e(n3,Bee),e(Bee,m8r),e(n3,f8r),e(bo,g8r),e(bo,s3),e(s3,h8r),e(s3,uwe),e(uwe,u8r),e(s3,p8r),e(s3,pwe),e(pwe,_8r),e(bo,b8r),M(l3,bo,null),b(m,jto,_),b(m,Pc,_),e(Pc,i3),e(i3,_we),M(hS,_we,null),e(Pc,v8r),e(Pc,bwe),e(bwe,F8r),b(m,Dto,_),b(m,or,_),M(uS,or,null),e(or,T8r),e(or,Bc),e(Bc,M8r),e(Bc,Iee),e(Iee,E8r),e(Bc,C8r),e(Bc,Nee),e(Nee,w8r),e(Bc,A8r),e(or,L8r),e(or,pS),e(pS,y8r),e(pS,vwe),e(vwe,x8r),e(pS,$8r),e(or,k8r),e(or,Gt),M(_S,Gt,null),e(Gt,S8r),e(Gt,Fwe),e(Fwe,R8r),e(Gt,P8r),e(Gt,Ic),e(Ic,B8r),e(Ic,Twe),e(Twe,I8r),e(Ic,N8r),e(Ic,qee),e(qee,q8r),e(Ic,j8r),e(Gt,D8r),M(d3,Gt,null),e(or,G8r),e(or,vo),M(bS,vo,null),e(vo,O8r),e(vo,Mwe),e(Mwe,V8r),e(vo,X8r),e(vo,Cn),e(Cn,z8r),e(Cn,Ewe),e(Ewe,Q8r),e(Cn,W8r),e(Cn,Cwe),e(Cwe,U8r),e(Cn,H8r),e(Cn,wwe),e(wwe,J8r),e(Cn,Y8r),e(vo,Z8r),e(vo,Le),e(Le,c3),e(c3,Awe),e(Awe,K8r),e(c3,eyr),e(c3,jee),e(jee,oyr),e(c3,ryr),e(Le,tyr),e(Le,m3),e(m3,Lwe),e(Lwe,ayr),e(m3,nyr),e(m3,Dee),e(Dee,syr),e(m3,lyr),e(Le,iyr),e(Le,f3),e(f3,ywe),e(ywe,dyr),e(f3,cyr),e(f3,Gee),e(Gee,myr),e(f3,fyr),e(Le,gyr),e(Le,g3),e(g3,xwe),e(xwe,hyr),e(g3,uyr),e(g3,Oee),e(Oee,pyr),e(g3,_yr),e(Le,byr),e(Le,h3),e(h3,$we),e($we,vyr),e(h3,Fyr),e(h3,Vee),e(Vee,Tyr),e(h3,Myr),e(Le,Eyr),e(Le,u3),e(u3,kwe),e(kwe,Cyr),e(u3,wyr),e(u3,Xee),e(Xee,Ayr),e(u3,Lyr),e(Le,yyr),e(Le,p3),e(p3,Swe),e(Swe,xyr),e(p3,$yr),e(p3,zee),e(zee,kyr),e(p3,Syr),e(Le,Ryr),e(Le,_3),e(_3,Rwe),e(Rwe,Pyr),e(_3,Byr),e(_3,Qee),e(Qee,Iyr),e(_3,Nyr),e(Le,qyr),e(Le,b3),e(b3,Pwe),e(Pwe,jyr),e(b3,Dyr),e(b3,Wee),e(Wee,Gyr),e(b3,Oyr),e(Le,Vyr),e(Le,v3),e(v3,Bwe),e(Bwe,Xyr),e(v3,zyr),e(v3,Uee),e(Uee,Qyr),e(v3,Wyr),e(vo,Uyr),e(vo,F3),e(F3,Hyr),e(F3,Iwe),e(Iwe,Jyr),e(F3,Yyr),e(F3,Nwe),e(Nwe,Zyr),e(vo,Kyr),M(T3,vo,null),b(m,Gto,_),b(m,Nc,_),e(Nc,M3),e(M3,qwe),M(vS,qwe,null),e(Nc,e9r),e(Nc,jwe),e(jwe,o9r),b(m,Oto,_),b(m,rr,_),M(FS,rr,null),e(rr,r9r),e(rr,qc),e(qc,t9r),e(qc,Hee),e(Hee,a9r),e(qc,n9r),e(qc,Jee),e(Jee,s9r),e(qc,l9r),e(rr,i9r),e(rr,TS),e(TS,d9r),e(TS,Dwe),e(Dwe,c9r),e(TS,m9r),e(rr,f9r),e(rr,Ot),M(MS,Ot,null),e(Ot,g9r),e(Ot,Gwe),e(Gwe,h9r),e(Ot,u9r),e(Ot,jc),e(jc,p9r),e(jc,Owe),e(Owe,_9r),e(jc,b9r),e(jc,Yee),e(Yee,v9r),e(jc,F9r),e(Ot,T9r),M(E3,Ot,null),e(rr,M9r),e(rr,Fo),M(ES,Fo,null),e(Fo,E9r),e(Fo,Vwe),e(Vwe,C9r),e(Fo,w9r),e(Fo,wn),e(wn,A9r),e(wn,Xwe),e(Xwe,L9r),e(wn,y9r),e(wn,zwe),e(zwe,x9r),e(wn,$9r),e(wn,Qwe),e(Qwe,k9r),e(wn,S9r),e(Fo,R9r),e(Fo,Dc),e(Dc,C3),e(C3,Wwe),e(Wwe,P9r),e(C3,B9r),e(C3,Zee),e(Zee,I9r),e(C3,N9r),e(Dc,q9r),e(Dc,w3),e(w3,Uwe),e(Uwe,j9r),e(w3,D9r),e(w3,Kee),e(Kee,G9r),e(w3,O9r),e(Dc,V9r),e(Dc,A3),e(A3,Hwe),e(Hwe,X9r),e(A3,z9r),e(A3,eoe),e(eoe,Q9r),e(A3,W9r),e(Fo,U9r),e(Fo,L3),e(L3,H9r),e(L3,Jwe),e(Jwe,J9r),e(L3,Y9r),e(L3,Ywe),e(Ywe,Z9r),e(Fo,K9r),M(y3,Fo,null),b(m,Vto,_),b(m,Gc,_),e(Gc,x3),e(x3,Zwe),M(CS,Zwe,null),e(Gc,exr),e(Gc,Kwe),e(Kwe,oxr),b(m,Xto,_),b(m,tr,_),M(wS,tr,null),e(tr,rxr),e(tr,Oc),e(Oc,txr),e(Oc,ooe),e(ooe,axr),e(Oc,nxr),e(Oc,roe),e(roe,sxr),e(Oc,lxr),e(tr,ixr),e(tr,AS),e(AS,dxr),e(AS,eAe),e(eAe,cxr),e(AS,mxr),e(tr,fxr),e(tr,Vt),M(LS,Vt,null),e(Vt,gxr),e(Vt,oAe),e(oAe,hxr),e(Vt,uxr),e(Vt,Vc),e(Vc,pxr),e(Vc,rAe),e(rAe,_xr),e(Vc,bxr),e(Vc,toe),e(toe,vxr),e(Vc,Fxr),e(Vt,Txr),M($3,Vt,null),e(tr,Mxr),e(tr,To),M(yS,To,null),e(To,Exr),e(To,tAe),e(tAe,Cxr),e(To,wxr),e(To,An),e(An,Axr),e(An,aAe),e(aAe,Lxr),e(An,yxr),e(An,nAe),e(nAe,xxr),e(An,$xr),e(An,sAe),e(sAe,kxr),e(An,Sxr),e(To,Rxr),e(To,pt),e(pt,k3),e(k3,lAe),e(lAe,Pxr),e(k3,Bxr),e(k3,aoe),e(aoe,Ixr),e(k3,Nxr),e(pt,qxr),e(pt,S3),e(S3,iAe),e(iAe,jxr),e(S3,Dxr),e(S3,noe),e(noe,Gxr),e(S3,Oxr),e(pt,Vxr),e(pt,R3),e(R3,dAe),e(dAe,Xxr),e(R3,zxr),e(R3,soe),e(soe,Qxr),e(R3,Wxr),e(pt,Uxr),e(pt,P3),e(P3,cAe),e(cAe,Hxr),e(P3,Jxr),e(P3,loe),e(loe,Yxr),e(P3,Zxr),e(pt,Kxr),e(pt,B3),e(B3,mAe),e(mAe,e$r),e(B3,o$r),e(B3,ioe),e(ioe,r$r),e(B3,t$r),e(To,a$r),e(To,I3),e(I3,n$r),e(I3,fAe),e(fAe,s$r),e(I3,l$r),e(I3,gAe),e(gAe,i$r),e(To,d$r),M(N3,To,null),b(m,zto,_),b(m,Xc,_),e(Xc,q3),e(q3,hAe),M(xS,hAe,null),e(Xc,c$r),e(Xc,uAe),e(uAe,m$r),b(m,Qto,_),b(m,ar,_),M($S,ar,null),e(ar,f$r),e(ar,zc),e(zc,g$r),e(zc,doe),e(doe,h$r),e(zc,u$r),e(zc,coe),e(coe,p$r),e(zc,_$r),e(ar,b$r),e(ar,kS),e(kS,v$r),e(kS,pAe),e(pAe,F$r),e(kS,T$r),e(ar,M$r),e(ar,Xt),M(SS,Xt,null),e(Xt,E$r),e(Xt,_Ae),e(_Ae,C$r),e(Xt,w$r),e(Xt,Qc),e(Qc,A$r),e(Qc,bAe),e(bAe,L$r),e(Qc,y$r),e(Qc,moe),e(moe,x$r),e(Qc,$$r),e(Xt,k$r),M(j3,Xt,null),e(ar,S$r),e(ar,Mo),M(RS,Mo,null),e(Mo,R$r),e(Mo,vAe),e(vAe,P$r),e(Mo,B$r),e(Mo,Ln),e(Ln,I$r),e(Ln,FAe),e(FAe,N$r),e(Ln,q$r),e(Ln,TAe),e(TAe,j$r),e(Ln,D$r),e(Ln,MAe),e(MAe,G$r),e(Ln,O$r),e(Mo,V$r),e(Mo,yn),e(yn,D3),e(D3,EAe),e(EAe,X$r),e(D3,z$r),e(D3,foe),e(foe,Q$r),e(D3,W$r),e(yn,U$r),e(yn,G3),e(G3,CAe),e(CAe,H$r),e(G3,J$r),e(G3,goe),e(goe,Y$r),e(G3,Z$r),e(yn,K$r),e(yn,O3),e(O3,wAe),e(wAe,ekr),e(O3,okr),e(O3,hoe),e(hoe,rkr),e(O3,tkr),e(yn,akr),e(yn,V3),e(V3,AAe),e(AAe,nkr),e(V3,skr),e(V3,uoe),e(uoe,lkr),e(V3,ikr),e(Mo,dkr),e(Mo,X3),e(X3,ckr),e(X3,LAe),e(LAe,mkr),e(X3,fkr),e(X3,yAe),e(yAe,gkr),e(Mo,hkr),M(z3,Mo,null),b(m,Wto,_),b(m,Wc,_),e(Wc,Q3),e(Q3,xAe),M(PS,xAe,null),e(Wc,ukr),e(Wc,$Ae),e($Ae,pkr),b(m,Uto,_),b(m,nr,_),M(BS,nr,null),e(nr,_kr),e(nr,Uc),e(Uc,bkr),e(Uc,poe),e(poe,vkr),e(Uc,Fkr),e(Uc,_oe),e(_oe,Tkr),e(Uc,Mkr),e(nr,Ekr),e(nr,IS),e(IS,Ckr),e(IS,kAe),e(kAe,wkr),e(IS,Akr),e(nr,Lkr),e(nr,zt),M(NS,zt,null),e(zt,ykr),e(zt,SAe),e(SAe,xkr),e(zt,$kr),e(zt,Hc),e(Hc,kkr),e(Hc,RAe),e(RAe,Skr),e(Hc,Rkr),e(Hc,boe),e(boe,Pkr),e(Hc,Bkr),e(zt,Ikr),M(W3,zt,null),e(nr,Nkr),e(nr,Eo),M(qS,Eo,null),e(Eo,qkr),e(Eo,PAe),e(PAe,jkr),e(Eo,Dkr),e(Eo,xn),e(xn,Gkr),e(xn,BAe),e(BAe,Okr),e(xn,Vkr),e(xn,IAe),e(IAe,Xkr),e(xn,zkr),e(xn,NAe),e(NAe,Qkr),e(xn,Wkr),e(Eo,Ukr),e(Eo,$n),e($n,U3),e(U3,qAe),e(qAe,Hkr),e(U3,Jkr),e(U3,voe),e(voe,Ykr),e(U3,Zkr),e($n,Kkr),e($n,H3),e(H3,jAe),e(jAe,eSr),e(H3,oSr),e(H3,Foe),e(Foe,rSr),e(H3,tSr),e($n,aSr),e($n,J3),e(J3,DAe),e(DAe,nSr),e(J3,sSr),e(J3,Toe),e(Toe,lSr),e(J3,iSr),e($n,dSr),e($n,Y3),e(Y3,GAe),e(GAe,cSr),e(Y3,mSr),e(Y3,Moe),e(Moe,fSr),e(Y3,gSr),e(Eo,hSr),e(Eo,Z3),e(Z3,uSr),e(Z3,OAe),e(OAe,pSr),e(Z3,_Sr),e(Z3,VAe),e(VAe,bSr),e(Eo,vSr),M(K3,Eo,null),b(m,Hto,_),b(m,Jc,_),e(Jc,e5),e(e5,XAe),M(jS,XAe,null),e(Jc,FSr),e(Jc,zAe),e(zAe,TSr),b(m,Jto,_),b(m,sr,_),M(DS,sr,null),e(sr,MSr),e(sr,Yc),e(Yc,ESr),e(Yc,Eoe),e(Eoe,CSr),e(Yc,wSr),e(Yc,Coe),e(Coe,ASr),e(Yc,LSr),e(sr,ySr),e(sr,GS),e(GS,xSr),e(GS,QAe),e(QAe,$Sr),e(GS,kSr),e(sr,SSr),e(sr,Qt),M(OS,Qt,null),e(Qt,RSr),e(Qt,WAe),e(WAe,PSr),e(Qt,BSr),e(Qt,Zc),e(Zc,ISr),e(Zc,UAe),e(UAe,NSr),e(Zc,qSr),e(Zc,woe),e(woe,jSr),e(Zc,DSr),e(Qt,GSr),M(o5,Qt,null),e(sr,OSr),e(sr,Co),M(VS,Co,null),e(Co,VSr),e(Co,HAe),e(HAe,XSr),e(Co,zSr),e(Co,kn),e(kn,QSr),e(kn,JAe),e(JAe,WSr),e(kn,USr),e(kn,YAe),e(YAe,HSr),e(kn,JSr),e(kn,ZAe),e(ZAe,YSr),e(kn,ZSr),e(Co,KSr),e(Co,KAe),e(KAe,r5),e(r5,e6e),e(e6e,eRr),e(r5,oRr),e(r5,Aoe),e(Aoe,rRr),e(r5,tRr),e(Co,aRr),e(Co,t5),e(t5,nRr),e(t5,o6e),e(o6e,sRr),e(t5,lRr),e(t5,r6e),e(r6e,iRr),e(Co,dRr),M(a5,Co,null),b(m,Yto,_),b(m,Kc,_),e(Kc,n5),e(n5,t6e),M(XS,t6e,null),e(Kc,cRr),e(Kc,a6e),e(a6e,mRr),b(m,Zto,_),b(m,lr,_),M(zS,lr,null),e(lr,fRr),e(lr,em),e(em,gRr),e(em,Loe),e(Loe,hRr),e(em,uRr),e(em,yoe),e(yoe,pRr),e(em,_Rr),e(lr,bRr),e(lr,QS),e(QS,vRr),e(QS,n6e),e(n6e,FRr),e(QS,TRr),e(lr,MRr),e(lr,Wt),M(WS,Wt,null),e(Wt,ERr),e(Wt,s6e),e(s6e,CRr),e(Wt,wRr),e(Wt,om),e(om,ARr),e(om,l6e),e(l6e,LRr),e(om,yRr),e(om,xoe),e(xoe,xRr),e(om,$Rr),e(Wt,kRr),M(s5,Wt,null),e(lr,SRr),e(lr,wo),M(US,wo,null),e(wo,RRr),e(wo,i6e),e(i6e,PRr),e(wo,BRr),e(wo,Sn),e(Sn,IRr),e(Sn,d6e),e(d6e,NRr),e(Sn,qRr),e(Sn,c6e),e(c6e,jRr),e(Sn,DRr),e(Sn,m6e),e(m6e,GRr),e(Sn,ORr),e(wo,VRr),e(wo,_t),e(_t,l5),e(l5,f6e),e(f6e,XRr),e(l5,zRr),e(l5,$oe),e($oe,QRr),e(l5,WRr),e(_t,URr),e(_t,i5),e(i5,g6e),e(g6e,HRr),e(i5,JRr),e(i5,koe),e(koe,YRr),e(i5,ZRr),e(_t,KRr),e(_t,d5),e(d5,h6e),e(h6e,ePr),e(d5,oPr),e(d5,Soe),e(Soe,rPr),e(d5,tPr),e(_t,aPr),e(_t,c5),e(c5,u6e),e(u6e,nPr),e(c5,sPr),e(c5,Roe),e(Roe,lPr),e(c5,iPr),e(_t,dPr),e(_t,m5),e(m5,p6e),e(p6e,cPr),e(m5,mPr),e(m5,Poe),e(Poe,fPr),e(m5,gPr),e(wo,hPr),e(wo,f5),e(f5,uPr),e(f5,_6e),e(_6e,pPr),e(f5,_Pr),e(f5,b6e),e(b6e,bPr),e(wo,vPr),M(g5,wo,null),b(m,Kto,_),b(m,rm,_),e(rm,h5),e(h5,v6e),M(HS,v6e,null),e(rm,FPr),e(rm,F6e),e(F6e,TPr),b(m,eao,_),b(m,ir,_),M(JS,ir,null),e(ir,MPr),e(ir,tm),e(tm,EPr),e(tm,Boe),e(Boe,CPr),e(tm,wPr),e(tm,Ioe),e(Ioe,APr),e(tm,LPr),e(ir,yPr),e(ir,YS),e(YS,xPr),e(YS,T6e),e(T6e,$Pr),e(YS,kPr),e(ir,SPr),e(ir,Ut),M(ZS,Ut,null),e(Ut,RPr),e(Ut,M6e),e(M6e,PPr),e(Ut,BPr),e(Ut,am),e(am,IPr),e(am,E6e),e(E6e,NPr),e(am,qPr),e(am,Noe),e(Noe,jPr),e(am,DPr),e(Ut,GPr),M(u5,Ut,null),e(ir,OPr),e(ir,Ao),M(KS,Ao,null),e(Ao,VPr),e(Ao,C6e),e(C6e,XPr),e(Ao,zPr),e(Ao,Rn),e(Rn,QPr),e(Rn,w6e),e(w6e,WPr),e(Rn,UPr),e(Rn,A6e),e(A6e,HPr),e(Rn,JPr),e(Rn,L6e),e(L6e,YPr),e(Rn,ZPr),e(Ao,KPr),e(Ao,y6e),e(y6e,p5),e(p5,x6e),e(x6e,eBr),e(p5,oBr),e(p5,qoe),e(qoe,rBr),e(p5,tBr),e(Ao,aBr),e(Ao,_5),e(_5,nBr),e(_5,$6e),e($6e,sBr),e(_5,lBr),e(_5,k6e),e(k6e,iBr),e(Ao,dBr),M(b5,Ao,null),b(m,oao,_),b(m,nm,_),e(nm,v5),e(v5,S6e),M(eR,S6e,null),e(nm,cBr),e(nm,R6e),e(R6e,mBr),b(m,rao,_),b(m,dr,_),M(oR,dr,null),e(dr,fBr),e(dr,sm),e(sm,gBr),e(sm,joe),e(joe,hBr),e(sm,uBr),e(sm,Doe),e(Doe,pBr),e(sm,_Br),e(dr,bBr),e(dr,rR),e(rR,vBr),e(rR,P6e),e(P6e,FBr),e(rR,TBr),e(dr,MBr),e(dr,Ht),M(tR,Ht,null),e(Ht,EBr),e(Ht,B6e),e(B6e,CBr),e(Ht,wBr),e(Ht,lm),e(lm,ABr),e(lm,I6e),e(I6e,LBr),e(lm,yBr),e(lm,Goe),e(Goe,xBr),e(lm,$Br),e(Ht,kBr),M(F5,Ht,null),e(dr,SBr),e(dr,Lo),M(aR,Lo,null),e(Lo,RBr),e(Lo,N6e),e(N6e,PBr),e(Lo,BBr),e(Lo,Pn),e(Pn,IBr),e(Pn,q6e),e(q6e,NBr),e(Pn,qBr),e(Pn,j6e),e(j6e,jBr),e(Pn,DBr),e(Pn,D6e),e(D6e,GBr),e(Pn,OBr),e(Lo,VBr),e(Lo,G6e),e(G6e,T5),e(T5,O6e),e(O6e,XBr),e(T5,zBr),e(T5,Ooe),e(Ooe,QBr),e(T5,WBr),e(Lo,UBr),e(Lo,M5),e(M5,HBr),e(M5,V6e),e(V6e,JBr),e(M5,YBr),e(M5,X6e),e(X6e,ZBr),e(Lo,KBr),M(E5,Lo,null),b(m,tao,_),b(m,im,_),e(im,C5),e(C5,z6e),M(nR,z6e,null),e(im,eIr),e(im,Q6e),e(Q6e,oIr),b(m,aao,_),b(m,cr,_),M(sR,cr,null),e(cr,rIr),e(cr,dm),e(dm,tIr),e(dm,Voe),e(Voe,aIr),e(dm,nIr),e(dm,Xoe),e(Xoe,sIr),e(dm,lIr),e(cr,iIr),e(cr,lR),e(lR,dIr),e(lR,W6e),e(W6e,cIr),e(lR,mIr),e(cr,fIr),e(cr,Jt),M(iR,Jt,null),e(Jt,gIr),e(Jt,U6e),e(U6e,hIr),e(Jt,uIr),e(Jt,cm),e(cm,pIr),e(cm,H6e),e(H6e,_Ir),e(cm,bIr),e(cm,zoe),e(zoe,vIr),e(cm,FIr),e(Jt,TIr),M(w5,Jt,null),e(cr,MIr),e(cr,Dr),M(dR,Dr,null),e(Dr,EIr),e(Dr,J6e),e(J6e,CIr),e(Dr,wIr),e(Dr,Bn),e(Bn,AIr),e(Bn,Y6e),e(Y6e,LIr),e(Bn,yIr),e(Bn,Z6e),e(Z6e,xIr),e(Bn,$Ir),e(Bn,K6e),e(K6e,kIr),e(Bn,SIr),e(Dr,RIr),e(Dr,B),e(B,A5),e(A5,e7e),e(e7e,PIr),e(A5,BIr),e(A5,Qoe),e(Qoe,IIr),e(A5,NIr),e(B,qIr),e(B,L5),e(L5,o7e),e(o7e,jIr),e(L5,DIr),e(L5,Woe),e(Woe,GIr),e(L5,OIr),e(B,VIr),e(B,y5),e(y5,r7e),e(r7e,XIr),e(y5,zIr),e(y5,Uoe),e(Uoe,QIr),e(y5,WIr),e(B,UIr),e(B,x5),e(x5,t7e),e(t7e,HIr),e(x5,JIr),e(x5,Hoe),e(Hoe,YIr),e(x5,ZIr),e(B,KIr),e(B,$5),e($5,a7e),e(a7e,eNr),e($5,oNr),e($5,Joe),e(Joe,rNr),e($5,tNr),e(B,aNr),e(B,k5),e(k5,n7e),e(n7e,nNr),e(k5,sNr),e(k5,Yoe),e(Yoe,lNr),e(k5,iNr),e(B,dNr),e(B,S5),e(S5,s7e),e(s7e,cNr),e(S5,mNr),e(S5,Zoe),e(Zoe,fNr),e(S5,gNr),e(B,hNr),e(B,R5),e(R5,l7e),e(l7e,uNr),e(R5,pNr),e(R5,Koe),e(Koe,_Nr),e(R5,bNr),e(B,vNr),e(B,P5),e(P5,i7e),e(i7e,FNr),e(P5,TNr),e(P5,ere),e(ere,MNr),e(P5,ENr),e(B,CNr),e(B,B5),e(B5,d7e),e(d7e,wNr),e(B5,ANr),e(B5,ore),e(ore,LNr),e(B5,yNr),e(B,xNr),e(B,I5),e(I5,c7e),e(c7e,$Nr),e(I5,kNr),e(I5,rre),e(rre,SNr),e(I5,RNr),e(B,PNr),e(B,N5),e(N5,m7e),e(m7e,BNr),e(N5,INr),e(N5,tre),e(tre,NNr),e(N5,qNr),e(B,jNr),e(B,q5),e(q5,f7e),e(f7e,DNr),e(q5,GNr),e(q5,are),e(are,ONr),e(q5,VNr),e(B,XNr),e(B,j5),e(j5,g7e),e(g7e,zNr),e(j5,QNr),e(j5,nre),e(nre,WNr),e(j5,UNr),e(B,HNr),e(B,D5),e(D5,h7e),e(h7e,JNr),e(D5,YNr),e(D5,sre),e(sre,ZNr),e(D5,KNr),e(B,eqr),e(B,G5),e(G5,u7e),e(u7e,oqr),e(G5,rqr),e(G5,lre),e(lre,tqr),e(G5,aqr),e(B,nqr),e(B,O5),e(O5,p7e),e(p7e,sqr),e(O5,lqr),e(O5,ire),e(ire,iqr),e(O5,dqr),e(B,cqr),e(B,V5),e(V5,_7e),e(_7e,mqr),e(V5,fqr),e(V5,dre),e(dre,gqr),e(V5,hqr),e(B,uqr),e(B,X5),e(X5,b7e),e(b7e,pqr),e(X5,_qr),e(X5,cre),e(cre,bqr),e(X5,vqr),e(B,Fqr),e(B,kl),e(kl,v7e),e(v7e,Tqr),e(kl,Mqr),e(kl,mre),e(mre,Eqr),e(kl,Cqr),e(kl,fre),e(fre,wqr),e(kl,Aqr),e(B,Lqr),e(B,z5),e(z5,F7e),e(F7e,yqr),e(z5,xqr),e(z5,gre),e(gre,$qr),e(z5,kqr),e(B,Sqr),e(B,Q5),e(Q5,T7e),e(T7e,Rqr),e(Q5,Pqr),e(Q5,hre),e(hre,Bqr),e(Q5,Iqr),e(B,Nqr),e(B,W5),e(W5,M7e),e(M7e,qqr),e(W5,jqr),e(W5,ure),e(ure,Dqr),e(W5,Gqr),e(B,Oqr),e(B,U5),e(U5,E7e),e(E7e,Vqr),e(U5,Xqr),e(U5,pre),e(pre,zqr),e(U5,Qqr),e(B,Wqr),e(B,H5),e(H5,C7e),e(C7e,Uqr),e(H5,Hqr),e(H5,_re),e(_re,Jqr),e(H5,Yqr),e(B,Zqr),e(B,J5),e(J5,w7e),e(w7e,Kqr),e(J5,ejr),e(J5,bre),e(bre,ojr),e(J5,rjr),e(B,tjr),e(B,Y5),e(Y5,A7e),e(A7e,ajr),e(Y5,njr),e(Y5,vre),e(vre,sjr),e(Y5,ljr),e(B,ijr),e(B,Z5),e(Z5,L7e),e(L7e,djr),e(Z5,cjr),e(Z5,Fre),e(Fre,mjr),e(Z5,fjr),e(B,gjr),e(B,K5),e(K5,y7e),e(y7e,hjr),e(K5,ujr),e(K5,Tre),e(Tre,pjr),e(K5,_jr),e(B,bjr),e(B,e0),e(e0,x7e),e(x7e,vjr),e(e0,Fjr),e(e0,Mre),e(Mre,Tjr),e(e0,Mjr),e(B,Ejr),e(B,o0),e(o0,$7e),e($7e,Cjr),e(o0,wjr),e(o0,Ere),e(Ere,Ajr),e(o0,Ljr),e(B,yjr),e(B,r0),e(r0,k7e),e(k7e,xjr),e(r0,$jr),e(r0,Cre),e(Cre,kjr),e(r0,Sjr),e(B,Rjr),e(B,t0),e(t0,S7e),e(S7e,Pjr),e(t0,Bjr),e(t0,wre),e(wre,Ijr),e(t0,Njr),e(B,qjr),e(B,a0),e(a0,R7e),e(R7e,jjr),e(a0,Djr),e(a0,Are),e(Are,Gjr),e(a0,Ojr),e(B,Vjr),e(B,n0),e(n0,P7e),e(P7e,Xjr),e(n0,zjr),e(n0,Lre),e(Lre,Qjr),e(n0,Wjr),e(B,Ujr),e(B,s0),e(s0,B7e),e(B7e,Hjr),e(s0,Jjr),e(s0,yre),e(yre,Yjr),e(s0,Zjr),e(B,Kjr),e(B,l0),e(l0,I7e),e(I7e,eDr),e(l0,oDr),e(l0,xre),e(xre,rDr),e(l0,tDr),e(B,aDr),e(B,i0),e(i0,N7e),e(N7e,nDr),e(i0,sDr),e(i0,$re),e($re,lDr),e(i0,iDr),e(B,dDr),e(B,d0),e(d0,q7e),e(q7e,cDr),e(d0,mDr),e(d0,kre),e(kre,fDr),e(d0,gDr),e(B,hDr),e(B,c0),e(c0,j7e),e(j7e,uDr),e(c0,pDr),e(c0,Sre),e(Sre,_Dr),e(c0,bDr),e(B,vDr),e(B,m0),e(m0,D7e),e(D7e,FDr),e(m0,TDr),e(m0,Rre),e(Rre,MDr),e(m0,EDr),e(B,CDr),e(B,f0),e(f0,G7e),e(G7e,wDr),e(f0,ADr),e(f0,Pre),e(Pre,LDr),e(f0,yDr),e(B,xDr),e(B,g0),e(g0,O7e),e(O7e,$Dr),e(g0,kDr),e(g0,Bre),e(Bre,SDr),e(g0,RDr),e(B,PDr),e(B,h0),e(h0,V7e),e(V7e,BDr),e(h0,IDr),e(h0,Ire),e(Ire,NDr),e(h0,qDr),e(B,jDr),e(B,u0),e(u0,X7e),e(X7e,DDr),e(u0,GDr),e(u0,Nre),e(Nre,ODr),e(u0,VDr),e(B,XDr),e(B,p0),e(p0,z7e),e(z7e,zDr),e(p0,QDr),e(p0,qre),e(qre,WDr),e(p0,UDr),e(B,HDr),e(B,_0),e(_0,Q7e),e(Q7e,JDr),e(_0,YDr),e(_0,jre),e(jre,ZDr),e(_0,KDr),e(B,eGr),e(B,b0),e(b0,W7e),e(W7e,oGr),e(b0,rGr),e(b0,Dre),e(Dre,tGr),e(b0,aGr),e(B,nGr),e(B,v0),e(v0,U7e),e(U7e,sGr),e(v0,lGr),e(v0,Gre),e(Gre,iGr),e(v0,dGr),e(B,cGr),e(B,F0),e(F0,H7e),e(H7e,mGr),e(F0,fGr),e(F0,Ore),e(Ore,gGr),e(F0,hGr),e(B,uGr),e(B,T0),e(T0,J7e),e(J7e,pGr),e(T0,_Gr),e(T0,Vre),e(Vre,bGr),e(T0,vGr),e(B,FGr),e(B,M0),e(M0,Y7e),e(Y7e,TGr),e(M0,MGr),e(M0,Xre),e(Xre,EGr),e(M0,CGr),e(B,wGr),e(B,E0),e(E0,Z7e),e(Z7e,AGr),e(E0,LGr),e(E0,zre),e(zre,yGr),e(E0,xGr),e(B,$Gr),e(B,C0),e(C0,K7e),e(K7e,kGr),e(C0,SGr),e(C0,Qre),e(Qre,RGr),e(C0,PGr),e(B,BGr),e(B,w0),e(w0,eLe),e(eLe,IGr),e(w0,NGr),e(w0,Wre),e(Wre,qGr),e(w0,jGr),e(B,DGr),e(B,A0),e(A0,oLe),e(oLe,GGr),e(A0,OGr),e(A0,Ure),e(Ure,VGr),e(A0,XGr),e(B,zGr),e(B,L0),e(L0,rLe),e(rLe,QGr),e(L0,WGr),e(L0,Hre),e(Hre,UGr),e(L0,HGr),e(Dr,JGr),M(y0,Dr,null),b(m,nao,_),b(m,mm,_),e(mm,x0),e(x0,tLe),M(cR,tLe,null),e(mm,YGr),e(mm,aLe),e(aLe,ZGr),b(m,sao,_),b(m,mr,_),M(mR,mr,null),e(mr,KGr),e(mr,fm),e(fm,eOr),e(fm,Jre),e(Jre,oOr),e(fm,rOr),e(fm,Yre),e(Yre,tOr),e(fm,aOr),e(mr,nOr),e(mr,fR),e(fR,sOr),e(fR,nLe),e(nLe,lOr),e(fR,iOr),e(mr,dOr),e(mr,Yt),M(gR,Yt,null),e(Yt,cOr),e(Yt,sLe),e(sLe,mOr),e(Yt,fOr),e(Yt,gm),e(gm,gOr),e(gm,lLe),e(lLe,hOr),e(gm,uOr),e(gm,Zre),e(Zre,pOr),e(gm,_Or),e(Yt,bOr),M($0,Yt,null),e(mr,vOr),e(mr,Gr),M(hR,Gr,null),e(Gr,FOr),e(Gr,iLe),e(iLe,TOr),e(Gr,MOr),e(Gr,In),e(In,EOr),e(In,dLe),e(dLe,COr),e(In,wOr),e(In,cLe),e(cLe,AOr),e(In,LOr),e(In,mLe),e(mLe,yOr),e(In,xOr),e(Gr,$Or),e(Gr,le),e(le,k0),e(k0,fLe),e(fLe,kOr),e(k0,SOr),e(k0,Kre),e(Kre,ROr),e(k0,POr),e(le,BOr),e(le,S0),e(S0,gLe),e(gLe,IOr),e(S0,NOr),e(S0,ete),e(ete,qOr),e(S0,jOr),e(le,DOr),e(le,R0),e(R0,hLe),e(hLe,GOr),e(R0,OOr),e(R0,ote),e(ote,VOr),e(R0,XOr),e(le,zOr),e(le,P0),e(P0,uLe),e(uLe,QOr),e(P0,WOr),e(P0,rte),e(rte,UOr),e(P0,HOr),e(le,JOr),e(le,B0),e(B0,pLe),e(pLe,YOr),e(B0,ZOr),e(B0,tte),e(tte,KOr),e(B0,eVr),e(le,oVr),e(le,I0),e(I0,_Le),e(_Le,rVr),e(I0,tVr),e(I0,ate),e(ate,aVr),e(I0,nVr),e(le,sVr),e(le,N0),e(N0,bLe),e(bLe,lVr),e(N0,iVr),e(N0,nte),e(nte,dVr),e(N0,cVr),e(le,mVr),e(le,q0),e(q0,vLe),e(vLe,fVr),e(q0,gVr),e(q0,ste),e(ste,hVr),e(q0,uVr),e(le,pVr),e(le,j0),e(j0,FLe),e(FLe,_Vr),e(j0,bVr),e(j0,lte),e(lte,vVr),e(j0,FVr),e(le,TVr),e(le,D0),e(D0,TLe),e(TLe,MVr),e(D0,EVr),e(D0,ite),e(ite,CVr),e(D0,wVr),e(le,AVr),e(le,G0),e(G0,MLe),e(MLe,LVr),e(G0,yVr),e(G0,dte),e(dte,xVr),e(G0,$Vr),e(le,kVr),e(le,O0),e(O0,ELe),e(ELe,SVr),e(O0,RVr),e(O0,cte),e(cte,PVr),e(O0,BVr),e(le,IVr),e(le,V0),e(V0,CLe),e(CLe,NVr),e(V0,qVr),e(V0,mte),e(mte,jVr),e(V0,DVr),e(le,GVr),e(le,X0),e(X0,wLe),e(wLe,OVr),e(X0,VVr),e(X0,fte),e(fte,XVr),e(X0,zVr),e(le,QVr),e(le,z0),e(z0,ALe),e(ALe,WVr),e(z0,UVr),e(z0,gte),e(gte,HVr),e(z0,JVr),e(le,YVr),e(le,Q0),e(Q0,LLe),e(LLe,ZVr),e(Q0,KVr),e(Q0,hte),e(hte,eXr),e(Q0,oXr),e(le,rXr),e(le,W0),e(W0,yLe),e(yLe,tXr),e(W0,aXr),e(W0,ute),e(ute,nXr),e(W0,sXr),e(le,lXr),e(le,U0),e(U0,xLe),e(xLe,iXr),e(U0,dXr),e(U0,pte),e(pte,cXr),e(U0,mXr),e(le,fXr),e(le,H0),e(H0,$Le),e($Le,gXr),e(H0,hXr),e(H0,_te),e(_te,uXr),e(H0,pXr),e(le,_Xr),e(le,J0),e(J0,kLe),e(kLe,bXr),e(J0,vXr),e(J0,bte),e(bte,FXr),e(J0,TXr),e(le,MXr),e(le,Y0),e(Y0,SLe),e(SLe,EXr),e(Y0,CXr),e(Y0,vte),e(vte,wXr),e(Y0,AXr),e(le,LXr),e(le,Z0),e(Z0,RLe),e(RLe,yXr),e(Z0,xXr),e(Z0,Fte),e(Fte,$Xr),e(Z0,kXr),e(le,SXr),e(le,K0),e(K0,PLe),e(PLe,RXr),e(K0,PXr),e(K0,Tte),e(Tte,BXr),e(K0,IXr),e(Gr,NXr),M(ew,Gr,null),b(m,lao,_),b(m,hm,_),e(hm,ow),e(ow,BLe),M(uR,BLe,null),e(hm,qXr),e(hm,ILe),e(ILe,jXr),b(m,iao,_),b(m,fr,_),M(pR,fr,null),e(fr,DXr),e(fr,um),e(um,GXr),e(um,Mte),e(Mte,OXr),e(um,VXr),e(um,Ete),e(Ete,XXr),e(um,zXr),e(fr,QXr),e(fr,_R),e(_R,WXr),e(_R,NLe),e(NLe,UXr),e(_R,HXr),e(fr,JXr),e(fr,Zt),M(bR,Zt,null),e(Zt,YXr),e(Zt,qLe),e(qLe,ZXr),e(Zt,KXr),e(Zt,pm),e(pm,ezr),e(pm,jLe),e(jLe,ozr),e(pm,rzr),e(pm,Cte),e(Cte,tzr),e(pm,azr),e(Zt,nzr),M(rw,Zt,null),e(fr,szr),e(fr,Or),M(vR,Or,null),e(Or,lzr),e(Or,DLe),e(DLe,izr),e(Or,dzr),e(Or,Nn),e(Nn,czr),e(Nn,GLe),e(GLe,mzr),e(Nn,fzr),e(Nn,OLe),e(OLe,gzr),e(Nn,hzr),e(Nn,VLe),e(VLe,uzr),e(Nn,pzr),e(Or,_zr),e(Or,Me),e(Me,tw),e(tw,XLe),e(XLe,bzr),e(tw,vzr),e(tw,wte),e(wte,Fzr),e(tw,Tzr),e(Me,Mzr),e(Me,aw),e(aw,zLe),e(zLe,Ezr),e(aw,Czr),e(aw,Ate),e(Ate,wzr),e(aw,Azr),e(Me,Lzr),e(Me,nw),e(nw,QLe),e(QLe,yzr),e(nw,xzr),e(nw,Lte),e(Lte,$zr),e(nw,kzr),e(Me,Szr),e(Me,sw),e(sw,WLe),e(WLe,Rzr),e(sw,Pzr),e(sw,yte),e(yte,Bzr),e(sw,Izr),e(Me,Nzr),e(Me,lw),e(lw,ULe),e(ULe,qzr),e(lw,jzr),e(lw,xte),e(xte,Dzr),e(lw,Gzr),e(Me,Ozr),e(Me,iw),e(iw,HLe),e(HLe,Vzr),e(iw,Xzr),e(iw,$te),e($te,zzr),e(iw,Qzr),e(Me,Wzr),e(Me,dw),e(dw,JLe),e(JLe,Uzr),e(dw,Hzr),e(dw,kte),e(kte,Jzr),e(dw,Yzr),e(Me,Zzr),e(Me,cw),e(cw,YLe),e(YLe,Kzr),e(cw,eQr),e(cw,Ste),e(Ste,oQr),e(cw,rQr),e(Me,tQr),e(Me,mw),e(mw,ZLe),e(ZLe,aQr),e(mw,nQr),e(mw,Rte),e(Rte,sQr),e(mw,lQr),e(Me,iQr),e(Me,fw),e(fw,KLe),e(KLe,dQr),e(fw,cQr),e(fw,Pte),e(Pte,mQr),e(fw,fQr),e(Me,gQr),e(Me,gw),e(gw,e8e),e(e8e,hQr),e(gw,uQr),e(gw,Bte),e(Bte,pQr),e(gw,_Qr),e(Me,bQr),e(Me,hw),e(hw,o8e),e(o8e,vQr),e(hw,FQr),e(hw,Ite),e(Ite,TQr),e(hw,MQr),e(Me,EQr),e(Me,uw),e(uw,r8e),e(r8e,CQr),e(uw,wQr),e(uw,Nte),e(Nte,AQr),e(uw,LQr),e(Me,yQr),e(Me,pw),e(pw,t8e),e(t8e,xQr),e(pw,$Qr),e(pw,qte),e(qte,kQr),e(pw,SQr),e(Or,RQr),M(_w,Or,null),b(m,dao,_),b(m,_m,_),e(_m,bw),e(bw,a8e),M(FR,a8e,null),e(_m,PQr),e(_m,n8e),e(n8e,BQr),b(m,cao,_),b(m,gr,_),M(TR,gr,null),e(gr,IQr),e(gr,bm),e(bm,NQr),e(bm,jte),e(jte,qQr),e(bm,jQr),e(bm,Dte),e(Dte,DQr),e(bm,GQr),e(gr,OQr),e(gr,MR),e(MR,VQr),e(MR,s8e),e(s8e,XQr),e(MR,zQr),e(gr,QQr),e(gr,Kt),M(ER,Kt,null),e(Kt,WQr),e(Kt,l8e),e(l8e,UQr),e(Kt,HQr),e(Kt,vm),e(vm,JQr),e(vm,i8e),e(i8e,YQr),e(vm,ZQr),e(vm,Gte),e(Gte,KQr),e(vm,eWr),e(Kt,oWr),M(vw,Kt,null),e(gr,rWr),e(gr,Vr),M(CR,Vr,null),e(Vr,tWr),e(Vr,d8e),e(d8e,aWr),e(Vr,nWr),e(Vr,qn),e(qn,sWr),e(qn,c8e),e(c8e,lWr),e(qn,iWr),e(qn,m8e),e(m8e,dWr),e(qn,cWr),e(qn,f8e),e(f8e,mWr),e(qn,fWr),e(Vr,gWr),e(Vr,ye),e(ye,Fw),e(Fw,g8e),e(g8e,hWr),e(Fw,uWr),e(Fw,Ote),e(Ote,pWr),e(Fw,_Wr),e(ye,bWr),e(ye,Tw),e(Tw,h8e),e(h8e,vWr),e(Tw,FWr),e(Tw,Vte),e(Vte,TWr),e(Tw,MWr),e(ye,EWr),e(ye,Mw),e(Mw,u8e),e(u8e,CWr),e(Mw,wWr),e(Mw,Xte),e(Xte,AWr),e(Mw,LWr),e(ye,yWr),e(ye,Sl),e(Sl,p8e),e(p8e,xWr),e(Sl,$Wr),e(Sl,zte),e(zte,kWr),e(Sl,SWr),e(Sl,Qte),e(Qte,RWr),e(Sl,PWr),e(ye,BWr),e(ye,Ew),e(Ew,_8e),e(_8e,IWr),e(Ew,NWr),e(Ew,Wte),e(Wte,qWr),e(Ew,jWr),e(ye,DWr),e(ye,Cw),e(Cw,b8e),e(b8e,GWr),e(Cw,OWr),e(Cw,Ute),e(Ute,VWr),e(Cw,XWr),e(ye,zWr),e(ye,ww),e(ww,v8e),e(v8e,QWr),e(ww,WWr),e(ww,Hte),e(Hte,UWr),e(ww,HWr),e(ye,JWr),e(ye,Aw),e(Aw,F8e),e(F8e,YWr),e(Aw,ZWr),e(Aw,Jte),e(Jte,KWr),e(Aw,eUr),e(ye,oUr),e(ye,Lw),e(Lw,T8e),e(T8e,rUr),e(Lw,tUr),e(Lw,Yte),e(Yte,aUr),e(Lw,nUr),e(ye,sUr),e(ye,yw),e(yw,M8e),e(M8e,lUr),e(yw,iUr),e(yw,Zte),e(Zte,dUr),e(yw,cUr),e(Vr,mUr),M(xw,Vr,null),b(m,mao,_),b(m,Fm,_),e(Fm,$w),e($w,E8e),M(wR,E8e,null),e(Fm,fUr),e(Fm,C8e),e(C8e,gUr),b(m,fao,_),b(m,hr,_),M(AR,hr,null),e(hr,hUr),e(hr,Tm),e(Tm,uUr),e(Tm,Kte),e(Kte,pUr),e(Tm,_Ur),e(Tm,eae),e(eae,bUr),e(Tm,vUr),e(hr,FUr),e(hr,LR),e(LR,TUr),e(LR,w8e),e(w8e,MUr),e(LR,EUr),e(hr,CUr),e(hr,ea),M(yR,ea,null),e(ea,wUr),e(ea,A8e),e(A8e,AUr),e(ea,LUr),e(ea,Mm),e(Mm,yUr),e(Mm,L8e),e(L8e,xUr),e(Mm,$Ur),e(Mm,oae),e(oae,kUr),e(Mm,SUr),e(ea,RUr),M(kw,ea,null),e(hr,PUr),e(hr,Xr),M(xR,Xr,null),e(Xr,BUr),e(Xr,y8e),e(y8e,IUr),e(Xr,NUr),e(Xr,jn),e(jn,qUr),e(jn,x8e),e(x8e,jUr),e(jn,DUr),e(jn,$8e),e($8e,GUr),e(jn,OUr),e(jn,k8e),e(k8e,VUr),e(jn,XUr),e(Xr,zUr),e(Xr,Em),e(Em,Sw),e(Sw,S8e),e(S8e,QUr),e(Sw,WUr),e(Sw,rae),e(rae,UUr),e(Sw,HUr),e(Em,JUr),e(Em,Rw),e(Rw,R8e),e(R8e,YUr),e(Rw,ZUr),e(Rw,tae),e(tae,KUr),e(Rw,eHr),e(Em,oHr),e(Em,Pw),e(Pw,P8e),e(P8e,rHr),e(Pw,tHr),e(Pw,aae),e(aae,aHr),e(Pw,nHr),e(Xr,sHr),M(Bw,Xr,null),b(m,gao,_),b(m,Cm,_),e(Cm,Iw),e(Iw,B8e),M($R,B8e,null),e(Cm,lHr),e(Cm,I8e),e(I8e,iHr),b(m,hao,_),b(m,ur,_),M(kR,ur,null),e(ur,dHr),e(ur,wm),e(wm,cHr),e(wm,nae),e(nae,mHr),e(wm,fHr),e(wm,sae),e(sae,gHr),e(wm,hHr),e(ur,uHr),e(ur,SR),e(SR,pHr),e(SR,N8e),e(N8e,_Hr),e(SR,bHr),e(ur,vHr),e(ur,oa),M(RR,oa,null),e(oa,FHr),e(oa,q8e),e(q8e,THr),e(oa,MHr),e(oa,Am),e(Am,EHr),e(Am,j8e),e(j8e,CHr),e(Am,wHr),e(Am,lae),e(lae,AHr),e(Am,LHr),e(oa,yHr),M(Nw,oa,null),e(ur,xHr),e(ur,zr),M(PR,zr,null),e(zr,$Hr),e(zr,D8e),e(D8e,kHr),e(zr,SHr),e(zr,Dn),e(Dn,RHr),e(Dn,G8e),e(G8e,PHr),e(Dn,BHr),e(Dn,O8e),e(O8e,IHr),e(Dn,NHr),e(Dn,V8e),e(V8e,qHr),e(Dn,jHr),e(zr,DHr),e(zr,ge),e(ge,qw),e(qw,X8e),e(X8e,GHr),e(qw,OHr),e(qw,iae),e(iae,VHr),e(qw,XHr),e(ge,zHr),e(ge,jw),e(jw,z8e),e(z8e,QHr),e(jw,WHr),e(jw,dae),e(dae,UHr),e(jw,HHr),e(ge,JHr),e(ge,Dw),e(Dw,Q8e),e(Q8e,YHr),e(Dw,ZHr),e(Dw,cae),e(cae,KHr),e(Dw,eJr),e(ge,oJr),e(ge,Gw),e(Gw,W8e),e(W8e,rJr),e(Gw,tJr),e(Gw,mae),e(mae,aJr),e(Gw,nJr),e(ge,sJr),e(ge,Ow),e(Ow,U8e),e(U8e,lJr),e(Ow,iJr),e(Ow,fae),e(fae,dJr),e(Ow,cJr),e(ge,mJr),e(ge,Vw),e(Vw,H8e),e(H8e,fJr),e(Vw,gJr),e(Vw,gae),e(gae,hJr),e(Vw,uJr),e(ge,pJr),e(ge,Xw),e(Xw,J8e),e(J8e,_Jr),e(Xw,bJr),e(Xw,hae),e(hae,vJr),e(Xw,FJr),e(ge,TJr),e(ge,zw),e(zw,Y8e),e(Y8e,MJr),e(zw,EJr),e(zw,uae),e(uae,CJr),e(zw,wJr),e(ge,AJr),e(ge,Qw),e(Qw,Z8e),e(Z8e,LJr),e(Qw,yJr),e(Qw,pae),e(pae,xJr),e(Qw,$Jr),e(ge,kJr),e(ge,Ww),e(Ww,K8e),e(K8e,SJr),e(Ww,RJr),e(Ww,_ae),e(_ae,PJr),e(Ww,BJr),e(ge,IJr),e(ge,Uw),e(Uw,eye),e(eye,NJr),e(Uw,qJr),e(Uw,bae),e(bae,jJr),e(Uw,DJr),e(ge,GJr),e(ge,Hw),e(Hw,oye),e(oye,OJr),e(Hw,VJr),e(Hw,vae),e(vae,XJr),e(Hw,zJr),e(ge,QJr),e(ge,Jw),e(Jw,rye),e(rye,WJr),e(Jw,UJr),e(Jw,Fae),e(Fae,HJr),e(Jw,JJr),e(ge,YJr),e(ge,Yw),e(Yw,tye),e(tye,ZJr),e(Yw,KJr),e(Yw,Tae),e(Tae,eYr),e(Yw,oYr),e(ge,rYr),e(ge,Zw),e(Zw,aye),e(aye,tYr),e(Zw,aYr),e(Zw,Mae),e(Mae,nYr),e(Zw,sYr),e(ge,lYr),e(ge,Kw),e(Kw,nye),e(nye,iYr),e(Kw,dYr),e(Kw,Eae),e(Eae,cYr),e(Kw,mYr),e(ge,fYr),e(ge,eA),e(eA,sye),e(sye,gYr),e(eA,hYr),e(eA,Cae),e(Cae,uYr),e(eA,pYr),e(ge,_Yr),e(ge,oA),e(oA,lye),e(lye,bYr),e(oA,vYr),e(oA,wae),e(wae,FYr),e(oA,TYr),e(ge,MYr),e(ge,rA),e(rA,iye),e(iye,EYr),e(rA,CYr),e(rA,Aae),e(Aae,wYr),e(rA,AYr),e(ge,LYr),e(ge,tA),e(tA,dye),e(dye,yYr),e(tA,xYr),e(tA,Lae),e(Lae,$Yr),e(tA,kYr),e(zr,SYr),M(aA,zr,null),b(m,uao,_),b(m,Lm,_),e(Lm,nA),e(nA,cye),M(BR,cye,null),e(Lm,RYr),e(Lm,mye),e(mye,PYr),b(m,pao,_),b(m,pr,_),M(IR,pr,null),e(pr,BYr),e(pr,ym),e(ym,IYr),e(ym,yae),e(yae,NYr),e(ym,qYr),e(ym,xae),e(xae,jYr),e(ym,DYr),e(pr,GYr),e(pr,NR),e(NR,OYr),e(NR,fye),e(fye,VYr),e(NR,XYr),e(pr,zYr),e(pr,ra),M(qR,ra,null),e(ra,QYr),e(ra,gye),e(gye,WYr),e(ra,UYr),e(ra,xm),e(xm,HYr),e(xm,hye),e(hye,JYr),e(xm,YYr),e(xm,$ae),e($ae,ZYr),e(xm,KYr),e(ra,eZr),M(sA,ra,null),e(pr,oZr),e(pr,Qr),M(jR,Qr,null),e(Qr,rZr),e(Qr,uye),e(uye,tZr),e(Qr,aZr),e(Qr,Gn),e(Gn,nZr),e(Gn,pye),e(pye,sZr),e(Gn,lZr),e(Gn,_ye),e(_ye,iZr),e(Gn,dZr),e(Gn,bye),e(bye,cZr),e(Gn,mZr),e(Qr,fZr),e(Qr,xe),e(xe,lA),e(lA,vye),e(vye,gZr),e(lA,hZr),e(lA,kae),e(kae,uZr),e(lA,pZr),e(xe,_Zr),e(xe,iA),e(iA,Fye),e(Fye,bZr),e(iA,vZr),e(iA,Sae),e(Sae,FZr),e(iA,TZr),e(xe,MZr),e(xe,dA),e(dA,Tye),e(Tye,EZr),e(dA,CZr),e(dA,Rae),e(Rae,wZr),e(dA,AZr),e(xe,LZr),e(xe,cA),e(cA,Mye),e(Mye,yZr),e(cA,xZr),e(cA,Pae),e(Pae,$Zr),e(cA,kZr),e(xe,SZr),e(xe,mA),e(mA,Eye),e(Eye,RZr),e(mA,PZr),e(mA,Bae),e(Bae,BZr),e(mA,IZr),e(xe,NZr),e(xe,fA),e(fA,Cye),e(Cye,qZr),e(fA,jZr),e(fA,Iae),e(Iae,DZr),e(fA,GZr),e(xe,OZr),e(xe,gA),e(gA,wye),e(wye,VZr),e(gA,XZr),e(gA,Nae),e(Nae,zZr),e(gA,QZr),e(xe,WZr),e(xe,hA),e(hA,Aye),e(Aye,UZr),e(hA,HZr),e(hA,qae),e(qae,JZr),e(hA,YZr),e(xe,ZZr),e(xe,uA),e(uA,Lye),e(Lye,KZr),e(uA,eKr),e(uA,jae),e(jae,oKr),e(uA,rKr),e(xe,tKr),e(xe,pA),e(pA,yye),e(yye,aKr),e(pA,nKr),e(pA,Dae),e(Dae,sKr),e(pA,lKr),e(Qr,iKr),M(_A,Qr,null),b(m,_ao,_),b(m,$m,_),e($m,bA),e(bA,xye),M(DR,xye,null),e($m,dKr),e($m,$ye),e($ye,cKr),b(m,bao,_),b(m,_r,_),M(GR,_r,null),e(_r,mKr),e(_r,km),e(km,fKr),e(km,Gae),e(Gae,gKr),e(km,hKr),e(km,Oae),e(Oae,uKr),e(km,pKr),e(_r,_Kr),e(_r,OR),e(OR,bKr),e(OR,kye),e(kye,vKr),e(OR,FKr),e(_r,TKr),e(_r,ta),M(VR,ta,null),e(ta,MKr),e(ta,Sye),e(Sye,EKr),e(ta,CKr),e(ta,Sm),e(Sm,wKr),e(Sm,Rye),e(Rye,AKr),e(Sm,LKr),e(Sm,Vae),e(Vae,yKr),e(Sm,xKr),e(ta,$Kr),M(vA,ta,null),e(_r,kKr),e(_r,Wr),M(XR,Wr,null),e(Wr,SKr),e(Wr,Pye),e(Pye,RKr),e(Wr,PKr),e(Wr,On),e(On,BKr),e(On,Bye),e(Bye,IKr),e(On,NKr),e(On,Iye),e(Iye,qKr),e(On,jKr),e(On,Nye),e(Nye,DKr),e(On,GKr),e(Wr,OKr),e(Wr,re),e(re,FA),e(FA,qye),e(qye,VKr),e(FA,XKr),e(FA,Xae),e(Xae,zKr),e(FA,QKr),e(re,WKr),e(re,TA),e(TA,jye),e(jye,UKr),e(TA,HKr),e(TA,zae),e(zae,JKr),e(TA,YKr),e(re,ZKr),e(re,MA),e(MA,Dye),e(Dye,KKr),e(MA,eet),e(MA,Qae),e(Qae,oet),e(MA,ret),e(re,tet),e(re,EA),e(EA,Gye),e(Gye,aet),e(EA,net),e(EA,Wae),e(Wae,set),e(EA,iet),e(re,det),e(re,CA),e(CA,Oye),e(Oye,cet),e(CA,met),e(CA,Uae),e(Uae,fet),e(CA,get),e(re,het),e(re,wA),e(wA,Vye),e(Vye,uet),e(wA,pet),e(wA,Hae),e(Hae,_et),e(wA,bet),e(re,vet),e(re,AA),e(AA,Xye),e(Xye,Fet),e(AA,Tet),e(AA,Jae),e(Jae,Met),e(AA,Eet),e(re,Cet),e(re,LA),e(LA,zye),e(zye,wet),e(LA,Aet),e(LA,Yae),e(Yae,Let),e(LA,yet),e(re,xet),e(re,yA),e(yA,Qye),e(Qye,$et),e(yA,ket),e(yA,Zae),e(Zae,Set),e(yA,Ret),e(re,Pet),e(re,xA),e(xA,Wye),e(Wye,Bet),e(xA,Iet),e(xA,Kae),e(Kae,Net),e(xA,qet),e(re,jet),e(re,$A),e($A,Uye),e(Uye,Det),e($A,Get),e($A,ene),e(ene,Oet),e($A,Vet),e(re,Xet),e(re,kA),e(kA,Hye),e(Hye,zet),e(kA,Qet),e(kA,one),e(one,Wet),e(kA,Uet),e(re,Het),e(re,SA),e(SA,Jye),e(Jye,Jet),e(SA,Yet),e(SA,rne),e(rne,Zet),e(SA,Ket),e(re,eot),e(re,RA),e(RA,Yye),e(Yye,oot),e(RA,rot),e(RA,tne),e(tne,tot),e(RA,aot),e(re,not),e(re,PA),e(PA,Zye),e(Zye,sot),e(PA,lot),e(PA,ane),e(ane,iot),e(PA,dot),e(re,cot),e(re,BA),e(BA,Kye),e(Kye,mot),e(BA,fot),e(BA,nne),e(nne,got),e(BA,hot),e(re,uot),e(re,IA),e(IA,e9e),e(e9e,pot),e(IA,_ot),e(IA,sne),e(sne,bot),e(IA,vot),e(re,Fot),e(re,NA),e(NA,o9e),e(o9e,Tot),e(NA,Mot),e(NA,lne),e(lne,Eot),e(NA,Cot),e(re,wot),e(re,qA),e(qA,r9e),e(r9e,Aot),e(qA,Lot),e(qA,ine),e(ine,yot),e(qA,xot),e(re,$ot),e(re,jA),e(jA,t9e),e(t9e,kot),e(jA,Sot),e(jA,dne),e(dne,Rot),e(jA,Pot),e(re,Bot),e(re,DA),e(DA,a9e),e(a9e,Iot),e(DA,Not),e(DA,cne),e(cne,qot),e(DA,jot),e(re,Dot),e(re,GA),e(GA,n9e),e(n9e,Got),e(GA,Oot),e(GA,mne),e(mne,Vot),e(GA,Xot),e(re,zot),e(re,OA),e(OA,s9e),e(s9e,Qot),e(OA,Wot),e(OA,fne),e(fne,Uot),e(OA,Hot),e(re,Jot),e(re,VA),e(VA,l9e),e(l9e,Yot),e(VA,Zot),e(VA,gne),e(gne,Kot),e(VA,ert),e(re,ort),e(re,XA),e(XA,i9e),e(i9e,rrt),e(XA,trt),e(XA,hne),e(hne,art),e(XA,nrt),e(re,srt),e(re,zA),e(zA,d9e),e(d9e,lrt),e(zA,irt),e(zA,une),e(une,drt),e(zA,crt),e(re,mrt),e(re,QA),e(QA,c9e),e(c9e,frt),e(QA,grt),e(QA,pne),e(pne,hrt),e(QA,urt),e(Wr,prt),M(WA,Wr,null),b(m,vao,_),b(m,Rm,_),e(Rm,UA),e(UA,m9e),M(zR,m9e,null),e(Rm,_rt),e(Rm,f9e),e(f9e,brt),b(m,Fao,_),b(m,br,_),M(QR,br,null),e(br,vrt),e(br,Pm),e(Pm,Frt),e(Pm,_ne),e(_ne,Trt),e(Pm,Mrt),e(Pm,bne),e(bne,Ert),e(Pm,Crt),e(br,wrt),e(br,WR),e(WR,Art),e(WR,g9e),e(g9e,Lrt),e(WR,yrt),e(br,xrt),e(br,aa),M(UR,aa,null),e(aa,$rt),e(aa,h9e),e(h9e,krt),e(aa,Srt),e(aa,Bm),e(Bm,Rrt),e(Bm,u9e),e(u9e,Prt),e(Bm,Brt),e(Bm,vne),e(vne,Irt),e(Bm,Nrt),e(aa,qrt),M(HA,aa,null),e(br,jrt),e(br,Ur),M(HR,Ur,null),e(Ur,Drt),e(Ur,p9e),e(p9e,Grt),e(Ur,Ort),e(Ur,Vn),e(Vn,Vrt),e(Vn,_9e),e(_9e,Xrt),e(Vn,zrt),e(Vn,b9e),e(b9e,Qrt),e(Vn,Wrt),e(Vn,v9e),e(v9e,Urt),e(Vn,Hrt),e(Ur,Jrt),e(Ur,ve),e(ve,JA),e(JA,F9e),e(F9e,Yrt),e(JA,Zrt),e(JA,Fne),e(Fne,Krt),e(JA,ett),e(ve,ott),e(ve,YA),e(YA,T9e),e(T9e,rtt),e(YA,ttt),e(YA,Tne),e(Tne,att),e(YA,ntt),e(ve,stt),e(ve,ZA),e(ZA,M9e),e(M9e,ltt),e(ZA,itt),e(ZA,Mne),e(Mne,dtt),e(ZA,ctt),e(ve,mtt),e(ve,KA),e(KA,E9e),e(E9e,ftt),e(KA,gtt),e(KA,Ene),e(Ene,htt),e(KA,utt),e(ve,ptt),e(ve,e6),e(e6,C9e),e(C9e,_tt),e(e6,btt),e(e6,Cne),e(Cne,vtt),e(e6,Ftt),e(ve,Ttt),e(ve,o6),e(o6,w9e),e(w9e,Mtt),e(o6,Ett),e(o6,wne),e(wne,Ctt),e(o6,wtt),e(ve,Att),e(ve,r6),e(r6,A9e),e(A9e,Ltt),e(r6,ytt),e(r6,Ane),e(Ane,xtt),e(r6,$tt),e(ve,ktt),e(ve,t6),e(t6,L9e),e(L9e,Stt),e(t6,Rtt),e(t6,Lne),e(Lne,Ptt),e(t6,Btt),e(ve,Itt),e(ve,a6),e(a6,y9e),e(y9e,Ntt),e(a6,qtt),e(a6,yne),e(yne,jtt),e(a6,Dtt),e(ve,Gtt),e(ve,n6),e(n6,x9e),e(x9e,Ott),e(n6,Vtt),e(n6,xne),e(xne,Xtt),e(n6,ztt),e(ve,Qtt),e(ve,s6),e(s6,$9e),e($9e,Wtt),e(s6,Utt),e(s6,$ne),e($ne,Htt),e(s6,Jtt),e(ve,Ytt),e(ve,l6),e(l6,k9e),e(k9e,Ztt),e(l6,Ktt),e(l6,kne),e(kne,eat),e(l6,oat),e(ve,rat),e(ve,i6),e(i6,S9e),e(S9e,tat),e(i6,aat),e(i6,Sne),e(Sne,nat),e(i6,sat),e(ve,lat),e(ve,d6),e(d6,R9e),e(R9e,iat),e(d6,dat),e(d6,Rne),e(Rne,cat),e(d6,mat),e(ve,fat),e(ve,c6),e(c6,P9e),e(P9e,gat),e(c6,hat),e(c6,Pne),e(Pne,uat),e(c6,pat),e(ve,_at),e(ve,m6),e(m6,B9e),e(B9e,bat),e(m6,vat),e(m6,Bne),e(Bne,Fat),e(m6,Tat),e(ve,Mat),e(ve,f6),e(f6,I9e),e(I9e,Eat),e(f6,Cat),e(f6,Ine),e(Ine,wat),e(f6,Aat),e(Ur,Lat),M(g6,Ur,null),b(m,Tao,_),b(m,Im,_),e(Im,h6),e(h6,N9e),M(JR,N9e,null),e(Im,yat),e(Im,q9e),e(q9e,xat),b(m,Mao,_),b(m,vr,_),M(YR,vr,null),e(vr,$at),e(vr,Nm),e(Nm,kat),e(Nm,Nne),e(Nne,Sat),e(Nm,Rat),e(Nm,qne),e(qne,Pat),e(Nm,Bat),e(vr,Iat),e(vr,ZR),e(ZR,Nat),e(ZR,j9e),e(j9e,qat),e(ZR,jat),e(vr,Dat),e(vr,na),M(KR,na,null),e(na,Gat),e(na,D9e),e(D9e,Oat),e(na,Vat),e(na,qm),e(qm,Xat),e(qm,G9e),e(G9e,zat),e(qm,Qat),e(qm,jne),e(jne,Wat),e(qm,Uat),e(na,Hat),M(u6,na,null),e(vr,Jat),e(vr,Hr),M(eP,Hr,null),e(Hr,Yat),e(Hr,O9e),e(O9e,Zat),e(Hr,Kat),e(Hr,Xn),e(Xn,ent),e(Xn,V9e),e(V9e,ont),e(Xn,rnt),e(Xn,X9e),e(X9e,tnt),e(Xn,ant),e(Xn,z9e),e(z9e,nnt),e(Xn,snt),e(Hr,lnt),e(Hr,oP),e(oP,p6),e(p6,Q9e),e(Q9e,int),e(p6,dnt),e(p6,Dne),e(Dne,cnt),e(p6,mnt),e(oP,fnt),e(oP,_6),e(_6,W9e),e(W9e,gnt),e(_6,hnt),e(_6,Gne),e(Gne,unt),e(_6,pnt),e(Hr,_nt),M(b6,Hr,null),b(m,Eao,_),b(m,jm,_),e(jm,v6),e(v6,U9e),M(rP,U9e,null),e(jm,bnt),e(jm,H9e),e(H9e,vnt),b(m,Cao,_),b(m,Fr,_),M(tP,Fr,null),e(Fr,Fnt),e(Fr,Dm),e(Dm,Tnt),e(Dm,One),e(One,Mnt),e(Dm,Ent),e(Dm,Vne),e(Vne,Cnt),e(Dm,wnt),e(Fr,Ant),e(Fr,aP),e(aP,Lnt),e(aP,J9e),e(J9e,ynt),e(aP,xnt),e(Fr,$nt),e(Fr,sa),M(nP,sa,null),e(sa,knt),e(sa,Y9e),e(Y9e,Snt),e(sa,Rnt),e(sa,Gm),e(Gm,Pnt),e(Gm,Z9e),e(Z9e,Bnt),e(Gm,Int),e(Gm,Xne),e(Xne,Nnt),e(Gm,qnt),e(sa,jnt),M(F6,sa,null),e(Fr,Dnt),e(Fr,Jr),M(sP,Jr,null),e(Jr,Gnt),e(Jr,K9e),e(K9e,Ont),e(Jr,Vnt),e(Jr,zn),e(zn,Xnt),e(zn,exe),e(exe,znt),e(zn,Qnt),e(zn,oxe),e(oxe,Wnt),e(zn,Unt),e(zn,rxe),e(rxe,Hnt),e(zn,Jnt),e(Jr,Ynt),e(Jr,txe),e(txe,T6),e(T6,axe),e(axe,Znt),e(T6,Knt),e(T6,zne),e(zne,est),e(T6,ost),e(Jr,rst),M(M6,Jr,null),b(m,wao,_),b(m,Om,_),e(Om,E6),e(E6,nxe),M(lP,nxe,null),e(Om,tst),e(Om,sxe),e(sxe,ast),b(m,Aao,_),b(m,Tr,_),M(iP,Tr,null),e(Tr,nst),e(Tr,Vm),e(Vm,sst),e(Vm,Qne),e(Qne,lst),e(Vm,ist),e(Vm,Wne),e(Wne,dst),e(Vm,cst),e(Tr,mst),e(Tr,dP),e(dP,fst),e(dP,lxe),e(lxe,gst),e(dP,hst),e(Tr,ust),e(Tr,la),M(cP,la,null),e(la,pst),e(la,ixe),e(ixe,_st),e(la,bst),e(la,Xm),e(Xm,vst),e(Xm,dxe),e(dxe,Fst),e(Xm,Tst),e(Xm,Une),e(Une,Mst),e(Xm,Est),e(la,Cst),M(C6,la,null),e(Tr,wst),e(Tr,Yr),M(mP,Yr,null),e(Yr,Ast),e(Yr,cxe),e(cxe,Lst),e(Yr,yst),e(Yr,Qn),e(Qn,xst),e(Qn,mxe),e(mxe,$st),e(Qn,kst),e(Qn,fxe),e(fxe,Sst),e(Qn,Rst),e(Qn,gxe),e(gxe,Pst),e(Qn,Bst),e(Yr,Ist),e(Yr,hxe),e(hxe,w6),e(w6,uxe),e(uxe,Nst),e(w6,qst),e(w6,Hne),e(Hne,jst),e(w6,Dst),e(Yr,Gst),M(A6,Yr,null),b(m,Lao,_),b(m,zm,_),e(zm,L6),e(L6,pxe),M(fP,pxe,null),e(zm,Ost),e(zm,_xe),e(_xe,Vst),b(m,yao,_),b(m,Mr,_),M(gP,Mr,null),e(Mr,Xst),e(Mr,Qm),e(Qm,zst),e(Qm,Jne),e(Jne,Qst),e(Qm,Wst),e(Qm,Yne),e(Yne,Ust),e(Qm,Hst),e(Mr,Jst),e(Mr,hP),e(hP,Yst),e(hP,bxe),e(bxe,Zst),e(hP,Kst),e(Mr,elt),e(Mr,ia),M(uP,ia,null),e(ia,olt),e(ia,vxe),e(vxe,rlt),e(ia,tlt),e(ia,Wm),e(Wm,alt),e(Wm,Fxe),e(Fxe,nlt),e(Wm,slt),e(Wm,Zne),e(Zne,llt),e(Wm,ilt),e(ia,dlt),M(y6,ia,null),e(Mr,clt),e(Mr,Zr),M(pP,Zr,null),e(Zr,mlt),e(Zr,Txe),e(Txe,flt),e(Zr,glt),e(Zr,Wn),e(Wn,hlt),e(Wn,Mxe),e(Mxe,ult),e(Wn,plt),e(Wn,Exe),e(Exe,_lt),e(Wn,blt),e(Wn,Cxe),e(Cxe,vlt),e(Wn,Flt),e(Zr,Tlt),e(Zr,ce),e(ce,x6),e(x6,wxe),e(wxe,Mlt),e(x6,Elt),e(x6,Kne),e(Kne,Clt),e(x6,wlt),e(ce,Alt),e(ce,$6),e($6,Axe),e(Axe,Llt),e($6,ylt),e($6,ese),e(ese,xlt),e($6,$lt),e(ce,klt),e(ce,k6),e(k6,Lxe),e(Lxe,Slt),e(k6,Rlt),e(k6,ose),e(ose,Plt),e(k6,Blt),e(ce,Ilt),e(ce,S6),e(S6,yxe),e(yxe,Nlt),e(S6,qlt),e(S6,rse),e(rse,jlt),e(S6,Dlt),e(ce,Glt),e(ce,R6),e(R6,xxe),e(xxe,Olt),e(R6,Vlt),e(R6,tse),e(tse,Xlt),e(R6,zlt),e(ce,Qlt),e(ce,P6),e(P6,$xe),e($xe,Wlt),e(P6,Ult),e(P6,ase),e(ase,Hlt),e(P6,Jlt),e(ce,Ylt),e(ce,B6),e(B6,kxe),e(kxe,Zlt),e(B6,Klt),e(B6,nse),e(nse,eit),e(B6,oit),e(ce,rit),e(ce,I6),e(I6,Sxe),e(Sxe,tit),e(I6,ait),e(I6,sse),e(sse,nit),e(I6,sit),e(ce,lit),e(ce,N6),e(N6,Rxe),e(Rxe,iit),e(N6,dit),e(N6,lse),e(lse,cit),e(N6,mit),e(ce,fit),e(ce,q6),e(q6,Pxe),e(Pxe,git),e(q6,hit),e(q6,ise),e(ise,uit),e(q6,pit),e(ce,_it),e(ce,j6),e(j6,Bxe),e(Bxe,bit),e(j6,vit),e(j6,dse),e(dse,Fit),e(j6,Tit),e(ce,Mit),e(ce,D6),e(D6,Ixe),e(Ixe,Eit),e(D6,Cit),e(D6,cse),e(cse,wit),e(D6,Ait),e(ce,Lit),e(ce,G6),e(G6,Nxe),e(Nxe,yit),e(G6,xit),e(G6,mse),e(mse,$it),e(G6,kit),e(ce,Sit),e(ce,O6),e(O6,qxe),e(qxe,Rit),e(O6,Pit),e(O6,fse),e(fse,Bit),e(O6,Iit),e(ce,Nit),e(ce,V6),e(V6,jxe),e(jxe,qit),e(V6,jit),e(V6,gse),e(gse,Dit),e(V6,Git),e(ce,Oit),e(ce,X6),e(X6,Dxe),e(Dxe,Vit),e(X6,Xit),e(X6,hse),e(hse,zit),e(X6,Qit),e(ce,Wit),e(ce,z6),e(z6,Gxe),e(Gxe,Uit),e(z6,Hit),e(z6,use),e(use,Jit),e(z6,Yit),e(ce,Zit),e(ce,Q6),e(Q6,Oxe),e(Oxe,Kit),e(Q6,edt),e(Q6,pse),e(pse,odt),e(Q6,rdt),e(ce,tdt),e(ce,W6),e(W6,Vxe),e(Vxe,adt),e(W6,ndt),e(W6,_se),e(_se,sdt),e(W6,ldt),e(ce,idt),e(ce,U6),e(U6,Xxe),e(Xxe,ddt),e(U6,cdt),e(U6,bse),e(bse,mdt),e(U6,fdt),e(ce,gdt),e(ce,H6),e(H6,zxe),e(zxe,hdt),e(H6,udt),e(H6,vse),e(vse,pdt),e(H6,_dt),e(Zr,bdt),M(J6,Zr,null),b(m,xao,_),b(m,Um,_),e(Um,Y6),e(Y6,Qxe),M(_P,Qxe,null),e(Um,vdt),e(Um,Wxe),e(Wxe,Fdt),b(m,$ao,_),b(m,Er,_),M(bP,Er,null),e(Er,Tdt),e(Er,Hm),e(Hm,Mdt),e(Hm,Fse),e(Fse,Edt),e(Hm,Cdt),e(Hm,Tse),e(Tse,wdt),e(Hm,Adt),e(Er,Ldt),e(Er,vP),e(vP,ydt),e(vP,Uxe),e(Uxe,xdt),e(vP,$dt),e(Er,kdt),e(Er,da),M(FP,da,null),e(da,Sdt),e(da,Hxe),e(Hxe,Rdt),e(da,Pdt),e(da,Jm),e(Jm,Bdt),e(Jm,Jxe),e(Jxe,Idt),e(Jm,Ndt),e(Jm,Mse),e(Mse,qdt),e(Jm,jdt),e(da,Ddt),M(Z6,da,null),e(Er,Gdt),e(Er,Kr),M(TP,Kr,null),e(Kr,Odt),e(Kr,Yxe),e(Yxe,Vdt),e(Kr,Xdt),e(Kr,Un),e(Un,zdt),e(Un,Zxe),e(Zxe,Qdt),e(Un,Wdt),e(Un,Kxe),e(Kxe,Udt),e(Un,Hdt),e(Un,e$e),e(e$e,Jdt),e(Un,Ydt),e(Kr,Zdt),e(Kr,me),e(me,K6),e(K6,o$e),e(o$e,Kdt),e(K6,ect),e(K6,Ese),e(Ese,oct),e(K6,rct),e(me,tct),e(me,e7),e(e7,r$e),e(r$e,act),e(e7,nct),e(e7,Cse),e(Cse,sct),e(e7,lct),e(me,ict),e(me,o7),e(o7,t$e),e(t$e,dct),e(o7,cct),e(o7,wse),e(wse,mct),e(o7,fct),e(me,gct),e(me,r7),e(r7,a$e),e(a$e,hct),e(r7,uct),e(r7,Ase),e(Ase,pct),e(r7,_ct),e(me,bct),e(me,t7),e(t7,n$e),e(n$e,vct),e(t7,Fct),e(t7,Lse),e(Lse,Tct),e(t7,Mct),e(me,Ect),e(me,a7),e(a7,s$e),e(s$e,Cct),e(a7,wct),e(a7,yse),e(yse,Act),e(a7,Lct),e(me,yct),e(me,n7),e(n7,l$e),e(l$e,xct),e(n7,$ct),e(n7,xse),e(xse,kct),e(n7,Sct),e(me,Rct),e(me,s7),e(s7,i$e),e(i$e,Pct),e(s7,Bct),e(s7,$se),e($se,Ict),e(s7,Nct),e(me,qct),e(me,l7),e(l7,d$e),e(d$e,jct),e(l7,Dct),e(l7,kse),e(kse,Gct),e(l7,Oct),e(me,Vct),e(me,i7),e(i7,c$e),e(c$e,Xct),e(i7,zct),e(i7,Sse),e(Sse,Qct),e(i7,Wct),e(me,Uct),e(me,d7),e(d7,m$e),e(m$e,Hct),e(d7,Jct),e(d7,Rse),e(Rse,Yct),e(d7,Zct),e(me,Kct),e(me,c7),e(c7,f$e),e(f$e,emt),e(c7,omt),e(c7,Pse),e(Pse,rmt),e(c7,tmt),e(me,amt),e(me,m7),e(m7,g$e),e(g$e,nmt),e(m7,smt),e(m7,Bse),e(Bse,lmt),e(m7,imt),e(me,dmt),e(me,f7),e(f7,h$e),e(h$e,cmt),e(f7,mmt),e(f7,Ise),e(Ise,fmt),e(f7,gmt),e(me,hmt),e(me,g7),e(g7,u$e),e(u$e,umt),e(g7,pmt),e(g7,Nse),e(Nse,_mt),e(g7,bmt),e(me,vmt),e(me,h7),e(h7,p$e),e(p$e,Fmt),e(h7,Tmt),e(h7,qse),e(qse,Mmt),e(h7,Emt),e(me,Cmt),e(me,u7),e(u7,_$e),e(_$e,wmt),e(u7,Amt),e(u7,jse),e(jse,Lmt),e(u7,ymt),e(me,xmt),e(me,p7),e(p7,b$e),e(b$e,$mt),e(p7,kmt),e(p7,Dse),e(Dse,Smt),e(p7,Rmt),e(me,Pmt),e(me,_7),e(_7,v$e),e(v$e,Bmt),e(_7,Imt),e(_7,Gse),e(Gse,Nmt),e(_7,qmt),e(me,jmt),e(me,b7),e(b7,F$e),e(F$e,Dmt),e(b7,Gmt),e(b7,Ose),e(Ose,Omt),e(b7,Vmt),e(me,Xmt),e(me,v7),e(v7,T$e),e(T$e,zmt),e(v7,Qmt),e(v7,Vse),e(Vse,Wmt),e(v7,Umt),e(Kr,Hmt),M(F7,Kr,null),b(m,kao,_),b(m,Ym,_),e(Ym,T7),e(T7,M$e),M(MP,M$e,null),e(Ym,Jmt),e(Ym,E$e),e(E$e,Ymt),b(m,Sao,_),b(m,Cr,_),M(EP,Cr,null),e(Cr,Zmt),e(Cr,Zm),e(Zm,Kmt),e(Zm,Xse),e(Xse,eft),e(Zm,oft),e(Zm,zse),e(zse,rft),e(Zm,tft),e(Cr,aft),e(Cr,CP),e(CP,nft),e(CP,C$e),e(C$e,sft),e(CP,lft),e(Cr,ift),e(Cr,ca),M(wP,ca,null),e(ca,dft),e(ca,w$e),e(w$e,cft),e(ca,mft),e(ca,Km),e(Km,fft),e(Km,A$e),e(A$e,gft),e(Km,hft),e(Km,Qse),e(Qse,uft),e(Km,pft),e(ca,_ft),M(M7,ca,null),e(Cr,bft),e(Cr,et),M(AP,et,null),e(et,vft),e(et,L$e),e(L$e,Fft),e(et,Tft),e(et,Hn),e(Hn,Mft),e(Hn,y$e),e(y$e,Eft),e(Hn,Cft),e(Hn,x$e),e(x$e,wft),e(Hn,Aft),e(Hn,$$e),e($$e,Lft),e(Hn,yft),e(et,xft),e(et,k$e),e(k$e,E7),e(E7,S$e),e(S$e,$ft),e(E7,kft),e(E7,Wse),e(Wse,Sft),e(E7,Rft),e(et,Pft),M(C7,et,null),b(m,Rao,_),b(m,ef,_),e(ef,w7),e(w7,R$e),M(LP,R$e,null),e(ef,Bft),e(ef,P$e),e(P$e,Ift),b(m,Pao,_),b(m,wr,_),M(yP,wr,null),e(wr,Nft),e(wr,of),e(of,qft),e(of,Use),e(Use,jft),e(of,Dft),e(of,Hse),e(Hse,Gft),e(of,Oft),e(wr,Vft),e(wr,xP),e(xP,Xft),e(xP,B$e),e(B$e,zft),e(xP,Qft),e(wr,Wft),e(wr,ma),M($P,ma,null),e(ma,Uft),e(ma,I$e),e(I$e,Hft),e(ma,Jft),e(ma,rf),e(rf,Yft),e(rf,N$e),e(N$e,Zft),e(rf,Kft),e(rf,Jse),e(Jse,egt),e(rf,ogt),e(ma,rgt),M(A7,ma,null),e(wr,tgt),e(wr,ot),M(kP,ot,null),e(ot,agt),e(ot,q$e),e(q$e,ngt),e(ot,sgt),e(ot,Jn),e(Jn,lgt),e(Jn,j$e),e(j$e,igt),e(Jn,dgt),e(Jn,D$e),e(D$e,cgt),e(Jn,mgt),e(Jn,G$e),e(G$e,fgt),e(Jn,ggt),e(ot,hgt),e(ot,SP),e(SP,L7),e(L7,O$e),e(O$e,ugt),e(L7,pgt),e(L7,Yse),e(Yse,_gt),e(L7,bgt),e(SP,vgt),e(SP,y7),e(y7,V$e),e(V$e,Fgt),e(y7,Tgt),e(y7,Zse),e(Zse,Mgt),e(y7,Egt),e(ot,Cgt),M(x7,ot,null),b(m,Bao,_),b(m,tf,_),e(tf,$7),e($7,X$e),M(RP,X$e,null),e(tf,wgt),e(tf,z$e),e(z$e,Agt),b(m,Iao,_),b(m,Ar,_),M(PP,Ar,null),e(Ar,Lgt),e(Ar,af),e(af,ygt),e(af,Kse),e(Kse,xgt),e(af,$gt),e(af,ele),e(ele,kgt),e(af,Sgt),e(Ar,Rgt),e(Ar,BP),e(BP,Pgt),e(BP,Q$e),e(Q$e,Bgt),e(BP,Igt),e(Ar,Ngt),e(Ar,fa),M(IP,fa,null),e(fa,qgt),e(fa,W$e),e(W$e,jgt),e(fa,Dgt),e(fa,nf),e(nf,Ggt),e(nf,U$e),e(U$e,Ogt),e(nf,Vgt),e(nf,ole),e(ole,Xgt),e(nf,zgt),e(fa,Qgt),M(k7,fa,null),e(Ar,Wgt),e(Ar,rt),M(NP,rt,null),e(rt,Ugt),e(rt,H$e),e(H$e,Hgt),e(rt,Jgt),e(rt,Yn),e(Yn,Ygt),e(Yn,J$e),e(J$e,Zgt),e(Yn,Kgt),e(Yn,Y$e),e(Y$e,eht),e(Yn,oht),e(Yn,Z$e),e(Z$e,rht),e(Yn,tht),e(rt,aht),e(rt,te),e(te,S7),e(S7,K$e),e(K$e,nht),e(S7,sht),e(S7,rle),e(rle,lht),e(S7,iht),e(te,dht),e(te,R7),e(R7,eke),e(eke,cht),e(R7,mht),e(R7,tle),e(tle,fht),e(R7,ght),e(te,hht),e(te,P7),e(P7,oke),e(oke,uht),e(P7,pht),e(P7,ale),e(ale,_ht),e(P7,bht),e(te,vht),e(te,B7),e(B7,rke),e(rke,Fht),e(B7,Tht),e(B7,nle),e(nle,Mht),e(B7,Eht),e(te,Cht),e(te,I7),e(I7,tke),e(tke,wht),e(I7,Aht),e(I7,sle),e(sle,Lht),e(I7,yht),e(te,xht),e(te,N7),e(N7,ake),e(ake,$ht),e(N7,kht),e(N7,lle),e(lle,Sht),e(N7,Rht),e(te,Pht),e(te,q7),e(q7,nke),e(nke,Bht),e(q7,Iht),e(q7,ile),e(ile,Nht),e(q7,qht),e(te,jht),e(te,j7),e(j7,ske),e(ske,Dht),e(j7,Ght),e(j7,dle),e(dle,Oht),e(j7,Vht),e(te,Xht),e(te,D7),e(D7,lke),e(lke,zht),e(D7,Qht),e(D7,cle),e(cle,Wht),e(D7,Uht),e(te,Hht),e(te,G7),e(G7,ike),e(ike,Jht),e(G7,Yht),e(G7,mle),e(mle,Zht),e(G7,Kht),e(te,eut),e(te,O7),e(O7,dke),e(dke,out),e(O7,rut),e(O7,fle),e(fle,tut),e(O7,aut),e(te,nut),e(te,V7),e(V7,cke),e(cke,sut),e(V7,lut),e(V7,gle),e(gle,iut),e(V7,dut),e(te,cut),e(te,X7),e(X7,mke),e(mke,mut),e(X7,fut),e(X7,hle),e(hle,gut),e(X7,hut),e(te,uut),e(te,z7),e(z7,fke),e(fke,put),e(z7,_ut),e(z7,ule),e(ule,but),e(z7,vut),e(te,Fut),e(te,Q7),e(Q7,gke),e(gke,Tut),e(Q7,Mut),e(Q7,ple),e(ple,Eut),e(Q7,Cut),e(te,wut),e(te,W7),e(W7,hke),e(hke,Aut),e(W7,Lut),e(W7,_le),e(_le,yut),e(W7,xut),e(te,$ut),e(te,U7),e(U7,uke),e(uke,kut),e(U7,Sut),e(U7,ble),e(ble,Rut),e(U7,Put),e(te,But),e(te,H7),e(H7,pke),e(pke,Iut),e(H7,Nut),e(H7,vle),e(vle,qut),e(H7,jut),e(te,Dut),e(te,J7),e(J7,_ke),e(_ke,Gut),e(J7,Out),e(J7,Fle),e(Fle,Vut),e(J7,Xut),e(te,zut),e(te,Y7),e(Y7,bke),e(bke,Qut),e(Y7,Wut),e(Y7,Tle),e(Tle,Uut),e(Y7,Hut),e(te,Jut),e(te,Z7),e(Z7,vke),e(vke,Yut),e(Z7,Zut),e(Z7,Mle),e(Mle,Kut),e(Z7,ept),e(te,opt),e(te,K7),e(K7,Fke),e(Fke,rpt),e(K7,tpt),e(K7,Ele),e(Ele,apt),e(K7,npt),e(te,spt),e(te,eL),e(eL,Tke),e(Tke,lpt),e(eL,ipt),e(eL,Cle),e(Cle,dpt),e(eL,cpt),e(te,mpt),e(te,oL),e(oL,Mke),e(Mke,fpt),e(oL,gpt),e(oL,wle),e(wle,hpt),e(oL,upt),e(te,ppt),e(te,rL),e(rL,Eke),e(Eke,_pt),e(rL,bpt),e(rL,Ale),e(Ale,vpt),e(rL,Fpt),e(te,Tpt),e(te,tL),e(tL,Cke),e(Cke,Mpt),e(tL,Ept),e(tL,Lle),e(Lle,Cpt),e(tL,wpt),e(te,Apt),e(te,aL),e(aL,wke),e(wke,Lpt),e(aL,ypt),e(aL,yle),e(yle,xpt),e(aL,$pt),e(rt,kpt),M(nL,rt,null),b(m,Nao,_),b(m,sf,_),e(sf,sL),e(sL,Ake),M(qP,Ake,null),e(sf,Spt),e(sf,Lke),e(Lke,Rpt),b(m,qao,_),b(m,Lr,_),M(jP,Lr,null),e(Lr,Ppt),e(Lr,lf),e(lf,Bpt),e(lf,xle),e(xle,Ipt),e(lf,Npt),e(lf,$le),e($le,qpt),e(lf,jpt),e(Lr,Dpt),e(Lr,DP),e(DP,Gpt),e(DP,yke),e(yke,Opt),e(DP,Vpt),e(Lr,Xpt),e(Lr,ga),M(GP,ga,null),e(ga,zpt),e(ga,xke),e(xke,Qpt),e(ga,Wpt),e(ga,df),e(df,Upt),e(df,$ke),e($ke,Hpt),e(df,Jpt),e(df,kle),e(kle,Ypt),e(df,Zpt),e(ga,Kpt),M(lL,ga,null),e(Lr,e_t),e(Lr,tt),M(OP,tt,null),e(tt,o_t),e(tt,kke),e(kke,r_t),e(tt,t_t),e(tt,Zn),e(Zn,a_t),e(Zn,Ske),e(Ske,n_t),e(Zn,s_t),e(Zn,Rke),e(Rke,l_t),e(Zn,i_t),e(Zn,Pke),e(Pke,d_t),e(Zn,c_t),e(tt,m_t),e(tt,$e),e($e,iL),e(iL,Bke),e(Bke,f_t),e(iL,g_t),e(iL,Sle),e(Sle,h_t),e(iL,u_t),e($e,p_t),e($e,dL),e(dL,Ike),e(Ike,__t),e(dL,b_t),e(dL,Rle),e(Rle,v_t),e(dL,F_t),e($e,T_t),e($e,cL),e(cL,Nke),e(Nke,M_t),e(cL,E_t),e(cL,Ple),e(Ple,C_t),e(cL,w_t),e($e,A_t),e($e,mL),e(mL,qke),e(qke,L_t),e(mL,y_t),e(mL,Ble),e(Ble,x_t),e(mL,$_t),e($e,k_t),e($e,fL),e(fL,jke),e(jke,S_t),e(fL,R_t),e(fL,Ile),e(Ile,P_t),e(fL,B_t),e($e,I_t),e($e,gL),e(gL,Dke),e(Dke,N_t),e(gL,q_t),e(gL,Nle),e(Nle,j_t),e(gL,D_t),e($e,G_t),e($e,hL),e(hL,Gke),e(Gke,O_t),e(hL,V_t),e(hL,qle),e(qle,X_t),e(hL,z_t),e($e,Q_t),e($e,uL),e(uL,Oke),e(Oke,W_t),e(uL,U_t),e(uL,jle),e(jle,H_t),e(uL,J_t),e($e,Y_t),e($e,pL),e(pL,Vke),e(Vke,Z_t),e(pL,K_t),e(pL,Dle),e(Dle,e1t),e(pL,o1t),e($e,r1t),e($e,_L),e(_L,Xke),e(Xke,t1t),e(_L,a1t),e(_L,Gle),e(Gle,n1t),e(_L,s1t),e(tt,l1t),M(bL,tt,null),b(m,jao,_),b(m,cf,_),e(cf,vL),e(vL,zke),M(VP,zke,null),e(cf,i1t),e(cf,Qke),e(Qke,d1t),b(m,Dao,_),b(m,yr,_),M(XP,yr,null),e(yr,c1t),e(yr,mf),e(mf,m1t),e(mf,Ole),e(Ole,f1t),e(mf,g1t),e(mf,Vle),e(Vle,h1t),e(mf,u1t),e(yr,p1t),e(yr,zP),e(zP,_1t),e(zP,Wke),e(Wke,b1t),e(zP,v1t),e(yr,F1t),e(yr,ha),M(QP,ha,null),e(ha,T1t),e(ha,Uke),e(Uke,M1t),e(ha,E1t),e(ha,ff),e(ff,C1t),e(ff,Hke),e(Hke,w1t),e(ff,A1t),e(ff,Xle),e(Xle,L1t),e(ff,y1t),e(ha,x1t),M(FL,ha,null),e(yr,$1t),e(yr,at),M(WP,at,null),e(at,k1t),e(at,Jke),e(Jke,S1t),e(at,R1t),e(at,Kn),e(Kn,P1t),e(Kn,Yke),e(Yke,B1t),e(Kn,I1t),e(Kn,Zke),e(Zke,N1t),e(Kn,q1t),e(Kn,Kke),e(Kke,j1t),e(Kn,D1t),e(at,G1t),e(at,Ee),e(Ee,TL),e(TL,eSe),e(eSe,O1t),e(TL,V1t),e(TL,zle),e(zle,X1t),e(TL,z1t),e(Ee,Q1t),e(Ee,ML),e(ML,oSe),e(oSe,W1t),e(ML,U1t),e(ML,Qle),e(Qle,H1t),e(ML,J1t),e(Ee,Y1t),e(Ee,EL),e(EL,rSe),e(rSe,Z1t),e(EL,K1t),e(EL,Wle),e(Wle,e2t),e(EL,o2t),e(Ee,r2t),e(Ee,CL),e(CL,tSe),e(tSe,t2t),e(CL,a2t),e(CL,Ule),e(Ule,n2t),e(CL,s2t),e(Ee,l2t),e(Ee,wL),e(wL,aSe),e(aSe,i2t),e(wL,d2t),e(wL,Hle),e(Hle,c2t),e(wL,m2t),e(Ee,f2t),e(Ee,AL),e(AL,nSe),e(nSe,g2t),e(AL,h2t),e(AL,Jle),e(Jle,u2t),e(AL,p2t),e(Ee,_2t),e(Ee,LL),e(LL,sSe),e(sSe,b2t),e(LL,v2t),e(LL,Yle),e(Yle,F2t),e(LL,T2t),e(Ee,M2t),e(Ee,yL),e(yL,lSe),e(lSe,E2t),e(yL,C2t),e(yL,Zle),e(Zle,w2t),e(yL,A2t),e(Ee,L2t),e(Ee,xL),e(xL,iSe),e(iSe,y2t),e(xL,x2t),e(xL,Kle),e(Kle,$2t),e(xL,k2t),e(Ee,S2t),e(Ee,$L),e($L,dSe),e(dSe,R2t),e($L,P2t),e($L,eie),e(eie,B2t),e($L,I2t),e(Ee,N2t),e(Ee,kL),e(kL,cSe),e(cSe,q2t),e(kL,j2t),e(kL,oie),e(oie,D2t),e(kL,G2t),e(Ee,O2t),e(Ee,SL),e(SL,mSe),e(mSe,V2t),e(SL,X2t),e(SL,rie),e(rie,z2t),e(SL,Q2t),e(Ee,W2t),e(Ee,RL),e(RL,fSe),e(fSe,U2t),e(RL,H2t),e(RL,tie),e(tie,J2t),e(RL,Y2t),e(at,Z2t),M(PL,at,null),b(m,Gao,_),b(m,gf,_),e(gf,BL),e(BL,gSe),M(UP,gSe,null),e(gf,K2t),e(gf,hSe),e(hSe,ebt),b(m,Oao,_),b(m,xr,_),M(HP,xr,null),e(xr,obt),e(xr,hf),e(hf,rbt),e(hf,aie),e(aie,tbt),e(hf,abt),e(hf,nie),e(nie,nbt),e(hf,sbt),e(xr,lbt),e(xr,JP),e(JP,ibt),e(JP,uSe),e(uSe,dbt),e(JP,cbt),e(xr,mbt),e(xr,ua),M(YP,ua,null),e(ua,fbt),e(ua,pSe),e(pSe,gbt),e(ua,hbt),e(ua,uf),e(uf,ubt),e(uf,_Se),e(_Se,pbt),e(uf,_bt),e(uf,sie),e(sie,bbt),e(uf,vbt),e(ua,Fbt),M(IL,ua,null),e(xr,Tbt),e(xr,nt),M(ZP,nt,null),e(nt,Mbt),e(nt,bSe),e(bSe,Ebt),e(nt,Cbt),e(nt,es),e(es,wbt),e(es,vSe),e(vSe,Abt),e(es,Lbt),e(es,FSe),e(FSe,ybt),e(es,xbt),e(es,TSe),e(TSe,$bt),e(es,kbt),e(nt,Sbt),e(nt,ke),e(ke,NL),e(NL,MSe),e(MSe,Rbt),e(NL,Pbt),e(NL,lie),e(lie,Bbt),e(NL,Ibt),e(ke,Nbt),e(ke,qL),e(qL,ESe),e(ESe,qbt),e(qL,jbt),e(qL,iie),e(iie,Dbt),e(qL,Gbt),e(ke,Obt),e(ke,jL),e(jL,CSe),e(CSe,Vbt),e(jL,Xbt),e(jL,die),e(die,zbt),e(jL,Qbt),e(ke,Wbt),e(ke,DL),e(DL,wSe),e(wSe,Ubt),e(DL,Hbt),e(DL,cie),e(cie,Jbt),e(DL,Ybt),e(ke,Zbt),e(ke,GL),e(GL,ASe),e(ASe,Kbt),e(GL,evt),e(GL,mie),e(mie,ovt),e(GL,rvt),e(ke,tvt),e(ke,OL),e(OL,LSe),e(LSe,avt),e(OL,nvt),e(OL,fie),e(fie,svt),e(OL,lvt),e(ke,ivt),e(ke,VL),e(VL,ySe),e(ySe,dvt),e(VL,cvt),e(VL,gie),e(gie,mvt),e(VL,fvt),e(ke,gvt),e(ke,XL),e(XL,xSe),e(xSe,hvt),e(XL,uvt),e(XL,hie),e(hie,pvt),e(XL,_vt),e(ke,bvt),e(ke,zL),e(zL,$Se),e($Se,vvt),e(zL,Fvt),e(zL,uie),e(uie,Tvt),e(zL,Mvt),e(ke,Evt),e(ke,QL),e(QL,kSe),e(kSe,Cvt),e(QL,wvt),e(QL,pie),e(pie,Avt),e(QL,Lvt),e(nt,yvt),M(WL,nt,null),b(m,Vao,_),b(m,pf,_),e(pf,UL),e(UL,SSe),M(KP,SSe,null),e(pf,xvt),e(pf,RSe),e(RSe,$vt),b(m,Xao,_),b(m,$r,_),M(eB,$r,null),e($r,kvt),e($r,_f),e(_f,Svt),e(_f,_ie),e(_ie,Rvt),e(_f,Pvt),e(_f,bie),e(bie,Bvt),e(_f,Ivt),e($r,Nvt),e($r,oB),e(oB,qvt),e(oB,PSe),e(PSe,jvt),e(oB,Dvt),e($r,Gvt),e($r,pa),M(rB,pa,null),e(pa,Ovt),e(pa,BSe),e(BSe,Vvt),e(pa,Xvt),e(pa,bf),e(bf,zvt),e(bf,ISe),e(ISe,Qvt),e(bf,Wvt),e(bf,vie),e(vie,Uvt),e(bf,Hvt),e(pa,Jvt),M(HL,pa,null),e($r,Yvt),e($r,st),M(tB,st,null),e(st,Zvt),e(st,NSe),e(NSe,Kvt),e(st,eFt),e(st,os),e(os,oFt),e(os,qSe),e(qSe,rFt),e(os,tFt),e(os,jSe),e(jSe,aFt),e(os,nFt),e(os,DSe),e(DSe,sFt),e(os,lFt),e(st,iFt),e(st,Se),e(Se,JL),e(JL,GSe),e(GSe,dFt),e(JL,cFt),e(JL,Fie),e(Fie,mFt),e(JL,fFt),e(Se,gFt),e(Se,YL),e(YL,OSe),e(OSe,hFt),e(YL,uFt),e(YL,Tie),e(Tie,pFt),e(YL,_Ft),e(Se,bFt),e(Se,ZL),e(ZL,VSe),e(VSe,vFt),e(ZL,FFt),e(ZL,Mie),e(Mie,TFt),e(ZL,MFt),e(Se,EFt),e(Se,KL),e(KL,XSe),e(XSe,CFt),e(KL,wFt),e(KL,Eie),e(Eie,AFt),e(KL,LFt),e(Se,yFt),e(Se,e8),e(e8,zSe),e(zSe,xFt),e(e8,$Ft),e(e8,Cie),e(Cie,kFt),e(e8,SFt),e(Se,RFt),e(Se,o8),e(o8,QSe),e(QSe,PFt),e(o8,BFt),e(o8,wie),e(wie,IFt),e(o8,NFt),e(Se,qFt),e(Se,r8),e(r8,WSe),e(WSe,jFt),e(r8,DFt),e(r8,Aie),e(Aie,GFt),e(r8,OFt),e(Se,VFt),e(Se,t8),e(t8,USe),e(USe,XFt),e(t8,zFt),e(t8,Lie),e(Lie,QFt),e(t8,WFt),e(Se,UFt),e(Se,a8),e(a8,HSe),e(HSe,HFt),e(a8,JFt),e(a8,yie),e(yie,YFt),e(a8,ZFt),e(Se,KFt),e(Se,n8),e(n8,JSe),e(JSe,eTt),e(n8,oTt),e(n8,xie),e(xie,rTt),e(n8,tTt),e(st,aTt),M(s8,st,null),b(m,zao,_),b(m,vf,_),e(vf,l8),e(l8,YSe),M(aB,YSe,null),e(vf,nTt),e(vf,ZSe),e(ZSe,sTt),b(m,Qao,_),b(m,kr,_),M(nB,kr,null),e(kr,lTt),e(kr,Ff),e(Ff,iTt),e(Ff,$ie),e($ie,dTt),e(Ff,cTt),e(Ff,kie),e(kie,mTt),e(Ff,fTt),e(kr,gTt),e(kr,sB),e(sB,hTt),e(sB,KSe),e(KSe,uTt),e(sB,pTt),e(kr,_Tt),e(kr,_a),M(lB,_a,null),e(_a,bTt),e(_a,eRe),e(eRe,vTt),e(_a,FTt),e(_a,Tf),e(Tf,TTt),e(Tf,oRe),e(oRe,MTt),e(Tf,ETt),e(Tf,Sie),e(Sie,CTt),e(Tf,wTt),e(_a,ATt),M(i8,_a,null),e(kr,LTt),e(kr,lt),M(iB,lt,null),e(lt,yTt),e(lt,rRe),e(rRe,xTt),e(lt,$Tt),e(lt,rs),e(rs,kTt),e(rs,tRe),e(tRe,STt),e(rs,RTt),e(rs,aRe),e(aRe,PTt),e(rs,BTt),e(rs,nRe),e(nRe,ITt),e(rs,NTt),e(lt,qTt),e(lt,Re),e(Re,d8),e(d8,sRe),e(sRe,jTt),e(d8,DTt),e(d8,Rie),e(Rie,GTt),e(d8,OTt),e(Re,VTt),e(Re,c8),e(c8,lRe),e(lRe,XTt),e(c8,zTt),e(c8,Pie),e(Pie,QTt),e(c8,WTt),e(Re,UTt),e(Re,m8),e(m8,iRe),e(iRe,HTt),e(m8,JTt),e(m8,Bie),e(Bie,YTt),e(m8,ZTt),e(Re,KTt),e(Re,f8),e(f8,dRe),e(dRe,eMt),e(f8,oMt),e(f8,Iie),e(Iie,rMt),e(f8,tMt),e(Re,aMt),e(Re,g8),e(g8,cRe),e(cRe,nMt),e(g8,sMt),e(g8,Nie),e(Nie,lMt),e(g8,iMt),e(Re,dMt),e(Re,h8),e(h8,mRe),e(mRe,cMt),e(h8,mMt),e(h8,qie),e(qie,fMt),e(h8,gMt),e(Re,hMt),e(Re,u8),e(u8,fRe),e(fRe,uMt),e(u8,pMt),e(u8,jie),e(jie,_Mt),e(u8,bMt),e(Re,vMt),e(Re,p8),e(p8,gRe),e(gRe,FMt),e(p8,TMt),e(p8,Die),e(Die,MMt),e(p8,EMt),e(Re,CMt),e(Re,_8),e(_8,hRe),e(hRe,wMt),e(_8,AMt),e(_8,Gie),e(Gie,LMt),e(_8,yMt),e(Re,xMt),e(Re,b8),e(b8,uRe),e(uRe,$Mt),e(b8,kMt),e(b8,Oie),e(Oie,SMt),e(b8,RMt),e(lt,PMt),M(v8,lt,null),b(m,Wao,_),b(m,Mf,_),e(Mf,F8),e(F8,pRe),M(dB,pRe,null),e(Mf,BMt),e(Mf,_Re),e(_Re,IMt),b(m,Uao,_),b(m,Sr,_),M(cB,Sr,null),e(Sr,NMt),e(Sr,Ef),e(Ef,qMt),e(Ef,Vie),e(Vie,jMt),e(Ef,DMt),e(Ef,Xie),e(Xie,GMt),e(Ef,OMt),e(Sr,VMt),e(Sr,mB),e(mB,XMt),e(mB,bRe),e(bRe,zMt),e(mB,QMt),e(Sr,WMt),e(Sr,ba),M(fB,ba,null),e(ba,UMt),e(ba,vRe),e(vRe,HMt),e(ba,JMt),e(ba,Cf),e(Cf,YMt),e(Cf,FRe),e(FRe,ZMt),e(Cf,KMt),e(Cf,zie),e(zie,eEt),e(Cf,oEt),e(ba,rEt),M(T8,ba,null),e(Sr,tEt),e(Sr,it),M(gB,it,null),e(it,aEt),e(it,TRe),e(TRe,nEt),e(it,sEt),e(it,ts),e(ts,lEt),e(ts,MRe),e(MRe,iEt),e(ts,dEt),e(ts,ERe),e(ERe,cEt),e(ts,mEt),e(ts,CRe),e(CRe,fEt),e(ts,gEt),e(it,hEt),e(it,Pe),e(Pe,M8),e(M8,wRe),e(wRe,uEt),e(M8,pEt),e(M8,Qie),e(Qie,_Et),e(M8,bEt),e(Pe,vEt),e(Pe,E8),e(E8,ARe),e(ARe,FEt),e(E8,TEt),e(E8,Wie),e(Wie,MEt),e(E8,EEt),e(Pe,CEt),e(Pe,C8),e(C8,LRe),e(LRe,wEt),e(C8,AEt),e(C8,Uie),e(Uie,LEt),e(C8,yEt),e(Pe,xEt),e(Pe,w8),e(w8,yRe),e(yRe,$Et),e(w8,kEt),e(w8,Hie),e(Hie,SEt),e(w8,REt),e(Pe,PEt),e(Pe,A8),e(A8,xRe),e(xRe,BEt),e(A8,IEt),e(A8,Jie),e(Jie,NEt),e(A8,qEt),e(Pe,jEt),e(Pe,L8),e(L8,$Re),e($Re,DEt),e(L8,GEt),e(L8,Yie),e(Yie,OEt),e(L8,VEt),e(Pe,XEt),e(Pe,y8),e(y8,kRe),e(kRe,zEt),e(y8,QEt),e(y8,Zie),e(Zie,WEt),e(y8,UEt),e(Pe,HEt),e(Pe,x8),e(x8,SRe),e(SRe,JEt),e(x8,YEt),e(x8,Kie),e(Kie,ZEt),e(x8,KEt),e(Pe,e4t),e(Pe,$8),e($8,RRe),e(RRe,o4t),e($8,r4t),e($8,ede),e(ede,t4t),e($8,a4t),e(Pe,n4t),e(Pe,k8),e(k8,PRe),e(PRe,s4t),e(k8,l4t),e(k8,ode),e(ode,i4t),e(k8,d4t),e(it,c4t),M(S8,it,null),b(m,Hao,_),b(m,wf,_),e(wf,R8),e(R8,BRe),M(hB,BRe,null),e(wf,m4t),e(wf,IRe),e(IRe,f4t),b(m,Jao,_),b(m,Rr,_),M(uB,Rr,null),e(Rr,g4t),e(Rr,Af),e(Af,h4t),e(Af,rde),e(rde,u4t),e(Af,p4t),e(Af,tde),e(tde,_4t),e(Af,b4t),e(Rr,v4t),e(Rr,pB),e(pB,F4t),e(pB,NRe),e(NRe,T4t),e(pB,M4t),e(Rr,E4t),e(Rr,va),M(_B,va,null),e(va,C4t),e(va,qRe),e(qRe,w4t),e(va,A4t),e(va,Lf),e(Lf,L4t),e(Lf,jRe),e(jRe,y4t),e(Lf,x4t),e(Lf,ade),e(ade,$4t),e(Lf,k4t),e(va,S4t),M(P8,va,null),e(Rr,R4t),e(Rr,dt),M(bB,dt,null),e(dt,P4t),e(dt,DRe),e(DRe,B4t),e(dt,I4t),e(dt,as),e(as,N4t),e(as,GRe),e(GRe,q4t),e(as,j4t),e(as,ORe),e(ORe,D4t),e(as,G4t),e(as,VRe),e(VRe,O4t),e(as,V4t),e(dt,X4t),e(dt,ze),e(ze,B8),e(B8,XRe),e(XRe,z4t),e(B8,Q4t),e(B8,nde),e(nde,W4t),e(B8,U4t),e(ze,H4t),e(ze,I8),e(I8,zRe),e(zRe,J4t),e(I8,Y4t),e(I8,sde),e(sde,Z4t),e(I8,K4t),e(ze,eCt),e(ze,N8),e(N8,QRe),e(QRe,oCt),e(N8,rCt),e(N8,lde),e(lde,tCt),e(N8,aCt),e(ze,nCt),e(ze,q8),e(q8,WRe),e(WRe,sCt),e(q8,lCt),e(q8,ide),e(ide,iCt),e(q8,dCt),e(ze,cCt),e(ze,j8),e(j8,URe),e(URe,mCt),e(j8,fCt),e(j8,dde),e(dde,gCt),e(j8,hCt),e(ze,uCt),e(ze,D8),e(D8,HRe),e(HRe,pCt),e(D8,_Ct),e(D8,cde),e(cde,bCt),e(D8,vCt),e(ze,FCt),e(ze,G8),e(G8,JRe),e(JRe,TCt),e(G8,MCt),e(G8,mde),e(mde,ECt),e(G8,CCt),e(ze,wCt),e(ze,O8),e(O8,YRe),e(YRe,ACt),e(O8,LCt),e(O8,fde),e(fde,yCt),e(O8,xCt),e(dt,$Ct),M(V8,dt,null),b(m,Yao,_),b(m,yf,_),e(yf,X8),e(X8,ZRe),M(vB,ZRe,null),e(yf,kCt),e(yf,KRe),e(KRe,SCt),b(m,Zao,_),b(m,Pr,_),M(FB,Pr,null),e(Pr,RCt),e(Pr,xf),e(xf,PCt),e(xf,gde),e(gde,BCt),e(xf,ICt),e(xf,hde),e(hde,NCt),e(xf,qCt),e(Pr,jCt),e(Pr,TB),e(TB,DCt),e(TB,ePe),e(ePe,GCt),e(TB,OCt),e(Pr,VCt),e(Pr,Fa),M(MB,Fa,null),e(Fa,XCt),e(Fa,oPe),e(oPe,zCt),e(Fa,QCt),e(Fa,$f),e($f,WCt),e($f,rPe),e(rPe,UCt),e($f,HCt),e($f,ude),e(ude,JCt),e($f,YCt),e(Fa,ZCt),M(z8,Fa,null),e(Pr,KCt),e(Pr,ct),M(EB,ct,null),e(ct,e3t),e(ct,tPe),e(tPe,o3t),e(ct,r3t),e(ct,ns),e(ns,t3t),e(ns,aPe),e(aPe,a3t),e(ns,n3t),e(ns,nPe),e(nPe,s3t),e(ns,l3t),e(ns,sPe),e(sPe,i3t),e(ns,d3t),e(ct,c3t),e(ct,Qe),e(Qe,Q8),e(Q8,lPe),e(lPe,m3t),e(Q8,f3t),e(Q8,pde),e(pde,g3t),e(Q8,h3t),e(Qe,u3t),e(Qe,W8),e(W8,iPe),e(iPe,p3t),e(W8,_3t),e(W8,_de),e(_de,b3t),e(W8,v3t),e(Qe,F3t),e(Qe,U8),e(U8,dPe),e(dPe,T3t),e(U8,M3t),e(U8,bde),e(bde,E3t),e(U8,C3t),e(Qe,w3t),e(Qe,H8),e(H8,cPe),e(cPe,A3t),e(H8,L3t),e(H8,vde),e(vde,y3t),e(H8,x3t),e(Qe,$3t),e(Qe,J8),e(J8,mPe),e(mPe,k3t),e(J8,S3t),e(J8,Fde),e(Fde,R3t),e(J8,P3t),e(Qe,B3t),e(Qe,Y8),e(Y8,fPe),e(fPe,I3t),e(Y8,N3t),e(Y8,Tde),e(Tde,q3t),e(Y8,j3t),e(Qe,D3t),e(Qe,Z8),e(Z8,gPe),e(gPe,G3t),e(Z8,O3t),e(Z8,Mde),e(Mde,V3t),e(Z8,X3t),e(Qe,z3t),e(Qe,K8),e(K8,hPe),e(hPe,Q3t),e(K8,W3t),e(K8,Ede),e(Ede,U3t),e(K8,H3t),e(ct,J3t),M(ey,ct,null),b(m,Kao,_),b(m,kf,_),e(kf,oy),e(oy,uPe),M(CB,uPe,null),e(kf,Y3t),e(kf,pPe),e(pPe,Z3t),b(m,eno,_),b(m,Br,_),M(wB,Br,null),e(Br,K3t),e(Br,Sf),e(Sf,e5t),e(Sf,Cde),e(Cde,o5t),e(Sf,r5t),e(Sf,wde),e(wde,t5t),e(Sf,a5t),e(Br,n5t),e(Br,AB),e(AB,s5t),e(AB,_Pe),e(_Pe,l5t),e(AB,i5t),e(Br,d5t),e(Br,Ta),M(LB,Ta,null),e(Ta,c5t),e(Ta,bPe),e(bPe,m5t),e(Ta,f5t),e(Ta,Rf),e(Rf,g5t),e(Rf,vPe),e(vPe,h5t),e(Rf,u5t),e(Rf,Ade),e(Ade,p5t),e(Rf,_5t),e(Ta,b5t),M(ry,Ta,null),e(Br,v5t),e(Br,mt),M(yB,mt,null),e(mt,F5t),e(mt,FPe),e(FPe,T5t),e(mt,M5t),e(mt,ss),e(ss,E5t),e(ss,TPe),e(TPe,C5t),e(ss,w5t),e(ss,MPe),e(MPe,A5t),e(ss,L5t),e(ss,EPe),e(EPe,y5t),e(ss,x5t),e(mt,$5t),e(mt,CPe),e(CPe,ty),e(ty,wPe),e(wPe,k5t),e(ty,S5t),e(ty,Lde),e(Lde,R5t),e(ty,P5t),e(mt,B5t),M(ay,mt,null),b(m,ono,_),b(m,Pf,_),e(Pf,ny),e(ny,APe),M(xB,APe,null),e(Pf,I5t),e(Pf,LPe),e(LPe,N5t),b(m,rno,_),b(m,Ir,_),M($B,Ir,null),e(Ir,q5t),e(Ir,Bf),e(Bf,j5t),e(Bf,yde),e(yde,D5t),e(Bf,G5t),e(Bf,xde),e(xde,O5t),e(Bf,V5t),e(Ir,X5t),e(Ir,kB),e(kB,z5t),e(kB,yPe),e(yPe,Q5t),e(kB,W5t),e(Ir,U5t),e(Ir,Ma),M(SB,Ma,null),e(Ma,H5t),e(Ma,xPe),e(xPe,J5t),e(Ma,Y5t),e(Ma,If),e(If,Z5t),e(If,$Pe),e($Pe,K5t),e(If,e0t),e(If,$de),e($de,o0t),e(If,r0t),e(Ma,t0t),M(sy,Ma,null),e(Ir,a0t),e(Ir,ft),M(RB,ft,null),e(ft,n0t),e(ft,kPe),e(kPe,s0t),e(ft,l0t),e(ft,ls),e(ls,i0t),e(ls,SPe),e(SPe,d0t),e(ls,c0t),e(ls,RPe),e(RPe,m0t),e(ls,f0t),e(ls,PPe),e(PPe,g0t),e(ls,h0t),e(ft,u0t),e(ft,PB),e(PB,ly),e(ly,BPe),e(BPe,p0t),e(ly,_0t),e(ly,kde),e(kde,b0t),e(ly,v0t),e(PB,F0t),e(PB,iy),e(iy,IPe),e(IPe,T0t),e(iy,M0t),e(iy,Sde),e(Sde,E0t),e(iy,C0t),e(ft,w0t),M(dy,ft,null),b(m,tno,_),b(m,Nf,_),e(Nf,cy),e(cy,NPe),M(BB,NPe,null),e(Nf,A0t),e(Nf,qPe),e(qPe,L0t),b(m,ano,_),b(m,Nr,_),M(IB,Nr,null),e(Nr,y0t),e(Nr,qf),e(qf,x0t),e(qf,Rde),e(Rde,$0t),e(qf,k0t),e(qf,Pde),e(Pde,S0t),e(qf,R0t),e(Nr,P0t),e(Nr,NB),e(NB,B0t),e(NB,jPe),e(jPe,I0t),e(NB,N0t),e(Nr,q0t),e(Nr,Ea),M(qB,Ea,null),e(Ea,j0t),e(Ea,DPe),e(DPe,D0t),e(Ea,G0t),e(Ea,jf),e(jf,O0t),e(jf,GPe),e(GPe,V0t),e(jf,X0t),e(jf,Bde),e(Bde,z0t),e(jf,Q0t),e(Ea,W0t),M(my,Ea,null),e(Nr,U0t),e(Nr,gt),M(jB,gt,null),e(gt,H0t),e(gt,OPe),e(OPe,J0t),e(gt,Y0t),e(gt,is),e(is,Z0t),e(is,VPe),e(VPe,K0t),e(is,ewt),e(is,XPe),e(XPe,owt),e(is,rwt),e(is,zPe),e(zPe,twt),e(is,awt),e(gt,nwt),e(gt,QPe),e(QPe,fy),e(fy,WPe),e(WPe,swt),e(fy,lwt),e(fy,Ide),e(Ide,iwt),e(fy,dwt),e(gt,cwt),M(gy,gt,null),nno=!0},p(m,[_]){const DB={};_&2&&(DB.$$scope={dirty:_,ctx:m}),Uf.$set(DB);const UPe={};_&2&&(UPe.$$scope={dirty:_,ctx:m}),Mu.$set(UPe);const HPe={};_&2&&(HPe.$$scope={dirty:_,ctx:m}),sp.$set(HPe);const JPe={};_&2&&(JPe.$$scope={dirty:_,ctx:m}),Zp.$set(JPe);const GB={};_&2&&(GB.$$scope={dirty:_,ctx:m}),Kp.$set(GB);const YPe={};_&2&&(YPe.$$scope={dirty:_,ctx:m}),w_.$set(YPe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:m}),A_.$set(ds);const ZPe={};_&2&&(ZPe.$$scope={dirty:_,ctx:m}),x_.$set(ZPe);const KPe={};_&2&&(KPe.$$scope={dirty:_,ctx:m}),J2.$set(KPe);const eBe={};_&2&&(eBe.$$scope={dirty:_,ctx:m}),Z2.$set(eBe);const OB={};_&2&&(OB.$$scope={dirty:_,ctx:m}),Ub.$set(OB);const oBe={};_&2&&(oBe.$$scope={dirty:_,ctx:m}),Jb.$set(oBe);const VB={};_&2&&(VB.$$scope={dirty:_,ctx:m}),Dv.$set(VB);const rBe={};_&2&&(rBe.$$scope={dirty:_,ctx:m}),Ov.$set(rBe);const XB={};_&2&&(XB.$$scope={dirty:_,ctx:m}),Qv.$set(XB);const tBe={};_&2&&(tBe.$$scope={dirty:_,ctx:m}),Uv.$set(tBe);const aBe={};_&2&&(aBe.$$scope={dirty:_,ctx:m}),BF.$set(aBe);const nBe={};_&2&&(nBe.$$scope={dirty:_,ctx:m}),NF.$set(nBe);const Df={};_&2&&(Df.$$scope={dirty:_,ctx:m}),nT.$set(Df);const sBe={};_&2&&(sBe.$$scope={dirty:_,ctx:m}),lT.$set(sBe);const lBe={};_&2&&(lBe.$$scope={dirty:_,ctx:m}),mM.$set(lBe);const iBe={};_&2&&(iBe.$$scope={dirty:_,ctx:m}),gM.$set(iBe);const zB={};_&2&&(zB.$$scope={dirty:_,ctx:m}),WM.$set(zB);const dBe={};_&2&&(dBe.$$scope={dirty:_,ctx:m}),HM.$set(dBe);const cBe={};_&2&&(cBe.$$scope={dirty:_,ctx:m}),aE.$set(cBe);const mBe={};_&2&&(mBe.$$scope={dirty:_,ctx:m}),sE.$set(mBe);const bt={};_&2&&(bt.$$scope={dirty:_,ctx:m}),HE.$set(bt);const QB={};_&2&&(QB.$$scope={dirty:_,ctx:m}),YE.$set(QB);const fBe={};_&2&&(fBe.$$scope={dirty:_,ctx:m}),W4.$set(fBe);const WB={};_&2&&(WB.$$scope={dirty:_,ctx:m}),H4.$set(WB);const gBe={};_&2&&(gBe.$$scope={dirty:_,ctx:m}),Z4.$set(gBe);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:m}),eC.$set(vt);const hBe={};_&2&&(hBe.$$scope={dirty:_,ctx:m}),nC.$set(hBe);const Gf={};_&2&&(Gf.$$scope={dirty:_,ctx:m}),lC.$set(Gf);const uBe={};_&2&&(uBe.$$scope={dirty:_,ctx:m}),CC.$set(uBe);const pBe={};_&2&&(pBe.$$scope={dirty:_,ctx:m}),AC.$set(pBe);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),xC.$set(L);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:m}),kC.$set(hy);const _Be={};_&2&&(_Be.$$scope={dirty:_,ctx:m}),PC.$set(_Be);const bBe={};_&2&&(bBe.$$scope={dirty:_,ctx:m}),IC.$set(bBe);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:m}),jC.$set(uy);const vBe={};_&2&&(vBe.$$scope={dirty:_,ctx:m}),GC.$set(vBe);const FBe={};_&2&&(FBe.$$scope={dirty:_,ctx:m}),ZC.$set(FBe);const py={};_&2&&(py.$$scope={dirty:_,ctx:m}),e3.$set(py);const TBe={};_&2&&(TBe.$$scope={dirty:_,ctx:m}),l3.$set(TBe);const MBe={};_&2&&(MBe.$$scope={dirty:_,ctx:m}),d3.$set(MBe);const _y={};_&2&&(_y.$$scope={dirty:_,ctx:m}),T3.$set(_y);const EBe={};_&2&&(EBe.$$scope={dirty:_,ctx:m}),E3.$set(EBe);const CBe={};_&2&&(CBe.$$scope={dirty:_,ctx:m}),y3.$set(CBe);const by={};_&2&&(by.$$scope={dirty:_,ctx:m}),$3.$set(by);const wBe={};_&2&&(wBe.$$scope={dirty:_,ctx:m}),N3.$set(wBe);const ABe={};_&2&&(ABe.$$scope={dirty:_,ctx:m}),j3.$set(ABe);const vy={};_&2&&(vy.$$scope={dirty:_,ctx:m}),z3.$set(vy);const LBe={};_&2&&(LBe.$$scope={dirty:_,ctx:m}),W3.$set(LBe);const yBe={};_&2&&(yBe.$$scope={dirty:_,ctx:m}),K3.$set(yBe);const Fy={};_&2&&(Fy.$$scope={dirty:_,ctx:m}),o5.$set(Fy);const xBe={};_&2&&(xBe.$$scope={dirty:_,ctx:m}),a5.$set(xBe);const $Be={};_&2&&($Be.$$scope={dirty:_,ctx:m}),s5.$set($Be);const Ty={};_&2&&(Ty.$$scope={dirty:_,ctx:m}),g5.$set(Ty);const kBe={};_&2&&(kBe.$$scope={dirty:_,ctx:m}),u5.$set(kBe);const SBe={};_&2&&(SBe.$$scope={dirty:_,ctx:m}),b5.$set(SBe);const My={};_&2&&(My.$$scope={dirty:_,ctx:m}),F5.$set(My);const RBe={};_&2&&(RBe.$$scope={dirty:_,ctx:m}),E5.$set(RBe);const PBe={};_&2&&(PBe.$$scope={dirty:_,ctx:m}),w5.$set(PBe);const Ey={};_&2&&(Ey.$$scope={dirty:_,ctx:m}),y0.$set(Ey);const BBe={};_&2&&(BBe.$$scope={dirty:_,ctx:m}),$0.$set(BBe);const IBe={};_&2&&(IBe.$$scope={dirty:_,ctx:m}),ew.$set(IBe);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:m}),rw.$set(Cy);const NBe={};_&2&&(NBe.$$scope={dirty:_,ctx:m}),_w.$set(NBe);const qBe={};_&2&&(qBe.$$scope={dirty:_,ctx:m}),vw.$set(qBe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:m}),xw.$set(wy);const jBe={};_&2&&(jBe.$$scope={dirty:_,ctx:m}),kw.$set(jBe);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:m}),Bw.$set(DBe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:m}),Nw.$set(Ay);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:m}),aA.$set(GBe);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:m}),sA.$set(OBe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:m}),_A.$set(Ly);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:m}),vA.$set(VBe);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:m}),WA.$set(XBe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:m}),HA.$set(yy);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:m}),g6.$set(zBe);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:m}),u6.$set(QBe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:m}),b6.$set(xy);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:m}),F6.$set(WBe);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:m}),M6.$set(UBe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:m}),C6.$set($y);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:m}),A6.$set(HBe);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:m}),y6.$set(JBe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:m}),J6.$set(ky);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:m}),Z6.$set(YBe);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:m}),F7.$set(ZBe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:m}),M7.$set(Sy);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:m}),C7.$set(KBe);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:m}),A7.$set(eIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:m}),x7.$set(Ry);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:m}),k7.$set(oIe);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:m}),nL.$set(rIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:m}),lL.$set(Py);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:m}),bL.$set(tIe);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:m}),FL.$set(aIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:m}),PL.$set(By);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:m}),IL.$set(nIe);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:m}),WL.$set(sIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:m}),HL.$set(Iy);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:m}),s8.$set(lIe);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:m}),i8.$set(iIe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:m}),v8.$set(Ny);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:m}),T8.$set(dIe);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:m}),S8.$set(cIe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:m}),P8.$set(qy);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:m}),V8.$set(mIe);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:m}),z8.$set(fIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:m}),ey.$set(jy);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:m}),ry.$set(gIe);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:m}),ay.$set(hIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:m}),sy.$set(Dy);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:m}),dy.$set(uIe);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:m}),my.$set(pIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:m}),gy.$set(Gy)},i(m){nno||(E(d.$$.fragment,m),E(en.$$.fragment,m),E(e$.$$.fragment,m),E(o$.$$.fragment,m),E(Uf.$$.fragment,m),E(r$.$$.fragment,m),E(t$.$$.fragment,m),E(s$.$$.fragment,m),E(Mu.$$.fragment,m),E(l$.$$.fragment,m),E(i$.$$.fragment,m),E(d$.$$.fragment,m),E(f$.$$.fragment,m),E(sp.$$.fragment,m),E(g$.$$.fragment,m),E(h$.$$.fragment,m),E(u$.$$.fragment,m),E(b$.$$.fragment,m),E(Zp.$$.fragment,m),E(Kp.$$.fragment,m),E(v$.$$.fragment,m),E(F$.$$.fragment,m),E(T$.$$.fragment,m),E(C$.$$.fragment,m),E(w_.$$.fragment,m),E(A_.$$.fragment,m),E(w$.$$.fragment,m),E(A$.$$.fragment,m),E(L$.$$.fragment,m),E(x$.$$.fragment,m),E(x_.$$.fragment,m),E($$.$$.fragment,m),E(J2.$$.fragment,m),E(k$.$$.fragment,m),E(S$.$$.fragment,m),E(P$.$$.fragment,m),E(Z2.$$.fragment,m),E(B$.$$.fragment,m),E(Ub.$$.fragment,m),E(I$.$$.fragment,m),E(N$.$$.fragment,m),E(j$.$$.fragment,m),E(Jb.$$.fragment,m),E(D$.$$.fragment,m),E(Dv.$$.fragment,m),E(G$.$$.fragment,m),E(O$.$$.fragment,m),E(X$.$$.fragment,m),E(Ov.$$.fragment,m),E(z$.$$.fragment,m),E(Qv.$$.fragment,m),E(W$.$$.fragment,m),E(U$.$$.fragment,m),E(J$.$$.fragment,m),E(Uv.$$.fragment,m),E(Y$.$$.fragment,m),E(BF.$$.fragment,m),E(Z$.$$.fragment,m),E(K$.$$.fragment,m),E(ok.$$.fragment,m),E(NF.$$.fragment,m),E(rk.$$.fragment,m),E(nT.$$.fragment,m),E(tk.$$.fragment,m),E(ak.$$.fragment,m),E(sk.$$.fragment,m),E(lT.$$.fragment,m),E(lk.$$.fragment,m),E(mM.$$.fragment,m),E(ik.$$.fragment,m),E(dk.$$.fragment,m),E(mk.$$.fragment,m),E(gM.$$.fragment,m),E(fk.$$.fragment,m),E(WM.$$.fragment,m),E(gk.$$.fragment,m),E(hk.$$.fragment,m),E(pk.$$.fragment,m),E(HM.$$.fragment,m),E(_k.$$.fragment,m),E(aE.$$.fragment,m),E(bk.$$.fragment,m),E(vk.$$.fragment,m),E(Tk.$$.fragment,m),E(sE.$$.fragment,m),E(Mk.$$.fragment,m),E(HE.$$.fragment,m),E(Ek.$$.fragment,m),E(Ck.$$.fragment,m),E(Ak.$$.fragment,m),E(YE.$$.fragment,m),E(Lk.$$.fragment,m),E(W4.$$.fragment,m),E(yk.$$.fragment,m),E(xk.$$.fragment,m),E(kk.$$.fragment,m),E(H4.$$.fragment,m),E(Sk.$$.fragment,m),E(Z4.$$.fragment,m),E(Rk.$$.fragment,m),E(Pk.$$.fragment,m),E(Ik.$$.fragment,m),E(eC.$$.fragment,m),E(Nk.$$.fragment,m),E(nC.$$.fragment,m),E(qk.$$.fragment,m),E(jk.$$.fragment,m),E(Gk.$$.fragment,m),E(lC.$$.fragment,m),E(Ok.$$.fragment,m),E(CC.$$.fragment,m),E(Vk.$$.fragment,m),E(Xk.$$.fragment,m),E(Qk.$$.fragment,m),E(AC.$$.fragment,m),E(Wk.$$.fragment,m),E(xC.$$.fragment,m),E(Uk.$$.fragment,m),E(Hk.$$.fragment,m),E(Yk.$$.fragment,m),E(kC.$$.fragment,m),E(Zk.$$.fragment,m),E(PC.$$.fragment,m),E(Kk.$$.fragment,m),E(eS.$$.fragment,m),E(rS.$$.fragment,m),E(IC.$$.fragment,m),E(tS.$$.fragment,m),E(jC.$$.fragment,m),E(aS.$$.fragment,m),E(nS.$$.fragment,m),E(lS.$$.fragment,m),E(GC.$$.fragment,m),E(iS.$$.fragment,m),E(ZC.$$.fragment,m),E(dS.$$.fragment,m),E(cS.$$.fragment,m),E(fS.$$.fragment,m),E(e3.$$.fragment,m),E(gS.$$.fragment,m),E(l3.$$.fragment,m),E(hS.$$.fragment,m),E(uS.$$.fragment,m),E(_S.$$.fragment,m),E(d3.$$.fragment,m),E(bS.$$.fragment,m),E(T3.$$.fragment,m),E(vS.$$.fragment,m),E(FS.$$.fragment,m),E(MS.$$.fragment,m),E(E3.$$.fragment,m),E(ES.$$.fragment,m),E(y3.$$.fragment,m),E(CS.$$.fragment,m),E(wS.$$.fragment,m),E(LS.$$.fragment,m),E($3.$$.fragment,m),E(yS.$$.fragment,m),E(N3.$$.fragment,m),E(xS.$$.fragment,m),E($S.$$.fragment,m),E(SS.$$.fragment,m),E(j3.$$.fragment,m),E(RS.$$.fragment,m),E(z3.$$.fragment,m),E(PS.$$.fragment,m),E(BS.$$.fragment,m),E(NS.$$.fragment,m),E(W3.$$.fragment,m),E(qS.$$.fragment,m),E(K3.$$.fragment,m),E(jS.$$.fragment,m),E(DS.$$.fragment,m),E(OS.$$.fragment,m),E(o5.$$.fragment,m),E(VS.$$.fragment,m),E(a5.$$.fragment,m),E(XS.$$.fragment,m),E(zS.$$.fragment,m),E(WS.$$.fragment,m),E(s5.$$.fragment,m),E(US.$$.fragment,m),E(g5.$$.fragment,m),E(HS.$$.fragment,m),E(JS.$$.fragment,m),E(ZS.$$.fragment,m),E(u5.$$.fragment,m),E(KS.$$.fragment,m),E(b5.$$.fragment,m),E(eR.$$.fragment,m),E(oR.$$.fragment,m),E(tR.$$.fragment,m),E(F5.$$.fragment,m),E(aR.$$.fragment,m),E(E5.$$.fragment,m),E(nR.$$.fragment,m),E(sR.$$.fragment,m),E(iR.$$.fragment,m),E(w5.$$.fragment,m),E(dR.$$.fragment,m),E(y0.$$.fragment,m),E(cR.$$.fragment,m),E(mR.$$.fragment,m),E(gR.$$.fragment,m),E($0.$$.fragment,m),E(hR.$$.fragment,m),E(ew.$$.fragment,m),E(uR.$$.fragment,m),E(pR.$$.fragment,m),E(bR.$$.fragment,m),E(rw.$$.fragment,m),E(vR.$$.fragment,m),E(_w.$$.fragment,m),E(FR.$$.fragment,m),E(TR.$$.fragment,m),E(ER.$$.fragment,m),E(vw.$$.fragment,m),E(CR.$$.fragment,m),E(xw.$$.fragment,m),E(wR.$$.fragment,m),E(AR.$$.fragment,m),E(yR.$$.fragment,m),E(kw.$$.fragment,m),E(xR.$$.fragment,m),E(Bw.$$.fragment,m),E($R.$$.fragment,m),E(kR.$$.fragment,m),E(RR.$$.fragment,m),E(Nw.$$.fragment,m),E(PR.$$.fragment,m),E(aA.$$.fragment,m),E(BR.$$.fragment,m),E(IR.$$.fragment,m),E(qR.$$.fragment,m),E(sA.$$.fragment,m),E(jR.$$.fragment,m),E(_A.$$.fragment,m),E(DR.$$.fragment,m),E(GR.$$.fragment,m),E(VR.$$.fragment,m),E(vA.$$.fragment,m),E(XR.$$.fragment,m),E(WA.$$.fragment,m),E(zR.$$.fragment,m),E(QR.$$.fragment,m),E(UR.$$.fragment,m),E(HA.$$.fragment,m),E(HR.$$.fragment,m),E(g6.$$.fragment,m),E(JR.$$.fragment,m),E(YR.$$.fragment,m),E(KR.$$.fragment,m),E(u6.$$.fragment,m),E(eP.$$.fragment,m),E(b6.$$.fragment,m),E(rP.$$.fragment,m),E(tP.$$.fragment,m),E(nP.$$.fragment,m),E(F6.$$.fragment,m),E(sP.$$.fragment,m),E(M6.$$.fragment,m),E(lP.$$.fragment,m),E(iP.$$.fragment,m),E(cP.$$.fragment,m),E(C6.$$.fragment,m),E(mP.$$.fragment,m),E(A6.$$.fragment,m),E(fP.$$.fragment,m),E(gP.$$.fragment,m),E(uP.$$.fragment,m),E(y6.$$.fragment,m),E(pP.$$.fragment,m),E(J6.$$.fragment,m),E(_P.$$.fragment,m),E(bP.$$.fragment,m),E(FP.$$.fragment,m),E(Z6.$$.fragment,m),E(TP.$$.fragment,m),E(F7.$$.fragment,m),E(MP.$$.fragment,m),E(EP.$$.fragment,m),E(wP.$$.fragment,m),E(M7.$$.fragment,m),E(AP.$$.fragment,m),E(C7.$$.fragment,m),E(LP.$$.fragment,m),E(yP.$$.fragment,m),E($P.$$.fragment,m),E(A7.$$.fragment,m),E(kP.$$.fragment,m),E(x7.$$.fragment,m),E(RP.$$.fragment,m),E(PP.$$.fragment,m),E(IP.$$.fragment,m),E(k7.$$.fragment,m),E(NP.$$.fragment,m),E(nL.$$.fragment,m),E(qP.$$.fragment,m),E(jP.$$.fragment,m),E(GP.$$.fragment,m),E(lL.$$.fragment,m),E(OP.$$.fragment,m),E(bL.$$.fragment,m),E(VP.$$.fragment,m),E(XP.$$.fragment,m),E(QP.$$.fragment,m),E(FL.$$.fragment,m),E(WP.$$.fragment,m),E(PL.$$.fragment,m),E(UP.$$.fragment,m),E(HP.$$.fragment,m),E(YP.$$.fragment,m),E(IL.$$.fragment,m),E(ZP.$$.fragment,m),E(WL.$$.fragment,m),E(KP.$$.fragment,m),E(eB.$$.fragment,m),E(rB.$$.fragment,m),E(HL.$$.fragment,m),E(tB.$$.fragment,m),E(s8.$$.fragment,m),E(aB.$$.fragment,m),E(nB.$$.fragment,m),E(lB.$$.fragment,m),E(i8.$$.fragment,m),E(iB.$$.fragment,m),E(v8.$$.fragment,m),E(dB.$$.fragment,m),E(cB.$$.fragment,m),E(fB.$$.fragment,m),E(T8.$$.fragment,m),E(gB.$$.fragment,m),E(S8.$$.fragment,m),E(hB.$$.fragment,m),E(uB.$$.fragment,m),E(_B.$$.fragment,m),E(P8.$$.fragment,m),E(bB.$$.fragment,m),E(V8.$$.fragment,m),E(vB.$$.fragment,m),E(FB.$$.fragment,m),E(MB.$$.fragment,m),E(z8.$$.fragment,m),E(EB.$$.fragment,m),E(ey.$$.fragment,m),E(CB.$$.fragment,m),E(wB.$$.fragment,m),E(LB.$$.fragment,m),E(ry.$$.fragment,m),E(yB.$$.fragment,m),E(ay.$$.fragment,m),E(xB.$$.fragment,m),E($B.$$.fragment,m),E(SB.$$.fragment,m),E(sy.$$.fragment,m),E(RB.$$.fragment,m),E(dy.$$.fragment,m),E(BB.$$.fragment,m),E(IB.$$.fragment,m),E(qB.$$.fragment,m),E(my.$$.fragment,m),E(jB.$$.fragment,m),E(gy.$$.fragment,m),nno=!0)},o(m){C(d.$$.fragment,m),C(en.$$.fragment,m),C(e$.$$.fragment,m),C(o$.$$.fragment,m),C(Uf.$$.fragment,m),C(r$.$$.fragment,m),C(t$.$$.fragment,m),C(s$.$$.fragment,m),C(Mu.$$.fragment,m),C(l$.$$.fragment,m),C(i$.$$.fragment,m),C(d$.$$.fragment,m),C(f$.$$.fragment,m),C(sp.$$.fragment,m),C(g$.$$.fragment,m),C(h$.$$.fragment,m),C(u$.$$.fragment,m),C(b$.$$.fragment,m),C(Zp.$$.fragment,m),C(Kp.$$.fragment,m),C(v$.$$.fragment,m),C(F$.$$.fragment,m),C(T$.$$.fragment,m),C(C$.$$.fragment,m),C(w_.$$.fragment,m),C(A_.$$.fragment,m),C(w$.$$.fragment,m),C(A$.$$.fragment,m),C(L$.$$.fragment,m),C(x$.$$.fragment,m),C(x_.$$.fragment,m),C($$.$$.fragment,m),C(J2.$$.fragment,m),C(k$.$$.fragment,m),C(S$.$$.fragment,m),C(P$.$$.fragment,m),C(Z2.$$.fragment,m),C(B$.$$.fragment,m),C(Ub.$$.fragment,m),C(I$.$$.fragment,m),C(N$.$$.fragment,m),C(j$.$$.fragment,m),C(Jb.$$.fragment,m),C(D$.$$.fragment,m),C(Dv.$$.fragment,m),C(G$.$$.fragment,m),C(O$.$$.fragment,m),C(X$.$$.fragment,m),C(Ov.$$.fragment,m),C(z$.$$.fragment,m),C(Qv.$$.fragment,m),C(W$.$$.fragment,m),C(U$.$$.fragment,m),C(J$.$$.fragment,m),C(Uv.$$.fragment,m),C(Y$.$$.fragment,m),C(BF.$$.fragment,m),C(Z$.$$.fragment,m),C(K$.$$.fragment,m),C(ok.$$.fragment,m),C(NF.$$.fragment,m),C(rk.$$.fragment,m),C(nT.$$.fragment,m),C(tk.$$.fragment,m),C(ak.$$.fragment,m),C(sk.$$.fragment,m),C(lT.$$.fragment,m),C(lk.$$.fragment,m),C(mM.$$.fragment,m),C(ik.$$.fragment,m),C(dk.$$.fragment,m),C(mk.$$.fragment,m),C(gM.$$.fragment,m),C(fk.$$.fragment,m),C(WM.$$.fragment,m),C(gk.$$.fragment,m),C(hk.$$.fragment,m),C(pk.$$.fragment,m),C(HM.$$.fragment,m),C(_k.$$.fragment,m),C(aE.$$.fragment,m),C(bk.$$.fragment,m),C(vk.$$.fragment,m),C(Tk.$$.fragment,m),C(sE.$$.fragment,m),C(Mk.$$.fragment,m),C(HE.$$.fragment,m),C(Ek.$$.fragment,m),C(Ck.$$.fragment,m),C(Ak.$$.fragment,m),C(YE.$$.fragment,m),C(Lk.$$.fragment,m),C(W4.$$.fragment,m),C(yk.$$.fragment,m),C(xk.$$.fragment,m),C(kk.$$.fragment,m),C(H4.$$.fragment,m),C(Sk.$$.fragment,m),C(Z4.$$.fragment,m),C(Rk.$$.fragment,m),C(Pk.$$.fragment,m),C(Ik.$$.fragment,m),C(eC.$$.fragment,m),C(Nk.$$.fragment,m),C(nC.$$.fragment,m),C(qk.$$.fragment,m),C(jk.$$.fragment,m),C(Gk.$$.fragment,m),C(lC.$$.fragment,m),C(Ok.$$.fragment,m),C(CC.$$.fragment,m),C(Vk.$$.fragment,m),C(Xk.$$.fragment,m),C(Qk.$$.fragment,m),C(AC.$$.fragment,m),C(Wk.$$.fragment,m),C(xC.$$.fragment,m),C(Uk.$$.fragment,m),C(Hk.$$.fragment,m),C(Yk.$$.fragment,m),C(kC.$$.fragment,m),C(Zk.$$.fragment,m),C(PC.$$.fragment,m),C(Kk.$$.fragment,m),C(eS.$$.fragment,m),C(rS.$$.fragment,m),C(IC.$$.fragment,m),C(tS.$$.fragment,m),C(jC.$$.fragment,m),C(aS.$$.fragment,m),C(nS.$$.fragment,m),C(lS.$$.fragment,m),C(GC.$$.fragment,m),C(iS.$$.fragment,m),C(ZC.$$.fragment,m),C(dS.$$.fragment,m),C(cS.$$.fragment,m),C(fS.$$.fragment,m),C(e3.$$.fragment,m),C(gS.$$.fragment,m),C(l3.$$.fragment,m),C(hS.$$.fragment,m),C(uS.$$.fragment,m),C(_S.$$.fragment,m),C(d3.$$.fragment,m),C(bS.$$.fragment,m),C(T3.$$.fragment,m),C(vS.$$.fragment,m),C(FS.$$.fragment,m),C(MS.$$.fragment,m),C(E3.$$.fragment,m),C(ES.$$.fragment,m),C(y3.$$.fragment,m),C(CS.$$.fragment,m),C(wS.$$.fragment,m),C(LS.$$.fragment,m),C($3.$$.fragment,m),C(yS.$$.fragment,m),C(N3.$$.fragment,m),C(xS.$$.fragment,m),C($S.$$.fragment,m),C(SS.$$.fragment,m),C(j3.$$.fragment,m),C(RS.$$.fragment,m),C(z3.$$.fragment,m),C(PS.$$.fragment,m),C(BS.$$.fragment,m),C(NS.$$.fragment,m),C(W3.$$.fragment,m),C(qS.$$.fragment,m),C(K3.$$.fragment,m),C(jS.$$.fragment,m),C(DS.$$.fragment,m),C(OS.$$.fragment,m),C(o5.$$.fragment,m),C(VS.$$.fragment,m),C(a5.$$.fragment,m),C(XS.$$.fragment,m),C(zS.$$.fragment,m),C(WS.$$.fragment,m),C(s5.$$.fragment,m),C(US.$$.fragment,m),C(g5.$$.fragment,m),C(HS.$$.fragment,m),C(JS.$$.fragment,m),C(ZS.$$.fragment,m),C(u5.$$.fragment,m),C(KS.$$.fragment,m),C(b5.$$.fragment,m),C(eR.$$.fragment,m),C(oR.$$.fragment,m),C(tR.$$.fragment,m),C(F5.$$.fragment,m),C(aR.$$.fragment,m),C(E5.$$.fragment,m),C(nR.$$.fragment,m),C(sR.$$.fragment,m),C(iR.$$.fragment,m),C(w5.$$.fragment,m),C(dR.$$.fragment,m),C(y0.$$.fragment,m),C(cR.$$.fragment,m),C(mR.$$.fragment,m),C(gR.$$.fragment,m),C($0.$$.fragment,m),C(hR.$$.fragment,m),C(ew.$$.fragment,m),C(uR.$$.fragment,m),C(pR.$$.fragment,m),C(bR.$$.fragment,m),C(rw.$$.fragment,m),C(vR.$$.fragment,m),C(_w.$$.fragment,m),C(FR.$$.fragment,m),C(TR.$$.fragment,m),C(ER.$$.fragment,m),C(vw.$$.fragment,m),C(CR.$$.fragment,m),C(xw.$$.fragment,m),C(wR.$$.fragment,m),C(AR.$$.fragment,m),C(yR.$$.fragment,m),C(kw.$$.fragment,m),C(xR.$$.fragment,m),C(Bw.$$.fragment,m),C($R.$$.fragment,m),C(kR.$$.fragment,m),C(RR.$$.fragment,m),C(Nw.$$.fragment,m),C(PR.$$.fragment,m),C(aA.$$.fragment,m),C(BR.$$.fragment,m),C(IR.$$.fragment,m),C(qR.$$.fragment,m),C(sA.$$.fragment,m),C(jR.$$.fragment,m),C(_A.$$.fragment,m),C(DR.$$.fragment,m),C(GR.$$.fragment,m),C(VR.$$.fragment,m),C(vA.$$.fragment,m),C(XR.$$.fragment,m),C(WA.$$.fragment,m),C(zR.$$.fragment,m),C(QR.$$.fragment,m),C(UR.$$.fragment,m),C(HA.$$.fragment,m),C(HR.$$.fragment,m),C(g6.$$.fragment,m),C(JR.$$.fragment,m),C(YR.$$.fragment,m),C(KR.$$.fragment,m),C(u6.$$.fragment,m),C(eP.$$.fragment,m),C(b6.$$.fragment,m),C(rP.$$.fragment,m),C(tP.$$.fragment,m),C(nP.$$.fragment,m),C(F6.$$.fragment,m),C(sP.$$.fragment,m),C(M6.$$.fragment,m),C(lP.$$.fragment,m),C(iP.$$.fragment,m),C(cP.$$.fragment,m),C(C6.$$.fragment,m),C(mP.$$.fragment,m),C(A6.$$.fragment,m),C(fP.$$.fragment,m),C(gP.$$.fragment,m),C(uP.$$.fragment,m),C(y6.$$.fragment,m),C(pP.$$.fragment,m),C(J6.$$.fragment,m),C(_P.$$.fragment,m),C(bP.$$.fragment,m),C(FP.$$.fragment,m),C(Z6.$$.fragment,m),C(TP.$$.fragment,m),C(F7.$$.fragment,m),C(MP.$$.fragment,m),C(EP.$$.fragment,m),C(wP.$$.fragment,m),C(M7.$$.fragment,m),C(AP.$$.fragment,m),C(C7.$$.fragment,m),C(LP.$$.fragment,m),C(yP.$$.fragment,m),C($P.$$.fragment,m),C(A7.$$.fragment,m),C(kP.$$.fragment,m),C(x7.$$.fragment,m),C(RP.$$.fragment,m),C(PP.$$.fragment,m),C(IP.$$.fragment,m),C(k7.$$.fragment,m),C(NP.$$.fragment,m),C(nL.$$.fragment,m),C(qP.$$.fragment,m),C(jP.$$.fragment,m),C(GP.$$.fragment,m),C(lL.$$.fragment,m),C(OP.$$.fragment,m),C(bL.$$.fragment,m),C(VP.$$.fragment,m),C(XP.$$.fragment,m),C(QP.$$.fragment,m),C(FL.$$.fragment,m),C(WP.$$.fragment,m),C(PL.$$.fragment,m),C(UP.$$.fragment,m),C(HP.$$.fragment,m),C(YP.$$.fragment,m),C(IL.$$.fragment,m),C(ZP.$$.fragment,m),C(WL.$$.fragment,m),C(KP.$$.fragment,m),C(eB.$$.fragment,m),C(rB.$$.fragment,m),C(HL.$$.fragment,m),C(tB.$$.fragment,m),C(s8.$$.fragment,m),C(aB.$$.fragment,m),C(nB.$$.fragment,m),C(lB.$$.fragment,m),C(i8.$$.fragment,m),C(iB.$$.fragment,m),C(v8.$$.fragment,m),C(dB.$$.fragment,m),C(cB.$$.fragment,m),C(fB.$$.fragment,m),C(T8.$$.fragment,m),C(gB.$$.fragment,m),C(S8.$$.fragment,m),C(hB.$$.fragment,m),C(uB.$$.fragment,m),C(_B.$$.fragment,m),C(P8.$$.fragment,m),C(bB.$$.fragment,m),C(V8.$$.fragment,m),C(vB.$$.fragment,m),C(FB.$$.fragment,m),C(MB.$$.fragment,m),C(z8.$$.fragment,m),C(EB.$$.fragment,m),C(ey.$$.fragment,m),C(CB.$$.fragment,m),C(wB.$$.fragment,m),C(LB.$$.fragment,m),C(ry.$$.fragment,m),C(yB.$$.fragment,m),C(ay.$$.fragment,m),C(xB.$$.fragment,m),C($B.$$.fragment,m),C(SB.$$.fragment,m),C(sy.$$.fragment,m),C(RB.$$.fragment,m),C(dy.$$.fragment,m),C(BB.$$.fragment,m),C(IB.$$.fragment,m),C(qB.$$.fragment,m),C(my.$$.fragment,m),C(jB.$$.fragment,m),C(gy.$$.fragment,m),nno=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Vf),m&&t(Ft),m&&t(Xe),m&&t(He),m&&t(zf),w(en,m),m&&t(Je),m&&t(Ae),m&&t(ko),m&&t(on),m&&t(Oro),m&&t(Ed),w(e$),m&&t(Vro),m&&t(hs),m&&t(Xro),w(o$,m),m&&t(zro),m&&t(_N),m&&t(Qro),w(Uf,m),m&&t(Wro),m&&t(Cd),w(r$),m&&t(Uro),m&&t(So),w(t$),w(s$),w(Mu),w(l$),m&&t(Hro),m&&t(Ad),w(i$),m&&t(Jro),m&&t(Ro),w(d$),w(f$),w(sp),w(g$),m&&t(Yro),m&&t(Ld),w(h$),m&&t(Zro),m&&t(Po),w(u$),w(b$),w(Zp),w(Kp),w(v$),m&&t(Kro),m&&t(yd),w(F$),m&&t(eto),m&&t(Bo),w(T$),w(C$),w(w_),w(A_),w(w$),m&&t(oto),m&&t($d),w(A$),m&&t(rto),m&&t(Io),w(L$),w(x$),w(x_),w($$),w(J2),m&&t(tto),m&&t(Rd),w(k$),m&&t(ato),m&&t(No),w(S$),w(P$),w(Z2),w(B$),w(Ub),m&&t(nto),m&&t(Id),w(I$),m&&t(sto),m&&t(qo),w(N$),w(j$),w(Jb),w(D$),w(Dv),m&&t(lto),m&&t(jd),w(G$),m&&t(ito),m&&t(jo),w(O$),w(X$),w(Ov),w(z$),w(Qv),m&&t(dto),m&&t(Od),w(W$),m&&t(cto),m&&t(Do),w(U$),w(J$),w(Uv),w(Y$),w(BF),m&&t(mto),m&&t(zd),w(Z$),m&&t(fto),m&&t(Go),w(K$),w(ok),w(NF),w(rk),w(nT),m&&t(gto),m&&t(Ud),w(tk),m&&t(hto),m&&t(Oo),w(ak),w(sk),w(lT),w(lk),w(mM),m&&t(uto),m&&t(Yd),w(ik),m&&t(pto),m&&t(Vo),w(dk),w(mk),w(gM),w(fk),w(WM),m&&t(_to),m&&t(ec),w(gk),m&&t(bto),m&&t(Xo),w(hk),w(pk),w(HM),w(_k),w(aE),m&&t(vto),m&&t(tc),w(bk),m&&t(Fto),m&&t(zo),w(vk),w(Tk),w(sE),w(Mk),w(HE),m&&t(Tto),m&&t(sc),w(Ek),m&&t(Mto),m&&t(Qo),w(Ck),w(Ak),w(YE),w(Lk),w(W4),m&&t(Eto),m&&t(dc),w(yk),m&&t(Cto),m&&t(Wo),w(xk),w(kk),w(H4),w(Sk),w(Z4),m&&t(wto),m&&t(fc),w(Rk),m&&t(Ato),m&&t(Uo),w(Pk),w(Ik),w(eC),w(Nk),w(nC),m&&t(Lto),m&&t(pc),w(qk),m&&t(yto),m&&t(Ho),w(jk),w(Gk),w(lC),w(Ok),w(CC),m&&t(xto),m&&t(vc),w(Vk),m&&t($to),m&&t(Jo),w(Xk),w(Qk),w(AC),w(Wk),w(xC),m&&t(kto),m&&t(Mc),w(Uk),m&&t(Sto),m&&t(Yo),w(Hk),w(Yk),w(kC),w(Zk),w(PC),m&&t(Rto),m&&t(wc),w(Kk),m&&t(Pto),m&&t(Zo),w(eS),w(rS),w(IC),w(tS),w(jC),m&&t(Bto),m&&t(yc),w(aS),m&&t(Ito),m&&t(Ko),w(nS),w(lS),w(GC),w(iS),w(ZC),m&&t(Nto),m&&t(kc),w(dS),m&&t(qto),m&&t(er),w(cS),w(fS),w(e3),w(gS),w(l3),m&&t(jto),m&&t(Pc),w(hS),m&&t(Dto),m&&t(or),w(uS),w(_S),w(d3),w(bS),w(T3),m&&t(Gto),m&&t(Nc),w(vS),m&&t(Oto),m&&t(rr),w(FS),w(MS),w(E3),w(ES),w(y3),m&&t(Vto),m&&t(Gc),w(CS),m&&t(Xto),m&&t(tr),w(wS),w(LS),w($3),w(yS),w(N3),m&&t(zto),m&&t(Xc),w(xS),m&&t(Qto),m&&t(ar),w($S),w(SS),w(j3),w(RS),w(z3),m&&t(Wto),m&&t(Wc),w(PS),m&&t(Uto),m&&t(nr),w(BS),w(NS),w(W3),w(qS),w(K3),m&&t(Hto),m&&t(Jc),w(jS),m&&t(Jto),m&&t(sr),w(DS),w(OS),w(o5),w(VS),w(a5),m&&t(Yto),m&&t(Kc),w(XS),m&&t(Zto),m&&t(lr),w(zS),w(WS),w(s5),w(US),w(g5),m&&t(Kto),m&&t(rm),w(HS),m&&t(eao),m&&t(ir),w(JS),w(ZS),w(u5),w(KS),w(b5),m&&t(oao),m&&t(nm),w(eR),m&&t(rao),m&&t(dr),w(oR),w(tR),w(F5),w(aR),w(E5),m&&t(tao),m&&t(im),w(nR),m&&t(aao),m&&t(cr),w(sR),w(iR),w(w5),w(dR),w(y0),m&&t(nao),m&&t(mm),w(cR),m&&t(sao),m&&t(mr),w(mR),w(gR),w($0),w(hR),w(ew),m&&t(lao),m&&t(hm),w(uR),m&&t(iao),m&&t(fr),w(pR),w(bR),w(rw),w(vR),w(_w),m&&t(dao),m&&t(_m),w(FR),m&&t(cao),m&&t(gr),w(TR),w(ER),w(vw),w(CR),w(xw),m&&t(mao),m&&t(Fm),w(wR),m&&t(fao),m&&t(hr),w(AR),w(yR),w(kw),w(xR),w(Bw),m&&t(gao),m&&t(Cm),w($R),m&&t(hao),m&&t(ur),w(kR),w(RR),w(Nw),w(PR),w(aA),m&&t(uao),m&&t(Lm),w(BR),m&&t(pao),m&&t(pr),w(IR),w(qR),w(sA),w(jR),w(_A),m&&t(_ao),m&&t($m),w(DR),m&&t(bao),m&&t(_r),w(GR),w(VR),w(vA),w(XR),w(WA),m&&t(vao),m&&t(Rm),w(zR),m&&t(Fao),m&&t(br),w(QR),w(UR),w(HA),w(HR),w(g6),m&&t(Tao),m&&t(Im),w(JR),m&&t(Mao),m&&t(vr),w(YR),w(KR),w(u6),w(eP),w(b6),m&&t(Eao),m&&t(jm),w(rP),m&&t(Cao),m&&t(Fr),w(tP),w(nP),w(F6),w(sP),w(M6),m&&t(wao),m&&t(Om),w(lP),m&&t(Aao),m&&t(Tr),w(iP),w(cP),w(C6),w(mP),w(A6),m&&t(Lao),m&&t(zm),w(fP),m&&t(yao),m&&t(Mr),w(gP),w(uP),w(y6),w(pP),w(J6),m&&t(xao),m&&t(Um),w(_P),m&&t($ao),m&&t(Er),w(bP),w(FP),w(Z6),w(TP),w(F7),m&&t(kao),m&&t(Ym),w(MP),m&&t(Sao),m&&t(Cr),w(EP),w(wP),w(M7),w(AP),w(C7),m&&t(Rao),m&&t(ef),w(LP),m&&t(Pao),m&&t(wr),w(yP),w($P),w(A7),w(kP),w(x7),m&&t(Bao),m&&t(tf),w(RP),m&&t(Iao),m&&t(Ar),w(PP),w(IP),w(k7),w(NP),w(nL),m&&t(Nao),m&&t(sf),w(qP),m&&t(qao),m&&t(Lr),w(jP),w(GP),w(lL),w(OP),w(bL),m&&t(jao),m&&t(cf),w(VP),m&&t(Dao),m&&t(yr),w(XP),w(QP),w(FL),w(WP),w(PL),m&&t(Gao),m&&t(gf),w(UP),m&&t(Oao),m&&t(xr),w(HP),w(YP),w(IL),w(ZP),w(WL),m&&t(Vao),m&&t(pf),w(KP),m&&t(Xao),m&&t($r),w(eB),w(rB),w(HL),w(tB),w(s8),m&&t(zao),m&&t(vf),w(aB),m&&t(Qao),m&&t(kr),w(nB),w(lB),w(i8),w(iB),w(v8),m&&t(Wao),m&&t(Mf),w(dB),m&&t(Uao),m&&t(Sr),w(cB),w(fB),w(T8),w(gB),w(S8),m&&t(Hao),m&&t(wf),w(hB),m&&t(Jao),m&&t(Rr),w(uB),w(_B),w(P8),w(bB),w(V8),m&&t(Yao),m&&t(yf),w(vB),m&&t(Zao),m&&t(Pr),w(FB),w(MB),w(z8),w(EB),w(ey),m&&t(Kao),m&&t(kf),w(CB),m&&t(eno),m&&t(Br),w(wB),w(LB),w(ry),w(yB),w(ay),m&&t(ono),m&&t(Pf),w(xB),m&&t(rno),m&&t(Ir),w($B),w(SB),w(sy),w(RB),w(dy),m&&t(tno),m&&t(Nf),w(BB),m&&t(ano),m&&t(Nr),w(IB),w(qB),w(my),w(jB),w(gy)}}}const z3a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Q3a($){return S4a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class K3a extends y4a{constructor(g){super();x4a(this,g,Q3a,X3a,$4a,{})}}export{K3a as default,z3a as metadata};
