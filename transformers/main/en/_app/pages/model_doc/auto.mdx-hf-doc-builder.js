import{S as v_a,i as F_a,s as T_a,e as a,k as l,w as F,t as o,M as M_a,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as E_a,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as kTt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as I}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function C_a($){let g,v,u,f,p,d,h,yo,td,Ef,pt,ad,nd,X9,Cf,Ve,He,sd,es,z9,os,rs,Q9,ld,ts,W9,id,wf,Qa;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),td=a("code"),Ef=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),ad=a("code"),nd=o('"new-model"'),X9=o(")."),Cf=l(),Ve=a("p"),He=o("Likewise, if your "),sd=a("code"),es=o("NewModel"),z9=o(" is a subclass of "),os=a("a"),rs=o("PreTrainedModel"),Q9=o(`, make sure its
`),ld=a("code"),ts=o("config_class"),W9=o(` attribute is set to the same class you use when registering the model (here
`),id=a("code"),wf=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var UB=s(u);f=r(UB,"NewModelConfig"),UB.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var dd=s(d);h=r(dd,"PretrainedConfig"),dd.forEach(t),yo=r(Ae,`, make sure its
`),td=n(Ae,"CODE",{});var HB=s(td);Ef=r(HB,"model_type"),HB.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),ad=n(Ae,"CODE",{});var JB=s(ad);nd=r(JB,'"new-model"'),JB.forEach(t),X9=r(Ae,")."),Ae.forEach(t),Cf=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),sd=n(xo,"CODE",{});var Wa=s(sd);es=r(Wa,"NewModel"),Wa.forEach(t),z9=r(xo," is a subclass of "),os=n(xo,"A",{href:!0});var YB=s(os);rs=r(YB,"PreTrainedModel"),YB.forEach(t),Q9=r(xo,`, make sure its
`),ld=n(xo,"CODE",{});var Af=s(ld);ts=r(Af,"config_class"),Af.forEach(t),W9=r(xo,` attribute is set to the same class you use when registering the model (here
`),id=n(xo,"CODE",{});var KB=s(id);wf=r(KB,"NewModelConfig"),KB.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){c(os,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,yo),e(g,td),e(td,Ef),e(g,pt),e(g,ad),e(ad,nd),e(g,X9),b(Je,Cf,Ae),b(Je,Ve,Ae),e(Ve,He),e(Ve,sd),e(sd,es),e(Ve,z9),e(Ve,os),e(os,rs),e(Ve,Q9),e(Ve,ld),e(ld,ts),e(Ve,W9),e(Ve,id),e(id,wf),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(Cf),Je&&t(Ve)}}}function w_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L_a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function y_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x_a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function $_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z_a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _ba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Tba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Eba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Aba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $ba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:N,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kba($){let g,v,u,f,p,d,h,yo,td,Ef,pt,ad,nd,X9,Cf,Ve,He,sd,es,z9,os,rs,Q9,ld,ts,W9,id,wf,Qa,Je,Ae,UB,dd,HB,JB,xo,Wa,YB,Af,KB,Qto,pZe,cd,Lf,Ode,U9,Wto,Vde,Uto,_Ze,as,Hto,Xde,Jto,Yto,zde,Kto,Zto,bZe,H9,vZe,ZB,eao,FZe,yf,TZe,md,xf,Qde,J9,oao,Wde,rao,MZe,$o,Y9,tao,K9,aao,eI,nao,sao,lao,Z9,iao,Ude,dao,cao,mao,Pr,ex,fao,Hde,gao,hao,fd,uao,Jde,pao,_ao,Yde,bao,vao,Fao,A,$f,Kde,Tao,Mao,oI,Eao,Cao,wao,kf,Zde,Aao,Lao,rI,yao,xao,$ao,Sf,ece,kao,Sao,tI,Rao,Pao,Bao,Rf,oce,Iao,Nao,aI,qao,jao,Dao,Pf,rce,Gao,Oao,nI,Vao,Xao,zao,Bf,tce,Qao,Wao,sI,Uao,Hao,Jao,If,ace,Yao,Kao,lI,Zao,eno,ono,Nf,nce,rno,tno,iI,ano,nno,sno,qf,sce,lno,ino,dI,dno,cno,mno,jf,lce,fno,gno,cI,hno,uno,pno,Df,ice,_no,bno,mI,vno,Fno,Tno,Gf,dce,Mno,Eno,fI,Cno,wno,Ano,Of,cce,Lno,yno,gI,xno,$no,kno,Vf,mce,Sno,Rno,hI,Pno,Bno,Ino,Xf,fce,Nno,qno,uI,jno,Dno,Gno,zf,gce,Ono,Vno,pI,Xno,zno,Qno,Qf,hce,Wno,Uno,_I,Hno,Jno,Yno,Wf,uce,Kno,Zno,bI,eso,oso,rso,Uf,pce,tso,aso,vI,nso,sso,lso,Hf,_ce,iso,dso,FI,cso,mso,fso,Jf,bce,gso,hso,TI,uso,pso,_so,Yf,vce,bso,vso,MI,Fso,Tso,Mso,Kf,Fce,Eso,Cso,EI,wso,Aso,Lso,Zf,Tce,yso,xso,CI,$so,kso,Sso,eg,Mce,Rso,Pso,wI,Bso,Iso,Nso,og,Ece,qso,jso,AI,Dso,Gso,Oso,rg,Cce,Vso,Xso,LI,zso,Qso,Wso,tg,wce,Uso,Hso,yI,Jso,Yso,Kso,ag,Ace,Zso,elo,xI,olo,rlo,tlo,ng,Lce,alo,nlo,$I,slo,llo,ilo,sg,yce,dlo,clo,kI,mlo,flo,glo,lg,xce,hlo,ulo,SI,plo,_lo,blo,ig,$ce,vlo,Flo,RI,Tlo,Mlo,Elo,dg,kce,Clo,wlo,PI,Alo,Llo,ylo,cg,Sce,xlo,$lo,BI,klo,Slo,Rlo,mg,Rce,Plo,Blo,II,Ilo,Nlo,qlo,fg,Pce,jlo,Dlo,NI,Glo,Olo,Vlo,gg,Bce,Xlo,zlo,qI,Qlo,Wlo,Ulo,hg,Ice,Hlo,Jlo,jI,Ylo,Klo,Zlo,ug,Nce,eio,oio,DI,rio,tio,aio,pg,qce,nio,sio,GI,lio,iio,dio,_g,jce,cio,mio,OI,fio,gio,hio,bg,Dce,uio,pio,VI,_io,bio,vio,vg,Gce,Fio,Tio,XI,Mio,Eio,Cio,Fg,Oce,wio,Aio,zI,Lio,yio,xio,Tg,Vce,$io,kio,QI,Sio,Rio,Pio,Mg,Xce,Bio,Iio,WI,Nio,qio,jio,Eg,zce,Dio,Gio,UI,Oio,Vio,Xio,Cg,Qce,zio,Qio,HI,Wio,Uio,Hio,wg,Wce,Jio,Yio,JI,Kio,Zio,edo,Ag,Uce,odo,rdo,YI,tdo,ado,ndo,Lg,Hce,sdo,ldo,KI,ido,ddo,cdo,yg,Jce,mdo,fdo,ZI,gdo,hdo,udo,xg,Yce,pdo,_do,eN,bdo,vdo,Fdo,$g,Kce,Tdo,Mdo,oN,Edo,Cdo,wdo,kg,Zce,Ado,Ldo,rN,ydo,xdo,$do,Sg,eme,kdo,Sdo,tN,Rdo,Pdo,Bdo,Rg,ome,Ido,Ndo,aN,qdo,jdo,Ddo,Pg,rme,Gdo,Odo,nN,Vdo,Xdo,zdo,Bg,tme,Qdo,Wdo,sN,Udo,Hdo,Jdo,Ig,ame,Ydo,Kdo,lN,Zdo,eco,oco,Ng,nme,rco,tco,iN,aco,nco,sco,qg,sme,lco,ico,dN,dco,cco,mco,jg,lme,fco,gco,cN,hco,uco,pco,Dg,ime,_co,bco,mN,vco,Fco,Tco,Gg,dme,Mco,Eco,fN,Cco,wco,Aco,Og,cme,Lco,yco,gN,xco,$co,kco,Vg,mme,Sco,Rco,hN,Pco,Bco,Ico,Xg,fme,Nco,qco,uN,jco,Dco,Gco,zg,gme,Oco,Vco,pN,Xco,zco,Qco,Qg,hme,Wco,Uco,_N,Hco,Jco,Yco,Wg,ume,Kco,Zco,bN,emo,omo,rmo,Ug,pme,tmo,amo,vN,nmo,smo,lmo,Hg,_me,imo,dmo,FN,cmo,mmo,fmo,Jg,bme,gmo,hmo,TN,umo,pmo,_mo,Yg,vme,bmo,vmo,MN,Fmo,Tmo,Mmo,Kg,Fme,Emo,Cmo,EN,wmo,Amo,Lmo,Zg,Tme,ymo,xmo,CN,$mo,kmo,Smo,eh,Mme,Rmo,Pmo,wN,Bmo,Imo,Nmo,oh,Eme,qmo,jmo,AN,Dmo,Gmo,Omo,rh,Cme,Vmo,Xmo,LN,zmo,Qmo,Wmo,th,wme,Umo,Hmo,yN,Jmo,Ymo,Kmo,ah,Ame,Zmo,efo,xN,ofo,rfo,tfo,nh,Lme,afo,nfo,$N,sfo,lfo,ifo,sh,yme,dfo,cfo,kN,mfo,ffo,gfo,lh,xme,hfo,ufo,SN,pfo,_fo,bfo,ih,$me,vfo,Ffo,RN,Tfo,Mfo,Efo,dh,kme,Cfo,wfo,PN,Afo,Lfo,yfo,ch,Sme,xfo,$fo,BN,kfo,Sfo,Rfo,mh,Rme,Pfo,Bfo,IN,Ifo,Nfo,qfo,fh,Pme,jfo,Dfo,NN,Gfo,Ofo,Vfo,gh,Bme,Xfo,zfo,qN,Qfo,Wfo,Ufo,hh,Ime,Hfo,Jfo,jN,Yfo,Kfo,Zfo,uh,Nme,ego,ogo,DN,rgo,tgo,ago,ph,qme,ngo,sgo,GN,lgo,igo,dgo,_h,jme,cgo,mgo,ON,fgo,ggo,hgo,bh,Dme,ugo,pgo,VN,_go,bgo,vgo,vh,Gme,Fgo,Tgo,XN,Mgo,Ego,Cgo,Fh,Ome,wgo,Ago,zN,Lgo,ygo,xgo,Th,Vme,$go,kgo,QN,Sgo,Rgo,Pgo,Mh,Xme,Bgo,Igo,WN,Ngo,qgo,jgo,Eh,zme,Dgo,Ggo,UN,Ogo,Vgo,Xgo,Ch,Qme,zgo,Qgo,HN,Wgo,Ugo,Hgo,wh,Wme,Jgo,Ygo,JN,Kgo,Zgo,eho,Ah,Ume,oho,rho,YN,tho,aho,nho,Lh,Hme,sho,lho,KN,iho,dho,cho,yh,Jme,mho,fho,ZN,gho,hho,uho,xh,Yme,pho,_ho,eq,bho,vho,Fho,$h,Kme,Tho,Mho,oq,Eho,Cho,who,kh,Zme,Aho,Lho,rq,yho,xho,$ho,Sh,efe,kho,Sho,tq,Rho,Pho,Bho,Rh,ofe,Iho,Nho,aq,qho,jho,Dho,Ph,rfe,Gho,Oho,nq,Vho,Xho,zho,Bh,tfe,Qho,Who,sq,Uho,Hho,Jho,Ih,afe,Yho,Kho,lq,Zho,euo,ouo,Nh,nfe,ruo,tuo,iq,auo,nuo,suo,qh,sfe,luo,iuo,dq,duo,cuo,muo,jh,lfe,fuo,guo,cq,huo,uuo,puo,Dh,ife,_uo,buo,mq,vuo,Fuo,Tuo,Gh,dfe,Muo,Euo,fq,Cuo,wuo,Auo,Oh,cfe,Luo,yuo,gq,xuo,$uo,kuo,Vh,mfe,Suo,Ruo,hq,Puo,Buo,Iuo,Xh,ffe,Nuo,quo,uq,juo,Duo,Guo,zh,gfe,Ouo,Vuo,pq,Xuo,zuo,Quo,Qh,hfe,Wuo,Uuo,_q,Huo,Juo,Yuo,Wh,ufe,Kuo,Zuo,bq,epo,opo,rpo,Uh,pfe,tpo,apo,vq,npo,spo,lpo,Hh,_fe,ipo,dpo,Fq,cpo,mpo,fpo,Jh,bfe,gpo,hpo,Tq,upo,ppo,_po,Yh,vfe,bpo,vpo,Mq,Fpo,Tpo,Mpo,Kh,Epo,Zh,ox,Cpo,Ffe,wpo,EZe,gd,eu,Tfe,rx,Apo,Mfe,Lpo,CZe,ko,tx,ypo,ax,xpo,Eq,$po,kpo,Spo,nx,Rpo,Efe,Ppo,Bpo,Ipo,Br,sx,Npo,Cfe,qpo,jpo,Ua,Dpo,wfe,Gpo,Opo,Afe,Vpo,Xpo,Lfe,zpo,Qpo,Wpo,k,ns,yfe,Upo,Hpo,Cq,Jpo,Ypo,wq,Kpo,Zpo,e_o,ss,xfe,o_o,r_o,Aq,t_o,a_o,Lq,n_o,s_o,l_o,ls,$fe,i_o,d_o,yq,c_o,m_o,xq,f_o,g_o,h_o,ou,kfe,u_o,p_o,$q,__o,b_o,v_o,is,Sfe,F_o,T_o,kq,M_o,E_o,Sq,C_o,w_o,A_o,ru,Rfe,L_o,y_o,Rq,x_o,$_o,k_o,tu,Pfe,S_o,R_o,Pq,P_o,B_o,I_o,au,Bfe,N_o,q_o,Bq,j_o,D_o,G_o,ds,Ife,O_o,V_o,Iq,X_o,z_o,Nq,Q_o,W_o,U_o,cs,Nfe,H_o,J_o,qq,Y_o,K_o,jq,Z_o,e2o,o2o,ms,qfe,r2o,t2o,Dq,a2o,n2o,Gq,s2o,l2o,i2o,nu,jfe,d2o,c2o,Oq,m2o,f2o,g2o,su,Dfe,h2o,u2o,Vq,p2o,_2o,b2o,lu,Gfe,v2o,F2o,Xq,T2o,M2o,E2o,fs,Ofe,C2o,w2o,zq,A2o,L2o,Qq,y2o,x2o,$2o,iu,Vfe,k2o,S2o,Wq,R2o,P2o,B2o,gs,Xfe,I2o,N2o,Uq,q2o,j2o,Hq,D2o,G2o,O2o,hs,zfe,V2o,X2o,Jq,z2o,Q2o,Yq,W2o,U2o,H2o,us,Qfe,J2o,Y2o,Kq,K2o,Z2o,Zq,ebo,obo,rbo,ps,Wfe,tbo,abo,ej,nbo,sbo,oj,lbo,ibo,dbo,du,Ufe,cbo,mbo,rj,fbo,gbo,hbo,_s,Hfe,ubo,pbo,tj,_bo,bbo,aj,vbo,Fbo,Tbo,bs,Jfe,Mbo,Ebo,nj,Cbo,wbo,sj,Abo,Lbo,ybo,vs,Yfe,xbo,$bo,lj,kbo,Sbo,ij,Rbo,Pbo,Bbo,Fs,Kfe,Ibo,Nbo,dj,qbo,jbo,cj,Dbo,Gbo,Obo,Ts,Zfe,Vbo,Xbo,mj,zbo,Qbo,fj,Wbo,Ubo,Hbo,Ms,ege,Jbo,Ybo,gj,Kbo,Zbo,hj,e1o,o1o,r1o,Es,oge,t1o,a1o,uj,n1o,s1o,pj,l1o,i1o,d1o,cu,rge,c1o,m1o,_j,f1o,g1o,h1o,Cs,tge,u1o,p1o,bj,_1o,b1o,vj,v1o,F1o,T1o,mu,age,M1o,E1o,Fj,C1o,w1o,A1o,ws,nge,L1o,y1o,Tj,x1o,$1o,Mj,k1o,S1o,R1o,As,sge,P1o,B1o,Ej,I1o,N1o,Cj,q1o,j1o,D1o,Ls,lge,G1o,O1o,wj,V1o,X1o,Aj,z1o,Q1o,W1o,fu,ige,U1o,H1o,Lj,J1o,Y1o,K1o,gu,dge,Z1o,evo,yj,ovo,rvo,tvo,ys,cge,avo,nvo,xj,svo,lvo,$j,ivo,dvo,cvo,xs,mge,mvo,fvo,kj,gvo,hvo,Sj,uvo,pvo,_vo,$s,fge,bvo,vvo,Rj,Fvo,Tvo,Pj,Mvo,Evo,Cvo,hu,gge,wvo,Avo,Bj,Lvo,yvo,xvo,ks,hge,$vo,kvo,Ij,Svo,Rvo,Nj,Pvo,Bvo,Ivo,Ss,uge,Nvo,qvo,qj,jvo,Dvo,jj,Gvo,Ovo,Vvo,Rs,pge,Xvo,zvo,Dj,Qvo,Wvo,Gj,Uvo,Hvo,Jvo,Ps,_ge,Yvo,Kvo,Oj,Zvo,eFo,Vj,oFo,rFo,tFo,Bs,bge,aFo,nFo,Xj,sFo,lFo,zj,iFo,dFo,cFo,Is,vge,mFo,fFo,Qj,gFo,hFo,Wj,uFo,pFo,_Fo,Ns,Fge,bFo,vFo,Uj,FFo,TFo,Hj,MFo,EFo,CFo,qs,Tge,wFo,AFo,Jj,LFo,yFo,Yj,xFo,$Fo,kFo,uu,Mge,SFo,RFo,Kj,PFo,BFo,IFo,js,Ege,NFo,qFo,Zj,jFo,DFo,eD,GFo,OFo,VFo,pu,Cge,XFo,zFo,oD,QFo,WFo,UFo,_u,wge,HFo,JFo,rD,YFo,KFo,ZFo,Ds,Age,eTo,oTo,tD,rTo,tTo,aD,aTo,nTo,sTo,Gs,Lge,lTo,iTo,nD,dTo,cTo,sD,mTo,fTo,gTo,Os,yge,hTo,uTo,lD,pTo,_To,iD,bTo,vTo,FTo,bu,xge,TTo,MTo,dD,ETo,CTo,wTo,Vs,$ge,ATo,LTo,cD,yTo,xTo,mD,$To,kTo,STo,Xs,kge,RTo,PTo,fD,BTo,ITo,gD,NTo,qTo,jTo,zs,Sge,DTo,GTo,hD,OTo,VTo,uD,XTo,zTo,QTo,Qs,Rge,WTo,UTo,pD,HTo,JTo,_D,YTo,KTo,ZTo,Ws,Pge,eMo,oMo,bD,rMo,tMo,vD,aMo,nMo,sMo,Us,Bge,lMo,iMo,FD,dMo,cMo,TD,mMo,fMo,gMo,Hs,Ige,hMo,uMo,MD,pMo,_Mo,ED,bMo,vMo,FMo,Js,Nge,TMo,MMo,CD,EMo,CMo,wD,wMo,AMo,LMo,vu,qge,yMo,xMo,AD,$Mo,kMo,SMo,Ys,jge,RMo,PMo,LD,BMo,IMo,yD,NMo,qMo,jMo,Ks,Dge,DMo,GMo,xD,OMo,VMo,$D,XMo,zMo,QMo,Fu,Gge,WMo,UMo,kD,HMo,JMo,YMo,Tu,Oge,KMo,ZMo,SD,eEo,oEo,rEo,Mu,Vge,tEo,aEo,RD,nEo,sEo,lEo,Eu,Xge,iEo,dEo,PD,cEo,mEo,fEo,Zs,zge,gEo,hEo,BD,uEo,pEo,ID,_Eo,bEo,vEo,Cu,Qge,FEo,TEo,ND,MEo,EEo,CEo,el,Wge,wEo,AEo,qD,LEo,yEo,jD,xEo,$Eo,kEo,ol,Uge,SEo,REo,DD,PEo,BEo,GD,IEo,NEo,qEo,rl,Hge,jEo,DEo,OD,GEo,OEo,VD,VEo,XEo,zEo,tl,Jge,QEo,WEo,XD,UEo,HEo,zD,JEo,YEo,KEo,al,Yge,ZEo,e4o,QD,o4o,r4o,WD,t4o,a4o,n4o,nl,Kge,s4o,l4o,UD,i4o,d4o,HD,c4o,m4o,f4o,wu,Zge,g4o,h4o,JD,u4o,p4o,_4o,Au,ehe,b4o,v4o,YD,F4o,T4o,M4o,sl,ohe,E4o,C4o,KD,w4o,A4o,ZD,L4o,y4o,x4o,ll,rhe,$4o,k4o,eG,S4o,R4o,oG,P4o,B4o,I4o,il,the,N4o,q4o,rG,j4o,D4o,tG,G4o,O4o,V4o,Lu,ahe,X4o,z4o,aG,Q4o,W4o,U4o,yu,nhe,H4o,J4o,nG,Y4o,K4o,Z4o,xu,she,eCo,oCo,sG,rCo,tCo,aCo,dl,lhe,nCo,sCo,lG,lCo,iCo,iG,dCo,cCo,mCo,cl,ihe,fCo,gCo,dG,hCo,uCo,cG,pCo,_Co,bCo,$u,dhe,vCo,FCo,mG,TCo,MCo,ECo,ku,che,CCo,wCo,fG,ACo,LCo,yCo,Su,mhe,xCo,$Co,gG,kCo,SCo,RCo,ml,fhe,PCo,BCo,hG,ICo,NCo,uG,qCo,jCo,DCo,fl,ghe,GCo,OCo,pG,VCo,XCo,_G,zCo,QCo,WCo,Ru,hhe,UCo,HCo,bG,JCo,YCo,KCo,Pu,uhe,ZCo,e3o,vG,o3o,r3o,t3o,gl,phe,a3o,n3o,FG,s3o,l3o,TG,i3o,d3o,c3o,hl,_he,m3o,f3o,MG,g3o,h3o,EG,u3o,p3o,_3o,ul,bhe,b3o,v3o,CG,F3o,T3o,wG,M3o,E3o,C3o,pl,vhe,w3o,A3o,AG,L3o,y3o,LG,x3o,$3o,k3o,Bu,S3o,Iu,lx,R3o,Fhe,P3o,wZe,hd,Nu,The,ix,B3o,Mhe,I3o,AZe,So,dx,N3o,cx,q3o,yG,j3o,D3o,G3o,mx,O3o,Ehe,V3o,X3o,z3o,Ye,fx,Q3o,Che,W3o,U3o,Ha,H3o,whe,J3o,Y3o,Ahe,K3o,Z3o,Lhe,e5o,o5o,r5o,z,qu,yhe,t5o,a5o,xG,n5o,s5o,l5o,ju,xhe,i5o,d5o,$G,c5o,m5o,f5o,Du,$he,g5o,h5o,kG,u5o,p5o,_5o,Gu,khe,b5o,v5o,SG,F5o,T5o,M5o,Ou,She,E5o,C5o,RG,w5o,A5o,L5o,Vu,Rhe,y5o,x5o,PG,$5o,k5o,S5o,Xu,Phe,R5o,P5o,BG,B5o,I5o,N5o,zu,Bhe,q5o,j5o,IG,D5o,G5o,O5o,Qu,Ihe,V5o,X5o,NG,z5o,Q5o,W5o,Wu,Nhe,U5o,H5o,qG,J5o,Y5o,K5o,Uu,qhe,Z5o,e0o,jG,o0o,r0o,t0o,Hu,jhe,a0o,n0o,DG,s0o,l0o,i0o,Ju,Dhe,d0o,c0o,GG,m0o,f0o,g0o,Yu,Ghe,h0o,u0o,OG,p0o,_0o,b0o,Ku,Ohe,v0o,F0o,VG,T0o,M0o,E0o,Zu,Vhe,C0o,w0o,XG,A0o,L0o,y0o,ep,Xhe,x0o,$0o,zG,k0o,S0o,R0o,op,zhe,P0o,B0o,QG,I0o,N0o,q0o,rp,Qhe,j0o,D0o,WG,G0o,O0o,V0o,tp,Whe,X0o,z0o,UG,Q0o,W0o,U0o,ap,Uhe,H0o,J0o,HG,Y0o,K0o,Z0o,np,Hhe,ewo,owo,JG,rwo,two,awo,sp,Jhe,nwo,swo,YG,lwo,iwo,dwo,lp,Yhe,cwo,mwo,KG,fwo,gwo,hwo,ip,Khe,uwo,pwo,ZG,_wo,bwo,vwo,dp,Zhe,Fwo,Two,eO,Mwo,Ewo,Cwo,cp,eue,wwo,Awo,oO,Lwo,ywo,xwo,mp,oue,$wo,kwo,rO,Swo,Rwo,Pwo,fp,rue,Bwo,Iwo,tO,Nwo,qwo,jwo,gp,tue,Dwo,Gwo,aO,Owo,Vwo,Xwo,hp,aue,zwo,Qwo,nO,Wwo,Uwo,Hwo,up,nue,Jwo,Ywo,sO,Kwo,Zwo,eAo,pp,sue,oAo,rAo,lO,tAo,aAo,nAo,_p,lue,sAo,lAo,iO,iAo,dAo,cAo,bp,iue,mAo,fAo,dO,gAo,hAo,uAo,vp,due,pAo,_Ao,cO,bAo,vAo,FAo,Fp,cue,TAo,MAo,mO,EAo,CAo,wAo,Tp,mue,AAo,LAo,fO,yAo,xAo,$Ao,Mp,fue,kAo,SAo,gO,RAo,PAo,BAo,Ep,gue,IAo,NAo,hO,qAo,jAo,DAo,Cp,hue,GAo,OAo,uO,VAo,XAo,zAo,wp,uue,QAo,WAo,pO,UAo,HAo,JAo,Ap,YAo,Lp,KAo,yp,gx,ZAo,pue,e6o,LZe,ud,xp,_ue,hx,o6o,bue,r6o,yZe,Ro,ux,t6o,px,a6o,_O,n6o,s6o,l6o,_x,i6o,vue,d6o,c6o,m6o,Ke,bx,f6o,Fue,g6o,h6o,pd,u6o,Tue,p6o,_6o,Mue,b6o,v6o,F6o,le,$p,Eue,T6o,M6o,bO,E6o,C6o,w6o,kp,Cue,A6o,L6o,vO,y6o,x6o,$6o,Sp,wue,k6o,S6o,FO,R6o,P6o,B6o,Rp,Aue,I6o,N6o,TO,q6o,j6o,D6o,Pp,Lue,G6o,O6o,MO,V6o,X6o,z6o,Bp,yue,Q6o,W6o,EO,U6o,H6o,J6o,Ip,xue,Y6o,K6o,CO,Z6o,e7o,o7o,Np,$ue,r7o,t7o,wO,a7o,n7o,s7o,qp,kue,l7o,i7o,AO,d7o,c7o,m7o,jp,Sue,f7o,g7o,LO,h7o,u7o,p7o,Dp,Rue,_7o,b7o,yO,v7o,F7o,T7o,Gp,Pue,M7o,E7o,xO,C7o,w7o,A7o,Op,Bue,L7o,y7o,$O,x7o,$7o,k7o,Vp,Iue,S7o,R7o,kO,P7o,B7o,I7o,Xp,Nue,N7o,q7o,SO,j7o,D7o,G7o,zp,que,O7o,V7o,RO,X7o,z7o,Q7o,Qp,jue,W7o,U7o,PO,H7o,J7o,Y7o,Wp,Due,K7o,Z7o,BO,eLo,oLo,rLo,Up,Gue,tLo,aLo,IO,nLo,sLo,lLo,Hp,Oue,iLo,dLo,NO,cLo,mLo,fLo,Jp,Vue,gLo,hLo,qO,uLo,pLo,_Lo,Yp,Xue,bLo,vLo,jO,FLo,TLo,MLo,Kp,ELo,Zp,CLo,e_,vx,wLo,zue,ALo,xZe,_d,o_,Que,Fx,LLo,Wue,yLo,$Ze,Po,Tx,xLo,bd,$Lo,DO,kLo,SLo,GO,RLo,PLo,BLo,Mx,ILo,Uue,NLo,qLo,jLo,_t,Ex,DLo,Hue,GLo,OLo,vd,VLo,Jue,XLo,zLo,OO,QLo,WLo,ULo,r_,HLo,Ze,Cx,JLo,Yue,YLo,KLo,Ja,ZLo,Kue,eyo,oyo,Zue,ryo,tyo,epe,ayo,nyo,syo,y,t_,ope,lyo,iyo,VO,dyo,cyo,myo,a_,rpe,fyo,gyo,XO,hyo,uyo,pyo,n_,tpe,_yo,byo,zO,vyo,Fyo,Tyo,s_,ape,Myo,Eyo,QO,Cyo,wyo,Ayo,l_,npe,Lyo,yyo,WO,xyo,$yo,kyo,i_,spe,Syo,Ryo,UO,Pyo,Byo,Iyo,d_,lpe,Nyo,qyo,HO,jyo,Dyo,Gyo,c_,ipe,Oyo,Vyo,JO,Xyo,zyo,Qyo,m_,dpe,Wyo,Uyo,YO,Hyo,Jyo,Yyo,f_,cpe,Kyo,Zyo,KO,e8o,o8o,r8o,g_,mpe,t8o,a8o,ZO,n8o,s8o,l8o,h_,fpe,i8o,d8o,eV,c8o,m8o,f8o,u_,gpe,g8o,h8o,oV,u8o,p8o,_8o,p_,hpe,b8o,v8o,rV,F8o,T8o,M8o,__,upe,E8o,C8o,tV,w8o,A8o,L8o,b_,ppe,y8o,x8o,aV,$8o,k8o,S8o,v_,_pe,R8o,P8o,nV,B8o,I8o,N8o,F_,bpe,q8o,j8o,sV,D8o,G8o,O8o,T_,vpe,V8o,X8o,lV,z8o,Q8o,W8o,M_,Fpe,U8o,H8o,iV,J8o,Y8o,K8o,E_,Tpe,Z8o,e9o,dV,o9o,r9o,t9o,C_,Mpe,a9o,n9o,cV,s9o,l9o,i9o,w_,Epe,d9o,c9o,mV,m9o,f9o,g9o,A_,Cpe,h9o,u9o,fV,p9o,_9o,b9o,L_,wpe,v9o,F9o,gV,T9o,M9o,E9o,y_,Ape,C9o,w9o,hV,A9o,L9o,y9o,x_,Lpe,x9o,$9o,uV,k9o,S9o,R9o,$_,ype,P9o,B9o,pV,I9o,N9o,q9o,k_,xpe,j9o,D9o,_V,G9o,O9o,V9o,S_,$pe,X9o,z9o,bV,Q9o,W9o,U9o,R_,kpe,H9o,J9o,vV,Y9o,K9o,Z9o,P_,Spe,exo,oxo,FV,rxo,txo,axo,B_,Rpe,nxo,sxo,TV,lxo,ixo,dxo,I_,Ppe,cxo,mxo,MV,fxo,gxo,hxo,N_,Bpe,uxo,pxo,EV,_xo,bxo,vxo,q_,Ipe,Fxo,Txo,CV,Mxo,Exo,Cxo,j_,Npe,wxo,Axo,wV,Lxo,yxo,xxo,D_,qpe,$xo,kxo,AV,Sxo,Rxo,Pxo,_l,jpe,Bxo,Ixo,LV,Nxo,qxo,yV,jxo,Dxo,Gxo,G_,Dpe,Oxo,Vxo,xV,Xxo,zxo,Qxo,O_,Gpe,Wxo,Uxo,$V,Hxo,Jxo,Yxo,V_,Ope,Kxo,Zxo,kV,e$o,o$o,r$o,X_,Vpe,t$o,a$o,SV,n$o,s$o,l$o,z_,Xpe,i$o,d$o,RV,c$o,m$o,f$o,Q_,zpe,g$o,h$o,PV,u$o,p$o,_$o,W_,Qpe,b$o,v$o,BV,F$o,T$o,M$o,U_,Wpe,E$o,C$o,IV,w$o,A$o,L$o,H_,Upe,y$o,x$o,NV,$$o,k$o,S$o,J_,Hpe,R$o,P$o,qV,B$o,I$o,N$o,Y_,Jpe,q$o,j$o,jV,D$o,G$o,O$o,K_,Ype,V$o,X$o,DV,z$o,Q$o,W$o,Z_,Kpe,U$o,H$o,GV,J$o,Y$o,K$o,e2,Zpe,Z$o,eko,OV,oko,rko,tko,o2,e_e,ako,nko,VV,sko,lko,iko,r2,o_e,dko,cko,XV,mko,fko,gko,t2,r_e,hko,uko,zV,pko,_ko,bko,a2,t_e,vko,Fko,QV,Tko,Mko,Eko,n2,a_e,Cko,wko,WV,Ako,Lko,yko,s2,n_e,xko,$ko,UV,kko,Sko,Rko,l2,s_e,Pko,Bko,HV,Iko,Nko,qko,i2,l_e,jko,Dko,JV,Gko,Oko,Vko,d2,i_e,Xko,zko,YV,Qko,Wko,Uko,c2,d_e,Hko,Jko,KV,Yko,Kko,Zko,m2,c_e,eSo,oSo,ZV,rSo,tSo,aSo,f2,m_e,nSo,sSo,eX,lSo,iSo,dSo,g2,f_e,cSo,mSo,oX,fSo,gSo,hSo,h2,g_e,uSo,pSo,rX,_So,bSo,vSo,u2,h_e,FSo,TSo,tX,MSo,ESo,CSo,p2,u_e,wSo,ASo,aX,LSo,ySo,xSo,_2,p_e,$So,kSo,nX,SSo,RSo,PSo,b2,__e,BSo,ISo,sX,NSo,qSo,jSo,v2,b_e,DSo,GSo,lX,OSo,VSo,XSo,F2,v_e,zSo,QSo,iX,WSo,USo,HSo,T2,F_e,JSo,YSo,dX,KSo,ZSo,eRo,M2,T_e,oRo,rRo,cX,tRo,aRo,nRo,E2,M_e,sRo,lRo,mX,iRo,dRo,cRo,C2,E_e,mRo,fRo,fX,gRo,hRo,uRo,w2,C_e,pRo,_Ro,gX,bRo,vRo,FRo,A2,w_e,TRo,MRo,hX,ERo,CRo,wRo,L2,A_e,ARo,LRo,uX,yRo,xRo,$Ro,y2,L_e,kRo,SRo,pX,RRo,PRo,BRo,x2,y_e,IRo,NRo,_X,qRo,jRo,DRo,$2,x_e,GRo,ORo,bX,VRo,XRo,zRo,k2,$_e,QRo,WRo,vX,URo,HRo,JRo,S2,k_e,YRo,KRo,FX,ZRo,ePo,oPo,R2,S_e,rPo,tPo,TX,aPo,nPo,sPo,P2,R_e,lPo,iPo,MX,dPo,cPo,mPo,B2,P_e,fPo,gPo,EX,hPo,uPo,pPo,I2,B_e,_Po,bPo,CX,vPo,FPo,TPo,N2,I_e,MPo,EPo,wX,CPo,wPo,APo,q2,N_e,LPo,yPo,AX,xPo,$Po,kPo,j2,q_e,SPo,RPo,LX,PPo,BPo,IPo,D2,j_e,NPo,qPo,yX,jPo,DPo,GPo,G2,D_e,OPo,VPo,xX,XPo,zPo,QPo,O2,G_e,WPo,UPo,$X,HPo,JPo,YPo,V2,O_e,KPo,ZPo,kX,eBo,oBo,rBo,X2,V_e,tBo,aBo,SX,nBo,sBo,lBo,z2,X_e,iBo,dBo,RX,cBo,mBo,fBo,Q2,z_e,gBo,hBo,PX,uBo,pBo,_Bo,W2,Q_e,bBo,vBo,BX,FBo,TBo,MBo,U2,W_e,EBo,CBo,IX,wBo,ABo,LBo,H2,U_e,yBo,xBo,NX,$Bo,kBo,SBo,J2,H_e,RBo,PBo,qX,BBo,IBo,NBo,Y2,J_e,qBo,jBo,jX,DBo,GBo,OBo,K2,Y_e,VBo,XBo,DX,zBo,QBo,WBo,Z2,K_e,UBo,HBo,GX,JBo,YBo,KBo,eb,Z_e,ZBo,eIo,OX,oIo,rIo,tIo,ob,e2e,aIo,nIo,VX,sIo,lIo,iIo,rb,o2e,dIo,cIo,XX,mIo,fIo,gIo,tb,r2e,hIo,uIo,zX,pIo,_Io,bIo,ab,t2e,vIo,FIo,QX,TIo,MIo,EIo,nb,a2e,CIo,wIo,WX,AIo,LIo,yIo,sb,n2e,xIo,$Io,UX,kIo,SIo,RIo,lb,s2e,PIo,BIo,HX,IIo,NIo,qIo,ib,l2e,jIo,DIo,JX,GIo,OIo,VIo,db,i2e,XIo,zIo,YX,QIo,WIo,UIo,cb,d2e,HIo,JIo,KX,YIo,KIo,ZIo,mb,c2e,eNo,oNo,ZX,rNo,tNo,aNo,fb,m2e,nNo,sNo,ez,lNo,iNo,dNo,gb,f2e,cNo,mNo,oz,fNo,gNo,hNo,hb,g2e,uNo,pNo,rz,_No,bNo,vNo,ub,h2e,FNo,TNo,tz,MNo,ENo,CNo,pb,u2e,wNo,ANo,az,LNo,yNo,xNo,_b,p2e,$No,kNo,nz,SNo,RNo,PNo,bb,BNo,_2e,INo,NNo,b2e,qNo,jNo,vb,kZe,Fd,Fb,v2e,wx,DNo,F2e,GNo,SZe,Bo,Ax,ONo,Td,VNo,sz,XNo,zNo,lz,QNo,WNo,UNo,Lx,HNo,T2e,JNo,YNo,KNo,bt,yx,ZNo,M2e,eqo,oqo,Md,rqo,E2e,tqo,aqo,iz,nqo,sqo,lqo,Tb,iqo,eo,xx,dqo,C2e,cqo,mqo,Ya,fqo,w2e,gqo,hqo,A2e,uqo,pqo,L2e,_qo,bqo,vqo,G,Mb,y2e,Fqo,Tqo,dz,Mqo,Eqo,Cqo,Eb,x2e,wqo,Aqo,cz,Lqo,yqo,xqo,Cb,$2e,$qo,kqo,mz,Sqo,Rqo,Pqo,wb,k2e,Bqo,Iqo,fz,Nqo,qqo,jqo,Ab,S2e,Dqo,Gqo,gz,Oqo,Vqo,Xqo,Lb,R2e,zqo,Qqo,hz,Wqo,Uqo,Hqo,yb,P2e,Jqo,Yqo,uz,Kqo,Zqo,ejo,xb,B2e,ojo,rjo,pz,tjo,ajo,njo,$b,I2e,sjo,ljo,_z,ijo,djo,cjo,kb,N2e,mjo,fjo,bz,gjo,hjo,ujo,Sb,q2e,pjo,_jo,vz,bjo,vjo,Fjo,Rb,j2e,Tjo,Mjo,Fz,Ejo,Cjo,wjo,Pb,D2e,Ajo,Ljo,Tz,yjo,xjo,$jo,Bb,G2e,kjo,Sjo,Mz,Rjo,Pjo,Bjo,Ib,O2e,Ijo,Njo,Ez,qjo,jjo,Djo,Nb,V2e,Gjo,Ojo,Cz,Vjo,Xjo,zjo,qb,X2e,Qjo,Wjo,wz,Ujo,Hjo,Jjo,jb,z2e,Yjo,Kjo,Az,Zjo,eDo,oDo,Db,Q2e,rDo,tDo,Lz,aDo,nDo,sDo,Gb,W2e,lDo,iDo,yz,dDo,cDo,mDo,Ob,U2e,fDo,gDo,xz,hDo,uDo,pDo,Vb,H2e,_Do,bDo,$z,vDo,FDo,TDo,Xb,J2e,MDo,EDo,kz,CDo,wDo,ADo,zb,Y2e,LDo,yDo,Sz,xDo,$Do,kDo,Qb,K2e,SDo,RDo,Rz,PDo,BDo,IDo,Wb,Z2e,NDo,qDo,Pz,jDo,DDo,GDo,Ub,ebe,ODo,VDo,Bz,XDo,zDo,QDo,Hb,obe,WDo,UDo,Iz,HDo,JDo,YDo,Jb,rbe,KDo,ZDo,Nz,eGo,oGo,rGo,Yb,tbe,tGo,aGo,qz,nGo,sGo,lGo,Kb,abe,iGo,dGo,jz,cGo,mGo,fGo,Zb,nbe,gGo,hGo,Dz,uGo,pGo,_Go,e1,sbe,bGo,vGo,Gz,FGo,TGo,MGo,o1,lbe,EGo,CGo,Oz,wGo,AGo,LGo,r1,ibe,yGo,xGo,Vz,$Go,kGo,SGo,t1,dbe,RGo,PGo,Xz,BGo,IGo,NGo,a1,cbe,qGo,jGo,zz,DGo,GGo,OGo,n1,mbe,VGo,XGo,Qz,zGo,QGo,WGo,s1,fbe,UGo,HGo,Wz,JGo,YGo,KGo,l1,gbe,ZGo,eOo,Uz,oOo,rOo,tOo,i1,hbe,aOo,nOo,Hz,sOo,lOo,iOo,d1,ube,dOo,cOo,Jz,mOo,fOo,gOo,c1,pbe,hOo,uOo,Yz,pOo,_Oo,bOo,m1,_be,vOo,FOo,Kz,TOo,MOo,EOo,f1,bbe,COo,wOo,Zz,AOo,LOo,yOo,g1,vbe,xOo,$Oo,eQ,kOo,SOo,ROo,h1,Fbe,POo,BOo,oQ,IOo,NOo,qOo,u1,Tbe,jOo,DOo,rQ,GOo,OOo,VOo,p1,XOo,Mbe,zOo,QOo,Ebe,WOo,UOo,_1,RZe,Ed,b1,Cbe,$x,HOo,wbe,JOo,PZe,Io,kx,YOo,Cd,KOo,tQ,ZOo,eVo,aQ,oVo,rVo,tVo,Sx,aVo,Abe,nVo,sVo,lVo,vt,Rx,iVo,Lbe,dVo,cVo,wd,mVo,ybe,fVo,gVo,nQ,hVo,uVo,pVo,v1,_Vo,oo,Px,bVo,xbe,vVo,FVo,Ka,TVo,$be,MVo,EVo,kbe,CVo,wVo,Sbe,AVo,LVo,yVo,Q,F1,Rbe,xVo,$Vo,sQ,kVo,SVo,RVo,T1,Pbe,PVo,BVo,lQ,IVo,NVo,qVo,M1,Bbe,jVo,DVo,iQ,GVo,OVo,VVo,E1,Ibe,XVo,zVo,dQ,QVo,WVo,UVo,C1,Nbe,HVo,JVo,cQ,YVo,KVo,ZVo,w1,qbe,eXo,oXo,mQ,rXo,tXo,aXo,A1,jbe,nXo,sXo,fQ,lXo,iXo,dXo,L1,Dbe,cXo,mXo,gQ,fXo,gXo,hXo,y1,Gbe,uXo,pXo,hQ,_Xo,bXo,vXo,x1,Obe,FXo,TXo,uQ,MXo,EXo,CXo,$1,Vbe,wXo,AXo,pQ,LXo,yXo,xXo,k1,Xbe,$Xo,kXo,_Q,SXo,RXo,PXo,S1,zbe,BXo,IXo,bQ,NXo,qXo,jXo,R1,Qbe,DXo,GXo,vQ,OXo,VXo,XXo,P1,Wbe,zXo,QXo,FQ,WXo,UXo,HXo,B1,Ube,JXo,YXo,TQ,KXo,ZXo,ezo,I1,Hbe,ozo,rzo,MQ,tzo,azo,nzo,N1,Jbe,szo,lzo,EQ,izo,dzo,czo,q1,Ybe,mzo,fzo,CQ,gzo,hzo,uzo,j1,Kbe,pzo,_zo,wQ,bzo,vzo,Fzo,D1,Zbe,Tzo,Mzo,AQ,Ezo,Czo,wzo,G1,e1e,Azo,Lzo,LQ,yzo,xzo,$zo,O1,o1e,kzo,Szo,yQ,Rzo,Pzo,Bzo,V1,r1e,Izo,Nzo,xQ,qzo,jzo,Dzo,X1,t1e,Gzo,Ozo,$Q,Vzo,Xzo,zzo,z1,a1e,Qzo,Wzo,kQ,Uzo,Hzo,Jzo,Q1,n1e,Yzo,Kzo,SQ,Zzo,eQo,oQo,W1,s1e,rQo,tQo,RQ,aQo,nQo,sQo,U1,l1e,lQo,iQo,PQ,dQo,cQo,mQo,H1,i1e,fQo,gQo,BQ,hQo,uQo,pQo,J1,d1e,_Qo,bQo,IQ,vQo,FQo,TQo,Y1,c1e,MQo,EQo,NQ,CQo,wQo,AQo,K1,m1e,LQo,yQo,qQ,xQo,$Qo,kQo,Z1,f1e,SQo,RQo,jQ,PQo,BQo,IQo,ev,g1e,NQo,qQo,DQ,jQo,DQo,GQo,ov,h1e,OQo,VQo,GQ,XQo,zQo,QQo,rv,u1e,WQo,UQo,OQ,HQo,JQo,YQo,tv,p1e,KQo,ZQo,VQ,eWo,oWo,rWo,av,_1e,tWo,aWo,XQ,nWo,sWo,lWo,nv,b1e,iWo,dWo,zQ,cWo,mWo,fWo,sv,v1e,gWo,hWo,QQ,uWo,pWo,_Wo,lv,F1e,bWo,vWo,WQ,FWo,TWo,MWo,iv,EWo,T1e,CWo,wWo,M1e,AWo,LWo,dv,BZe,Ad,cv,E1e,Bx,yWo,C1e,xWo,IZe,No,Ix,$Wo,Ld,kWo,UQ,SWo,RWo,HQ,PWo,BWo,IWo,Nx,NWo,w1e,qWo,jWo,DWo,Ft,qx,GWo,A1e,OWo,VWo,yd,XWo,L1e,zWo,QWo,JQ,WWo,UWo,HWo,mv,JWo,ro,jx,YWo,y1e,KWo,ZWo,Za,eUo,x1e,oUo,rUo,$1e,tUo,aUo,k1e,nUo,sUo,lUo,H,fv,S1e,iUo,dUo,YQ,cUo,mUo,fUo,gv,R1e,gUo,hUo,KQ,uUo,pUo,_Uo,hv,P1e,bUo,vUo,ZQ,FUo,TUo,MUo,uv,B1e,EUo,CUo,eW,wUo,AUo,LUo,pv,I1e,yUo,xUo,oW,$Uo,kUo,SUo,_v,N1e,RUo,PUo,rW,BUo,IUo,NUo,bv,q1e,qUo,jUo,tW,DUo,GUo,OUo,vv,j1e,VUo,XUo,aW,zUo,QUo,WUo,Fv,D1e,UUo,HUo,nW,JUo,YUo,KUo,Tv,G1e,ZUo,eHo,sW,oHo,rHo,tHo,Mv,O1e,aHo,nHo,lW,sHo,lHo,iHo,Ev,V1e,dHo,cHo,iW,mHo,fHo,gHo,Cv,X1e,hHo,uHo,dW,pHo,_Ho,bHo,wv,z1e,vHo,FHo,cW,THo,MHo,EHo,Av,Q1e,CHo,wHo,mW,AHo,LHo,yHo,Lv,W1e,xHo,$Ho,fW,kHo,SHo,RHo,yv,U1e,PHo,BHo,gW,IHo,NHo,qHo,xv,H1e,jHo,DHo,hW,GHo,OHo,VHo,$v,J1e,XHo,zHo,uW,QHo,WHo,UHo,kv,Y1e,HHo,JHo,pW,YHo,KHo,ZHo,Sv,K1e,eJo,oJo,_W,rJo,tJo,aJo,Rv,Z1e,nJo,sJo,bW,lJo,iJo,dJo,Pv,eve,cJo,mJo,vW,fJo,gJo,hJo,Bv,ove,uJo,pJo,FW,_Jo,bJo,vJo,Iv,rve,FJo,TJo,TW,MJo,EJo,CJo,Nv,tve,wJo,AJo,MW,LJo,yJo,xJo,qv,ave,$Jo,kJo,EW,SJo,RJo,PJo,jv,nve,BJo,IJo,CW,NJo,qJo,jJo,Dv,sve,DJo,GJo,wW,OJo,VJo,XJo,Gv,lve,zJo,QJo,AW,WJo,UJo,HJo,Ov,ive,JJo,YJo,LW,KJo,ZJo,eYo,Vv,dve,oYo,rYo,yW,tYo,aYo,nYo,Xv,cve,sYo,lYo,xW,iYo,dYo,cYo,zv,mve,mYo,fYo,$W,gYo,hYo,uYo,Qv,fve,pYo,_Yo,gve,bYo,vYo,FYo,Wv,hve,TYo,MYo,kW,EYo,CYo,wYo,Uv,uve,AYo,LYo,SW,yYo,xYo,$Yo,Hv,pve,kYo,SYo,RW,RYo,PYo,BYo,Jv,_ve,IYo,NYo,PW,qYo,jYo,DYo,Yv,GYo,bve,OYo,VYo,vve,XYo,zYo,Kv,NZe,xd,Zv,Fve,Dx,QYo,Tve,WYo,qZe,qo,Gx,UYo,$d,HYo,BW,JYo,YYo,IW,KYo,ZYo,eKo,Ox,oKo,Mve,rKo,tKo,aKo,Tt,Vx,nKo,Eve,sKo,lKo,kd,iKo,Cve,dKo,cKo,NW,mKo,fKo,gKo,eF,hKo,to,Xx,uKo,wve,pKo,_Ko,en,bKo,Ave,vKo,FKo,Lve,TKo,MKo,yve,EKo,CKo,wKo,fe,oF,xve,AKo,LKo,qW,yKo,xKo,$Ko,rF,$ve,kKo,SKo,jW,RKo,PKo,BKo,tF,kve,IKo,NKo,DW,qKo,jKo,DKo,aF,Sve,GKo,OKo,GW,VKo,XKo,zKo,nF,Rve,QKo,WKo,OW,UKo,HKo,JKo,sF,Pve,YKo,KKo,VW,ZKo,eZo,oZo,lF,Bve,rZo,tZo,XW,aZo,nZo,sZo,iF,Ive,lZo,iZo,zW,dZo,cZo,mZo,dF,Nve,fZo,gZo,QW,hZo,uZo,pZo,cF,qve,_Zo,bZo,WW,vZo,FZo,TZo,mF,jve,MZo,EZo,UW,CZo,wZo,AZo,fF,Dve,LZo,yZo,HW,xZo,$Zo,kZo,gF,Gve,SZo,RZo,JW,PZo,BZo,IZo,hF,Ove,NZo,qZo,YW,jZo,DZo,GZo,uF,Vve,OZo,VZo,KW,XZo,zZo,QZo,pF,Xve,WZo,UZo,ZW,HZo,JZo,YZo,_F,zve,KZo,ZZo,eU,eer,oer,rer,bF,Qve,ter,aer,oU,ner,ser,ler,vF,Wve,ier,der,rU,cer,mer,fer,FF,Uve,ger,her,tU,uer,per,_er,TF,ber,Hve,ver,Fer,Jve,Ter,Mer,MF,jZe,Sd,EF,Yve,zx,Eer,Kve,Cer,DZe,jo,Qx,wer,Rd,Aer,aU,Ler,yer,nU,xer,$er,ker,Wx,Ser,Zve,Rer,Per,Ber,Mt,Ux,Ier,eFe,Ner,qer,Pd,jer,oFe,Der,Ger,sU,Oer,Ver,Xer,CF,zer,ao,Hx,Qer,rFe,Wer,Uer,on,Her,tFe,Jer,Yer,aFe,Ker,Zer,nFe,eor,oor,ror,q,wF,sFe,tor,aor,lU,nor,sor,lor,AF,lFe,ior,dor,iU,cor,mor,gor,LF,iFe,hor,uor,dU,por,_or,bor,yF,dFe,vor,For,cU,Tor,Mor,Eor,xF,cFe,Cor,wor,mU,Aor,Lor,yor,$F,mFe,xor,$or,fU,kor,Sor,Ror,kF,fFe,Por,Bor,gU,Ior,Nor,qor,SF,gFe,jor,Dor,hU,Gor,Oor,Vor,RF,hFe,Xor,zor,uU,Qor,Wor,Uor,PF,uFe,Hor,Jor,pU,Yor,Kor,Zor,BF,pFe,err,orr,_U,rrr,trr,arr,IF,_Fe,nrr,srr,bU,lrr,irr,drr,NF,bFe,crr,mrr,vU,frr,grr,hrr,qF,vFe,urr,prr,FU,_rr,brr,vrr,jF,FFe,Frr,Trr,TU,Mrr,Err,Crr,DF,TFe,wrr,Arr,MU,Lrr,yrr,xrr,GF,MFe,$rr,krr,EU,Srr,Rrr,Prr,OF,EFe,Brr,Irr,CU,Nrr,qrr,jrr,VF,CFe,Drr,Grr,wU,Orr,Vrr,Xrr,XF,wFe,zrr,Qrr,AU,Wrr,Urr,Hrr,zF,AFe,Jrr,Yrr,LU,Krr,Zrr,etr,QF,LFe,otr,rtr,yU,ttr,atr,ntr,WF,yFe,str,ltr,xU,itr,dtr,ctr,UF,xFe,mtr,ftr,$U,gtr,htr,utr,HF,$Fe,ptr,_tr,kU,btr,vtr,Ftr,JF,kFe,Ttr,Mtr,SU,Etr,Ctr,wtr,YF,SFe,Atr,Ltr,RU,ytr,xtr,$tr,KF,RFe,ktr,Str,PU,Rtr,Ptr,Btr,ZF,PFe,Itr,Ntr,BU,qtr,jtr,Dtr,eT,BFe,Gtr,Otr,IU,Vtr,Xtr,ztr,oT,IFe,Qtr,Wtr,NU,Utr,Htr,Jtr,rT,NFe,Ytr,Ktr,qU,Ztr,ear,oar,tT,qFe,rar,tar,jU,aar,nar,sar,aT,jFe,lar,iar,DU,dar,car,mar,nT,DFe,far,gar,GU,har,uar,par,sT,GFe,_ar,bar,OU,Far,Tar,Mar,lT,OFe,Ear,Car,VU,war,Aar,Lar,iT,VFe,yar,xar,XU,$ar,kar,Sar,dT,XFe,Rar,Par,zU,Bar,Iar,Nar,cT,zFe,qar,jar,QU,Dar,Gar,Oar,mT,QFe,Var,Xar,WU,zar,Qar,War,fT,WFe,Uar,Har,UU,Jar,Yar,Kar,gT,UFe,Zar,enr,HU,onr,rnr,tnr,hT,HFe,anr,nnr,JU,snr,lnr,inr,uT,JFe,dnr,cnr,YU,mnr,fnr,gnr,pT,YFe,hnr,unr,KU,pnr,_nr,bnr,_T,KFe,vnr,Fnr,ZU,Tnr,Mnr,Enr,bT,ZFe,Cnr,wnr,eH,Anr,Lnr,ynr,vT,eTe,xnr,$nr,oH,knr,Snr,Rnr,FT,oTe,Pnr,Bnr,rH,Inr,Nnr,qnr,TT,rTe,jnr,Dnr,tH,Gnr,Onr,Vnr,MT,tTe,Xnr,znr,aH,Qnr,Wnr,Unr,ET,aTe,Hnr,Jnr,nH,Ynr,Knr,Znr,CT,nTe,esr,osr,sH,rsr,tsr,asr,wT,nsr,sTe,ssr,lsr,lTe,isr,dsr,AT,GZe,Bd,LT,iTe,Jx,csr,dTe,msr,OZe,Do,Yx,fsr,Id,gsr,lH,hsr,usr,iH,psr,_sr,bsr,Kx,vsr,cTe,Fsr,Tsr,Msr,Et,Zx,Esr,mTe,Csr,wsr,Nd,Asr,fTe,Lsr,ysr,dH,xsr,$sr,ksr,yT,Ssr,no,e$,Rsr,gTe,Psr,Bsr,rn,Isr,hTe,Nsr,qsr,uTe,jsr,Dsr,pTe,Gsr,Osr,Vsr,Z,xT,_Te,Xsr,zsr,cH,Qsr,Wsr,Usr,$T,bTe,Hsr,Jsr,mH,Ysr,Ksr,Zsr,kT,vTe,elr,olr,fH,rlr,tlr,alr,ST,FTe,nlr,slr,gH,llr,ilr,dlr,RT,TTe,clr,mlr,hH,flr,glr,hlr,PT,MTe,ulr,plr,uH,_lr,blr,vlr,BT,ETe,Flr,Tlr,pH,Mlr,Elr,Clr,IT,CTe,wlr,Alr,_H,Llr,ylr,xlr,NT,wTe,$lr,klr,bH,Slr,Rlr,Plr,qT,ATe,Blr,Ilr,vH,Nlr,qlr,jlr,jT,LTe,Dlr,Glr,FH,Olr,Vlr,Xlr,DT,yTe,zlr,Qlr,TH,Wlr,Ulr,Hlr,GT,xTe,Jlr,Ylr,MH,Klr,Zlr,eir,OT,$Te,oir,rir,EH,tir,air,nir,VT,kTe,sir,lir,CH,iir,dir,cir,XT,STe,mir,fir,wH,gir,hir,uir,zT,RTe,pir,_ir,AH,bir,vir,Fir,QT,PTe,Tir,Mir,LH,Eir,Cir,wir,WT,BTe,Air,Lir,yH,yir,xir,$ir,UT,ITe,kir,Sir,xH,Rir,Pir,Bir,HT,NTe,Iir,Nir,$H,qir,jir,Dir,JT,qTe,Gir,Oir,kH,Vir,Xir,zir,YT,jTe,Qir,Wir,SH,Uir,Hir,Jir,KT,DTe,Yir,Kir,RH,Zir,edr,odr,ZT,GTe,rdr,tdr,PH,adr,ndr,sdr,eM,OTe,ldr,idr,BH,ddr,cdr,mdr,oM,VTe,fdr,gdr,IH,hdr,udr,pdr,rM,XTe,_dr,bdr,NH,vdr,Fdr,Tdr,tM,zTe,Mdr,Edr,qH,Cdr,wdr,Adr,aM,QTe,Ldr,ydr,jH,xdr,$dr,kdr,nM,WTe,Sdr,Rdr,DH,Pdr,Bdr,Idr,sM,UTe,Ndr,qdr,GH,jdr,Ddr,Gdr,lM,Odr,HTe,Vdr,Xdr,JTe,zdr,Qdr,iM,VZe,qd,dM,YTe,o$,Wdr,KTe,Udr,XZe,Go,r$,Hdr,jd,Jdr,OH,Ydr,Kdr,VH,Zdr,ecr,ocr,t$,rcr,ZTe,tcr,acr,ncr,Ct,a$,scr,eMe,lcr,icr,Dd,dcr,oMe,ccr,mcr,XH,fcr,gcr,hcr,cM,ucr,so,n$,pcr,rMe,_cr,bcr,tn,vcr,tMe,Fcr,Tcr,aMe,Mcr,Ecr,nMe,Ccr,wcr,Acr,Ue,mM,sMe,Lcr,ycr,zH,xcr,$cr,kcr,fM,lMe,Scr,Rcr,QH,Pcr,Bcr,Icr,gM,iMe,Ncr,qcr,WH,jcr,Dcr,Gcr,hM,dMe,Ocr,Vcr,UH,Xcr,zcr,Qcr,uM,cMe,Wcr,Ucr,HH,Hcr,Jcr,Ycr,pM,mMe,Kcr,Zcr,JH,emr,omr,rmr,_M,fMe,tmr,amr,YH,nmr,smr,lmr,bM,imr,gMe,dmr,cmr,hMe,mmr,fmr,vM,zZe,Gd,FM,uMe,s$,gmr,pMe,hmr,QZe,Oo,l$,umr,Od,pmr,KH,_mr,bmr,ZH,vmr,Fmr,Tmr,i$,Mmr,_Me,Emr,Cmr,wmr,wt,d$,Amr,bMe,Lmr,ymr,Vd,xmr,vMe,$mr,kmr,eJ,Smr,Rmr,Pmr,TM,Bmr,lo,c$,Imr,FMe,Nmr,qmr,an,jmr,TMe,Dmr,Gmr,MMe,Omr,Vmr,EMe,Xmr,zmr,Qmr,J,MM,CMe,Wmr,Umr,oJ,Hmr,Jmr,Ymr,EM,wMe,Kmr,Zmr,rJ,efr,ofr,rfr,CM,AMe,tfr,afr,tJ,nfr,sfr,lfr,wM,LMe,ifr,dfr,aJ,cfr,mfr,ffr,AM,yMe,gfr,hfr,nJ,ufr,pfr,_fr,LM,xMe,bfr,vfr,sJ,Ffr,Tfr,Mfr,yM,$Me,Efr,Cfr,lJ,wfr,Afr,Lfr,xM,kMe,yfr,xfr,iJ,$fr,kfr,Sfr,$M,SMe,Rfr,Pfr,dJ,Bfr,Ifr,Nfr,kM,RMe,qfr,jfr,cJ,Dfr,Gfr,Ofr,SM,PMe,Vfr,Xfr,mJ,zfr,Qfr,Wfr,RM,BMe,Ufr,Hfr,fJ,Jfr,Yfr,Kfr,PM,IMe,Zfr,egr,gJ,ogr,rgr,tgr,BM,NMe,agr,ngr,hJ,sgr,lgr,igr,IM,qMe,dgr,cgr,uJ,mgr,fgr,ggr,NM,jMe,hgr,ugr,pJ,pgr,_gr,bgr,qM,DMe,vgr,Fgr,_J,Tgr,Mgr,Egr,jM,GMe,Cgr,wgr,bJ,Agr,Lgr,ygr,DM,OMe,xgr,$gr,vJ,kgr,Sgr,Rgr,GM,VMe,Pgr,Bgr,FJ,Igr,Ngr,qgr,OM,XMe,jgr,Dgr,TJ,Ggr,Ogr,Vgr,VM,zMe,Xgr,zgr,MJ,Qgr,Wgr,Ugr,XM,QMe,Hgr,Jgr,EJ,Ygr,Kgr,Zgr,zM,WMe,ehr,ohr,CJ,rhr,thr,ahr,QM,UMe,nhr,shr,wJ,lhr,ihr,dhr,WM,HMe,chr,mhr,AJ,fhr,ghr,hhr,UM,JMe,uhr,phr,LJ,_hr,bhr,vhr,HM,YMe,Fhr,Thr,yJ,Mhr,Ehr,Chr,JM,KMe,whr,Ahr,xJ,Lhr,yhr,xhr,YM,ZMe,$hr,khr,$J,Shr,Rhr,Phr,KM,eEe,Bhr,Ihr,kJ,Nhr,qhr,jhr,ZM,oEe,Dhr,Ghr,SJ,Ohr,Vhr,Xhr,eE,rEe,zhr,Qhr,RJ,Whr,Uhr,Hhr,oE,tEe,Jhr,Yhr,PJ,Khr,Zhr,eur,rE,aEe,our,rur,BJ,tur,aur,nur,tE,nEe,sur,lur,IJ,iur,dur,cur,aE,sEe,mur,fur,NJ,gur,hur,uur,nE,lEe,pur,_ur,qJ,bur,vur,Fur,sE,iEe,Tur,Mur,jJ,Eur,Cur,wur,lE,Aur,dEe,Lur,yur,cEe,xur,$ur,iE,WZe,Xd,dE,mEe,m$,kur,fEe,Sur,UZe,Vo,f$,Rur,zd,Pur,DJ,Bur,Iur,GJ,Nur,qur,jur,g$,Dur,gEe,Gur,Our,Vur,At,h$,Xur,hEe,zur,Qur,Qd,Wur,uEe,Uur,Hur,OJ,Jur,Yur,Kur,cE,Zur,io,u$,epr,pEe,opr,rpr,nn,tpr,_Ee,apr,npr,bEe,spr,lpr,vEe,ipr,dpr,cpr,V,mE,FEe,mpr,fpr,VJ,gpr,hpr,upr,fE,TEe,ppr,_pr,XJ,bpr,vpr,Fpr,gE,MEe,Tpr,Mpr,zJ,Epr,Cpr,wpr,hE,EEe,Apr,Lpr,QJ,ypr,xpr,$pr,uE,CEe,kpr,Spr,WJ,Rpr,Ppr,Bpr,pE,wEe,Ipr,Npr,UJ,qpr,jpr,Dpr,_E,AEe,Gpr,Opr,HJ,Vpr,Xpr,zpr,bE,LEe,Qpr,Wpr,JJ,Upr,Hpr,Jpr,vE,yEe,Ypr,Kpr,YJ,Zpr,e_r,o_r,FE,xEe,r_r,t_r,KJ,a_r,n_r,s_r,TE,$Ee,l_r,i_r,ZJ,d_r,c_r,m_r,ME,kEe,f_r,g_r,eY,h_r,u_r,p_r,EE,SEe,__r,b_r,oY,v_r,F_r,T_r,CE,REe,M_r,E_r,rY,C_r,w_r,A_r,wE,PEe,L_r,y_r,tY,x_r,$_r,k_r,AE,BEe,S_r,R_r,aY,P_r,B_r,I_r,LE,IEe,N_r,q_r,nY,j_r,D_r,G_r,yE,NEe,O_r,V_r,sY,X_r,z_r,Q_r,xE,qEe,W_r,U_r,lY,H_r,J_r,Y_r,$E,jEe,K_r,Z_r,iY,e2r,o2r,r2r,kE,DEe,t2r,a2r,dY,n2r,s2r,l2r,SE,GEe,i2r,d2r,cY,c2r,m2r,f2r,RE,OEe,g2r,h2r,mY,u2r,p2r,_2r,PE,VEe,b2r,v2r,fY,F2r,T2r,M2r,BE,XEe,E2r,C2r,gY,w2r,A2r,L2r,IE,zEe,y2r,x2r,hY,$2r,k2r,S2r,NE,QEe,R2r,P2r,uY,B2r,I2r,N2r,qE,WEe,q2r,j2r,pY,D2r,G2r,O2r,jE,UEe,V2r,X2r,_Y,z2r,Q2r,W2r,DE,HEe,U2r,H2r,bY,J2r,Y2r,K2r,GE,JEe,Z2r,ebr,vY,obr,rbr,tbr,OE,YEe,abr,nbr,FY,sbr,lbr,ibr,VE,KEe,dbr,cbr,TY,mbr,fbr,gbr,XE,ZEe,hbr,ubr,MY,pbr,_br,bbr,zE,e4e,vbr,Fbr,EY,Tbr,Mbr,Ebr,QE,o4e,Cbr,wbr,CY,Abr,Lbr,ybr,WE,r4e,xbr,$br,wY,kbr,Sbr,Rbr,UE,t4e,Pbr,Bbr,AY,Ibr,Nbr,qbr,HE,a4e,jbr,Dbr,LY,Gbr,Obr,Vbr,JE,n4e,Xbr,zbr,yY,Qbr,Wbr,Ubr,YE,s4e,Hbr,Jbr,xY,Ybr,Kbr,Zbr,KE,l4e,e1r,o1r,$Y,r1r,t1r,a1r,ZE,i4e,n1r,s1r,kY,l1r,i1r,d1r,e4,d4e,c1r,m1r,SY,f1r,g1r,h1r,o4,c4e,u1r,p1r,RY,_1r,b1r,v1r,r4,F1r,m4e,T1r,M1r,f4e,E1r,C1r,t4,HZe,Wd,a4,g4e,p$,w1r,h4e,A1r,JZe,Xo,_$,L1r,Ud,y1r,PY,x1r,$1r,BY,k1r,S1r,R1r,b$,P1r,u4e,B1r,I1r,N1r,Lt,v$,q1r,p4e,j1r,D1r,Hd,G1r,_4e,O1r,V1r,IY,X1r,z1r,Q1r,n4,W1r,co,F$,U1r,b4e,H1r,J1r,sn,Y1r,v4e,K1r,Z1r,F4e,evr,ovr,T4e,rvr,tvr,avr,M4e,s4,E4e,nvr,svr,NY,lvr,ivr,dvr,l4,cvr,C4e,mvr,fvr,w4e,gvr,hvr,i4,YZe,Jd,d4,A4e,T$,uvr,L4e,pvr,KZe,zo,M$,_vr,Yd,bvr,qY,vvr,Fvr,jY,Tvr,Mvr,Evr,E$,Cvr,y4e,wvr,Avr,Lvr,yt,C$,yvr,x4e,xvr,$vr,Kd,kvr,$4e,Svr,Rvr,DY,Pvr,Bvr,Ivr,c4,Nvr,mo,w$,qvr,k4e,jvr,Dvr,ln,Gvr,S4e,Ovr,Vvr,R4e,Xvr,zvr,P4e,Qvr,Wvr,Uvr,Zd,m4,B4e,Hvr,Jvr,GY,Yvr,Kvr,Zvr,f4,I4e,eFr,oFr,OY,rFr,tFr,aFr,g4,N4e,nFr,sFr,VY,lFr,iFr,dFr,h4,cFr,q4e,mFr,fFr,j4e,gFr,hFr,u4,ZZe,ec,p4,D4e,A$,uFr,G4e,pFr,eeo,Qo,L$,_Fr,oc,bFr,XY,vFr,FFr,zY,TFr,MFr,EFr,y$,CFr,O4e,wFr,AFr,LFr,xt,x$,yFr,V4e,xFr,$Fr,rc,kFr,X4e,SFr,RFr,QY,PFr,BFr,IFr,_4,NFr,fo,$$,qFr,z4e,jFr,DFr,dn,GFr,Q4e,OFr,VFr,W4e,XFr,zFr,U4e,QFr,WFr,UFr,be,b4,H4e,HFr,JFr,WY,YFr,KFr,ZFr,v4,J4e,eTr,oTr,UY,rTr,tTr,aTr,F4,Y4e,nTr,sTr,HY,lTr,iTr,dTr,T4,K4e,cTr,mTr,JY,fTr,gTr,hTr,bl,Z4e,uTr,pTr,YY,_Tr,bTr,KY,vTr,FTr,TTr,M4,eCe,MTr,ETr,ZY,CTr,wTr,ATr,vl,oCe,LTr,yTr,eK,xTr,$Tr,oK,kTr,STr,RTr,E4,rCe,PTr,BTr,rK,ITr,NTr,qTr,$t,tCe,jTr,DTr,tK,GTr,OTr,aK,VTr,XTr,nK,zTr,QTr,WTr,C4,aCe,UTr,HTr,sK,JTr,YTr,KTr,w4,nCe,ZTr,eMr,lK,oMr,rMr,tMr,A4,sCe,aMr,nMr,iK,sMr,lMr,iMr,L4,lCe,dMr,cMr,dK,mMr,fMr,gMr,y4,iCe,hMr,uMr,cK,pMr,_Mr,bMr,x4,dCe,vMr,FMr,mK,TMr,MMr,EMr,$4,cCe,CMr,wMr,fK,AMr,LMr,yMr,k4,mCe,xMr,$Mr,gK,kMr,SMr,RMr,S4,fCe,PMr,BMr,hK,IMr,NMr,qMr,R4,jMr,gCe,DMr,GMr,hCe,OMr,VMr,P4,oeo,tc,B4,uCe,k$,XMr,pCe,zMr,reo,Wo,S$,QMr,ac,WMr,uK,UMr,HMr,pK,JMr,YMr,KMr,R$,ZMr,_Ce,eEr,oEr,rEr,kt,P$,tEr,bCe,aEr,nEr,nc,sEr,vCe,lEr,iEr,_K,dEr,cEr,mEr,I4,fEr,go,B$,gEr,FCe,hEr,uEr,cn,pEr,TCe,_Er,bEr,MCe,vEr,FEr,ECe,TEr,MEr,EEr,CCe,N4,wCe,CEr,wEr,bK,AEr,LEr,yEr,q4,xEr,ACe,$Er,kEr,LCe,SEr,REr,j4,teo,sc,D4,yCe,I$,PEr,xCe,BEr,aeo,Uo,N$,IEr,lc,NEr,vK,qEr,jEr,FK,DEr,GEr,OEr,q$,VEr,$Ce,XEr,zEr,QEr,St,j$,WEr,kCe,UEr,HEr,ic,JEr,SCe,YEr,KEr,TK,ZEr,e4r,o4r,G4,r4r,ho,D$,t4r,RCe,a4r,n4r,mn,s4r,PCe,l4r,i4r,BCe,d4r,c4r,ICe,m4r,f4r,g4r,NCe,O4,qCe,h4r,u4r,MK,p4r,_4r,b4r,V4,v4r,jCe,F4r,T4r,DCe,M4r,E4r,X4,neo,dc,z4,GCe,G$,C4r,OCe,w4r,seo,Ho,O$,A4r,cc,L4r,EK,y4r,x4r,CK,$4r,k4r,S4r,V$,R4r,VCe,P4r,B4r,I4r,Rt,X$,N4r,XCe,q4r,j4r,mc,D4r,zCe,G4r,O4r,wK,V4r,X4r,z4r,Q4,Q4r,uo,z$,W4r,QCe,U4r,H4r,fn,J4r,WCe,Y4r,K4r,UCe,Z4r,eCr,HCe,oCr,rCr,tCr,JCe,W4,YCe,aCr,nCr,AK,sCr,lCr,iCr,U4,dCr,KCe,cCr,mCr,ZCe,fCr,gCr,H4,leo,fc,J4,e3e,Q$,hCr,o3e,uCr,ieo,Jo,W$,pCr,gc,_Cr,LK,bCr,vCr,yK,FCr,TCr,MCr,U$,ECr,r3e,CCr,wCr,ACr,Pt,H$,LCr,t3e,yCr,xCr,hc,$Cr,a3e,kCr,SCr,xK,RCr,PCr,BCr,Y4,ICr,po,J$,NCr,n3e,qCr,jCr,gn,DCr,s3e,GCr,OCr,l3e,VCr,XCr,i3e,zCr,QCr,WCr,Pe,K4,d3e,UCr,HCr,$K,JCr,YCr,KCr,Z4,c3e,ZCr,e3r,kK,o3r,r3r,t3r,eC,m3e,a3r,n3r,SK,s3r,l3r,i3r,oC,f3e,d3r,c3r,RK,m3r,f3r,g3r,rC,g3e,h3r,u3r,PK,p3r,_3r,b3r,tC,h3e,v3r,F3r,BK,T3r,M3r,E3r,aC,u3e,C3r,w3r,IK,A3r,L3r,y3r,nC,p3e,x3r,$3r,NK,k3r,S3r,R3r,sC,_3e,P3r,B3r,qK,I3r,N3r,q3r,lC,j3r,b3e,D3r,G3r,v3e,O3r,V3r,iC,deo,uc,dC,F3e,Y$,X3r,T3e,z3r,ceo,Yo,K$,Q3r,pc,W3r,jK,U3r,H3r,DK,J3r,Y3r,K3r,Z$,Z3r,M3e,e5r,o5r,r5r,Bt,ek,t5r,E3e,a5r,n5r,_c,s5r,C3e,l5r,i5r,GK,d5r,c5r,m5r,cC,f5r,_o,ok,g5r,w3e,h5r,u5r,hn,p5r,A3e,_5r,b5r,L3e,v5r,F5r,y3e,T5r,M5r,E5r,mt,mC,x3e,C5r,w5r,OK,A5r,L5r,y5r,fC,$3e,x5r,$5r,VK,k5r,S5r,R5r,gC,k3e,P5r,B5r,XK,I5r,N5r,q5r,hC,S3e,j5r,D5r,zK,G5r,O5r,V5r,uC,R3e,X5r,z5r,QK,Q5r,W5r,U5r,pC,H5r,P3e,J5r,Y5r,B3e,K5r,Z5r,_C,meo,bc,bC,I3e,rk,e0r,N3e,o0r,feo,Ko,tk,r0r,vc,t0r,WK,a0r,n0r,UK,s0r,l0r,i0r,ak,d0r,q3e,c0r,m0r,f0r,It,nk,g0r,j3e,h0r,u0r,Fc,p0r,D3e,_0r,b0r,HK,v0r,F0r,T0r,vC,M0r,bo,sk,E0r,G3e,C0r,w0r,un,A0r,O3e,L0r,y0r,V3e,x0r,$0r,X3e,k0r,S0r,R0r,Le,FC,z3e,P0r,B0r,JK,I0r,N0r,q0r,TC,Q3e,j0r,D0r,YK,G0r,O0r,V0r,MC,W3e,X0r,z0r,KK,Q0r,W0r,U0r,EC,U3e,H0r,J0r,ZK,Y0r,K0r,Z0r,CC,H3e,ewr,owr,eZ,rwr,twr,awr,wC,J3e,nwr,swr,oZ,lwr,iwr,dwr,AC,Y3e,cwr,mwr,rZ,fwr,gwr,hwr,LC,K3e,uwr,pwr,tZ,_wr,bwr,vwr,yC,Z3e,Fwr,Twr,aZ,Mwr,Ewr,Cwr,xC,e5e,wwr,Awr,nZ,Lwr,ywr,xwr,$C,$wr,o5e,kwr,Swr,r5e,Rwr,Pwr,kC,geo,Tc,SC,t5e,lk,Bwr,a5e,Iwr,heo,Zo,ik,Nwr,Mc,qwr,sZ,jwr,Dwr,lZ,Gwr,Owr,Vwr,dk,Xwr,n5e,zwr,Qwr,Wwr,Nt,ck,Uwr,s5e,Hwr,Jwr,Ec,Ywr,l5e,Kwr,Zwr,iZ,eAr,oAr,rAr,RC,tAr,vo,mk,aAr,i5e,nAr,sAr,pn,lAr,d5e,iAr,dAr,c5e,cAr,mAr,m5e,fAr,gAr,hAr,fk,PC,f5e,uAr,pAr,dZ,_Ar,bAr,vAr,BC,g5e,FAr,TAr,cZ,MAr,EAr,CAr,IC,wAr,h5e,AAr,LAr,u5e,yAr,xAr,NC,ueo,Cc,qC,p5e,gk,$Ar,_5e,kAr,peo,er,hk,SAr,wc,RAr,mZ,PAr,BAr,fZ,IAr,NAr,qAr,uk,jAr,b5e,DAr,GAr,OAr,qt,pk,VAr,v5e,XAr,zAr,Ac,QAr,F5e,WAr,UAr,gZ,HAr,JAr,YAr,jC,KAr,Fo,_k,ZAr,T5e,e6r,o6r,_n,r6r,M5e,t6r,a6r,E5e,n6r,s6r,C5e,l6r,i6r,d6r,ft,DC,w5e,c6r,m6r,hZ,f6r,g6r,h6r,GC,A5e,u6r,p6r,uZ,_6r,b6r,v6r,OC,L5e,F6r,T6r,pZ,M6r,E6r,C6r,VC,y5e,w6r,A6r,_Z,L6r,y6r,x6r,XC,x5e,$6r,k6r,bZ,S6r,R6r,P6r,zC,B6r,$5e,I6r,N6r,k5e,q6r,j6r,QC,_eo,Lc,WC,S5e,bk,D6r,R5e,G6r,beo,or,vk,O6r,yc,V6r,vZ,X6r,z6r,FZ,Q6r,W6r,U6r,Fk,H6r,P5e,J6r,Y6r,K6r,jt,Tk,Z6r,B5e,e7r,o7r,xc,r7r,I5e,t7r,a7r,TZ,n7r,s7r,l7r,UC,i7r,To,Mk,d7r,N5e,c7r,m7r,bn,f7r,q5e,g7r,h7r,j5e,u7r,p7r,D5e,_7r,b7r,v7r,vn,HC,G5e,F7r,T7r,MZ,M7r,E7r,C7r,JC,O5e,w7r,A7r,EZ,L7r,y7r,x7r,YC,V5e,$7r,k7r,CZ,S7r,R7r,P7r,KC,X5e,B7r,I7r,wZ,N7r,q7r,j7r,ZC,D7r,z5e,G7r,O7r,Q5e,V7r,X7r,e3,veo,$c,o3,W5e,Ek,z7r,U5e,Q7r,Feo,rr,Ck,W7r,kc,U7r,AZ,H7r,J7r,LZ,Y7r,K7r,Z7r,wk,eLr,H5e,oLr,rLr,tLr,Dt,Ak,aLr,J5e,nLr,sLr,Sc,lLr,Y5e,iLr,dLr,yZ,cLr,mLr,fLr,r3,gLr,Mo,Lk,hLr,K5e,uLr,pLr,Fn,_Lr,Z5e,bLr,vLr,e0e,FLr,TLr,o0e,MLr,ELr,CLr,Tn,t3,r0e,wLr,ALr,xZ,LLr,yLr,xLr,a3,t0e,$Lr,kLr,$Z,SLr,RLr,PLr,n3,a0e,BLr,ILr,kZ,NLr,qLr,jLr,s3,n0e,DLr,GLr,SZ,OLr,VLr,XLr,l3,zLr,s0e,QLr,WLr,l0e,ULr,HLr,i3,Teo,Rc,d3,i0e,yk,JLr,d0e,YLr,Meo,tr,xk,KLr,Pc,ZLr,RZ,eyr,oyr,PZ,ryr,tyr,ayr,$k,nyr,c0e,syr,lyr,iyr,Gt,kk,dyr,m0e,cyr,myr,Bc,fyr,f0e,gyr,hyr,BZ,uyr,pyr,_yr,c3,byr,Eo,Sk,vyr,g0e,Fyr,Tyr,Mn,Myr,h0e,Eyr,Cyr,u0e,wyr,Ayr,p0e,Lyr,yyr,xyr,_0e,m3,b0e,$yr,kyr,IZ,Syr,Ryr,Pyr,f3,Byr,v0e,Iyr,Nyr,F0e,qyr,jyr,g3,Eeo,Ic,h3,T0e,Rk,Dyr,M0e,Gyr,Ceo,ar,Pk,Oyr,Nc,Vyr,NZ,Xyr,zyr,qZ,Qyr,Wyr,Uyr,Bk,Hyr,E0e,Jyr,Yyr,Kyr,Ot,Ik,Zyr,C0e,e8r,o8r,qc,r8r,w0e,t8r,a8r,jZ,n8r,s8r,l8r,u3,i8r,Co,Nk,d8r,A0e,c8r,m8r,En,f8r,L0e,g8r,h8r,y0e,u8r,p8r,x0e,_8r,b8r,v8r,gt,p3,$0e,F8r,T8r,DZ,M8r,E8r,C8r,_3,k0e,w8r,A8r,GZ,L8r,y8r,x8r,b3,S0e,$8r,k8r,OZ,S8r,R8r,P8r,v3,R0e,B8r,I8r,VZ,N8r,q8r,j8r,F3,P0e,D8r,G8r,XZ,O8r,V8r,X8r,T3,z8r,B0e,Q8r,W8r,I0e,U8r,H8r,M3,weo,jc,E3,N0e,qk,J8r,q0e,Y8r,Aeo,nr,jk,K8r,Dc,Z8r,zZ,e9r,o9r,QZ,r9r,t9r,a9r,Dk,n9r,j0e,s9r,l9r,i9r,Vt,Gk,d9r,D0e,c9r,m9r,Gc,f9r,G0e,g9r,h9r,WZ,u9r,p9r,_9r,C3,b9r,wo,Ok,v9r,O0e,F9r,T9r,Cn,M9r,V0e,E9r,C9r,X0e,w9r,A9r,z0e,L9r,y9r,x9r,Q0e,w3,W0e,$9r,k9r,UZ,S9r,R9r,P9r,A3,B9r,U0e,I9r,N9r,H0e,q9r,j9r,L3,Leo,Oc,y3,J0e,Vk,D9r,Y0e,G9r,yeo,sr,Xk,O9r,Vc,V9r,HZ,X9r,z9r,JZ,Q9r,W9r,U9r,zk,H9r,K0e,J9r,Y9r,K9r,Xt,Qk,Z9r,Z0e,exr,oxr,Xc,rxr,ewe,txr,axr,YZ,nxr,sxr,lxr,x3,ixr,Ir,Wk,dxr,owe,cxr,mxr,wn,fxr,rwe,gxr,hxr,twe,uxr,pxr,awe,_xr,bxr,vxr,B,$3,nwe,Fxr,Txr,KZ,Mxr,Exr,Cxr,k3,swe,wxr,Axr,ZZ,Lxr,yxr,xxr,S3,lwe,$xr,kxr,eee,Sxr,Rxr,Pxr,R3,iwe,Bxr,Ixr,oee,Nxr,qxr,jxr,P3,dwe,Dxr,Gxr,ree,Oxr,Vxr,Xxr,B3,cwe,zxr,Qxr,tee,Wxr,Uxr,Hxr,I3,mwe,Jxr,Yxr,aee,Kxr,Zxr,e$r,N3,fwe,o$r,r$r,nee,t$r,a$r,n$r,q3,gwe,s$r,l$r,see,i$r,d$r,c$r,j3,hwe,m$r,f$r,lee,g$r,h$r,u$r,D3,uwe,p$r,_$r,iee,b$r,v$r,F$r,G3,pwe,T$r,M$r,dee,E$r,C$r,w$r,O3,_we,A$r,L$r,cee,y$r,x$r,$$r,V3,bwe,k$r,S$r,mee,R$r,P$r,B$r,X3,vwe,I$r,N$r,fee,q$r,j$r,D$r,z3,Fwe,G$r,O$r,gee,V$r,X$r,z$r,Q3,Twe,Q$r,W$r,hee,U$r,H$r,J$r,W3,Mwe,Y$r,K$r,uee,Z$r,ekr,okr,Fl,Ewe,rkr,tkr,pee,akr,nkr,_ee,skr,lkr,ikr,U3,Cwe,dkr,ckr,bee,mkr,fkr,gkr,H3,wwe,hkr,ukr,vee,pkr,_kr,bkr,J3,Awe,vkr,Fkr,Fee,Tkr,Mkr,Ekr,Y3,Lwe,Ckr,wkr,Tee,Akr,Lkr,ykr,K3,ywe,xkr,$kr,Mee,kkr,Skr,Rkr,Z3,xwe,Pkr,Bkr,Eee,Ikr,Nkr,qkr,e5,$we,jkr,Dkr,Cee,Gkr,Okr,Vkr,o5,kwe,Xkr,zkr,wee,Qkr,Wkr,Ukr,r5,Swe,Hkr,Jkr,Aee,Ykr,Kkr,Zkr,t5,Rwe,eSr,oSr,Lee,rSr,tSr,aSr,a5,Pwe,nSr,sSr,yee,lSr,iSr,dSr,n5,Bwe,cSr,mSr,xee,fSr,gSr,hSr,s5,Iwe,uSr,pSr,$ee,_Sr,bSr,vSr,l5,Nwe,FSr,TSr,kee,MSr,ESr,CSr,i5,qwe,wSr,ASr,See,LSr,ySr,xSr,d5,jwe,$Sr,kSr,Ree,SSr,RSr,PSr,c5,Dwe,BSr,ISr,Pee,NSr,qSr,jSr,m5,Gwe,DSr,GSr,Bee,OSr,VSr,XSr,f5,Owe,zSr,QSr,Iee,WSr,USr,HSr,g5,Vwe,JSr,YSr,Nee,KSr,ZSr,eRr,h5,Xwe,oRr,rRr,qee,tRr,aRr,nRr,u5,zwe,sRr,lRr,jee,iRr,dRr,cRr,p5,Qwe,mRr,fRr,Dee,gRr,hRr,uRr,_5,Wwe,pRr,_Rr,Gee,bRr,vRr,FRr,b5,Uwe,TRr,MRr,Oee,ERr,CRr,wRr,v5,Hwe,ARr,LRr,Vee,yRr,xRr,$Rr,F5,Jwe,kRr,SRr,Xee,RRr,PRr,BRr,T5,Ywe,IRr,NRr,zee,qRr,jRr,DRr,M5,Kwe,GRr,ORr,Qee,VRr,XRr,zRr,E5,Zwe,QRr,WRr,Wee,URr,HRr,JRr,C5,eAe,YRr,KRr,Uee,ZRr,ePr,oPr,w5,oAe,rPr,tPr,Hee,aPr,nPr,sPr,A5,rAe,lPr,iPr,Jee,dPr,cPr,mPr,L5,tAe,fPr,gPr,Yee,hPr,uPr,pPr,y5,aAe,_Pr,bPr,Kee,vPr,FPr,TPr,x5,nAe,MPr,EPr,Zee,CPr,wPr,APr,$5,xeo,zc,k5,sAe,Uk,LPr,lAe,yPr,$eo,lr,Hk,xPr,Qc,$Pr,eoe,kPr,SPr,ooe,RPr,PPr,BPr,Jk,IPr,iAe,NPr,qPr,jPr,zt,Yk,DPr,dAe,GPr,OPr,Wc,VPr,cAe,XPr,zPr,roe,QPr,WPr,UPr,S5,HPr,Nr,Kk,JPr,mAe,YPr,KPr,An,ZPr,fAe,eBr,oBr,gAe,rBr,tBr,hAe,aBr,nBr,sBr,se,R5,uAe,lBr,iBr,toe,dBr,cBr,mBr,P5,pAe,fBr,gBr,aoe,hBr,uBr,pBr,B5,_Ae,_Br,bBr,noe,vBr,FBr,TBr,I5,bAe,MBr,EBr,soe,CBr,wBr,ABr,N5,vAe,LBr,yBr,loe,xBr,$Br,kBr,q5,FAe,SBr,RBr,ioe,PBr,BBr,IBr,j5,TAe,NBr,qBr,doe,jBr,DBr,GBr,D5,MAe,OBr,VBr,coe,XBr,zBr,QBr,G5,EAe,WBr,UBr,moe,HBr,JBr,YBr,O5,CAe,KBr,ZBr,foe,eIr,oIr,rIr,V5,wAe,tIr,aIr,goe,nIr,sIr,lIr,X5,AAe,iIr,dIr,hoe,cIr,mIr,fIr,z5,LAe,gIr,hIr,uoe,uIr,pIr,_Ir,Q5,yAe,bIr,vIr,poe,FIr,TIr,MIr,W5,xAe,EIr,CIr,_oe,wIr,AIr,LIr,U5,$Ae,yIr,xIr,boe,$Ir,kIr,SIr,H5,kAe,RIr,PIr,voe,BIr,IIr,NIr,J5,SAe,qIr,jIr,Foe,DIr,GIr,OIr,Y5,RAe,VIr,XIr,Toe,zIr,QIr,WIr,K5,PAe,UIr,HIr,Moe,JIr,YIr,KIr,Z5,BAe,ZIr,eNr,Eoe,oNr,rNr,tNr,e0,IAe,aNr,nNr,Coe,sNr,lNr,iNr,o0,NAe,dNr,cNr,woe,mNr,fNr,gNr,r0,keo,Uc,t0,qAe,Zk,hNr,jAe,uNr,Seo,ir,eS,pNr,Hc,_Nr,Aoe,bNr,vNr,Loe,FNr,TNr,MNr,oS,ENr,DAe,CNr,wNr,ANr,Qt,rS,LNr,GAe,yNr,xNr,Jc,$Nr,OAe,kNr,SNr,yoe,RNr,PNr,BNr,a0,INr,qr,tS,NNr,VAe,qNr,jNr,Ln,DNr,XAe,GNr,ONr,zAe,VNr,XNr,QAe,zNr,QNr,WNr,Me,n0,WAe,UNr,HNr,xoe,JNr,YNr,KNr,s0,UAe,ZNr,eqr,$oe,oqr,rqr,tqr,l0,HAe,aqr,nqr,koe,sqr,lqr,iqr,i0,JAe,dqr,cqr,Soe,mqr,fqr,gqr,d0,YAe,hqr,uqr,Roe,pqr,_qr,bqr,c0,KAe,vqr,Fqr,Poe,Tqr,Mqr,Eqr,m0,ZAe,Cqr,wqr,Boe,Aqr,Lqr,yqr,f0,e6e,xqr,$qr,Ioe,kqr,Sqr,Rqr,g0,o6e,Pqr,Bqr,Noe,Iqr,Nqr,qqr,h0,r6e,jqr,Dqr,qoe,Gqr,Oqr,Vqr,u0,t6e,Xqr,zqr,joe,Qqr,Wqr,Uqr,p0,a6e,Hqr,Jqr,Doe,Yqr,Kqr,Zqr,_0,n6e,ejr,ojr,Goe,rjr,tjr,ajr,b0,s6e,njr,sjr,Ooe,ljr,ijr,djr,v0,Reo,Yc,F0,l6e,aS,cjr,i6e,mjr,Peo,dr,nS,fjr,Kc,gjr,Voe,hjr,ujr,Xoe,pjr,_jr,bjr,sS,vjr,d6e,Fjr,Tjr,Mjr,Wt,lS,Ejr,c6e,Cjr,wjr,Zc,Ajr,m6e,Ljr,yjr,zoe,xjr,$jr,kjr,T0,Sjr,jr,iS,Rjr,f6e,Pjr,Bjr,yn,Ijr,g6e,Njr,qjr,h6e,jjr,Djr,u6e,Gjr,Ojr,Vjr,Be,M0,p6e,Xjr,zjr,Qoe,Qjr,Wjr,Ujr,E0,_6e,Hjr,Jjr,Woe,Yjr,Kjr,Zjr,Tl,b6e,eDr,oDr,Uoe,rDr,tDr,Hoe,aDr,nDr,sDr,C0,v6e,lDr,iDr,Joe,dDr,cDr,mDr,w0,F6e,fDr,gDr,Yoe,hDr,uDr,pDr,A0,T6e,_Dr,bDr,Koe,vDr,FDr,TDr,L0,M6e,MDr,EDr,Zoe,CDr,wDr,ADr,y0,E6e,LDr,yDr,ere,xDr,$Dr,kDr,x0,C6e,SDr,RDr,ore,PDr,BDr,IDr,$0,Beo,em,k0,w6e,dS,NDr,A6e,qDr,Ieo,cr,cS,jDr,om,DDr,rre,GDr,ODr,tre,VDr,XDr,zDr,mS,QDr,L6e,WDr,UDr,HDr,Ut,fS,JDr,y6e,YDr,KDr,rm,ZDr,x6e,eGr,oGr,are,rGr,tGr,aGr,S0,nGr,Dr,gS,sGr,$6e,lGr,iGr,xn,dGr,k6e,cGr,mGr,S6e,fGr,gGr,R6e,hGr,uGr,pGr,tm,R0,P6e,_Gr,bGr,nre,vGr,FGr,TGr,P0,B6e,MGr,EGr,sre,CGr,wGr,AGr,B0,I6e,LGr,yGr,lre,xGr,$Gr,kGr,I0,Neo,am,N0,N6e,hS,SGr,q6e,RGr,qeo,mr,uS,PGr,nm,BGr,ire,IGr,NGr,dre,qGr,jGr,DGr,pS,GGr,j6e,OGr,VGr,XGr,Ht,_S,zGr,D6e,QGr,WGr,sm,UGr,G6e,HGr,JGr,cre,YGr,KGr,ZGr,q0,eOr,Gr,bS,oOr,O6e,rOr,tOr,$n,aOr,V6e,nOr,sOr,X6e,lOr,iOr,z6e,dOr,cOr,mOr,ge,j0,Q6e,fOr,gOr,mre,hOr,uOr,pOr,D0,W6e,_Or,bOr,fre,vOr,FOr,TOr,G0,U6e,MOr,EOr,gre,COr,wOr,AOr,O0,H6e,LOr,yOr,hre,xOr,$Or,kOr,V0,J6e,SOr,ROr,ure,POr,BOr,IOr,X0,Y6e,NOr,qOr,pre,jOr,DOr,GOr,z0,K6e,OOr,VOr,_re,XOr,zOr,QOr,Q0,Z6e,WOr,UOr,bre,HOr,JOr,YOr,W0,e7e,KOr,ZOr,vre,eVr,oVr,rVr,U0,o7e,tVr,aVr,Fre,nVr,sVr,lVr,H0,r7e,iVr,dVr,Tre,cVr,mVr,fVr,J0,t7e,gVr,hVr,Mre,uVr,pVr,_Vr,Y0,a7e,bVr,vVr,Ere,FVr,TVr,MVr,K0,n7e,EVr,CVr,Cre,wVr,AVr,LVr,Z0,s7e,yVr,xVr,wre,$Vr,kVr,SVr,ew,l7e,RVr,PVr,Are,BVr,IVr,NVr,ow,i7e,qVr,jVr,Lre,DVr,GVr,OVr,rw,d7e,VVr,XVr,yre,zVr,QVr,WVr,tw,c7e,UVr,HVr,xre,JVr,YVr,KVr,aw,m7e,ZVr,eXr,$re,oXr,rXr,tXr,nw,jeo,lm,sw,f7e,vS,aXr,g7e,nXr,Deo,fr,FS,sXr,im,lXr,kre,iXr,dXr,Sre,cXr,mXr,fXr,TS,gXr,h7e,hXr,uXr,pXr,Jt,MS,_Xr,u7e,bXr,vXr,dm,FXr,p7e,TXr,MXr,Rre,EXr,CXr,wXr,lw,AXr,Or,ES,LXr,_7e,yXr,xXr,kn,$Xr,b7e,kXr,SXr,v7e,RXr,PXr,F7e,BXr,IXr,NXr,ye,iw,T7e,qXr,jXr,Pre,DXr,GXr,OXr,dw,M7e,VXr,XXr,Bre,zXr,QXr,WXr,cw,E7e,UXr,HXr,Ire,JXr,YXr,KXr,mw,C7e,ZXr,ezr,Nre,ozr,rzr,tzr,fw,w7e,azr,nzr,qre,szr,lzr,izr,gw,A7e,dzr,czr,jre,mzr,fzr,gzr,hw,L7e,hzr,uzr,Dre,pzr,_zr,bzr,uw,y7e,vzr,Fzr,Gre,Tzr,Mzr,Ezr,pw,x7e,Czr,wzr,Ore,Azr,Lzr,yzr,_w,$7e,xzr,$zr,Vre,kzr,Szr,Rzr,bw,Geo,cm,vw,k7e,CS,Pzr,S7e,Bzr,Oeo,gr,wS,Izr,mm,Nzr,Xre,qzr,jzr,zre,Dzr,Gzr,Ozr,AS,Vzr,R7e,Xzr,zzr,Qzr,Yt,LS,Wzr,P7e,Uzr,Hzr,fm,Jzr,B7e,Yzr,Kzr,Qre,Zzr,eQr,oQr,Fw,rQr,Vr,yS,tQr,I7e,aQr,nQr,Sn,sQr,N7e,lQr,iQr,q7e,dQr,cQr,j7e,mQr,fQr,gQr,re,Tw,D7e,hQr,uQr,Wre,pQr,_Qr,bQr,Mw,G7e,vQr,FQr,Ure,TQr,MQr,EQr,Ew,O7e,CQr,wQr,Hre,AQr,LQr,yQr,Cw,V7e,xQr,$Qr,Jre,kQr,SQr,RQr,ww,X7e,PQr,BQr,Yre,IQr,NQr,qQr,Aw,z7e,jQr,DQr,Kre,GQr,OQr,VQr,Lw,Q7e,XQr,zQr,Zre,QQr,WQr,UQr,yw,W7e,HQr,JQr,ete,YQr,KQr,ZQr,xw,U7e,eWr,oWr,ote,rWr,tWr,aWr,$w,H7e,nWr,sWr,rte,lWr,iWr,dWr,kw,J7e,cWr,mWr,tte,fWr,gWr,hWr,Sw,Y7e,uWr,pWr,ate,_Wr,bWr,vWr,Rw,K7e,FWr,TWr,nte,MWr,EWr,CWr,Pw,Z7e,wWr,AWr,ste,LWr,yWr,xWr,Bw,eLe,$Wr,kWr,lte,SWr,RWr,PWr,Iw,oLe,BWr,IWr,ite,NWr,qWr,jWr,Nw,rLe,DWr,GWr,dte,OWr,VWr,XWr,qw,tLe,zWr,QWr,cte,WWr,UWr,HWr,jw,aLe,JWr,YWr,mte,KWr,ZWr,eUr,Dw,nLe,oUr,rUr,fte,tUr,aUr,nUr,Gw,sLe,sUr,lUr,gte,iUr,dUr,cUr,Ow,lLe,mUr,fUr,hte,gUr,hUr,uUr,Vw,iLe,pUr,_Ur,ute,bUr,vUr,FUr,Xw,dLe,TUr,MUr,pte,EUr,CUr,wUr,zw,cLe,AUr,LUr,_te,yUr,xUr,$Ur,Qw,mLe,kUr,SUr,bte,RUr,PUr,BUr,Ww,fLe,IUr,NUr,vte,qUr,jUr,DUr,Uw,Veo,gm,Hw,gLe,xS,GUr,hLe,OUr,Xeo,hr,$S,VUr,hm,XUr,Fte,zUr,QUr,Tte,WUr,UUr,HUr,kS,JUr,uLe,YUr,KUr,ZUr,Kt,SS,eHr,pLe,oHr,rHr,um,tHr,_Le,aHr,nHr,Mte,sHr,lHr,iHr,Jw,dHr,Xr,RS,cHr,bLe,mHr,fHr,Rn,gHr,vLe,hHr,uHr,FLe,pHr,_Hr,TLe,bHr,vHr,FHr,ve,Yw,MLe,THr,MHr,Ete,EHr,CHr,wHr,Kw,ELe,AHr,LHr,Cte,yHr,xHr,$Hr,Zw,CLe,kHr,SHr,wte,RHr,PHr,BHr,eA,wLe,IHr,NHr,Ate,qHr,jHr,DHr,oA,ALe,GHr,OHr,Lte,VHr,XHr,zHr,rA,LLe,QHr,WHr,yte,UHr,HHr,JHr,tA,yLe,YHr,KHr,xte,ZHr,eJr,oJr,aA,xLe,rJr,tJr,$te,aJr,nJr,sJr,nA,$Le,lJr,iJr,kte,dJr,cJr,mJr,sA,kLe,fJr,gJr,Ste,hJr,uJr,pJr,lA,SLe,_Jr,bJr,Rte,vJr,FJr,TJr,iA,RLe,MJr,EJr,Pte,CJr,wJr,AJr,dA,PLe,LJr,yJr,Bte,xJr,$Jr,kJr,cA,BLe,SJr,RJr,Ite,PJr,BJr,IJr,mA,ILe,NJr,qJr,Nte,jJr,DJr,GJr,fA,NLe,OJr,VJr,qte,XJr,zJr,QJr,gA,qLe,WJr,UJr,jte,HJr,JJr,YJr,hA,zeo,pm,uA,jLe,PS,KJr,DLe,ZJr,Qeo,ur,BS,eYr,_m,oYr,Dte,rYr,tYr,Gte,aYr,nYr,sYr,IS,lYr,GLe,iYr,dYr,cYr,Zt,NS,mYr,OLe,fYr,gYr,bm,hYr,VLe,uYr,pYr,Ote,_Yr,bYr,vYr,pA,FYr,zr,qS,TYr,XLe,MYr,EYr,Pn,CYr,zLe,wYr,AYr,QLe,LYr,yYr,WLe,xYr,$Yr,kYr,jS,_A,ULe,SYr,RYr,Vte,PYr,BYr,IYr,bA,HLe,NYr,qYr,Xte,jYr,DYr,GYr,vA,Weo,vm,FA,JLe,DS,OYr,YLe,VYr,Ueo,pr,GS,XYr,Fm,zYr,zte,QYr,WYr,Qte,UYr,HYr,JYr,OS,YYr,KLe,KYr,ZYr,eKr,ea,VS,oKr,ZLe,rKr,tKr,Tm,aKr,eye,nKr,sKr,Wte,lKr,iKr,dKr,TA,cKr,Qr,XS,mKr,oye,fKr,gKr,Bn,hKr,rye,uKr,pKr,tye,_Kr,bKr,aye,vKr,FKr,TKr,nye,MA,sye,MKr,EKr,Ute,CKr,wKr,AKr,EA,Heo,Mm,CA,lye,zS,LKr,iye,yKr,Jeo,_r,QS,xKr,Em,$Kr,Hte,kKr,SKr,Jte,RKr,PKr,BKr,WS,IKr,dye,NKr,qKr,jKr,oa,US,DKr,cye,GKr,OKr,Cm,VKr,mye,XKr,zKr,Yte,QKr,WKr,UKr,wA,HKr,Wr,HS,JKr,fye,YKr,KKr,In,ZKr,gye,eZr,oZr,hye,rZr,tZr,uye,aZr,nZr,sZr,pye,AA,_ye,lZr,iZr,Kte,dZr,cZr,mZr,LA,Yeo,wm,yA,bye,JS,fZr,vye,gZr,Keo,br,YS,hZr,Am,uZr,Zte,pZr,_Zr,eae,bZr,vZr,FZr,KS,TZr,Fye,MZr,EZr,CZr,ra,ZS,wZr,Tye,AZr,LZr,Lm,yZr,Mye,xZr,$Zr,oae,kZr,SZr,RZr,xA,PZr,Ur,eR,BZr,Eye,IZr,NZr,Nn,qZr,Cye,jZr,DZr,wye,GZr,OZr,Aye,VZr,XZr,zZr,de,$A,Lye,QZr,WZr,rae,UZr,HZr,JZr,kA,yye,YZr,KZr,tae,ZZr,eet,oet,SA,xye,ret,tet,aae,aet,net,set,RA,$ye,iet,det,nae,cet,met,fet,PA,kye,get,het,sae,uet,pet,_et,BA,Sye,bet,vet,lae,Fet,Tet,Met,IA,Rye,Eet,Cet,iae,wet,Aet,Let,NA,Pye,yet,xet,dae,$et,ket,Set,qA,Bye,Ret,Pet,cae,Bet,Iet,Net,jA,Iye,qet,jet,mae,Det,Get,Oet,DA,Nye,Vet,Xet,fae,zet,Qet,Wet,GA,qye,Uet,Het,gae,Jet,Yet,Ket,OA,jye,Zet,eot,hae,oot,rot,tot,VA,Dye,aot,not,uae,sot,lot,iot,XA,Gye,dot,cot,pae,mot,fot,got,zA,Oye,hot,uot,_ae,pot,_ot,bot,QA,Vye,vot,Fot,bae,Tot,Mot,Eot,WA,Xye,Cot,wot,vae,Aot,Lot,yot,UA,zye,xot,$ot,Fae,kot,Sot,Rot,HA,Qye,Pot,Bot,Tae,Iot,Not,qot,JA,Wye,jot,Dot,Mae,Got,Oot,Vot,YA,Zeo,ym,KA,Uye,oR,Xot,Hye,zot,eoo,vr,rR,Qot,xm,Wot,Eae,Uot,Hot,Cae,Jot,Yot,Kot,tR,Zot,Jye,ert,ort,rrt,ta,aR,trt,Yye,art,nrt,$m,srt,Kye,lrt,irt,wae,drt,crt,mrt,ZA,frt,Hr,nR,grt,Zye,hrt,urt,qn,prt,e8e,_rt,brt,o8e,vrt,Frt,r8e,Trt,Mrt,Ert,ce,e6,t8e,Crt,wrt,Aae,Art,Lrt,yrt,o6,a8e,xrt,$rt,Lae,krt,Srt,Rrt,r6,n8e,Prt,Brt,yae,Irt,Nrt,qrt,t6,s8e,jrt,Drt,xae,Grt,Ort,Vrt,a6,l8e,Xrt,zrt,$ae,Qrt,Wrt,Urt,n6,i8e,Hrt,Jrt,kae,Yrt,Krt,Zrt,s6,d8e,ett,ott,Sae,rtt,ttt,att,l6,c8e,ntt,stt,Rae,ltt,itt,dtt,i6,m8e,ctt,mtt,Pae,ftt,gtt,htt,d6,f8e,utt,ptt,Bae,_tt,btt,vtt,c6,g8e,Ftt,Ttt,Iae,Mtt,Ett,Ctt,m6,h8e,wtt,Att,Nae,Ltt,ytt,xtt,f6,u8e,$tt,ktt,qae,Stt,Rtt,Ptt,g6,p8e,Btt,Itt,jae,Ntt,qtt,jtt,h6,_8e,Dtt,Gtt,Dae,Ott,Vtt,Xtt,u6,b8e,ztt,Qtt,Gae,Wtt,Utt,Htt,p6,v8e,Jtt,Ytt,Oae,Ktt,Ztt,eat,_6,F8e,oat,rat,Vae,tat,aat,nat,b6,T8e,sat,lat,Xae,iat,dat,cat,v6,M8e,mat,fat,zae,gat,hat,uat,F6,E8e,pat,_at,Qae,bat,vat,Fat,T6,ooo,km,M6,C8e,sR,Tat,w8e,Mat,roo,Fr,lR,Eat,Sm,Cat,Wae,wat,Aat,Uae,Lat,yat,xat,iR,$at,A8e,kat,Sat,Rat,aa,dR,Pat,L8e,Bat,Iat,Rm,Nat,y8e,qat,jat,Hae,Dat,Gat,Oat,E6,Vat,Jr,cR,Xat,x8e,zat,Qat,jn,Wat,$8e,Uat,Hat,k8e,Jat,Yat,S8e,Kat,Zat,ent,R8e,C6,P8e,ont,rnt,Jae,tnt,ant,nnt,w6,too,Pm,A6,B8e,mR,snt,I8e,lnt,aoo,Tr,fR,int,Bm,dnt,Yae,cnt,mnt,Kae,fnt,gnt,hnt,gR,unt,N8e,pnt,_nt,bnt,na,hR,vnt,q8e,Fnt,Tnt,Im,Mnt,j8e,Ent,Cnt,Zae,wnt,Ant,Lnt,L6,ynt,Yr,uR,xnt,D8e,$nt,knt,Dn,Snt,G8e,Rnt,Pnt,O8e,Bnt,Int,V8e,Nnt,qnt,jnt,X8e,y6,z8e,Dnt,Gnt,ene,Ont,Vnt,Xnt,x6,noo,Nm,$6,Q8e,pR,znt,W8e,Qnt,soo,Mr,_R,Wnt,qm,Unt,one,Hnt,Jnt,rne,Ynt,Knt,Znt,bR,est,U8e,ost,rst,tst,sa,vR,ast,H8e,nst,sst,jm,lst,J8e,ist,dst,tne,cst,mst,fst,k6,gst,Kr,FR,hst,Y8e,ust,pst,Gn,_st,K8e,bst,vst,Z8e,Fst,Tst,e9e,Mst,Est,Cst,te,S6,o9e,wst,Ast,ane,Lst,yst,xst,R6,r9e,$st,kst,nne,Sst,Rst,Pst,P6,t9e,Bst,Ist,sne,Nst,qst,jst,B6,a9e,Dst,Gst,lne,Ost,Vst,Xst,I6,n9e,zst,Qst,ine,Wst,Ust,Hst,N6,s9e,Jst,Yst,dne,Kst,Zst,elt,q6,l9e,olt,rlt,cne,tlt,alt,nlt,j6,i9e,slt,llt,mne,ilt,dlt,clt,D6,d9e,mlt,flt,fne,glt,hlt,ult,G6,c9e,plt,_lt,gne,blt,vlt,Flt,O6,m9e,Tlt,Mlt,hne,Elt,Clt,wlt,V6,f9e,Alt,Llt,une,ylt,xlt,$lt,X6,g9e,klt,Slt,pne,Rlt,Plt,Blt,z6,h9e,Ilt,Nlt,_ne,qlt,jlt,Dlt,Q6,u9e,Glt,Olt,bne,Vlt,Xlt,zlt,W6,p9e,Qlt,Wlt,vne,Ult,Hlt,Jlt,U6,_9e,Ylt,Klt,Fne,Zlt,eit,oit,H6,b9e,rit,tit,Tne,ait,nit,sit,J6,v9e,lit,iit,Mne,dit,cit,mit,Y6,F9e,fit,git,Ene,hit,uit,pit,K6,T9e,_it,bit,Cne,vit,Fit,Tit,Z6,M9e,Mit,Eit,wne,Cit,wit,Ait,e7,E9e,Lit,yit,Ane,xit,$it,kit,o7,C9e,Sit,Rit,Lne,Pit,Bit,Iit,r7,w9e,Nit,qit,yne,jit,Dit,Git,t7,A9e,Oit,Vit,xne,Xit,zit,Qit,a7,L9e,Wit,Uit,$ne,Hit,Jit,Yit,n7,loo,Dm,s7,y9e,TR,Kit,x9e,Zit,ioo,Er,MR,edt,Gm,odt,kne,rdt,tdt,Sne,adt,ndt,sdt,ER,ldt,$9e,idt,ddt,cdt,la,CR,mdt,k9e,fdt,gdt,Om,hdt,S9e,udt,pdt,Rne,_dt,bdt,vdt,l7,Fdt,Zr,wR,Tdt,R9e,Mdt,Edt,On,Cdt,P9e,wdt,Adt,B9e,Ldt,ydt,I9e,xdt,$dt,kdt,xe,i7,N9e,Sdt,Rdt,Pne,Pdt,Bdt,Idt,d7,q9e,Ndt,qdt,Bne,jdt,Ddt,Gdt,c7,j9e,Odt,Vdt,Ine,Xdt,zdt,Qdt,m7,D9e,Wdt,Udt,Nne,Hdt,Jdt,Ydt,f7,G9e,Kdt,Zdt,qne,ect,oct,rct,g7,O9e,tct,act,jne,nct,sct,lct,h7,V9e,ict,dct,Dne,cct,mct,fct,u7,X9e,gct,hct,Gne,uct,pct,_ct,p7,z9e,bct,vct,One,Fct,Tct,Mct,_7,Q9e,Ect,Cct,Vne,wct,Act,Lct,b7,doo,Vm,v7,W9e,AR,yct,U9e,xct,coo,Cr,LR,$ct,Xm,kct,Xne,Sct,Rct,zne,Pct,Bct,Ict,yR,Nct,H9e,qct,jct,Dct,ia,xR,Gct,J9e,Oct,Vct,zm,Xct,Y9e,zct,Qct,Qne,Wct,Uct,Hct,F7,Jct,et,$R,Yct,K9e,Kct,Zct,Vn,emt,Z9e,omt,rmt,exe,tmt,amt,oxe,nmt,smt,lmt,Ee,T7,rxe,imt,dmt,Wne,cmt,mmt,fmt,M7,txe,gmt,hmt,Une,umt,pmt,_mt,E7,axe,bmt,vmt,Hne,Fmt,Tmt,Mmt,C7,nxe,Emt,Cmt,Jne,wmt,Amt,Lmt,w7,sxe,ymt,xmt,Yne,$mt,kmt,Smt,A7,lxe,Rmt,Pmt,Kne,Bmt,Imt,Nmt,L7,ixe,qmt,jmt,Zne,Dmt,Gmt,Omt,y7,dxe,Vmt,Xmt,ese,zmt,Qmt,Wmt,x7,cxe,Umt,Hmt,ose,Jmt,Ymt,Kmt,$7,mxe,Zmt,eft,rse,oft,rft,tft,k7,fxe,aft,nft,tse,sft,lft,ift,S7,gxe,dft,cft,ase,mft,fft,gft,R7,hxe,hft,uft,nse,pft,_ft,bft,P7,moo,Qm,B7,uxe,kR,vft,pxe,Fft,foo,wr,SR,Tft,Wm,Mft,sse,Eft,Cft,lse,wft,Aft,Lft,RR,yft,_xe,xft,$ft,kft,da,PR,Sft,bxe,Rft,Pft,Um,Bft,vxe,Ift,Nft,ise,qft,jft,Dft,I7,Gft,ot,BR,Oft,Fxe,Vft,Xft,Xn,zft,Txe,Qft,Wft,Mxe,Uft,Hft,Exe,Jft,Yft,Kft,$e,N7,Cxe,Zft,egt,dse,ogt,rgt,tgt,q7,wxe,agt,ngt,cse,sgt,lgt,igt,j7,Axe,dgt,cgt,mse,mgt,fgt,ggt,D7,Lxe,hgt,ugt,fse,pgt,_gt,bgt,G7,yxe,vgt,Fgt,gse,Tgt,Mgt,Egt,O7,xxe,Cgt,wgt,hse,Agt,Lgt,ygt,V7,$xe,xgt,$gt,use,kgt,Sgt,Rgt,X7,kxe,Pgt,Bgt,pse,Igt,Ngt,qgt,z7,Sxe,jgt,Dgt,_se,Ggt,Ogt,Vgt,Q7,Rxe,Xgt,zgt,bse,Qgt,Wgt,Ugt,W7,goo,Hm,U7,Pxe,IR,Hgt,Bxe,Jgt,hoo,Ar,NR,Ygt,Jm,Kgt,vse,Zgt,eht,Fse,oht,rht,tht,qR,aht,Ixe,nht,sht,lht,ca,jR,iht,Nxe,dht,cht,Ym,mht,qxe,fht,ght,Tse,hht,uht,pht,H7,_ht,rt,DR,bht,jxe,vht,Fht,zn,Tht,Dxe,Mht,Eht,Gxe,Cht,wht,Oxe,Aht,Lht,yht,ke,J7,Vxe,xht,$ht,Mse,kht,Sht,Rht,Y7,Xxe,Pht,Bht,Ese,Iht,Nht,qht,K7,zxe,jht,Dht,Cse,Ght,Oht,Vht,Z7,Qxe,Xht,zht,wse,Qht,Wht,Uht,eL,Wxe,Hht,Jht,Ase,Yht,Kht,Zht,oL,Uxe,eut,out,Lse,rut,tut,aut,rL,Hxe,nut,sut,yse,lut,iut,dut,tL,Jxe,cut,mut,xse,fut,gut,hut,aL,Yxe,uut,put,$se,_ut,but,vut,nL,Kxe,Fut,Tut,kse,Mut,Eut,Cut,sL,uoo,Km,lL,Zxe,GR,wut,e$e,Aut,poo,Lr,OR,Lut,Zm,yut,Sse,xut,$ut,Rse,kut,Sut,Rut,VR,Put,o$e,But,Iut,Nut,ma,XR,qut,r$e,jut,Dut,ef,Gut,t$e,Out,Vut,Pse,Xut,zut,Qut,iL,Wut,tt,zR,Uut,a$e,Hut,Jut,Qn,Yut,n$e,Kut,Zut,s$e,ept,opt,l$e,rpt,tpt,apt,Se,dL,i$e,npt,spt,Bse,lpt,ipt,dpt,cL,d$e,cpt,mpt,Ise,fpt,gpt,hpt,mL,c$e,upt,ppt,Nse,_pt,bpt,vpt,fL,m$e,Fpt,Tpt,qse,Mpt,Ept,Cpt,gL,f$e,wpt,Apt,jse,Lpt,ypt,xpt,hL,g$e,$pt,kpt,Dse,Spt,Rpt,Ppt,uL,h$e,Bpt,Ipt,Gse,Npt,qpt,jpt,pL,u$e,Dpt,Gpt,Ose,Opt,Vpt,Xpt,_L,p$e,zpt,Qpt,Vse,Wpt,Upt,Hpt,bL,_$e,Jpt,Ypt,Xse,Kpt,Zpt,e_t,vL,_oo,of,FL,b$e,QR,o_t,v$e,r_t,boo,yr,WR,t_t,rf,a_t,zse,n_t,s_t,Qse,l_t,i_t,d_t,UR,c_t,F$e,m_t,f_t,g_t,fa,HR,h_t,T$e,u_t,p_t,tf,__t,M$e,b_t,v_t,Wse,F_t,T_t,M_t,TL,E_t,at,JR,C_t,E$e,w_t,A_t,Wn,L_t,C$e,y_t,x_t,w$e,$_t,k_t,A$e,S_t,R_t,P_t,Re,ML,L$e,B_t,I_t,Use,N_t,q_t,j_t,EL,y$e,D_t,G_t,Hse,O_t,V_t,X_t,CL,x$e,z_t,Q_t,Jse,W_t,U_t,H_t,wL,$$e,J_t,Y_t,Yse,K_t,Z_t,e2t,AL,k$e,o2t,r2t,Kse,t2t,a2t,n2t,LL,S$e,s2t,l2t,Zse,i2t,d2t,c2t,yL,R$e,m2t,f2t,ele,g2t,h2t,u2t,xL,P$e,p2t,_2t,ole,b2t,v2t,F2t,$L,B$e,T2t,M2t,rle,E2t,C2t,w2t,kL,I$e,A2t,L2t,tle,y2t,x2t,$2t,SL,voo,af,RL,N$e,YR,k2t,q$e,S2t,Foo,xr,KR,R2t,nf,P2t,ale,B2t,I2t,nle,N2t,q2t,j2t,ZR,D2t,j$e,G2t,O2t,V2t,ga,eP,X2t,D$e,z2t,Q2t,sf,W2t,G$e,U2t,H2t,sle,J2t,Y2t,K2t,PL,Z2t,nt,oP,ebt,O$e,obt,rbt,Un,tbt,V$e,abt,nbt,X$e,sbt,lbt,z$e,ibt,dbt,cbt,Xe,BL,Q$e,mbt,fbt,lle,gbt,hbt,ubt,IL,W$e,pbt,_bt,ile,bbt,vbt,Fbt,NL,U$e,Tbt,Mbt,dle,Ebt,Cbt,wbt,qL,H$e,Abt,Lbt,cle,ybt,xbt,$bt,jL,J$e,kbt,Sbt,mle,Rbt,Pbt,Bbt,DL,Y$e,Ibt,Nbt,fle,qbt,jbt,Dbt,GL,K$e,Gbt,Obt,gle,Vbt,Xbt,zbt,OL,Z$e,Qbt,Wbt,hle,Ubt,Hbt,Jbt,VL,Too,lf,XL,eke,rP,Ybt,oke,Kbt,Moo,$r,tP,Zbt,df,e1t,ule,o1t,r1t,ple,t1t,a1t,n1t,aP,s1t,rke,l1t,i1t,d1t,ha,nP,c1t,tke,m1t,f1t,cf,g1t,ake,h1t,u1t,_le,p1t,_1t,b1t,zL,v1t,st,sP,F1t,nke,T1t,M1t,Hn,E1t,ske,C1t,w1t,lke,A1t,L1t,ike,y1t,x1t,$1t,ze,QL,dke,k1t,S1t,ble,R1t,P1t,B1t,WL,cke,I1t,N1t,vle,q1t,j1t,D1t,UL,mke,G1t,O1t,Fle,V1t,X1t,z1t,HL,fke,Q1t,W1t,Tle,U1t,H1t,J1t,JL,gke,Y1t,K1t,Mle,Z1t,evt,ovt,YL,hke,rvt,tvt,Ele,avt,nvt,svt,KL,uke,lvt,ivt,Cle,dvt,cvt,mvt,ZL,pke,fvt,gvt,wle,hvt,uvt,pvt,ey,Eoo,mf,oy,_ke,lP,_vt,bke,bvt,Coo,kr,iP,vvt,ff,Fvt,Ale,Tvt,Mvt,Lle,Evt,Cvt,wvt,dP,Avt,vke,Lvt,yvt,xvt,ua,cP,$vt,Fke,kvt,Svt,gf,Rvt,Tke,Pvt,Bvt,yle,Ivt,Nvt,qvt,ry,jvt,lt,mP,Dvt,Mke,Gvt,Ovt,Jn,Vvt,Eke,Xvt,zvt,Cke,Qvt,Wvt,wke,Uvt,Hvt,Jvt,Ake,ty,Lke,Yvt,Kvt,xle,Zvt,eFt,oFt,ay,woo,hf,ny,yke,fP,rFt,xke,tFt,Aoo,Sr,gP,aFt,uf,nFt,$le,sFt,lFt,kle,iFt,dFt,cFt,hP,mFt,$ke,fFt,gFt,hFt,pa,uP,uFt,kke,pFt,_Ft,pf,bFt,Ske,vFt,FFt,Sle,TFt,MFt,EFt,sy,CFt,it,pP,wFt,Rke,AFt,LFt,Yn,yFt,Pke,xFt,$Ft,Bke,kFt,SFt,Ike,RFt,PFt,BFt,_P,ly,Nke,IFt,NFt,Rle,qFt,jFt,DFt,iy,qke,GFt,OFt,Ple,VFt,XFt,zFt,dy,Loo,_f,cy,jke,bP,QFt,Dke,WFt,yoo,Rr,vP,UFt,bf,HFt,Ble,JFt,YFt,Ile,KFt,ZFt,eTt,FP,oTt,Gke,rTt,tTt,aTt,_a,TP,nTt,Oke,sTt,lTt,vf,iTt,Vke,dTt,cTt,Nle,mTt,fTt,gTt,my,hTt,dt,MP,uTt,Xke,pTt,_Tt,Kn,bTt,zke,vTt,FTt,Qke,TTt,MTt,Wke,ETt,CTt,wTt,Uke,fy,Hke,ATt,LTt,qle,yTt,xTt,$Tt,gy,xoo;return d=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),U9=new oe({}),H9=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),yf=new kTt({props:{warning:!0,$$slots:{default:[C_a]},$$scope:{ctx:$}}}),J9=new oe({}),Y9=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L650"}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L673"}}),Kh=new I({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[w_a]},$$scope:{ctx:$}}}),ox=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L796"}}),rx=new oe({}),tx=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L427"}}),sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L441"}}),Bu=new I({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[A_a]},$$scope:{ctx:$}}}),lx=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L642"}}),ix=new oe({}),dx=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L202"}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L216"}}),Ap=new kTt({props:{$$slots:{default:[L_a]},$$scope:{ctx:$}}}),Lp=new I({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[y_a]},$$scope:{ctx:$}}}),gx=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L343"}}),hx=new oe({}),ux=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L95"}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L109"}}),Kp=new kTt({props:{$$slots:{default:[x_a]},$$scope:{ctx:$}}}),Zp=new I({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$_a]},$$scope:{ctx:$}}}),vx=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L276"}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L854"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r_=new I({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[k_a]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vb=new I({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[S_a]},$$scope:{ctx:$}}}),wx=new oe({}),Ax=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L861"}}),yx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Tb=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[R_a]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_1=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[P_a]},$$scope:{ctx:$}}}),$x=new oe({}),kx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L876"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v1=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[B_a]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dv=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[I_a]},$$scope:{ctx:$}}}),Bx=new oe({}),Ix=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L883"}}),qx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mv=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[N_a]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Kv=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[q_a]},$$scope:{ctx:$}}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L890"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eF=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[j_a]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),MF=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[D_a]},$$scope:{ctx:$}}}),zx=new oe({}),Qx=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L899"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),CF=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[G_a]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AT=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[O_a]},$$scope:{ctx:$}}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L955"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yT=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[V_a]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iM=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[X_a]},$$scope:{ctx:$}}}),o$=new oe({}),r$=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L962"}}),a$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cM=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[z_a]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vM=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Q_a]},$$scope:{ctx:$}}}),s$=new oe({}),l$=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L948"}}),d$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),TM=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[W_a]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iE=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[U_a]},$$scope:{ctx:$}}}),m$=new oe({}),f$=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L908"}}),h$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cE=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[H_a]},$$scope:{ctx:$}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t4=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[J_a]},$$scope:{ctx:$}}}),p$=new oe({}),_$=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L915"}}),v$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n4=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Y_a]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i4=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[K_a]},$$scope:{ctx:$}}}),T$=new oe({}),M$=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L937"}}),C$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),c4=new I({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[Z_a]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u4=new I({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[e2a]},$$scope:{ctx:$}}}),A$=new oe({}),L$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L971"}}),x$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_4=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[o2a]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P4=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[r2a]},$$scope:{ctx:$}}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1010"}}),P$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I4=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[t2a]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j4=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[a2a]},$$scope:{ctx:$}}}),I$=new oe({}),N$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1017"}}),j$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G4=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[n2a]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X4=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[s2a]},$$scope:{ctx:$}}}),G$=new oe({}),O$=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L926"}}),X$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q4=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[l2a]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H4=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[i2a]},$$scope:{ctx:$}}}),Q$=new oe({}),W$=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1024"}}),H$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y4=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[d2a]},$$scope:{ctx:$}}}),J$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[c2a]},$$scope:{ctx:$}}}),Y$=new oe({}),K$=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1047"}}),ek=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cC=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[m2a]},$$scope:{ctx:$}}}),ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_C=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[f2a]},$$scope:{ctx:$}}}),rk=new oe({}),tk=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1031"}}),nk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vC=new I({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[g2a]},$$scope:{ctx:$}}}),sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),kC=new I({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[h2a]},$$scope:{ctx:$}}}),lk=new oe({}),ik=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1038"}}),ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),RC=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[u2a]},$$scope:{ctx:$}}}),mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NC=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[p2a]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1056"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jC=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[_2a]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QC=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[b2a]},$$scope:{ctx:$}}}),bk=new oe({}),vk=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1063"}}),Tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UC=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[v2a]},$$scope:{ctx:$}}}),Mk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[F2a]},$$scope:{ctx:$}}}),Ek=new oe({}),Ck=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1003"}}),Ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[T2a]},$$scope:{ctx:$}}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[M2a]},$$scope:{ctx:$}}}),yk=new oe({}),xk=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L978"}}),kk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),c3=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[E2a]},$$scope:{ctx:$}}}),Sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g3=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[C2a]},$$scope:{ctx:$}}}),Rk=new oe({}),Pk=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L985"}}),Ik=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u3=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[w2a]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M3=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[A2a]},$$scope:{ctx:$}}}),qk=new oe({}),jk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L994"}}),Gk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C3=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[L2a]},$$scope:{ctx:$}}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L3=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[y2a]},$$scope:{ctx:$}}}),Vk=new oe({}),Xk=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L434"}}),Qk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x3=new I({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[x2a]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$5=new I({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[$2a]},$$scope:{ctx:$}}}),Uk=new oe({}),Hk=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),Yk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S5=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[k2a]},$$scope:{ctx:$}}}),Kk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r0=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[S2a]},$$scope:{ctx:$}}}),Zk=new oe({}),eS=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),rS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a0=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[R2a]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v0=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[P2a]},$$scope:{ctx:$}}}),aS=new oe({}),nS=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),lS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T0=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[B2a]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$0=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[I2a]},$$scope:{ctx:$}}}),dS=new oe({}),cS=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),fS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S0=new I({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[N2a]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I0=new I({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[q2a]},$$scope:{ctx:$}}}),hS=new oe({}),uS=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L497"}}),_S=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q0=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[j2a]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),nw=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[D2a]},$$scope:{ctx:$}}}),vS=new oe({}),FS=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),MS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),lw=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[G2a]},$$scope:{ctx:$}}}),ES=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bw=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[O2a]},$$scope:{ctx:$}}}),CS=new oe({}),wS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L513"}}),LS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Fw=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[V2a]},$$scope:{ctx:$}}}),yS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Uw=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[X2a]},$$scope:{ctx:$}}}),xS=new oe({}),$S=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L560"}}),SS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Jw=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[z2a]},$$scope:{ctx:$}}}),RS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hA=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Q2a]},$$scope:{ctx:$}}}),PS=new oe({}),BS=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L567"}}),NS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pA=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[W2a]},$$scope:{ctx:$}}}),qS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vA=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[U2a]},$$scope:{ctx:$}}}),DS=new oe({}),GS=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L540"}}),VS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),TA=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[H2a]},$$scope:{ctx:$}}}),XS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),EA=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[J2a]},$$scope:{ctx:$}}}),zS=new oe({}),QS=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L529"}}),US=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),wA=new I({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[Y2a]},$$scope:{ctx:$}}}),HS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),LA=new I({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[K2a]},$$scope:{ctx:$}}}),JS=new oe({}),YS=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L551"}}),ZS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xA=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[Z2a]},$$scope:{ctx:$}}}),eR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),YA=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[eba]},$$scope:{ctx:$}}}),oR=new oe({}),rR=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),aR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ZA=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[oba]},$$scope:{ctx:$}}}),nR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T6=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[rba]},$$scope:{ctx:$}}}),sR=new oe({}),lR=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L490"}}),dR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E6=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[tba]},$$scope:{ctx:$}}}),cR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w6=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[aba]},$$scope:{ctx:$}}}),mR=new oe({}),fR=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L576"}}),hR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),L6=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[nba]},$$scope:{ctx:$}}}),uR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x6=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[sba]},$$scope:{ctx:$}}}),pR=new oe({}),_R=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),vR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k6=new I({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[lba]},$$scope:{ctx:$}}}),FR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n7=new I({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[iba]},$$scope:{ctx:$}}}),TR=new oe({}),MR=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),CR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l7=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[dba]},$$scope:{ctx:$}}}),wR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),b7=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[cba]},$$scope:{ctx:$}}}),AR=new oe({}),LR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),xR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),F7=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[mba]},$$scope:{ctx:$}}}),$R=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[fba]},$$scope:{ctx:$}}}),kR=new oe({}),SR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),PR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[gba]},$$scope:{ctx:$}}}),BR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W7=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[hba]},$$scope:{ctx:$}}}),IR=new oe({}),NR=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),jR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H7=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[uba]},$$scope:{ctx:$}}}),DR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sL=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[pba]},$$scope:{ctx:$}}}),GR=new oe({}),OR=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),XR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),iL=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[_ba]},$$scope:{ctx:$}}}),zR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vL=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[bba]},$$scope:{ctx:$}}}),QR=new oe({}),WR=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),HR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),TL=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[vba]},$$scope:{ctx:$}}}),JR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),SL=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Fba]},$$scope:{ctx:$}}}),YR=new oe({}),KR=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),eP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),PL=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Tba]},$$scope:{ctx:$}}}),oP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VL=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Mba]},$$scope:{ctx:$}}}),rP=new oe({}),tP=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),nP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zL=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Eba]},$$scope:{ctx:$}}}),sP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ey=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Cba]},$$scope:{ctx:$}}}),lP=new oe({}),iP=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),cP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ry=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[wba]},$$scope:{ctx:$}}}),mP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ay=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Aba]},$$scope:{ctx:$}}}),fP=new oe({}),gP=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),uP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sy=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Lba]},$$scope:{ctx:$}}}),pP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dy=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[yba]},$$scope:{ctx:$}}}),bP=new oe({}),vP=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),TP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),my=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[xba]},$$scope:{ctx:$}}}),MP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gy=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[$ba]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),yo=a("span"),td=o("Auto Classes"),Ef=l(),pt=a("p"),ad=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),nd=a("code"),X9=o("from_pretrained()"),Cf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),sd=o("Instantiating one of "),es=a("a"),z9=o("AutoConfig"),os=o(", "),rs=a("a"),Q9=o("AutoModel"),ld=o(`, and
`),ts=a("a"),W9=o("AutoTokenizer"),id=o(" will directly create a class of the relevant architecture. For instance"),wf=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),UB=o("will create a model that is an instance of "),dd=a("a"),HB=o("BertModel"),JB=o("."),xo=l(),Wa=a("p"),YB=o("There is one class of "),Af=a("code"),KB=o("AutoModel"),Qto=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),pZe=l(),cd=a("h2"),Lf=a("a"),Ode=a("span"),F(U9.$$.fragment),Wto=l(),Vde=a("span"),Uto=o("Extending the Auto Classes"),_Ze=l(),as=a("p"),Hto=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Xde=a("code"),Jto=o("NewModel"),Yto=o(", make sure you have a "),zde=a("code"),Kto=o("NewModelConfig"),Zto=o(` then you can add those to the auto
classes like this:`),bZe=l(),F(H9.$$.fragment),vZe=l(),ZB=a("p"),eao=o("You will then be able to use the auto classes like you would usually do!"),FZe=l(),F(yf.$$.fragment),TZe=l(),md=a("h2"),xf=a("a"),Qde=a("span"),F(J9.$$.fragment),oao=l(),Wde=a("span"),rao=o("AutoConfig"),MZe=l(),$o=a("div"),F(Y9.$$.fragment),tao=l(),K9=a("p"),aao=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),eI=a("a"),nao=o("from_pretrained()"),sao=o(" class method."),lao=l(),Z9=a("p"),iao=o("This class cannot be instantiated directly using "),Ude=a("code"),dao=o("__init__()"),cao=o(" (throws an error)."),mao=l(),Pr=a("div"),F(ex.$$.fragment),fao=l(),Hde=a("p"),gao=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),hao=l(),fd=a("p"),uao=o("The configuration class to instantiate is selected based on the "),Jde=a("code"),pao=o("model_type"),_ao=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Yde=a("code"),bao=o("pretrained_model_name_or_path"),vao=o(":"),Fao=l(),A=a("ul"),$f=a("li"),Kde=a("strong"),Tao=o("albert"),Mao=o(" \u2014 "),oI=a("a"),Eao=o("AlbertConfig"),Cao=o(" (ALBERT model)"),wao=l(),kf=a("li"),Zde=a("strong"),Aao=o("bart"),Lao=o(" \u2014 "),rI=a("a"),yao=o("BartConfig"),xao=o(" (BART model)"),$ao=l(),Sf=a("li"),ece=a("strong"),kao=o("beit"),Sao=o(" \u2014 "),tI=a("a"),Rao=o("BeitConfig"),Pao=o(" (BEiT model)"),Bao=l(),Rf=a("li"),oce=a("strong"),Iao=o("bert"),Nao=o(" \u2014 "),aI=a("a"),qao=o("BertConfig"),jao=o(" (BERT model)"),Dao=l(),Pf=a("li"),rce=a("strong"),Gao=o("bert-generation"),Oao=o(" \u2014 "),nI=a("a"),Vao=o("BertGenerationConfig"),Xao=o(" (Bert Generation model)"),zao=l(),Bf=a("li"),tce=a("strong"),Qao=o("big_bird"),Wao=o(" \u2014 "),sI=a("a"),Uao=o("BigBirdConfig"),Hao=o(" (BigBird model)"),Jao=l(),If=a("li"),ace=a("strong"),Yao=o("bigbird_pegasus"),Kao=o(" \u2014 "),lI=a("a"),Zao=o("BigBirdPegasusConfig"),eno=o(" (BigBird-Pegasus model)"),ono=l(),Nf=a("li"),nce=a("strong"),rno=o("blenderbot"),tno=o(" \u2014 "),iI=a("a"),ano=o("BlenderbotConfig"),nno=o(" (Blenderbot model)"),sno=l(),qf=a("li"),sce=a("strong"),lno=o("blenderbot-small"),ino=o(" \u2014 "),dI=a("a"),dno=o("BlenderbotSmallConfig"),cno=o(" (BlenderbotSmall model)"),mno=l(),jf=a("li"),lce=a("strong"),fno=o("bloom"),gno=o(" \u2014 "),cI=a("a"),hno=o("BloomConfig"),uno=o(" (BLOOM model)"),pno=l(),Df=a("li"),ice=a("strong"),_no=o("camembert"),bno=o(" \u2014 "),mI=a("a"),vno=o("CamembertConfig"),Fno=o(" (CamemBERT model)"),Tno=l(),Gf=a("li"),dce=a("strong"),Mno=o("canine"),Eno=o(" \u2014 "),fI=a("a"),Cno=o("CanineConfig"),wno=o(" (CANINE model)"),Ano=l(),Of=a("li"),cce=a("strong"),Lno=o("clip"),yno=o(" \u2014 "),gI=a("a"),xno=o("CLIPConfig"),$no=o(" (CLIP model)"),kno=l(),Vf=a("li"),mce=a("strong"),Sno=o("codegen"),Rno=o(" \u2014 "),hI=a("a"),Pno=o("CodeGenConfig"),Bno=o(" (CodeGen model)"),Ino=l(),Xf=a("li"),fce=a("strong"),Nno=o("conditional_detr"),qno=o(" \u2014 "),uI=a("a"),jno=o("ConditionalDetrConfig"),Dno=o(" (Conditional DETR model)"),Gno=l(),zf=a("li"),gce=a("strong"),Ono=o("convbert"),Vno=o(" \u2014 "),pI=a("a"),Xno=o("ConvBertConfig"),zno=o(" (ConvBERT model)"),Qno=l(),Qf=a("li"),hce=a("strong"),Wno=o("convnext"),Uno=o(" \u2014 "),_I=a("a"),Hno=o("ConvNextConfig"),Jno=o(" (ConvNeXT model)"),Yno=l(),Wf=a("li"),uce=a("strong"),Kno=o("ctrl"),Zno=o(" \u2014 "),bI=a("a"),eso=o("CTRLConfig"),oso=o(" (CTRL model)"),rso=l(),Uf=a("li"),pce=a("strong"),tso=o("cvt"),aso=o(" \u2014 "),vI=a("a"),nso=o("CvtConfig"),sso=o(" (CvT model)"),lso=l(),Hf=a("li"),_ce=a("strong"),iso=o("data2vec-audio"),dso=o(" \u2014 "),FI=a("a"),cso=o("Data2VecAudioConfig"),mso=o(" (Data2VecAudio model)"),fso=l(),Jf=a("li"),bce=a("strong"),gso=o("data2vec-text"),hso=o(" \u2014 "),TI=a("a"),uso=o("Data2VecTextConfig"),pso=o(" (Data2VecText model)"),_so=l(),Yf=a("li"),vce=a("strong"),bso=o("data2vec-vision"),vso=o(" \u2014 "),MI=a("a"),Fso=o("Data2VecVisionConfig"),Tso=o(" (Data2VecVision model)"),Mso=l(),Kf=a("li"),Fce=a("strong"),Eso=o("deberta"),Cso=o(" \u2014 "),EI=a("a"),wso=o("DebertaConfig"),Aso=o(" (DeBERTa model)"),Lso=l(),Zf=a("li"),Tce=a("strong"),yso=o("deberta-v2"),xso=o(" \u2014 "),CI=a("a"),$so=o("DebertaV2Config"),kso=o(" (DeBERTa-v2 model)"),Sso=l(),eg=a("li"),Mce=a("strong"),Rso=o("decision_transformer"),Pso=o(" \u2014 "),wI=a("a"),Bso=o("DecisionTransformerConfig"),Iso=o(" (Decision Transformer model)"),Nso=l(),og=a("li"),Ece=a("strong"),qso=o("deformable_detr"),jso=o(" \u2014 "),AI=a("a"),Dso=o("DeformableDetrConfig"),Gso=o(" (Deformable DETR model)"),Oso=l(),rg=a("li"),Cce=a("strong"),Vso=o("deit"),Xso=o(" \u2014 "),LI=a("a"),zso=o("DeiTConfig"),Qso=o(" (DeiT model)"),Wso=l(),tg=a("li"),wce=a("strong"),Uso=o("detr"),Hso=o(" \u2014 "),yI=a("a"),Jso=o("DetrConfig"),Yso=o(" (DETR model)"),Kso=l(),ag=a("li"),Ace=a("strong"),Zso=o("distilbert"),elo=o(" \u2014 "),xI=a("a"),olo=o("DistilBertConfig"),rlo=o(" (DistilBERT model)"),tlo=l(),ng=a("li"),Lce=a("strong"),alo=o("donut-swin"),nlo=o(" \u2014 "),$I=a("a"),slo=o("DonutSwinConfig"),llo=o(" (DonutSwin model)"),ilo=l(),sg=a("li"),yce=a("strong"),dlo=o("dpr"),clo=o(" \u2014 "),kI=a("a"),mlo=o("DPRConfig"),flo=o(" (DPR model)"),glo=l(),lg=a("li"),xce=a("strong"),hlo=o("dpt"),ulo=o(" \u2014 "),SI=a("a"),plo=o("DPTConfig"),_lo=o(" (DPT model)"),blo=l(),ig=a("li"),$ce=a("strong"),vlo=o("electra"),Flo=o(" \u2014 "),RI=a("a"),Tlo=o("ElectraConfig"),Mlo=o(" (ELECTRA model)"),Elo=l(),dg=a("li"),kce=a("strong"),Clo=o("encoder-decoder"),wlo=o(" \u2014 "),PI=a("a"),Alo=o("EncoderDecoderConfig"),Llo=o(" (Encoder decoder model)"),ylo=l(),cg=a("li"),Sce=a("strong"),xlo=o("ernie"),$lo=o(" \u2014 "),BI=a("a"),klo=o("ErnieConfig"),Slo=o(" (ERNIE model)"),Rlo=l(),mg=a("li"),Rce=a("strong"),Plo=o("flaubert"),Blo=o(" \u2014 "),II=a("a"),Ilo=o("FlaubertConfig"),Nlo=o(" (FlauBERT model)"),qlo=l(),fg=a("li"),Pce=a("strong"),jlo=o("flava"),Dlo=o(" \u2014 "),NI=a("a"),Glo=o("FlavaConfig"),Olo=o(" (FLAVA model)"),Vlo=l(),gg=a("li"),Bce=a("strong"),Xlo=o("fnet"),zlo=o(" \u2014 "),qI=a("a"),Qlo=o("FNetConfig"),Wlo=o(" (FNet model)"),Ulo=l(),hg=a("li"),Ice=a("strong"),Hlo=o("fsmt"),Jlo=o(" \u2014 "),jI=a("a"),Ylo=o("FSMTConfig"),Klo=o(" (FairSeq Machine-Translation model)"),Zlo=l(),ug=a("li"),Nce=a("strong"),eio=o("funnel"),oio=o(" \u2014 "),DI=a("a"),rio=o("FunnelConfig"),tio=o(" (Funnel Transformer model)"),aio=l(),pg=a("li"),qce=a("strong"),nio=o("glpn"),sio=o(" \u2014 "),GI=a("a"),lio=o("GLPNConfig"),iio=o(" (GLPN model)"),dio=l(),_g=a("li"),jce=a("strong"),cio=o("gpt2"),mio=o(" \u2014 "),OI=a("a"),fio=o("GPT2Config"),gio=o(" (OpenAI GPT-2 model)"),hio=l(),bg=a("li"),Dce=a("strong"),uio=o("gpt_neo"),pio=o(" \u2014 "),VI=a("a"),_io=o("GPTNeoConfig"),bio=o(" (GPT Neo model)"),vio=l(),vg=a("li"),Gce=a("strong"),Fio=o("gpt_neox"),Tio=o(" \u2014 "),XI=a("a"),Mio=o("GPTNeoXConfig"),Eio=o(" (GPT NeoX model)"),Cio=l(),Fg=a("li"),Oce=a("strong"),wio=o("gpt_neox_japanese"),Aio=o(" \u2014 "),zI=a("a"),Lio=o("GPTNeoXJapaneseConfig"),yio=o(" (GPT NeoX Japanese model)"),xio=l(),Tg=a("li"),Vce=a("strong"),$io=o("gptj"),kio=o(" \u2014 "),QI=a("a"),Sio=o("GPTJConfig"),Rio=o(" (GPT-J model)"),Pio=l(),Mg=a("li"),Xce=a("strong"),Bio=o("groupvit"),Iio=o(" \u2014 "),WI=a("a"),Nio=o("GroupViTConfig"),qio=o(" (GroupViT model)"),jio=l(),Eg=a("li"),zce=a("strong"),Dio=o("hubert"),Gio=o(" \u2014 "),UI=a("a"),Oio=o("HubertConfig"),Vio=o(" (Hubert model)"),Xio=l(),Cg=a("li"),Qce=a("strong"),zio=o("ibert"),Qio=o(" \u2014 "),HI=a("a"),Wio=o("IBertConfig"),Uio=o(" (I-BERT model)"),Hio=l(),wg=a("li"),Wce=a("strong"),Jio=o("imagegpt"),Yio=o(" \u2014 "),JI=a("a"),Kio=o("ImageGPTConfig"),Zio=o(" (ImageGPT model)"),edo=l(),Ag=a("li"),Uce=a("strong"),odo=o("layoutlm"),rdo=o(" \u2014 "),YI=a("a"),tdo=o("LayoutLMConfig"),ado=o(" (LayoutLM model)"),ndo=l(),Lg=a("li"),Hce=a("strong"),sdo=o("layoutlmv2"),ldo=o(" \u2014 "),KI=a("a"),ido=o("LayoutLMv2Config"),ddo=o(" (LayoutLMv2 model)"),cdo=l(),yg=a("li"),Jce=a("strong"),mdo=o("layoutlmv3"),fdo=o(" \u2014 "),ZI=a("a"),gdo=o("LayoutLMv3Config"),hdo=o(" (LayoutLMv3 model)"),udo=l(),xg=a("li"),Yce=a("strong"),pdo=o("led"),_do=o(" \u2014 "),eN=a("a"),bdo=o("LEDConfig"),vdo=o(" (LED model)"),Fdo=l(),$g=a("li"),Kce=a("strong"),Tdo=o("levit"),Mdo=o(" \u2014 "),oN=a("a"),Edo=o("LevitConfig"),Cdo=o(" (LeViT model)"),wdo=l(),kg=a("li"),Zce=a("strong"),Ado=o("longformer"),Ldo=o(" \u2014 "),rN=a("a"),ydo=o("LongformerConfig"),xdo=o(" (Longformer model)"),$do=l(),Sg=a("li"),eme=a("strong"),kdo=o("longt5"),Sdo=o(" \u2014 "),tN=a("a"),Rdo=o("LongT5Config"),Pdo=o(" (LongT5 model)"),Bdo=l(),Rg=a("li"),ome=a("strong"),Ido=o("luke"),Ndo=o(" \u2014 "),aN=a("a"),qdo=o("LukeConfig"),jdo=o(" (LUKE model)"),Ddo=l(),Pg=a("li"),rme=a("strong"),Gdo=o("lxmert"),Odo=o(" \u2014 "),nN=a("a"),Vdo=o("LxmertConfig"),Xdo=o(" (LXMERT model)"),zdo=l(),Bg=a("li"),tme=a("strong"),Qdo=o("m2m_100"),Wdo=o(" \u2014 "),sN=a("a"),Udo=o("M2M100Config"),Hdo=o(" (M2M100 model)"),Jdo=l(),Ig=a("li"),ame=a("strong"),Ydo=o("marian"),Kdo=o(" \u2014 "),lN=a("a"),Zdo=o("MarianConfig"),eco=o(" (Marian model)"),oco=l(),Ng=a("li"),nme=a("strong"),rco=o("markuplm"),tco=o(" \u2014 "),iN=a("a"),aco=o("MarkupLMConfig"),nco=o(" (MarkupLM model)"),sco=l(),qg=a("li"),sme=a("strong"),lco=o("maskformer"),ico=o(" \u2014 "),dN=a("a"),dco=o("MaskFormerConfig"),cco=o(" (MaskFormer model)"),mco=l(),jg=a("li"),lme=a("strong"),fco=o("mbart"),gco=o(" \u2014 "),cN=a("a"),hco=o("MBartConfig"),uco=o(" (mBART model)"),pco=l(),Dg=a("li"),ime=a("strong"),_co=o("mctct"),bco=o(" \u2014 "),mN=a("a"),vco=o("MCTCTConfig"),Fco=o(" (M-CTC-T model)"),Tco=l(),Gg=a("li"),dme=a("strong"),Mco=o("megatron-bert"),Eco=o(" \u2014 "),fN=a("a"),Cco=o("MegatronBertConfig"),wco=o(" (Megatron-BERT model)"),Aco=l(),Og=a("li"),cme=a("strong"),Lco=o("mobilebert"),yco=o(" \u2014 "),gN=a("a"),xco=o("MobileBertConfig"),$co=o(" (MobileBERT model)"),kco=l(),Vg=a("li"),mme=a("strong"),Sco=o("mobilevit"),Rco=o(" \u2014 "),hN=a("a"),Pco=o("MobileViTConfig"),Bco=o(" (MobileViT model)"),Ico=l(),Xg=a("li"),fme=a("strong"),Nco=o("mpnet"),qco=o(" \u2014 "),uN=a("a"),jco=o("MPNetConfig"),Dco=o(" (MPNet model)"),Gco=l(),zg=a("li"),gme=a("strong"),Oco=o("mt5"),Vco=o(" \u2014 "),pN=a("a"),Xco=o("MT5Config"),zco=o(" (MT5 model)"),Qco=l(),Qg=a("li"),hme=a("strong"),Wco=o("mvp"),Uco=o(" \u2014 "),_N=a("a"),Hco=o("MvpConfig"),Jco=o(" (MVP model)"),Yco=l(),Wg=a("li"),ume=a("strong"),Kco=o("nezha"),Zco=o(" \u2014 "),bN=a("a"),emo=o("NezhaConfig"),omo=o(" (Nezha model)"),rmo=l(),Ug=a("li"),pme=a("strong"),tmo=o("nystromformer"),amo=o(" \u2014 "),vN=a("a"),nmo=o("NystromformerConfig"),smo=o(" (Nystr\xF6mformer model)"),lmo=l(),Hg=a("li"),_me=a("strong"),imo=o("openai-gpt"),dmo=o(" \u2014 "),FN=a("a"),cmo=o("OpenAIGPTConfig"),mmo=o(" (OpenAI GPT model)"),fmo=l(),Jg=a("li"),bme=a("strong"),gmo=o("opt"),hmo=o(" \u2014 "),TN=a("a"),umo=o("OPTConfig"),pmo=o(" (OPT model)"),_mo=l(),Yg=a("li"),vme=a("strong"),bmo=o("owlvit"),vmo=o(" \u2014 "),MN=a("a"),Fmo=o("OwlViTConfig"),Tmo=o(" (OWL-ViT model)"),Mmo=l(),Kg=a("li"),Fme=a("strong"),Emo=o("pegasus"),Cmo=o(" \u2014 "),EN=a("a"),wmo=o("PegasusConfig"),Amo=o(" (Pegasus model)"),Lmo=l(),Zg=a("li"),Tme=a("strong"),ymo=o("pegasus_x"),xmo=o(" \u2014 "),CN=a("a"),$mo=o("PegasusXConfig"),kmo=o(" (PEGASUS-X model)"),Smo=l(),eh=a("li"),Mme=a("strong"),Rmo=o("perceiver"),Pmo=o(" \u2014 "),wN=a("a"),Bmo=o("PerceiverConfig"),Imo=o(" (Perceiver model)"),Nmo=l(),oh=a("li"),Eme=a("strong"),qmo=o("plbart"),jmo=o(" \u2014 "),AN=a("a"),Dmo=o("PLBartConfig"),Gmo=o(" (PLBart model)"),Omo=l(),rh=a("li"),Cme=a("strong"),Vmo=o("poolformer"),Xmo=o(" \u2014 "),LN=a("a"),zmo=o("PoolFormerConfig"),Qmo=o(" (PoolFormer model)"),Wmo=l(),th=a("li"),wme=a("strong"),Umo=o("prophetnet"),Hmo=o(" \u2014 "),yN=a("a"),Jmo=o("ProphetNetConfig"),Ymo=o(" (ProphetNet model)"),Kmo=l(),ah=a("li"),Ame=a("strong"),Zmo=o("qdqbert"),efo=o(" \u2014 "),xN=a("a"),ofo=o("QDQBertConfig"),rfo=o(" (QDQBert model)"),tfo=l(),nh=a("li"),Lme=a("strong"),afo=o("rag"),nfo=o(" \u2014 "),$N=a("a"),sfo=o("RagConfig"),lfo=o(" (RAG model)"),ifo=l(),sh=a("li"),yme=a("strong"),dfo=o("realm"),cfo=o(" \u2014 "),kN=a("a"),mfo=o("RealmConfig"),ffo=o(" (REALM model)"),gfo=l(),lh=a("li"),xme=a("strong"),hfo=o("reformer"),ufo=o(" \u2014 "),SN=a("a"),pfo=o("ReformerConfig"),_fo=o(" (Reformer model)"),bfo=l(),ih=a("li"),$me=a("strong"),vfo=o("regnet"),Ffo=o(" \u2014 "),RN=a("a"),Tfo=o("RegNetConfig"),Mfo=o(" (RegNet model)"),Efo=l(),dh=a("li"),kme=a("strong"),Cfo=o("rembert"),wfo=o(" \u2014 "),PN=a("a"),Afo=o("RemBertConfig"),Lfo=o(" (RemBERT model)"),yfo=l(),ch=a("li"),Sme=a("strong"),xfo=o("resnet"),$fo=o(" \u2014 "),BN=a("a"),kfo=o("ResNetConfig"),Sfo=o(" (ResNet model)"),Rfo=l(),mh=a("li"),Rme=a("strong"),Pfo=o("retribert"),Bfo=o(" \u2014 "),IN=a("a"),Ifo=o("RetriBertConfig"),Nfo=o(" (RetriBERT model)"),qfo=l(),fh=a("li"),Pme=a("strong"),jfo=o("roberta"),Dfo=o(" \u2014 "),NN=a("a"),Gfo=o("RobertaConfig"),Ofo=o(" (RoBERTa model)"),Vfo=l(),gh=a("li"),Bme=a("strong"),Xfo=o("roformer"),zfo=o(" \u2014 "),qN=a("a"),Qfo=o("RoFormerConfig"),Wfo=o(" (RoFormer model)"),Ufo=l(),hh=a("li"),Ime=a("strong"),Hfo=o("segformer"),Jfo=o(" \u2014 "),jN=a("a"),Yfo=o("SegformerConfig"),Kfo=o(" (SegFormer model)"),Zfo=l(),uh=a("li"),Nme=a("strong"),ego=o("sew"),ogo=o(" \u2014 "),DN=a("a"),rgo=o("SEWConfig"),tgo=o(" (SEW model)"),ago=l(),ph=a("li"),qme=a("strong"),ngo=o("sew-d"),sgo=o(" \u2014 "),GN=a("a"),lgo=o("SEWDConfig"),igo=o(" (SEW-D model)"),dgo=l(),_h=a("li"),jme=a("strong"),cgo=o("speech-encoder-decoder"),mgo=o(" \u2014 "),ON=a("a"),fgo=o("SpeechEncoderDecoderConfig"),ggo=o(" (Speech Encoder decoder model)"),hgo=l(),bh=a("li"),Dme=a("strong"),ugo=o("speech_to_text"),pgo=o(" \u2014 "),VN=a("a"),_go=o("Speech2TextConfig"),bgo=o(" (Speech2Text model)"),vgo=l(),vh=a("li"),Gme=a("strong"),Fgo=o("speech_to_text_2"),Tgo=o(" \u2014 "),XN=a("a"),Mgo=o("Speech2Text2Config"),Ego=o(" (Speech2Text2 model)"),Cgo=l(),Fh=a("li"),Ome=a("strong"),wgo=o("splinter"),Ago=o(" \u2014 "),zN=a("a"),Lgo=o("SplinterConfig"),ygo=o(" (Splinter model)"),xgo=l(),Th=a("li"),Vme=a("strong"),$go=o("squeezebert"),kgo=o(" \u2014 "),QN=a("a"),Sgo=o("SqueezeBertConfig"),Rgo=o(" (SqueezeBERT model)"),Pgo=l(),Mh=a("li"),Xme=a("strong"),Bgo=o("swin"),Igo=o(" \u2014 "),WN=a("a"),Ngo=o("SwinConfig"),qgo=o(" (Swin Transformer model)"),jgo=l(),Eh=a("li"),zme=a("strong"),Dgo=o("swinv2"),Ggo=o(" \u2014 "),UN=a("a"),Ogo=o("Swinv2Config"),Vgo=o(" (Swin Transformer V2 model)"),Xgo=l(),Ch=a("li"),Qme=a("strong"),zgo=o("t5"),Qgo=o(" \u2014 "),HN=a("a"),Wgo=o("T5Config"),Ugo=o(" (T5 model)"),Hgo=l(),wh=a("li"),Wme=a("strong"),Jgo=o("tapas"),Ygo=o(" \u2014 "),JN=a("a"),Kgo=o("TapasConfig"),Zgo=o(" (TAPAS model)"),eho=l(),Ah=a("li"),Ume=a("strong"),oho=o("trajectory_transformer"),rho=o(" \u2014 "),YN=a("a"),tho=o("TrajectoryTransformerConfig"),aho=o(" (Trajectory Transformer model)"),nho=l(),Lh=a("li"),Hme=a("strong"),sho=o("transfo-xl"),lho=o(" \u2014 "),KN=a("a"),iho=o("TransfoXLConfig"),dho=o(" (Transformer-XL model)"),cho=l(),yh=a("li"),Jme=a("strong"),mho=o("trocr"),fho=o(" \u2014 "),ZN=a("a"),gho=o("TrOCRConfig"),hho=o(" (TrOCR model)"),uho=l(),xh=a("li"),Yme=a("strong"),pho=o("unispeech"),_ho=o(" \u2014 "),eq=a("a"),bho=o("UniSpeechConfig"),vho=o(" (UniSpeech model)"),Fho=l(),$h=a("li"),Kme=a("strong"),Tho=o("unispeech-sat"),Mho=o(" \u2014 "),oq=a("a"),Eho=o("UniSpeechSatConfig"),Cho=o(" (UniSpeechSat model)"),who=l(),kh=a("li"),Zme=a("strong"),Aho=o("van"),Lho=o(" \u2014 "),rq=a("a"),yho=o("VanConfig"),xho=o(" (VAN model)"),$ho=l(),Sh=a("li"),efe=a("strong"),kho=o("videomae"),Sho=o(" \u2014 "),tq=a("a"),Rho=o("VideoMAEConfig"),Pho=o(" (VideoMAE model)"),Bho=l(),Rh=a("li"),ofe=a("strong"),Iho=o("vilt"),Nho=o(" \u2014 "),aq=a("a"),qho=o("ViltConfig"),jho=o(" (ViLT model)"),Dho=l(),Ph=a("li"),rfe=a("strong"),Gho=o("vision-encoder-decoder"),Oho=o(" \u2014 "),nq=a("a"),Vho=o("VisionEncoderDecoderConfig"),Xho=o(" (Vision Encoder decoder model)"),zho=l(),Bh=a("li"),tfe=a("strong"),Qho=o("vision-text-dual-encoder"),Who=o(" \u2014 "),sq=a("a"),Uho=o("VisionTextDualEncoderConfig"),Hho=o(" (VisionTextDualEncoder model)"),Jho=l(),Ih=a("li"),afe=a("strong"),Yho=o("visual_bert"),Kho=o(" \u2014 "),lq=a("a"),Zho=o("VisualBertConfig"),euo=o(" (VisualBERT model)"),ouo=l(),Nh=a("li"),nfe=a("strong"),ruo=o("vit"),tuo=o(" \u2014 "),iq=a("a"),auo=o("ViTConfig"),nuo=o(" (ViT model)"),suo=l(),qh=a("li"),sfe=a("strong"),luo=o("vit_mae"),iuo=o(" \u2014 "),dq=a("a"),duo=o("ViTMAEConfig"),cuo=o(" (ViTMAE model)"),muo=l(),jh=a("li"),lfe=a("strong"),fuo=o("vit_msn"),guo=o(" \u2014 "),cq=a("a"),huo=o("ViTMSNConfig"),uuo=o(" (ViTMSN model)"),puo=l(),Dh=a("li"),ife=a("strong"),_uo=o("wav2vec2"),buo=o(" \u2014 "),mq=a("a"),vuo=o("Wav2Vec2Config"),Fuo=o(" (Wav2Vec2 model)"),Tuo=l(),Gh=a("li"),dfe=a("strong"),Muo=o("wav2vec2-conformer"),Euo=o(" \u2014 "),fq=a("a"),Cuo=o("Wav2Vec2ConformerConfig"),wuo=o(" (Wav2Vec2-Conformer model)"),Auo=l(),Oh=a("li"),cfe=a("strong"),Luo=o("wavlm"),yuo=o(" \u2014 "),gq=a("a"),xuo=o("WavLMConfig"),$uo=o(" (WavLM model)"),kuo=l(),Vh=a("li"),mfe=a("strong"),Suo=o("xclip"),Ruo=o(" \u2014 "),hq=a("a"),Puo=o("XCLIPConfig"),Buo=o(" (X-CLIP model)"),Iuo=l(),Xh=a("li"),ffe=a("strong"),Nuo=o("xglm"),quo=o(" \u2014 "),uq=a("a"),juo=o("XGLMConfig"),Duo=o(" (XGLM model)"),Guo=l(),zh=a("li"),gfe=a("strong"),Ouo=o("xlm"),Vuo=o(" \u2014 "),pq=a("a"),Xuo=o("XLMConfig"),zuo=o(" (XLM model)"),Quo=l(),Qh=a("li"),hfe=a("strong"),Wuo=o("xlm-prophetnet"),Uuo=o(" \u2014 "),_q=a("a"),Huo=o("XLMProphetNetConfig"),Juo=o(" (XLM-ProphetNet model)"),Yuo=l(),Wh=a("li"),ufe=a("strong"),Kuo=o("xlm-roberta"),Zuo=o(" \u2014 "),bq=a("a"),epo=o("XLMRobertaConfig"),opo=o(" (XLM-RoBERTa model)"),rpo=l(),Uh=a("li"),pfe=a("strong"),tpo=o("xlm-roberta-xl"),apo=o(" \u2014 "),vq=a("a"),npo=o("XLMRobertaXLConfig"),spo=o(" (XLM-RoBERTa-XL model)"),lpo=l(),Hh=a("li"),_fe=a("strong"),ipo=o("xlnet"),dpo=o(" \u2014 "),Fq=a("a"),cpo=o("XLNetConfig"),mpo=o(" (XLNet model)"),fpo=l(),Jh=a("li"),bfe=a("strong"),gpo=o("yolos"),hpo=o(" \u2014 "),Tq=a("a"),upo=o("YolosConfig"),ppo=o(" (YOLOS model)"),_po=l(),Yh=a("li"),vfe=a("strong"),bpo=o("yoso"),vpo=o(" \u2014 "),Mq=a("a"),Fpo=o("YosoConfig"),Tpo=o(" (YOSO model)"),Mpo=l(),F(Kh.$$.fragment),Epo=l(),Zh=a("div"),F(ox.$$.fragment),Cpo=l(),Ffe=a("p"),wpo=o("Register a new configuration for this class."),EZe=l(),gd=a("h2"),eu=a("a"),Tfe=a("span"),F(rx.$$.fragment),Apo=l(),Mfe=a("span"),Lpo=o("AutoTokenizer"),CZe=l(),ko=a("div"),F(tx.$$.fragment),ypo=l(),ax=a("p"),xpo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),Eq=a("a"),$po=o("AutoTokenizer.from_pretrained()"),kpo=o(" class method."),Spo=l(),nx=a("p"),Rpo=o("This class cannot be instantiated directly using "),Efe=a("code"),Ppo=o("__init__()"),Bpo=o(" (throws an error)."),Ipo=l(),Br=a("div"),F(sx.$$.fragment),Npo=l(),Cfe=a("p"),qpo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),jpo=l(),Ua=a("p"),Dpo=o("The tokenizer class to instantiate is selected based on the "),wfe=a("code"),Gpo=o("model_type"),Opo=o(` property of the config object (either
passed as an argument or loaded from `),Afe=a("code"),Vpo=o("pretrained_model_name_or_path"),Xpo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lfe=a("code"),zpo=o("pretrained_model_name_or_path"),Qpo=o(":"),Wpo=l(),k=a("ul"),ns=a("li"),yfe=a("strong"),Upo=o("albert"),Hpo=o(" \u2014 "),Cq=a("a"),Jpo=o("AlbertTokenizer"),Ypo=o(" or "),wq=a("a"),Kpo=o("AlbertTokenizerFast"),Zpo=o(" (ALBERT model)"),e_o=l(),ss=a("li"),xfe=a("strong"),o_o=o("bart"),r_o=o(" \u2014 "),Aq=a("a"),t_o=o("BartTokenizer"),a_o=o(" or "),Lq=a("a"),n_o=o("BartTokenizerFast"),s_o=o(" (BART model)"),l_o=l(),ls=a("li"),$fe=a("strong"),i_o=o("barthez"),d_o=o(" \u2014 "),yq=a("a"),c_o=o("BarthezTokenizer"),m_o=o(" or "),xq=a("a"),f_o=o("BarthezTokenizerFast"),g_o=o(" (BARThez model)"),h_o=l(),ou=a("li"),kfe=a("strong"),u_o=o("bartpho"),p_o=o(" \u2014 "),$q=a("a"),__o=o("BartphoTokenizer"),b_o=o(" (BARTpho model)"),v_o=l(),is=a("li"),Sfe=a("strong"),F_o=o("bert"),T_o=o(" \u2014 "),kq=a("a"),M_o=o("BertTokenizer"),E_o=o(" or "),Sq=a("a"),C_o=o("BertTokenizerFast"),w_o=o(" (BERT model)"),A_o=l(),ru=a("li"),Rfe=a("strong"),L_o=o("bert-generation"),y_o=o(" \u2014 "),Rq=a("a"),x_o=o("BertGenerationTokenizer"),$_o=o(" (Bert Generation model)"),k_o=l(),tu=a("li"),Pfe=a("strong"),S_o=o("bert-japanese"),R_o=o(" \u2014 "),Pq=a("a"),P_o=o("BertJapaneseTokenizer"),B_o=o(" (BertJapanese model)"),I_o=l(),au=a("li"),Bfe=a("strong"),N_o=o("bertweet"),q_o=o(" \u2014 "),Bq=a("a"),j_o=o("BertweetTokenizer"),D_o=o(" (BERTweet model)"),G_o=l(),ds=a("li"),Ife=a("strong"),O_o=o("big_bird"),V_o=o(" \u2014 "),Iq=a("a"),X_o=o("BigBirdTokenizer"),z_o=o(" or "),Nq=a("a"),Q_o=o("BigBirdTokenizerFast"),W_o=o(" (BigBird model)"),U_o=l(),cs=a("li"),Nfe=a("strong"),H_o=o("bigbird_pegasus"),J_o=o(" \u2014 "),qq=a("a"),Y_o=o("PegasusTokenizer"),K_o=o(" or "),jq=a("a"),Z_o=o("PegasusTokenizerFast"),e2o=o(" (BigBird-Pegasus model)"),o2o=l(),ms=a("li"),qfe=a("strong"),r2o=o("blenderbot"),t2o=o(" \u2014 "),Dq=a("a"),a2o=o("BlenderbotTokenizer"),n2o=o(" or "),Gq=a("a"),s2o=o("BlenderbotTokenizerFast"),l2o=o(" (Blenderbot model)"),i2o=l(),nu=a("li"),jfe=a("strong"),d2o=o("blenderbot-small"),c2o=o(" \u2014 "),Oq=a("a"),m2o=o("BlenderbotSmallTokenizer"),f2o=o(" (BlenderbotSmall model)"),g2o=l(),su=a("li"),Dfe=a("strong"),h2o=o("bloom"),u2o=o(" \u2014 "),Vq=a("a"),p2o=o("BloomTokenizerFast"),_2o=o(" (BLOOM model)"),b2o=l(),lu=a("li"),Gfe=a("strong"),v2o=o("byt5"),F2o=o(" \u2014 "),Xq=a("a"),T2o=o("ByT5Tokenizer"),M2o=o(" (ByT5 model)"),E2o=l(),fs=a("li"),Ofe=a("strong"),C2o=o("camembert"),w2o=o(" \u2014 "),zq=a("a"),A2o=o("CamembertTokenizer"),L2o=o(" or "),Qq=a("a"),y2o=o("CamembertTokenizerFast"),x2o=o(" (CamemBERT model)"),$2o=l(),iu=a("li"),Vfe=a("strong"),k2o=o("canine"),S2o=o(" \u2014 "),Wq=a("a"),R2o=o("CanineTokenizer"),P2o=o(" (CANINE model)"),B2o=l(),gs=a("li"),Xfe=a("strong"),I2o=o("clip"),N2o=o(" \u2014 "),Uq=a("a"),q2o=o("CLIPTokenizer"),j2o=o(" or "),Hq=a("a"),D2o=o("CLIPTokenizerFast"),G2o=o(" (CLIP model)"),O2o=l(),hs=a("li"),zfe=a("strong"),V2o=o("codegen"),X2o=o(" \u2014 "),Jq=a("a"),z2o=o("CodeGenTokenizer"),Q2o=o(" or "),Yq=a("a"),W2o=o("CodeGenTokenizerFast"),U2o=o(" (CodeGen model)"),H2o=l(),us=a("li"),Qfe=a("strong"),J2o=o("convbert"),Y2o=o(" \u2014 "),Kq=a("a"),K2o=o("ConvBertTokenizer"),Z2o=o(" or "),Zq=a("a"),ebo=o("ConvBertTokenizerFast"),obo=o(" (ConvBERT model)"),rbo=l(),ps=a("li"),Wfe=a("strong"),tbo=o("cpm"),abo=o(" \u2014 "),ej=a("a"),nbo=o("CpmTokenizer"),sbo=o(" or "),oj=a("a"),lbo=o("CpmTokenizerFast"),ibo=o(" (CPM model)"),dbo=l(),du=a("li"),Ufe=a("strong"),cbo=o("ctrl"),mbo=o(" \u2014 "),rj=a("a"),fbo=o("CTRLTokenizer"),gbo=o(" (CTRL model)"),hbo=l(),_s=a("li"),Hfe=a("strong"),ubo=o("data2vec-text"),pbo=o(" \u2014 "),tj=a("a"),_bo=o("RobertaTokenizer"),bbo=o(" or "),aj=a("a"),vbo=o("RobertaTokenizerFast"),Fbo=o(" (Data2VecText model)"),Tbo=l(),bs=a("li"),Jfe=a("strong"),Mbo=o("deberta"),Ebo=o(" \u2014 "),nj=a("a"),Cbo=o("DebertaTokenizer"),wbo=o(" or "),sj=a("a"),Abo=o("DebertaTokenizerFast"),Lbo=o(" (DeBERTa model)"),ybo=l(),vs=a("li"),Yfe=a("strong"),xbo=o("deberta-v2"),$bo=o(" \u2014 "),lj=a("a"),kbo=o("DebertaV2Tokenizer"),Sbo=o(" or "),ij=a("a"),Rbo=o("DebertaV2TokenizerFast"),Pbo=o(" (DeBERTa-v2 model)"),Bbo=l(),Fs=a("li"),Kfe=a("strong"),Ibo=o("distilbert"),Nbo=o(" \u2014 "),dj=a("a"),qbo=o("DistilBertTokenizer"),jbo=o(" or "),cj=a("a"),Dbo=o("DistilBertTokenizerFast"),Gbo=o(" (DistilBERT model)"),Obo=l(),Ts=a("li"),Zfe=a("strong"),Vbo=o("dpr"),Xbo=o(" \u2014 "),mj=a("a"),zbo=o("DPRQuestionEncoderTokenizer"),Qbo=o(" or "),fj=a("a"),Wbo=o("DPRQuestionEncoderTokenizerFast"),Ubo=o(" (DPR model)"),Hbo=l(),Ms=a("li"),ege=a("strong"),Jbo=o("electra"),Ybo=o(" \u2014 "),gj=a("a"),Kbo=o("ElectraTokenizer"),Zbo=o(" or "),hj=a("a"),e1o=o("ElectraTokenizerFast"),o1o=o(" (ELECTRA model)"),r1o=l(),Es=a("li"),oge=a("strong"),t1o=o("ernie"),a1o=o(" \u2014 "),uj=a("a"),n1o=o("BertTokenizer"),s1o=o(" or "),pj=a("a"),l1o=o("BertTokenizerFast"),i1o=o(" (ERNIE model)"),d1o=l(),cu=a("li"),rge=a("strong"),c1o=o("flaubert"),m1o=o(" \u2014 "),_j=a("a"),f1o=o("FlaubertTokenizer"),g1o=o(" (FlauBERT model)"),h1o=l(),Cs=a("li"),tge=a("strong"),u1o=o("fnet"),p1o=o(" \u2014 "),bj=a("a"),_1o=o("FNetTokenizer"),b1o=o(" or "),vj=a("a"),v1o=o("FNetTokenizerFast"),F1o=o(" (FNet model)"),T1o=l(),mu=a("li"),age=a("strong"),M1o=o("fsmt"),E1o=o(" \u2014 "),Fj=a("a"),C1o=o("FSMTTokenizer"),w1o=o(" (FairSeq Machine-Translation model)"),A1o=l(),ws=a("li"),nge=a("strong"),L1o=o("funnel"),y1o=o(" \u2014 "),Tj=a("a"),x1o=o("FunnelTokenizer"),$1o=o(" or "),Mj=a("a"),k1o=o("FunnelTokenizerFast"),S1o=o(" (Funnel Transformer model)"),R1o=l(),As=a("li"),sge=a("strong"),P1o=o("gpt2"),B1o=o(" \u2014 "),Ej=a("a"),I1o=o("GPT2Tokenizer"),N1o=o(" or "),Cj=a("a"),q1o=o("GPT2TokenizerFast"),j1o=o(" (OpenAI GPT-2 model)"),D1o=l(),Ls=a("li"),lge=a("strong"),G1o=o("gpt_neo"),O1o=o(" \u2014 "),wj=a("a"),V1o=o("GPT2Tokenizer"),X1o=o(" or "),Aj=a("a"),z1o=o("GPT2TokenizerFast"),Q1o=o(" (GPT Neo model)"),W1o=l(),fu=a("li"),ige=a("strong"),U1o=o("gpt_neox"),H1o=o(" \u2014 "),Lj=a("a"),J1o=o("GPTNeoXTokenizerFast"),Y1o=o(" (GPT NeoX model)"),K1o=l(),gu=a("li"),dge=a("strong"),Z1o=o("gpt_neox_japanese"),evo=o(" \u2014 "),yj=a("a"),ovo=o("GPTNeoXJapaneseTokenizer"),rvo=o(" (GPT NeoX Japanese model)"),tvo=l(),ys=a("li"),cge=a("strong"),avo=o("gptj"),nvo=o(" \u2014 "),xj=a("a"),svo=o("GPT2Tokenizer"),lvo=o(" or "),$j=a("a"),ivo=o("GPT2TokenizerFast"),dvo=o(" (GPT-J model)"),cvo=l(),xs=a("li"),mge=a("strong"),mvo=o("groupvit"),fvo=o(" \u2014 "),kj=a("a"),gvo=o("CLIPTokenizer"),hvo=o(" or "),Sj=a("a"),uvo=o("CLIPTokenizerFast"),pvo=o(" (GroupViT model)"),_vo=l(),$s=a("li"),fge=a("strong"),bvo=o("herbert"),vvo=o(" \u2014 "),Rj=a("a"),Fvo=o("HerbertTokenizer"),Tvo=o(" or "),Pj=a("a"),Mvo=o("HerbertTokenizerFast"),Evo=o(" (HerBERT model)"),Cvo=l(),hu=a("li"),gge=a("strong"),wvo=o("hubert"),Avo=o(" \u2014 "),Bj=a("a"),Lvo=o("Wav2Vec2CTCTokenizer"),yvo=o(" (Hubert model)"),xvo=l(),ks=a("li"),hge=a("strong"),$vo=o("ibert"),kvo=o(" \u2014 "),Ij=a("a"),Svo=o("RobertaTokenizer"),Rvo=o(" or "),Nj=a("a"),Pvo=o("RobertaTokenizerFast"),Bvo=o(" (I-BERT model)"),Ivo=l(),Ss=a("li"),uge=a("strong"),Nvo=o("layoutlm"),qvo=o(" \u2014 "),qj=a("a"),jvo=o("LayoutLMTokenizer"),Dvo=o(" or "),jj=a("a"),Gvo=o("LayoutLMTokenizerFast"),Ovo=o(" (LayoutLM model)"),Vvo=l(),Rs=a("li"),pge=a("strong"),Xvo=o("layoutlmv2"),zvo=o(" \u2014 "),Dj=a("a"),Qvo=o("LayoutLMv2Tokenizer"),Wvo=o(" or "),Gj=a("a"),Uvo=o("LayoutLMv2TokenizerFast"),Hvo=o(" (LayoutLMv2 model)"),Jvo=l(),Ps=a("li"),_ge=a("strong"),Yvo=o("layoutlmv3"),Kvo=o(" \u2014 "),Oj=a("a"),Zvo=o("LayoutLMv3Tokenizer"),eFo=o(" or "),Vj=a("a"),oFo=o("LayoutLMv3TokenizerFast"),rFo=o(" (LayoutLMv3 model)"),tFo=l(),Bs=a("li"),bge=a("strong"),aFo=o("layoutxlm"),nFo=o(" \u2014 "),Xj=a("a"),sFo=o("LayoutXLMTokenizer"),lFo=o(" or "),zj=a("a"),iFo=o("LayoutXLMTokenizerFast"),dFo=o(" (LayoutXLM model)"),cFo=l(),Is=a("li"),vge=a("strong"),mFo=o("led"),fFo=o(" \u2014 "),Qj=a("a"),gFo=o("LEDTokenizer"),hFo=o(" or "),Wj=a("a"),uFo=o("LEDTokenizerFast"),pFo=o(" (LED model)"),_Fo=l(),Ns=a("li"),Fge=a("strong"),bFo=o("longformer"),vFo=o(" \u2014 "),Uj=a("a"),FFo=o("LongformerTokenizer"),TFo=o(" or "),Hj=a("a"),MFo=o("LongformerTokenizerFast"),EFo=o(" (Longformer model)"),CFo=l(),qs=a("li"),Tge=a("strong"),wFo=o("longt5"),AFo=o(" \u2014 "),Jj=a("a"),LFo=o("T5Tokenizer"),yFo=o(" or "),Yj=a("a"),xFo=o("T5TokenizerFast"),$Fo=o(" (LongT5 model)"),kFo=l(),uu=a("li"),Mge=a("strong"),SFo=o("luke"),RFo=o(" \u2014 "),Kj=a("a"),PFo=o("LukeTokenizer"),BFo=o(" (LUKE model)"),IFo=l(),js=a("li"),Ege=a("strong"),NFo=o("lxmert"),qFo=o(" \u2014 "),Zj=a("a"),jFo=o("LxmertTokenizer"),DFo=o(" or "),eD=a("a"),GFo=o("LxmertTokenizerFast"),OFo=o(" (LXMERT model)"),VFo=l(),pu=a("li"),Cge=a("strong"),XFo=o("m2m_100"),zFo=o(" \u2014 "),oD=a("a"),QFo=o("M2M100Tokenizer"),WFo=o(" (M2M100 model)"),UFo=l(),_u=a("li"),wge=a("strong"),HFo=o("marian"),JFo=o(" \u2014 "),rD=a("a"),YFo=o("MarianTokenizer"),KFo=o(" (Marian model)"),ZFo=l(),Ds=a("li"),Age=a("strong"),eTo=o("mbart"),oTo=o(" \u2014 "),tD=a("a"),rTo=o("MBartTokenizer"),tTo=o(" or "),aD=a("a"),aTo=o("MBartTokenizerFast"),nTo=o(" (mBART model)"),sTo=l(),Gs=a("li"),Lge=a("strong"),lTo=o("mbart50"),iTo=o(" \u2014 "),nD=a("a"),dTo=o("MBart50Tokenizer"),cTo=o(" or "),sD=a("a"),mTo=o("MBart50TokenizerFast"),fTo=o(" (mBART-50 model)"),gTo=l(),Os=a("li"),yge=a("strong"),hTo=o("megatron-bert"),uTo=o(" \u2014 "),lD=a("a"),pTo=o("BertTokenizer"),_To=o(" or "),iD=a("a"),bTo=o("BertTokenizerFast"),vTo=o(" (Megatron-BERT model)"),FTo=l(),bu=a("li"),xge=a("strong"),TTo=o("mluke"),MTo=o(" \u2014 "),dD=a("a"),ETo=o("MLukeTokenizer"),CTo=o(" (mLUKE model)"),wTo=l(),Vs=a("li"),$ge=a("strong"),ATo=o("mobilebert"),LTo=o(" \u2014 "),cD=a("a"),yTo=o("MobileBertTokenizer"),xTo=o(" or "),mD=a("a"),$To=o("MobileBertTokenizerFast"),kTo=o(" (MobileBERT model)"),STo=l(),Xs=a("li"),kge=a("strong"),RTo=o("mpnet"),PTo=o(" \u2014 "),fD=a("a"),BTo=o("MPNetTokenizer"),ITo=o(" or "),gD=a("a"),NTo=o("MPNetTokenizerFast"),qTo=o(" (MPNet model)"),jTo=l(),zs=a("li"),Sge=a("strong"),DTo=o("mt5"),GTo=o(" \u2014 "),hD=a("a"),OTo=o("MT5Tokenizer"),VTo=o(" or "),uD=a("a"),XTo=o("MT5TokenizerFast"),zTo=o(" (MT5 model)"),QTo=l(),Qs=a("li"),Rge=a("strong"),WTo=o("mvp"),UTo=o(" \u2014 "),pD=a("a"),HTo=o("MvpTokenizer"),JTo=o(" or "),_D=a("a"),YTo=o("MvpTokenizerFast"),KTo=o(" (MVP model)"),ZTo=l(),Ws=a("li"),Pge=a("strong"),eMo=o("nezha"),oMo=o(" \u2014 "),bD=a("a"),rMo=o("BertTokenizer"),tMo=o(" or "),vD=a("a"),aMo=o("BertTokenizerFast"),nMo=o(" (Nezha model)"),sMo=l(),Us=a("li"),Bge=a("strong"),lMo=o("nllb"),iMo=o(" \u2014 "),FD=a("a"),dMo=o("NllbTokenizer"),cMo=o(" or "),TD=a("a"),mMo=o("NllbTokenizerFast"),fMo=o(" (NLLB model)"),gMo=l(),Hs=a("li"),Ige=a("strong"),hMo=o("nystromformer"),uMo=o(" \u2014 "),MD=a("a"),pMo=o("AlbertTokenizer"),_Mo=o(" or "),ED=a("a"),bMo=o("AlbertTokenizerFast"),vMo=o(" (Nystr\xF6mformer model)"),FMo=l(),Js=a("li"),Nge=a("strong"),TMo=o("openai-gpt"),MMo=o(" \u2014 "),CD=a("a"),EMo=o("OpenAIGPTTokenizer"),CMo=o(" or "),wD=a("a"),wMo=o("OpenAIGPTTokenizerFast"),AMo=o(" (OpenAI GPT model)"),LMo=l(),vu=a("li"),qge=a("strong"),yMo=o("opt"),xMo=o(" \u2014 "),AD=a("a"),$Mo=o("GPT2Tokenizer"),kMo=o(" (OPT model)"),SMo=l(),Ys=a("li"),jge=a("strong"),RMo=o("owlvit"),PMo=o(" \u2014 "),LD=a("a"),BMo=o("CLIPTokenizer"),IMo=o(" or "),yD=a("a"),NMo=o("CLIPTokenizerFast"),qMo=o(" (OWL-ViT model)"),jMo=l(),Ks=a("li"),Dge=a("strong"),DMo=o("pegasus"),GMo=o(" \u2014 "),xD=a("a"),OMo=o("PegasusTokenizer"),VMo=o(" or "),$D=a("a"),XMo=o("PegasusTokenizerFast"),zMo=o(" (Pegasus model)"),QMo=l(),Fu=a("li"),Gge=a("strong"),WMo=o("perceiver"),UMo=o(" \u2014 "),kD=a("a"),HMo=o("PerceiverTokenizer"),JMo=o(" (Perceiver model)"),YMo=l(),Tu=a("li"),Oge=a("strong"),KMo=o("phobert"),ZMo=o(" \u2014 "),SD=a("a"),eEo=o("PhobertTokenizer"),oEo=o(" (PhoBERT model)"),rEo=l(),Mu=a("li"),Vge=a("strong"),tEo=o("plbart"),aEo=o(" \u2014 "),RD=a("a"),nEo=o("PLBartTokenizer"),sEo=o(" (PLBart model)"),lEo=l(),Eu=a("li"),Xge=a("strong"),iEo=o("prophetnet"),dEo=o(" \u2014 "),PD=a("a"),cEo=o("ProphetNetTokenizer"),mEo=o(" (ProphetNet model)"),fEo=l(),Zs=a("li"),zge=a("strong"),gEo=o("qdqbert"),hEo=o(" \u2014 "),BD=a("a"),uEo=o("BertTokenizer"),pEo=o(" or "),ID=a("a"),_Eo=o("BertTokenizerFast"),bEo=o(" (QDQBert model)"),vEo=l(),Cu=a("li"),Qge=a("strong"),FEo=o("rag"),TEo=o(" \u2014 "),ND=a("a"),MEo=o("RagTokenizer"),EEo=o(" (RAG model)"),CEo=l(),el=a("li"),Wge=a("strong"),wEo=o("realm"),AEo=o(" \u2014 "),qD=a("a"),LEo=o("RealmTokenizer"),yEo=o(" or "),jD=a("a"),xEo=o("RealmTokenizerFast"),$Eo=o(" (REALM model)"),kEo=l(),ol=a("li"),Uge=a("strong"),SEo=o("reformer"),REo=o(" \u2014 "),DD=a("a"),PEo=o("ReformerTokenizer"),BEo=o(" or "),GD=a("a"),IEo=o("ReformerTokenizerFast"),NEo=o(" (Reformer model)"),qEo=l(),rl=a("li"),Hge=a("strong"),jEo=o("rembert"),DEo=o(" \u2014 "),OD=a("a"),GEo=o("RemBertTokenizer"),OEo=o(" or "),VD=a("a"),VEo=o("RemBertTokenizerFast"),XEo=o(" (RemBERT model)"),zEo=l(),tl=a("li"),Jge=a("strong"),QEo=o("retribert"),WEo=o(" \u2014 "),XD=a("a"),UEo=o("RetriBertTokenizer"),HEo=o(" or "),zD=a("a"),JEo=o("RetriBertTokenizerFast"),YEo=o(" (RetriBERT model)"),KEo=l(),al=a("li"),Yge=a("strong"),ZEo=o("roberta"),e4o=o(" \u2014 "),QD=a("a"),o4o=o("RobertaTokenizer"),r4o=o(" or "),WD=a("a"),t4o=o("RobertaTokenizerFast"),a4o=o(" (RoBERTa model)"),n4o=l(),nl=a("li"),Kge=a("strong"),s4o=o("roformer"),l4o=o(" \u2014 "),UD=a("a"),i4o=o("RoFormerTokenizer"),d4o=o(" or "),HD=a("a"),c4o=o("RoFormerTokenizerFast"),m4o=o(" (RoFormer model)"),f4o=l(),wu=a("li"),Zge=a("strong"),g4o=o("speech_to_text"),h4o=o(" \u2014 "),JD=a("a"),u4o=o("Speech2TextTokenizer"),p4o=o(" (Speech2Text model)"),_4o=l(),Au=a("li"),ehe=a("strong"),b4o=o("speech_to_text_2"),v4o=o(" \u2014 "),YD=a("a"),F4o=o("Speech2Text2Tokenizer"),T4o=o(" (Speech2Text2 model)"),M4o=l(),sl=a("li"),ohe=a("strong"),E4o=o("splinter"),C4o=o(" \u2014 "),KD=a("a"),w4o=o("SplinterTokenizer"),A4o=o(" or "),ZD=a("a"),L4o=o("SplinterTokenizerFast"),y4o=o(" (Splinter model)"),x4o=l(),ll=a("li"),rhe=a("strong"),$4o=o("squeezebert"),k4o=o(" \u2014 "),eG=a("a"),S4o=o("SqueezeBertTokenizer"),R4o=o(" or "),oG=a("a"),P4o=o("SqueezeBertTokenizerFast"),B4o=o(" (SqueezeBERT model)"),I4o=l(),il=a("li"),the=a("strong"),N4o=o("t5"),q4o=o(" \u2014 "),rG=a("a"),j4o=o("T5Tokenizer"),D4o=o(" or "),tG=a("a"),G4o=o("T5TokenizerFast"),O4o=o(" (T5 model)"),V4o=l(),Lu=a("li"),ahe=a("strong"),X4o=o("tapas"),z4o=o(" \u2014 "),aG=a("a"),Q4o=o("TapasTokenizer"),W4o=o(" (TAPAS model)"),U4o=l(),yu=a("li"),nhe=a("strong"),H4o=o("tapex"),J4o=o(" \u2014 "),nG=a("a"),Y4o=o("TapexTokenizer"),K4o=o(" (TAPEX model)"),Z4o=l(),xu=a("li"),she=a("strong"),eCo=o("transfo-xl"),oCo=o(" \u2014 "),sG=a("a"),rCo=o("TransfoXLTokenizer"),tCo=o(" (Transformer-XL model)"),aCo=l(),dl=a("li"),lhe=a("strong"),nCo=o("vilt"),sCo=o(" \u2014 "),lG=a("a"),lCo=o("BertTokenizer"),iCo=o(" or "),iG=a("a"),dCo=o("BertTokenizerFast"),cCo=o(" (ViLT model)"),mCo=l(),cl=a("li"),ihe=a("strong"),fCo=o("visual_bert"),gCo=o(" \u2014 "),dG=a("a"),hCo=o("BertTokenizer"),uCo=o(" or "),cG=a("a"),pCo=o("BertTokenizerFast"),_Co=o(" (VisualBERT model)"),bCo=l(),$u=a("li"),dhe=a("strong"),vCo=o("wav2vec2"),FCo=o(" \u2014 "),mG=a("a"),TCo=o("Wav2Vec2CTCTokenizer"),MCo=o(" (Wav2Vec2 model)"),ECo=l(),ku=a("li"),che=a("strong"),CCo=o("wav2vec2-conformer"),wCo=o(" \u2014 "),fG=a("a"),ACo=o("Wav2Vec2CTCTokenizer"),LCo=o(" (Wav2Vec2-Conformer model)"),yCo=l(),Su=a("li"),mhe=a("strong"),xCo=o("wav2vec2_phoneme"),$Co=o(" \u2014 "),gG=a("a"),kCo=o("Wav2Vec2PhonemeCTCTokenizer"),SCo=o(" (Wav2Vec2Phoneme model)"),RCo=l(),ml=a("li"),fhe=a("strong"),PCo=o("xclip"),BCo=o(" \u2014 "),hG=a("a"),ICo=o("CLIPTokenizer"),NCo=o(" or "),uG=a("a"),qCo=o("CLIPTokenizerFast"),jCo=o(" (X-CLIP model)"),DCo=l(),fl=a("li"),ghe=a("strong"),GCo=o("xglm"),OCo=o(" \u2014 "),pG=a("a"),VCo=o("XGLMTokenizer"),XCo=o(" or "),_G=a("a"),zCo=o("XGLMTokenizerFast"),QCo=o(" (XGLM model)"),WCo=l(),Ru=a("li"),hhe=a("strong"),UCo=o("xlm"),HCo=o(" \u2014 "),bG=a("a"),JCo=o("XLMTokenizer"),YCo=o(" (XLM model)"),KCo=l(),Pu=a("li"),uhe=a("strong"),ZCo=o("xlm-prophetnet"),e3o=o(" \u2014 "),vG=a("a"),o3o=o("XLMProphetNetTokenizer"),r3o=o(" (XLM-ProphetNet model)"),t3o=l(),gl=a("li"),phe=a("strong"),a3o=o("xlm-roberta"),n3o=o(" \u2014 "),FG=a("a"),s3o=o("XLMRobertaTokenizer"),l3o=o(" or "),TG=a("a"),i3o=o("XLMRobertaTokenizerFast"),d3o=o(" (XLM-RoBERTa model)"),c3o=l(),hl=a("li"),_he=a("strong"),m3o=o("xlm-roberta-xl"),f3o=o(" \u2014 "),MG=a("a"),g3o=o("XLMRobertaTokenizer"),h3o=o(" or "),EG=a("a"),u3o=o("XLMRobertaTokenizerFast"),p3o=o(" (XLM-RoBERTa-XL model)"),_3o=l(),ul=a("li"),bhe=a("strong"),b3o=o("xlnet"),v3o=o(" \u2014 "),CG=a("a"),F3o=o("XLNetTokenizer"),T3o=o(" or "),wG=a("a"),M3o=o("XLNetTokenizerFast"),E3o=o(" (XLNet model)"),C3o=l(),pl=a("li"),vhe=a("strong"),w3o=o("yoso"),A3o=o(" \u2014 "),AG=a("a"),L3o=o("AlbertTokenizer"),y3o=o(" or "),LG=a("a"),x3o=o("AlbertTokenizerFast"),$3o=o(" (YOSO model)"),k3o=l(),F(Bu.$$.fragment),S3o=l(),Iu=a("div"),F(lx.$$.fragment),R3o=l(),Fhe=a("p"),P3o=o("Register a new tokenizer in this mapping."),wZe=l(),hd=a("h2"),Nu=a("a"),The=a("span"),F(ix.$$.fragment),B3o=l(),Mhe=a("span"),I3o=o("AutoFeatureExtractor"),AZe=l(),So=a("div"),F(dx.$$.fragment),N3o=l(),cx=a("p"),q3o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),yG=a("a"),j3o=o("AutoFeatureExtractor.from_pretrained()"),D3o=o(" class method."),G3o=l(),mx=a("p"),O3o=o("This class cannot be instantiated directly using "),Ehe=a("code"),V3o=o("__init__()"),X3o=o(" (throws an error)."),z3o=l(),Ye=a("div"),F(fx.$$.fragment),Q3o=l(),Che=a("p"),W3o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),U3o=l(),Ha=a("p"),H3o=o("The feature extractor class to instantiate is selected based on the "),whe=a("code"),J3o=o("model_type"),Y3o=o(` property of the config object
(either passed as an argument or loaded from `),Ahe=a("code"),K3o=o("pretrained_model_name_or_path"),Z3o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lhe=a("code"),e5o=o("pretrained_model_name_or_path"),o5o=o(":"),r5o=l(),z=a("ul"),qu=a("li"),yhe=a("strong"),t5o=o("beit"),a5o=o(" \u2014 "),xG=a("a"),n5o=o("BeitFeatureExtractor"),s5o=o(" (BEiT model)"),l5o=l(),ju=a("li"),xhe=a("strong"),i5o=o("clip"),d5o=o(" \u2014 "),$G=a("a"),c5o=o("CLIPFeatureExtractor"),m5o=o(" (CLIP model)"),f5o=l(),Du=a("li"),$he=a("strong"),g5o=o("conditional_detr"),h5o=o(" \u2014 "),kG=a("a"),u5o=o("ConditionalDetrFeatureExtractor"),p5o=o(" (Conditional DETR model)"),_5o=l(),Gu=a("li"),khe=a("strong"),b5o=o("convnext"),v5o=o(" \u2014 "),SG=a("a"),F5o=o("ConvNextFeatureExtractor"),T5o=o(" (ConvNeXT model)"),M5o=l(),Ou=a("li"),She=a("strong"),E5o=o("cvt"),C5o=o(" \u2014 "),RG=a("a"),w5o=o("ConvNextFeatureExtractor"),A5o=o(" (CvT model)"),L5o=l(),Vu=a("li"),Rhe=a("strong"),y5o=o("data2vec-audio"),x5o=o(" \u2014 "),PG=a("a"),$5o=o("Wav2Vec2FeatureExtractor"),k5o=o(" (Data2VecAudio model)"),S5o=l(),Xu=a("li"),Phe=a("strong"),R5o=o("data2vec-vision"),P5o=o(" \u2014 "),BG=a("a"),B5o=o("BeitFeatureExtractor"),I5o=o(" (Data2VecVision model)"),N5o=l(),zu=a("li"),Bhe=a("strong"),q5o=o("deformable_detr"),j5o=o(" \u2014 "),IG=a("a"),D5o=o("DeformableDetrFeatureExtractor"),G5o=o(" (Deformable DETR model)"),O5o=l(),Qu=a("li"),Ihe=a("strong"),V5o=o("deit"),X5o=o(" \u2014 "),NG=a("a"),z5o=o("DeiTFeatureExtractor"),Q5o=o(" (DeiT model)"),W5o=l(),Wu=a("li"),Nhe=a("strong"),U5o=o("detr"),H5o=o(" \u2014 "),qG=a("a"),J5o=o("DetrFeatureExtractor"),Y5o=o(" (DETR model)"),K5o=l(),Uu=a("li"),qhe=a("strong"),Z5o=o("donut"),e0o=o(" \u2014 "),jG=a("a"),o0o=o("DonutFeatureExtractor"),r0o=o(" (Donut model)"),t0o=l(),Hu=a("li"),jhe=a("strong"),a0o=o("dpt"),n0o=o(" \u2014 "),DG=a("a"),s0o=o("DPTFeatureExtractor"),l0o=o(" (DPT model)"),i0o=l(),Ju=a("li"),Dhe=a("strong"),d0o=o("flava"),c0o=o(" \u2014 "),GG=a("a"),m0o=o("FlavaFeatureExtractor"),f0o=o(" (FLAVA model)"),g0o=l(),Yu=a("li"),Ghe=a("strong"),h0o=o("glpn"),u0o=o(" \u2014 "),OG=a("a"),p0o=o("GLPNFeatureExtractor"),_0o=o(" (GLPN model)"),b0o=l(),Ku=a("li"),Ohe=a("strong"),v0o=o("groupvit"),F0o=o(" \u2014 "),VG=a("a"),T0o=o("CLIPFeatureExtractor"),M0o=o(" (GroupViT model)"),E0o=l(),Zu=a("li"),Vhe=a("strong"),C0o=o("hubert"),w0o=o(" \u2014 "),XG=a("a"),A0o=o("Wav2Vec2FeatureExtractor"),L0o=o(" (Hubert model)"),y0o=l(),ep=a("li"),Xhe=a("strong"),x0o=o("imagegpt"),$0o=o(" \u2014 "),zG=a("a"),k0o=o("ImageGPTFeatureExtractor"),S0o=o(" (ImageGPT model)"),R0o=l(),op=a("li"),zhe=a("strong"),P0o=o("layoutlmv2"),B0o=o(" \u2014 "),QG=a("a"),I0o=o("LayoutLMv2FeatureExtractor"),N0o=o(" (LayoutLMv2 model)"),q0o=l(),rp=a("li"),Qhe=a("strong"),j0o=o("layoutlmv3"),D0o=o(" \u2014 "),WG=a("a"),G0o=o("LayoutLMv3FeatureExtractor"),O0o=o(" (LayoutLMv3 model)"),V0o=l(),tp=a("li"),Whe=a("strong"),X0o=o("levit"),z0o=o(" \u2014 "),UG=a("a"),Q0o=o("LevitFeatureExtractor"),W0o=o(" (LeViT model)"),U0o=l(),ap=a("li"),Uhe=a("strong"),H0o=o("maskformer"),J0o=o(" \u2014 "),HG=a("a"),Y0o=o("MaskFormerFeatureExtractor"),K0o=o(" (MaskFormer model)"),Z0o=l(),np=a("li"),Hhe=a("strong"),ewo=o("mctct"),owo=o(" \u2014 "),JG=a("a"),rwo=o("MCTCTFeatureExtractor"),two=o(" (M-CTC-T model)"),awo=l(),sp=a("li"),Jhe=a("strong"),nwo=o("mobilevit"),swo=o(" \u2014 "),YG=a("a"),lwo=o("MobileViTFeatureExtractor"),iwo=o(" (MobileViT model)"),dwo=l(),lp=a("li"),Yhe=a("strong"),cwo=o("owlvit"),mwo=o(" \u2014 "),KG=a("a"),fwo=o("OwlViTFeatureExtractor"),gwo=o(" (OWL-ViT model)"),hwo=l(),ip=a("li"),Khe=a("strong"),uwo=o("perceiver"),pwo=o(" \u2014 "),ZG=a("a"),_wo=o("PerceiverFeatureExtractor"),bwo=o(" (Perceiver model)"),vwo=l(),dp=a("li"),Zhe=a("strong"),Fwo=o("poolformer"),Two=o(" \u2014 "),eO=a("a"),Mwo=o("PoolFormerFeatureExtractor"),Ewo=o(" (PoolFormer model)"),Cwo=l(),cp=a("li"),eue=a("strong"),wwo=o("regnet"),Awo=o(" \u2014 "),oO=a("a"),Lwo=o("ConvNextFeatureExtractor"),ywo=o(" (RegNet model)"),xwo=l(),mp=a("li"),oue=a("strong"),$wo=o("resnet"),kwo=o(" \u2014 "),rO=a("a"),Swo=o("ConvNextFeatureExtractor"),Rwo=o(" (ResNet model)"),Pwo=l(),fp=a("li"),rue=a("strong"),Bwo=o("segformer"),Iwo=o(" \u2014 "),tO=a("a"),Nwo=o("SegformerFeatureExtractor"),qwo=o(" (SegFormer model)"),jwo=l(),gp=a("li"),tue=a("strong"),Dwo=o("speech_to_text"),Gwo=o(" \u2014 "),aO=a("a"),Owo=o("Speech2TextFeatureExtractor"),Vwo=o(" (Speech2Text model)"),Xwo=l(),hp=a("li"),aue=a("strong"),zwo=o("swin"),Qwo=o(" \u2014 "),nO=a("a"),Wwo=o("ViTFeatureExtractor"),Uwo=o(" (Swin Transformer model)"),Hwo=l(),up=a("li"),nue=a("strong"),Jwo=o("swinv2"),Ywo=o(" \u2014 "),sO=a("a"),Kwo=o("ViTFeatureExtractor"),Zwo=o(" (Swin Transformer V2 model)"),eAo=l(),pp=a("li"),sue=a("strong"),oAo=o("van"),rAo=o(" \u2014 "),lO=a("a"),tAo=o("ConvNextFeatureExtractor"),aAo=o(" (VAN model)"),nAo=l(),_p=a("li"),lue=a("strong"),sAo=o("videomae"),lAo=o(" \u2014 "),iO=a("a"),iAo=o("VideoMAEFeatureExtractor"),dAo=o(" (VideoMAE model)"),cAo=l(),bp=a("li"),iue=a("strong"),mAo=o("vilt"),fAo=o(" \u2014 "),dO=a("a"),gAo=o("ViltFeatureExtractor"),hAo=o(" (ViLT model)"),uAo=l(),vp=a("li"),due=a("strong"),pAo=o("vit"),_Ao=o(" \u2014 "),cO=a("a"),bAo=o("ViTFeatureExtractor"),vAo=o(" (ViT model)"),FAo=l(),Fp=a("li"),cue=a("strong"),TAo=o("vit_mae"),MAo=o(" \u2014 "),mO=a("a"),EAo=o("ViTFeatureExtractor"),CAo=o(" (ViTMAE model)"),wAo=l(),Tp=a("li"),mue=a("strong"),AAo=o("vit_msn"),LAo=o(" \u2014 "),fO=a("a"),yAo=o("ViTFeatureExtractor"),xAo=o(" (ViTMSN model)"),$Ao=l(),Mp=a("li"),fue=a("strong"),kAo=o("wav2vec2"),SAo=o(" \u2014 "),gO=a("a"),RAo=o("Wav2Vec2FeatureExtractor"),PAo=o(" (Wav2Vec2 model)"),BAo=l(),Ep=a("li"),gue=a("strong"),IAo=o("wav2vec2-conformer"),NAo=o(" \u2014 "),hO=a("a"),qAo=o("Wav2Vec2FeatureExtractor"),jAo=o(" (Wav2Vec2-Conformer model)"),DAo=l(),Cp=a("li"),hue=a("strong"),GAo=o("xclip"),OAo=o(" \u2014 "),uO=a("a"),VAo=o("CLIPFeatureExtractor"),XAo=o(" (X-CLIP model)"),zAo=l(),wp=a("li"),uue=a("strong"),QAo=o("yolos"),WAo=o(" \u2014 "),pO=a("a"),UAo=o("YolosFeatureExtractor"),HAo=o(" (YOLOS model)"),JAo=l(),F(Ap.$$.fragment),YAo=l(),F(Lp.$$.fragment),KAo=l(),yp=a("div"),F(gx.$$.fragment),ZAo=l(),pue=a("p"),e6o=o("Register a new feature extractor for this class."),LZe=l(),ud=a("h2"),xp=a("a"),_ue=a("span"),F(hx.$$.fragment),o6o=l(),bue=a("span"),r6o=o("AutoProcessor"),yZe=l(),Ro=a("div"),F(ux.$$.fragment),t6o=l(),px=a("p"),a6o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),_O=a("a"),n6o=o("AutoProcessor.from_pretrained()"),s6o=o(" class method."),l6o=l(),_x=a("p"),i6o=o("This class cannot be instantiated directly using "),vue=a("code"),d6o=o("__init__()"),c6o=o(" (throws an error)."),m6o=l(),Ke=a("div"),F(bx.$$.fragment),f6o=l(),Fue=a("p"),g6o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),h6o=l(),pd=a("p"),u6o=o("The processor class to instantiate is selected based on the "),Tue=a("code"),p6o=o("model_type"),_6o=o(` property of the config object (either
passed as an argument or loaded from `),Mue=a("code"),b6o=o("pretrained_model_name_or_path"),v6o=o(" if possible):"),F6o=l(),le=a("ul"),$p=a("li"),Eue=a("strong"),T6o=o("clip"),M6o=o(" \u2014 "),bO=a("a"),E6o=o("CLIPProcessor"),C6o=o(" (CLIP model)"),w6o=l(),kp=a("li"),Cue=a("strong"),A6o=o("donut"),L6o=o(" \u2014 "),vO=a("a"),y6o=o("DonutProcessor"),x6o=o(" (Donut model)"),$6o=l(),Sp=a("li"),wue=a("strong"),k6o=o("flava"),S6o=o(" \u2014 "),FO=a("a"),R6o=o("FlavaProcessor"),P6o=o(" (FLAVA model)"),B6o=l(),Rp=a("li"),Aue=a("strong"),I6o=o("groupvit"),N6o=o(" \u2014 "),TO=a("a"),q6o=o("CLIPProcessor"),j6o=o(" (GroupViT model)"),D6o=l(),Pp=a("li"),Lue=a("strong"),G6o=o("layoutlmv2"),O6o=o(" \u2014 "),MO=a("a"),V6o=o("LayoutLMv2Processor"),X6o=o(" (LayoutLMv2 model)"),z6o=l(),Bp=a("li"),yue=a("strong"),Q6o=o("layoutlmv3"),W6o=o(" \u2014 "),EO=a("a"),U6o=o("LayoutLMv3Processor"),H6o=o(" (LayoutLMv3 model)"),J6o=l(),Ip=a("li"),xue=a("strong"),Y6o=o("layoutxlm"),K6o=o(" \u2014 "),CO=a("a"),Z6o=o("LayoutXLMProcessor"),e7o=o(" (LayoutXLM model)"),o7o=l(),Np=a("li"),$ue=a("strong"),r7o=o("markuplm"),t7o=o(" \u2014 "),wO=a("a"),a7o=o("MarkupLMProcessor"),n7o=o(" (MarkupLM model)"),s7o=l(),qp=a("li"),kue=a("strong"),l7o=o("owlvit"),i7o=o(" \u2014 "),AO=a("a"),d7o=o("OwlViTProcessor"),c7o=o(" (OWL-ViT model)"),m7o=l(),jp=a("li"),Sue=a("strong"),f7o=o("sew"),g7o=o(" \u2014 "),LO=a("a"),h7o=o("Wav2Vec2Processor"),u7o=o(" (SEW model)"),p7o=l(),Dp=a("li"),Rue=a("strong"),_7o=o("sew-d"),b7o=o(" \u2014 "),yO=a("a"),v7o=o("Wav2Vec2Processor"),F7o=o(" (SEW-D model)"),T7o=l(),Gp=a("li"),Pue=a("strong"),M7o=o("speech_to_text"),E7o=o(" \u2014 "),xO=a("a"),C7o=o("Speech2TextProcessor"),w7o=o(" (Speech2Text model)"),A7o=l(),Op=a("li"),Bue=a("strong"),L7o=o("speech_to_text_2"),y7o=o(" \u2014 "),$O=a("a"),x7o=o("Speech2Text2Processor"),$7o=o(" (Speech2Text2 model)"),k7o=l(),Vp=a("li"),Iue=a("strong"),S7o=o("trocr"),R7o=o(" \u2014 "),kO=a("a"),P7o=o("TrOCRProcessor"),B7o=o(" (TrOCR model)"),I7o=l(),Xp=a("li"),Nue=a("strong"),N7o=o("unispeech"),q7o=o(" \u2014 "),SO=a("a"),j7o=o("Wav2Vec2Processor"),D7o=o(" (UniSpeech model)"),G7o=l(),zp=a("li"),que=a("strong"),O7o=o("unispeech-sat"),V7o=o(" \u2014 "),RO=a("a"),X7o=o("Wav2Vec2Processor"),z7o=o(" (UniSpeechSat model)"),Q7o=l(),Qp=a("li"),jue=a("strong"),W7o=o("vilt"),U7o=o(" \u2014 "),PO=a("a"),H7o=o("ViltProcessor"),J7o=o(" (ViLT model)"),Y7o=l(),Wp=a("li"),Due=a("strong"),K7o=o("vision-text-dual-encoder"),Z7o=o(" \u2014 "),BO=a("a"),eLo=o("VisionTextDualEncoderProcessor"),oLo=o(" (VisionTextDualEncoder model)"),rLo=l(),Up=a("li"),Gue=a("strong"),tLo=o("wav2vec2"),aLo=o(" \u2014 "),IO=a("a"),nLo=o("Wav2Vec2Processor"),sLo=o(" (Wav2Vec2 model)"),lLo=l(),Hp=a("li"),Oue=a("strong"),iLo=o("wav2vec2-conformer"),dLo=o(" \u2014 "),NO=a("a"),cLo=o("Wav2Vec2Processor"),mLo=o(" (Wav2Vec2-Conformer model)"),fLo=l(),Jp=a("li"),Vue=a("strong"),gLo=o("wavlm"),hLo=o(" \u2014 "),qO=a("a"),uLo=o("Wav2Vec2Processor"),pLo=o(" (WavLM model)"),_Lo=l(),Yp=a("li"),Xue=a("strong"),bLo=o("xclip"),vLo=o(" \u2014 "),jO=a("a"),FLo=o("CLIPProcessor"),TLo=o(" (X-CLIP model)"),MLo=l(),F(Kp.$$.fragment),ELo=l(),F(Zp.$$.fragment),CLo=l(),e_=a("div"),F(vx.$$.fragment),wLo=l(),zue=a("p"),ALo=o("Register a new processor for this class."),xZe=l(),_d=a("h2"),o_=a("a"),Que=a("span"),F(Fx.$$.fragment),LLo=l(),Wue=a("span"),yLo=o("AutoModel"),$Ze=l(),Po=a("div"),F(Tx.$$.fragment),xLo=l(),bd=a("p"),$Lo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),DO=a("a"),kLo=o("from_pretrained()"),SLo=o(" class method or the "),GO=a("a"),RLo=o("from_config()"),PLo=o(` class
method.`),BLo=l(),Mx=a("p"),ILo=o("This class cannot be instantiated directly using "),Uue=a("code"),NLo=o("__init__()"),qLo=o(" (throws an error)."),jLo=l(),_t=a("div"),F(Ex.$$.fragment),DLo=l(),Hue=a("p"),GLo=o("Instantiates one of the base model classes of the library from a configuration."),OLo=l(),vd=a("p"),VLo=o(`Note:
Loading a model from its configuration file does `),Jue=a("strong"),XLo=o("not"),zLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OO=a("a"),QLo=o("from_pretrained()"),WLo=o(" to load the model weights."),ULo=l(),F(r_.$$.fragment),HLo=l(),Ze=a("div"),F(Cx.$$.fragment),JLo=l(),Yue=a("p"),YLo=o("Instantiate one of the base model classes of the library from a pretrained model."),KLo=l(),Ja=a("p"),ZLo=o("The model class to instantiate is selected based on the "),Kue=a("code"),eyo=o("model_type"),oyo=o(` property of the config object (either
passed as an argument or loaded from `),Zue=a("code"),ryo=o("pretrained_model_name_or_path"),tyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),epe=a("code"),ayo=o("pretrained_model_name_or_path"),nyo=o(":"),syo=l(),y=a("ul"),t_=a("li"),ope=a("strong"),lyo=o("albert"),iyo=o(" \u2014 "),VO=a("a"),dyo=o("AlbertModel"),cyo=o(" (ALBERT model)"),myo=l(),a_=a("li"),rpe=a("strong"),fyo=o("bart"),gyo=o(" \u2014 "),XO=a("a"),hyo=o("BartModel"),uyo=o(" (BART model)"),pyo=l(),n_=a("li"),tpe=a("strong"),_yo=o("beit"),byo=o(" \u2014 "),zO=a("a"),vyo=o("BeitModel"),Fyo=o(" (BEiT model)"),Tyo=l(),s_=a("li"),ape=a("strong"),Myo=o("bert"),Eyo=o(" \u2014 "),QO=a("a"),Cyo=o("BertModel"),wyo=o(" (BERT model)"),Ayo=l(),l_=a("li"),npe=a("strong"),Lyo=o("bert-generation"),yyo=o(" \u2014 "),WO=a("a"),xyo=o("BertGenerationEncoder"),$yo=o(" (Bert Generation model)"),kyo=l(),i_=a("li"),spe=a("strong"),Syo=o("big_bird"),Ryo=o(" \u2014 "),UO=a("a"),Pyo=o("BigBirdModel"),Byo=o(" (BigBird model)"),Iyo=l(),d_=a("li"),lpe=a("strong"),Nyo=o("bigbird_pegasus"),qyo=o(" \u2014 "),HO=a("a"),jyo=o("BigBirdPegasusModel"),Dyo=o(" (BigBird-Pegasus model)"),Gyo=l(),c_=a("li"),ipe=a("strong"),Oyo=o("blenderbot"),Vyo=o(" \u2014 "),JO=a("a"),Xyo=o("BlenderbotModel"),zyo=o(" (Blenderbot model)"),Qyo=l(),m_=a("li"),dpe=a("strong"),Wyo=o("blenderbot-small"),Uyo=o(" \u2014 "),YO=a("a"),Hyo=o("BlenderbotSmallModel"),Jyo=o(" (BlenderbotSmall model)"),Yyo=l(),f_=a("li"),cpe=a("strong"),Kyo=o("bloom"),Zyo=o(" \u2014 "),KO=a("a"),e8o=o("BloomModel"),o8o=o(" (BLOOM model)"),r8o=l(),g_=a("li"),mpe=a("strong"),t8o=o("camembert"),a8o=o(" \u2014 "),ZO=a("a"),n8o=o("CamembertModel"),s8o=o(" (CamemBERT model)"),l8o=l(),h_=a("li"),fpe=a("strong"),i8o=o("canine"),d8o=o(" \u2014 "),eV=a("a"),c8o=o("CanineModel"),m8o=o(" (CANINE model)"),f8o=l(),u_=a("li"),gpe=a("strong"),g8o=o("clip"),h8o=o(" \u2014 "),oV=a("a"),u8o=o("CLIPModel"),p8o=o(" (CLIP model)"),_8o=l(),p_=a("li"),hpe=a("strong"),b8o=o("codegen"),v8o=o(" \u2014 "),rV=a("a"),F8o=o("CodeGenModel"),T8o=o(" (CodeGen model)"),M8o=l(),__=a("li"),upe=a("strong"),E8o=o("conditional_detr"),C8o=o(" \u2014 "),tV=a("a"),w8o=o("ConditionalDetrModel"),A8o=o(" (Conditional DETR model)"),L8o=l(),b_=a("li"),ppe=a("strong"),y8o=o("convbert"),x8o=o(" \u2014 "),aV=a("a"),$8o=o("ConvBertModel"),k8o=o(" (ConvBERT model)"),S8o=l(),v_=a("li"),_pe=a("strong"),R8o=o("convnext"),P8o=o(" \u2014 "),nV=a("a"),B8o=o("ConvNextModel"),I8o=o(" (ConvNeXT model)"),N8o=l(),F_=a("li"),bpe=a("strong"),q8o=o("ctrl"),j8o=o(" \u2014 "),sV=a("a"),D8o=o("CTRLModel"),G8o=o(" (CTRL model)"),O8o=l(),T_=a("li"),vpe=a("strong"),V8o=o("cvt"),X8o=o(" \u2014 "),lV=a("a"),z8o=o("CvtModel"),Q8o=o(" (CvT model)"),W8o=l(),M_=a("li"),Fpe=a("strong"),U8o=o("data2vec-audio"),H8o=o(" \u2014 "),iV=a("a"),J8o=o("Data2VecAudioModel"),Y8o=o(" (Data2VecAudio model)"),K8o=l(),E_=a("li"),Tpe=a("strong"),Z8o=o("data2vec-text"),e9o=o(" \u2014 "),dV=a("a"),o9o=o("Data2VecTextModel"),r9o=o(" (Data2VecText model)"),t9o=l(),C_=a("li"),Mpe=a("strong"),a9o=o("data2vec-vision"),n9o=o(" \u2014 "),cV=a("a"),s9o=o("Data2VecVisionModel"),l9o=o(" (Data2VecVision model)"),i9o=l(),w_=a("li"),Epe=a("strong"),d9o=o("deberta"),c9o=o(" \u2014 "),mV=a("a"),m9o=o("DebertaModel"),f9o=o(" (DeBERTa model)"),g9o=l(),A_=a("li"),Cpe=a("strong"),h9o=o("deberta-v2"),u9o=o(" \u2014 "),fV=a("a"),p9o=o("DebertaV2Model"),_9o=o(" (DeBERTa-v2 model)"),b9o=l(),L_=a("li"),wpe=a("strong"),v9o=o("decision_transformer"),F9o=o(" \u2014 "),gV=a("a"),T9o=o("DecisionTransformerModel"),M9o=o(" (Decision Transformer model)"),E9o=l(),y_=a("li"),Ape=a("strong"),C9o=o("deformable_detr"),w9o=o(" \u2014 "),hV=a("a"),A9o=o("DeformableDetrModel"),L9o=o(" (Deformable DETR model)"),y9o=l(),x_=a("li"),Lpe=a("strong"),x9o=o("deit"),$9o=o(" \u2014 "),uV=a("a"),k9o=o("DeiTModel"),S9o=o(" (DeiT model)"),R9o=l(),$_=a("li"),ype=a("strong"),P9o=o("detr"),B9o=o(" \u2014 "),pV=a("a"),I9o=o("DetrModel"),N9o=o(" (DETR model)"),q9o=l(),k_=a("li"),xpe=a("strong"),j9o=o("distilbert"),D9o=o(" \u2014 "),_V=a("a"),G9o=o("DistilBertModel"),O9o=o(" (DistilBERT model)"),V9o=l(),S_=a("li"),$pe=a("strong"),X9o=o("donut-swin"),z9o=o(" \u2014 "),bV=a("a"),Q9o=o("DonutSwinModel"),W9o=o(" (DonutSwin model)"),U9o=l(),R_=a("li"),kpe=a("strong"),H9o=o("dpr"),J9o=o(" \u2014 "),vV=a("a"),Y9o=o("DPRQuestionEncoder"),K9o=o(" (DPR model)"),Z9o=l(),P_=a("li"),Spe=a("strong"),exo=o("dpt"),oxo=o(" \u2014 "),FV=a("a"),rxo=o("DPTModel"),txo=o(" (DPT model)"),axo=l(),B_=a("li"),Rpe=a("strong"),nxo=o("electra"),sxo=o(" \u2014 "),TV=a("a"),lxo=o("ElectraModel"),ixo=o(" (ELECTRA model)"),dxo=l(),I_=a("li"),Ppe=a("strong"),cxo=o("ernie"),mxo=o(" \u2014 "),MV=a("a"),fxo=o("ErnieModel"),gxo=o(" (ERNIE model)"),hxo=l(),N_=a("li"),Bpe=a("strong"),uxo=o("flaubert"),pxo=o(" \u2014 "),EV=a("a"),_xo=o("FlaubertModel"),bxo=o(" (FlauBERT model)"),vxo=l(),q_=a("li"),Ipe=a("strong"),Fxo=o("flava"),Txo=o(" \u2014 "),CV=a("a"),Mxo=o("FlavaModel"),Exo=o(" (FLAVA model)"),Cxo=l(),j_=a("li"),Npe=a("strong"),wxo=o("fnet"),Axo=o(" \u2014 "),wV=a("a"),Lxo=o("FNetModel"),yxo=o(" (FNet model)"),xxo=l(),D_=a("li"),qpe=a("strong"),$xo=o("fsmt"),kxo=o(" \u2014 "),AV=a("a"),Sxo=o("FSMTModel"),Rxo=o(" (FairSeq Machine-Translation model)"),Pxo=l(),_l=a("li"),jpe=a("strong"),Bxo=o("funnel"),Ixo=o(" \u2014 "),LV=a("a"),Nxo=o("FunnelModel"),qxo=o(" or "),yV=a("a"),jxo=o("FunnelBaseModel"),Dxo=o(" (Funnel Transformer model)"),Gxo=l(),G_=a("li"),Dpe=a("strong"),Oxo=o("glpn"),Vxo=o(" \u2014 "),xV=a("a"),Xxo=o("GLPNModel"),zxo=o(" (GLPN model)"),Qxo=l(),O_=a("li"),Gpe=a("strong"),Wxo=o("gpt2"),Uxo=o(" \u2014 "),$V=a("a"),Hxo=o("GPT2Model"),Jxo=o(" (OpenAI GPT-2 model)"),Yxo=l(),V_=a("li"),Ope=a("strong"),Kxo=o("gpt_neo"),Zxo=o(" \u2014 "),kV=a("a"),e$o=o("GPTNeoModel"),o$o=o(" (GPT Neo model)"),r$o=l(),X_=a("li"),Vpe=a("strong"),t$o=o("gpt_neox"),a$o=o(" \u2014 "),SV=a("a"),n$o=o("GPTNeoXModel"),s$o=o(" (GPT NeoX model)"),l$o=l(),z_=a("li"),Xpe=a("strong"),i$o=o("gpt_neox_japanese"),d$o=o(" \u2014 "),RV=a("a"),c$o=o("GPTNeoXJapaneseModel"),m$o=o(" (GPT NeoX Japanese model)"),f$o=l(),Q_=a("li"),zpe=a("strong"),g$o=o("gptj"),h$o=o(" \u2014 "),PV=a("a"),u$o=o("GPTJModel"),p$o=o(" (GPT-J model)"),_$o=l(),W_=a("li"),Qpe=a("strong"),b$o=o("groupvit"),v$o=o(" \u2014 "),BV=a("a"),F$o=o("GroupViTModel"),T$o=o(" (GroupViT model)"),M$o=l(),U_=a("li"),Wpe=a("strong"),E$o=o("hubert"),C$o=o(" \u2014 "),IV=a("a"),w$o=o("HubertModel"),A$o=o(" (Hubert model)"),L$o=l(),H_=a("li"),Upe=a("strong"),y$o=o("ibert"),x$o=o(" \u2014 "),NV=a("a"),$$o=o("IBertModel"),k$o=o(" (I-BERT model)"),S$o=l(),J_=a("li"),Hpe=a("strong"),R$o=o("imagegpt"),P$o=o(" \u2014 "),qV=a("a"),B$o=o("ImageGPTModel"),I$o=o(" (ImageGPT model)"),N$o=l(),Y_=a("li"),Jpe=a("strong"),q$o=o("layoutlm"),j$o=o(" \u2014 "),jV=a("a"),D$o=o("LayoutLMModel"),G$o=o(" (LayoutLM model)"),O$o=l(),K_=a("li"),Ype=a("strong"),V$o=o("layoutlmv2"),X$o=o(" \u2014 "),DV=a("a"),z$o=o("LayoutLMv2Model"),Q$o=o(" (LayoutLMv2 model)"),W$o=l(),Z_=a("li"),Kpe=a("strong"),U$o=o("layoutlmv3"),H$o=o(" \u2014 "),GV=a("a"),J$o=o("LayoutLMv3Model"),Y$o=o(" (LayoutLMv3 model)"),K$o=l(),e2=a("li"),Zpe=a("strong"),Z$o=o("led"),eko=o(" \u2014 "),OV=a("a"),oko=o("LEDModel"),rko=o(" (LED model)"),tko=l(),o2=a("li"),e_e=a("strong"),ako=o("levit"),nko=o(" \u2014 "),VV=a("a"),sko=o("LevitModel"),lko=o(" (LeViT model)"),iko=l(),r2=a("li"),o_e=a("strong"),dko=o("longformer"),cko=o(" \u2014 "),XV=a("a"),mko=o("LongformerModel"),fko=o(" (Longformer model)"),gko=l(),t2=a("li"),r_e=a("strong"),hko=o("longt5"),uko=o(" \u2014 "),zV=a("a"),pko=o("LongT5Model"),_ko=o(" (LongT5 model)"),bko=l(),a2=a("li"),t_e=a("strong"),vko=o("luke"),Fko=o(" \u2014 "),QV=a("a"),Tko=o("LukeModel"),Mko=o(" (LUKE model)"),Eko=l(),n2=a("li"),a_e=a("strong"),Cko=o("lxmert"),wko=o(" \u2014 "),WV=a("a"),Ako=o("LxmertModel"),Lko=o(" (LXMERT model)"),yko=l(),s2=a("li"),n_e=a("strong"),xko=o("m2m_100"),$ko=o(" \u2014 "),UV=a("a"),kko=o("M2M100Model"),Sko=o(" (M2M100 model)"),Rko=l(),l2=a("li"),s_e=a("strong"),Pko=o("marian"),Bko=o(" \u2014 "),HV=a("a"),Iko=o("MarianModel"),Nko=o(" (Marian model)"),qko=l(),i2=a("li"),l_e=a("strong"),jko=o("markuplm"),Dko=o(" \u2014 "),JV=a("a"),Gko=o("MarkupLMModel"),Oko=o(" (MarkupLM model)"),Vko=l(),d2=a("li"),i_e=a("strong"),Xko=o("maskformer"),zko=o(" \u2014 "),YV=a("a"),Qko=o("MaskFormerModel"),Wko=o(" (MaskFormer model)"),Uko=l(),c2=a("li"),d_e=a("strong"),Hko=o("mbart"),Jko=o(" \u2014 "),KV=a("a"),Yko=o("MBartModel"),Kko=o(" (mBART model)"),Zko=l(),m2=a("li"),c_e=a("strong"),eSo=o("mctct"),oSo=o(" \u2014 "),ZV=a("a"),rSo=o("MCTCTModel"),tSo=o(" (M-CTC-T model)"),aSo=l(),f2=a("li"),m_e=a("strong"),nSo=o("megatron-bert"),sSo=o(" \u2014 "),eX=a("a"),lSo=o("MegatronBertModel"),iSo=o(" (Megatron-BERT model)"),dSo=l(),g2=a("li"),f_e=a("strong"),cSo=o("mobilebert"),mSo=o(" \u2014 "),oX=a("a"),fSo=o("MobileBertModel"),gSo=o(" (MobileBERT model)"),hSo=l(),h2=a("li"),g_e=a("strong"),uSo=o("mobilevit"),pSo=o(" \u2014 "),rX=a("a"),_So=o("MobileViTModel"),bSo=o(" (MobileViT model)"),vSo=l(),u2=a("li"),h_e=a("strong"),FSo=o("mpnet"),TSo=o(" \u2014 "),tX=a("a"),MSo=o("MPNetModel"),ESo=o(" (MPNet model)"),CSo=l(),p2=a("li"),u_e=a("strong"),wSo=o("mt5"),ASo=o(" \u2014 "),aX=a("a"),LSo=o("MT5Model"),ySo=o(" (MT5 model)"),xSo=l(),_2=a("li"),p_e=a("strong"),$So=o("mvp"),kSo=o(" \u2014 "),nX=a("a"),SSo=o("MvpModel"),RSo=o(" (MVP model)"),PSo=l(),b2=a("li"),__e=a("strong"),BSo=o("nezha"),ISo=o(" \u2014 "),sX=a("a"),NSo=o("NezhaModel"),qSo=o(" (Nezha model)"),jSo=l(),v2=a("li"),b_e=a("strong"),DSo=o("nllb"),GSo=o(" \u2014 "),lX=a("a"),OSo=o("M2M100Model"),VSo=o(" (NLLB model)"),XSo=l(),F2=a("li"),v_e=a("strong"),zSo=o("nystromformer"),QSo=o(" \u2014 "),iX=a("a"),WSo=o("NystromformerModel"),USo=o(" (Nystr\xF6mformer model)"),HSo=l(),T2=a("li"),F_e=a("strong"),JSo=o("openai-gpt"),YSo=o(" \u2014 "),dX=a("a"),KSo=o("OpenAIGPTModel"),ZSo=o(" (OpenAI GPT model)"),eRo=l(),M2=a("li"),T_e=a("strong"),oRo=o("opt"),rRo=o(" \u2014 "),cX=a("a"),tRo=o("OPTModel"),aRo=o(" (OPT model)"),nRo=l(),E2=a("li"),M_e=a("strong"),sRo=o("owlvit"),lRo=o(" \u2014 "),mX=a("a"),iRo=o("OwlViTModel"),dRo=o(" (OWL-ViT model)"),cRo=l(),C2=a("li"),E_e=a("strong"),mRo=o("pegasus"),fRo=o(" \u2014 "),fX=a("a"),gRo=o("PegasusModel"),hRo=o(" (Pegasus model)"),uRo=l(),w2=a("li"),C_e=a("strong"),pRo=o("pegasus_x"),_Ro=o(" \u2014 "),gX=a("a"),bRo=o("PegasusXModel"),vRo=o(" (PEGASUS-X model)"),FRo=l(),A2=a("li"),w_e=a("strong"),TRo=o("perceiver"),MRo=o(" \u2014 "),hX=a("a"),ERo=o("PerceiverModel"),CRo=o(" (Perceiver model)"),wRo=l(),L2=a("li"),A_e=a("strong"),ARo=o("plbart"),LRo=o(" \u2014 "),uX=a("a"),yRo=o("PLBartModel"),xRo=o(" (PLBart model)"),$Ro=l(),y2=a("li"),L_e=a("strong"),kRo=o("poolformer"),SRo=o(" \u2014 "),pX=a("a"),RRo=o("PoolFormerModel"),PRo=o(" (PoolFormer model)"),BRo=l(),x2=a("li"),y_e=a("strong"),IRo=o("prophetnet"),NRo=o(" \u2014 "),_X=a("a"),qRo=o("ProphetNetModel"),jRo=o(" (ProphetNet model)"),DRo=l(),$2=a("li"),x_e=a("strong"),GRo=o("qdqbert"),ORo=o(" \u2014 "),bX=a("a"),VRo=o("QDQBertModel"),XRo=o(" (QDQBert model)"),zRo=l(),k2=a("li"),$_e=a("strong"),QRo=o("reformer"),WRo=o(" \u2014 "),vX=a("a"),URo=o("ReformerModel"),HRo=o(" (Reformer model)"),JRo=l(),S2=a("li"),k_e=a("strong"),YRo=o("regnet"),KRo=o(" \u2014 "),FX=a("a"),ZRo=o("RegNetModel"),ePo=o(" (RegNet model)"),oPo=l(),R2=a("li"),S_e=a("strong"),rPo=o("rembert"),tPo=o(" \u2014 "),TX=a("a"),aPo=o("RemBertModel"),nPo=o(" (RemBERT model)"),sPo=l(),P2=a("li"),R_e=a("strong"),lPo=o("resnet"),iPo=o(" \u2014 "),MX=a("a"),dPo=o("ResNetModel"),cPo=o(" (ResNet model)"),mPo=l(),B2=a("li"),P_e=a("strong"),fPo=o("retribert"),gPo=o(" \u2014 "),EX=a("a"),hPo=o("RetriBertModel"),uPo=o(" (RetriBERT model)"),pPo=l(),I2=a("li"),B_e=a("strong"),_Po=o("roberta"),bPo=o(" \u2014 "),CX=a("a"),vPo=o("RobertaModel"),FPo=o(" (RoBERTa model)"),TPo=l(),N2=a("li"),I_e=a("strong"),MPo=o("roformer"),EPo=o(" \u2014 "),wX=a("a"),CPo=o("RoFormerModel"),wPo=o(" (RoFormer model)"),APo=l(),q2=a("li"),N_e=a("strong"),LPo=o("segformer"),yPo=o(" \u2014 "),AX=a("a"),xPo=o("SegformerModel"),$Po=o(" (SegFormer model)"),kPo=l(),j2=a("li"),q_e=a("strong"),SPo=o("sew"),RPo=o(" \u2014 "),LX=a("a"),PPo=o("SEWModel"),BPo=o(" (SEW model)"),IPo=l(),D2=a("li"),j_e=a("strong"),NPo=o("sew-d"),qPo=o(" \u2014 "),yX=a("a"),jPo=o("SEWDModel"),DPo=o(" (SEW-D model)"),GPo=l(),G2=a("li"),D_e=a("strong"),OPo=o("speech_to_text"),VPo=o(" \u2014 "),xX=a("a"),XPo=o("Speech2TextModel"),zPo=o(" (Speech2Text model)"),QPo=l(),O2=a("li"),G_e=a("strong"),WPo=o("splinter"),UPo=o(" \u2014 "),$X=a("a"),HPo=o("SplinterModel"),JPo=o(" (Splinter model)"),YPo=l(),V2=a("li"),O_e=a("strong"),KPo=o("squeezebert"),ZPo=o(" \u2014 "),kX=a("a"),eBo=o("SqueezeBertModel"),oBo=o(" (SqueezeBERT model)"),rBo=l(),X2=a("li"),V_e=a("strong"),tBo=o("swin"),aBo=o(" \u2014 "),SX=a("a"),nBo=o("SwinModel"),sBo=o(" (Swin Transformer model)"),lBo=l(),z2=a("li"),X_e=a("strong"),iBo=o("swinv2"),dBo=o(" \u2014 "),RX=a("a"),cBo=o("Swinv2Model"),mBo=o(" (Swin Transformer V2 model)"),fBo=l(),Q2=a("li"),z_e=a("strong"),gBo=o("t5"),hBo=o(" \u2014 "),PX=a("a"),uBo=o("T5Model"),pBo=o(" (T5 model)"),_Bo=l(),W2=a("li"),Q_e=a("strong"),bBo=o("tapas"),vBo=o(" \u2014 "),BX=a("a"),FBo=o("TapasModel"),TBo=o(" (TAPAS model)"),MBo=l(),U2=a("li"),W_e=a("strong"),EBo=o("trajectory_transformer"),CBo=o(" \u2014 "),IX=a("a"),wBo=o("TrajectoryTransformerModel"),ABo=o(" (Trajectory Transformer model)"),LBo=l(),H2=a("li"),U_e=a("strong"),yBo=o("transfo-xl"),xBo=o(" \u2014 "),NX=a("a"),$Bo=o("TransfoXLModel"),kBo=o(" (Transformer-XL model)"),SBo=l(),J2=a("li"),H_e=a("strong"),RBo=o("unispeech"),PBo=o(" \u2014 "),qX=a("a"),BBo=o("UniSpeechModel"),IBo=o(" (UniSpeech model)"),NBo=l(),Y2=a("li"),J_e=a("strong"),qBo=o("unispeech-sat"),jBo=o(" \u2014 "),jX=a("a"),DBo=o("UniSpeechSatModel"),GBo=o(" (UniSpeechSat model)"),OBo=l(),K2=a("li"),Y_e=a("strong"),VBo=o("van"),XBo=o(" \u2014 "),DX=a("a"),zBo=o("VanModel"),QBo=o(" (VAN model)"),WBo=l(),Z2=a("li"),K_e=a("strong"),UBo=o("videomae"),HBo=o(" \u2014 "),GX=a("a"),JBo=o("VideoMAEModel"),YBo=o(" (VideoMAE model)"),KBo=l(),eb=a("li"),Z_e=a("strong"),ZBo=o("vilt"),eIo=o(" \u2014 "),OX=a("a"),oIo=o("ViltModel"),rIo=o(" (ViLT model)"),tIo=l(),ob=a("li"),e2e=a("strong"),aIo=o("vision-text-dual-encoder"),nIo=o(" \u2014 "),VX=a("a"),sIo=o("VisionTextDualEncoderModel"),lIo=o(" (VisionTextDualEncoder model)"),iIo=l(),rb=a("li"),o2e=a("strong"),dIo=o("visual_bert"),cIo=o(" \u2014 "),XX=a("a"),mIo=o("VisualBertModel"),fIo=o(" (VisualBERT model)"),gIo=l(),tb=a("li"),r2e=a("strong"),hIo=o("vit"),uIo=o(" \u2014 "),zX=a("a"),pIo=o("ViTModel"),_Io=o(" (ViT model)"),bIo=l(),ab=a("li"),t2e=a("strong"),vIo=o("vit_mae"),FIo=o(" \u2014 "),QX=a("a"),TIo=o("ViTMAEModel"),MIo=o(" (ViTMAE model)"),EIo=l(),nb=a("li"),a2e=a("strong"),CIo=o("vit_msn"),wIo=o(" \u2014 "),WX=a("a"),AIo=o("ViTMSNModel"),LIo=o(" (ViTMSN model)"),yIo=l(),sb=a("li"),n2e=a("strong"),xIo=o("wav2vec2"),$Io=o(" \u2014 "),UX=a("a"),kIo=o("Wav2Vec2Model"),SIo=o(" (Wav2Vec2 model)"),RIo=l(),lb=a("li"),s2e=a("strong"),PIo=o("wav2vec2-conformer"),BIo=o(" \u2014 "),HX=a("a"),IIo=o("Wav2Vec2ConformerModel"),NIo=o(" (Wav2Vec2-Conformer model)"),qIo=l(),ib=a("li"),l2e=a("strong"),jIo=o("wavlm"),DIo=o(" \u2014 "),JX=a("a"),GIo=o("WavLMModel"),OIo=o(" (WavLM model)"),VIo=l(),db=a("li"),i2e=a("strong"),XIo=o("xclip"),zIo=o(" \u2014 "),YX=a("a"),QIo=o("XCLIPModel"),WIo=o(" (X-CLIP model)"),UIo=l(),cb=a("li"),d2e=a("strong"),HIo=o("xglm"),JIo=o(" \u2014 "),KX=a("a"),YIo=o("XGLMModel"),KIo=o(" (XGLM model)"),ZIo=l(),mb=a("li"),c2e=a("strong"),eNo=o("xlm"),oNo=o(" \u2014 "),ZX=a("a"),rNo=o("XLMModel"),tNo=o(" (XLM model)"),aNo=l(),fb=a("li"),m2e=a("strong"),nNo=o("xlm-prophetnet"),sNo=o(" \u2014 "),ez=a("a"),lNo=o("XLMProphetNetModel"),iNo=o(" (XLM-ProphetNet model)"),dNo=l(),gb=a("li"),f2e=a("strong"),cNo=o("xlm-roberta"),mNo=o(" \u2014 "),oz=a("a"),fNo=o("XLMRobertaModel"),gNo=o(" (XLM-RoBERTa model)"),hNo=l(),hb=a("li"),g2e=a("strong"),uNo=o("xlm-roberta-xl"),pNo=o(" \u2014 "),rz=a("a"),_No=o("XLMRobertaXLModel"),bNo=o(" (XLM-RoBERTa-XL model)"),vNo=l(),ub=a("li"),h2e=a("strong"),FNo=o("xlnet"),TNo=o(" \u2014 "),tz=a("a"),MNo=o("XLNetModel"),ENo=o(" (XLNet model)"),CNo=l(),pb=a("li"),u2e=a("strong"),wNo=o("yolos"),ANo=o(" \u2014 "),az=a("a"),LNo=o("YolosModel"),yNo=o(" (YOLOS model)"),xNo=l(),_b=a("li"),p2e=a("strong"),$No=o("yoso"),kNo=o(" \u2014 "),nz=a("a"),SNo=o("YosoModel"),RNo=o(" (YOSO model)"),PNo=l(),bb=a("p"),BNo=o("The model is set in evaluation mode by default using "),_2e=a("code"),INo=o("model.eval()"),NNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=a("code"),qNo=o("model.train()"),jNo=l(),F(vb.$$.fragment),kZe=l(),Fd=a("h2"),Fb=a("a"),v2e=a("span"),F(wx.$$.fragment),DNo=l(),F2e=a("span"),GNo=o("AutoModelForPreTraining"),SZe=l(),Bo=a("div"),F(Ax.$$.fragment),ONo=l(),Td=a("p"),VNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),sz=a("a"),XNo=o("from_pretrained()"),zNo=o(" class method or the "),lz=a("a"),QNo=o("from_config()"),WNo=o(` class
method.`),UNo=l(),Lx=a("p"),HNo=o("This class cannot be instantiated directly using "),T2e=a("code"),JNo=o("__init__()"),YNo=o(" (throws an error)."),KNo=l(),bt=a("div"),F(yx.$$.fragment),ZNo=l(),M2e=a("p"),eqo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),oqo=l(),Md=a("p"),rqo=o(`Note:
Loading a model from its configuration file does `),E2e=a("strong"),tqo=o("not"),aqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=a("a"),nqo=o("from_pretrained()"),sqo=o(" to load the model weights."),lqo=l(),F(Tb.$$.fragment),iqo=l(),eo=a("div"),F(xx.$$.fragment),dqo=l(),C2e=a("p"),cqo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),mqo=l(),Ya=a("p"),fqo=o("The model class to instantiate is selected based on the "),w2e=a("code"),gqo=o("model_type"),hqo=o(` property of the config object (either
passed as an argument or loaded from `),A2e=a("code"),uqo=o("pretrained_model_name_or_path"),pqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=a("code"),_qo=o("pretrained_model_name_or_path"),bqo=o(":"),vqo=l(),G=a("ul"),Mb=a("li"),y2e=a("strong"),Fqo=o("albert"),Tqo=o(" \u2014 "),dz=a("a"),Mqo=o("AlbertForPreTraining"),Eqo=o(" (ALBERT model)"),Cqo=l(),Eb=a("li"),x2e=a("strong"),wqo=o("bart"),Aqo=o(" \u2014 "),cz=a("a"),Lqo=o("BartForConditionalGeneration"),yqo=o(" (BART model)"),xqo=l(),Cb=a("li"),$2e=a("strong"),$qo=o("bert"),kqo=o(" \u2014 "),mz=a("a"),Sqo=o("BertForPreTraining"),Rqo=o(" (BERT model)"),Pqo=l(),wb=a("li"),k2e=a("strong"),Bqo=o("big_bird"),Iqo=o(" \u2014 "),fz=a("a"),Nqo=o("BigBirdForPreTraining"),qqo=o(" (BigBird model)"),jqo=l(),Ab=a("li"),S2e=a("strong"),Dqo=o("bloom"),Gqo=o(" \u2014 "),gz=a("a"),Oqo=o("BloomForCausalLM"),Vqo=o(" (BLOOM model)"),Xqo=l(),Lb=a("li"),R2e=a("strong"),zqo=o("camembert"),Qqo=o(" \u2014 "),hz=a("a"),Wqo=o("CamembertForMaskedLM"),Uqo=o(" (CamemBERT model)"),Hqo=l(),yb=a("li"),P2e=a("strong"),Jqo=o("ctrl"),Yqo=o(" \u2014 "),uz=a("a"),Kqo=o("CTRLLMHeadModel"),Zqo=o(" (CTRL model)"),ejo=l(),xb=a("li"),B2e=a("strong"),ojo=o("data2vec-text"),rjo=o(" \u2014 "),pz=a("a"),tjo=o("Data2VecTextForMaskedLM"),ajo=o(" (Data2VecText model)"),njo=l(),$b=a("li"),I2e=a("strong"),sjo=o("deberta"),ljo=o(" \u2014 "),_z=a("a"),ijo=o("DebertaForMaskedLM"),djo=o(" (DeBERTa model)"),cjo=l(),kb=a("li"),N2e=a("strong"),mjo=o("deberta-v2"),fjo=o(" \u2014 "),bz=a("a"),gjo=o("DebertaV2ForMaskedLM"),hjo=o(" (DeBERTa-v2 model)"),ujo=l(),Sb=a("li"),q2e=a("strong"),pjo=o("distilbert"),_jo=o(" \u2014 "),vz=a("a"),bjo=o("DistilBertForMaskedLM"),vjo=o(" (DistilBERT model)"),Fjo=l(),Rb=a("li"),j2e=a("strong"),Tjo=o("electra"),Mjo=o(" \u2014 "),Fz=a("a"),Ejo=o("ElectraForPreTraining"),Cjo=o(" (ELECTRA model)"),wjo=l(),Pb=a("li"),D2e=a("strong"),Ajo=o("ernie"),Ljo=o(" \u2014 "),Tz=a("a"),yjo=o("ErnieForPreTraining"),xjo=o(" (ERNIE model)"),$jo=l(),Bb=a("li"),G2e=a("strong"),kjo=o("flaubert"),Sjo=o(" \u2014 "),Mz=a("a"),Rjo=o("FlaubertWithLMHeadModel"),Pjo=o(" (FlauBERT model)"),Bjo=l(),Ib=a("li"),O2e=a("strong"),Ijo=o("flava"),Njo=o(" \u2014 "),Ez=a("a"),qjo=o("FlavaForPreTraining"),jjo=o(" (FLAVA model)"),Djo=l(),Nb=a("li"),V2e=a("strong"),Gjo=o("fnet"),Ojo=o(" \u2014 "),Cz=a("a"),Vjo=o("FNetForPreTraining"),Xjo=o(" (FNet model)"),zjo=l(),qb=a("li"),X2e=a("strong"),Qjo=o("fsmt"),Wjo=o(" \u2014 "),wz=a("a"),Ujo=o("FSMTForConditionalGeneration"),Hjo=o(" (FairSeq Machine-Translation model)"),Jjo=l(),jb=a("li"),z2e=a("strong"),Yjo=o("funnel"),Kjo=o(" \u2014 "),Az=a("a"),Zjo=o("FunnelForPreTraining"),eDo=o(" (Funnel Transformer model)"),oDo=l(),Db=a("li"),Q2e=a("strong"),rDo=o("gpt2"),tDo=o(" \u2014 "),Lz=a("a"),aDo=o("GPT2LMHeadModel"),nDo=o(" (OpenAI GPT-2 model)"),sDo=l(),Gb=a("li"),W2e=a("strong"),lDo=o("ibert"),iDo=o(" \u2014 "),yz=a("a"),dDo=o("IBertForMaskedLM"),cDo=o(" (I-BERT model)"),mDo=l(),Ob=a("li"),U2e=a("strong"),fDo=o("layoutlm"),gDo=o(" \u2014 "),xz=a("a"),hDo=o("LayoutLMForMaskedLM"),uDo=o(" (LayoutLM model)"),pDo=l(),Vb=a("li"),H2e=a("strong"),_Do=o("longformer"),bDo=o(" \u2014 "),$z=a("a"),vDo=o("LongformerForMaskedLM"),FDo=o(" (Longformer model)"),TDo=l(),Xb=a("li"),J2e=a("strong"),MDo=o("luke"),EDo=o(" \u2014 "),kz=a("a"),CDo=o("LukeForMaskedLM"),wDo=o(" (LUKE model)"),ADo=l(),zb=a("li"),Y2e=a("strong"),LDo=o("lxmert"),yDo=o(" \u2014 "),Sz=a("a"),xDo=o("LxmertForPreTraining"),$Do=o(" (LXMERT model)"),kDo=l(),Qb=a("li"),K2e=a("strong"),SDo=o("megatron-bert"),RDo=o(" \u2014 "),Rz=a("a"),PDo=o("MegatronBertForPreTraining"),BDo=o(" (Megatron-BERT model)"),IDo=l(),Wb=a("li"),Z2e=a("strong"),NDo=o("mobilebert"),qDo=o(" \u2014 "),Pz=a("a"),jDo=o("MobileBertForPreTraining"),DDo=o(" (MobileBERT model)"),GDo=l(),Ub=a("li"),ebe=a("strong"),ODo=o("mpnet"),VDo=o(" \u2014 "),Bz=a("a"),XDo=o("MPNetForMaskedLM"),zDo=o(" (MPNet model)"),QDo=l(),Hb=a("li"),obe=a("strong"),WDo=o("mvp"),UDo=o(" \u2014 "),Iz=a("a"),HDo=o("MvpForConditionalGeneration"),JDo=o(" (MVP model)"),YDo=l(),Jb=a("li"),rbe=a("strong"),KDo=o("nezha"),ZDo=o(" \u2014 "),Nz=a("a"),eGo=o("NezhaForPreTraining"),oGo=o(" (Nezha model)"),rGo=l(),Yb=a("li"),tbe=a("strong"),tGo=o("openai-gpt"),aGo=o(" \u2014 "),qz=a("a"),nGo=o("OpenAIGPTLMHeadModel"),sGo=o(" (OpenAI GPT model)"),lGo=l(),Kb=a("li"),abe=a("strong"),iGo=o("retribert"),dGo=o(" \u2014 "),jz=a("a"),cGo=o("RetriBertModel"),mGo=o(" (RetriBERT model)"),fGo=l(),Zb=a("li"),nbe=a("strong"),gGo=o("roberta"),hGo=o(" \u2014 "),Dz=a("a"),uGo=o("RobertaForMaskedLM"),pGo=o(" (RoBERTa model)"),_Go=l(),e1=a("li"),sbe=a("strong"),bGo=o("splinter"),vGo=o(" \u2014 "),Gz=a("a"),FGo=o("SplinterForPreTraining"),TGo=o(" (Splinter model)"),MGo=l(),o1=a("li"),lbe=a("strong"),EGo=o("squeezebert"),CGo=o(" \u2014 "),Oz=a("a"),wGo=o("SqueezeBertForMaskedLM"),AGo=o(" (SqueezeBERT model)"),LGo=l(),r1=a("li"),ibe=a("strong"),yGo=o("t5"),xGo=o(" \u2014 "),Vz=a("a"),$Go=o("T5ForConditionalGeneration"),kGo=o(" (T5 model)"),SGo=l(),t1=a("li"),dbe=a("strong"),RGo=o("tapas"),PGo=o(" \u2014 "),Xz=a("a"),BGo=o("TapasForMaskedLM"),IGo=o(" (TAPAS model)"),NGo=l(),a1=a("li"),cbe=a("strong"),qGo=o("transfo-xl"),jGo=o(" \u2014 "),zz=a("a"),DGo=o("TransfoXLLMHeadModel"),GGo=o(" (Transformer-XL model)"),OGo=l(),n1=a("li"),mbe=a("strong"),VGo=o("unispeech"),XGo=o(" \u2014 "),Qz=a("a"),zGo=o("UniSpeechForPreTraining"),QGo=o(" (UniSpeech model)"),WGo=l(),s1=a("li"),fbe=a("strong"),UGo=o("unispeech-sat"),HGo=o(" \u2014 "),Wz=a("a"),JGo=o("UniSpeechSatForPreTraining"),YGo=o(" (UniSpeechSat model)"),KGo=l(),l1=a("li"),gbe=a("strong"),ZGo=o("videomae"),eOo=o(" \u2014 "),Uz=a("a"),oOo=o("VideoMAEForPreTraining"),rOo=o(" (VideoMAE model)"),tOo=l(),i1=a("li"),hbe=a("strong"),aOo=o("visual_bert"),nOo=o(" \u2014 "),Hz=a("a"),sOo=o("VisualBertForPreTraining"),lOo=o(" (VisualBERT model)"),iOo=l(),d1=a("li"),ube=a("strong"),dOo=o("vit_mae"),cOo=o(" \u2014 "),Jz=a("a"),mOo=o("ViTMAEForPreTraining"),fOo=o(" (ViTMAE model)"),gOo=l(),c1=a("li"),pbe=a("strong"),hOo=o("wav2vec2"),uOo=o(" \u2014 "),Yz=a("a"),pOo=o("Wav2Vec2ForPreTraining"),_Oo=o(" (Wav2Vec2 model)"),bOo=l(),m1=a("li"),_be=a("strong"),vOo=o("wav2vec2-conformer"),FOo=o(" \u2014 "),Kz=a("a"),TOo=o("Wav2Vec2ConformerForPreTraining"),MOo=o(" (Wav2Vec2-Conformer model)"),EOo=l(),f1=a("li"),bbe=a("strong"),COo=o("xlm"),wOo=o(" \u2014 "),Zz=a("a"),AOo=o("XLMWithLMHeadModel"),LOo=o(" (XLM model)"),yOo=l(),g1=a("li"),vbe=a("strong"),xOo=o("xlm-roberta"),$Oo=o(" \u2014 "),eQ=a("a"),kOo=o("XLMRobertaForMaskedLM"),SOo=o(" (XLM-RoBERTa model)"),ROo=l(),h1=a("li"),Fbe=a("strong"),POo=o("xlm-roberta-xl"),BOo=o(" \u2014 "),oQ=a("a"),IOo=o("XLMRobertaXLForMaskedLM"),NOo=o(" (XLM-RoBERTa-XL model)"),qOo=l(),u1=a("li"),Tbe=a("strong"),jOo=o("xlnet"),DOo=o(" \u2014 "),rQ=a("a"),GOo=o("XLNetLMHeadModel"),OOo=o(" (XLNet model)"),VOo=l(),p1=a("p"),XOo=o("The model is set in evaluation mode by default using "),Mbe=a("code"),zOo=o("model.eval()"),QOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=a("code"),WOo=o("model.train()"),UOo=l(),F(_1.$$.fragment),RZe=l(),Ed=a("h2"),b1=a("a"),Cbe=a("span"),F($x.$$.fragment),HOo=l(),wbe=a("span"),JOo=o("AutoModelForCausalLM"),PZe=l(),Io=a("div"),F(kx.$$.fragment),YOo=l(),Cd=a("p"),KOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),tQ=a("a"),ZOo=o("from_pretrained()"),eVo=o(" class method or the "),aQ=a("a"),oVo=o("from_config()"),rVo=o(` class
method.`),tVo=l(),Sx=a("p"),aVo=o("This class cannot be instantiated directly using "),Abe=a("code"),nVo=o("__init__()"),sVo=o(" (throws an error)."),lVo=l(),vt=a("div"),F(Rx.$$.fragment),iVo=l(),Lbe=a("p"),dVo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),cVo=l(),wd=a("p"),mVo=o(`Note:
Loading a model from its configuration file does `),ybe=a("strong"),fVo=o("not"),gVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nQ=a("a"),hVo=o("from_pretrained()"),uVo=o(" to load the model weights."),pVo=l(),F(v1.$$.fragment),_Vo=l(),oo=a("div"),F(Px.$$.fragment),bVo=l(),xbe=a("p"),vVo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),FVo=l(),Ka=a("p"),TVo=o("The model class to instantiate is selected based on the "),$be=a("code"),MVo=o("model_type"),EVo=o(` property of the config object (either
passed as an argument or loaded from `),kbe=a("code"),CVo=o("pretrained_model_name_or_path"),wVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=a("code"),AVo=o("pretrained_model_name_or_path"),LVo=o(":"),yVo=l(),Q=a("ul"),F1=a("li"),Rbe=a("strong"),xVo=o("bart"),$Vo=o(" \u2014 "),sQ=a("a"),kVo=o("BartForCausalLM"),SVo=o(" (BART model)"),RVo=l(),T1=a("li"),Pbe=a("strong"),PVo=o("bert"),BVo=o(" \u2014 "),lQ=a("a"),IVo=o("BertLMHeadModel"),NVo=o(" (BERT model)"),qVo=l(),M1=a("li"),Bbe=a("strong"),jVo=o("bert-generation"),DVo=o(" \u2014 "),iQ=a("a"),GVo=o("BertGenerationDecoder"),OVo=o(" (Bert Generation model)"),VVo=l(),E1=a("li"),Ibe=a("strong"),XVo=o("big_bird"),zVo=o(" \u2014 "),dQ=a("a"),QVo=o("BigBirdForCausalLM"),WVo=o(" (BigBird model)"),UVo=l(),C1=a("li"),Nbe=a("strong"),HVo=o("bigbird_pegasus"),JVo=o(" \u2014 "),cQ=a("a"),YVo=o("BigBirdPegasusForCausalLM"),KVo=o(" (BigBird-Pegasus model)"),ZVo=l(),w1=a("li"),qbe=a("strong"),eXo=o("blenderbot"),oXo=o(" \u2014 "),mQ=a("a"),rXo=o("BlenderbotForCausalLM"),tXo=o(" (Blenderbot model)"),aXo=l(),A1=a("li"),jbe=a("strong"),nXo=o("blenderbot-small"),sXo=o(" \u2014 "),fQ=a("a"),lXo=o("BlenderbotSmallForCausalLM"),iXo=o(" (BlenderbotSmall model)"),dXo=l(),L1=a("li"),Dbe=a("strong"),cXo=o("bloom"),mXo=o(" \u2014 "),gQ=a("a"),fXo=o("BloomForCausalLM"),gXo=o(" (BLOOM model)"),hXo=l(),y1=a("li"),Gbe=a("strong"),uXo=o("camembert"),pXo=o(" \u2014 "),hQ=a("a"),_Xo=o("CamembertForCausalLM"),bXo=o(" (CamemBERT model)"),vXo=l(),x1=a("li"),Obe=a("strong"),FXo=o("codegen"),TXo=o(" \u2014 "),uQ=a("a"),MXo=o("CodeGenForCausalLM"),EXo=o(" (CodeGen model)"),CXo=l(),$1=a("li"),Vbe=a("strong"),wXo=o("ctrl"),AXo=o(" \u2014 "),pQ=a("a"),LXo=o("CTRLLMHeadModel"),yXo=o(" (CTRL model)"),xXo=l(),k1=a("li"),Xbe=a("strong"),$Xo=o("data2vec-text"),kXo=o(" \u2014 "),_Q=a("a"),SXo=o("Data2VecTextForCausalLM"),RXo=o(" (Data2VecText model)"),PXo=l(),S1=a("li"),zbe=a("strong"),BXo=o("electra"),IXo=o(" \u2014 "),bQ=a("a"),NXo=o("ElectraForCausalLM"),qXo=o(" (ELECTRA model)"),jXo=l(),R1=a("li"),Qbe=a("strong"),DXo=o("ernie"),GXo=o(" \u2014 "),vQ=a("a"),OXo=o("ErnieForCausalLM"),VXo=o(" (ERNIE model)"),XXo=l(),P1=a("li"),Wbe=a("strong"),zXo=o("gpt2"),QXo=o(" \u2014 "),FQ=a("a"),WXo=o("GPT2LMHeadModel"),UXo=o(" (OpenAI GPT-2 model)"),HXo=l(),B1=a("li"),Ube=a("strong"),JXo=o("gpt_neo"),YXo=o(" \u2014 "),TQ=a("a"),KXo=o("GPTNeoForCausalLM"),ZXo=o(" (GPT Neo model)"),ezo=l(),I1=a("li"),Hbe=a("strong"),ozo=o("gpt_neox"),rzo=o(" \u2014 "),MQ=a("a"),tzo=o("GPTNeoXForCausalLM"),azo=o(" (GPT NeoX model)"),nzo=l(),N1=a("li"),Jbe=a("strong"),szo=o("gpt_neox_japanese"),lzo=o(" \u2014 "),EQ=a("a"),izo=o("GPTNeoXJapaneseForCausalLM"),dzo=o(" (GPT NeoX Japanese model)"),czo=l(),q1=a("li"),Ybe=a("strong"),mzo=o("gptj"),fzo=o(" \u2014 "),CQ=a("a"),gzo=o("GPTJForCausalLM"),hzo=o(" (GPT-J model)"),uzo=l(),j1=a("li"),Kbe=a("strong"),pzo=o("marian"),_zo=o(" \u2014 "),wQ=a("a"),bzo=o("MarianForCausalLM"),vzo=o(" (Marian model)"),Fzo=l(),D1=a("li"),Zbe=a("strong"),Tzo=o("mbart"),Mzo=o(" \u2014 "),AQ=a("a"),Ezo=o("MBartForCausalLM"),Czo=o(" (mBART model)"),wzo=l(),G1=a("li"),e1e=a("strong"),Azo=o("megatron-bert"),Lzo=o(" \u2014 "),LQ=a("a"),yzo=o("MegatronBertForCausalLM"),xzo=o(" (Megatron-BERT model)"),$zo=l(),O1=a("li"),o1e=a("strong"),kzo=o("mvp"),Szo=o(" \u2014 "),yQ=a("a"),Rzo=o("MvpForCausalLM"),Pzo=o(" (MVP model)"),Bzo=l(),V1=a("li"),r1e=a("strong"),Izo=o("openai-gpt"),Nzo=o(" \u2014 "),xQ=a("a"),qzo=o("OpenAIGPTLMHeadModel"),jzo=o(" (OpenAI GPT model)"),Dzo=l(),X1=a("li"),t1e=a("strong"),Gzo=o("opt"),Ozo=o(" \u2014 "),$Q=a("a"),Vzo=o("OPTForCausalLM"),Xzo=o(" (OPT model)"),zzo=l(),z1=a("li"),a1e=a("strong"),Qzo=o("pegasus"),Wzo=o(" \u2014 "),kQ=a("a"),Uzo=o("PegasusForCausalLM"),Hzo=o(" (Pegasus model)"),Jzo=l(),Q1=a("li"),n1e=a("strong"),Yzo=o("plbart"),Kzo=o(" \u2014 "),SQ=a("a"),Zzo=o("PLBartForCausalLM"),eQo=o(" (PLBart model)"),oQo=l(),W1=a("li"),s1e=a("strong"),rQo=o("prophetnet"),tQo=o(" \u2014 "),RQ=a("a"),aQo=o("ProphetNetForCausalLM"),nQo=o(" (ProphetNet model)"),sQo=l(),U1=a("li"),l1e=a("strong"),lQo=o("qdqbert"),iQo=o(" \u2014 "),PQ=a("a"),dQo=o("QDQBertLMHeadModel"),cQo=o(" (QDQBert model)"),mQo=l(),H1=a("li"),i1e=a("strong"),fQo=o("reformer"),gQo=o(" \u2014 "),BQ=a("a"),hQo=o("ReformerModelWithLMHead"),uQo=o(" (Reformer model)"),pQo=l(),J1=a("li"),d1e=a("strong"),_Qo=o("rembert"),bQo=o(" \u2014 "),IQ=a("a"),vQo=o("RemBertForCausalLM"),FQo=o(" (RemBERT model)"),TQo=l(),Y1=a("li"),c1e=a("strong"),MQo=o("roberta"),EQo=o(" \u2014 "),NQ=a("a"),CQo=o("RobertaForCausalLM"),wQo=o(" (RoBERTa model)"),AQo=l(),K1=a("li"),m1e=a("strong"),LQo=o("roformer"),yQo=o(" \u2014 "),qQ=a("a"),xQo=o("RoFormerForCausalLM"),$Qo=o(" (RoFormer model)"),kQo=l(),Z1=a("li"),f1e=a("strong"),SQo=o("speech_to_text_2"),RQo=o(" \u2014 "),jQ=a("a"),PQo=o("Speech2Text2ForCausalLM"),BQo=o(" (Speech2Text2 model)"),IQo=l(),ev=a("li"),g1e=a("strong"),NQo=o("transfo-xl"),qQo=o(" \u2014 "),DQ=a("a"),jQo=o("TransfoXLLMHeadModel"),DQo=o(" (Transformer-XL model)"),GQo=l(),ov=a("li"),h1e=a("strong"),OQo=o("trocr"),VQo=o(" \u2014 "),GQ=a("a"),XQo=o("TrOCRForCausalLM"),zQo=o(" (TrOCR model)"),QQo=l(),rv=a("li"),u1e=a("strong"),WQo=o("xglm"),UQo=o(" \u2014 "),OQ=a("a"),HQo=o("XGLMForCausalLM"),JQo=o(" (XGLM model)"),YQo=l(),tv=a("li"),p1e=a("strong"),KQo=o("xlm"),ZQo=o(" \u2014 "),VQ=a("a"),eWo=o("XLMWithLMHeadModel"),oWo=o(" (XLM model)"),rWo=l(),av=a("li"),_1e=a("strong"),tWo=o("xlm-prophetnet"),aWo=o(" \u2014 "),XQ=a("a"),nWo=o("XLMProphetNetForCausalLM"),sWo=o(" (XLM-ProphetNet model)"),lWo=l(),nv=a("li"),b1e=a("strong"),iWo=o("xlm-roberta"),dWo=o(" \u2014 "),zQ=a("a"),cWo=o("XLMRobertaForCausalLM"),mWo=o(" (XLM-RoBERTa model)"),fWo=l(),sv=a("li"),v1e=a("strong"),gWo=o("xlm-roberta-xl"),hWo=o(" \u2014 "),QQ=a("a"),uWo=o("XLMRobertaXLForCausalLM"),pWo=o(" (XLM-RoBERTa-XL model)"),_Wo=l(),lv=a("li"),F1e=a("strong"),bWo=o("xlnet"),vWo=o(" \u2014 "),WQ=a("a"),FWo=o("XLNetLMHeadModel"),TWo=o(" (XLNet model)"),MWo=l(),iv=a("p"),EWo=o("The model is set in evaluation mode by default using "),T1e=a("code"),CWo=o("model.eval()"),wWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M1e=a("code"),AWo=o("model.train()"),LWo=l(),F(dv.$$.fragment),BZe=l(),Ad=a("h2"),cv=a("a"),E1e=a("span"),F(Bx.$$.fragment),yWo=l(),C1e=a("span"),xWo=o("AutoModelForMaskedLM"),IZe=l(),No=a("div"),F(Ix.$$.fragment),$Wo=l(),Ld=a("p"),kWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),UQ=a("a"),SWo=o("from_pretrained()"),RWo=o(" class method or the "),HQ=a("a"),PWo=o("from_config()"),BWo=o(` class
method.`),IWo=l(),Nx=a("p"),NWo=o("This class cannot be instantiated directly using "),w1e=a("code"),qWo=o("__init__()"),jWo=o(" (throws an error)."),DWo=l(),Ft=a("div"),F(qx.$$.fragment),GWo=l(),A1e=a("p"),OWo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),VWo=l(),yd=a("p"),XWo=o(`Note:
Loading a model from its configuration file does `),L1e=a("strong"),zWo=o("not"),QWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JQ=a("a"),WWo=o("from_pretrained()"),UWo=o(" to load the model weights."),HWo=l(),F(mv.$$.fragment),JWo=l(),ro=a("div"),F(jx.$$.fragment),YWo=l(),y1e=a("p"),KWo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ZWo=l(),Za=a("p"),eUo=o("The model class to instantiate is selected based on the "),x1e=a("code"),oUo=o("model_type"),rUo=o(` property of the config object (either
passed as an argument or loaded from `),$1e=a("code"),tUo=o("pretrained_model_name_or_path"),aUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k1e=a("code"),nUo=o("pretrained_model_name_or_path"),sUo=o(":"),lUo=l(),H=a("ul"),fv=a("li"),S1e=a("strong"),iUo=o("albert"),dUo=o(" \u2014 "),YQ=a("a"),cUo=o("AlbertForMaskedLM"),mUo=o(" (ALBERT model)"),fUo=l(),gv=a("li"),R1e=a("strong"),gUo=o("bart"),hUo=o(" \u2014 "),KQ=a("a"),uUo=o("BartForConditionalGeneration"),pUo=o(" (BART model)"),_Uo=l(),hv=a("li"),P1e=a("strong"),bUo=o("bert"),vUo=o(" \u2014 "),ZQ=a("a"),FUo=o("BertForMaskedLM"),TUo=o(" (BERT model)"),MUo=l(),uv=a("li"),B1e=a("strong"),EUo=o("big_bird"),CUo=o(" \u2014 "),eW=a("a"),wUo=o("BigBirdForMaskedLM"),AUo=o(" (BigBird model)"),LUo=l(),pv=a("li"),I1e=a("strong"),yUo=o("camembert"),xUo=o(" \u2014 "),oW=a("a"),$Uo=o("CamembertForMaskedLM"),kUo=o(" (CamemBERT model)"),SUo=l(),_v=a("li"),N1e=a("strong"),RUo=o("convbert"),PUo=o(" \u2014 "),rW=a("a"),BUo=o("ConvBertForMaskedLM"),IUo=o(" (ConvBERT model)"),NUo=l(),bv=a("li"),q1e=a("strong"),qUo=o("data2vec-text"),jUo=o(" \u2014 "),tW=a("a"),DUo=o("Data2VecTextForMaskedLM"),GUo=o(" (Data2VecText model)"),OUo=l(),vv=a("li"),j1e=a("strong"),VUo=o("deberta"),XUo=o(" \u2014 "),aW=a("a"),zUo=o("DebertaForMaskedLM"),QUo=o(" (DeBERTa model)"),WUo=l(),Fv=a("li"),D1e=a("strong"),UUo=o("deberta-v2"),HUo=o(" \u2014 "),nW=a("a"),JUo=o("DebertaV2ForMaskedLM"),YUo=o(" (DeBERTa-v2 model)"),KUo=l(),Tv=a("li"),G1e=a("strong"),ZUo=o("distilbert"),eHo=o(" \u2014 "),sW=a("a"),oHo=o("DistilBertForMaskedLM"),rHo=o(" (DistilBERT model)"),tHo=l(),Mv=a("li"),O1e=a("strong"),aHo=o("electra"),nHo=o(" \u2014 "),lW=a("a"),sHo=o("ElectraForMaskedLM"),lHo=o(" (ELECTRA model)"),iHo=l(),Ev=a("li"),V1e=a("strong"),dHo=o("ernie"),cHo=o(" \u2014 "),iW=a("a"),mHo=o("ErnieForMaskedLM"),fHo=o(" (ERNIE model)"),gHo=l(),Cv=a("li"),X1e=a("strong"),hHo=o("flaubert"),uHo=o(" \u2014 "),dW=a("a"),pHo=o("FlaubertWithLMHeadModel"),_Ho=o(" (FlauBERT model)"),bHo=l(),wv=a("li"),z1e=a("strong"),vHo=o("fnet"),FHo=o(" \u2014 "),cW=a("a"),THo=o("FNetForMaskedLM"),MHo=o(" (FNet model)"),EHo=l(),Av=a("li"),Q1e=a("strong"),CHo=o("funnel"),wHo=o(" \u2014 "),mW=a("a"),AHo=o("FunnelForMaskedLM"),LHo=o(" (Funnel Transformer model)"),yHo=l(),Lv=a("li"),W1e=a("strong"),xHo=o("ibert"),$Ho=o(" \u2014 "),fW=a("a"),kHo=o("IBertForMaskedLM"),SHo=o(" (I-BERT model)"),RHo=l(),yv=a("li"),U1e=a("strong"),PHo=o("layoutlm"),BHo=o(" \u2014 "),gW=a("a"),IHo=o("LayoutLMForMaskedLM"),NHo=o(" (LayoutLM model)"),qHo=l(),xv=a("li"),H1e=a("strong"),jHo=o("longformer"),DHo=o(" \u2014 "),hW=a("a"),GHo=o("LongformerForMaskedLM"),OHo=o(" (Longformer model)"),VHo=l(),$v=a("li"),J1e=a("strong"),XHo=o("luke"),zHo=o(" \u2014 "),uW=a("a"),QHo=o("LukeForMaskedLM"),WHo=o(" (LUKE model)"),UHo=l(),kv=a("li"),Y1e=a("strong"),HHo=o("mbart"),JHo=o(" \u2014 "),pW=a("a"),YHo=o("MBartForConditionalGeneration"),KHo=o(" (mBART model)"),ZHo=l(),Sv=a("li"),K1e=a("strong"),eJo=o("megatron-bert"),oJo=o(" \u2014 "),_W=a("a"),rJo=o("MegatronBertForMaskedLM"),tJo=o(" (Megatron-BERT model)"),aJo=l(),Rv=a("li"),Z1e=a("strong"),nJo=o("mobilebert"),sJo=o(" \u2014 "),bW=a("a"),lJo=o("MobileBertForMaskedLM"),iJo=o(" (MobileBERT model)"),dJo=l(),Pv=a("li"),eve=a("strong"),cJo=o("mpnet"),mJo=o(" \u2014 "),vW=a("a"),fJo=o("MPNetForMaskedLM"),gJo=o(" (MPNet model)"),hJo=l(),Bv=a("li"),ove=a("strong"),uJo=o("mvp"),pJo=o(" \u2014 "),FW=a("a"),_Jo=o("MvpForConditionalGeneration"),bJo=o(" (MVP model)"),vJo=l(),Iv=a("li"),rve=a("strong"),FJo=o("nezha"),TJo=o(" \u2014 "),TW=a("a"),MJo=o("NezhaForMaskedLM"),EJo=o(" (Nezha model)"),CJo=l(),Nv=a("li"),tve=a("strong"),wJo=o("nystromformer"),AJo=o(" \u2014 "),MW=a("a"),LJo=o("NystromformerForMaskedLM"),yJo=o(" (Nystr\xF6mformer model)"),xJo=l(),qv=a("li"),ave=a("strong"),$Jo=o("perceiver"),kJo=o(" \u2014 "),EW=a("a"),SJo=o("PerceiverForMaskedLM"),RJo=o(" (Perceiver model)"),PJo=l(),jv=a("li"),nve=a("strong"),BJo=o("qdqbert"),IJo=o(" \u2014 "),CW=a("a"),NJo=o("QDQBertForMaskedLM"),qJo=o(" (QDQBert model)"),jJo=l(),Dv=a("li"),sve=a("strong"),DJo=o("reformer"),GJo=o(" \u2014 "),wW=a("a"),OJo=o("ReformerForMaskedLM"),VJo=o(" (Reformer model)"),XJo=l(),Gv=a("li"),lve=a("strong"),zJo=o("rembert"),QJo=o(" \u2014 "),AW=a("a"),WJo=o("RemBertForMaskedLM"),UJo=o(" (RemBERT model)"),HJo=l(),Ov=a("li"),ive=a("strong"),JJo=o("roberta"),YJo=o(" \u2014 "),LW=a("a"),KJo=o("RobertaForMaskedLM"),ZJo=o(" (RoBERTa model)"),eYo=l(),Vv=a("li"),dve=a("strong"),oYo=o("roformer"),rYo=o(" \u2014 "),yW=a("a"),tYo=o("RoFormerForMaskedLM"),aYo=o(" (RoFormer model)"),nYo=l(),Xv=a("li"),cve=a("strong"),sYo=o("squeezebert"),lYo=o(" \u2014 "),xW=a("a"),iYo=o("SqueezeBertForMaskedLM"),dYo=o(" (SqueezeBERT model)"),cYo=l(),zv=a("li"),mve=a("strong"),mYo=o("tapas"),fYo=o(" \u2014 "),$W=a("a"),gYo=o("TapasForMaskedLM"),hYo=o(" (TAPAS model)"),uYo=l(),Qv=a("li"),fve=a("strong"),pYo=o("wav2vec2"),_Yo=o(" \u2014 "),gve=a("code"),bYo=o("Wav2Vec2ForMaskedLM"),vYo=o(" (Wav2Vec2 model)"),FYo=l(),Wv=a("li"),hve=a("strong"),TYo=o("xlm"),MYo=o(" \u2014 "),kW=a("a"),EYo=o("XLMWithLMHeadModel"),CYo=o(" (XLM model)"),wYo=l(),Uv=a("li"),uve=a("strong"),AYo=o("xlm-roberta"),LYo=o(" \u2014 "),SW=a("a"),yYo=o("XLMRobertaForMaskedLM"),xYo=o(" (XLM-RoBERTa model)"),$Yo=l(),Hv=a("li"),pve=a("strong"),kYo=o("xlm-roberta-xl"),SYo=o(" \u2014 "),RW=a("a"),RYo=o("XLMRobertaXLForMaskedLM"),PYo=o(" (XLM-RoBERTa-XL model)"),BYo=l(),Jv=a("li"),_ve=a("strong"),IYo=o("yoso"),NYo=o(" \u2014 "),PW=a("a"),qYo=o("YosoForMaskedLM"),jYo=o(" (YOSO model)"),DYo=l(),Yv=a("p"),GYo=o("The model is set in evaluation mode by default using "),bve=a("code"),OYo=o("model.eval()"),VYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vve=a("code"),XYo=o("model.train()"),zYo=l(),F(Kv.$$.fragment),NZe=l(),xd=a("h2"),Zv=a("a"),Fve=a("span"),F(Dx.$$.fragment),QYo=l(),Tve=a("span"),WYo=o("AutoModelForSeq2SeqLM"),qZe=l(),qo=a("div"),F(Gx.$$.fragment),UYo=l(),$d=a("p"),HYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),BW=a("a"),JYo=o("from_pretrained()"),YYo=o(" class method or the "),IW=a("a"),KYo=o("from_config()"),ZYo=o(` class
method.`),eKo=l(),Ox=a("p"),oKo=o("This class cannot be instantiated directly using "),Mve=a("code"),rKo=o("__init__()"),tKo=o(" (throws an error)."),aKo=l(),Tt=a("div"),F(Vx.$$.fragment),nKo=l(),Eve=a("p"),sKo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lKo=l(),kd=a("p"),iKo=o(`Note:
Loading a model from its configuration file does `),Cve=a("strong"),dKo=o("not"),cKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NW=a("a"),mKo=o("from_pretrained()"),fKo=o(" to load the model weights."),gKo=l(),F(eF.$$.fragment),hKo=l(),to=a("div"),F(Xx.$$.fragment),uKo=l(),wve=a("p"),pKo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),_Ko=l(),en=a("p"),bKo=o("The model class to instantiate is selected based on the "),Ave=a("code"),vKo=o("model_type"),FKo=o(` property of the config object (either
passed as an argument or loaded from `),Lve=a("code"),TKo=o("pretrained_model_name_or_path"),MKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yve=a("code"),EKo=o("pretrained_model_name_or_path"),CKo=o(":"),wKo=l(),fe=a("ul"),oF=a("li"),xve=a("strong"),AKo=o("bart"),LKo=o(" \u2014 "),qW=a("a"),yKo=o("BartForConditionalGeneration"),xKo=o(" (BART model)"),$Ko=l(),rF=a("li"),$ve=a("strong"),kKo=o("bigbird_pegasus"),SKo=o(" \u2014 "),jW=a("a"),RKo=o("BigBirdPegasusForConditionalGeneration"),PKo=o(" (BigBird-Pegasus model)"),BKo=l(),tF=a("li"),kve=a("strong"),IKo=o("blenderbot"),NKo=o(" \u2014 "),DW=a("a"),qKo=o("BlenderbotForConditionalGeneration"),jKo=o(" (Blenderbot model)"),DKo=l(),aF=a("li"),Sve=a("strong"),GKo=o("blenderbot-small"),OKo=o(" \u2014 "),GW=a("a"),VKo=o("BlenderbotSmallForConditionalGeneration"),XKo=o(" (BlenderbotSmall model)"),zKo=l(),nF=a("li"),Rve=a("strong"),QKo=o("encoder-decoder"),WKo=o(" \u2014 "),OW=a("a"),UKo=o("EncoderDecoderModel"),HKo=o(" (Encoder decoder model)"),JKo=l(),sF=a("li"),Pve=a("strong"),YKo=o("fsmt"),KKo=o(" \u2014 "),VW=a("a"),ZKo=o("FSMTForConditionalGeneration"),eZo=o(" (FairSeq Machine-Translation model)"),oZo=l(),lF=a("li"),Bve=a("strong"),rZo=o("led"),tZo=o(" \u2014 "),XW=a("a"),aZo=o("LEDForConditionalGeneration"),nZo=o(" (LED model)"),sZo=l(),iF=a("li"),Ive=a("strong"),lZo=o("longt5"),iZo=o(" \u2014 "),zW=a("a"),dZo=o("LongT5ForConditionalGeneration"),cZo=o(" (LongT5 model)"),mZo=l(),dF=a("li"),Nve=a("strong"),fZo=o("m2m_100"),gZo=o(" \u2014 "),QW=a("a"),hZo=o("M2M100ForConditionalGeneration"),uZo=o(" (M2M100 model)"),pZo=l(),cF=a("li"),qve=a("strong"),_Zo=o("marian"),bZo=o(" \u2014 "),WW=a("a"),vZo=o("MarianMTModel"),FZo=o(" (Marian model)"),TZo=l(),mF=a("li"),jve=a("strong"),MZo=o("mbart"),EZo=o(" \u2014 "),UW=a("a"),CZo=o("MBartForConditionalGeneration"),wZo=o(" (mBART model)"),AZo=l(),fF=a("li"),Dve=a("strong"),LZo=o("mt5"),yZo=o(" \u2014 "),HW=a("a"),xZo=o("MT5ForConditionalGeneration"),$Zo=o(" (MT5 model)"),kZo=l(),gF=a("li"),Gve=a("strong"),SZo=o("mvp"),RZo=o(" \u2014 "),JW=a("a"),PZo=o("MvpForConditionalGeneration"),BZo=o(" (MVP model)"),IZo=l(),hF=a("li"),Ove=a("strong"),NZo=o("nllb"),qZo=o(" \u2014 "),YW=a("a"),jZo=o("M2M100ForConditionalGeneration"),DZo=o(" (NLLB model)"),GZo=l(),uF=a("li"),Vve=a("strong"),OZo=o("pegasus"),VZo=o(" \u2014 "),KW=a("a"),XZo=o("PegasusForConditionalGeneration"),zZo=o(" (Pegasus model)"),QZo=l(),pF=a("li"),Xve=a("strong"),WZo=o("pegasus_x"),UZo=o(" \u2014 "),ZW=a("a"),HZo=o("PegasusXForConditionalGeneration"),JZo=o(" (PEGASUS-X model)"),YZo=l(),_F=a("li"),zve=a("strong"),KZo=o("plbart"),ZZo=o(" \u2014 "),eU=a("a"),eer=o("PLBartForConditionalGeneration"),oer=o(" (PLBart model)"),rer=l(),bF=a("li"),Qve=a("strong"),ter=o("prophetnet"),aer=o(" \u2014 "),oU=a("a"),ner=o("ProphetNetForConditionalGeneration"),ser=o(" (ProphetNet model)"),ler=l(),vF=a("li"),Wve=a("strong"),ier=o("t5"),der=o(" \u2014 "),rU=a("a"),cer=o("T5ForConditionalGeneration"),mer=o(" (T5 model)"),fer=l(),FF=a("li"),Uve=a("strong"),ger=o("xlm-prophetnet"),her=o(" \u2014 "),tU=a("a"),uer=o("XLMProphetNetForConditionalGeneration"),per=o(" (XLM-ProphetNet model)"),_er=l(),TF=a("p"),ber=o("The model is set in evaluation mode by default using "),Hve=a("code"),ver=o("model.eval()"),Fer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jve=a("code"),Ter=o("model.train()"),Mer=l(),F(MF.$$.fragment),jZe=l(),Sd=a("h2"),EF=a("a"),Yve=a("span"),F(zx.$$.fragment),Eer=l(),Kve=a("span"),Cer=o("AutoModelForSequenceClassification"),DZe=l(),jo=a("div"),F(Qx.$$.fragment),wer=l(),Rd=a("p"),Aer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),aU=a("a"),Ler=o("from_pretrained()"),yer=o(" class method or the "),nU=a("a"),xer=o("from_config()"),$er=o(` class
method.`),ker=l(),Wx=a("p"),Ser=o("This class cannot be instantiated directly using "),Zve=a("code"),Rer=o("__init__()"),Per=o(" (throws an error)."),Ber=l(),Mt=a("div"),F(Ux.$$.fragment),Ier=l(),eFe=a("p"),Ner=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),qer=l(),Pd=a("p"),jer=o(`Note:
Loading a model from its configuration file does `),oFe=a("strong"),Der=o("not"),Ger=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sU=a("a"),Oer=o("from_pretrained()"),Ver=o(" to load the model weights."),Xer=l(),F(CF.$$.fragment),zer=l(),ao=a("div"),F(Hx.$$.fragment),Qer=l(),rFe=a("p"),Wer=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Uer=l(),on=a("p"),Her=o("The model class to instantiate is selected based on the "),tFe=a("code"),Jer=o("model_type"),Yer=o(` property of the config object (either
passed as an argument or loaded from `),aFe=a("code"),Ker=o("pretrained_model_name_or_path"),Zer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nFe=a("code"),eor=o("pretrained_model_name_or_path"),oor=o(":"),ror=l(),q=a("ul"),wF=a("li"),sFe=a("strong"),tor=o("albert"),aor=o(" \u2014 "),lU=a("a"),nor=o("AlbertForSequenceClassification"),sor=o(" (ALBERT model)"),lor=l(),AF=a("li"),lFe=a("strong"),ior=o("bart"),dor=o(" \u2014 "),iU=a("a"),cor=o("BartForSequenceClassification"),mor=o(" (BART model)"),gor=l(),LF=a("li"),iFe=a("strong"),hor=o("bert"),uor=o(" \u2014 "),dU=a("a"),por=o("BertForSequenceClassification"),_or=o(" (BERT model)"),bor=l(),yF=a("li"),dFe=a("strong"),vor=o("big_bird"),For=o(" \u2014 "),cU=a("a"),Tor=o("BigBirdForSequenceClassification"),Mor=o(" (BigBird model)"),Eor=l(),xF=a("li"),cFe=a("strong"),Cor=o("bigbird_pegasus"),wor=o(" \u2014 "),mU=a("a"),Aor=o("BigBirdPegasusForSequenceClassification"),Lor=o(" (BigBird-Pegasus model)"),yor=l(),$F=a("li"),mFe=a("strong"),xor=o("bloom"),$or=o(" \u2014 "),fU=a("a"),kor=o("BloomForSequenceClassification"),Sor=o(" (BLOOM model)"),Ror=l(),kF=a("li"),fFe=a("strong"),Por=o("camembert"),Bor=o(" \u2014 "),gU=a("a"),Ior=o("CamembertForSequenceClassification"),Nor=o(" (CamemBERT model)"),qor=l(),SF=a("li"),gFe=a("strong"),jor=o("canine"),Dor=o(" \u2014 "),hU=a("a"),Gor=o("CanineForSequenceClassification"),Oor=o(" (CANINE model)"),Vor=l(),RF=a("li"),hFe=a("strong"),Xor=o("convbert"),zor=o(" \u2014 "),uU=a("a"),Qor=o("ConvBertForSequenceClassification"),Wor=o(" (ConvBERT model)"),Uor=l(),PF=a("li"),uFe=a("strong"),Hor=o("ctrl"),Jor=o(" \u2014 "),pU=a("a"),Yor=o("CTRLForSequenceClassification"),Kor=o(" (CTRL model)"),Zor=l(),BF=a("li"),pFe=a("strong"),err=o("data2vec-text"),orr=o(" \u2014 "),_U=a("a"),rrr=o("Data2VecTextForSequenceClassification"),trr=o(" (Data2VecText model)"),arr=l(),IF=a("li"),_Fe=a("strong"),nrr=o("deberta"),srr=o(" \u2014 "),bU=a("a"),lrr=o("DebertaForSequenceClassification"),irr=o(" (DeBERTa model)"),drr=l(),NF=a("li"),bFe=a("strong"),crr=o("deberta-v2"),mrr=o(" \u2014 "),vU=a("a"),frr=o("DebertaV2ForSequenceClassification"),grr=o(" (DeBERTa-v2 model)"),hrr=l(),qF=a("li"),vFe=a("strong"),urr=o("distilbert"),prr=o(" \u2014 "),FU=a("a"),_rr=o("DistilBertForSequenceClassification"),brr=o(" (DistilBERT model)"),vrr=l(),jF=a("li"),FFe=a("strong"),Frr=o("electra"),Trr=o(" \u2014 "),TU=a("a"),Mrr=o("ElectraForSequenceClassification"),Err=o(" (ELECTRA model)"),Crr=l(),DF=a("li"),TFe=a("strong"),wrr=o("ernie"),Arr=o(" \u2014 "),MU=a("a"),Lrr=o("ErnieForSequenceClassification"),yrr=o(" (ERNIE model)"),xrr=l(),GF=a("li"),MFe=a("strong"),$rr=o("flaubert"),krr=o(" \u2014 "),EU=a("a"),Srr=o("FlaubertForSequenceClassification"),Rrr=o(" (FlauBERT model)"),Prr=l(),OF=a("li"),EFe=a("strong"),Brr=o("fnet"),Irr=o(" \u2014 "),CU=a("a"),Nrr=o("FNetForSequenceClassification"),qrr=o(" (FNet model)"),jrr=l(),VF=a("li"),CFe=a("strong"),Drr=o("funnel"),Grr=o(" \u2014 "),wU=a("a"),Orr=o("FunnelForSequenceClassification"),Vrr=o(" (Funnel Transformer model)"),Xrr=l(),XF=a("li"),wFe=a("strong"),zrr=o("gpt2"),Qrr=o(" \u2014 "),AU=a("a"),Wrr=o("GPT2ForSequenceClassification"),Urr=o(" (OpenAI GPT-2 model)"),Hrr=l(),zF=a("li"),AFe=a("strong"),Jrr=o("gpt_neo"),Yrr=o(" \u2014 "),LU=a("a"),Krr=o("GPTNeoForSequenceClassification"),Zrr=o(" (GPT Neo model)"),etr=l(),QF=a("li"),LFe=a("strong"),otr=o("gptj"),rtr=o(" \u2014 "),yU=a("a"),ttr=o("GPTJForSequenceClassification"),atr=o(" (GPT-J model)"),ntr=l(),WF=a("li"),yFe=a("strong"),str=o("ibert"),ltr=o(" \u2014 "),xU=a("a"),itr=o("IBertForSequenceClassification"),dtr=o(" (I-BERT model)"),ctr=l(),UF=a("li"),xFe=a("strong"),mtr=o("layoutlm"),ftr=o(" \u2014 "),$U=a("a"),gtr=o("LayoutLMForSequenceClassification"),htr=o(" (LayoutLM model)"),utr=l(),HF=a("li"),$Fe=a("strong"),ptr=o("layoutlmv2"),_tr=o(" \u2014 "),kU=a("a"),btr=o("LayoutLMv2ForSequenceClassification"),vtr=o(" (LayoutLMv2 model)"),Ftr=l(),JF=a("li"),kFe=a("strong"),Ttr=o("layoutlmv3"),Mtr=o(" \u2014 "),SU=a("a"),Etr=o("LayoutLMv3ForSequenceClassification"),Ctr=o(" (LayoutLMv3 model)"),wtr=l(),YF=a("li"),SFe=a("strong"),Atr=o("led"),Ltr=o(" \u2014 "),RU=a("a"),ytr=o("LEDForSequenceClassification"),xtr=o(" (LED model)"),$tr=l(),KF=a("li"),RFe=a("strong"),ktr=o("longformer"),Str=o(" \u2014 "),PU=a("a"),Rtr=o("LongformerForSequenceClassification"),Ptr=o(" (Longformer model)"),Btr=l(),ZF=a("li"),PFe=a("strong"),Itr=o("luke"),Ntr=o(" \u2014 "),BU=a("a"),qtr=o("LukeForSequenceClassification"),jtr=o(" (LUKE model)"),Dtr=l(),eT=a("li"),BFe=a("strong"),Gtr=o("markuplm"),Otr=o(" \u2014 "),IU=a("a"),Vtr=o("MarkupLMForSequenceClassification"),Xtr=o(" (MarkupLM model)"),ztr=l(),oT=a("li"),IFe=a("strong"),Qtr=o("mbart"),Wtr=o(" \u2014 "),NU=a("a"),Utr=o("MBartForSequenceClassification"),Htr=o(" (mBART model)"),Jtr=l(),rT=a("li"),NFe=a("strong"),Ytr=o("megatron-bert"),Ktr=o(" \u2014 "),qU=a("a"),Ztr=o("MegatronBertForSequenceClassification"),ear=o(" (Megatron-BERT model)"),oar=l(),tT=a("li"),qFe=a("strong"),rar=o("mobilebert"),tar=o(" \u2014 "),jU=a("a"),aar=o("MobileBertForSequenceClassification"),nar=o(" (MobileBERT model)"),sar=l(),aT=a("li"),jFe=a("strong"),lar=o("mpnet"),iar=o(" \u2014 "),DU=a("a"),dar=o("MPNetForSequenceClassification"),car=o(" (MPNet model)"),mar=l(),nT=a("li"),DFe=a("strong"),far=o("mvp"),gar=o(" \u2014 "),GU=a("a"),har=o("MvpForSequenceClassification"),uar=o(" (MVP model)"),par=l(),sT=a("li"),GFe=a("strong"),_ar=o("nezha"),bar=o(" \u2014 "),OU=a("a"),Far=o("NezhaForSequenceClassification"),Tar=o(" (Nezha model)"),Mar=l(),lT=a("li"),OFe=a("strong"),Ear=o("nystromformer"),Car=o(" \u2014 "),VU=a("a"),war=o("NystromformerForSequenceClassification"),Aar=o(" (Nystr\xF6mformer model)"),Lar=l(),iT=a("li"),VFe=a("strong"),yar=o("openai-gpt"),xar=o(" \u2014 "),XU=a("a"),$ar=o("OpenAIGPTForSequenceClassification"),kar=o(" (OpenAI GPT model)"),Sar=l(),dT=a("li"),XFe=a("strong"),Rar=o("opt"),Par=o(" \u2014 "),zU=a("a"),Bar=o("OPTForSequenceClassification"),Iar=o(" (OPT model)"),Nar=l(),cT=a("li"),zFe=a("strong"),qar=o("perceiver"),jar=o(" \u2014 "),QU=a("a"),Dar=o("PerceiverForSequenceClassification"),Gar=o(" (Perceiver model)"),Oar=l(),mT=a("li"),QFe=a("strong"),Var=o("plbart"),Xar=o(" \u2014 "),WU=a("a"),zar=o("PLBartForSequenceClassification"),Qar=o(" (PLBart model)"),War=l(),fT=a("li"),WFe=a("strong"),Uar=o("qdqbert"),Har=o(" \u2014 "),UU=a("a"),Jar=o("QDQBertForSequenceClassification"),Yar=o(" (QDQBert model)"),Kar=l(),gT=a("li"),UFe=a("strong"),Zar=o("reformer"),enr=o(" \u2014 "),HU=a("a"),onr=o("ReformerForSequenceClassification"),rnr=o(" (Reformer model)"),tnr=l(),hT=a("li"),HFe=a("strong"),anr=o("rembert"),nnr=o(" \u2014 "),JU=a("a"),snr=o("RemBertForSequenceClassification"),lnr=o(" (RemBERT model)"),inr=l(),uT=a("li"),JFe=a("strong"),dnr=o("roberta"),cnr=o(" \u2014 "),YU=a("a"),mnr=o("RobertaForSequenceClassification"),fnr=o(" (RoBERTa model)"),gnr=l(),pT=a("li"),YFe=a("strong"),hnr=o("roformer"),unr=o(" \u2014 "),KU=a("a"),pnr=o("RoFormerForSequenceClassification"),_nr=o(" (RoFormer model)"),bnr=l(),_T=a("li"),KFe=a("strong"),vnr=o("squeezebert"),Fnr=o(" \u2014 "),ZU=a("a"),Tnr=o("SqueezeBertForSequenceClassification"),Mnr=o(" (SqueezeBERT model)"),Enr=l(),bT=a("li"),ZFe=a("strong"),Cnr=o("tapas"),wnr=o(" \u2014 "),eH=a("a"),Anr=o("TapasForSequenceClassification"),Lnr=o(" (TAPAS model)"),ynr=l(),vT=a("li"),eTe=a("strong"),xnr=o("transfo-xl"),$nr=o(" \u2014 "),oH=a("a"),knr=o("TransfoXLForSequenceClassification"),Snr=o(" (Transformer-XL model)"),Rnr=l(),FT=a("li"),oTe=a("strong"),Pnr=o("xlm"),Bnr=o(" \u2014 "),rH=a("a"),Inr=o("XLMForSequenceClassification"),Nnr=o(" (XLM model)"),qnr=l(),TT=a("li"),rTe=a("strong"),jnr=o("xlm-roberta"),Dnr=o(" \u2014 "),tH=a("a"),Gnr=o("XLMRobertaForSequenceClassification"),Onr=o(" (XLM-RoBERTa model)"),Vnr=l(),MT=a("li"),tTe=a("strong"),Xnr=o("xlm-roberta-xl"),znr=o(" \u2014 "),aH=a("a"),Qnr=o("XLMRobertaXLForSequenceClassification"),Wnr=o(" (XLM-RoBERTa-XL model)"),Unr=l(),ET=a("li"),aTe=a("strong"),Hnr=o("xlnet"),Jnr=o(" \u2014 "),nH=a("a"),Ynr=o("XLNetForSequenceClassification"),Knr=o(" (XLNet model)"),Znr=l(),CT=a("li"),nTe=a("strong"),esr=o("yoso"),osr=o(" \u2014 "),sH=a("a"),rsr=o("YosoForSequenceClassification"),tsr=o(" (YOSO model)"),asr=l(),wT=a("p"),nsr=o("The model is set in evaluation mode by default using "),sTe=a("code"),ssr=o("model.eval()"),lsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lTe=a("code"),isr=o("model.train()"),dsr=l(),F(AT.$$.fragment),GZe=l(),Bd=a("h2"),LT=a("a"),iTe=a("span"),F(Jx.$$.fragment),csr=l(),dTe=a("span"),msr=o("AutoModelForMultipleChoice"),OZe=l(),Do=a("div"),F(Yx.$$.fragment),fsr=l(),Id=a("p"),gsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lH=a("a"),hsr=o("from_pretrained()"),usr=o(" class method or the "),iH=a("a"),psr=o("from_config()"),_sr=o(` class
method.`),bsr=l(),Kx=a("p"),vsr=o("This class cannot be instantiated directly using "),cTe=a("code"),Fsr=o("__init__()"),Tsr=o(" (throws an error)."),Msr=l(),Et=a("div"),F(Zx.$$.fragment),Esr=l(),mTe=a("p"),Csr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wsr=l(),Nd=a("p"),Asr=o(`Note:
Loading a model from its configuration file does `),fTe=a("strong"),Lsr=o("not"),ysr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dH=a("a"),xsr=o("from_pretrained()"),$sr=o(" to load the model weights."),ksr=l(),F(yT.$$.fragment),Ssr=l(),no=a("div"),F(e$.$$.fragment),Rsr=l(),gTe=a("p"),Psr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Bsr=l(),rn=a("p"),Isr=o("The model class to instantiate is selected based on the "),hTe=a("code"),Nsr=o("model_type"),qsr=o(` property of the config object (either
passed as an argument or loaded from `),uTe=a("code"),jsr=o("pretrained_model_name_or_path"),Dsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=a("code"),Gsr=o("pretrained_model_name_or_path"),Osr=o(":"),Vsr=l(),Z=a("ul"),xT=a("li"),_Te=a("strong"),Xsr=o("albert"),zsr=o(" \u2014 "),cH=a("a"),Qsr=o("AlbertForMultipleChoice"),Wsr=o(" (ALBERT model)"),Usr=l(),$T=a("li"),bTe=a("strong"),Hsr=o("bert"),Jsr=o(" \u2014 "),mH=a("a"),Ysr=o("BertForMultipleChoice"),Ksr=o(" (BERT model)"),Zsr=l(),kT=a("li"),vTe=a("strong"),elr=o("big_bird"),olr=o(" \u2014 "),fH=a("a"),rlr=o("BigBirdForMultipleChoice"),tlr=o(" (BigBird model)"),alr=l(),ST=a("li"),FTe=a("strong"),nlr=o("camembert"),slr=o(" \u2014 "),gH=a("a"),llr=o("CamembertForMultipleChoice"),ilr=o(" (CamemBERT model)"),dlr=l(),RT=a("li"),TTe=a("strong"),clr=o("canine"),mlr=o(" \u2014 "),hH=a("a"),flr=o("CanineForMultipleChoice"),glr=o(" (CANINE model)"),hlr=l(),PT=a("li"),MTe=a("strong"),ulr=o("convbert"),plr=o(" \u2014 "),uH=a("a"),_lr=o("ConvBertForMultipleChoice"),blr=o(" (ConvBERT model)"),vlr=l(),BT=a("li"),ETe=a("strong"),Flr=o("data2vec-text"),Tlr=o(" \u2014 "),pH=a("a"),Mlr=o("Data2VecTextForMultipleChoice"),Elr=o(" (Data2VecText model)"),Clr=l(),IT=a("li"),CTe=a("strong"),wlr=o("deberta-v2"),Alr=o(" \u2014 "),_H=a("a"),Llr=o("DebertaV2ForMultipleChoice"),ylr=o(" (DeBERTa-v2 model)"),xlr=l(),NT=a("li"),wTe=a("strong"),$lr=o("distilbert"),klr=o(" \u2014 "),bH=a("a"),Slr=o("DistilBertForMultipleChoice"),Rlr=o(" (DistilBERT model)"),Plr=l(),qT=a("li"),ATe=a("strong"),Blr=o("electra"),Ilr=o(" \u2014 "),vH=a("a"),Nlr=o("ElectraForMultipleChoice"),qlr=o(" (ELECTRA model)"),jlr=l(),jT=a("li"),LTe=a("strong"),Dlr=o("ernie"),Glr=o(" \u2014 "),FH=a("a"),Olr=o("ErnieForMultipleChoice"),Vlr=o(" (ERNIE model)"),Xlr=l(),DT=a("li"),yTe=a("strong"),zlr=o("flaubert"),Qlr=o(" \u2014 "),TH=a("a"),Wlr=o("FlaubertForMultipleChoice"),Ulr=o(" (FlauBERT model)"),Hlr=l(),GT=a("li"),xTe=a("strong"),Jlr=o("fnet"),Ylr=o(" \u2014 "),MH=a("a"),Klr=o("FNetForMultipleChoice"),Zlr=o(" (FNet model)"),eir=l(),OT=a("li"),$Te=a("strong"),oir=o("funnel"),rir=o(" \u2014 "),EH=a("a"),tir=o("FunnelForMultipleChoice"),air=o(" (Funnel Transformer model)"),nir=l(),VT=a("li"),kTe=a("strong"),sir=o("ibert"),lir=o(" \u2014 "),CH=a("a"),iir=o("IBertForMultipleChoice"),dir=o(" (I-BERT model)"),cir=l(),XT=a("li"),STe=a("strong"),mir=o("longformer"),fir=o(" \u2014 "),wH=a("a"),gir=o("LongformerForMultipleChoice"),hir=o(" (Longformer model)"),uir=l(),zT=a("li"),RTe=a("strong"),pir=o("luke"),_ir=o(" \u2014 "),AH=a("a"),bir=o("LukeForMultipleChoice"),vir=o(" (LUKE model)"),Fir=l(),QT=a("li"),PTe=a("strong"),Tir=o("megatron-bert"),Mir=o(" \u2014 "),LH=a("a"),Eir=o("MegatronBertForMultipleChoice"),Cir=o(" (Megatron-BERT model)"),wir=l(),WT=a("li"),BTe=a("strong"),Air=o("mobilebert"),Lir=o(" \u2014 "),yH=a("a"),yir=o("MobileBertForMultipleChoice"),xir=o(" (MobileBERT model)"),$ir=l(),UT=a("li"),ITe=a("strong"),kir=o("mpnet"),Sir=o(" \u2014 "),xH=a("a"),Rir=o("MPNetForMultipleChoice"),Pir=o(" (MPNet model)"),Bir=l(),HT=a("li"),NTe=a("strong"),Iir=o("nezha"),Nir=o(" \u2014 "),$H=a("a"),qir=o("NezhaForMultipleChoice"),jir=o(" (Nezha model)"),Dir=l(),JT=a("li"),qTe=a("strong"),Gir=o("nystromformer"),Oir=o(" \u2014 "),kH=a("a"),Vir=o("NystromformerForMultipleChoice"),Xir=o(" (Nystr\xF6mformer model)"),zir=l(),YT=a("li"),jTe=a("strong"),Qir=o("qdqbert"),Wir=o(" \u2014 "),SH=a("a"),Uir=o("QDQBertForMultipleChoice"),Hir=o(" (QDQBert model)"),Jir=l(),KT=a("li"),DTe=a("strong"),Yir=o("rembert"),Kir=o(" \u2014 "),RH=a("a"),Zir=o("RemBertForMultipleChoice"),edr=o(" (RemBERT model)"),odr=l(),ZT=a("li"),GTe=a("strong"),rdr=o("roberta"),tdr=o(" \u2014 "),PH=a("a"),adr=o("RobertaForMultipleChoice"),ndr=o(" (RoBERTa model)"),sdr=l(),eM=a("li"),OTe=a("strong"),ldr=o("roformer"),idr=o(" \u2014 "),BH=a("a"),ddr=o("RoFormerForMultipleChoice"),cdr=o(" (RoFormer model)"),mdr=l(),oM=a("li"),VTe=a("strong"),fdr=o("squeezebert"),gdr=o(" \u2014 "),IH=a("a"),hdr=o("SqueezeBertForMultipleChoice"),udr=o(" (SqueezeBERT model)"),pdr=l(),rM=a("li"),XTe=a("strong"),_dr=o("xlm"),bdr=o(" \u2014 "),NH=a("a"),vdr=o("XLMForMultipleChoice"),Fdr=o(" (XLM model)"),Tdr=l(),tM=a("li"),zTe=a("strong"),Mdr=o("xlm-roberta"),Edr=o(" \u2014 "),qH=a("a"),Cdr=o("XLMRobertaForMultipleChoice"),wdr=o(" (XLM-RoBERTa model)"),Adr=l(),aM=a("li"),QTe=a("strong"),Ldr=o("xlm-roberta-xl"),ydr=o(" \u2014 "),jH=a("a"),xdr=o("XLMRobertaXLForMultipleChoice"),$dr=o(" (XLM-RoBERTa-XL model)"),kdr=l(),nM=a("li"),WTe=a("strong"),Sdr=o("xlnet"),Rdr=o(" \u2014 "),DH=a("a"),Pdr=o("XLNetForMultipleChoice"),Bdr=o(" (XLNet model)"),Idr=l(),sM=a("li"),UTe=a("strong"),Ndr=o("yoso"),qdr=o(" \u2014 "),GH=a("a"),jdr=o("YosoForMultipleChoice"),Ddr=o(" (YOSO model)"),Gdr=l(),lM=a("p"),Odr=o("The model is set in evaluation mode by default using "),HTe=a("code"),Vdr=o("model.eval()"),Xdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JTe=a("code"),zdr=o("model.train()"),Qdr=l(),F(iM.$$.fragment),VZe=l(),qd=a("h2"),dM=a("a"),YTe=a("span"),F(o$.$$.fragment),Wdr=l(),KTe=a("span"),Udr=o("AutoModelForNextSentencePrediction"),XZe=l(),Go=a("div"),F(r$.$$.fragment),Hdr=l(),jd=a("p"),Jdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OH=a("a"),Ydr=o("from_pretrained()"),Kdr=o(" class method or the "),VH=a("a"),Zdr=o("from_config()"),ecr=o(` class
method.`),ocr=l(),t$=a("p"),rcr=o("This class cannot be instantiated directly using "),ZTe=a("code"),tcr=o("__init__()"),acr=o(" (throws an error)."),ncr=l(),Ct=a("div"),F(a$.$$.fragment),scr=l(),eMe=a("p"),lcr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),icr=l(),Dd=a("p"),dcr=o(`Note:
Loading a model from its configuration file does `),oMe=a("strong"),ccr=o("not"),mcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=a("a"),fcr=o("from_pretrained()"),gcr=o(" to load the model weights."),hcr=l(),F(cM.$$.fragment),ucr=l(),so=a("div"),F(n$.$$.fragment),pcr=l(),rMe=a("p"),_cr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),bcr=l(),tn=a("p"),vcr=o("The model class to instantiate is selected based on the "),tMe=a("code"),Fcr=o("model_type"),Tcr=o(` property of the config object (either
passed as an argument or loaded from `),aMe=a("code"),Mcr=o("pretrained_model_name_or_path"),Ecr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=a("code"),Ccr=o("pretrained_model_name_or_path"),wcr=o(":"),Acr=l(),Ue=a("ul"),mM=a("li"),sMe=a("strong"),Lcr=o("bert"),ycr=o(" \u2014 "),zH=a("a"),xcr=o("BertForNextSentencePrediction"),$cr=o(" (BERT model)"),kcr=l(),fM=a("li"),lMe=a("strong"),Scr=o("ernie"),Rcr=o(" \u2014 "),QH=a("a"),Pcr=o("ErnieForNextSentencePrediction"),Bcr=o(" (ERNIE model)"),Icr=l(),gM=a("li"),iMe=a("strong"),Ncr=o("fnet"),qcr=o(" \u2014 "),WH=a("a"),jcr=o("FNetForNextSentencePrediction"),Dcr=o(" (FNet model)"),Gcr=l(),hM=a("li"),dMe=a("strong"),Ocr=o("megatron-bert"),Vcr=o(" \u2014 "),UH=a("a"),Xcr=o("MegatronBertForNextSentencePrediction"),zcr=o(" (Megatron-BERT model)"),Qcr=l(),uM=a("li"),cMe=a("strong"),Wcr=o("mobilebert"),Ucr=o(" \u2014 "),HH=a("a"),Hcr=o("MobileBertForNextSentencePrediction"),Jcr=o(" (MobileBERT model)"),Ycr=l(),pM=a("li"),mMe=a("strong"),Kcr=o("nezha"),Zcr=o(" \u2014 "),JH=a("a"),emr=o("NezhaForNextSentencePrediction"),omr=o(" (Nezha model)"),rmr=l(),_M=a("li"),fMe=a("strong"),tmr=o("qdqbert"),amr=o(" \u2014 "),YH=a("a"),nmr=o("QDQBertForNextSentencePrediction"),smr=o(" (QDQBert model)"),lmr=l(),bM=a("p"),imr=o("The model is set in evaluation mode by default using "),gMe=a("code"),dmr=o("model.eval()"),cmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hMe=a("code"),mmr=o("model.train()"),fmr=l(),F(vM.$$.fragment),zZe=l(),Gd=a("h2"),FM=a("a"),uMe=a("span"),F(s$.$$.fragment),gmr=l(),pMe=a("span"),hmr=o("AutoModelForTokenClassification"),QZe=l(),Oo=a("div"),F(l$.$$.fragment),umr=l(),Od=a("p"),pmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),KH=a("a"),_mr=o("from_pretrained()"),bmr=o(" class method or the "),ZH=a("a"),vmr=o("from_config()"),Fmr=o(` class
method.`),Tmr=l(),i$=a("p"),Mmr=o("This class cannot be instantiated directly using "),_Me=a("code"),Emr=o("__init__()"),Cmr=o(" (throws an error)."),wmr=l(),wt=a("div"),F(d$.$$.fragment),Amr=l(),bMe=a("p"),Lmr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ymr=l(),Vd=a("p"),xmr=o(`Note:
Loading a model from its configuration file does `),vMe=a("strong"),$mr=o("not"),kmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),Smr=o("from_pretrained()"),Rmr=o(" to load the model weights."),Pmr=l(),F(TM.$$.fragment),Bmr=l(),lo=a("div"),F(c$.$$.fragment),Imr=l(),FMe=a("p"),Nmr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qmr=l(),an=a("p"),jmr=o("The model class to instantiate is selected based on the "),TMe=a("code"),Dmr=o("model_type"),Gmr=o(` property of the config object (either
passed as an argument or loaded from `),MMe=a("code"),Omr=o("pretrained_model_name_or_path"),Vmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EMe=a("code"),Xmr=o("pretrained_model_name_or_path"),zmr=o(":"),Qmr=l(),J=a("ul"),MM=a("li"),CMe=a("strong"),Wmr=o("albert"),Umr=o(" \u2014 "),oJ=a("a"),Hmr=o("AlbertForTokenClassification"),Jmr=o(" (ALBERT model)"),Ymr=l(),EM=a("li"),wMe=a("strong"),Kmr=o("bert"),Zmr=o(" \u2014 "),rJ=a("a"),efr=o("BertForTokenClassification"),ofr=o(" (BERT model)"),rfr=l(),CM=a("li"),AMe=a("strong"),tfr=o("big_bird"),afr=o(" \u2014 "),tJ=a("a"),nfr=o("BigBirdForTokenClassification"),sfr=o(" (BigBird model)"),lfr=l(),wM=a("li"),LMe=a("strong"),ifr=o("bloom"),dfr=o(" \u2014 "),aJ=a("a"),cfr=o("BloomForTokenClassification"),mfr=o(" (BLOOM model)"),ffr=l(),AM=a("li"),yMe=a("strong"),gfr=o("camembert"),hfr=o(" \u2014 "),nJ=a("a"),ufr=o("CamembertForTokenClassification"),pfr=o(" (CamemBERT model)"),_fr=l(),LM=a("li"),xMe=a("strong"),bfr=o("canine"),vfr=o(" \u2014 "),sJ=a("a"),Ffr=o("CanineForTokenClassification"),Tfr=o(" (CANINE model)"),Mfr=l(),yM=a("li"),$Me=a("strong"),Efr=o("convbert"),Cfr=o(" \u2014 "),lJ=a("a"),wfr=o("ConvBertForTokenClassification"),Afr=o(" (ConvBERT model)"),Lfr=l(),xM=a("li"),kMe=a("strong"),yfr=o("data2vec-text"),xfr=o(" \u2014 "),iJ=a("a"),$fr=o("Data2VecTextForTokenClassification"),kfr=o(" (Data2VecText model)"),Sfr=l(),$M=a("li"),SMe=a("strong"),Rfr=o("deberta"),Pfr=o(" \u2014 "),dJ=a("a"),Bfr=o("DebertaForTokenClassification"),Ifr=o(" (DeBERTa model)"),Nfr=l(),kM=a("li"),RMe=a("strong"),qfr=o("deberta-v2"),jfr=o(" \u2014 "),cJ=a("a"),Dfr=o("DebertaV2ForTokenClassification"),Gfr=o(" (DeBERTa-v2 model)"),Ofr=l(),SM=a("li"),PMe=a("strong"),Vfr=o("distilbert"),Xfr=o(" \u2014 "),mJ=a("a"),zfr=o("DistilBertForTokenClassification"),Qfr=o(" (DistilBERT model)"),Wfr=l(),RM=a("li"),BMe=a("strong"),Ufr=o("electra"),Hfr=o(" \u2014 "),fJ=a("a"),Jfr=o("ElectraForTokenClassification"),Yfr=o(" (ELECTRA model)"),Kfr=l(),PM=a("li"),IMe=a("strong"),Zfr=o("ernie"),egr=o(" \u2014 "),gJ=a("a"),ogr=o("ErnieForTokenClassification"),rgr=o(" (ERNIE model)"),tgr=l(),BM=a("li"),NMe=a("strong"),agr=o("flaubert"),ngr=o(" \u2014 "),hJ=a("a"),sgr=o("FlaubertForTokenClassification"),lgr=o(" (FlauBERT model)"),igr=l(),IM=a("li"),qMe=a("strong"),dgr=o("fnet"),cgr=o(" \u2014 "),uJ=a("a"),mgr=o("FNetForTokenClassification"),fgr=o(" (FNet model)"),ggr=l(),NM=a("li"),jMe=a("strong"),hgr=o("funnel"),ugr=o(" \u2014 "),pJ=a("a"),pgr=o("FunnelForTokenClassification"),_gr=o(" (Funnel Transformer model)"),bgr=l(),qM=a("li"),DMe=a("strong"),vgr=o("gpt2"),Fgr=o(" \u2014 "),_J=a("a"),Tgr=o("GPT2ForTokenClassification"),Mgr=o(" (OpenAI GPT-2 model)"),Egr=l(),jM=a("li"),GMe=a("strong"),Cgr=o("ibert"),wgr=o(" \u2014 "),bJ=a("a"),Agr=o("IBertForTokenClassification"),Lgr=o(" (I-BERT model)"),ygr=l(),DM=a("li"),OMe=a("strong"),xgr=o("layoutlm"),$gr=o(" \u2014 "),vJ=a("a"),kgr=o("LayoutLMForTokenClassification"),Sgr=o(" (LayoutLM model)"),Rgr=l(),GM=a("li"),VMe=a("strong"),Pgr=o("layoutlmv2"),Bgr=o(" \u2014 "),FJ=a("a"),Igr=o("LayoutLMv2ForTokenClassification"),Ngr=o(" (LayoutLMv2 model)"),qgr=l(),OM=a("li"),XMe=a("strong"),jgr=o("layoutlmv3"),Dgr=o(" \u2014 "),TJ=a("a"),Ggr=o("LayoutLMv3ForTokenClassification"),Ogr=o(" (LayoutLMv3 model)"),Vgr=l(),VM=a("li"),zMe=a("strong"),Xgr=o("longformer"),zgr=o(" \u2014 "),MJ=a("a"),Qgr=o("LongformerForTokenClassification"),Wgr=o(" (Longformer model)"),Ugr=l(),XM=a("li"),QMe=a("strong"),Hgr=o("luke"),Jgr=o(" \u2014 "),EJ=a("a"),Ygr=o("LukeForTokenClassification"),Kgr=o(" (LUKE model)"),Zgr=l(),zM=a("li"),WMe=a("strong"),ehr=o("markuplm"),ohr=o(" \u2014 "),CJ=a("a"),rhr=o("MarkupLMForTokenClassification"),thr=o(" (MarkupLM model)"),ahr=l(),QM=a("li"),UMe=a("strong"),nhr=o("megatron-bert"),shr=o(" \u2014 "),wJ=a("a"),lhr=o("MegatronBertForTokenClassification"),ihr=o(" (Megatron-BERT model)"),dhr=l(),WM=a("li"),HMe=a("strong"),chr=o("mobilebert"),mhr=o(" \u2014 "),AJ=a("a"),fhr=o("MobileBertForTokenClassification"),ghr=o(" (MobileBERT model)"),hhr=l(),UM=a("li"),JMe=a("strong"),uhr=o("mpnet"),phr=o(" \u2014 "),LJ=a("a"),_hr=o("MPNetForTokenClassification"),bhr=o(" (MPNet model)"),vhr=l(),HM=a("li"),YMe=a("strong"),Fhr=o("nezha"),Thr=o(" \u2014 "),yJ=a("a"),Mhr=o("NezhaForTokenClassification"),Ehr=o(" (Nezha model)"),Chr=l(),JM=a("li"),KMe=a("strong"),whr=o("nystromformer"),Ahr=o(" \u2014 "),xJ=a("a"),Lhr=o("NystromformerForTokenClassification"),yhr=o(" (Nystr\xF6mformer model)"),xhr=l(),YM=a("li"),ZMe=a("strong"),$hr=o("qdqbert"),khr=o(" \u2014 "),$J=a("a"),Shr=o("QDQBertForTokenClassification"),Rhr=o(" (QDQBert model)"),Phr=l(),KM=a("li"),eEe=a("strong"),Bhr=o("rembert"),Ihr=o(" \u2014 "),kJ=a("a"),Nhr=o("RemBertForTokenClassification"),qhr=o(" (RemBERT model)"),jhr=l(),ZM=a("li"),oEe=a("strong"),Dhr=o("roberta"),Ghr=o(" \u2014 "),SJ=a("a"),Ohr=o("RobertaForTokenClassification"),Vhr=o(" (RoBERTa model)"),Xhr=l(),eE=a("li"),rEe=a("strong"),zhr=o("roformer"),Qhr=o(" \u2014 "),RJ=a("a"),Whr=o("RoFormerForTokenClassification"),Uhr=o(" (RoFormer model)"),Hhr=l(),oE=a("li"),tEe=a("strong"),Jhr=o("squeezebert"),Yhr=o(" \u2014 "),PJ=a("a"),Khr=o("SqueezeBertForTokenClassification"),Zhr=o(" (SqueezeBERT model)"),eur=l(),rE=a("li"),aEe=a("strong"),our=o("xlm"),rur=o(" \u2014 "),BJ=a("a"),tur=o("XLMForTokenClassification"),aur=o(" (XLM model)"),nur=l(),tE=a("li"),nEe=a("strong"),sur=o("xlm-roberta"),lur=o(" \u2014 "),IJ=a("a"),iur=o("XLMRobertaForTokenClassification"),dur=o(" (XLM-RoBERTa model)"),cur=l(),aE=a("li"),sEe=a("strong"),mur=o("xlm-roberta-xl"),fur=o(" \u2014 "),NJ=a("a"),gur=o("XLMRobertaXLForTokenClassification"),hur=o(" (XLM-RoBERTa-XL model)"),uur=l(),nE=a("li"),lEe=a("strong"),pur=o("xlnet"),_ur=o(" \u2014 "),qJ=a("a"),bur=o("XLNetForTokenClassification"),vur=o(" (XLNet model)"),Fur=l(),sE=a("li"),iEe=a("strong"),Tur=o("yoso"),Mur=o(" \u2014 "),jJ=a("a"),Eur=o("YosoForTokenClassification"),Cur=o(" (YOSO model)"),wur=l(),lE=a("p"),Aur=o("The model is set in evaluation mode by default using "),dEe=a("code"),Lur=o("model.eval()"),yur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cEe=a("code"),xur=o("model.train()"),$ur=l(),F(iE.$$.fragment),WZe=l(),Xd=a("h2"),dE=a("a"),mEe=a("span"),F(m$.$$.fragment),kur=l(),fEe=a("span"),Sur=o("AutoModelForQuestionAnswering"),UZe=l(),Vo=a("div"),F(f$.$$.fragment),Rur=l(),zd=a("p"),Pur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DJ=a("a"),Bur=o("from_pretrained()"),Iur=o(" class method or the "),GJ=a("a"),Nur=o("from_config()"),qur=o(` class
method.`),jur=l(),g$=a("p"),Dur=o("This class cannot be instantiated directly using "),gEe=a("code"),Gur=o("__init__()"),Our=o(" (throws an error)."),Vur=l(),At=a("div"),F(h$.$$.fragment),Xur=l(),hEe=a("p"),zur=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Qur=l(),Qd=a("p"),Wur=o(`Note:
Loading a model from its configuration file does `),uEe=a("strong"),Uur=o("not"),Hur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OJ=a("a"),Jur=o("from_pretrained()"),Yur=o(" to load the model weights."),Kur=l(),F(cE.$$.fragment),Zur=l(),io=a("div"),F(u$.$$.fragment),epr=l(),pEe=a("p"),opr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),rpr=l(),nn=a("p"),tpr=o("The model class to instantiate is selected based on the "),_Ee=a("code"),apr=o("model_type"),npr=o(` property of the config object (either
passed as an argument or loaded from `),bEe=a("code"),spr=o("pretrained_model_name_or_path"),lpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vEe=a("code"),ipr=o("pretrained_model_name_or_path"),dpr=o(":"),cpr=l(),V=a("ul"),mE=a("li"),FEe=a("strong"),mpr=o("albert"),fpr=o(" \u2014 "),VJ=a("a"),gpr=o("AlbertForQuestionAnswering"),hpr=o(" (ALBERT model)"),upr=l(),fE=a("li"),TEe=a("strong"),ppr=o("bart"),_pr=o(" \u2014 "),XJ=a("a"),bpr=o("BartForQuestionAnswering"),vpr=o(" (BART model)"),Fpr=l(),gE=a("li"),MEe=a("strong"),Tpr=o("bert"),Mpr=o(" \u2014 "),zJ=a("a"),Epr=o("BertForQuestionAnswering"),Cpr=o(" (BERT model)"),wpr=l(),hE=a("li"),EEe=a("strong"),Apr=o("big_bird"),Lpr=o(" \u2014 "),QJ=a("a"),ypr=o("BigBirdForQuestionAnswering"),xpr=o(" (BigBird model)"),$pr=l(),uE=a("li"),CEe=a("strong"),kpr=o("bigbird_pegasus"),Spr=o(" \u2014 "),WJ=a("a"),Rpr=o("BigBirdPegasusForQuestionAnswering"),Ppr=o(" (BigBird-Pegasus model)"),Bpr=l(),pE=a("li"),wEe=a("strong"),Ipr=o("camembert"),Npr=o(" \u2014 "),UJ=a("a"),qpr=o("CamembertForQuestionAnswering"),jpr=o(" (CamemBERT model)"),Dpr=l(),_E=a("li"),AEe=a("strong"),Gpr=o("canine"),Opr=o(" \u2014 "),HJ=a("a"),Vpr=o("CanineForQuestionAnswering"),Xpr=o(" (CANINE model)"),zpr=l(),bE=a("li"),LEe=a("strong"),Qpr=o("convbert"),Wpr=o(" \u2014 "),JJ=a("a"),Upr=o("ConvBertForQuestionAnswering"),Hpr=o(" (ConvBERT model)"),Jpr=l(),vE=a("li"),yEe=a("strong"),Ypr=o("data2vec-text"),Kpr=o(" \u2014 "),YJ=a("a"),Zpr=o("Data2VecTextForQuestionAnswering"),e_r=o(" (Data2VecText model)"),o_r=l(),FE=a("li"),xEe=a("strong"),r_r=o("deberta"),t_r=o(" \u2014 "),KJ=a("a"),a_r=o("DebertaForQuestionAnswering"),n_r=o(" (DeBERTa model)"),s_r=l(),TE=a("li"),$Ee=a("strong"),l_r=o("deberta-v2"),i_r=o(" \u2014 "),ZJ=a("a"),d_r=o("DebertaV2ForQuestionAnswering"),c_r=o(" (DeBERTa-v2 model)"),m_r=l(),ME=a("li"),kEe=a("strong"),f_r=o("distilbert"),g_r=o(" \u2014 "),eY=a("a"),h_r=o("DistilBertForQuestionAnswering"),u_r=o(" (DistilBERT model)"),p_r=l(),EE=a("li"),SEe=a("strong"),__r=o("electra"),b_r=o(" \u2014 "),oY=a("a"),v_r=o("ElectraForQuestionAnswering"),F_r=o(" (ELECTRA model)"),T_r=l(),CE=a("li"),REe=a("strong"),M_r=o("ernie"),E_r=o(" \u2014 "),rY=a("a"),C_r=o("ErnieForQuestionAnswering"),w_r=o(" (ERNIE model)"),A_r=l(),wE=a("li"),PEe=a("strong"),L_r=o("flaubert"),y_r=o(" \u2014 "),tY=a("a"),x_r=o("FlaubertForQuestionAnsweringSimple"),$_r=o(" (FlauBERT model)"),k_r=l(),AE=a("li"),BEe=a("strong"),S_r=o("fnet"),R_r=o(" \u2014 "),aY=a("a"),P_r=o("FNetForQuestionAnswering"),B_r=o(" (FNet model)"),I_r=l(),LE=a("li"),IEe=a("strong"),N_r=o("funnel"),q_r=o(" \u2014 "),nY=a("a"),j_r=o("FunnelForQuestionAnswering"),D_r=o(" (Funnel Transformer model)"),G_r=l(),yE=a("li"),NEe=a("strong"),O_r=o("gptj"),V_r=o(" \u2014 "),sY=a("a"),X_r=o("GPTJForQuestionAnswering"),z_r=o(" (GPT-J model)"),Q_r=l(),xE=a("li"),qEe=a("strong"),W_r=o("ibert"),U_r=o(" \u2014 "),lY=a("a"),H_r=o("IBertForQuestionAnswering"),J_r=o(" (I-BERT model)"),Y_r=l(),$E=a("li"),jEe=a("strong"),K_r=o("layoutlmv2"),Z_r=o(" \u2014 "),iY=a("a"),e2r=o("LayoutLMv2ForQuestionAnswering"),o2r=o(" (LayoutLMv2 model)"),r2r=l(),kE=a("li"),DEe=a("strong"),t2r=o("layoutlmv3"),a2r=o(" \u2014 "),dY=a("a"),n2r=o("LayoutLMv3ForQuestionAnswering"),s2r=o(" (LayoutLMv3 model)"),l2r=l(),SE=a("li"),GEe=a("strong"),i2r=o("led"),d2r=o(" \u2014 "),cY=a("a"),c2r=o("LEDForQuestionAnswering"),m2r=o(" (LED model)"),f2r=l(),RE=a("li"),OEe=a("strong"),g2r=o("longformer"),h2r=o(" \u2014 "),mY=a("a"),u2r=o("LongformerForQuestionAnswering"),p2r=o(" (Longformer model)"),_2r=l(),PE=a("li"),VEe=a("strong"),b2r=o("luke"),v2r=o(" \u2014 "),fY=a("a"),F2r=o("LukeForQuestionAnswering"),T2r=o(" (LUKE model)"),M2r=l(),BE=a("li"),XEe=a("strong"),E2r=o("lxmert"),C2r=o(" \u2014 "),gY=a("a"),w2r=o("LxmertForQuestionAnswering"),A2r=o(" (LXMERT model)"),L2r=l(),IE=a("li"),zEe=a("strong"),y2r=o("markuplm"),x2r=o(" \u2014 "),hY=a("a"),$2r=o("MarkupLMForQuestionAnswering"),k2r=o(" (MarkupLM model)"),S2r=l(),NE=a("li"),QEe=a("strong"),R2r=o("mbart"),P2r=o(" \u2014 "),uY=a("a"),B2r=o("MBartForQuestionAnswering"),I2r=o(" (mBART model)"),N2r=l(),qE=a("li"),WEe=a("strong"),q2r=o("megatron-bert"),j2r=o(" \u2014 "),pY=a("a"),D2r=o("MegatronBertForQuestionAnswering"),G2r=o(" (Megatron-BERT model)"),O2r=l(),jE=a("li"),UEe=a("strong"),V2r=o("mobilebert"),X2r=o(" \u2014 "),_Y=a("a"),z2r=o("MobileBertForQuestionAnswering"),Q2r=o(" (MobileBERT model)"),W2r=l(),DE=a("li"),HEe=a("strong"),U2r=o("mpnet"),H2r=o(" \u2014 "),bY=a("a"),J2r=o("MPNetForQuestionAnswering"),Y2r=o(" (MPNet model)"),K2r=l(),GE=a("li"),JEe=a("strong"),Z2r=o("mvp"),ebr=o(" \u2014 "),vY=a("a"),obr=o("MvpForQuestionAnswering"),rbr=o(" (MVP model)"),tbr=l(),OE=a("li"),YEe=a("strong"),abr=o("nezha"),nbr=o(" \u2014 "),FY=a("a"),sbr=o("NezhaForQuestionAnswering"),lbr=o(" (Nezha model)"),ibr=l(),VE=a("li"),KEe=a("strong"),dbr=o("nystromformer"),cbr=o(" \u2014 "),TY=a("a"),mbr=o("NystromformerForQuestionAnswering"),fbr=o(" (Nystr\xF6mformer model)"),gbr=l(),XE=a("li"),ZEe=a("strong"),hbr=o("qdqbert"),ubr=o(" \u2014 "),MY=a("a"),pbr=o("QDQBertForQuestionAnswering"),_br=o(" (QDQBert model)"),bbr=l(),zE=a("li"),e4e=a("strong"),vbr=o("reformer"),Fbr=o(" \u2014 "),EY=a("a"),Tbr=o("ReformerForQuestionAnswering"),Mbr=o(" (Reformer model)"),Ebr=l(),QE=a("li"),o4e=a("strong"),Cbr=o("rembert"),wbr=o(" \u2014 "),CY=a("a"),Abr=o("RemBertForQuestionAnswering"),Lbr=o(" (RemBERT model)"),ybr=l(),WE=a("li"),r4e=a("strong"),xbr=o("roberta"),$br=o(" \u2014 "),wY=a("a"),kbr=o("RobertaForQuestionAnswering"),Sbr=o(" (RoBERTa model)"),Rbr=l(),UE=a("li"),t4e=a("strong"),Pbr=o("roformer"),Bbr=o(" \u2014 "),AY=a("a"),Ibr=o("RoFormerForQuestionAnswering"),Nbr=o(" (RoFormer model)"),qbr=l(),HE=a("li"),a4e=a("strong"),jbr=o("splinter"),Dbr=o(" \u2014 "),LY=a("a"),Gbr=o("SplinterForQuestionAnswering"),Obr=o(" (Splinter model)"),Vbr=l(),JE=a("li"),n4e=a("strong"),Xbr=o("squeezebert"),zbr=o(" \u2014 "),yY=a("a"),Qbr=o("SqueezeBertForQuestionAnswering"),Wbr=o(" (SqueezeBERT model)"),Ubr=l(),YE=a("li"),s4e=a("strong"),Hbr=o("xlm"),Jbr=o(" \u2014 "),xY=a("a"),Ybr=o("XLMForQuestionAnsweringSimple"),Kbr=o(" (XLM model)"),Zbr=l(),KE=a("li"),l4e=a("strong"),e1r=o("xlm-roberta"),o1r=o(" \u2014 "),$Y=a("a"),r1r=o("XLMRobertaForQuestionAnswering"),t1r=o(" (XLM-RoBERTa model)"),a1r=l(),ZE=a("li"),i4e=a("strong"),n1r=o("xlm-roberta-xl"),s1r=o(" \u2014 "),kY=a("a"),l1r=o("XLMRobertaXLForQuestionAnswering"),i1r=o(" (XLM-RoBERTa-XL model)"),d1r=l(),e4=a("li"),d4e=a("strong"),c1r=o("xlnet"),m1r=o(" \u2014 "),SY=a("a"),f1r=o("XLNetForQuestionAnsweringSimple"),g1r=o(" (XLNet model)"),h1r=l(),o4=a("li"),c4e=a("strong"),u1r=o("yoso"),p1r=o(" \u2014 "),RY=a("a"),_1r=o("YosoForQuestionAnswering"),b1r=o(" (YOSO model)"),v1r=l(),r4=a("p"),F1r=o("The model is set in evaluation mode by default using "),m4e=a("code"),T1r=o("model.eval()"),M1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f4e=a("code"),E1r=o("model.train()"),C1r=l(),F(t4.$$.fragment),HZe=l(),Wd=a("h2"),a4=a("a"),g4e=a("span"),F(p$.$$.fragment),w1r=l(),h4e=a("span"),A1r=o("AutoModelForTableQuestionAnswering"),JZe=l(),Xo=a("div"),F(_$.$$.fragment),L1r=l(),Ud=a("p"),y1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PY=a("a"),x1r=o("from_pretrained()"),$1r=o(" class method or the "),BY=a("a"),k1r=o("from_config()"),S1r=o(` class
method.`),R1r=l(),b$=a("p"),P1r=o("This class cannot be instantiated directly using "),u4e=a("code"),B1r=o("__init__()"),I1r=o(" (throws an error)."),N1r=l(),Lt=a("div"),F(v$.$$.fragment),q1r=l(),p4e=a("p"),j1r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),D1r=l(),Hd=a("p"),G1r=o(`Note:
Loading a model from its configuration file does `),_4e=a("strong"),O1r=o("not"),V1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),X1r=o("from_pretrained()"),z1r=o(" to load the model weights."),Q1r=l(),F(n4.$$.fragment),W1r=l(),co=a("div"),F(F$.$$.fragment),U1r=l(),b4e=a("p"),H1r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),J1r=l(),sn=a("p"),Y1r=o("The model class to instantiate is selected based on the "),v4e=a("code"),K1r=o("model_type"),Z1r=o(` property of the config object (either
passed as an argument or loaded from `),F4e=a("code"),evr=o("pretrained_model_name_or_path"),ovr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T4e=a("code"),rvr=o("pretrained_model_name_or_path"),tvr=o(":"),avr=l(),M4e=a("ul"),s4=a("li"),E4e=a("strong"),nvr=o("tapas"),svr=o(" \u2014 "),NY=a("a"),lvr=o("TapasForQuestionAnswering"),ivr=o(" (TAPAS model)"),dvr=l(),l4=a("p"),cvr=o("The model is set in evaluation mode by default using "),C4e=a("code"),mvr=o("model.eval()"),fvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w4e=a("code"),gvr=o("model.train()"),hvr=l(),F(i4.$$.fragment),YZe=l(),Jd=a("h2"),d4=a("a"),A4e=a("span"),F(T$.$$.fragment),uvr=l(),L4e=a("span"),pvr=o("AutoModelForDocumentQuestionAnswering"),KZe=l(),zo=a("div"),F(M$.$$.fragment),_vr=l(),Yd=a("p"),bvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),qY=a("a"),vvr=o("from_pretrained()"),Fvr=o(" class method or the "),jY=a("a"),Tvr=o("from_config()"),Mvr=o(` class
method.`),Evr=l(),E$=a("p"),Cvr=o("This class cannot be instantiated directly using "),y4e=a("code"),wvr=o("__init__()"),Avr=o(" (throws an error)."),Lvr=l(),yt=a("div"),F(C$.$$.fragment),yvr=l(),x4e=a("p"),xvr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),$vr=l(),Kd=a("p"),kvr=o(`Note:
Loading a model from its configuration file does `),$4e=a("strong"),Svr=o("not"),Rvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=a("a"),Pvr=o("from_pretrained()"),Bvr=o(" to load the model weights."),Ivr=l(),F(c4.$$.fragment),Nvr=l(),mo=a("div"),F(w$.$$.fragment),qvr=l(),k4e=a("p"),jvr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Dvr=l(),ln=a("p"),Gvr=o("The model class to instantiate is selected based on the "),S4e=a("code"),Ovr=o("model_type"),Vvr=o(` property of the config object (either
passed as an argument or loaded from `),R4e=a("code"),Xvr=o("pretrained_model_name_or_path"),zvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P4e=a("code"),Qvr=o("pretrained_model_name_or_path"),Wvr=o(":"),Uvr=l(),Zd=a("ul"),m4=a("li"),B4e=a("strong"),Hvr=o("layoutlm"),Jvr=o(" \u2014 "),GY=a("a"),Yvr=o("LayoutLMForQuestionAnswering"),Kvr=o(" (LayoutLM model)"),Zvr=l(),f4=a("li"),I4e=a("strong"),eFr=o("layoutlmv2"),oFr=o(" \u2014 "),OY=a("a"),rFr=o("LayoutLMv2ForQuestionAnswering"),tFr=o(" (LayoutLMv2 model)"),aFr=l(),g4=a("li"),N4e=a("strong"),nFr=o("layoutlmv3"),sFr=o(" \u2014 "),VY=a("a"),lFr=o("LayoutLMv3ForQuestionAnswering"),iFr=o(" (LayoutLMv3 model)"),dFr=l(),h4=a("p"),cFr=o("The model is set in evaluation mode by default using "),q4e=a("code"),mFr=o("model.eval()"),fFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j4e=a("code"),gFr=o("model.train()"),hFr=l(),F(u4.$$.fragment),ZZe=l(),ec=a("h2"),p4=a("a"),D4e=a("span"),F(A$.$$.fragment),uFr=l(),G4e=a("span"),pFr=o("AutoModelForImageClassification"),eeo=l(),Qo=a("div"),F(L$.$$.fragment),_Fr=l(),oc=a("p"),bFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),XY=a("a"),vFr=o("from_pretrained()"),FFr=o(" class method or the "),zY=a("a"),TFr=o("from_config()"),MFr=o(` class
method.`),EFr=l(),y$=a("p"),CFr=o("This class cannot be instantiated directly using "),O4e=a("code"),wFr=o("__init__()"),AFr=o(" (throws an error)."),LFr=l(),xt=a("div"),F(x$.$$.fragment),yFr=l(),V4e=a("p"),xFr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$Fr=l(),rc=a("p"),kFr=o(`Note:
Loading a model from its configuration file does `),X4e=a("strong"),SFr=o("not"),RFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=a("a"),PFr=o("from_pretrained()"),BFr=o(" to load the model weights."),IFr=l(),F(_4.$$.fragment),NFr=l(),fo=a("div"),F($$.$$.fragment),qFr=l(),z4e=a("p"),jFr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),DFr=l(),dn=a("p"),GFr=o("The model class to instantiate is selected based on the "),Q4e=a("code"),OFr=o("model_type"),VFr=o(` property of the config object (either
passed as an argument or loaded from `),W4e=a("code"),XFr=o("pretrained_model_name_or_path"),zFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U4e=a("code"),QFr=o("pretrained_model_name_or_path"),WFr=o(":"),UFr=l(),be=a("ul"),b4=a("li"),H4e=a("strong"),HFr=o("beit"),JFr=o(" \u2014 "),WY=a("a"),YFr=o("BeitForImageClassification"),KFr=o(" (BEiT model)"),ZFr=l(),v4=a("li"),J4e=a("strong"),eTr=o("convnext"),oTr=o(" \u2014 "),UY=a("a"),rTr=o("ConvNextForImageClassification"),tTr=o(" (ConvNeXT model)"),aTr=l(),F4=a("li"),Y4e=a("strong"),nTr=o("cvt"),sTr=o(" \u2014 "),HY=a("a"),lTr=o("CvtForImageClassification"),iTr=o(" (CvT model)"),dTr=l(),T4=a("li"),K4e=a("strong"),cTr=o("data2vec-vision"),mTr=o(" \u2014 "),JY=a("a"),fTr=o("Data2VecVisionForImageClassification"),gTr=o(" (Data2VecVision model)"),hTr=l(),bl=a("li"),Z4e=a("strong"),uTr=o("deit"),pTr=o(" \u2014 "),YY=a("a"),_Tr=o("DeiTForImageClassification"),bTr=o(" or "),KY=a("a"),vTr=o("DeiTForImageClassificationWithTeacher"),FTr=o(" (DeiT model)"),TTr=l(),M4=a("li"),eCe=a("strong"),MTr=o("imagegpt"),ETr=o(" \u2014 "),ZY=a("a"),CTr=o("ImageGPTForImageClassification"),wTr=o(" (ImageGPT model)"),ATr=l(),vl=a("li"),oCe=a("strong"),LTr=o("levit"),yTr=o(" \u2014 "),eK=a("a"),xTr=o("LevitForImageClassification"),$Tr=o(" or "),oK=a("a"),kTr=o("LevitForImageClassificationWithTeacher"),STr=o(" (LeViT model)"),RTr=l(),E4=a("li"),rCe=a("strong"),PTr=o("mobilevit"),BTr=o(" \u2014 "),rK=a("a"),ITr=o("MobileViTForImageClassification"),NTr=o(" (MobileViT model)"),qTr=l(),$t=a("li"),tCe=a("strong"),jTr=o("perceiver"),DTr=o(" \u2014 "),tK=a("a"),GTr=o("PerceiverForImageClassificationLearned"),OTr=o(" or "),aK=a("a"),VTr=o("PerceiverForImageClassificationFourier"),XTr=o(" or "),nK=a("a"),zTr=o("PerceiverForImageClassificationConvProcessing"),QTr=o(" (Perceiver model)"),WTr=l(),C4=a("li"),aCe=a("strong"),UTr=o("poolformer"),HTr=o(" \u2014 "),sK=a("a"),JTr=o("PoolFormerForImageClassification"),YTr=o(" (PoolFormer model)"),KTr=l(),w4=a("li"),nCe=a("strong"),ZTr=o("regnet"),eMr=o(" \u2014 "),lK=a("a"),oMr=o("RegNetForImageClassification"),rMr=o(" (RegNet model)"),tMr=l(),A4=a("li"),sCe=a("strong"),aMr=o("resnet"),nMr=o(" \u2014 "),iK=a("a"),sMr=o("ResNetForImageClassification"),lMr=o(" (ResNet model)"),iMr=l(),L4=a("li"),lCe=a("strong"),dMr=o("segformer"),cMr=o(" \u2014 "),dK=a("a"),mMr=o("SegformerForImageClassification"),fMr=o(" (SegFormer model)"),gMr=l(),y4=a("li"),iCe=a("strong"),hMr=o("swin"),uMr=o(" \u2014 "),cK=a("a"),pMr=o("SwinForImageClassification"),_Mr=o(" (Swin Transformer model)"),bMr=l(),x4=a("li"),dCe=a("strong"),vMr=o("swinv2"),FMr=o(" \u2014 "),mK=a("a"),TMr=o("Swinv2ForImageClassification"),MMr=o(" (Swin Transformer V2 model)"),EMr=l(),$4=a("li"),cCe=a("strong"),CMr=o("van"),wMr=o(" \u2014 "),fK=a("a"),AMr=o("VanForImageClassification"),LMr=o(" (VAN model)"),yMr=l(),k4=a("li"),mCe=a("strong"),xMr=o("vit"),$Mr=o(" \u2014 "),gK=a("a"),kMr=o("ViTForImageClassification"),SMr=o(" (ViT model)"),RMr=l(),S4=a("li"),fCe=a("strong"),PMr=o("vit_msn"),BMr=o(" \u2014 "),hK=a("a"),IMr=o("ViTMSNForImageClassification"),NMr=o(" (ViTMSN model)"),qMr=l(),R4=a("p"),jMr=o("The model is set in evaluation mode by default using "),gCe=a("code"),DMr=o("model.eval()"),GMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hCe=a("code"),OMr=o("model.train()"),VMr=l(),F(P4.$$.fragment),oeo=l(),tc=a("h2"),B4=a("a"),uCe=a("span"),F(k$.$$.fragment),XMr=l(),pCe=a("span"),zMr=o("AutoModelForVideoClassification"),reo=l(),Wo=a("div"),F(S$.$$.fragment),QMr=l(),ac=a("p"),WMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),uK=a("a"),UMr=o("from_pretrained()"),HMr=o(" class method or the "),pK=a("a"),JMr=o("from_config()"),YMr=o(` class
method.`),KMr=l(),R$=a("p"),ZMr=o("This class cannot be instantiated directly using "),_Ce=a("code"),eEr=o("__init__()"),oEr=o(" (throws an error)."),rEr=l(),kt=a("div"),F(P$.$$.fragment),tEr=l(),bCe=a("p"),aEr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),nEr=l(),nc=a("p"),sEr=o(`Note:
Loading a model from its configuration file does `),vCe=a("strong"),lEr=o("not"),iEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=a("a"),dEr=o("from_pretrained()"),cEr=o(" to load the model weights."),mEr=l(),F(I4.$$.fragment),fEr=l(),go=a("div"),F(B$.$$.fragment),gEr=l(),FCe=a("p"),hEr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),uEr=l(),cn=a("p"),pEr=o("The model class to instantiate is selected based on the "),TCe=a("code"),_Er=o("model_type"),bEr=o(` property of the config object (either
passed as an argument or loaded from `),MCe=a("code"),vEr=o("pretrained_model_name_or_path"),FEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ECe=a("code"),TEr=o("pretrained_model_name_or_path"),MEr=o(":"),EEr=l(),CCe=a("ul"),N4=a("li"),wCe=a("strong"),CEr=o("videomae"),wEr=o(" \u2014 "),bK=a("a"),AEr=o("VideoMAEForVideoClassification"),LEr=o(" (VideoMAE model)"),yEr=l(),q4=a("p"),xEr=o("The model is set in evaluation mode by default using "),ACe=a("code"),$Er=o("model.eval()"),kEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LCe=a("code"),SEr=o("model.train()"),REr=l(),F(j4.$$.fragment),teo=l(),sc=a("h2"),D4=a("a"),yCe=a("span"),F(I$.$$.fragment),PEr=l(),xCe=a("span"),BEr=o("AutoModelForVision2Seq"),aeo=l(),Uo=a("div"),F(N$.$$.fragment),IEr=l(),lc=a("p"),NEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vK=a("a"),qEr=o("from_pretrained()"),jEr=o(" class method or the "),FK=a("a"),DEr=o("from_config()"),GEr=o(` class
method.`),OEr=l(),q$=a("p"),VEr=o("This class cannot be instantiated directly using "),$Ce=a("code"),XEr=o("__init__()"),zEr=o(" (throws an error)."),QEr=l(),St=a("div"),F(j$.$$.fragment),WEr=l(),kCe=a("p"),UEr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),HEr=l(),ic=a("p"),JEr=o(`Note:
Loading a model from its configuration file does `),SCe=a("strong"),YEr=o("not"),KEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TK=a("a"),ZEr=o("from_pretrained()"),e4r=o(" to load the model weights."),o4r=l(),F(G4.$$.fragment),r4r=l(),ho=a("div"),F(D$.$$.fragment),t4r=l(),RCe=a("p"),a4r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),n4r=l(),mn=a("p"),s4r=o("The model class to instantiate is selected based on the "),PCe=a("code"),l4r=o("model_type"),i4r=o(` property of the config object (either
passed as an argument or loaded from `),BCe=a("code"),d4r=o("pretrained_model_name_or_path"),c4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ICe=a("code"),m4r=o("pretrained_model_name_or_path"),f4r=o(":"),g4r=l(),NCe=a("ul"),O4=a("li"),qCe=a("strong"),h4r=o("vision-encoder-decoder"),u4r=o(" \u2014 "),MK=a("a"),p4r=o("VisionEncoderDecoderModel"),_4r=o(" (Vision Encoder decoder model)"),b4r=l(),V4=a("p"),v4r=o("The model is set in evaluation mode by default using "),jCe=a("code"),F4r=o("model.eval()"),T4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DCe=a("code"),M4r=o("model.train()"),E4r=l(),F(X4.$$.fragment),neo=l(),dc=a("h2"),z4=a("a"),GCe=a("span"),F(G$.$$.fragment),C4r=l(),OCe=a("span"),w4r=o("AutoModelForVisualQuestionAnswering"),seo=l(),Ho=a("div"),F(O$.$$.fragment),A4r=l(),cc=a("p"),L4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),EK=a("a"),y4r=o("from_pretrained()"),x4r=o(" class method or the "),CK=a("a"),$4r=o("from_config()"),k4r=o(` class
method.`),S4r=l(),V$=a("p"),R4r=o("This class cannot be instantiated directly using "),VCe=a("code"),P4r=o("__init__()"),B4r=o(" (throws an error)."),I4r=l(),Rt=a("div"),F(X$.$$.fragment),N4r=l(),XCe=a("p"),q4r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),j4r=l(),mc=a("p"),D4r=o(`Note:
Loading a model from its configuration file does `),zCe=a("strong"),G4r=o("not"),O4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=a("a"),V4r=o("from_pretrained()"),X4r=o(" to load the model weights."),z4r=l(),F(Q4.$$.fragment),Q4r=l(),uo=a("div"),F(z$.$$.fragment),W4r=l(),QCe=a("p"),U4r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),H4r=l(),fn=a("p"),J4r=o("The model class to instantiate is selected based on the "),WCe=a("code"),Y4r=o("model_type"),K4r=o(` property of the config object (either
passed as an argument or loaded from `),UCe=a("code"),Z4r=o("pretrained_model_name_or_path"),eCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HCe=a("code"),oCr=o("pretrained_model_name_or_path"),rCr=o(":"),tCr=l(),JCe=a("ul"),W4=a("li"),YCe=a("strong"),aCr=o("vilt"),nCr=o(" \u2014 "),AK=a("a"),sCr=o("ViltForQuestionAnswering"),lCr=o(" (ViLT model)"),iCr=l(),U4=a("p"),dCr=o("The model is set in evaluation mode by default using "),KCe=a("code"),cCr=o("model.eval()"),mCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZCe=a("code"),fCr=o("model.train()"),gCr=l(),F(H4.$$.fragment),leo=l(),fc=a("h2"),J4=a("a"),e3e=a("span"),F(Q$.$$.fragment),hCr=l(),o3e=a("span"),uCr=o("AutoModelForAudioClassification"),ieo=l(),Jo=a("div"),F(W$.$$.fragment),pCr=l(),gc=a("p"),_Cr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),LK=a("a"),bCr=o("from_pretrained()"),vCr=o(" class method or the "),yK=a("a"),FCr=o("from_config()"),TCr=o(` class
method.`),MCr=l(),U$=a("p"),ECr=o("This class cannot be instantiated directly using "),r3e=a("code"),CCr=o("__init__()"),wCr=o(" (throws an error)."),ACr=l(),Pt=a("div"),F(H$.$$.fragment),LCr=l(),t3e=a("p"),yCr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),xCr=l(),hc=a("p"),$Cr=o(`Note:
Loading a model from its configuration file does `),a3e=a("strong"),kCr=o("not"),SCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=a("a"),RCr=o("from_pretrained()"),PCr=o(" to load the model weights."),BCr=l(),F(Y4.$$.fragment),ICr=l(),po=a("div"),F(J$.$$.fragment),NCr=l(),n3e=a("p"),qCr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),jCr=l(),gn=a("p"),DCr=o("The model class to instantiate is selected based on the "),s3e=a("code"),GCr=o("model_type"),OCr=o(` property of the config object (either
passed as an argument or loaded from `),l3e=a("code"),VCr=o("pretrained_model_name_or_path"),XCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=a("code"),zCr=o("pretrained_model_name_or_path"),QCr=o(":"),WCr=l(),Pe=a("ul"),K4=a("li"),d3e=a("strong"),UCr=o("data2vec-audio"),HCr=o(" \u2014 "),$K=a("a"),JCr=o("Data2VecAudioForSequenceClassification"),YCr=o(" (Data2VecAudio model)"),KCr=l(),Z4=a("li"),c3e=a("strong"),ZCr=o("hubert"),e3r=o(" \u2014 "),kK=a("a"),o3r=o("HubertForSequenceClassification"),r3r=o(" (Hubert model)"),t3r=l(),eC=a("li"),m3e=a("strong"),a3r=o("sew"),n3r=o(" \u2014 "),SK=a("a"),s3r=o("SEWForSequenceClassification"),l3r=o(" (SEW model)"),i3r=l(),oC=a("li"),f3e=a("strong"),d3r=o("sew-d"),c3r=o(" \u2014 "),RK=a("a"),m3r=o("SEWDForSequenceClassification"),f3r=o(" (SEW-D model)"),g3r=l(),rC=a("li"),g3e=a("strong"),h3r=o("unispeech"),u3r=o(" \u2014 "),PK=a("a"),p3r=o("UniSpeechForSequenceClassification"),_3r=o(" (UniSpeech model)"),b3r=l(),tC=a("li"),h3e=a("strong"),v3r=o("unispeech-sat"),F3r=o(" \u2014 "),BK=a("a"),T3r=o("UniSpeechSatForSequenceClassification"),M3r=o(" (UniSpeechSat model)"),E3r=l(),aC=a("li"),u3e=a("strong"),C3r=o("wav2vec2"),w3r=o(" \u2014 "),IK=a("a"),A3r=o("Wav2Vec2ForSequenceClassification"),L3r=o(" (Wav2Vec2 model)"),y3r=l(),nC=a("li"),p3e=a("strong"),x3r=o("wav2vec2-conformer"),$3r=o(" \u2014 "),NK=a("a"),k3r=o("Wav2Vec2ConformerForSequenceClassification"),S3r=o(" (Wav2Vec2-Conformer model)"),R3r=l(),sC=a("li"),_3e=a("strong"),P3r=o("wavlm"),B3r=o(" \u2014 "),qK=a("a"),I3r=o("WavLMForSequenceClassification"),N3r=o(" (WavLM model)"),q3r=l(),lC=a("p"),j3r=o("The model is set in evaluation mode by default using "),b3e=a("code"),D3r=o("model.eval()"),G3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v3e=a("code"),O3r=o("model.train()"),V3r=l(),F(iC.$$.fragment),deo=l(),uc=a("h2"),dC=a("a"),F3e=a("span"),F(Y$.$$.fragment),X3r=l(),T3e=a("span"),z3r=o("AutoModelForAudioFrameClassification"),ceo=l(),Yo=a("div"),F(K$.$$.fragment),Q3r=l(),pc=a("p"),W3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),jK=a("a"),U3r=o("from_pretrained()"),H3r=o(" class method or the "),DK=a("a"),J3r=o("from_config()"),Y3r=o(` class
method.`),K3r=l(),Z$=a("p"),Z3r=o("This class cannot be instantiated directly using "),M3e=a("code"),e5r=o("__init__()"),o5r=o(" (throws an error)."),r5r=l(),Bt=a("div"),F(ek.$$.fragment),t5r=l(),E3e=a("p"),a5r=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),n5r=l(),_c=a("p"),s5r=o(`Note:
Loading a model from its configuration file does `),C3e=a("strong"),l5r=o("not"),i5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=a("a"),d5r=o("from_pretrained()"),c5r=o(" to load the model weights."),m5r=l(),F(cC.$$.fragment),f5r=l(),_o=a("div"),F(ok.$$.fragment),g5r=l(),w3e=a("p"),h5r=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),u5r=l(),hn=a("p"),p5r=o("The model class to instantiate is selected based on the "),A3e=a("code"),_5r=o("model_type"),b5r=o(` property of the config object (either
passed as an argument or loaded from `),L3e=a("code"),v5r=o("pretrained_model_name_or_path"),F5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y3e=a("code"),T5r=o("pretrained_model_name_or_path"),M5r=o(":"),E5r=l(),mt=a("ul"),mC=a("li"),x3e=a("strong"),C5r=o("data2vec-audio"),w5r=o(" \u2014 "),OK=a("a"),A5r=o("Data2VecAudioForAudioFrameClassification"),L5r=o(" (Data2VecAudio model)"),y5r=l(),fC=a("li"),$3e=a("strong"),x5r=o("unispeech-sat"),$5r=o(" \u2014 "),VK=a("a"),k5r=o("UniSpeechSatForAudioFrameClassification"),S5r=o(" (UniSpeechSat model)"),R5r=l(),gC=a("li"),k3e=a("strong"),P5r=o("wav2vec2"),B5r=o(" \u2014 "),XK=a("a"),I5r=o("Wav2Vec2ForAudioFrameClassification"),N5r=o(" (Wav2Vec2 model)"),q5r=l(),hC=a("li"),S3e=a("strong"),j5r=o("wav2vec2-conformer"),D5r=o(" \u2014 "),zK=a("a"),G5r=o("Wav2Vec2ConformerForAudioFrameClassification"),O5r=o(" (Wav2Vec2-Conformer model)"),V5r=l(),uC=a("li"),R3e=a("strong"),X5r=o("wavlm"),z5r=o(" \u2014 "),QK=a("a"),Q5r=o("WavLMForAudioFrameClassification"),W5r=o(" (WavLM model)"),U5r=l(),pC=a("p"),H5r=o("The model is set in evaluation mode by default using "),P3e=a("code"),J5r=o("model.eval()"),Y5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B3e=a("code"),K5r=o("model.train()"),Z5r=l(),F(_C.$$.fragment),meo=l(),bc=a("h2"),bC=a("a"),I3e=a("span"),F(rk.$$.fragment),e0r=l(),N3e=a("span"),o0r=o("AutoModelForCTC"),feo=l(),Ko=a("div"),F(tk.$$.fragment),r0r=l(),vc=a("p"),t0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),WK=a("a"),a0r=o("from_pretrained()"),n0r=o(" class method or the "),UK=a("a"),s0r=o("from_config()"),l0r=o(` class
method.`),i0r=l(),ak=a("p"),d0r=o("This class cannot be instantiated directly using "),q3e=a("code"),c0r=o("__init__()"),m0r=o(" (throws an error)."),f0r=l(),It=a("div"),F(nk.$$.fragment),g0r=l(),j3e=a("p"),h0r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),u0r=l(),Fc=a("p"),p0r=o(`Note:
Loading a model from its configuration file does `),D3e=a("strong"),_0r=o("not"),b0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HK=a("a"),v0r=o("from_pretrained()"),F0r=o(" to load the model weights."),T0r=l(),F(vC.$$.fragment),M0r=l(),bo=a("div"),F(sk.$$.fragment),E0r=l(),G3e=a("p"),C0r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),w0r=l(),un=a("p"),A0r=o("The model class to instantiate is selected based on the "),O3e=a("code"),L0r=o("model_type"),y0r=o(` property of the config object (either
passed as an argument or loaded from `),V3e=a("code"),x0r=o("pretrained_model_name_or_path"),$0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X3e=a("code"),k0r=o("pretrained_model_name_or_path"),S0r=o(":"),R0r=l(),Le=a("ul"),FC=a("li"),z3e=a("strong"),P0r=o("data2vec-audio"),B0r=o(" \u2014 "),JK=a("a"),I0r=o("Data2VecAudioForCTC"),N0r=o(" (Data2VecAudio model)"),q0r=l(),TC=a("li"),Q3e=a("strong"),j0r=o("hubert"),D0r=o(" \u2014 "),YK=a("a"),G0r=o("HubertForCTC"),O0r=o(" (Hubert model)"),V0r=l(),MC=a("li"),W3e=a("strong"),X0r=o("mctct"),z0r=o(" \u2014 "),KK=a("a"),Q0r=o("MCTCTForCTC"),W0r=o(" (M-CTC-T model)"),U0r=l(),EC=a("li"),U3e=a("strong"),H0r=o("sew"),J0r=o(" \u2014 "),ZK=a("a"),Y0r=o("SEWForCTC"),K0r=o(" (SEW model)"),Z0r=l(),CC=a("li"),H3e=a("strong"),ewr=o("sew-d"),owr=o(" \u2014 "),eZ=a("a"),rwr=o("SEWDForCTC"),twr=o(" (SEW-D model)"),awr=l(),wC=a("li"),J3e=a("strong"),nwr=o("unispeech"),swr=o(" \u2014 "),oZ=a("a"),lwr=o("UniSpeechForCTC"),iwr=o(" (UniSpeech model)"),dwr=l(),AC=a("li"),Y3e=a("strong"),cwr=o("unispeech-sat"),mwr=o(" \u2014 "),rZ=a("a"),fwr=o("UniSpeechSatForCTC"),gwr=o(" (UniSpeechSat model)"),hwr=l(),LC=a("li"),K3e=a("strong"),uwr=o("wav2vec2"),pwr=o(" \u2014 "),tZ=a("a"),_wr=o("Wav2Vec2ForCTC"),bwr=o(" (Wav2Vec2 model)"),vwr=l(),yC=a("li"),Z3e=a("strong"),Fwr=o("wav2vec2-conformer"),Twr=o(" \u2014 "),aZ=a("a"),Mwr=o("Wav2Vec2ConformerForCTC"),Ewr=o(" (Wav2Vec2-Conformer model)"),Cwr=l(),xC=a("li"),e5e=a("strong"),wwr=o("wavlm"),Awr=o(" \u2014 "),nZ=a("a"),Lwr=o("WavLMForCTC"),ywr=o(" (WavLM model)"),xwr=l(),$C=a("p"),$wr=o("The model is set in evaluation mode by default using "),o5e=a("code"),kwr=o("model.eval()"),Swr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r5e=a("code"),Rwr=o("model.train()"),Pwr=l(),F(kC.$$.fragment),geo=l(),Tc=a("h2"),SC=a("a"),t5e=a("span"),F(lk.$$.fragment),Bwr=l(),a5e=a("span"),Iwr=o("AutoModelForSpeechSeq2Seq"),heo=l(),Zo=a("div"),F(ik.$$.fragment),Nwr=l(),Mc=a("p"),qwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),sZ=a("a"),jwr=o("from_pretrained()"),Dwr=o(" class method or the "),lZ=a("a"),Gwr=o("from_config()"),Owr=o(` class
method.`),Vwr=l(),dk=a("p"),Xwr=o("This class cannot be instantiated directly using "),n5e=a("code"),zwr=o("__init__()"),Qwr=o(" (throws an error)."),Wwr=l(),Nt=a("div"),F(ck.$$.fragment),Uwr=l(),s5e=a("p"),Hwr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Jwr=l(),Ec=a("p"),Ywr=o(`Note:
Loading a model from its configuration file does `),l5e=a("strong"),Kwr=o("not"),Zwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iZ=a("a"),eAr=o("from_pretrained()"),oAr=o(" to load the model weights."),rAr=l(),F(RC.$$.fragment),tAr=l(),vo=a("div"),F(mk.$$.fragment),aAr=l(),i5e=a("p"),nAr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),sAr=l(),pn=a("p"),lAr=o("The model class to instantiate is selected based on the "),d5e=a("code"),iAr=o("model_type"),dAr=o(` property of the config object (either
passed as an argument or loaded from `),c5e=a("code"),cAr=o("pretrained_model_name_or_path"),mAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=a("code"),fAr=o("pretrained_model_name_or_path"),gAr=o(":"),hAr=l(),fk=a("ul"),PC=a("li"),f5e=a("strong"),uAr=o("speech-encoder-decoder"),pAr=o(" \u2014 "),dZ=a("a"),_Ar=o("SpeechEncoderDecoderModel"),bAr=o(" (Speech Encoder decoder model)"),vAr=l(),BC=a("li"),g5e=a("strong"),FAr=o("speech_to_text"),TAr=o(" \u2014 "),cZ=a("a"),MAr=o("Speech2TextForConditionalGeneration"),EAr=o(" (Speech2Text model)"),CAr=l(),IC=a("p"),wAr=o("The model is set in evaluation mode by default using "),h5e=a("code"),AAr=o("model.eval()"),LAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u5e=a("code"),yAr=o("model.train()"),xAr=l(),F(NC.$$.fragment),ueo=l(),Cc=a("h2"),qC=a("a"),p5e=a("span"),F(gk.$$.fragment),$Ar=l(),_5e=a("span"),kAr=o("AutoModelForAudioXVector"),peo=l(),er=a("div"),F(hk.$$.fragment),SAr=l(),wc=a("p"),RAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),mZ=a("a"),PAr=o("from_pretrained()"),BAr=o(" class method or the "),fZ=a("a"),IAr=o("from_config()"),NAr=o(` class
method.`),qAr=l(),uk=a("p"),jAr=o("This class cannot be instantiated directly using "),b5e=a("code"),DAr=o("__init__()"),GAr=o(" (throws an error)."),OAr=l(),qt=a("div"),F(pk.$$.fragment),VAr=l(),v5e=a("p"),XAr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),zAr=l(),Ac=a("p"),QAr=o(`Note:
Loading a model from its configuration file does `),F5e=a("strong"),WAr=o("not"),UAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=a("a"),HAr=o("from_pretrained()"),JAr=o(" to load the model weights."),YAr=l(),F(jC.$$.fragment),KAr=l(),Fo=a("div"),F(_k.$$.fragment),ZAr=l(),T5e=a("p"),e6r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),o6r=l(),_n=a("p"),r6r=o("The model class to instantiate is selected based on the "),M5e=a("code"),t6r=o("model_type"),a6r=o(` property of the config object (either
passed as an argument or loaded from `),E5e=a("code"),n6r=o("pretrained_model_name_or_path"),s6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C5e=a("code"),l6r=o("pretrained_model_name_or_path"),i6r=o(":"),d6r=l(),ft=a("ul"),DC=a("li"),w5e=a("strong"),c6r=o("data2vec-audio"),m6r=o(" \u2014 "),hZ=a("a"),f6r=o("Data2VecAudioForXVector"),g6r=o(" (Data2VecAudio model)"),h6r=l(),GC=a("li"),A5e=a("strong"),u6r=o("unispeech-sat"),p6r=o(" \u2014 "),uZ=a("a"),_6r=o("UniSpeechSatForXVector"),b6r=o(" (UniSpeechSat model)"),v6r=l(),OC=a("li"),L5e=a("strong"),F6r=o("wav2vec2"),T6r=o(" \u2014 "),pZ=a("a"),M6r=o("Wav2Vec2ForXVector"),E6r=o(" (Wav2Vec2 model)"),C6r=l(),VC=a("li"),y5e=a("strong"),w6r=o("wav2vec2-conformer"),A6r=o(" \u2014 "),_Z=a("a"),L6r=o("Wav2Vec2ConformerForXVector"),y6r=o(" (Wav2Vec2-Conformer model)"),x6r=l(),XC=a("li"),x5e=a("strong"),$6r=o("wavlm"),k6r=o(" \u2014 "),bZ=a("a"),S6r=o("WavLMForXVector"),R6r=o(" (WavLM model)"),P6r=l(),zC=a("p"),B6r=o("The model is set in evaluation mode by default using "),$5e=a("code"),I6r=o("model.eval()"),N6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k5e=a("code"),q6r=o("model.train()"),j6r=l(),F(QC.$$.fragment),_eo=l(),Lc=a("h2"),WC=a("a"),S5e=a("span"),F(bk.$$.fragment),D6r=l(),R5e=a("span"),G6r=o("AutoModelForMaskedImageModeling"),beo=l(),or=a("div"),F(vk.$$.fragment),O6r=l(),yc=a("p"),V6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),vZ=a("a"),X6r=o("from_pretrained()"),z6r=o(" class method or the "),FZ=a("a"),Q6r=o("from_config()"),W6r=o(` class
method.`),U6r=l(),Fk=a("p"),H6r=o("This class cannot be instantiated directly using "),P5e=a("code"),J6r=o("__init__()"),Y6r=o(" (throws an error)."),K6r=l(),jt=a("div"),F(Tk.$$.fragment),Z6r=l(),B5e=a("p"),e7r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),o7r=l(),xc=a("p"),r7r=o(`Note:
Loading a model from its configuration file does `),I5e=a("strong"),t7r=o("not"),a7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TZ=a("a"),n7r=o("from_pretrained()"),s7r=o(" to load the model weights."),l7r=l(),F(UC.$$.fragment),i7r=l(),To=a("div"),F(Mk.$$.fragment),d7r=l(),N5e=a("p"),c7r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),m7r=l(),bn=a("p"),f7r=o("The model class to instantiate is selected based on the "),q5e=a("code"),g7r=o("model_type"),h7r=o(` property of the config object (either
passed as an argument or loaded from `),j5e=a("code"),u7r=o("pretrained_model_name_or_path"),p7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D5e=a("code"),_7r=o("pretrained_model_name_or_path"),b7r=o(":"),v7r=l(),vn=a("ul"),HC=a("li"),G5e=a("strong"),F7r=o("deit"),T7r=o(" \u2014 "),MZ=a("a"),M7r=o("DeiTForMaskedImageModeling"),E7r=o(" (DeiT model)"),C7r=l(),JC=a("li"),O5e=a("strong"),w7r=o("swin"),A7r=o(" \u2014 "),EZ=a("a"),L7r=o("SwinForMaskedImageModeling"),y7r=o(" (Swin Transformer model)"),x7r=l(),YC=a("li"),V5e=a("strong"),$7r=o("swinv2"),k7r=o(" \u2014 "),CZ=a("a"),S7r=o("Swinv2ForMaskedImageModeling"),R7r=o(" (Swin Transformer V2 model)"),P7r=l(),KC=a("li"),X5e=a("strong"),B7r=o("vit"),I7r=o(" \u2014 "),wZ=a("a"),N7r=o("ViTForMaskedImageModeling"),q7r=o(" (ViT model)"),j7r=l(),ZC=a("p"),D7r=o("The model is set in evaluation mode by default using "),z5e=a("code"),G7r=o("model.eval()"),O7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q5e=a("code"),V7r=o("model.train()"),X7r=l(),F(e3.$$.fragment),veo=l(),$c=a("h2"),o3=a("a"),W5e=a("span"),F(Ek.$$.fragment),z7r=l(),U5e=a("span"),Q7r=o("AutoModelForObjectDetection"),Feo=l(),rr=a("div"),F(Ck.$$.fragment),W7r=l(),kc=a("p"),U7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),AZ=a("a"),H7r=o("from_pretrained()"),J7r=o(" class method or the "),LZ=a("a"),Y7r=o("from_config()"),K7r=o(` class
method.`),Z7r=l(),wk=a("p"),eLr=o("This class cannot be instantiated directly using "),H5e=a("code"),oLr=o("__init__()"),rLr=o(" (throws an error)."),tLr=l(),Dt=a("div"),F(Ak.$$.fragment),aLr=l(),J5e=a("p"),nLr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),sLr=l(),Sc=a("p"),lLr=o(`Note:
Loading a model from its configuration file does `),Y5e=a("strong"),iLr=o("not"),dLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yZ=a("a"),cLr=o("from_pretrained()"),mLr=o(" to load the model weights."),fLr=l(),F(r3.$$.fragment),gLr=l(),Mo=a("div"),F(Lk.$$.fragment),hLr=l(),K5e=a("p"),uLr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),pLr=l(),Fn=a("p"),_Lr=o("The model class to instantiate is selected based on the "),Z5e=a("code"),bLr=o("model_type"),vLr=o(` property of the config object (either
passed as an argument or loaded from `),e0e=a("code"),FLr=o("pretrained_model_name_or_path"),TLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o0e=a("code"),MLr=o("pretrained_model_name_or_path"),ELr=o(":"),CLr=l(),Tn=a("ul"),t3=a("li"),r0e=a("strong"),wLr=o("conditional_detr"),ALr=o(" \u2014 "),xZ=a("a"),LLr=o("ConditionalDetrForObjectDetection"),yLr=o(" (Conditional DETR model)"),xLr=l(),a3=a("li"),t0e=a("strong"),$Lr=o("deformable_detr"),kLr=o(" \u2014 "),$Z=a("a"),SLr=o("DeformableDetrForObjectDetection"),RLr=o(" (Deformable DETR model)"),PLr=l(),n3=a("li"),a0e=a("strong"),BLr=o("detr"),ILr=o(" \u2014 "),kZ=a("a"),NLr=o("DetrForObjectDetection"),qLr=o(" (DETR model)"),jLr=l(),s3=a("li"),n0e=a("strong"),DLr=o("yolos"),GLr=o(" \u2014 "),SZ=a("a"),OLr=o("YolosForObjectDetection"),VLr=o(" (YOLOS model)"),XLr=l(),l3=a("p"),zLr=o("The model is set in evaluation mode by default using "),s0e=a("code"),QLr=o("model.eval()"),WLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=a("code"),ULr=o("model.train()"),HLr=l(),F(i3.$$.fragment),Teo=l(),Rc=a("h2"),d3=a("a"),i0e=a("span"),F(yk.$$.fragment),JLr=l(),d0e=a("span"),YLr=o("AutoModelForImageSegmentation"),Meo=l(),tr=a("div"),F(xk.$$.fragment),KLr=l(),Pc=a("p"),ZLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),RZ=a("a"),eyr=o("from_pretrained()"),oyr=o(" class method or the "),PZ=a("a"),ryr=o("from_config()"),tyr=o(` class
method.`),ayr=l(),$k=a("p"),nyr=o("This class cannot be instantiated directly using "),c0e=a("code"),syr=o("__init__()"),lyr=o(" (throws an error)."),iyr=l(),Gt=a("div"),F(kk.$$.fragment),dyr=l(),m0e=a("p"),cyr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),myr=l(),Bc=a("p"),fyr=o(`Note:
Loading a model from its configuration file does `),f0e=a("strong"),gyr=o("not"),hyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BZ=a("a"),uyr=o("from_pretrained()"),pyr=o(" to load the model weights."),_yr=l(),F(c3.$$.fragment),byr=l(),Eo=a("div"),F(Sk.$$.fragment),vyr=l(),g0e=a("p"),Fyr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Tyr=l(),Mn=a("p"),Myr=o("The model class to instantiate is selected based on the "),h0e=a("code"),Eyr=o("model_type"),Cyr=o(` property of the config object (either
passed as an argument or loaded from `),u0e=a("code"),wyr=o("pretrained_model_name_or_path"),Ayr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=a("code"),Lyr=o("pretrained_model_name_or_path"),yyr=o(":"),xyr=l(),_0e=a("ul"),m3=a("li"),b0e=a("strong"),$yr=o("detr"),kyr=o(" \u2014 "),IZ=a("a"),Syr=o("DetrForSegmentation"),Ryr=o(" (DETR model)"),Pyr=l(),f3=a("p"),Byr=o("The model is set in evaluation mode by default using "),v0e=a("code"),Iyr=o("model.eval()"),Nyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F0e=a("code"),qyr=o("model.train()"),jyr=l(),F(g3.$$.fragment),Eeo=l(),Ic=a("h2"),h3=a("a"),T0e=a("span"),F(Rk.$$.fragment),Dyr=l(),M0e=a("span"),Gyr=o("AutoModelForSemanticSegmentation"),Ceo=l(),ar=a("div"),F(Pk.$$.fragment),Oyr=l(),Nc=a("p"),Vyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),NZ=a("a"),Xyr=o("from_pretrained()"),zyr=o(" class method or the "),qZ=a("a"),Qyr=o("from_config()"),Wyr=o(` class
method.`),Uyr=l(),Bk=a("p"),Hyr=o("This class cannot be instantiated directly using "),E0e=a("code"),Jyr=o("__init__()"),Yyr=o(" (throws an error)."),Kyr=l(),Ot=a("div"),F(Ik.$$.fragment),Zyr=l(),C0e=a("p"),e8r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),o8r=l(),qc=a("p"),r8r=o(`Note:
Loading a model from its configuration file does `),w0e=a("strong"),t8r=o("not"),a8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jZ=a("a"),n8r=o("from_pretrained()"),s8r=o(" to load the model weights."),l8r=l(),F(u3.$$.fragment),i8r=l(),Co=a("div"),F(Nk.$$.fragment),d8r=l(),A0e=a("p"),c8r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),m8r=l(),En=a("p"),f8r=o("The model class to instantiate is selected based on the "),L0e=a("code"),g8r=o("model_type"),h8r=o(` property of the config object (either
passed as an argument or loaded from `),y0e=a("code"),u8r=o("pretrained_model_name_or_path"),p8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=a("code"),_8r=o("pretrained_model_name_or_path"),b8r=o(":"),v8r=l(),gt=a("ul"),p3=a("li"),$0e=a("strong"),F8r=o("beit"),T8r=o(" \u2014 "),DZ=a("a"),M8r=o("BeitForSemanticSegmentation"),E8r=o(" (BEiT model)"),C8r=l(),_3=a("li"),k0e=a("strong"),w8r=o("data2vec-vision"),A8r=o(" \u2014 "),GZ=a("a"),L8r=o("Data2VecVisionForSemanticSegmentation"),y8r=o(" (Data2VecVision model)"),x8r=l(),b3=a("li"),S0e=a("strong"),$8r=o("dpt"),k8r=o(" \u2014 "),OZ=a("a"),S8r=o("DPTForSemanticSegmentation"),R8r=o(" (DPT model)"),P8r=l(),v3=a("li"),R0e=a("strong"),B8r=o("mobilevit"),I8r=o(" \u2014 "),VZ=a("a"),N8r=o("MobileViTForSemanticSegmentation"),q8r=o(" (MobileViT model)"),j8r=l(),F3=a("li"),P0e=a("strong"),D8r=o("segformer"),G8r=o(" \u2014 "),XZ=a("a"),O8r=o("SegformerForSemanticSegmentation"),V8r=o(" (SegFormer model)"),X8r=l(),T3=a("p"),z8r=o("The model is set in evaluation mode by default using "),B0e=a("code"),Q8r=o("model.eval()"),W8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I0e=a("code"),U8r=o("model.train()"),H8r=l(),F(M3.$$.fragment),weo=l(),jc=a("h2"),E3=a("a"),N0e=a("span"),F(qk.$$.fragment),J8r=l(),q0e=a("span"),Y8r=o("AutoModelForInstanceSegmentation"),Aeo=l(),nr=a("div"),F(jk.$$.fragment),K8r=l(),Dc=a("p"),Z8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),zZ=a("a"),e9r=o("from_pretrained()"),o9r=o(" class method or the "),QZ=a("a"),r9r=o("from_config()"),t9r=o(` class
method.`),a9r=l(),Dk=a("p"),n9r=o("This class cannot be instantiated directly using "),j0e=a("code"),s9r=o("__init__()"),l9r=o(" (throws an error)."),i9r=l(),Vt=a("div"),F(Gk.$$.fragment),d9r=l(),D0e=a("p"),c9r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),m9r=l(),Gc=a("p"),f9r=o(`Note:
Loading a model from its configuration file does `),G0e=a("strong"),g9r=o("not"),h9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WZ=a("a"),u9r=o("from_pretrained()"),p9r=o(" to load the model weights."),_9r=l(),F(C3.$$.fragment),b9r=l(),wo=a("div"),F(Ok.$$.fragment),v9r=l(),O0e=a("p"),F9r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),T9r=l(),Cn=a("p"),M9r=o("The model class to instantiate is selected based on the "),V0e=a("code"),E9r=o("model_type"),C9r=o(` property of the config object (either
passed as an argument or loaded from `),X0e=a("code"),w9r=o("pretrained_model_name_or_path"),A9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z0e=a("code"),L9r=o("pretrained_model_name_or_path"),y9r=o(":"),x9r=l(),Q0e=a("ul"),w3=a("li"),W0e=a("strong"),$9r=o("maskformer"),k9r=o(" \u2014 "),UZ=a("a"),S9r=o("MaskFormerForInstanceSegmentation"),R9r=o(" (MaskFormer model)"),P9r=l(),A3=a("p"),B9r=o("The model is set in evaluation mode by default using "),U0e=a("code"),I9r=o("model.eval()"),N9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H0e=a("code"),q9r=o("model.train()"),j9r=l(),F(L3.$$.fragment),Leo=l(),Oc=a("h2"),y3=a("a"),J0e=a("span"),F(Vk.$$.fragment),D9r=l(),Y0e=a("span"),G9r=o("TFAutoModel"),yeo=l(),sr=a("div"),F(Xk.$$.fragment),O9r=l(),Vc=a("p"),V9r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),HZ=a("a"),X9r=o("from_pretrained()"),z9r=o(" class method or the "),JZ=a("a"),Q9r=o("from_config()"),W9r=o(` class
method.`),U9r=l(),zk=a("p"),H9r=o("This class cannot be instantiated directly using "),K0e=a("code"),J9r=o("__init__()"),Y9r=o(" (throws an error)."),K9r=l(),Xt=a("div"),F(Qk.$$.fragment),Z9r=l(),Z0e=a("p"),exr=o("Instantiates one of the base model classes of the library from a configuration."),oxr=l(),Xc=a("p"),rxr=o(`Note:
Loading a model from its configuration file does `),ewe=a("strong"),txr=o("not"),axr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YZ=a("a"),nxr=o("from_pretrained()"),sxr=o(" to load the model weights."),lxr=l(),F(x3.$$.fragment),ixr=l(),Ir=a("div"),F(Wk.$$.fragment),dxr=l(),owe=a("p"),cxr=o("Instantiate one of the base model classes of the library from a pretrained model."),mxr=l(),wn=a("p"),fxr=o("The model class to instantiate is selected based on the "),rwe=a("code"),gxr=o("model_type"),hxr=o(` property of the config object (either
passed as an argument or loaded from `),twe=a("code"),uxr=o("pretrained_model_name_or_path"),pxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),awe=a("code"),_xr=o("pretrained_model_name_or_path"),bxr=o(":"),vxr=l(),B=a("ul"),$3=a("li"),nwe=a("strong"),Fxr=o("albert"),Txr=o(" \u2014 "),KZ=a("a"),Mxr=o("TFAlbertModel"),Exr=o(" (ALBERT model)"),Cxr=l(),k3=a("li"),swe=a("strong"),wxr=o("bart"),Axr=o(" \u2014 "),ZZ=a("a"),Lxr=o("TFBartModel"),yxr=o(" (BART model)"),xxr=l(),S3=a("li"),lwe=a("strong"),$xr=o("bert"),kxr=o(" \u2014 "),eee=a("a"),Sxr=o("TFBertModel"),Rxr=o(" (BERT model)"),Pxr=l(),R3=a("li"),iwe=a("strong"),Bxr=o("blenderbot"),Ixr=o(" \u2014 "),oee=a("a"),Nxr=o("TFBlenderbotModel"),qxr=o(" (Blenderbot model)"),jxr=l(),P3=a("li"),dwe=a("strong"),Dxr=o("blenderbot-small"),Gxr=o(" \u2014 "),ree=a("a"),Oxr=o("TFBlenderbotSmallModel"),Vxr=o(" (BlenderbotSmall model)"),Xxr=l(),B3=a("li"),cwe=a("strong"),zxr=o("camembert"),Qxr=o(" \u2014 "),tee=a("a"),Wxr=o("TFCamembertModel"),Uxr=o(" (CamemBERT model)"),Hxr=l(),I3=a("li"),mwe=a("strong"),Jxr=o("clip"),Yxr=o(" \u2014 "),aee=a("a"),Kxr=o("TFCLIPModel"),Zxr=o(" (CLIP model)"),e$r=l(),N3=a("li"),fwe=a("strong"),o$r=o("convbert"),r$r=o(" \u2014 "),nee=a("a"),t$r=o("TFConvBertModel"),a$r=o(" (ConvBERT model)"),n$r=l(),q3=a("li"),gwe=a("strong"),s$r=o("convnext"),l$r=o(" \u2014 "),see=a("a"),i$r=o("TFConvNextModel"),d$r=o(" (ConvNeXT model)"),c$r=l(),j3=a("li"),hwe=a("strong"),m$r=o("ctrl"),f$r=o(" \u2014 "),lee=a("a"),g$r=o("TFCTRLModel"),h$r=o(" (CTRL model)"),u$r=l(),D3=a("li"),uwe=a("strong"),p$r=o("data2vec-vision"),_$r=o(" \u2014 "),iee=a("a"),b$r=o("TFData2VecVisionModel"),v$r=o(" (Data2VecVision model)"),F$r=l(),G3=a("li"),pwe=a("strong"),T$r=o("deberta"),M$r=o(" \u2014 "),dee=a("a"),E$r=o("TFDebertaModel"),C$r=o(" (DeBERTa model)"),w$r=l(),O3=a("li"),_we=a("strong"),A$r=o("deberta-v2"),L$r=o(" \u2014 "),cee=a("a"),y$r=o("TFDebertaV2Model"),x$r=o(" (DeBERTa-v2 model)"),$$r=l(),V3=a("li"),bwe=a("strong"),k$r=o("deit"),S$r=o(" \u2014 "),mee=a("a"),R$r=o("TFDeiTModel"),P$r=o(" (DeiT model)"),B$r=l(),X3=a("li"),vwe=a("strong"),I$r=o("distilbert"),N$r=o(" \u2014 "),fee=a("a"),q$r=o("TFDistilBertModel"),j$r=o(" (DistilBERT model)"),D$r=l(),z3=a("li"),Fwe=a("strong"),G$r=o("dpr"),O$r=o(" \u2014 "),gee=a("a"),V$r=o("TFDPRQuestionEncoder"),X$r=o(" (DPR model)"),z$r=l(),Q3=a("li"),Twe=a("strong"),Q$r=o("electra"),W$r=o(" \u2014 "),hee=a("a"),U$r=o("TFElectraModel"),H$r=o(" (ELECTRA model)"),J$r=l(),W3=a("li"),Mwe=a("strong"),Y$r=o("flaubert"),K$r=o(" \u2014 "),uee=a("a"),Z$r=o("TFFlaubertModel"),ekr=o(" (FlauBERT model)"),okr=l(),Fl=a("li"),Ewe=a("strong"),rkr=o("funnel"),tkr=o(" \u2014 "),pee=a("a"),akr=o("TFFunnelModel"),nkr=o(" or "),_ee=a("a"),skr=o("TFFunnelBaseModel"),lkr=o(" (Funnel Transformer model)"),ikr=l(),U3=a("li"),Cwe=a("strong"),dkr=o("gpt2"),ckr=o(" \u2014 "),bee=a("a"),mkr=o("TFGPT2Model"),fkr=o(" (OpenAI GPT-2 model)"),gkr=l(),H3=a("li"),wwe=a("strong"),hkr=o("gptj"),ukr=o(" \u2014 "),vee=a("a"),pkr=o("TFGPTJModel"),_kr=o(" (GPT-J model)"),bkr=l(),J3=a("li"),Awe=a("strong"),vkr=o("groupvit"),Fkr=o(" \u2014 "),Fee=a("a"),Tkr=o("TFGroupViTModel"),Mkr=o(" (GroupViT model)"),Ekr=l(),Y3=a("li"),Lwe=a("strong"),Ckr=o("hubert"),wkr=o(" \u2014 "),Tee=a("a"),Akr=o("TFHubertModel"),Lkr=o(" (Hubert model)"),ykr=l(),K3=a("li"),ywe=a("strong"),xkr=o("layoutlm"),$kr=o(" \u2014 "),Mee=a("a"),kkr=o("TFLayoutLMModel"),Skr=o(" (LayoutLM model)"),Rkr=l(),Z3=a("li"),xwe=a("strong"),Pkr=o("layoutlmv3"),Bkr=o(" \u2014 "),Eee=a("a"),Ikr=o("TFLayoutLMv3Model"),Nkr=o(" (LayoutLMv3 model)"),qkr=l(),e5=a("li"),$we=a("strong"),jkr=o("led"),Dkr=o(" \u2014 "),Cee=a("a"),Gkr=o("TFLEDModel"),Okr=o(" (LED model)"),Vkr=l(),o5=a("li"),kwe=a("strong"),Xkr=o("longformer"),zkr=o(" \u2014 "),wee=a("a"),Qkr=o("TFLongformerModel"),Wkr=o(" (Longformer model)"),Ukr=l(),r5=a("li"),Swe=a("strong"),Hkr=o("lxmert"),Jkr=o(" \u2014 "),Aee=a("a"),Ykr=o("TFLxmertModel"),Kkr=o(" (LXMERT model)"),Zkr=l(),t5=a("li"),Rwe=a("strong"),eSr=o("marian"),oSr=o(" \u2014 "),Lee=a("a"),rSr=o("TFMarianModel"),tSr=o(" (Marian model)"),aSr=l(),a5=a("li"),Pwe=a("strong"),nSr=o("mbart"),sSr=o(" \u2014 "),yee=a("a"),lSr=o("TFMBartModel"),iSr=o(" (mBART model)"),dSr=l(),n5=a("li"),Bwe=a("strong"),cSr=o("mobilebert"),mSr=o(" \u2014 "),xee=a("a"),fSr=o("TFMobileBertModel"),gSr=o(" (MobileBERT model)"),hSr=l(),s5=a("li"),Iwe=a("strong"),uSr=o("mobilevit"),pSr=o(" \u2014 "),$ee=a("a"),_Sr=o("TFMobileViTModel"),bSr=o(" (MobileViT model)"),vSr=l(),l5=a("li"),Nwe=a("strong"),FSr=o("mpnet"),TSr=o(" \u2014 "),kee=a("a"),MSr=o("TFMPNetModel"),ESr=o(" (MPNet model)"),CSr=l(),i5=a("li"),qwe=a("strong"),wSr=o("mt5"),ASr=o(" \u2014 "),See=a("a"),LSr=o("TFMT5Model"),ySr=o(" (MT5 model)"),xSr=l(),d5=a("li"),jwe=a("strong"),$Sr=o("openai-gpt"),kSr=o(" \u2014 "),Ree=a("a"),SSr=o("TFOpenAIGPTModel"),RSr=o(" (OpenAI GPT model)"),PSr=l(),c5=a("li"),Dwe=a("strong"),BSr=o("opt"),ISr=o(" \u2014 "),Pee=a("a"),NSr=o("TFOPTModel"),qSr=o(" (OPT model)"),jSr=l(),m5=a("li"),Gwe=a("strong"),DSr=o("pegasus"),GSr=o(" \u2014 "),Bee=a("a"),OSr=o("TFPegasusModel"),VSr=o(" (Pegasus model)"),XSr=l(),f5=a("li"),Owe=a("strong"),zSr=o("regnet"),QSr=o(" \u2014 "),Iee=a("a"),WSr=o("TFRegNetModel"),USr=o(" (RegNet model)"),HSr=l(),g5=a("li"),Vwe=a("strong"),JSr=o("rembert"),YSr=o(" \u2014 "),Nee=a("a"),KSr=o("TFRemBertModel"),ZSr=o(" (RemBERT model)"),eRr=l(),h5=a("li"),Xwe=a("strong"),oRr=o("resnet"),rRr=o(" \u2014 "),qee=a("a"),tRr=o("TFResNetModel"),aRr=o(" (ResNet model)"),nRr=l(),u5=a("li"),zwe=a("strong"),sRr=o("roberta"),lRr=o(" \u2014 "),jee=a("a"),iRr=o("TFRobertaModel"),dRr=o(" (RoBERTa model)"),cRr=l(),p5=a("li"),Qwe=a("strong"),mRr=o("roformer"),fRr=o(" \u2014 "),Dee=a("a"),gRr=o("TFRoFormerModel"),hRr=o(" (RoFormer model)"),uRr=l(),_5=a("li"),Wwe=a("strong"),pRr=o("segformer"),_Rr=o(" \u2014 "),Gee=a("a"),bRr=o("TFSegformerModel"),vRr=o(" (SegFormer model)"),FRr=l(),b5=a("li"),Uwe=a("strong"),TRr=o("speech_to_text"),MRr=o(" \u2014 "),Oee=a("a"),ERr=o("TFSpeech2TextModel"),CRr=o(" (Speech2Text model)"),wRr=l(),v5=a("li"),Hwe=a("strong"),ARr=o("swin"),LRr=o(" \u2014 "),Vee=a("a"),yRr=o("TFSwinModel"),xRr=o(" (Swin Transformer model)"),$Rr=l(),F5=a("li"),Jwe=a("strong"),kRr=o("t5"),SRr=o(" \u2014 "),Xee=a("a"),RRr=o("TFT5Model"),PRr=o(" (T5 model)"),BRr=l(),T5=a("li"),Ywe=a("strong"),IRr=o("tapas"),NRr=o(" \u2014 "),zee=a("a"),qRr=o("TFTapasModel"),jRr=o(" (TAPAS model)"),DRr=l(),M5=a("li"),Kwe=a("strong"),GRr=o("transfo-xl"),ORr=o(" \u2014 "),Qee=a("a"),VRr=o("TFTransfoXLModel"),XRr=o(" (Transformer-XL model)"),zRr=l(),E5=a("li"),Zwe=a("strong"),QRr=o("vit"),WRr=o(" \u2014 "),Wee=a("a"),URr=o("TFViTModel"),HRr=o(" (ViT model)"),JRr=l(),C5=a("li"),eAe=a("strong"),YRr=o("vit_mae"),KRr=o(" \u2014 "),Uee=a("a"),ZRr=o("TFViTMAEModel"),ePr=o(" (ViTMAE model)"),oPr=l(),w5=a("li"),oAe=a("strong"),rPr=o("wav2vec2"),tPr=o(" \u2014 "),Hee=a("a"),aPr=o("TFWav2Vec2Model"),nPr=o(" (Wav2Vec2 model)"),sPr=l(),A5=a("li"),rAe=a("strong"),lPr=o("xglm"),iPr=o(" \u2014 "),Jee=a("a"),dPr=o("TFXGLMModel"),cPr=o(" (XGLM model)"),mPr=l(),L5=a("li"),tAe=a("strong"),fPr=o("xlm"),gPr=o(" \u2014 "),Yee=a("a"),hPr=o("TFXLMModel"),uPr=o(" (XLM model)"),pPr=l(),y5=a("li"),aAe=a("strong"),_Pr=o("xlm-roberta"),bPr=o(" \u2014 "),Kee=a("a"),vPr=o("TFXLMRobertaModel"),FPr=o(" (XLM-RoBERTa model)"),TPr=l(),x5=a("li"),nAe=a("strong"),MPr=o("xlnet"),EPr=o(" \u2014 "),Zee=a("a"),CPr=o("TFXLNetModel"),wPr=o(" (XLNet model)"),APr=l(),F($5.$$.fragment),xeo=l(),zc=a("h2"),k5=a("a"),sAe=a("span"),F(Uk.$$.fragment),LPr=l(),lAe=a("span"),yPr=o("TFAutoModelForPreTraining"),$eo=l(),lr=a("div"),F(Hk.$$.fragment),xPr=l(),Qc=a("p"),$Pr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),eoe=a("a"),kPr=o("from_pretrained()"),SPr=o(" class method or the "),ooe=a("a"),RPr=o("from_config()"),PPr=o(` class
method.`),BPr=l(),Jk=a("p"),IPr=o("This class cannot be instantiated directly using "),iAe=a("code"),NPr=o("__init__()"),qPr=o(" (throws an error)."),jPr=l(),zt=a("div"),F(Yk.$$.fragment),DPr=l(),dAe=a("p"),GPr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),OPr=l(),Wc=a("p"),VPr=o(`Note:
Loading a model from its configuration file does `),cAe=a("strong"),XPr=o("not"),zPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=a("a"),QPr=o("from_pretrained()"),WPr=o(" to load the model weights."),UPr=l(),F(S5.$$.fragment),HPr=l(),Nr=a("div"),F(Kk.$$.fragment),JPr=l(),mAe=a("p"),YPr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KPr=l(),An=a("p"),ZPr=o("The model class to instantiate is selected based on the "),fAe=a("code"),eBr=o("model_type"),oBr=o(` property of the config object (either
passed as an argument or loaded from `),gAe=a("code"),rBr=o("pretrained_model_name_or_path"),tBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hAe=a("code"),aBr=o("pretrained_model_name_or_path"),nBr=o(":"),sBr=l(),se=a("ul"),R5=a("li"),uAe=a("strong"),lBr=o("albert"),iBr=o(" \u2014 "),toe=a("a"),dBr=o("TFAlbertForPreTraining"),cBr=o(" (ALBERT model)"),mBr=l(),P5=a("li"),pAe=a("strong"),fBr=o("bart"),gBr=o(" \u2014 "),aoe=a("a"),hBr=o("TFBartForConditionalGeneration"),uBr=o(" (BART model)"),pBr=l(),B5=a("li"),_Ae=a("strong"),_Br=o("bert"),bBr=o(" \u2014 "),noe=a("a"),vBr=o("TFBertForPreTraining"),FBr=o(" (BERT model)"),TBr=l(),I5=a("li"),bAe=a("strong"),MBr=o("camembert"),EBr=o(" \u2014 "),soe=a("a"),CBr=o("TFCamembertForMaskedLM"),wBr=o(" (CamemBERT model)"),ABr=l(),N5=a("li"),vAe=a("strong"),LBr=o("ctrl"),yBr=o(" \u2014 "),loe=a("a"),xBr=o("TFCTRLLMHeadModel"),$Br=o(" (CTRL model)"),kBr=l(),q5=a("li"),FAe=a("strong"),SBr=o("distilbert"),RBr=o(" \u2014 "),ioe=a("a"),PBr=o("TFDistilBertForMaskedLM"),BBr=o(" (DistilBERT model)"),IBr=l(),j5=a("li"),TAe=a("strong"),NBr=o("electra"),qBr=o(" \u2014 "),doe=a("a"),jBr=o("TFElectraForPreTraining"),DBr=o(" (ELECTRA model)"),GBr=l(),D5=a("li"),MAe=a("strong"),OBr=o("flaubert"),VBr=o(" \u2014 "),coe=a("a"),XBr=o("TFFlaubertWithLMHeadModel"),zBr=o(" (FlauBERT model)"),QBr=l(),G5=a("li"),EAe=a("strong"),WBr=o("funnel"),UBr=o(" \u2014 "),moe=a("a"),HBr=o("TFFunnelForPreTraining"),JBr=o(" (Funnel Transformer model)"),YBr=l(),O5=a("li"),CAe=a("strong"),KBr=o("gpt2"),ZBr=o(" \u2014 "),foe=a("a"),eIr=o("TFGPT2LMHeadModel"),oIr=o(" (OpenAI GPT-2 model)"),rIr=l(),V5=a("li"),wAe=a("strong"),tIr=o("layoutlm"),aIr=o(" \u2014 "),goe=a("a"),nIr=o("TFLayoutLMForMaskedLM"),sIr=o(" (LayoutLM model)"),lIr=l(),X5=a("li"),AAe=a("strong"),iIr=o("lxmert"),dIr=o(" \u2014 "),hoe=a("a"),cIr=o("TFLxmertForPreTraining"),mIr=o(" (LXMERT model)"),fIr=l(),z5=a("li"),LAe=a("strong"),gIr=o("mobilebert"),hIr=o(" \u2014 "),uoe=a("a"),uIr=o("TFMobileBertForPreTraining"),pIr=o(" (MobileBERT model)"),_Ir=l(),Q5=a("li"),yAe=a("strong"),bIr=o("mpnet"),vIr=o(" \u2014 "),poe=a("a"),FIr=o("TFMPNetForMaskedLM"),TIr=o(" (MPNet model)"),MIr=l(),W5=a("li"),xAe=a("strong"),EIr=o("openai-gpt"),CIr=o(" \u2014 "),_oe=a("a"),wIr=o("TFOpenAIGPTLMHeadModel"),AIr=o(" (OpenAI GPT model)"),LIr=l(),U5=a("li"),$Ae=a("strong"),yIr=o("roberta"),xIr=o(" \u2014 "),boe=a("a"),$Ir=o("TFRobertaForMaskedLM"),kIr=o(" (RoBERTa model)"),SIr=l(),H5=a("li"),kAe=a("strong"),RIr=o("t5"),PIr=o(" \u2014 "),voe=a("a"),BIr=o("TFT5ForConditionalGeneration"),IIr=o(" (T5 model)"),NIr=l(),J5=a("li"),SAe=a("strong"),qIr=o("tapas"),jIr=o(" \u2014 "),Foe=a("a"),DIr=o("TFTapasForMaskedLM"),GIr=o(" (TAPAS model)"),OIr=l(),Y5=a("li"),RAe=a("strong"),VIr=o("transfo-xl"),XIr=o(" \u2014 "),Toe=a("a"),zIr=o("TFTransfoXLLMHeadModel"),QIr=o(" (Transformer-XL model)"),WIr=l(),K5=a("li"),PAe=a("strong"),UIr=o("vit_mae"),HIr=o(" \u2014 "),Moe=a("a"),JIr=o("TFViTMAEForPreTraining"),YIr=o(" (ViTMAE model)"),KIr=l(),Z5=a("li"),BAe=a("strong"),ZIr=o("xlm"),eNr=o(" \u2014 "),Eoe=a("a"),oNr=o("TFXLMWithLMHeadModel"),rNr=o(" (XLM model)"),tNr=l(),e0=a("li"),IAe=a("strong"),aNr=o("xlm-roberta"),nNr=o(" \u2014 "),Coe=a("a"),sNr=o("TFXLMRobertaForMaskedLM"),lNr=o(" (XLM-RoBERTa model)"),iNr=l(),o0=a("li"),NAe=a("strong"),dNr=o("xlnet"),cNr=o(" \u2014 "),woe=a("a"),mNr=o("TFXLNetLMHeadModel"),fNr=o(" (XLNet model)"),gNr=l(),F(r0.$$.fragment),keo=l(),Uc=a("h2"),t0=a("a"),qAe=a("span"),F(Zk.$$.fragment),hNr=l(),jAe=a("span"),uNr=o("TFAutoModelForCausalLM"),Seo=l(),ir=a("div"),F(eS.$$.fragment),pNr=l(),Hc=a("p"),_Nr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Aoe=a("a"),bNr=o("from_pretrained()"),vNr=o(" class method or the "),Loe=a("a"),FNr=o("from_config()"),TNr=o(` class
method.`),MNr=l(),oS=a("p"),ENr=o("This class cannot be instantiated directly using "),DAe=a("code"),CNr=o("__init__()"),wNr=o(" (throws an error)."),ANr=l(),Qt=a("div"),F(rS.$$.fragment),LNr=l(),GAe=a("p"),yNr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),xNr=l(),Jc=a("p"),$Nr=o(`Note:
Loading a model from its configuration file does `),OAe=a("strong"),kNr=o("not"),SNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=a("a"),RNr=o("from_pretrained()"),PNr=o(" to load the model weights."),BNr=l(),F(a0.$$.fragment),INr=l(),qr=a("div"),F(tS.$$.fragment),NNr=l(),VAe=a("p"),qNr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),jNr=l(),Ln=a("p"),DNr=o("The model class to instantiate is selected based on the "),XAe=a("code"),GNr=o("model_type"),ONr=o(` property of the config object (either
passed as an argument or loaded from `),zAe=a("code"),VNr=o("pretrained_model_name_or_path"),XNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QAe=a("code"),zNr=o("pretrained_model_name_or_path"),QNr=o(":"),WNr=l(),Me=a("ul"),n0=a("li"),WAe=a("strong"),UNr=o("bert"),HNr=o(" \u2014 "),xoe=a("a"),JNr=o("TFBertLMHeadModel"),YNr=o(" (BERT model)"),KNr=l(),s0=a("li"),UAe=a("strong"),ZNr=o("camembert"),eqr=o(" \u2014 "),$oe=a("a"),oqr=o("TFCamembertForCausalLM"),rqr=o(" (CamemBERT model)"),tqr=l(),l0=a("li"),HAe=a("strong"),aqr=o("ctrl"),nqr=o(" \u2014 "),koe=a("a"),sqr=o("TFCTRLLMHeadModel"),lqr=o(" (CTRL model)"),iqr=l(),i0=a("li"),JAe=a("strong"),dqr=o("gpt2"),cqr=o(" \u2014 "),Soe=a("a"),mqr=o("TFGPT2LMHeadModel"),fqr=o(" (OpenAI GPT-2 model)"),gqr=l(),d0=a("li"),YAe=a("strong"),hqr=o("gptj"),uqr=o(" \u2014 "),Roe=a("a"),pqr=o("TFGPTJForCausalLM"),_qr=o(" (GPT-J model)"),bqr=l(),c0=a("li"),KAe=a("strong"),vqr=o("openai-gpt"),Fqr=o(" \u2014 "),Poe=a("a"),Tqr=o("TFOpenAIGPTLMHeadModel"),Mqr=o(" (OpenAI GPT model)"),Eqr=l(),m0=a("li"),ZAe=a("strong"),Cqr=o("opt"),wqr=o(" \u2014 "),Boe=a("a"),Aqr=o("TFOPTForCausalLM"),Lqr=o(" (OPT model)"),yqr=l(),f0=a("li"),e6e=a("strong"),xqr=o("rembert"),$qr=o(" \u2014 "),Ioe=a("a"),kqr=o("TFRemBertForCausalLM"),Sqr=o(" (RemBERT model)"),Rqr=l(),g0=a("li"),o6e=a("strong"),Pqr=o("roberta"),Bqr=o(" \u2014 "),Noe=a("a"),Iqr=o("TFRobertaForCausalLM"),Nqr=o(" (RoBERTa model)"),qqr=l(),h0=a("li"),r6e=a("strong"),jqr=o("roformer"),Dqr=o(" \u2014 "),qoe=a("a"),Gqr=o("TFRoFormerForCausalLM"),Oqr=o(" (RoFormer model)"),Vqr=l(),u0=a("li"),t6e=a("strong"),Xqr=o("transfo-xl"),zqr=o(" \u2014 "),joe=a("a"),Qqr=o("TFTransfoXLLMHeadModel"),Wqr=o(" (Transformer-XL model)"),Uqr=l(),p0=a("li"),a6e=a("strong"),Hqr=o("xglm"),Jqr=o(" \u2014 "),Doe=a("a"),Yqr=o("TFXGLMForCausalLM"),Kqr=o(" (XGLM model)"),Zqr=l(),_0=a("li"),n6e=a("strong"),ejr=o("xlm"),ojr=o(" \u2014 "),Goe=a("a"),rjr=o("TFXLMWithLMHeadModel"),tjr=o(" (XLM model)"),ajr=l(),b0=a("li"),s6e=a("strong"),njr=o("xlnet"),sjr=o(" \u2014 "),Ooe=a("a"),ljr=o("TFXLNetLMHeadModel"),ijr=o(" (XLNet model)"),djr=l(),F(v0.$$.fragment),Reo=l(),Yc=a("h2"),F0=a("a"),l6e=a("span"),F(aS.$$.fragment),cjr=l(),i6e=a("span"),mjr=o("TFAutoModelForImageClassification"),Peo=l(),dr=a("div"),F(nS.$$.fragment),fjr=l(),Kc=a("p"),gjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Voe=a("a"),hjr=o("from_pretrained()"),ujr=o(" class method or the "),Xoe=a("a"),pjr=o("from_config()"),_jr=o(` class
method.`),bjr=l(),sS=a("p"),vjr=o("This class cannot be instantiated directly using "),d6e=a("code"),Fjr=o("__init__()"),Tjr=o(" (throws an error)."),Mjr=l(),Wt=a("div"),F(lS.$$.fragment),Ejr=l(),c6e=a("p"),Cjr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wjr=l(),Zc=a("p"),Ajr=o(`Note:
Loading a model from its configuration file does `),m6e=a("strong"),Ljr=o("not"),yjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=a("a"),xjr=o("from_pretrained()"),$jr=o(" to load the model weights."),kjr=l(),F(T0.$$.fragment),Sjr=l(),jr=a("div"),F(iS.$$.fragment),Rjr=l(),f6e=a("p"),Pjr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Bjr=l(),yn=a("p"),Ijr=o("The model class to instantiate is selected based on the "),g6e=a("code"),Njr=o("model_type"),qjr=o(` property of the config object (either
passed as an argument or loaded from `),h6e=a("code"),jjr=o("pretrained_model_name_or_path"),Djr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u6e=a("code"),Gjr=o("pretrained_model_name_or_path"),Ojr=o(":"),Vjr=l(),Be=a("ul"),M0=a("li"),p6e=a("strong"),Xjr=o("convnext"),zjr=o(" \u2014 "),Qoe=a("a"),Qjr=o("TFConvNextForImageClassification"),Wjr=o(" (ConvNeXT model)"),Ujr=l(),E0=a("li"),_6e=a("strong"),Hjr=o("data2vec-vision"),Jjr=o(" \u2014 "),Woe=a("a"),Yjr=o("TFData2VecVisionForImageClassification"),Kjr=o(" (Data2VecVision model)"),Zjr=l(),Tl=a("li"),b6e=a("strong"),eDr=o("deit"),oDr=o(" \u2014 "),Uoe=a("a"),rDr=o("TFDeiTForImageClassification"),tDr=o(" or "),Hoe=a("a"),aDr=o("TFDeiTForImageClassificationWithTeacher"),nDr=o(" (DeiT model)"),sDr=l(),C0=a("li"),v6e=a("strong"),lDr=o("mobilevit"),iDr=o(" \u2014 "),Joe=a("a"),dDr=o("TFMobileViTForImageClassification"),cDr=o(" (MobileViT model)"),mDr=l(),w0=a("li"),F6e=a("strong"),fDr=o("regnet"),gDr=o(" \u2014 "),Yoe=a("a"),hDr=o("TFRegNetForImageClassification"),uDr=o(" (RegNet model)"),pDr=l(),A0=a("li"),T6e=a("strong"),_Dr=o("resnet"),bDr=o(" \u2014 "),Koe=a("a"),vDr=o("TFResNetForImageClassification"),FDr=o(" (ResNet model)"),TDr=l(),L0=a("li"),M6e=a("strong"),MDr=o("segformer"),EDr=o(" \u2014 "),Zoe=a("a"),CDr=o("TFSegformerForImageClassification"),wDr=o(" (SegFormer model)"),ADr=l(),y0=a("li"),E6e=a("strong"),LDr=o("swin"),yDr=o(" \u2014 "),ere=a("a"),xDr=o("TFSwinForImageClassification"),$Dr=o(" (Swin Transformer model)"),kDr=l(),x0=a("li"),C6e=a("strong"),SDr=o("vit"),RDr=o(" \u2014 "),ore=a("a"),PDr=o("TFViTForImageClassification"),BDr=o(" (ViT model)"),IDr=l(),F($0.$$.fragment),Beo=l(),em=a("h2"),k0=a("a"),w6e=a("span"),F(dS.$$.fragment),NDr=l(),A6e=a("span"),qDr=o("TFAutoModelForSemanticSegmentation"),Ieo=l(),cr=a("div"),F(cS.$$.fragment),jDr=l(),om=a("p"),DDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),rre=a("a"),GDr=o("from_pretrained()"),ODr=o(" class method or the "),tre=a("a"),VDr=o("from_config()"),XDr=o(` class
method.`),zDr=l(),mS=a("p"),QDr=o("This class cannot be instantiated directly using "),L6e=a("code"),WDr=o("__init__()"),UDr=o(" (throws an error)."),HDr=l(),Ut=a("div"),F(fS.$$.fragment),JDr=l(),y6e=a("p"),YDr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),KDr=l(),rm=a("p"),ZDr=o(`Note:
Loading a model from its configuration file does `),x6e=a("strong"),eGr=o("not"),oGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),are=a("a"),rGr=o("from_pretrained()"),tGr=o(" to load the model weights."),aGr=l(),F(S0.$$.fragment),nGr=l(),Dr=a("div"),F(gS.$$.fragment),sGr=l(),$6e=a("p"),lGr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),iGr=l(),xn=a("p"),dGr=o("The model class to instantiate is selected based on the "),k6e=a("code"),cGr=o("model_type"),mGr=o(` property of the config object (either
passed as an argument or loaded from `),S6e=a("code"),fGr=o("pretrained_model_name_or_path"),gGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R6e=a("code"),hGr=o("pretrained_model_name_or_path"),uGr=o(":"),pGr=l(),tm=a("ul"),R0=a("li"),P6e=a("strong"),_Gr=o("data2vec-vision"),bGr=o(" \u2014 "),nre=a("a"),vGr=o("TFData2VecVisionForSemanticSegmentation"),FGr=o(" (Data2VecVision model)"),TGr=l(),P0=a("li"),B6e=a("strong"),MGr=o("mobilevit"),EGr=o(" \u2014 "),sre=a("a"),CGr=o("TFMobileViTForSemanticSegmentation"),wGr=o(" (MobileViT model)"),AGr=l(),B0=a("li"),I6e=a("strong"),LGr=o("segformer"),yGr=o(" \u2014 "),lre=a("a"),xGr=o("TFSegformerForSemanticSegmentation"),$Gr=o(" (SegFormer model)"),kGr=l(),F(I0.$$.fragment),Neo=l(),am=a("h2"),N0=a("a"),N6e=a("span"),F(hS.$$.fragment),SGr=l(),q6e=a("span"),RGr=o("TFAutoModelForMaskedLM"),qeo=l(),mr=a("div"),F(uS.$$.fragment),PGr=l(),nm=a("p"),BGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ire=a("a"),IGr=o("from_pretrained()"),NGr=o(" class method or the "),dre=a("a"),qGr=o("from_config()"),jGr=o(` class
method.`),DGr=l(),pS=a("p"),GGr=o("This class cannot be instantiated directly using "),j6e=a("code"),OGr=o("__init__()"),VGr=o(" (throws an error)."),XGr=l(),Ht=a("div"),F(_S.$$.fragment),zGr=l(),D6e=a("p"),QGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),WGr=l(),sm=a("p"),UGr=o(`Note:
Loading a model from its configuration file does `),G6e=a("strong"),HGr=o("not"),JGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cre=a("a"),YGr=o("from_pretrained()"),KGr=o(" to load the model weights."),ZGr=l(),F(q0.$$.fragment),eOr=l(),Gr=a("div"),F(bS.$$.fragment),oOr=l(),O6e=a("p"),rOr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),tOr=l(),$n=a("p"),aOr=o("The model class to instantiate is selected based on the "),V6e=a("code"),nOr=o("model_type"),sOr=o(` property of the config object (either
passed as an argument or loaded from `),X6e=a("code"),lOr=o("pretrained_model_name_or_path"),iOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z6e=a("code"),dOr=o("pretrained_model_name_or_path"),cOr=o(":"),mOr=l(),ge=a("ul"),j0=a("li"),Q6e=a("strong"),fOr=o("albert"),gOr=o(" \u2014 "),mre=a("a"),hOr=o("TFAlbertForMaskedLM"),uOr=o(" (ALBERT model)"),pOr=l(),D0=a("li"),W6e=a("strong"),_Or=o("bert"),bOr=o(" \u2014 "),fre=a("a"),vOr=o("TFBertForMaskedLM"),FOr=o(" (BERT model)"),TOr=l(),G0=a("li"),U6e=a("strong"),MOr=o("camembert"),EOr=o(" \u2014 "),gre=a("a"),COr=o("TFCamembertForMaskedLM"),wOr=o(" (CamemBERT model)"),AOr=l(),O0=a("li"),H6e=a("strong"),LOr=o("convbert"),yOr=o(" \u2014 "),hre=a("a"),xOr=o("TFConvBertForMaskedLM"),$Or=o(" (ConvBERT model)"),kOr=l(),V0=a("li"),J6e=a("strong"),SOr=o("deberta"),ROr=o(" \u2014 "),ure=a("a"),POr=o("TFDebertaForMaskedLM"),BOr=o(" (DeBERTa model)"),IOr=l(),X0=a("li"),Y6e=a("strong"),NOr=o("deberta-v2"),qOr=o(" \u2014 "),pre=a("a"),jOr=o("TFDebertaV2ForMaskedLM"),DOr=o(" (DeBERTa-v2 model)"),GOr=l(),z0=a("li"),K6e=a("strong"),OOr=o("distilbert"),VOr=o(" \u2014 "),_re=a("a"),XOr=o("TFDistilBertForMaskedLM"),zOr=o(" (DistilBERT model)"),QOr=l(),Q0=a("li"),Z6e=a("strong"),WOr=o("electra"),UOr=o(" \u2014 "),bre=a("a"),HOr=o("TFElectraForMaskedLM"),JOr=o(" (ELECTRA model)"),YOr=l(),W0=a("li"),e7e=a("strong"),KOr=o("flaubert"),ZOr=o(" \u2014 "),vre=a("a"),eVr=o("TFFlaubertWithLMHeadModel"),oVr=o(" (FlauBERT model)"),rVr=l(),U0=a("li"),o7e=a("strong"),tVr=o("funnel"),aVr=o(" \u2014 "),Fre=a("a"),nVr=o("TFFunnelForMaskedLM"),sVr=o(" (Funnel Transformer model)"),lVr=l(),H0=a("li"),r7e=a("strong"),iVr=o("layoutlm"),dVr=o(" \u2014 "),Tre=a("a"),cVr=o("TFLayoutLMForMaskedLM"),mVr=o(" (LayoutLM model)"),fVr=l(),J0=a("li"),t7e=a("strong"),gVr=o("longformer"),hVr=o(" \u2014 "),Mre=a("a"),uVr=o("TFLongformerForMaskedLM"),pVr=o(" (Longformer model)"),_Vr=l(),Y0=a("li"),a7e=a("strong"),bVr=o("mobilebert"),vVr=o(" \u2014 "),Ere=a("a"),FVr=o("TFMobileBertForMaskedLM"),TVr=o(" (MobileBERT model)"),MVr=l(),K0=a("li"),n7e=a("strong"),EVr=o("mpnet"),CVr=o(" \u2014 "),Cre=a("a"),wVr=o("TFMPNetForMaskedLM"),AVr=o(" (MPNet model)"),LVr=l(),Z0=a("li"),s7e=a("strong"),yVr=o("rembert"),xVr=o(" \u2014 "),wre=a("a"),$Vr=o("TFRemBertForMaskedLM"),kVr=o(" (RemBERT model)"),SVr=l(),ew=a("li"),l7e=a("strong"),RVr=o("roberta"),PVr=o(" \u2014 "),Are=a("a"),BVr=o("TFRobertaForMaskedLM"),IVr=o(" (RoBERTa model)"),NVr=l(),ow=a("li"),i7e=a("strong"),qVr=o("roformer"),jVr=o(" \u2014 "),Lre=a("a"),DVr=o("TFRoFormerForMaskedLM"),GVr=o(" (RoFormer model)"),OVr=l(),rw=a("li"),d7e=a("strong"),VVr=o("tapas"),XVr=o(" \u2014 "),yre=a("a"),zVr=o("TFTapasForMaskedLM"),QVr=o(" (TAPAS model)"),WVr=l(),tw=a("li"),c7e=a("strong"),UVr=o("xlm"),HVr=o(" \u2014 "),xre=a("a"),JVr=o("TFXLMWithLMHeadModel"),YVr=o(" (XLM model)"),KVr=l(),aw=a("li"),m7e=a("strong"),ZVr=o("xlm-roberta"),eXr=o(" \u2014 "),$re=a("a"),oXr=o("TFXLMRobertaForMaskedLM"),rXr=o(" (XLM-RoBERTa model)"),tXr=l(),F(nw.$$.fragment),jeo=l(),lm=a("h2"),sw=a("a"),f7e=a("span"),F(vS.$$.fragment),aXr=l(),g7e=a("span"),nXr=o("TFAutoModelForSeq2SeqLM"),Deo=l(),fr=a("div"),F(FS.$$.fragment),sXr=l(),im=a("p"),lXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kre=a("a"),iXr=o("from_pretrained()"),dXr=o(" class method or the "),Sre=a("a"),cXr=o("from_config()"),mXr=o(` class
method.`),fXr=l(),TS=a("p"),gXr=o("This class cannot be instantiated directly using "),h7e=a("code"),hXr=o("__init__()"),uXr=o(" (throws an error)."),pXr=l(),Jt=a("div"),F(MS.$$.fragment),_Xr=l(),u7e=a("p"),bXr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vXr=l(),dm=a("p"),FXr=o(`Note:
Loading a model from its configuration file does `),p7e=a("strong"),TXr=o("not"),MXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=a("a"),EXr=o("from_pretrained()"),CXr=o(" to load the model weights."),wXr=l(),F(lw.$$.fragment),AXr=l(),Or=a("div"),F(ES.$$.fragment),LXr=l(),_7e=a("p"),yXr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xXr=l(),kn=a("p"),$Xr=o("The model class to instantiate is selected based on the "),b7e=a("code"),kXr=o("model_type"),SXr=o(` property of the config object (either
passed as an argument or loaded from `),v7e=a("code"),RXr=o("pretrained_model_name_or_path"),PXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F7e=a("code"),BXr=o("pretrained_model_name_or_path"),IXr=o(":"),NXr=l(),ye=a("ul"),iw=a("li"),T7e=a("strong"),qXr=o("bart"),jXr=o(" \u2014 "),Pre=a("a"),DXr=o("TFBartForConditionalGeneration"),GXr=o(" (BART model)"),OXr=l(),dw=a("li"),M7e=a("strong"),VXr=o("blenderbot"),XXr=o(" \u2014 "),Bre=a("a"),zXr=o("TFBlenderbotForConditionalGeneration"),QXr=o(" (Blenderbot model)"),WXr=l(),cw=a("li"),E7e=a("strong"),UXr=o("blenderbot-small"),HXr=o(" \u2014 "),Ire=a("a"),JXr=o("TFBlenderbotSmallForConditionalGeneration"),YXr=o(" (BlenderbotSmall model)"),KXr=l(),mw=a("li"),C7e=a("strong"),ZXr=o("encoder-decoder"),ezr=o(" \u2014 "),Nre=a("a"),ozr=o("TFEncoderDecoderModel"),rzr=o(" (Encoder decoder model)"),tzr=l(),fw=a("li"),w7e=a("strong"),azr=o("led"),nzr=o(" \u2014 "),qre=a("a"),szr=o("TFLEDForConditionalGeneration"),lzr=o(" (LED model)"),izr=l(),gw=a("li"),A7e=a("strong"),dzr=o("marian"),czr=o(" \u2014 "),jre=a("a"),mzr=o("TFMarianMTModel"),fzr=o(" (Marian model)"),gzr=l(),hw=a("li"),L7e=a("strong"),hzr=o("mbart"),uzr=o(" \u2014 "),Dre=a("a"),pzr=o("TFMBartForConditionalGeneration"),_zr=o(" (mBART model)"),bzr=l(),uw=a("li"),y7e=a("strong"),vzr=o("mt5"),Fzr=o(" \u2014 "),Gre=a("a"),Tzr=o("TFMT5ForConditionalGeneration"),Mzr=o(" (MT5 model)"),Ezr=l(),pw=a("li"),x7e=a("strong"),Czr=o("pegasus"),wzr=o(" \u2014 "),Ore=a("a"),Azr=o("TFPegasusForConditionalGeneration"),Lzr=o(" (Pegasus model)"),yzr=l(),_w=a("li"),$7e=a("strong"),xzr=o("t5"),$zr=o(" \u2014 "),Vre=a("a"),kzr=o("TFT5ForConditionalGeneration"),Szr=o(" (T5 model)"),Rzr=l(),F(bw.$$.fragment),Geo=l(),cm=a("h2"),vw=a("a"),k7e=a("span"),F(CS.$$.fragment),Pzr=l(),S7e=a("span"),Bzr=o("TFAutoModelForSequenceClassification"),Oeo=l(),gr=a("div"),F(wS.$$.fragment),Izr=l(),mm=a("p"),Nzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Xre=a("a"),qzr=o("from_pretrained()"),jzr=o(" class method or the "),zre=a("a"),Dzr=o("from_config()"),Gzr=o(` class
method.`),Ozr=l(),AS=a("p"),Vzr=o("This class cannot be instantiated directly using "),R7e=a("code"),Xzr=o("__init__()"),zzr=o(" (throws an error)."),Qzr=l(),Yt=a("div"),F(LS.$$.fragment),Wzr=l(),P7e=a("p"),Uzr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Hzr=l(),fm=a("p"),Jzr=o(`Note:
Loading a model from its configuration file does `),B7e=a("strong"),Yzr=o("not"),Kzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qre=a("a"),Zzr=o("from_pretrained()"),eQr=o(" to load the model weights."),oQr=l(),F(Fw.$$.fragment),rQr=l(),Vr=a("div"),F(yS.$$.fragment),tQr=l(),I7e=a("p"),aQr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nQr=l(),Sn=a("p"),sQr=o("The model class to instantiate is selected based on the "),N7e=a("code"),lQr=o("model_type"),iQr=o(` property of the config object (either
passed as an argument or loaded from `),q7e=a("code"),dQr=o("pretrained_model_name_or_path"),cQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j7e=a("code"),mQr=o("pretrained_model_name_or_path"),fQr=o(":"),gQr=l(),re=a("ul"),Tw=a("li"),D7e=a("strong"),hQr=o("albert"),uQr=o(" \u2014 "),Wre=a("a"),pQr=o("TFAlbertForSequenceClassification"),_Qr=o(" (ALBERT model)"),bQr=l(),Mw=a("li"),G7e=a("strong"),vQr=o("bert"),FQr=o(" \u2014 "),Ure=a("a"),TQr=o("TFBertForSequenceClassification"),MQr=o(" (BERT model)"),EQr=l(),Ew=a("li"),O7e=a("strong"),CQr=o("camembert"),wQr=o(" \u2014 "),Hre=a("a"),AQr=o("TFCamembertForSequenceClassification"),LQr=o(" (CamemBERT model)"),yQr=l(),Cw=a("li"),V7e=a("strong"),xQr=o("convbert"),$Qr=o(" \u2014 "),Jre=a("a"),kQr=o("TFConvBertForSequenceClassification"),SQr=o(" (ConvBERT model)"),RQr=l(),ww=a("li"),X7e=a("strong"),PQr=o("ctrl"),BQr=o(" \u2014 "),Yre=a("a"),IQr=o("TFCTRLForSequenceClassification"),NQr=o(" (CTRL model)"),qQr=l(),Aw=a("li"),z7e=a("strong"),jQr=o("deberta"),DQr=o(" \u2014 "),Kre=a("a"),GQr=o("TFDebertaForSequenceClassification"),OQr=o(" (DeBERTa model)"),VQr=l(),Lw=a("li"),Q7e=a("strong"),XQr=o("deberta-v2"),zQr=o(" \u2014 "),Zre=a("a"),QQr=o("TFDebertaV2ForSequenceClassification"),WQr=o(" (DeBERTa-v2 model)"),UQr=l(),yw=a("li"),W7e=a("strong"),HQr=o("distilbert"),JQr=o(" \u2014 "),ete=a("a"),YQr=o("TFDistilBertForSequenceClassification"),KQr=o(" (DistilBERT model)"),ZQr=l(),xw=a("li"),U7e=a("strong"),eWr=o("electra"),oWr=o(" \u2014 "),ote=a("a"),rWr=o("TFElectraForSequenceClassification"),tWr=o(" (ELECTRA model)"),aWr=l(),$w=a("li"),H7e=a("strong"),nWr=o("flaubert"),sWr=o(" \u2014 "),rte=a("a"),lWr=o("TFFlaubertForSequenceClassification"),iWr=o(" (FlauBERT model)"),dWr=l(),kw=a("li"),J7e=a("strong"),cWr=o("funnel"),mWr=o(" \u2014 "),tte=a("a"),fWr=o("TFFunnelForSequenceClassification"),gWr=o(" (Funnel Transformer model)"),hWr=l(),Sw=a("li"),Y7e=a("strong"),uWr=o("gpt2"),pWr=o(" \u2014 "),ate=a("a"),_Wr=o("TFGPT2ForSequenceClassification"),bWr=o(" (OpenAI GPT-2 model)"),vWr=l(),Rw=a("li"),K7e=a("strong"),FWr=o("gptj"),TWr=o(" \u2014 "),nte=a("a"),MWr=o("TFGPTJForSequenceClassification"),EWr=o(" (GPT-J model)"),CWr=l(),Pw=a("li"),Z7e=a("strong"),wWr=o("layoutlm"),AWr=o(" \u2014 "),ste=a("a"),LWr=o("TFLayoutLMForSequenceClassification"),yWr=o(" (LayoutLM model)"),xWr=l(),Bw=a("li"),eLe=a("strong"),$Wr=o("layoutlmv3"),kWr=o(" \u2014 "),lte=a("a"),SWr=o("TFLayoutLMv3ForSequenceClassification"),RWr=o(" (LayoutLMv3 model)"),PWr=l(),Iw=a("li"),oLe=a("strong"),BWr=o("longformer"),IWr=o(" \u2014 "),ite=a("a"),NWr=o("TFLongformerForSequenceClassification"),qWr=o(" (Longformer model)"),jWr=l(),Nw=a("li"),rLe=a("strong"),DWr=o("mobilebert"),GWr=o(" \u2014 "),dte=a("a"),OWr=o("TFMobileBertForSequenceClassification"),VWr=o(" (MobileBERT model)"),XWr=l(),qw=a("li"),tLe=a("strong"),zWr=o("mpnet"),QWr=o(" \u2014 "),cte=a("a"),WWr=o("TFMPNetForSequenceClassification"),UWr=o(" (MPNet model)"),HWr=l(),jw=a("li"),aLe=a("strong"),JWr=o("openai-gpt"),YWr=o(" \u2014 "),mte=a("a"),KWr=o("TFOpenAIGPTForSequenceClassification"),ZWr=o(" (OpenAI GPT model)"),eUr=l(),Dw=a("li"),nLe=a("strong"),oUr=o("rembert"),rUr=o(" \u2014 "),fte=a("a"),tUr=o("TFRemBertForSequenceClassification"),aUr=o(" (RemBERT model)"),nUr=l(),Gw=a("li"),sLe=a("strong"),sUr=o("roberta"),lUr=o(" \u2014 "),gte=a("a"),iUr=o("TFRobertaForSequenceClassification"),dUr=o(" (RoBERTa model)"),cUr=l(),Ow=a("li"),lLe=a("strong"),mUr=o("roformer"),fUr=o(" \u2014 "),hte=a("a"),gUr=o("TFRoFormerForSequenceClassification"),hUr=o(" (RoFormer model)"),uUr=l(),Vw=a("li"),iLe=a("strong"),pUr=o("tapas"),_Ur=o(" \u2014 "),ute=a("a"),bUr=o("TFTapasForSequenceClassification"),vUr=o(" (TAPAS model)"),FUr=l(),Xw=a("li"),dLe=a("strong"),TUr=o("transfo-xl"),MUr=o(" \u2014 "),pte=a("a"),EUr=o("TFTransfoXLForSequenceClassification"),CUr=o(" (Transformer-XL model)"),wUr=l(),zw=a("li"),cLe=a("strong"),AUr=o("xlm"),LUr=o(" \u2014 "),_te=a("a"),yUr=o("TFXLMForSequenceClassification"),xUr=o(" (XLM model)"),$Ur=l(),Qw=a("li"),mLe=a("strong"),kUr=o("xlm-roberta"),SUr=o(" \u2014 "),bte=a("a"),RUr=o("TFXLMRobertaForSequenceClassification"),PUr=o(" (XLM-RoBERTa model)"),BUr=l(),Ww=a("li"),fLe=a("strong"),IUr=o("xlnet"),NUr=o(" \u2014 "),vte=a("a"),qUr=o("TFXLNetForSequenceClassification"),jUr=o(" (XLNet model)"),DUr=l(),F(Uw.$$.fragment),Veo=l(),gm=a("h2"),Hw=a("a"),gLe=a("span"),F(xS.$$.fragment),GUr=l(),hLe=a("span"),OUr=o("TFAutoModelForMultipleChoice"),Xeo=l(),hr=a("div"),F($S.$$.fragment),VUr=l(),hm=a("p"),XUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Fte=a("a"),zUr=o("from_pretrained()"),QUr=o(" class method or the "),Tte=a("a"),WUr=o("from_config()"),UUr=o(` class
method.`),HUr=l(),kS=a("p"),JUr=o("This class cannot be instantiated directly using "),uLe=a("code"),YUr=o("__init__()"),KUr=o(" (throws an error)."),ZUr=l(),Kt=a("div"),F(SS.$$.fragment),eHr=l(),pLe=a("p"),oHr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),rHr=l(),um=a("p"),tHr=o(`Note:
Loading a model from its configuration file does `),_Le=a("strong"),aHr=o("not"),nHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mte=a("a"),sHr=o("from_pretrained()"),lHr=o(" to load the model weights."),iHr=l(),F(Jw.$$.fragment),dHr=l(),Xr=a("div"),F(RS.$$.fragment),cHr=l(),bLe=a("p"),mHr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),fHr=l(),Rn=a("p"),gHr=o("The model class to instantiate is selected based on the "),vLe=a("code"),hHr=o("model_type"),uHr=o(` property of the config object (either
passed as an argument or loaded from `),FLe=a("code"),pHr=o("pretrained_model_name_or_path"),_Hr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TLe=a("code"),bHr=o("pretrained_model_name_or_path"),vHr=o(":"),FHr=l(),ve=a("ul"),Yw=a("li"),MLe=a("strong"),THr=o("albert"),MHr=o(" \u2014 "),Ete=a("a"),EHr=o("TFAlbertForMultipleChoice"),CHr=o(" (ALBERT model)"),wHr=l(),Kw=a("li"),ELe=a("strong"),AHr=o("bert"),LHr=o(" \u2014 "),Cte=a("a"),yHr=o("TFBertForMultipleChoice"),xHr=o(" (BERT model)"),$Hr=l(),Zw=a("li"),CLe=a("strong"),kHr=o("camembert"),SHr=o(" \u2014 "),wte=a("a"),RHr=o("TFCamembertForMultipleChoice"),PHr=o(" (CamemBERT model)"),BHr=l(),eA=a("li"),wLe=a("strong"),IHr=o("convbert"),NHr=o(" \u2014 "),Ate=a("a"),qHr=o("TFConvBertForMultipleChoice"),jHr=o(" (ConvBERT model)"),DHr=l(),oA=a("li"),ALe=a("strong"),GHr=o("distilbert"),OHr=o(" \u2014 "),Lte=a("a"),VHr=o("TFDistilBertForMultipleChoice"),XHr=o(" (DistilBERT model)"),zHr=l(),rA=a("li"),LLe=a("strong"),QHr=o("electra"),WHr=o(" \u2014 "),yte=a("a"),UHr=o("TFElectraForMultipleChoice"),HHr=o(" (ELECTRA model)"),JHr=l(),tA=a("li"),yLe=a("strong"),YHr=o("flaubert"),KHr=o(" \u2014 "),xte=a("a"),ZHr=o("TFFlaubertForMultipleChoice"),eJr=o(" (FlauBERT model)"),oJr=l(),aA=a("li"),xLe=a("strong"),rJr=o("funnel"),tJr=o(" \u2014 "),$te=a("a"),aJr=o("TFFunnelForMultipleChoice"),nJr=o(" (Funnel Transformer model)"),sJr=l(),nA=a("li"),$Le=a("strong"),lJr=o("longformer"),iJr=o(" \u2014 "),kte=a("a"),dJr=o("TFLongformerForMultipleChoice"),cJr=o(" (Longformer model)"),mJr=l(),sA=a("li"),kLe=a("strong"),fJr=o("mobilebert"),gJr=o(" \u2014 "),Ste=a("a"),hJr=o("TFMobileBertForMultipleChoice"),uJr=o(" (MobileBERT model)"),pJr=l(),lA=a("li"),SLe=a("strong"),_Jr=o("mpnet"),bJr=o(" \u2014 "),Rte=a("a"),vJr=o("TFMPNetForMultipleChoice"),FJr=o(" (MPNet model)"),TJr=l(),iA=a("li"),RLe=a("strong"),MJr=o("rembert"),EJr=o(" \u2014 "),Pte=a("a"),CJr=o("TFRemBertForMultipleChoice"),wJr=o(" (RemBERT model)"),AJr=l(),dA=a("li"),PLe=a("strong"),LJr=o("roberta"),yJr=o(" \u2014 "),Bte=a("a"),xJr=o("TFRobertaForMultipleChoice"),$Jr=o(" (RoBERTa model)"),kJr=l(),cA=a("li"),BLe=a("strong"),SJr=o("roformer"),RJr=o(" \u2014 "),Ite=a("a"),PJr=o("TFRoFormerForMultipleChoice"),BJr=o(" (RoFormer model)"),IJr=l(),mA=a("li"),ILe=a("strong"),NJr=o("xlm"),qJr=o(" \u2014 "),Nte=a("a"),jJr=o("TFXLMForMultipleChoice"),DJr=o(" (XLM model)"),GJr=l(),fA=a("li"),NLe=a("strong"),OJr=o("xlm-roberta"),VJr=o(" \u2014 "),qte=a("a"),XJr=o("TFXLMRobertaForMultipleChoice"),zJr=o(" (XLM-RoBERTa model)"),QJr=l(),gA=a("li"),qLe=a("strong"),WJr=o("xlnet"),UJr=o(" \u2014 "),jte=a("a"),HJr=o("TFXLNetForMultipleChoice"),JJr=o(" (XLNet model)"),YJr=l(),F(hA.$$.fragment),zeo=l(),pm=a("h2"),uA=a("a"),jLe=a("span"),F(PS.$$.fragment),KJr=l(),DLe=a("span"),ZJr=o("TFAutoModelForNextSentencePrediction"),Qeo=l(),ur=a("div"),F(BS.$$.fragment),eYr=l(),_m=a("p"),oYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Dte=a("a"),rYr=o("from_pretrained()"),tYr=o(" class method or the "),Gte=a("a"),aYr=o("from_config()"),nYr=o(` class
method.`),sYr=l(),IS=a("p"),lYr=o("This class cannot be instantiated directly using "),GLe=a("code"),iYr=o("__init__()"),dYr=o(" (throws an error)."),cYr=l(),Zt=a("div"),F(NS.$$.fragment),mYr=l(),OLe=a("p"),fYr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gYr=l(),bm=a("p"),hYr=o(`Note:
Loading a model from its configuration file does `),VLe=a("strong"),uYr=o("not"),pYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ote=a("a"),_Yr=o("from_pretrained()"),bYr=o(" to load the model weights."),vYr=l(),F(pA.$$.fragment),FYr=l(),zr=a("div"),F(qS.$$.fragment),TYr=l(),XLe=a("p"),MYr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),EYr=l(),Pn=a("p"),CYr=o("The model class to instantiate is selected based on the "),zLe=a("code"),wYr=o("model_type"),AYr=o(` property of the config object (either
passed as an argument or loaded from `),QLe=a("code"),LYr=o("pretrained_model_name_or_path"),yYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WLe=a("code"),xYr=o("pretrained_model_name_or_path"),$Yr=o(":"),kYr=l(),jS=a("ul"),_A=a("li"),ULe=a("strong"),SYr=o("bert"),RYr=o(" \u2014 "),Vte=a("a"),PYr=o("TFBertForNextSentencePrediction"),BYr=o(" (BERT model)"),IYr=l(),bA=a("li"),HLe=a("strong"),NYr=o("mobilebert"),qYr=o(" \u2014 "),Xte=a("a"),jYr=o("TFMobileBertForNextSentencePrediction"),DYr=o(" (MobileBERT model)"),GYr=l(),F(vA.$$.fragment),Weo=l(),vm=a("h2"),FA=a("a"),JLe=a("span"),F(DS.$$.fragment),OYr=l(),YLe=a("span"),VYr=o("TFAutoModelForTableQuestionAnswering"),Ueo=l(),pr=a("div"),F(GS.$$.fragment),XYr=l(),Fm=a("p"),zYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zte=a("a"),QYr=o("from_pretrained()"),WYr=o(" class method or the "),Qte=a("a"),UYr=o("from_config()"),HYr=o(` class
method.`),JYr=l(),OS=a("p"),YYr=o("This class cannot be instantiated directly using "),KLe=a("code"),KYr=o("__init__()"),ZYr=o(" (throws an error)."),eKr=l(),ea=a("div"),F(VS.$$.fragment),oKr=l(),ZLe=a("p"),rKr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),tKr=l(),Tm=a("p"),aKr=o(`Note:
Loading a model from its configuration file does `),eye=a("strong"),nKr=o("not"),sKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wte=a("a"),lKr=o("from_pretrained()"),iKr=o(" to load the model weights."),dKr=l(),F(TA.$$.fragment),cKr=l(),Qr=a("div"),F(XS.$$.fragment),mKr=l(),oye=a("p"),fKr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),gKr=l(),Bn=a("p"),hKr=o("The model class to instantiate is selected based on the "),rye=a("code"),uKr=o("model_type"),pKr=o(` property of the config object (either
passed as an argument or loaded from `),tye=a("code"),_Kr=o("pretrained_model_name_or_path"),bKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aye=a("code"),vKr=o("pretrained_model_name_or_path"),FKr=o(":"),TKr=l(),nye=a("ul"),MA=a("li"),sye=a("strong"),MKr=o("tapas"),EKr=o(" \u2014 "),Ute=a("a"),CKr=o("TFTapasForQuestionAnswering"),wKr=o(" (TAPAS model)"),AKr=l(),F(EA.$$.fragment),Heo=l(),Mm=a("h2"),CA=a("a"),lye=a("span"),F(zS.$$.fragment),LKr=l(),iye=a("span"),yKr=o("TFAutoModelForDocumentQuestionAnswering"),Jeo=l(),_r=a("div"),F(QS.$$.fragment),xKr=l(),Em=a("p"),$Kr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Hte=a("a"),kKr=o("from_pretrained()"),SKr=o(" class method or the "),Jte=a("a"),RKr=o("from_config()"),PKr=o(` class
method.`),BKr=l(),WS=a("p"),IKr=o("This class cannot be instantiated directly using "),dye=a("code"),NKr=o("__init__()"),qKr=o(" (throws an error)."),jKr=l(),oa=a("div"),F(US.$$.fragment),DKr=l(),cye=a("p"),GKr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),OKr=l(),Cm=a("p"),VKr=o(`Note:
Loading a model from its configuration file does `),mye=a("strong"),XKr=o("not"),zKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yte=a("a"),QKr=o("from_pretrained()"),WKr=o(" to load the model weights."),UKr=l(),F(wA.$$.fragment),HKr=l(),Wr=a("div"),F(HS.$$.fragment),JKr=l(),fye=a("p"),YKr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),KKr=l(),In=a("p"),ZKr=o("The model class to instantiate is selected based on the "),gye=a("code"),eZr=o("model_type"),oZr=o(` property of the config object (either
passed as an argument or loaded from `),hye=a("code"),rZr=o("pretrained_model_name_or_path"),tZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=a("code"),aZr=o("pretrained_model_name_or_path"),nZr=o(":"),sZr=l(),pye=a("ul"),AA=a("li"),_ye=a("strong"),lZr=o("layoutlm"),iZr=o(" \u2014 "),Kte=a("a"),dZr=o("TFLayoutLMForQuestionAnswering"),cZr=o(" (LayoutLM model)"),mZr=l(),F(LA.$$.fragment),Yeo=l(),wm=a("h2"),yA=a("a"),bye=a("span"),F(JS.$$.fragment),fZr=l(),vye=a("span"),gZr=o("TFAutoModelForTokenClassification"),Keo=l(),br=a("div"),F(YS.$$.fragment),hZr=l(),Am=a("p"),uZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Zte=a("a"),pZr=o("from_pretrained()"),_Zr=o(" class method or the "),eae=a("a"),bZr=o("from_config()"),vZr=o(` class
method.`),FZr=l(),KS=a("p"),TZr=o("This class cannot be instantiated directly using "),Fye=a("code"),MZr=o("__init__()"),EZr=o(" (throws an error)."),CZr=l(),ra=a("div"),F(ZS.$$.fragment),wZr=l(),Tye=a("p"),AZr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),LZr=l(),Lm=a("p"),yZr=o(`Note:
Loading a model from its configuration file does `),Mye=a("strong"),xZr=o("not"),$Zr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oae=a("a"),kZr=o("from_pretrained()"),SZr=o(" to load the model weights."),RZr=l(),F(xA.$$.fragment),PZr=l(),Ur=a("div"),F(eR.$$.fragment),BZr=l(),Eye=a("p"),IZr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),NZr=l(),Nn=a("p"),qZr=o("The model class to instantiate is selected based on the "),Cye=a("code"),jZr=o("model_type"),DZr=o(` property of the config object (either
passed as an argument or loaded from `),wye=a("code"),GZr=o("pretrained_model_name_or_path"),OZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aye=a("code"),VZr=o("pretrained_model_name_or_path"),XZr=o(":"),zZr=l(),de=a("ul"),$A=a("li"),Lye=a("strong"),QZr=o("albert"),WZr=o(" \u2014 "),rae=a("a"),UZr=o("TFAlbertForTokenClassification"),HZr=o(" (ALBERT model)"),JZr=l(),kA=a("li"),yye=a("strong"),YZr=o("bert"),KZr=o(" \u2014 "),tae=a("a"),ZZr=o("TFBertForTokenClassification"),eet=o(" (BERT model)"),oet=l(),SA=a("li"),xye=a("strong"),ret=o("camembert"),tet=o(" \u2014 "),aae=a("a"),aet=o("TFCamembertForTokenClassification"),net=o(" (CamemBERT model)"),set=l(),RA=a("li"),$ye=a("strong"),iet=o("convbert"),det=o(" \u2014 "),nae=a("a"),cet=o("TFConvBertForTokenClassification"),met=o(" (ConvBERT model)"),fet=l(),PA=a("li"),kye=a("strong"),get=o("deberta"),het=o(" \u2014 "),sae=a("a"),uet=o("TFDebertaForTokenClassification"),pet=o(" (DeBERTa model)"),_et=l(),BA=a("li"),Sye=a("strong"),bet=o("deberta-v2"),vet=o(" \u2014 "),lae=a("a"),Fet=o("TFDebertaV2ForTokenClassification"),Tet=o(" (DeBERTa-v2 model)"),Met=l(),IA=a("li"),Rye=a("strong"),Eet=o("distilbert"),Cet=o(" \u2014 "),iae=a("a"),wet=o("TFDistilBertForTokenClassification"),Aet=o(" (DistilBERT model)"),Let=l(),NA=a("li"),Pye=a("strong"),yet=o("electra"),xet=o(" \u2014 "),dae=a("a"),$et=o("TFElectraForTokenClassification"),ket=o(" (ELECTRA model)"),Set=l(),qA=a("li"),Bye=a("strong"),Ret=o("flaubert"),Pet=o(" \u2014 "),cae=a("a"),Bet=o("TFFlaubertForTokenClassification"),Iet=o(" (FlauBERT model)"),Net=l(),jA=a("li"),Iye=a("strong"),qet=o("funnel"),jet=o(" \u2014 "),mae=a("a"),Det=o("TFFunnelForTokenClassification"),Get=o(" (Funnel Transformer model)"),Oet=l(),DA=a("li"),Nye=a("strong"),Vet=o("layoutlm"),Xet=o(" \u2014 "),fae=a("a"),zet=o("TFLayoutLMForTokenClassification"),Qet=o(" (LayoutLM model)"),Wet=l(),GA=a("li"),qye=a("strong"),Uet=o("layoutlmv3"),Het=o(" \u2014 "),gae=a("a"),Jet=o("TFLayoutLMv3ForTokenClassification"),Yet=o(" (LayoutLMv3 model)"),Ket=l(),OA=a("li"),jye=a("strong"),Zet=o("longformer"),eot=o(" \u2014 "),hae=a("a"),oot=o("TFLongformerForTokenClassification"),rot=o(" (Longformer model)"),tot=l(),VA=a("li"),Dye=a("strong"),aot=o("mobilebert"),not=o(" \u2014 "),uae=a("a"),sot=o("TFMobileBertForTokenClassification"),lot=o(" (MobileBERT model)"),iot=l(),XA=a("li"),Gye=a("strong"),dot=o("mpnet"),cot=o(" \u2014 "),pae=a("a"),mot=o("TFMPNetForTokenClassification"),fot=o(" (MPNet model)"),got=l(),zA=a("li"),Oye=a("strong"),hot=o("rembert"),uot=o(" \u2014 "),_ae=a("a"),pot=o("TFRemBertForTokenClassification"),_ot=o(" (RemBERT model)"),bot=l(),QA=a("li"),Vye=a("strong"),vot=o("roberta"),Fot=o(" \u2014 "),bae=a("a"),Tot=o("TFRobertaForTokenClassification"),Mot=o(" (RoBERTa model)"),Eot=l(),WA=a("li"),Xye=a("strong"),Cot=o("roformer"),wot=o(" \u2014 "),vae=a("a"),Aot=o("TFRoFormerForTokenClassification"),Lot=o(" (RoFormer model)"),yot=l(),UA=a("li"),zye=a("strong"),xot=o("xlm"),$ot=o(" \u2014 "),Fae=a("a"),kot=o("TFXLMForTokenClassification"),Sot=o(" (XLM model)"),Rot=l(),HA=a("li"),Qye=a("strong"),Pot=o("xlm-roberta"),Bot=o(" \u2014 "),Tae=a("a"),Iot=o("TFXLMRobertaForTokenClassification"),Not=o(" (XLM-RoBERTa model)"),qot=l(),JA=a("li"),Wye=a("strong"),jot=o("xlnet"),Dot=o(" \u2014 "),Mae=a("a"),Got=o("TFXLNetForTokenClassification"),Oot=o(" (XLNet model)"),Vot=l(),F(YA.$$.fragment),Zeo=l(),ym=a("h2"),KA=a("a"),Uye=a("span"),F(oR.$$.fragment),Xot=l(),Hye=a("span"),zot=o("TFAutoModelForQuestionAnswering"),eoo=l(),vr=a("div"),F(rR.$$.fragment),Qot=l(),xm=a("p"),Wot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Eae=a("a"),Uot=o("from_pretrained()"),Hot=o(" class method or the "),Cae=a("a"),Jot=o("from_config()"),Yot=o(` class
method.`),Kot=l(),tR=a("p"),Zot=o("This class cannot be instantiated directly using "),Jye=a("code"),ert=o("__init__()"),ort=o(" (throws an error)."),rrt=l(),ta=a("div"),F(aR.$$.fragment),trt=l(),Yye=a("p"),art=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),nrt=l(),$m=a("p"),srt=o(`Note:
Loading a model from its configuration file does `),Kye=a("strong"),lrt=o("not"),irt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wae=a("a"),drt=o("from_pretrained()"),crt=o(" to load the model weights."),mrt=l(),F(ZA.$$.fragment),frt=l(),Hr=a("div"),F(nR.$$.fragment),grt=l(),Zye=a("p"),hrt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),urt=l(),qn=a("p"),prt=o("The model class to instantiate is selected based on the "),e8e=a("code"),_rt=o("model_type"),brt=o(` property of the config object (either
passed as an argument or loaded from `),o8e=a("code"),vrt=o("pretrained_model_name_or_path"),Frt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r8e=a("code"),Trt=o("pretrained_model_name_or_path"),Mrt=o(":"),Ert=l(),ce=a("ul"),e6=a("li"),t8e=a("strong"),Crt=o("albert"),wrt=o(" \u2014 "),Aae=a("a"),Art=o("TFAlbertForQuestionAnswering"),Lrt=o(" (ALBERT model)"),yrt=l(),o6=a("li"),a8e=a("strong"),xrt=o("bert"),$rt=o(" \u2014 "),Lae=a("a"),krt=o("TFBertForQuestionAnswering"),Srt=o(" (BERT model)"),Rrt=l(),r6=a("li"),n8e=a("strong"),Prt=o("camembert"),Brt=o(" \u2014 "),yae=a("a"),Irt=o("TFCamembertForQuestionAnswering"),Nrt=o(" (CamemBERT model)"),qrt=l(),t6=a("li"),s8e=a("strong"),jrt=o("convbert"),Drt=o(" \u2014 "),xae=a("a"),Grt=o("TFConvBertForQuestionAnswering"),Ort=o(" (ConvBERT model)"),Vrt=l(),a6=a("li"),l8e=a("strong"),Xrt=o("deberta"),zrt=o(" \u2014 "),$ae=a("a"),Qrt=o("TFDebertaForQuestionAnswering"),Wrt=o(" (DeBERTa model)"),Urt=l(),n6=a("li"),i8e=a("strong"),Hrt=o("deberta-v2"),Jrt=o(" \u2014 "),kae=a("a"),Yrt=o("TFDebertaV2ForQuestionAnswering"),Krt=o(" (DeBERTa-v2 model)"),Zrt=l(),s6=a("li"),d8e=a("strong"),ett=o("distilbert"),ott=o(" \u2014 "),Sae=a("a"),rtt=o("TFDistilBertForQuestionAnswering"),ttt=o(" (DistilBERT model)"),att=l(),l6=a("li"),c8e=a("strong"),ntt=o("electra"),stt=o(" \u2014 "),Rae=a("a"),ltt=o("TFElectraForQuestionAnswering"),itt=o(" (ELECTRA model)"),dtt=l(),i6=a("li"),m8e=a("strong"),ctt=o("flaubert"),mtt=o(" \u2014 "),Pae=a("a"),ftt=o("TFFlaubertForQuestionAnsweringSimple"),gtt=o(" (FlauBERT model)"),htt=l(),d6=a("li"),f8e=a("strong"),utt=o("funnel"),ptt=o(" \u2014 "),Bae=a("a"),_tt=o("TFFunnelForQuestionAnswering"),btt=o(" (Funnel Transformer model)"),vtt=l(),c6=a("li"),g8e=a("strong"),Ftt=o("gptj"),Ttt=o(" \u2014 "),Iae=a("a"),Mtt=o("TFGPTJForQuestionAnswering"),Ett=o(" (GPT-J model)"),Ctt=l(),m6=a("li"),h8e=a("strong"),wtt=o("layoutlmv3"),Att=o(" \u2014 "),Nae=a("a"),Ltt=o("TFLayoutLMv3ForQuestionAnswering"),ytt=o(" (LayoutLMv3 model)"),xtt=l(),f6=a("li"),u8e=a("strong"),$tt=o("longformer"),ktt=o(" \u2014 "),qae=a("a"),Stt=o("TFLongformerForQuestionAnswering"),Rtt=o(" (Longformer model)"),Ptt=l(),g6=a("li"),p8e=a("strong"),Btt=o("mobilebert"),Itt=o(" \u2014 "),jae=a("a"),Ntt=o("TFMobileBertForQuestionAnswering"),qtt=o(" (MobileBERT model)"),jtt=l(),h6=a("li"),_8e=a("strong"),Dtt=o("mpnet"),Gtt=o(" \u2014 "),Dae=a("a"),Ott=o("TFMPNetForQuestionAnswering"),Vtt=o(" (MPNet model)"),Xtt=l(),u6=a("li"),b8e=a("strong"),ztt=o("rembert"),Qtt=o(" \u2014 "),Gae=a("a"),Wtt=o("TFRemBertForQuestionAnswering"),Utt=o(" (RemBERT model)"),Htt=l(),p6=a("li"),v8e=a("strong"),Jtt=o("roberta"),Ytt=o(" \u2014 "),Oae=a("a"),Ktt=o("TFRobertaForQuestionAnswering"),Ztt=o(" (RoBERTa model)"),eat=l(),_6=a("li"),F8e=a("strong"),oat=o("roformer"),rat=o(" \u2014 "),Vae=a("a"),tat=o("TFRoFormerForQuestionAnswering"),aat=o(" (RoFormer model)"),nat=l(),b6=a("li"),T8e=a("strong"),sat=o("xlm"),lat=o(" \u2014 "),Xae=a("a"),iat=o("TFXLMForQuestionAnsweringSimple"),dat=o(" (XLM model)"),cat=l(),v6=a("li"),M8e=a("strong"),mat=o("xlm-roberta"),fat=o(" \u2014 "),zae=a("a"),gat=o("TFXLMRobertaForQuestionAnswering"),hat=o(" (XLM-RoBERTa model)"),uat=l(),F6=a("li"),E8e=a("strong"),pat=o("xlnet"),_at=o(" \u2014 "),Qae=a("a"),bat=o("TFXLNetForQuestionAnsweringSimple"),vat=o(" (XLNet model)"),Fat=l(),F(T6.$$.fragment),ooo=l(),km=a("h2"),M6=a("a"),C8e=a("span"),F(sR.$$.fragment),Tat=l(),w8e=a("span"),Mat=o("TFAutoModelForVision2Seq"),roo=l(),Fr=a("div"),F(lR.$$.fragment),Eat=l(),Sm=a("p"),Cat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wae=a("a"),wat=o("from_pretrained()"),Aat=o(" class method or the "),Uae=a("a"),Lat=o("from_config()"),yat=o(` class
method.`),xat=l(),iR=a("p"),$at=o("This class cannot be instantiated directly using "),A8e=a("code"),kat=o("__init__()"),Sat=o(" (throws an error)."),Rat=l(),aa=a("div"),F(dR.$$.fragment),Pat=l(),L8e=a("p"),Bat=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Iat=l(),Rm=a("p"),Nat=o(`Note:
Loading a model from its configuration file does `),y8e=a("strong"),qat=o("not"),jat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hae=a("a"),Dat=o("from_pretrained()"),Gat=o(" to load the model weights."),Oat=l(),F(E6.$$.fragment),Vat=l(),Jr=a("div"),F(cR.$$.fragment),Xat=l(),x8e=a("p"),zat=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Qat=l(),jn=a("p"),Wat=o("The model class to instantiate is selected based on the "),$8e=a("code"),Uat=o("model_type"),Hat=o(` property of the config object (either
passed as an argument or loaded from `),k8e=a("code"),Jat=o("pretrained_model_name_or_path"),Yat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S8e=a("code"),Kat=o("pretrained_model_name_or_path"),Zat=o(":"),ent=l(),R8e=a("ul"),C6=a("li"),P8e=a("strong"),ont=o("vision-encoder-decoder"),rnt=o(" \u2014 "),Jae=a("a"),tnt=o("TFVisionEncoderDecoderModel"),ant=o(" (Vision Encoder decoder model)"),nnt=l(),F(w6.$$.fragment),too=l(),Pm=a("h2"),A6=a("a"),B8e=a("span"),F(mR.$$.fragment),snt=l(),I8e=a("span"),lnt=o("TFAutoModelForSpeechSeq2Seq"),aoo=l(),Tr=a("div"),F(fR.$$.fragment),int=l(),Bm=a("p"),dnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Yae=a("a"),cnt=o("from_pretrained()"),mnt=o(" class method or the "),Kae=a("a"),fnt=o("from_config()"),gnt=o(` class
method.`),hnt=l(),gR=a("p"),unt=o("This class cannot be instantiated directly using "),N8e=a("code"),pnt=o("__init__()"),_nt=o(" (throws an error)."),bnt=l(),na=a("div"),F(hR.$$.fragment),vnt=l(),q8e=a("p"),Fnt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Tnt=l(),Im=a("p"),Mnt=o(`Note:
Loading a model from its configuration file does `),j8e=a("strong"),Ent=o("not"),Cnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=a("a"),wnt=o("from_pretrained()"),Ant=o(" to load the model weights."),Lnt=l(),F(L6.$$.fragment),ynt=l(),Yr=a("div"),F(uR.$$.fragment),xnt=l(),D8e=a("p"),$nt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),knt=l(),Dn=a("p"),Snt=o("The model class to instantiate is selected based on the "),G8e=a("code"),Rnt=o("model_type"),Pnt=o(` property of the config object (either
passed as an argument or loaded from `),O8e=a("code"),Bnt=o("pretrained_model_name_or_path"),Int=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V8e=a("code"),Nnt=o("pretrained_model_name_or_path"),qnt=o(":"),jnt=l(),X8e=a("ul"),y6=a("li"),z8e=a("strong"),Dnt=o("speech_to_text"),Gnt=o(" \u2014 "),ene=a("a"),Ont=o("TFSpeech2TextForConditionalGeneration"),Vnt=o(" (Speech2Text model)"),Xnt=l(),F(x6.$$.fragment),noo=l(),Nm=a("h2"),$6=a("a"),Q8e=a("span"),F(pR.$$.fragment),znt=l(),W8e=a("span"),Qnt=o("FlaxAutoModel"),soo=l(),Mr=a("div"),F(_R.$$.fragment),Wnt=l(),qm=a("p"),Unt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),one=a("a"),Hnt=o("from_pretrained()"),Jnt=o(" class method or the "),rne=a("a"),Ynt=o("from_config()"),Knt=o(` class
method.`),Znt=l(),bR=a("p"),est=o("This class cannot be instantiated directly using "),U8e=a("code"),ost=o("__init__()"),rst=o(" (throws an error)."),tst=l(),sa=a("div"),F(vR.$$.fragment),ast=l(),H8e=a("p"),nst=o("Instantiates one of the base model classes of the library from a configuration."),sst=l(),jm=a("p"),lst=o(`Note:
Loading a model from its configuration file does `),J8e=a("strong"),ist=o("not"),dst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tne=a("a"),cst=o("from_pretrained()"),mst=o(" to load the model weights."),fst=l(),F(k6.$$.fragment),gst=l(),Kr=a("div"),F(FR.$$.fragment),hst=l(),Y8e=a("p"),ust=o("Instantiate one of the base model classes of the library from a pretrained model."),pst=l(),Gn=a("p"),_st=o("The model class to instantiate is selected based on the "),K8e=a("code"),bst=o("model_type"),vst=o(` property of the config object (either
passed as an argument or loaded from `),Z8e=a("code"),Fst=o("pretrained_model_name_or_path"),Tst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e9e=a("code"),Mst=o("pretrained_model_name_or_path"),Est=o(":"),Cst=l(),te=a("ul"),S6=a("li"),o9e=a("strong"),wst=o("albert"),Ast=o(" \u2014 "),ane=a("a"),Lst=o("FlaxAlbertModel"),yst=o(" (ALBERT model)"),xst=l(),R6=a("li"),r9e=a("strong"),$st=o("bart"),kst=o(" \u2014 "),nne=a("a"),Sst=o("FlaxBartModel"),Rst=o(" (BART model)"),Pst=l(),P6=a("li"),t9e=a("strong"),Bst=o("beit"),Ist=o(" \u2014 "),sne=a("a"),Nst=o("FlaxBeitModel"),qst=o(" (BEiT model)"),jst=l(),B6=a("li"),a9e=a("strong"),Dst=o("bert"),Gst=o(" \u2014 "),lne=a("a"),Ost=o("FlaxBertModel"),Vst=o(" (BERT model)"),Xst=l(),I6=a("li"),n9e=a("strong"),zst=o("big_bird"),Qst=o(" \u2014 "),ine=a("a"),Wst=o("FlaxBigBirdModel"),Ust=o(" (BigBird model)"),Hst=l(),N6=a("li"),s9e=a("strong"),Jst=o("blenderbot"),Yst=o(" \u2014 "),dne=a("a"),Kst=o("FlaxBlenderbotModel"),Zst=o(" (Blenderbot model)"),elt=l(),q6=a("li"),l9e=a("strong"),olt=o("blenderbot-small"),rlt=o(" \u2014 "),cne=a("a"),tlt=o("FlaxBlenderbotSmallModel"),alt=o(" (BlenderbotSmall model)"),nlt=l(),j6=a("li"),i9e=a("strong"),slt=o("clip"),llt=o(" \u2014 "),mne=a("a"),ilt=o("FlaxCLIPModel"),dlt=o(" (CLIP model)"),clt=l(),D6=a("li"),d9e=a("strong"),mlt=o("distilbert"),flt=o(" \u2014 "),fne=a("a"),glt=o("FlaxDistilBertModel"),hlt=o(" (DistilBERT model)"),ult=l(),G6=a("li"),c9e=a("strong"),plt=o("electra"),_lt=o(" \u2014 "),gne=a("a"),blt=o("FlaxElectraModel"),vlt=o(" (ELECTRA model)"),Flt=l(),O6=a("li"),m9e=a("strong"),Tlt=o("gpt2"),Mlt=o(" \u2014 "),hne=a("a"),Elt=o("FlaxGPT2Model"),Clt=o(" (OpenAI GPT-2 model)"),wlt=l(),V6=a("li"),f9e=a("strong"),Alt=o("gpt_neo"),Llt=o(" \u2014 "),une=a("a"),ylt=o("FlaxGPTNeoModel"),xlt=o(" (GPT Neo model)"),$lt=l(),X6=a("li"),g9e=a("strong"),klt=o("gptj"),Slt=o(" \u2014 "),pne=a("a"),Rlt=o("FlaxGPTJModel"),Plt=o(" (GPT-J model)"),Blt=l(),z6=a("li"),h9e=a("strong"),Ilt=o("longt5"),Nlt=o(" \u2014 "),_ne=a("a"),qlt=o("FlaxLongT5Model"),jlt=o(" (LongT5 model)"),Dlt=l(),Q6=a("li"),u9e=a("strong"),Glt=o("marian"),Olt=o(" \u2014 "),bne=a("a"),Vlt=o("FlaxMarianModel"),Xlt=o(" (Marian model)"),zlt=l(),W6=a("li"),p9e=a("strong"),Qlt=o("mbart"),Wlt=o(" \u2014 "),vne=a("a"),Ult=o("FlaxMBartModel"),Hlt=o(" (mBART model)"),Jlt=l(),U6=a("li"),_9e=a("strong"),Ylt=o("mt5"),Klt=o(" \u2014 "),Fne=a("a"),Zlt=o("FlaxMT5Model"),eit=o(" (MT5 model)"),oit=l(),H6=a("li"),b9e=a("strong"),rit=o("opt"),tit=o(" \u2014 "),Tne=a("a"),ait=o("FlaxOPTModel"),nit=o(" (OPT model)"),sit=l(),J6=a("li"),v9e=a("strong"),lit=o("pegasus"),iit=o(" \u2014 "),Mne=a("a"),dit=o("FlaxPegasusModel"),cit=o(" (Pegasus model)"),mit=l(),Y6=a("li"),F9e=a("strong"),fit=o("roberta"),git=o(" \u2014 "),Ene=a("a"),hit=o("FlaxRobertaModel"),uit=o(" (RoBERTa model)"),pit=l(),K6=a("li"),T9e=a("strong"),_it=o("roformer"),bit=o(" \u2014 "),Cne=a("a"),vit=o("FlaxRoFormerModel"),Fit=o(" (RoFormer model)"),Tit=l(),Z6=a("li"),M9e=a("strong"),Mit=o("t5"),Eit=o(" \u2014 "),wne=a("a"),Cit=o("FlaxT5Model"),wit=o(" (T5 model)"),Ait=l(),e7=a("li"),E9e=a("strong"),Lit=o("vision-text-dual-encoder"),yit=o(" \u2014 "),Ane=a("a"),xit=o("FlaxVisionTextDualEncoderModel"),$it=o(" (VisionTextDualEncoder model)"),kit=l(),o7=a("li"),C9e=a("strong"),Sit=o("vit"),Rit=o(" \u2014 "),Lne=a("a"),Pit=o("FlaxViTModel"),Bit=o(" (ViT model)"),Iit=l(),r7=a("li"),w9e=a("strong"),Nit=o("wav2vec2"),qit=o(" \u2014 "),yne=a("a"),jit=o("FlaxWav2Vec2Model"),Dit=o(" (Wav2Vec2 model)"),Git=l(),t7=a("li"),A9e=a("strong"),Oit=o("xglm"),Vit=o(" \u2014 "),xne=a("a"),Xit=o("FlaxXGLMModel"),zit=o(" (XGLM model)"),Qit=l(),a7=a("li"),L9e=a("strong"),Wit=o("xlm-roberta"),Uit=o(" \u2014 "),$ne=a("a"),Hit=o("FlaxXLMRobertaModel"),Jit=o(" (XLM-RoBERTa model)"),Yit=l(),F(n7.$$.fragment),loo=l(),Dm=a("h2"),s7=a("a"),y9e=a("span"),F(TR.$$.fragment),Kit=l(),x9e=a("span"),Zit=o("FlaxAutoModelForCausalLM"),ioo=l(),Er=a("div"),F(MR.$$.fragment),edt=l(),Gm=a("p"),odt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),kne=a("a"),rdt=o("from_pretrained()"),tdt=o(" class method or the "),Sne=a("a"),adt=o("from_config()"),ndt=o(` class
method.`),sdt=l(),ER=a("p"),ldt=o("This class cannot be instantiated directly using "),$9e=a("code"),idt=o("__init__()"),ddt=o(" (throws an error)."),cdt=l(),la=a("div"),F(CR.$$.fragment),mdt=l(),k9e=a("p"),fdt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gdt=l(),Om=a("p"),hdt=o(`Note:
Loading a model from its configuration file does `),S9e=a("strong"),udt=o("not"),pdt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rne=a("a"),_dt=o("from_pretrained()"),bdt=o(" to load the model weights."),vdt=l(),F(l7.$$.fragment),Fdt=l(),Zr=a("div"),F(wR.$$.fragment),Tdt=l(),R9e=a("p"),Mdt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Edt=l(),On=a("p"),Cdt=o("The model class to instantiate is selected based on the "),P9e=a("code"),wdt=o("model_type"),Adt=o(` property of the config object (either
passed as an argument or loaded from `),B9e=a("code"),Ldt=o("pretrained_model_name_or_path"),ydt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I9e=a("code"),xdt=o("pretrained_model_name_or_path"),$dt=o(":"),kdt=l(),xe=a("ul"),i7=a("li"),N9e=a("strong"),Sdt=o("bart"),Rdt=o(" \u2014 "),Pne=a("a"),Pdt=o("FlaxBartForCausalLM"),Bdt=o(" (BART model)"),Idt=l(),d7=a("li"),q9e=a("strong"),Ndt=o("bert"),qdt=o(" \u2014 "),Bne=a("a"),jdt=o("FlaxBertForCausalLM"),Ddt=o(" (BERT model)"),Gdt=l(),c7=a("li"),j9e=a("strong"),Odt=o("big_bird"),Vdt=o(" \u2014 "),Ine=a("a"),Xdt=o("FlaxBigBirdForCausalLM"),zdt=o(" (BigBird model)"),Qdt=l(),m7=a("li"),D9e=a("strong"),Wdt=o("electra"),Udt=o(" \u2014 "),Nne=a("a"),Hdt=o("FlaxElectraForCausalLM"),Jdt=o(" (ELECTRA model)"),Ydt=l(),f7=a("li"),G9e=a("strong"),Kdt=o("gpt2"),Zdt=o(" \u2014 "),qne=a("a"),ect=o("FlaxGPT2LMHeadModel"),oct=o(" (OpenAI GPT-2 model)"),rct=l(),g7=a("li"),O9e=a("strong"),tct=o("gpt_neo"),act=o(" \u2014 "),jne=a("a"),nct=o("FlaxGPTNeoForCausalLM"),sct=o(" (GPT Neo model)"),lct=l(),h7=a("li"),V9e=a("strong"),ict=o("gptj"),dct=o(" \u2014 "),Dne=a("a"),cct=o("FlaxGPTJForCausalLM"),mct=o(" (GPT-J model)"),fct=l(),u7=a("li"),X9e=a("strong"),gct=o("opt"),hct=o(" \u2014 "),Gne=a("a"),uct=o("FlaxOPTForCausalLM"),pct=o(" (OPT model)"),_ct=l(),p7=a("li"),z9e=a("strong"),bct=o("roberta"),vct=o(" \u2014 "),One=a("a"),Fct=o("FlaxRobertaForCausalLM"),Tct=o(" (RoBERTa model)"),Mct=l(),_7=a("li"),Q9e=a("strong"),Ect=o("xglm"),Cct=o(" \u2014 "),Vne=a("a"),wct=o("FlaxXGLMForCausalLM"),Act=o(" (XGLM model)"),Lct=l(),F(b7.$$.fragment),doo=l(),Vm=a("h2"),v7=a("a"),W9e=a("span"),F(AR.$$.fragment),yct=l(),U9e=a("span"),xct=o("FlaxAutoModelForPreTraining"),coo=l(),Cr=a("div"),F(LR.$$.fragment),$ct=l(),Xm=a("p"),kct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Xne=a("a"),Sct=o("from_pretrained()"),Rct=o(" class method or the "),zne=a("a"),Pct=o("from_config()"),Bct=o(` class
method.`),Ict=l(),yR=a("p"),Nct=o("This class cannot be instantiated directly using "),H9e=a("code"),qct=o("__init__()"),jct=o(" (throws an error)."),Dct=l(),ia=a("div"),F(xR.$$.fragment),Gct=l(),J9e=a("p"),Oct=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Vct=l(),zm=a("p"),Xct=o(`Note:
Loading a model from its configuration file does `),Y9e=a("strong"),zct=o("not"),Qct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qne=a("a"),Wct=o("from_pretrained()"),Uct=o(" to load the model weights."),Hct=l(),F(F7.$$.fragment),Jct=l(),et=a("div"),F($R.$$.fragment),Yct=l(),K9e=a("p"),Kct=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Zct=l(),Vn=a("p"),emt=o("The model class to instantiate is selected based on the "),Z9e=a("code"),omt=o("model_type"),rmt=o(` property of the config object (either
passed as an argument or loaded from `),exe=a("code"),tmt=o("pretrained_model_name_or_path"),amt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oxe=a("code"),nmt=o("pretrained_model_name_or_path"),smt=o(":"),lmt=l(),Ee=a("ul"),T7=a("li"),rxe=a("strong"),imt=o("albert"),dmt=o(" \u2014 "),Wne=a("a"),cmt=o("FlaxAlbertForPreTraining"),mmt=o(" (ALBERT model)"),fmt=l(),M7=a("li"),txe=a("strong"),gmt=o("bart"),hmt=o(" \u2014 "),Une=a("a"),umt=o("FlaxBartForConditionalGeneration"),pmt=o(" (BART model)"),_mt=l(),E7=a("li"),axe=a("strong"),bmt=o("bert"),vmt=o(" \u2014 "),Hne=a("a"),Fmt=o("FlaxBertForPreTraining"),Tmt=o(" (BERT model)"),Mmt=l(),C7=a("li"),nxe=a("strong"),Emt=o("big_bird"),Cmt=o(" \u2014 "),Jne=a("a"),wmt=o("FlaxBigBirdForPreTraining"),Amt=o(" (BigBird model)"),Lmt=l(),w7=a("li"),sxe=a("strong"),ymt=o("electra"),xmt=o(" \u2014 "),Yne=a("a"),$mt=o("FlaxElectraForPreTraining"),kmt=o(" (ELECTRA model)"),Smt=l(),A7=a("li"),lxe=a("strong"),Rmt=o("longt5"),Pmt=o(" \u2014 "),Kne=a("a"),Bmt=o("FlaxLongT5ForConditionalGeneration"),Imt=o(" (LongT5 model)"),Nmt=l(),L7=a("li"),ixe=a("strong"),qmt=o("mbart"),jmt=o(" \u2014 "),Zne=a("a"),Dmt=o("FlaxMBartForConditionalGeneration"),Gmt=o(" (mBART model)"),Omt=l(),y7=a("li"),dxe=a("strong"),Vmt=o("mt5"),Xmt=o(" \u2014 "),ese=a("a"),zmt=o("FlaxMT5ForConditionalGeneration"),Qmt=o(" (MT5 model)"),Wmt=l(),x7=a("li"),cxe=a("strong"),Umt=o("roberta"),Hmt=o(" \u2014 "),ose=a("a"),Jmt=o("FlaxRobertaForMaskedLM"),Ymt=o(" (RoBERTa model)"),Kmt=l(),$7=a("li"),mxe=a("strong"),Zmt=o("roformer"),eft=o(" \u2014 "),rse=a("a"),oft=o("FlaxRoFormerForMaskedLM"),rft=o(" (RoFormer model)"),tft=l(),k7=a("li"),fxe=a("strong"),aft=o("t5"),nft=o(" \u2014 "),tse=a("a"),sft=o("FlaxT5ForConditionalGeneration"),lft=o(" (T5 model)"),ift=l(),S7=a("li"),gxe=a("strong"),dft=o("wav2vec2"),cft=o(" \u2014 "),ase=a("a"),mft=o("FlaxWav2Vec2ForPreTraining"),fft=o(" (Wav2Vec2 model)"),gft=l(),R7=a("li"),hxe=a("strong"),hft=o("xlm-roberta"),uft=o(" \u2014 "),nse=a("a"),pft=o("FlaxXLMRobertaForMaskedLM"),_ft=o(" (XLM-RoBERTa model)"),bft=l(),F(P7.$$.fragment),moo=l(),Qm=a("h2"),B7=a("a"),uxe=a("span"),F(kR.$$.fragment),vft=l(),pxe=a("span"),Fft=o("FlaxAutoModelForMaskedLM"),foo=l(),wr=a("div"),F(SR.$$.fragment),Tft=l(),Wm=a("p"),Mft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sse=a("a"),Eft=o("from_pretrained()"),Cft=o(" class method or the "),lse=a("a"),wft=o("from_config()"),Aft=o(` class
method.`),Lft=l(),RR=a("p"),yft=o("This class cannot be instantiated directly using "),_xe=a("code"),xft=o("__init__()"),$ft=o(" (throws an error)."),kft=l(),da=a("div"),F(PR.$$.fragment),Sft=l(),bxe=a("p"),Rft=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Pft=l(),Um=a("p"),Bft=o(`Note:
Loading a model from its configuration file does `),vxe=a("strong"),Ift=o("not"),Nft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ise=a("a"),qft=o("from_pretrained()"),jft=o(" to load the model weights."),Dft=l(),F(I7.$$.fragment),Gft=l(),ot=a("div"),F(BR.$$.fragment),Oft=l(),Fxe=a("p"),Vft=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xft=l(),Xn=a("p"),zft=o("The model class to instantiate is selected based on the "),Txe=a("code"),Qft=o("model_type"),Wft=o(` property of the config object (either
passed as an argument or loaded from `),Mxe=a("code"),Uft=o("pretrained_model_name_or_path"),Hft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Exe=a("code"),Jft=o("pretrained_model_name_or_path"),Yft=o(":"),Kft=l(),$e=a("ul"),N7=a("li"),Cxe=a("strong"),Zft=o("albert"),egt=o(" \u2014 "),dse=a("a"),ogt=o("FlaxAlbertForMaskedLM"),rgt=o(" (ALBERT model)"),tgt=l(),q7=a("li"),wxe=a("strong"),agt=o("bart"),ngt=o(" \u2014 "),cse=a("a"),sgt=o("FlaxBartForConditionalGeneration"),lgt=o(" (BART model)"),igt=l(),j7=a("li"),Axe=a("strong"),dgt=o("bert"),cgt=o(" \u2014 "),mse=a("a"),mgt=o("FlaxBertForMaskedLM"),fgt=o(" (BERT model)"),ggt=l(),D7=a("li"),Lxe=a("strong"),hgt=o("big_bird"),ugt=o(" \u2014 "),fse=a("a"),pgt=o("FlaxBigBirdForMaskedLM"),_gt=o(" (BigBird model)"),bgt=l(),G7=a("li"),yxe=a("strong"),vgt=o("distilbert"),Fgt=o(" \u2014 "),gse=a("a"),Tgt=o("FlaxDistilBertForMaskedLM"),Mgt=o(" (DistilBERT model)"),Egt=l(),O7=a("li"),xxe=a("strong"),Cgt=o("electra"),wgt=o(" \u2014 "),hse=a("a"),Agt=o("FlaxElectraForMaskedLM"),Lgt=o(" (ELECTRA model)"),ygt=l(),V7=a("li"),$xe=a("strong"),xgt=o("mbart"),$gt=o(" \u2014 "),use=a("a"),kgt=o("FlaxMBartForConditionalGeneration"),Sgt=o(" (mBART model)"),Rgt=l(),X7=a("li"),kxe=a("strong"),Pgt=o("roberta"),Bgt=o(" \u2014 "),pse=a("a"),Igt=o("FlaxRobertaForMaskedLM"),Ngt=o(" (RoBERTa model)"),qgt=l(),z7=a("li"),Sxe=a("strong"),jgt=o("roformer"),Dgt=o(" \u2014 "),_se=a("a"),Ggt=o("FlaxRoFormerForMaskedLM"),Ogt=o(" (RoFormer model)"),Vgt=l(),Q7=a("li"),Rxe=a("strong"),Xgt=o("xlm-roberta"),zgt=o(" \u2014 "),bse=a("a"),Qgt=o("FlaxXLMRobertaForMaskedLM"),Wgt=o(" (XLM-RoBERTa model)"),Ugt=l(),F(W7.$$.fragment),goo=l(),Hm=a("h2"),U7=a("a"),Pxe=a("span"),F(IR.$$.fragment),Hgt=l(),Bxe=a("span"),Jgt=o("FlaxAutoModelForSeq2SeqLM"),hoo=l(),Ar=a("div"),F(NR.$$.fragment),Ygt=l(),Jm=a("p"),Kgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),vse=a("a"),Zgt=o("from_pretrained()"),eht=o(" class method or the "),Fse=a("a"),oht=o("from_config()"),rht=o(` class
method.`),tht=l(),qR=a("p"),aht=o("This class cannot be instantiated directly using "),Ixe=a("code"),nht=o("__init__()"),sht=o(" (throws an error)."),lht=l(),ca=a("div"),F(jR.$$.fragment),iht=l(),Nxe=a("p"),dht=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),cht=l(),Ym=a("p"),mht=o(`Note:
Loading a model from its configuration file does `),qxe=a("strong"),fht=o("not"),ght=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tse=a("a"),hht=o("from_pretrained()"),uht=o(" to load the model weights."),pht=l(),F(H7.$$.fragment),_ht=l(),rt=a("div"),F(DR.$$.fragment),bht=l(),jxe=a("p"),vht=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Fht=l(),zn=a("p"),Tht=o("The model class to instantiate is selected based on the "),Dxe=a("code"),Mht=o("model_type"),Eht=o(` property of the config object (either
passed as an argument or loaded from `),Gxe=a("code"),Cht=o("pretrained_model_name_or_path"),wht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=a("code"),Aht=o("pretrained_model_name_or_path"),Lht=o(":"),yht=l(),ke=a("ul"),J7=a("li"),Vxe=a("strong"),xht=o("bart"),$ht=o(" \u2014 "),Mse=a("a"),kht=o("FlaxBartForConditionalGeneration"),Sht=o(" (BART model)"),Rht=l(),Y7=a("li"),Xxe=a("strong"),Pht=o("blenderbot"),Bht=o(" \u2014 "),Ese=a("a"),Iht=o("FlaxBlenderbotForConditionalGeneration"),Nht=o(" (Blenderbot model)"),qht=l(),K7=a("li"),zxe=a("strong"),jht=o("blenderbot-small"),Dht=o(" \u2014 "),Cse=a("a"),Ght=o("FlaxBlenderbotSmallForConditionalGeneration"),Oht=o(" (BlenderbotSmall model)"),Vht=l(),Z7=a("li"),Qxe=a("strong"),Xht=o("encoder-decoder"),zht=o(" \u2014 "),wse=a("a"),Qht=o("FlaxEncoderDecoderModel"),Wht=o(" (Encoder decoder model)"),Uht=l(),eL=a("li"),Wxe=a("strong"),Hht=o("longt5"),Jht=o(" \u2014 "),Ase=a("a"),Yht=o("FlaxLongT5ForConditionalGeneration"),Kht=o(" (LongT5 model)"),Zht=l(),oL=a("li"),Uxe=a("strong"),eut=o("marian"),out=o(" \u2014 "),Lse=a("a"),rut=o("FlaxMarianMTModel"),tut=o(" (Marian model)"),aut=l(),rL=a("li"),Hxe=a("strong"),nut=o("mbart"),sut=o(" \u2014 "),yse=a("a"),lut=o("FlaxMBartForConditionalGeneration"),iut=o(" (mBART model)"),dut=l(),tL=a("li"),Jxe=a("strong"),cut=o("mt5"),mut=o(" \u2014 "),xse=a("a"),fut=o("FlaxMT5ForConditionalGeneration"),gut=o(" (MT5 model)"),hut=l(),aL=a("li"),Yxe=a("strong"),uut=o("pegasus"),put=o(" \u2014 "),$se=a("a"),_ut=o("FlaxPegasusForConditionalGeneration"),but=o(" (Pegasus model)"),vut=l(),nL=a("li"),Kxe=a("strong"),Fut=o("t5"),Tut=o(" \u2014 "),kse=a("a"),Mut=o("FlaxT5ForConditionalGeneration"),Eut=o(" (T5 model)"),Cut=l(),F(sL.$$.fragment),uoo=l(),Km=a("h2"),lL=a("a"),Zxe=a("span"),F(GR.$$.fragment),wut=l(),e$e=a("span"),Aut=o("FlaxAutoModelForSequenceClassification"),poo=l(),Lr=a("div"),F(OR.$$.fragment),Lut=l(),Zm=a("p"),yut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Sse=a("a"),xut=o("from_pretrained()"),$ut=o(" class method or the "),Rse=a("a"),kut=o("from_config()"),Sut=o(` class
method.`),Rut=l(),VR=a("p"),Put=o("This class cannot be instantiated directly using "),o$e=a("code"),But=o("__init__()"),Iut=o(" (throws an error)."),Nut=l(),ma=a("div"),F(XR.$$.fragment),qut=l(),r$e=a("p"),jut=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Dut=l(),ef=a("p"),Gut=o(`Note:
Loading a model from its configuration file does `),t$e=a("strong"),Out=o("not"),Vut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pse=a("a"),Xut=o("from_pretrained()"),zut=o(" to load the model weights."),Qut=l(),F(iL.$$.fragment),Wut=l(),tt=a("div"),F(zR.$$.fragment),Uut=l(),a$e=a("p"),Hut=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Jut=l(),Qn=a("p"),Yut=o("The model class to instantiate is selected based on the "),n$e=a("code"),Kut=o("model_type"),Zut=o(` property of the config object (either
passed as an argument or loaded from `),s$e=a("code"),ept=o("pretrained_model_name_or_path"),opt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l$e=a("code"),rpt=o("pretrained_model_name_or_path"),tpt=o(":"),apt=l(),Se=a("ul"),dL=a("li"),i$e=a("strong"),npt=o("albert"),spt=o(" \u2014 "),Bse=a("a"),lpt=o("FlaxAlbertForSequenceClassification"),ipt=o(" (ALBERT model)"),dpt=l(),cL=a("li"),d$e=a("strong"),cpt=o("bart"),mpt=o(" \u2014 "),Ise=a("a"),fpt=o("FlaxBartForSequenceClassification"),gpt=o(" (BART model)"),hpt=l(),mL=a("li"),c$e=a("strong"),upt=o("bert"),ppt=o(" \u2014 "),Nse=a("a"),_pt=o("FlaxBertForSequenceClassification"),bpt=o(" (BERT model)"),vpt=l(),fL=a("li"),m$e=a("strong"),Fpt=o("big_bird"),Tpt=o(" \u2014 "),qse=a("a"),Mpt=o("FlaxBigBirdForSequenceClassification"),Ept=o(" (BigBird model)"),Cpt=l(),gL=a("li"),f$e=a("strong"),wpt=o("distilbert"),Apt=o(" \u2014 "),jse=a("a"),Lpt=o("FlaxDistilBertForSequenceClassification"),ypt=o(" (DistilBERT model)"),xpt=l(),hL=a("li"),g$e=a("strong"),$pt=o("electra"),kpt=o(" \u2014 "),Dse=a("a"),Spt=o("FlaxElectraForSequenceClassification"),Rpt=o(" (ELECTRA model)"),Ppt=l(),uL=a("li"),h$e=a("strong"),Bpt=o("mbart"),Ipt=o(" \u2014 "),Gse=a("a"),Npt=o("FlaxMBartForSequenceClassification"),qpt=o(" (mBART model)"),jpt=l(),pL=a("li"),u$e=a("strong"),Dpt=o("roberta"),Gpt=o(" \u2014 "),Ose=a("a"),Opt=o("FlaxRobertaForSequenceClassification"),Vpt=o(" (RoBERTa model)"),Xpt=l(),_L=a("li"),p$e=a("strong"),zpt=o("roformer"),Qpt=o(" \u2014 "),Vse=a("a"),Wpt=o("FlaxRoFormerForSequenceClassification"),Upt=o(" (RoFormer model)"),Hpt=l(),bL=a("li"),_$e=a("strong"),Jpt=o("xlm-roberta"),Ypt=o(" \u2014 "),Xse=a("a"),Kpt=o("FlaxXLMRobertaForSequenceClassification"),Zpt=o(" (XLM-RoBERTa model)"),e_t=l(),F(vL.$$.fragment),_oo=l(),of=a("h2"),FL=a("a"),b$e=a("span"),F(QR.$$.fragment),o_t=l(),v$e=a("span"),r_t=o("FlaxAutoModelForQuestionAnswering"),boo=l(),yr=a("div"),F(WR.$$.fragment),t_t=l(),rf=a("p"),a_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),zse=a("a"),n_t=o("from_pretrained()"),s_t=o(" class method or the "),Qse=a("a"),l_t=o("from_config()"),i_t=o(` class
method.`),d_t=l(),UR=a("p"),c_t=o("This class cannot be instantiated directly using "),F$e=a("code"),m_t=o("__init__()"),f_t=o(" (throws an error)."),g_t=l(),fa=a("div"),F(HR.$$.fragment),h_t=l(),T$e=a("p"),u_t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),p_t=l(),tf=a("p"),__t=o(`Note:
Loading a model from its configuration file does `),M$e=a("strong"),b_t=o("not"),v_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=a("a"),F_t=o("from_pretrained()"),T_t=o(" to load the model weights."),M_t=l(),F(TL.$$.fragment),E_t=l(),at=a("div"),F(JR.$$.fragment),C_t=l(),E$e=a("p"),w_t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),A_t=l(),Wn=a("p"),L_t=o("The model class to instantiate is selected based on the "),C$e=a("code"),y_t=o("model_type"),x_t=o(` property of the config object (either
passed as an argument or loaded from `),w$e=a("code"),$_t=o("pretrained_model_name_or_path"),k_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A$e=a("code"),S_t=o("pretrained_model_name_or_path"),R_t=o(":"),P_t=l(),Re=a("ul"),ML=a("li"),L$e=a("strong"),B_t=o("albert"),I_t=o(" \u2014 "),Use=a("a"),N_t=o("FlaxAlbertForQuestionAnswering"),q_t=o(" (ALBERT model)"),j_t=l(),EL=a("li"),y$e=a("strong"),D_t=o("bart"),G_t=o(" \u2014 "),Hse=a("a"),O_t=o("FlaxBartForQuestionAnswering"),V_t=o(" (BART model)"),X_t=l(),CL=a("li"),x$e=a("strong"),z_t=o("bert"),Q_t=o(" \u2014 "),Jse=a("a"),W_t=o("FlaxBertForQuestionAnswering"),U_t=o(" (BERT model)"),H_t=l(),wL=a("li"),$$e=a("strong"),J_t=o("big_bird"),Y_t=o(" \u2014 "),Yse=a("a"),K_t=o("FlaxBigBirdForQuestionAnswering"),Z_t=o(" (BigBird model)"),e2t=l(),AL=a("li"),k$e=a("strong"),o2t=o("distilbert"),r2t=o(" \u2014 "),Kse=a("a"),t2t=o("FlaxDistilBertForQuestionAnswering"),a2t=o(" (DistilBERT model)"),n2t=l(),LL=a("li"),S$e=a("strong"),s2t=o("electra"),l2t=o(" \u2014 "),Zse=a("a"),i2t=o("FlaxElectraForQuestionAnswering"),d2t=o(" (ELECTRA model)"),c2t=l(),yL=a("li"),R$e=a("strong"),m2t=o("mbart"),f2t=o(" \u2014 "),ele=a("a"),g2t=o("FlaxMBartForQuestionAnswering"),h2t=o(" (mBART model)"),u2t=l(),xL=a("li"),P$e=a("strong"),p2t=o("roberta"),_2t=o(" \u2014 "),ole=a("a"),b2t=o("FlaxRobertaForQuestionAnswering"),v2t=o(" (RoBERTa model)"),F2t=l(),$L=a("li"),B$e=a("strong"),T2t=o("roformer"),M2t=o(" \u2014 "),rle=a("a"),E2t=o("FlaxRoFormerForQuestionAnswering"),C2t=o(" (RoFormer model)"),w2t=l(),kL=a("li"),I$e=a("strong"),A2t=o("xlm-roberta"),L2t=o(" \u2014 "),tle=a("a"),y2t=o("FlaxXLMRobertaForQuestionAnswering"),x2t=o(" (XLM-RoBERTa model)"),$2t=l(),F(SL.$$.fragment),voo=l(),af=a("h2"),RL=a("a"),N$e=a("span"),F(YR.$$.fragment),k2t=l(),q$e=a("span"),S2t=o("FlaxAutoModelForTokenClassification"),Foo=l(),xr=a("div"),F(KR.$$.fragment),R2t=l(),nf=a("p"),P2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ale=a("a"),B2t=o("from_pretrained()"),I2t=o(" class method or the "),nle=a("a"),N2t=o("from_config()"),q2t=o(` class
method.`),j2t=l(),ZR=a("p"),D2t=o("This class cannot be instantiated directly using "),j$e=a("code"),G2t=o("__init__()"),O2t=o(" (throws an error)."),V2t=l(),ga=a("div"),F(eP.$$.fragment),X2t=l(),D$e=a("p"),z2t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Q2t=l(),sf=a("p"),W2t=o(`Note:
Loading a model from its configuration file does `),G$e=a("strong"),U2t=o("not"),H2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sle=a("a"),J2t=o("from_pretrained()"),Y2t=o(" to load the model weights."),K2t=l(),F(PL.$$.fragment),Z2t=l(),nt=a("div"),F(oP.$$.fragment),ebt=l(),O$e=a("p"),obt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),rbt=l(),Un=a("p"),tbt=o("The model class to instantiate is selected based on the "),V$e=a("code"),abt=o("model_type"),nbt=o(` property of the config object (either
passed as an argument or loaded from `),X$e=a("code"),sbt=o("pretrained_model_name_or_path"),lbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z$e=a("code"),ibt=o("pretrained_model_name_or_path"),dbt=o(":"),cbt=l(),Xe=a("ul"),BL=a("li"),Q$e=a("strong"),mbt=o("albert"),fbt=o(" \u2014 "),lle=a("a"),gbt=o("FlaxAlbertForTokenClassification"),hbt=o(" (ALBERT model)"),ubt=l(),IL=a("li"),W$e=a("strong"),pbt=o("bert"),_bt=o(" \u2014 "),ile=a("a"),bbt=o("FlaxBertForTokenClassification"),vbt=o(" (BERT model)"),Fbt=l(),NL=a("li"),U$e=a("strong"),Tbt=o("big_bird"),Mbt=o(" \u2014 "),dle=a("a"),Ebt=o("FlaxBigBirdForTokenClassification"),Cbt=o(" (BigBird model)"),wbt=l(),qL=a("li"),H$e=a("strong"),Abt=o("distilbert"),Lbt=o(" \u2014 "),cle=a("a"),ybt=o("FlaxDistilBertForTokenClassification"),xbt=o(" (DistilBERT model)"),$bt=l(),jL=a("li"),J$e=a("strong"),kbt=o("electra"),Sbt=o(" \u2014 "),mle=a("a"),Rbt=o("FlaxElectraForTokenClassification"),Pbt=o(" (ELECTRA model)"),Bbt=l(),DL=a("li"),Y$e=a("strong"),Ibt=o("roberta"),Nbt=o(" \u2014 "),fle=a("a"),qbt=o("FlaxRobertaForTokenClassification"),jbt=o(" (RoBERTa model)"),Dbt=l(),GL=a("li"),K$e=a("strong"),Gbt=o("roformer"),Obt=o(" \u2014 "),gle=a("a"),Vbt=o("FlaxRoFormerForTokenClassification"),Xbt=o(" (RoFormer model)"),zbt=l(),OL=a("li"),Z$e=a("strong"),Qbt=o("xlm-roberta"),Wbt=o(" \u2014 "),hle=a("a"),Ubt=o("FlaxXLMRobertaForTokenClassification"),Hbt=o(" (XLM-RoBERTa model)"),Jbt=l(),F(VL.$$.fragment),Too=l(),lf=a("h2"),XL=a("a"),eke=a("span"),F(rP.$$.fragment),Ybt=l(),oke=a("span"),Kbt=o("FlaxAutoModelForMultipleChoice"),Moo=l(),$r=a("div"),F(tP.$$.fragment),Zbt=l(),df=a("p"),e1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),ule=a("a"),o1t=o("from_pretrained()"),r1t=o(" class method or the "),ple=a("a"),t1t=o("from_config()"),a1t=o(` class
method.`),n1t=l(),aP=a("p"),s1t=o("This class cannot be instantiated directly using "),rke=a("code"),l1t=o("__init__()"),i1t=o(" (throws an error)."),d1t=l(),ha=a("div"),F(nP.$$.fragment),c1t=l(),tke=a("p"),m1t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),f1t=l(),cf=a("p"),g1t=o(`Note:
Loading a model from its configuration file does `),ake=a("strong"),h1t=o("not"),u1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_le=a("a"),p1t=o("from_pretrained()"),_1t=o(" to load the model weights."),b1t=l(),F(zL.$$.fragment),v1t=l(),st=a("div"),F(sP.$$.fragment),F1t=l(),nke=a("p"),T1t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),M1t=l(),Hn=a("p"),E1t=o("The model class to instantiate is selected based on the "),ske=a("code"),C1t=o("model_type"),w1t=o(` property of the config object (either
passed as an argument or loaded from `),lke=a("code"),A1t=o("pretrained_model_name_or_path"),L1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ike=a("code"),y1t=o("pretrained_model_name_or_path"),x1t=o(":"),$1t=l(),ze=a("ul"),QL=a("li"),dke=a("strong"),k1t=o("albert"),S1t=o(" \u2014 "),ble=a("a"),R1t=o("FlaxAlbertForMultipleChoice"),P1t=o(" (ALBERT model)"),B1t=l(),WL=a("li"),cke=a("strong"),I1t=o("bert"),N1t=o(" \u2014 "),vle=a("a"),q1t=o("FlaxBertForMultipleChoice"),j1t=o(" (BERT model)"),D1t=l(),UL=a("li"),mke=a("strong"),G1t=o("big_bird"),O1t=o(" \u2014 "),Fle=a("a"),V1t=o("FlaxBigBirdForMultipleChoice"),X1t=o(" (BigBird model)"),z1t=l(),HL=a("li"),fke=a("strong"),Q1t=o("distilbert"),W1t=o(" \u2014 "),Tle=a("a"),U1t=o("FlaxDistilBertForMultipleChoice"),H1t=o(" (DistilBERT model)"),J1t=l(),JL=a("li"),gke=a("strong"),Y1t=o("electra"),K1t=o(" \u2014 "),Mle=a("a"),Z1t=o("FlaxElectraForMultipleChoice"),evt=o(" (ELECTRA model)"),ovt=l(),YL=a("li"),hke=a("strong"),rvt=o("roberta"),tvt=o(" \u2014 "),Ele=a("a"),avt=o("FlaxRobertaForMultipleChoice"),nvt=o(" (RoBERTa model)"),svt=l(),KL=a("li"),uke=a("strong"),lvt=o("roformer"),ivt=o(" \u2014 "),Cle=a("a"),dvt=o("FlaxRoFormerForMultipleChoice"),cvt=o(" (RoFormer model)"),mvt=l(),ZL=a("li"),pke=a("strong"),fvt=o("xlm-roberta"),gvt=o(" \u2014 "),wle=a("a"),hvt=o("FlaxXLMRobertaForMultipleChoice"),uvt=o(" (XLM-RoBERTa model)"),pvt=l(),F(ey.$$.fragment),Eoo=l(),mf=a("h2"),oy=a("a"),_ke=a("span"),F(lP.$$.fragment),_vt=l(),bke=a("span"),bvt=o("FlaxAutoModelForNextSentencePrediction"),Coo=l(),kr=a("div"),F(iP.$$.fragment),vvt=l(),ff=a("p"),Fvt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Ale=a("a"),Tvt=o("from_pretrained()"),Mvt=o(" class method or the "),Lle=a("a"),Evt=o("from_config()"),Cvt=o(` class
method.`),wvt=l(),dP=a("p"),Avt=o("This class cannot be instantiated directly using "),vke=a("code"),Lvt=o("__init__()"),yvt=o(" (throws an error)."),xvt=l(),ua=a("div"),F(cP.$$.fragment),$vt=l(),Fke=a("p"),kvt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Svt=l(),gf=a("p"),Rvt=o(`Note:
Loading a model from its configuration file does `),Tke=a("strong"),Pvt=o("not"),Bvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yle=a("a"),Ivt=o("from_pretrained()"),Nvt=o(" to load the model weights."),qvt=l(),F(ry.$$.fragment),jvt=l(),lt=a("div"),F(mP.$$.fragment),Dvt=l(),Mke=a("p"),Gvt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Ovt=l(),Jn=a("p"),Vvt=o("The model class to instantiate is selected based on the "),Eke=a("code"),Xvt=o("model_type"),zvt=o(` property of the config object (either
passed as an argument or loaded from `),Cke=a("code"),Qvt=o("pretrained_model_name_or_path"),Wvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wke=a("code"),Uvt=o("pretrained_model_name_or_path"),Hvt=o(":"),Jvt=l(),Ake=a("ul"),ty=a("li"),Lke=a("strong"),Yvt=o("bert"),Kvt=o(" \u2014 "),xle=a("a"),Zvt=o("FlaxBertForNextSentencePrediction"),eFt=o(" (BERT model)"),oFt=l(),F(ay.$$.fragment),woo=l(),hf=a("h2"),ny=a("a"),yke=a("span"),F(fP.$$.fragment),rFt=l(),xke=a("span"),tFt=o("FlaxAutoModelForImageClassification"),Aoo=l(),Sr=a("div"),F(gP.$$.fragment),aFt=l(),uf=a("p"),nFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),$le=a("a"),sFt=o("from_pretrained()"),lFt=o(" class method or the "),kle=a("a"),iFt=o("from_config()"),dFt=o(` class
method.`),cFt=l(),hP=a("p"),mFt=o("This class cannot be instantiated directly using "),$ke=a("code"),fFt=o("__init__()"),gFt=o(" (throws an error)."),hFt=l(),pa=a("div"),F(uP.$$.fragment),uFt=l(),kke=a("p"),pFt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_Ft=l(),pf=a("p"),bFt=o(`Note:
Loading a model from its configuration file does `),Ske=a("strong"),vFt=o("not"),FFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sle=a("a"),TFt=o("from_pretrained()"),MFt=o(" to load the model weights."),EFt=l(),F(sy.$$.fragment),CFt=l(),it=a("div"),F(pP.$$.fragment),wFt=l(),Rke=a("p"),AFt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),LFt=l(),Yn=a("p"),yFt=o("The model class to instantiate is selected based on the "),Pke=a("code"),xFt=o("model_type"),$Ft=o(` property of the config object (either
passed as an argument or loaded from `),Bke=a("code"),kFt=o("pretrained_model_name_or_path"),SFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ike=a("code"),RFt=o("pretrained_model_name_or_path"),PFt=o(":"),BFt=l(),_P=a("ul"),ly=a("li"),Nke=a("strong"),IFt=o("beit"),NFt=o(" \u2014 "),Rle=a("a"),qFt=o("FlaxBeitForImageClassification"),jFt=o(" (BEiT model)"),DFt=l(),iy=a("li"),qke=a("strong"),GFt=o("vit"),OFt=o(" \u2014 "),Ple=a("a"),VFt=o("FlaxViTForImageClassification"),XFt=o(" (ViT model)"),zFt=l(),F(dy.$$.fragment),Loo=l(),_f=a("h2"),cy=a("a"),jke=a("span"),F(bP.$$.fragment),QFt=l(),Dke=a("span"),WFt=o("FlaxAutoModelForVision2Seq"),yoo=l(),Rr=a("div"),F(vP.$$.fragment),UFt=l(),bf=a("p"),HFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ble=a("a"),JFt=o("from_pretrained()"),YFt=o(" class method or the "),Ile=a("a"),KFt=o("from_config()"),ZFt=o(` class
method.`),eTt=l(),FP=a("p"),oTt=o("This class cannot be instantiated directly using "),Gke=a("code"),rTt=o("__init__()"),tTt=o(" (throws an error)."),aTt=l(),_a=a("div"),F(TP.$$.fragment),nTt=l(),Oke=a("p"),sTt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),lTt=l(),vf=a("p"),iTt=o(`Note:
Loading a model from its configuration file does `),Vke=a("strong"),dTt=o("not"),cTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nle=a("a"),mTt=o("from_pretrained()"),fTt=o(" to load the model weights."),gTt=l(),F(my.$$.fragment),hTt=l(),dt=a("div"),F(MP.$$.fragment),uTt=l(),Xke=a("p"),pTt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),_Tt=l(),Kn=a("p"),bTt=o("The model class to instantiate is selected based on the "),zke=a("code"),vTt=o("model_type"),FTt=o(` property of the config object (either
passed as an argument or loaded from `),Qke=a("code"),TTt=o("pretrained_model_name_or_path"),MTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wke=a("code"),ETt=o("pretrained_model_name_or_path"),CTt=o(":"),wTt=l(),Uke=a("ul"),fy=a("li"),Hke=a("strong"),ATt=o("vision-encoder-decoder"),LTt=o(" \u2014 "),qle=a("a"),yTt=o("FlaxVisionEncoderDecoderModel"),xTt=o(" (Vision Encoder decoder model)"),$Tt=l(),F(gy.$$.fragment),this.h()},l(m){const _=M_a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(m),u=n(m,"H1",{class:!0});var EP=s(u);f=n(EP,"A",{id:!0,class:!0,href:!0});var Jke=s(f);p=n(Jke,"SPAN",{});var Yke=s(p);T(d.$$.fragment,Yke),Yke.forEach(t),Jke.forEach(t),h=i(EP),yo=n(EP,"SPAN",{});var Kke=s(yo);td=r(Kke,"Auto Classes"),Kke.forEach(t),EP.forEach(t),Ef=i(m),pt=n(m,"P",{});var CP=s(pt);ad=r(CP,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),nd=n(CP,"CODE",{});var Zke=s(nd);X9=r(Zke,"from_pretrained()"),Zke.forEach(t),Cf=r(CP,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),CP.forEach(t),Ve=i(m),He=n(m,"P",{});var Zn=s(He);sd=r(Zn,"Instantiating one of "),es=n(Zn,"A",{href:!0});var eSe=s(es);z9=r(eSe,"AutoConfig"),eSe.forEach(t),os=r(Zn,", "),rs=n(Zn,"A",{href:!0});var oSe=s(rs);Q9=r(oSe,"AutoModel"),oSe.forEach(t),ld=r(Zn,`, and
`),ts=n(Zn,"A",{href:!0});var rSe=s(ts);W9=r(rSe,"AutoTokenizer"),rSe.forEach(t),id=r(Zn," will directly create a class of the relevant architecture. For instance"),Zn.forEach(t),wf=i(m),T(Qa.$$.fragment,m),Je=i(m),Ae=n(m,"P",{});var wP=s(Ae);UB=r(wP,"will create a model that is an instance of "),dd=n(wP,"A",{href:!0});var tSe=s(dd);HB=r(tSe,"BertModel"),tSe.forEach(t),JB=r(wP,"."),wP.forEach(t),xo=i(m),Wa=n(m,"P",{});var AP=s(Wa);YB=r(AP,"There is one class of "),Af=n(AP,"CODE",{});var aSe=s(Af);KB=r(aSe,"AutoModel"),aSe.forEach(t),Qto=r(AP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),AP.forEach(t),pZe=i(m),cd=n(m,"H2",{class:!0});var LP=s(cd);Lf=n(LP,"A",{id:!0,class:!0,href:!0});var nSe=s(Lf);Ode=n(nSe,"SPAN",{});var sSe=s(Ode);T(U9.$$.fragment,sSe),sSe.forEach(t),nSe.forEach(t),Wto=i(LP),Vde=n(LP,"SPAN",{});var lSe=s(Vde);Uto=r(lSe,"Extending the Auto Classes"),lSe.forEach(t),LP.forEach(t),_Ze=i(m),as=n(m,"P",{});var Ff=s(as);Hto=r(Ff,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Xde=n(Ff,"CODE",{});var iSe=s(Xde);Jto=r(iSe,"NewModel"),iSe.forEach(t),Yto=r(Ff,", make sure you have a "),zde=n(Ff,"CODE",{});var dSe=s(zde);Kto=r(dSe,"NewModelConfig"),dSe.forEach(t),Zto=r(Ff,` then you can add those to the auto
classes like this:`),Ff.forEach(t),bZe=i(m),T(H9.$$.fragment,m),vZe=i(m),ZB=n(m,"P",{});var cSe=s(ZB);eao=r(cSe,"You will then be able to use the auto classes like you would usually do!"),cSe.forEach(t),FZe=i(m),T(yf.$$.fragment,m),TZe=i(m),md=n(m,"H2",{class:!0});var yP=s(md);xf=n(yP,"A",{id:!0,class:!0,href:!0});var mSe=s(xf);Qde=n(mSe,"SPAN",{});var fSe=s(Qde);T(J9.$$.fragment,fSe),fSe.forEach(t),mSe.forEach(t),oao=i(yP),Wde=n(yP,"SPAN",{});var gSe=s(Wde);rao=r(gSe,"AutoConfig"),gSe.forEach(t),yP.forEach(t),MZe=i(m),$o=n(m,"DIV",{class:!0});var ht=s($o);T(Y9.$$.fragment,ht),tao=i(ht),K9=n(ht,"P",{});var xP=s(K9);aao=r(xP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),eI=n(xP,"A",{href:!0});var hSe=s(eI);nao=r(hSe,"from_pretrained()"),hSe.forEach(t),sao=r(xP," class method."),xP.forEach(t),lao=i(ht),Z9=n(ht,"P",{});var $P=s(Z9);iao=r($P,"This class cannot be instantiated directly using "),Ude=n($P,"CODE",{});var uSe=s(Ude);dao=r(uSe,"__init__()"),uSe.forEach(t),cao=r($P," (throws an error)."),$P.forEach(t),mao=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(ex.$$.fragment,ut),fao=i(ut),Hde=n(ut,"P",{});var pSe=s(Hde);gao=r(pSe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),pSe.forEach(t),hao=i(ut),fd=n(ut,"P",{});var Tf=s(fd);uao=r(Tf,"The configuration class to instantiate is selected based on the "),Jde=n(Tf,"CODE",{});var _Se=s(Jde);pao=r(_Se,"model_type"),_Se.forEach(t),_ao=r(Tf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Yde=n(Tf,"CODE",{});var bSe=s(Yde);bao=r(bSe,"pretrained_model_name_or_path"),bSe.forEach(t),vao=r(Tf,":"),Tf.forEach(t),Fao=i(ut),A=n(ut,"UL",{});var L=s(A);$f=n(L,"LI",{});var hy=s($f);Kde=n(hy,"STRONG",{});var vSe=s(Kde);Tao=r(vSe,"albert"),vSe.forEach(t),Mao=r(hy," \u2014 "),oI=n(hy,"A",{href:!0});var FSe=s(oI);Eao=r(FSe,"AlbertConfig"),FSe.forEach(t),Cao=r(hy," (ALBERT model)"),hy.forEach(t),wao=i(L),kf=n(L,"LI",{});var uy=s(kf);Zde=n(uy,"STRONG",{});var TSe=s(Zde);Aao=r(TSe,"bart"),TSe.forEach(t),Lao=r(uy," \u2014 "),rI=n(uy,"A",{href:!0});var MSe=s(rI);yao=r(MSe,"BartConfig"),MSe.forEach(t),xao=r(uy," (BART model)"),uy.forEach(t),$ao=i(L),Sf=n(L,"LI",{});var py=s(Sf);ece=n(py,"STRONG",{});var ESe=s(ece);kao=r(ESe,"beit"),ESe.forEach(t),Sao=r(py," \u2014 "),tI=n(py,"A",{href:!0});var CSe=s(tI);Rao=r(CSe,"BeitConfig"),CSe.forEach(t),Pao=r(py," (BEiT model)"),py.forEach(t),Bao=i(L),Rf=n(L,"LI",{});var _y=s(Rf);oce=n(_y,"STRONG",{});var wSe=s(oce);Iao=r(wSe,"bert"),wSe.forEach(t),Nao=r(_y," \u2014 "),aI=n(_y,"A",{href:!0});var ASe=s(aI);qao=r(ASe,"BertConfig"),ASe.forEach(t),jao=r(_y," (BERT model)"),_y.forEach(t),Dao=i(L),Pf=n(L,"LI",{});var by=s(Pf);rce=n(by,"STRONG",{});var LSe=s(rce);Gao=r(LSe,"bert-generation"),LSe.forEach(t),Oao=r(by," \u2014 "),nI=n(by,"A",{href:!0});var ySe=s(nI);Vao=r(ySe,"BertGenerationConfig"),ySe.forEach(t),Xao=r(by," (Bert Generation model)"),by.forEach(t),zao=i(L),Bf=n(L,"LI",{});var vy=s(Bf);tce=n(vy,"STRONG",{});var xSe=s(tce);Qao=r(xSe,"big_bird"),xSe.forEach(t),Wao=r(vy," \u2014 "),sI=n(vy,"A",{href:!0});var $Se=s(sI);Uao=r($Se,"BigBirdConfig"),$Se.forEach(t),Hao=r(vy," (BigBird model)"),vy.forEach(t),Jao=i(L),If=n(L,"LI",{});var Fy=s(If);ace=n(Fy,"STRONG",{});var kSe=s(ace);Yao=r(kSe,"bigbird_pegasus"),kSe.forEach(t),Kao=r(Fy," \u2014 "),lI=n(Fy,"A",{href:!0});var SSe=s(lI);Zao=r(SSe,"BigBirdPegasusConfig"),SSe.forEach(t),eno=r(Fy," (BigBird-Pegasus model)"),Fy.forEach(t),ono=i(L),Nf=n(L,"LI",{});var Ty=s(Nf);nce=n(Ty,"STRONG",{});var RSe=s(nce);rno=r(RSe,"blenderbot"),RSe.forEach(t),tno=r(Ty," \u2014 "),iI=n(Ty,"A",{href:!0});var PSe=s(iI);ano=r(PSe,"BlenderbotConfig"),PSe.forEach(t),nno=r(Ty," (Blenderbot model)"),Ty.forEach(t),sno=i(L),qf=n(L,"LI",{});var My=s(qf);sce=n(My,"STRONG",{});var BSe=s(sce);lno=r(BSe,"blenderbot-small"),BSe.forEach(t),ino=r(My," \u2014 "),dI=n(My,"A",{href:!0});var ISe=s(dI);dno=r(ISe,"BlenderbotSmallConfig"),ISe.forEach(t),cno=r(My," (BlenderbotSmall model)"),My.forEach(t),mno=i(L),jf=n(L,"LI",{});var Ey=s(jf);lce=n(Ey,"STRONG",{});var NSe=s(lce);fno=r(NSe,"bloom"),NSe.forEach(t),gno=r(Ey," \u2014 "),cI=n(Ey,"A",{href:!0});var qSe=s(cI);hno=r(qSe,"BloomConfig"),qSe.forEach(t),uno=r(Ey," (BLOOM model)"),Ey.forEach(t),pno=i(L),Df=n(L,"LI",{});var Cy=s(Df);ice=n(Cy,"STRONG",{});var jSe=s(ice);_no=r(jSe,"camembert"),jSe.forEach(t),bno=r(Cy," \u2014 "),mI=n(Cy,"A",{href:!0});var DSe=s(mI);vno=r(DSe,"CamembertConfig"),DSe.forEach(t),Fno=r(Cy," (CamemBERT model)"),Cy.forEach(t),Tno=i(L),Gf=n(L,"LI",{});var wy=s(Gf);dce=n(wy,"STRONG",{});var GSe=s(dce);Mno=r(GSe,"canine"),GSe.forEach(t),Eno=r(wy," \u2014 "),fI=n(wy,"A",{href:!0});var OSe=s(fI);Cno=r(OSe,"CanineConfig"),OSe.forEach(t),wno=r(wy," (CANINE model)"),wy.forEach(t),Ano=i(L),Of=n(L,"LI",{});var Ay=s(Of);cce=n(Ay,"STRONG",{});var VSe=s(cce);Lno=r(VSe,"clip"),VSe.forEach(t),yno=r(Ay," \u2014 "),gI=n(Ay,"A",{href:!0});var XSe=s(gI);xno=r(XSe,"CLIPConfig"),XSe.forEach(t),$no=r(Ay," (CLIP model)"),Ay.forEach(t),kno=i(L),Vf=n(L,"LI",{});var Ly=s(Vf);mce=n(Ly,"STRONG",{});var zSe=s(mce);Sno=r(zSe,"codegen"),zSe.forEach(t),Rno=r(Ly," \u2014 "),hI=n(Ly,"A",{href:!0});var QSe=s(hI);Pno=r(QSe,"CodeGenConfig"),QSe.forEach(t),Bno=r(Ly," (CodeGen model)"),Ly.forEach(t),Ino=i(L),Xf=n(L,"LI",{});var yy=s(Xf);fce=n(yy,"STRONG",{});var WSe=s(fce);Nno=r(WSe,"conditional_detr"),WSe.forEach(t),qno=r(yy," \u2014 "),uI=n(yy,"A",{href:!0});var USe=s(uI);jno=r(USe,"ConditionalDetrConfig"),USe.forEach(t),Dno=r(yy," (Conditional DETR model)"),yy.forEach(t),Gno=i(L),zf=n(L,"LI",{});var xy=s(zf);gce=n(xy,"STRONG",{});var HSe=s(gce);Ono=r(HSe,"convbert"),HSe.forEach(t),Vno=r(xy," \u2014 "),pI=n(xy,"A",{href:!0});var JSe=s(pI);Xno=r(JSe,"ConvBertConfig"),JSe.forEach(t),zno=r(xy," (ConvBERT model)"),xy.forEach(t),Qno=i(L),Qf=n(L,"LI",{});var $y=s(Qf);hce=n($y,"STRONG",{});var YSe=s(hce);Wno=r(YSe,"convnext"),YSe.forEach(t),Uno=r($y," \u2014 "),_I=n($y,"A",{href:!0});var KSe=s(_I);Hno=r(KSe,"ConvNextConfig"),KSe.forEach(t),Jno=r($y," (ConvNeXT model)"),$y.forEach(t),Yno=i(L),Wf=n(L,"LI",{});var ky=s(Wf);uce=n(ky,"STRONG",{});var ZSe=s(uce);Kno=r(ZSe,"ctrl"),ZSe.forEach(t),Zno=r(ky," \u2014 "),bI=n(ky,"A",{href:!0});var eRe=s(bI);eso=r(eRe,"CTRLConfig"),eRe.forEach(t),oso=r(ky," (CTRL model)"),ky.forEach(t),rso=i(L),Uf=n(L,"LI",{});var Sy=s(Uf);pce=n(Sy,"STRONG",{});var oRe=s(pce);tso=r(oRe,"cvt"),oRe.forEach(t),aso=r(Sy," \u2014 "),vI=n(Sy,"A",{href:!0});var rRe=s(vI);nso=r(rRe,"CvtConfig"),rRe.forEach(t),sso=r(Sy," (CvT model)"),Sy.forEach(t),lso=i(L),Hf=n(L,"LI",{});var Ry=s(Hf);_ce=n(Ry,"STRONG",{});var tRe=s(_ce);iso=r(tRe,"data2vec-audio"),tRe.forEach(t),dso=r(Ry," \u2014 "),FI=n(Ry,"A",{href:!0});var aRe=s(FI);cso=r(aRe,"Data2VecAudioConfig"),aRe.forEach(t),mso=r(Ry," (Data2VecAudio model)"),Ry.forEach(t),fso=i(L),Jf=n(L,"LI",{});var Py=s(Jf);bce=n(Py,"STRONG",{});var nRe=s(bce);gso=r(nRe,"data2vec-text"),nRe.forEach(t),hso=r(Py," \u2014 "),TI=n(Py,"A",{href:!0});var sRe=s(TI);uso=r(sRe,"Data2VecTextConfig"),sRe.forEach(t),pso=r(Py," (Data2VecText model)"),Py.forEach(t),_so=i(L),Yf=n(L,"LI",{});var By=s(Yf);vce=n(By,"STRONG",{});var lRe=s(vce);bso=r(lRe,"data2vec-vision"),lRe.forEach(t),vso=r(By," \u2014 "),MI=n(By,"A",{href:!0});var iRe=s(MI);Fso=r(iRe,"Data2VecVisionConfig"),iRe.forEach(t),Tso=r(By," (Data2VecVision model)"),By.forEach(t),Mso=i(L),Kf=n(L,"LI",{});var Iy=s(Kf);Fce=n(Iy,"STRONG",{});var dRe=s(Fce);Eso=r(dRe,"deberta"),dRe.forEach(t),Cso=r(Iy," \u2014 "),EI=n(Iy,"A",{href:!0});var cRe=s(EI);wso=r(cRe,"DebertaConfig"),cRe.forEach(t),Aso=r(Iy," (DeBERTa model)"),Iy.forEach(t),Lso=i(L),Zf=n(L,"LI",{});var Ny=s(Zf);Tce=n(Ny,"STRONG",{});var mRe=s(Tce);yso=r(mRe,"deberta-v2"),mRe.forEach(t),xso=r(Ny," \u2014 "),CI=n(Ny,"A",{href:!0});var fRe=s(CI);$so=r(fRe,"DebertaV2Config"),fRe.forEach(t),kso=r(Ny," (DeBERTa-v2 model)"),Ny.forEach(t),Sso=i(L),eg=n(L,"LI",{});var qy=s(eg);Mce=n(qy,"STRONG",{});var gRe=s(Mce);Rso=r(gRe,"decision_transformer"),gRe.forEach(t),Pso=r(qy," \u2014 "),wI=n(qy,"A",{href:!0});var hRe=s(wI);Bso=r(hRe,"DecisionTransformerConfig"),hRe.forEach(t),Iso=r(qy," (Decision Transformer model)"),qy.forEach(t),Nso=i(L),og=n(L,"LI",{});var jy=s(og);Ece=n(jy,"STRONG",{});var uRe=s(Ece);qso=r(uRe,"deformable_detr"),uRe.forEach(t),jso=r(jy," \u2014 "),AI=n(jy,"A",{href:!0});var pRe=s(AI);Dso=r(pRe,"DeformableDetrConfig"),pRe.forEach(t),Gso=r(jy," (Deformable DETR model)"),jy.forEach(t),Oso=i(L),rg=n(L,"LI",{});var _Re=s(rg);Cce=n(_Re,"STRONG",{});var STt=s(Cce);Vso=r(STt,"deit"),STt.forEach(t),Xso=r(_Re," \u2014 "),LI=n(_Re,"A",{href:!0});var RTt=s(LI);zso=r(RTt,"DeiTConfig"),RTt.forEach(t),Qso=r(_Re," (DeiT model)"),_Re.forEach(t),Wso=i(L),tg=n(L,"LI",{});var bRe=s(tg);wce=n(bRe,"STRONG",{});var PTt=s(wce);Uso=r(PTt,"detr"),PTt.forEach(t),Hso=r(bRe," \u2014 "),yI=n(bRe,"A",{href:!0});var BTt=s(yI);Jso=r(BTt,"DetrConfig"),BTt.forEach(t),Yso=r(bRe," (DETR model)"),bRe.forEach(t),Kso=i(L),ag=n(L,"LI",{});var vRe=s(ag);Ace=n(vRe,"STRONG",{});var ITt=s(Ace);Zso=r(ITt,"distilbert"),ITt.forEach(t),elo=r(vRe," \u2014 "),xI=n(vRe,"A",{href:!0});var NTt=s(xI);olo=r(NTt,"DistilBertConfig"),NTt.forEach(t),rlo=r(vRe," (DistilBERT model)"),vRe.forEach(t),tlo=i(L),ng=n(L,"LI",{});var FRe=s(ng);Lce=n(FRe,"STRONG",{});var qTt=s(Lce);alo=r(qTt,"donut-swin"),qTt.forEach(t),nlo=r(FRe," \u2014 "),$I=n(FRe,"A",{href:!0});var jTt=s($I);slo=r(jTt,"DonutSwinConfig"),jTt.forEach(t),llo=r(FRe," (DonutSwin model)"),FRe.forEach(t),ilo=i(L),sg=n(L,"LI",{});var TRe=s(sg);yce=n(TRe,"STRONG",{});var DTt=s(yce);dlo=r(DTt,"dpr"),DTt.forEach(t),clo=r(TRe," \u2014 "),kI=n(TRe,"A",{href:!0});var GTt=s(kI);mlo=r(GTt,"DPRConfig"),GTt.forEach(t),flo=r(TRe," (DPR model)"),TRe.forEach(t),glo=i(L),lg=n(L,"LI",{});var MRe=s(lg);xce=n(MRe,"STRONG",{});var OTt=s(xce);hlo=r(OTt,"dpt"),OTt.forEach(t),ulo=r(MRe," \u2014 "),SI=n(MRe,"A",{href:!0});var VTt=s(SI);plo=r(VTt,"DPTConfig"),VTt.forEach(t),_lo=r(MRe," (DPT model)"),MRe.forEach(t),blo=i(L),ig=n(L,"LI",{});var ERe=s(ig);$ce=n(ERe,"STRONG",{});var XTt=s($ce);vlo=r(XTt,"electra"),XTt.forEach(t),Flo=r(ERe," \u2014 "),RI=n(ERe,"A",{href:!0});var zTt=s(RI);Tlo=r(zTt,"ElectraConfig"),zTt.forEach(t),Mlo=r(ERe," (ELECTRA model)"),ERe.forEach(t),Elo=i(L),dg=n(L,"LI",{});var CRe=s(dg);kce=n(CRe,"STRONG",{});var QTt=s(kce);Clo=r(QTt,"encoder-decoder"),QTt.forEach(t),wlo=r(CRe," \u2014 "),PI=n(CRe,"A",{href:!0});var WTt=s(PI);Alo=r(WTt,"EncoderDecoderConfig"),WTt.forEach(t),Llo=r(CRe," (Encoder decoder model)"),CRe.forEach(t),ylo=i(L),cg=n(L,"LI",{});var wRe=s(cg);Sce=n(wRe,"STRONG",{});var UTt=s(Sce);xlo=r(UTt,"ernie"),UTt.forEach(t),$lo=r(wRe," \u2014 "),BI=n(wRe,"A",{href:!0});var HTt=s(BI);klo=r(HTt,"ErnieConfig"),HTt.forEach(t),Slo=r(wRe," (ERNIE model)"),wRe.forEach(t),Rlo=i(L),mg=n(L,"LI",{});var ARe=s(mg);Rce=n(ARe,"STRONG",{});var JTt=s(Rce);Plo=r(JTt,"flaubert"),JTt.forEach(t),Blo=r(ARe," \u2014 "),II=n(ARe,"A",{href:!0});var YTt=s(II);Ilo=r(YTt,"FlaubertConfig"),YTt.forEach(t),Nlo=r(ARe," (FlauBERT model)"),ARe.forEach(t),qlo=i(L),fg=n(L,"LI",{});var LRe=s(fg);Pce=n(LRe,"STRONG",{});var KTt=s(Pce);jlo=r(KTt,"flava"),KTt.forEach(t),Dlo=r(LRe," \u2014 "),NI=n(LRe,"A",{href:!0});var ZTt=s(NI);Glo=r(ZTt,"FlavaConfig"),ZTt.forEach(t),Olo=r(LRe," (FLAVA model)"),LRe.forEach(t),Vlo=i(L),gg=n(L,"LI",{});var yRe=s(gg);Bce=n(yRe,"STRONG",{});var eMt=s(Bce);Xlo=r(eMt,"fnet"),eMt.forEach(t),zlo=r(yRe," \u2014 "),qI=n(yRe,"A",{href:!0});var oMt=s(qI);Qlo=r(oMt,"FNetConfig"),oMt.forEach(t),Wlo=r(yRe," (FNet model)"),yRe.forEach(t),Ulo=i(L),hg=n(L,"LI",{});var xRe=s(hg);Ice=n(xRe,"STRONG",{});var rMt=s(Ice);Hlo=r(rMt,"fsmt"),rMt.forEach(t),Jlo=r(xRe," \u2014 "),jI=n(xRe,"A",{href:!0});var tMt=s(jI);Ylo=r(tMt,"FSMTConfig"),tMt.forEach(t),Klo=r(xRe," (FairSeq Machine-Translation model)"),xRe.forEach(t),Zlo=i(L),ug=n(L,"LI",{});var $Re=s(ug);Nce=n($Re,"STRONG",{});var aMt=s(Nce);eio=r(aMt,"funnel"),aMt.forEach(t),oio=r($Re," \u2014 "),DI=n($Re,"A",{href:!0});var nMt=s(DI);rio=r(nMt,"FunnelConfig"),nMt.forEach(t),tio=r($Re," (Funnel Transformer model)"),$Re.forEach(t),aio=i(L),pg=n(L,"LI",{});var kRe=s(pg);qce=n(kRe,"STRONG",{});var sMt=s(qce);nio=r(sMt,"glpn"),sMt.forEach(t),sio=r(kRe," \u2014 "),GI=n(kRe,"A",{href:!0});var lMt=s(GI);lio=r(lMt,"GLPNConfig"),lMt.forEach(t),iio=r(kRe," (GLPN model)"),kRe.forEach(t),dio=i(L),_g=n(L,"LI",{});var SRe=s(_g);jce=n(SRe,"STRONG",{});var iMt=s(jce);cio=r(iMt,"gpt2"),iMt.forEach(t),mio=r(SRe," \u2014 "),OI=n(SRe,"A",{href:!0});var dMt=s(OI);fio=r(dMt,"GPT2Config"),dMt.forEach(t),gio=r(SRe," (OpenAI GPT-2 model)"),SRe.forEach(t),hio=i(L),bg=n(L,"LI",{});var RRe=s(bg);Dce=n(RRe,"STRONG",{});var cMt=s(Dce);uio=r(cMt,"gpt_neo"),cMt.forEach(t),pio=r(RRe," \u2014 "),VI=n(RRe,"A",{href:!0});var mMt=s(VI);_io=r(mMt,"GPTNeoConfig"),mMt.forEach(t),bio=r(RRe," (GPT Neo model)"),RRe.forEach(t),vio=i(L),vg=n(L,"LI",{});var PRe=s(vg);Gce=n(PRe,"STRONG",{});var fMt=s(Gce);Fio=r(fMt,"gpt_neox"),fMt.forEach(t),Tio=r(PRe," \u2014 "),XI=n(PRe,"A",{href:!0});var gMt=s(XI);Mio=r(gMt,"GPTNeoXConfig"),gMt.forEach(t),Eio=r(PRe," (GPT NeoX model)"),PRe.forEach(t),Cio=i(L),Fg=n(L,"LI",{});var BRe=s(Fg);Oce=n(BRe,"STRONG",{});var hMt=s(Oce);wio=r(hMt,"gpt_neox_japanese"),hMt.forEach(t),Aio=r(BRe," \u2014 "),zI=n(BRe,"A",{href:!0});var uMt=s(zI);Lio=r(uMt,"GPTNeoXJapaneseConfig"),uMt.forEach(t),yio=r(BRe," (GPT NeoX Japanese model)"),BRe.forEach(t),xio=i(L),Tg=n(L,"LI",{});var IRe=s(Tg);Vce=n(IRe,"STRONG",{});var pMt=s(Vce);$io=r(pMt,"gptj"),pMt.forEach(t),kio=r(IRe," \u2014 "),QI=n(IRe,"A",{href:!0});var _Mt=s(QI);Sio=r(_Mt,"GPTJConfig"),_Mt.forEach(t),Rio=r(IRe," (GPT-J model)"),IRe.forEach(t),Pio=i(L),Mg=n(L,"LI",{});var NRe=s(Mg);Xce=n(NRe,"STRONG",{});var bMt=s(Xce);Bio=r(bMt,"groupvit"),bMt.forEach(t),Iio=r(NRe," \u2014 "),WI=n(NRe,"A",{href:!0});var vMt=s(WI);Nio=r(vMt,"GroupViTConfig"),vMt.forEach(t),qio=r(NRe," (GroupViT model)"),NRe.forEach(t),jio=i(L),Eg=n(L,"LI",{});var qRe=s(Eg);zce=n(qRe,"STRONG",{});var FMt=s(zce);Dio=r(FMt,"hubert"),FMt.forEach(t),Gio=r(qRe," \u2014 "),UI=n(qRe,"A",{href:!0});var TMt=s(UI);Oio=r(TMt,"HubertConfig"),TMt.forEach(t),Vio=r(qRe," (Hubert model)"),qRe.forEach(t),Xio=i(L),Cg=n(L,"LI",{});var jRe=s(Cg);Qce=n(jRe,"STRONG",{});var MMt=s(Qce);zio=r(MMt,"ibert"),MMt.forEach(t),Qio=r(jRe," \u2014 "),HI=n(jRe,"A",{href:!0});var EMt=s(HI);Wio=r(EMt,"IBertConfig"),EMt.forEach(t),Uio=r(jRe," (I-BERT model)"),jRe.forEach(t),Hio=i(L),wg=n(L,"LI",{});var DRe=s(wg);Wce=n(DRe,"STRONG",{});var CMt=s(Wce);Jio=r(CMt,"imagegpt"),CMt.forEach(t),Yio=r(DRe," \u2014 "),JI=n(DRe,"A",{href:!0});var wMt=s(JI);Kio=r(wMt,"ImageGPTConfig"),wMt.forEach(t),Zio=r(DRe," (ImageGPT model)"),DRe.forEach(t),edo=i(L),Ag=n(L,"LI",{});var GRe=s(Ag);Uce=n(GRe,"STRONG",{});var AMt=s(Uce);odo=r(AMt,"layoutlm"),AMt.forEach(t),rdo=r(GRe," \u2014 "),YI=n(GRe,"A",{href:!0});var LMt=s(YI);tdo=r(LMt,"LayoutLMConfig"),LMt.forEach(t),ado=r(GRe," (LayoutLM model)"),GRe.forEach(t),ndo=i(L),Lg=n(L,"LI",{});var ORe=s(Lg);Hce=n(ORe,"STRONG",{});var yMt=s(Hce);sdo=r(yMt,"layoutlmv2"),yMt.forEach(t),ldo=r(ORe," \u2014 "),KI=n(ORe,"A",{href:!0});var xMt=s(KI);ido=r(xMt,"LayoutLMv2Config"),xMt.forEach(t),ddo=r(ORe," (LayoutLMv2 model)"),ORe.forEach(t),cdo=i(L),yg=n(L,"LI",{});var VRe=s(yg);Jce=n(VRe,"STRONG",{});var $Mt=s(Jce);mdo=r($Mt,"layoutlmv3"),$Mt.forEach(t),fdo=r(VRe," \u2014 "),ZI=n(VRe,"A",{href:!0});var kMt=s(ZI);gdo=r(kMt,"LayoutLMv3Config"),kMt.forEach(t),hdo=r(VRe," (LayoutLMv3 model)"),VRe.forEach(t),udo=i(L),xg=n(L,"LI",{});var XRe=s(xg);Yce=n(XRe,"STRONG",{});var SMt=s(Yce);pdo=r(SMt,"led"),SMt.forEach(t),_do=r(XRe," \u2014 "),eN=n(XRe,"A",{href:!0});var RMt=s(eN);bdo=r(RMt,"LEDConfig"),RMt.forEach(t),vdo=r(XRe," (LED model)"),XRe.forEach(t),Fdo=i(L),$g=n(L,"LI",{});var zRe=s($g);Kce=n(zRe,"STRONG",{});var PMt=s(Kce);Tdo=r(PMt,"levit"),PMt.forEach(t),Mdo=r(zRe," \u2014 "),oN=n(zRe,"A",{href:!0});var BMt=s(oN);Edo=r(BMt,"LevitConfig"),BMt.forEach(t),Cdo=r(zRe," (LeViT model)"),zRe.forEach(t),wdo=i(L),kg=n(L,"LI",{});var QRe=s(kg);Zce=n(QRe,"STRONG",{});var IMt=s(Zce);Ado=r(IMt,"longformer"),IMt.forEach(t),Ldo=r(QRe," \u2014 "),rN=n(QRe,"A",{href:!0});var NMt=s(rN);ydo=r(NMt,"LongformerConfig"),NMt.forEach(t),xdo=r(QRe," (Longformer model)"),QRe.forEach(t),$do=i(L),Sg=n(L,"LI",{});var WRe=s(Sg);eme=n(WRe,"STRONG",{});var qMt=s(eme);kdo=r(qMt,"longt5"),qMt.forEach(t),Sdo=r(WRe," \u2014 "),tN=n(WRe,"A",{href:!0});var jMt=s(tN);Rdo=r(jMt,"LongT5Config"),jMt.forEach(t),Pdo=r(WRe," (LongT5 model)"),WRe.forEach(t),Bdo=i(L),Rg=n(L,"LI",{});var URe=s(Rg);ome=n(URe,"STRONG",{});var DMt=s(ome);Ido=r(DMt,"luke"),DMt.forEach(t),Ndo=r(URe," \u2014 "),aN=n(URe,"A",{href:!0});var GMt=s(aN);qdo=r(GMt,"LukeConfig"),GMt.forEach(t),jdo=r(URe," (LUKE model)"),URe.forEach(t),Ddo=i(L),Pg=n(L,"LI",{});var HRe=s(Pg);rme=n(HRe,"STRONG",{});var OMt=s(rme);Gdo=r(OMt,"lxmert"),OMt.forEach(t),Odo=r(HRe," \u2014 "),nN=n(HRe,"A",{href:!0});var VMt=s(nN);Vdo=r(VMt,"LxmertConfig"),VMt.forEach(t),Xdo=r(HRe," (LXMERT model)"),HRe.forEach(t),zdo=i(L),Bg=n(L,"LI",{});var JRe=s(Bg);tme=n(JRe,"STRONG",{});var XMt=s(tme);Qdo=r(XMt,"m2m_100"),XMt.forEach(t),Wdo=r(JRe," \u2014 "),sN=n(JRe,"A",{href:!0});var zMt=s(sN);Udo=r(zMt,"M2M100Config"),zMt.forEach(t),Hdo=r(JRe," (M2M100 model)"),JRe.forEach(t),Jdo=i(L),Ig=n(L,"LI",{});var YRe=s(Ig);ame=n(YRe,"STRONG",{});var QMt=s(ame);Ydo=r(QMt,"marian"),QMt.forEach(t),Kdo=r(YRe," \u2014 "),lN=n(YRe,"A",{href:!0});var WMt=s(lN);Zdo=r(WMt,"MarianConfig"),WMt.forEach(t),eco=r(YRe," (Marian model)"),YRe.forEach(t),oco=i(L),Ng=n(L,"LI",{});var KRe=s(Ng);nme=n(KRe,"STRONG",{});var UMt=s(nme);rco=r(UMt,"markuplm"),UMt.forEach(t),tco=r(KRe," \u2014 "),iN=n(KRe,"A",{href:!0});var HMt=s(iN);aco=r(HMt,"MarkupLMConfig"),HMt.forEach(t),nco=r(KRe," (MarkupLM model)"),KRe.forEach(t),sco=i(L),qg=n(L,"LI",{});var ZRe=s(qg);sme=n(ZRe,"STRONG",{});var JMt=s(sme);lco=r(JMt,"maskformer"),JMt.forEach(t),ico=r(ZRe," \u2014 "),dN=n(ZRe,"A",{href:!0});var YMt=s(dN);dco=r(YMt,"MaskFormerConfig"),YMt.forEach(t),cco=r(ZRe," (MaskFormer model)"),ZRe.forEach(t),mco=i(L),jg=n(L,"LI",{});var ePe=s(jg);lme=n(ePe,"STRONG",{});var KMt=s(lme);fco=r(KMt,"mbart"),KMt.forEach(t),gco=r(ePe," \u2014 "),cN=n(ePe,"A",{href:!0});var ZMt=s(cN);hco=r(ZMt,"MBartConfig"),ZMt.forEach(t),uco=r(ePe," (mBART model)"),ePe.forEach(t),pco=i(L),Dg=n(L,"LI",{});var oPe=s(Dg);ime=n(oPe,"STRONG",{});var eEt=s(ime);_co=r(eEt,"mctct"),eEt.forEach(t),bco=r(oPe," \u2014 "),mN=n(oPe,"A",{href:!0});var oEt=s(mN);vco=r(oEt,"MCTCTConfig"),oEt.forEach(t),Fco=r(oPe," (M-CTC-T model)"),oPe.forEach(t),Tco=i(L),Gg=n(L,"LI",{});var rPe=s(Gg);dme=n(rPe,"STRONG",{});var rEt=s(dme);Mco=r(rEt,"megatron-bert"),rEt.forEach(t),Eco=r(rPe," \u2014 "),fN=n(rPe,"A",{href:!0});var tEt=s(fN);Cco=r(tEt,"MegatronBertConfig"),tEt.forEach(t),wco=r(rPe," (Megatron-BERT model)"),rPe.forEach(t),Aco=i(L),Og=n(L,"LI",{});var tPe=s(Og);cme=n(tPe,"STRONG",{});var aEt=s(cme);Lco=r(aEt,"mobilebert"),aEt.forEach(t),yco=r(tPe," \u2014 "),gN=n(tPe,"A",{href:!0});var nEt=s(gN);xco=r(nEt,"MobileBertConfig"),nEt.forEach(t),$co=r(tPe," (MobileBERT model)"),tPe.forEach(t),kco=i(L),Vg=n(L,"LI",{});var aPe=s(Vg);mme=n(aPe,"STRONG",{});var sEt=s(mme);Sco=r(sEt,"mobilevit"),sEt.forEach(t),Rco=r(aPe," \u2014 "),hN=n(aPe,"A",{href:!0});var lEt=s(hN);Pco=r(lEt,"MobileViTConfig"),lEt.forEach(t),Bco=r(aPe," (MobileViT model)"),aPe.forEach(t),Ico=i(L),Xg=n(L,"LI",{});var nPe=s(Xg);fme=n(nPe,"STRONG",{});var iEt=s(fme);Nco=r(iEt,"mpnet"),iEt.forEach(t),qco=r(nPe," \u2014 "),uN=n(nPe,"A",{href:!0});var dEt=s(uN);jco=r(dEt,"MPNetConfig"),dEt.forEach(t),Dco=r(nPe," (MPNet model)"),nPe.forEach(t),Gco=i(L),zg=n(L,"LI",{});var sPe=s(zg);gme=n(sPe,"STRONG",{});var cEt=s(gme);Oco=r(cEt,"mt5"),cEt.forEach(t),Vco=r(sPe," \u2014 "),pN=n(sPe,"A",{href:!0});var mEt=s(pN);Xco=r(mEt,"MT5Config"),mEt.forEach(t),zco=r(sPe," (MT5 model)"),sPe.forEach(t),Qco=i(L),Qg=n(L,"LI",{});var lPe=s(Qg);hme=n(lPe,"STRONG",{});var fEt=s(hme);Wco=r(fEt,"mvp"),fEt.forEach(t),Uco=r(lPe," \u2014 "),_N=n(lPe,"A",{href:!0});var gEt=s(_N);Hco=r(gEt,"MvpConfig"),gEt.forEach(t),Jco=r(lPe," (MVP model)"),lPe.forEach(t),Yco=i(L),Wg=n(L,"LI",{});var iPe=s(Wg);ume=n(iPe,"STRONG",{});var hEt=s(ume);Kco=r(hEt,"nezha"),hEt.forEach(t),Zco=r(iPe," \u2014 "),bN=n(iPe,"A",{href:!0});var uEt=s(bN);emo=r(uEt,"NezhaConfig"),uEt.forEach(t),omo=r(iPe," (Nezha model)"),iPe.forEach(t),rmo=i(L),Ug=n(L,"LI",{});var dPe=s(Ug);pme=n(dPe,"STRONG",{});var pEt=s(pme);tmo=r(pEt,"nystromformer"),pEt.forEach(t),amo=r(dPe," \u2014 "),vN=n(dPe,"A",{href:!0});var _Et=s(vN);nmo=r(_Et,"NystromformerConfig"),_Et.forEach(t),smo=r(dPe," (Nystr\xF6mformer model)"),dPe.forEach(t),lmo=i(L),Hg=n(L,"LI",{});var cPe=s(Hg);_me=n(cPe,"STRONG",{});var bEt=s(_me);imo=r(bEt,"openai-gpt"),bEt.forEach(t),dmo=r(cPe," \u2014 "),FN=n(cPe,"A",{href:!0});var vEt=s(FN);cmo=r(vEt,"OpenAIGPTConfig"),vEt.forEach(t),mmo=r(cPe," (OpenAI GPT model)"),cPe.forEach(t),fmo=i(L),Jg=n(L,"LI",{});var mPe=s(Jg);bme=n(mPe,"STRONG",{});var FEt=s(bme);gmo=r(FEt,"opt"),FEt.forEach(t),hmo=r(mPe," \u2014 "),TN=n(mPe,"A",{href:!0});var TEt=s(TN);umo=r(TEt,"OPTConfig"),TEt.forEach(t),pmo=r(mPe," (OPT model)"),mPe.forEach(t),_mo=i(L),Yg=n(L,"LI",{});var fPe=s(Yg);vme=n(fPe,"STRONG",{});var MEt=s(vme);bmo=r(MEt,"owlvit"),MEt.forEach(t),vmo=r(fPe," \u2014 "),MN=n(fPe,"A",{href:!0});var EEt=s(MN);Fmo=r(EEt,"OwlViTConfig"),EEt.forEach(t),Tmo=r(fPe," (OWL-ViT model)"),fPe.forEach(t),Mmo=i(L),Kg=n(L,"LI",{});var gPe=s(Kg);Fme=n(gPe,"STRONG",{});var CEt=s(Fme);Emo=r(CEt,"pegasus"),CEt.forEach(t),Cmo=r(gPe," \u2014 "),EN=n(gPe,"A",{href:!0});var wEt=s(EN);wmo=r(wEt,"PegasusConfig"),wEt.forEach(t),Amo=r(gPe," (Pegasus model)"),gPe.forEach(t),Lmo=i(L),Zg=n(L,"LI",{});var hPe=s(Zg);Tme=n(hPe,"STRONG",{});var AEt=s(Tme);ymo=r(AEt,"pegasus_x"),AEt.forEach(t),xmo=r(hPe," \u2014 "),CN=n(hPe,"A",{href:!0});var LEt=s(CN);$mo=r(LEt,"PegasusXConfig"),LEt.forEach(t),kmo=r(hPe," (PEGASUS-X model)"),hPe.forEach(t),Smo=i(L),eh=n(L,"LI",{});var uPe=s(eh);Mme=n(uPe,"STRONG",{});var yEt=s(Mme);Rmo=r(yEt,"perceiver"),yEt.forEach(t),Pmo=r(uPe," \u2014 "),wN=n(uPe,"A",{href:!0});var xEt=s(wN);Bmo=r(xEt,"PerceiverConfig"),xEt.forEach(t),Imo=r(uPe," (Perceiver model)"),uPe.forEach(t),Nmo=i(L),oh=n(L,"LI",{});var pPe=s(oh);Eme=n(pPe,"STRONG",{});var $Et=s(Eme);qmo=r($Et,"plbart"),$Et.forEach(t),jmo=r(pPe," \u2014 "),AN=n(pPe,"A",{href:!0});var kEt=s(AN);Dmo=r(kEt,"PLBartConfig"),kEt.forEach(t),Gmo=r(pPe," (PLBart model)"),pPe.forEach(t),Omo=i(L),rh=n(L,"LI",{});var _Pe=s(rh);Cme=n(_Pe,"STRONG",{});var SEt=s(Cme);Vmo=r(SEt,"poolformer"),SEt.forEach(t),Xmo=r(_Pe," \u2014 "),LN=n(_Pe,"A",{href:!0});var REt=s(LN);zmo=r(REt,"PoolFormerConfig"),REt.forEach(t),Qmo=r(_Pe," (PoolFormer model)"),_Pe.forEach(t),Wmo=i(L),th=n(L,"LI",{});var bPe=s(th);wme=n(bPe,"STRONG",{});var PEt=s(wme);Umo=r(PEt,"prophetnet"),PEt.forEach(t),Hmo=r(bPe," \u2014 "),yN=n(bPe,"A",{href:!0});var BEt=s(yN);Jmo=r(BEt,"ProphetNetConfig"),BEt.forEach(t),Ymo=r(bPe," (ProphetNet model)"),bPe.forEach(t),Kmo=i(L),ah=n(L,"LI",{});var vPe=s(ah);Ame=n(vPe,"STRONG",{});var IEt=s(Ame);Zmo=r(IEt,"qdqbert"),IEt.forEach(t),efo=r(vPe," \u2014 "),xN=n(vPe,"A",{href:!0});var NEt=s(xN);ofo=r(NEt,"QDQBertConfig"),NEt.forEach(t),rfo=r(vPe," (QDQBert model)"),vPe.forEach(t),tfo=i(L),nh=n(L,"LI",{});var FPe=s(nh);Lme=n(FPe,"STRONG",{});var qEt=s(Lme);afo=r(qEt,"rag"),qEt.forEach(t),nfo=r(FPe," \u2014 "),$N=n(FPe,"A",{href:!0});var jEt=s($N);sfo=r(jEt,"RagConfig"),jEt.forEach(t),lfo=r(FPe," (RAG model)"),FPe.forEach(t),ifo=i(L),sh=n(L,"LI",{});var TPe=s(sh);yme=n(TPe,"STRONG",{});var DEt=s(yme);dfo=r(DEt,"realm"),DEt.forEach(t),cfo=r(TPe," \u2014 "),kN=n(TPe,"A",{href:!0});var GEt=s(kN);mfo=r(GEt,"RealmConfig"),GEt.forEach(t),ffo=r(TPe," (REALM model)"),TPe.forEach(t),gfo=i(L),lh=n(L,"LI",{});var MPe=s(lh);xme=n(MPe,"STRONG",{});var OEt=s(xme);hfo=r(OEt,"reformer"),OEt.forEach(t),ufo=r(MPe," \u2014 "),SN=n(MPe,"A",{href:!0});var VEt=s(SN);pfo=r(VEt,"ReformerConfig"),VEt.forEach(t),_fo=r(MPe," (Reformer model)"),MPe.forEach(t),bfo=i(L),ih=n(L,"LI",{});var EPe=s(ih);$me=n(EPe,"STRONG",{});var XEt=s($me);vfo=r(XEt,"regnet"),XEt.forEach(t),Ffo=r(EPe," \u2014 "),RN=n(EPe,"A",{href:!0});var zEt=s(RN);Tfo=r(zEt,"RegNetConfig"),zEt.forEach(t),Mfo=r(EPe," (RegNet model)"),EPe.forEach(t),Efo=i(L),dh=n(L,"LI",{});var CPe=s(dh);kme=n(CPe,"STRONG",{});var QEt=s(kme);Cfo=r(QEt,"rembert"),QEt.forEach(t),wfo=r(CPe," \u2014 "),PN=n(CPe,"A",{href:!0});var WEt=s(PN);Afo=r(WEt,"RemBertConfig"),WEt.forEach(t),Lfo=r(CPe," (RemBERT model)"),CPe.forEach(t),yfo=i(L),ch=n(L,"LI",{});var wPe=s(ch);Sme=n(wPe,"STRONG",{});var UEt=s(Sme);xfo=r(UEt,"resnet"),UEt.forEach(t),$fo=r(wPe," \u2014 "),BN=n(wPe,"A",{href:!0});var HEt=s(BN);kfo=r(HEt,"ResNetConfig"),HEt.forEach(t),Sfo=r(wPe," (ResNet model)"),wPe.forEach(t),Rfo=i(L),mh=n(L,"LI",{});var APe=s(mh);Rme=n(APe,"STRONG",{});var JEt=s(Rme);Pfo=r(JEt,"retribert"),JEt.forEach(t),Bfo=r(APe," \u2014 "),IN=n(APe,"A",{href:!0});var YEt=s(IN);Ifo=r(YEt,"RetriBertConfig"),YEt.forEach(t),Nfo=r(APe," (RetriBERT model)"),APe.forEach(t),qfo=i(L),fh=n(L,"LI",{});var LPe=s(fh);Pme=n(LPe,"STRONG",{});var KEt=s(Pme);jfo=r(KEt,"roberta"),KEt.forEach(t),Dfo=r(LPe," \u2014 "),NN=n(LPe,"A",{href:!0});var ZEt=s(NN);Gfo=r(ZEt,"RobertaConfig"),ZEt.forEach(t),Ofo=r(LPe," (RoBERTa model)"),LPe.forEach(t),Vfo=i(L),gh=n(L,"LI",{});var yPe=s(gh);Bme=n(yPe,"STRONG",{});var e4t=s(Bme);Xfo=r(e4t,"roformer"),e4t.forEach(t),zfo=r(yPe," \u2014 "),qN=n(yPe,"A",{href:!0});var o4t=s(qN);Qfo=r(o4t,"RoFormerConfig"),o4t.forEach(t),Wfo=r(yPe," (RoFormer model)"),yPe.forEach(t),Ufo=i(L),hh=n(L,"LI",{});var xPe=s(hh);Ime=n(xPe,"STRONG",{});var r4t=s(Ime);Hfo=r(r4t,"segformer"),r4t.forEach(t),Jfo=r(xPe," \u2014 "),jN=n(xPe,"A",{href:!0});var t4t=s(jN);Yfo=r(t4t,"SegformerConfig"),t4t.forEach(t),Kfo=r(xPe," (SegFormer model)"),xPe.forEach(t),Zfo=i(L),uh=n(L,"LI",{});var $Pe=s(uh);Nme=n($Pe,"STRONG",{});var a4t=s(Nme);ego=r(a4t,"sew"),a4t.forEach(t),ogo=r($Pe," \u2014 "),DN=n($Pe,"A",{href:!0});var n4t=s(DN);rgo=r(n4t,"SEWConfig"),n4t.forEach(t),tgo=r($Pe," (SEW model)"),$Pe.forEach(t),ago=i(L),ph=n(L,"LI",{});var kPe=s(ph);qme=n(kPe,"STRONG",{});var s4t=s(qme);ngo=r(s4t,"sew-d"),s4t.forEach(t),sgo=r(kPe," \u2014 "),GN=n(kPe,"A",{href:!0});var l4t=s(GN);lgo=r(l4t,"SEWDConfig"),l4t.forEach(t),igo=r(kPe," (SEW-D model)"),kPe.forEach(t),dgo=i(L),_h=n(L,"LI",{});var SPe=s(_h);jme=n(SPe,"STRONG",{});var i4t=s(jme);cgo=r(i4t,"speech-encoder-decoder"),i4t.forEach(t),mgo=r(SPe," \u2014 "),ON=n(SPe,"A",{href:!0});var d4t=s(ON);fgo=r(d4t,"SpeechEncoderDecoderConfig"),d4t.forEach(t),ggo=r(SPe," (Speech Encoder decoder model)"),SPe.forEach(t),hgo=i(L),bh=n(L,"LI",{});var RPe=s(bh);Dme=n(RPe,"STRONG",{});var c4t=s(Dme);ugo=r(c4t,"speech_to_text"),c4t.forEach(t),pgo=r(RPe," \u2014 "),VN=n(RPe,"A",{href:!0});var m4t=s(VN);_go=r(m4t,"Speech2TextConfig"),m4t.forEach(t),bgo=r(RPe," (Speech2Text model)"),RPe.forEach(t),vgo=i(L),vh=n(L,"LI",{});var PPe=s(vh);Gme=n(PPe,"STRONG",{});var f4t=s(Gme);Fgo=r(f4t,"speech_to_text_2"),f4t.forEach(t),Tgo=r(PPe," \u2014 "),XN=n(PPe,"A",{href:!0});var g4t=s(XN);Mgo=r(g4t,"Speech2Text2Config"),g4t.forEach(t),Ego=r(PPe," (Speech2Text2 model)"),PPe.forEach(t),Cgo=i(L),Fh=n(L,"LI",{});var BPe=s(Fh);Ome=n(BPe,"STRONG",{});var h4t=s(Ome);wgo=r(h4t,"splinter"),h4t.forEach(t),Ago=r(BPe," \u2014 "),zN=n(BPe,"A",{href:!0});var u4t=s(zN);Lgo=r(u4t,"SplinterConfig"),u4t.forEach(t),ygo=r(BPe," (Splinter model)"),BPe.forEach(t),xgo=i(L),Th=n(L,"LI",{});var IPe=s(Th);Vme=n(IPe,"STRONG",{});var p4t=s(Vme);$go=r(p4t,"squeezebert"),p4t.forEach(t),kgo=r(IPe," \u2014 "),QN=n(IPe,"A",{href:!0});var _4t=s(QN);Sgo=r(_4t,"SqueezeBertConfig"),_4t.forEach(t),Rgo=r(IPe," (SqueezeBERT model)"),IPe.forEach(t),Pgo=i(L),Mh=n(L,"LI",{});var NPe=s(Mh);Xme=n(NPe,"STRONG",{});var b4t=s(Xme);Bgo=r(b4t,"swin"),b4t.forEach(t),Igo=r(NPe," \u2014 "),WN=n(NPe,"A",{href:!0});var v4t=s(WN);Ngo=r(v4t,"SwinConfig"),v4t.forEach(t),qgo=r(NPe," (Swin Transformer model)"),NPe.forEach(t),jgo=i(L),Eh=n(L,"LI",{});var qPe=s(Eh);zme=n(qPe,"STRONG",{});var F4t=s(zme);Dgo=r(F4t,"swinv2"),F4t.forEach(t),Ggo=r(qPe," \u2014 "),UN=n(qPe,"A",{href:!0});var T4t=s(UN);Ogo=r(T4t,"Swinv2Config"),T4t.forEach(t),Vgo=r(qPe," (Swin Transformer V2 model)"),qPe.forEach(t),Xgo=i(L),Ch=n(L,"LI",{});var jPe=s(Ch);Qme=n(jPe,"STRONG",{});var M4t=s(Qme);zgo=r(M4t,"t5"),M4t.forEach(t),Qgo=r(jPe," \u2014 "),HN=n(jPe,"A",{href:!0});var E4t=s(HN);Wgo=r(E4t,"T5Config"),E4t.forEach(t),Ugo=r(jPe," (T5 model)"),jPe.forEach(t),Hgo=i(L),wh=n(L,"LI",{});var DPe=s(wh);Wme=n(DPe,"STRONG",{});var C4t=s(Wme);Jgo=r(C4t,"tapas"),C4t.forEach(t),Ygo=r(DPe," \u2014 "),JN=n(DPe,"A",{href:!0});var w4t=s(JN);Kgo=r(w4t,"TapasConfig"),w4t.forEach(t),Zgo=r(DPe," (TAPAS model)"),DPe.forEach(t),eho=i(L),Ah=n(L,"LI",{});var GPe=s(Ah);Ume=n(GPe,"STRONG",{});var A4t=s(Ume);oho=r(A4t,"trajectory_transformer"),A4t.forEach(t),rho=r(GPe," \u2014 "),YN=n(GPe,"A",{href:!0});var L4t=s(YN);tho=r(L4t,"TrajectoryTransformerConfig"),L4t.forEach(t),aho=r(GPe," (Trajectory Transformer model)"),GPe.forEach(t),nho=i(L),Lh=n(L,"LI",{});var OPe=s(Lh);Hme=n(OPe,"STRONG",{});var y4t=s(Hme);sho=r(y4t,"transfo-xl"),y4t.forEach(t),lho=r(OPe," \u2014 "),KN=n(OPe,"A",{href:!0});var x4t=s(KN);iho=r(x4t,"TransfoXLConfig"),x4t.forEach(t),dho=r(OPe," (Transformer-XL model)"),OPe.forEach(t),cho=i(L),yh=n(L,"LI",{});var VPe=s(yh);Jme=n(VPe,"STRONG",{});var $4t=s(Jme);mho=r($4t,"trocr"),$4t.forEach(t),fho=r(VPe," \u2014 "),ZN=n(VPe,"A",{href:!0});var k4t=s(ZN);gho=r(k4t,"TrOCRConfig"),k4t.forEach(t),hho=r(VPe," (TrOCR model)"),VPe.forEach(t),uho=i(L),xh=n(L,"LI",{});var XPe=s(xh);Yme=n(XPe,"STRONG",{});var S4t=s(Yme);pho=r(S4t,"unispeech"),S4t.forEach(t),_ho=r(XPe," \u2014 "),eq=n(XPe,"A",{href:!0});var R4t=s(eq);bho=r(R4t,"UniSpeechConfig"),R4t.forEach(t),vho=r(XPe," (UniSpeech model)"),XPe.forEach(t),Fho=i(L),$h=n(L,"LI",{});var zPe=s($h);Kme=n(zPe,"STRONG",{});var P4t=s(Kme);Tho=r(P4t,"unispeech-sat"),P4t.forEach(t),Mho=r(zPe," \u2014 "),oq=n(zPe,"A",{href:!0});var B4t=s(oq);Eho=r(B4t,"UniSpeechSatConfig"),B4t.forEach(t),Cho=r(zPe," (UniSpeechSat model)"),zPe.forEach(t),who=i(L),kh=n(L,"LI",{});var QPe=s(kh);Zme=n(QPe,"STRONG",{});var I4t=s(Zme);Aho=r(I4t,"van"),I4t.forEach(t),Lho=r(QPe," \u2014 "),rq=n(QPe,"A",{href:!0});var N4t=s(rq);yho=r(N4t,"VanConfig"),N4t.forEach(t),xho=r(QPe," (VAN model)"),QPe.forEach(t),$ho=i(L),Sh=n(L,"LI",{});var WPe=s(Sh);efe=n(WPe,"STRONG",{});var q4t=s(efe);kho=r(q4t,"videomae"),q4t.forEach(t),Sho=r(WPe," \u2014 "),tq=n(WPe,"A",{href:!0});var j4t=s(tq);Rho=r(j4t,"VideoMAEConfig"),j4t.forEach(t),Pho=r(WPe," (VideoMAE model)"),WPe.forEach(t),Bho=i(L),Rh=n(L,"LI",{});var UPe=s(Rh);ofe=n(UPe,"STRONG",{});var D4t=s(ofe);Iho=r(D4t,"vilt"),D4t.forEach(t),Nho=r(UPe," \u2014 "),aq=n(UPe,"A",{href:!0});var G4t=s(aq);qho=r(G4t,"ViltConfig"),G4t.forEach(t),jho=r(UPe," (ViLT model)"),UPe.forEach(t),Dho=i(L),Ph=n(L,"LI",{});var HPe=s(Ph);rfe=n(HPe,"STRONG",{});var O4t=s(rfe);Gho=r(O4t,"vision-encoder-decoder"),O4t.forEach(t),Oho=r(HPe," \u2014 "),nq=n(HPe,"A",{href:!0});var V4t=s(nq);Vho=r(V4t,"VisionEncoderDecoderConfig"),V4t.forEach(t),Xho=r(HPe," (Vision Encoder decoder model)"),HPe.forEach(t),zho=i(L),Bh=n(L,"LI",{});var JPe=s(Bh);tfe=n(JPe,"STRONG",{});var X4t=s(tfe);Qho=r(X4t,"vision-text-dual-encoder"),X4t.forEach(t),Who=r(JPe," \u2014 "),sq=n(JPe,"A",{href:!0});var z4t=s(sq);Uho=r(z4t,"VisionTextDualEncoderConfig"),z4t.forEach(t),Hho=r(JPe," (VisionTextDualEncoder model)"),JPe.forEach(t),Jho=i(L),Ih=n(L,"LI",{});var YPe=s(Ih);afe=n(YPe,"STRONG",{});var Q4t=s(afe);Yho=r(Q4t,"visual_bert"),Q4t.forEach(t),Kho=r(YPe," \u2014 "),lq=n(YPe,"A",{href:!0});var W4t=s(lq);Zho=r(W4t,"VisualBertConfig"),W4t.forEach(t),euo=r(YPe," (VisualBERT model)"),YPe.forEach(t),ouo=i(L),Nh=n(L,"LI",{});var KPe=s(Nh);nfe=n(KPe,"STRONG",{});var U4t=s(nfe);ruo=r(U4t,"vit"),U4t.forEach(t),tuo=r(KPe," \u2014 "),iq=n(KPe,"A",{href:!0});var H4t=s(iq);auo=r(H4t,"ViTConfig"),H4t.forEach(t),nuo=r(KPe," (ViT model)"),KPe.forEach(t),suo=i(L),qh=n(L,"LI",{});var ZPe=s(qh);sfe=n(ZPe,"STRONG",{});var J4t=s(sfe);luo=r(J4t,"vit_mae"),J4t.forEach(t),iuo=r(ZPe," \u2014 "),dq=n(ZPe,"A",{href:!0});var Y4t=s(dq);duo=r(Y4t,"ViTMAEConfig"),Y4t.forEach(t),cuo=r(ZPe," (ViTMAE model)"),ZPe.forEach(t),muo=i(L),jh=n(L,"LI",{});var eBe=s(jh);lfe=n(eBe,"STRONG",{});var K4t=s(lfe);fuo=r(K4t,"vit_msn"),K4t.forEach(t),guo=r(eBe," \u2014 "),cq=n(eBe,"A",{href:!0});var Z4t=s(cq);huo=r(Z4t,"ViTMSNConfig"),Z4t.forEach(t),uuo=r(eBe," (ViTMSN model)"),eBe.forEach(t),puo=i(L),Dh=n(L,"LI",{});var oBe=s(Dh);ife=n(oBe,"STRONG",{});var eCt=s(ife);_uo=r(eCt,"wav2vec2"),eCt.forEach(t),buo=r(oBe," \u2014 "),mq=n(oBe,"A",{href:!0});var oCt=s(mq);vuo=r(oCt,"Wav2Vec2Config"),oCt.forEach(t),Fuo=r(oBe," (Wav2Vec2 model)"),oBe.forEach(t),Tuo=i(L),Gh=n(L,"LI",{});var rBe=s(Gh);dfe=n(rBe,"STRONG",{});var rCt=s(dfe);Muo=r(rCt,"wav2vec2-conformer"),rCt.forEach(t),Euo=r(rBe," \u2014 "),fq=n(rBe,"A",{href:!0});var tCt=s(fq);Cuo=r(tCt,"Wav2Vec2ConformerConfig"),tCt.forEach(t),wuo=r(rBe," (Wav2Vec2-Conformer model)"),rBe.forEach(t),Auo=i(L),Oh=n(L,"LI",{});var tBe=s(Oh);cfe=n(tBe,"STRONG",{});var aCt=s(cfe);Luo=r(aCt,"wavlm"),aCt.forEach(t),yuo=r(tBe," \u2014 "),gq=n(tBe,"A",{href:!0});var nCt=s(gq);xuo=r(nCt,"WavLMConfig"),nCt.forEach(t),$uo=r(tBe," (WavLM model)"),tBe.forEach(t),kuo=i(L),Vh=n(L,"LI",{});var aBe=s(Vh);mfe=n(aBe,"STRONG",{});var sCt=s(mfe);Suo=r(sCt,"xclip"),sCt.forEach(t),Ruo=r(aBe," \u2014 "),hq=n(aBe,"A",{href:!0});var lCt=s(hq);Puo=r(lCt,"XCLIPConfig"),lCt.forEach(t),Buo=r(aBe," (X-CLIP model)"),aBe.forEach(t),Iuo=i(L),Xh=n(L,"LI",{});var nBe=s(Xh);ffe=n(nBe,"STRONG",{});var iCt=s(ffe);Nuo=r(iCt,"xglm"),iCt.forEach(t),quo=r(nBe," \u2014 "),uq=n(nBe,"A",{href:!0});var dCt=s(uq);juo=r(dCt,"XGLMConfig"),dCt.forEach(t),Duo=r(nBe," (XGLM model)"),nBe.forEach(t),Guo=i(L),zh=n(L,"LI",{});var sBe=s(zh);gfe=n(sBe,"STRONG",{});var cCt=s(gfe);Ouo=r(cCt,"xlm"),cCt.forEach(t),Vuo=r(sBe," \u2014 "),pq=n(sBe,"A",{href:!0});var mCt=s(pq);Xuo=r(mCt,"XLMConfig"),mCt.forEach(t),zuo=r(sBe," (XLM model)"),sBe.forEach(t),Quo=i(L),Qh=n(L,"LI",{});var lBe=s(Qh);hfe=n(lBe,"STRONG",{});var fCt=s(hfe);Wuo=r(fCt,"xlm-prophetnet"),fCt.forEach(t),Uuo=r(lBe," \u2014 "),_q=n(lBe,"A",{href:!0});var gCt=s(_q);Huo=r(gCt,"XLMProphetNetConfig"),gCt.forEach(t),Juo=r(lBe," (XLM-ProphetNet model)"),lBe.forEach(t),Yuo=i(L),Wh=n(L,"LI",{});var iBe=s(Wh);ufe=n(iBe,"STRONG",{});var hCt=s(ufe);Kuo=r(hCt,"xlm-roberta"),hCt.forEach(t),Zuo=r(iBe," \u2014 "),bq=n(iBe,"A",{href:!0});var uCt=s(bq);epo=r(uCt,"XLMRobertaConfig"),uCt.forEach(t),opo=r(iBe," (XLM-RoBERTa model)"),iBe.forEach(t),rpo=i(L),Uh=n(L,"LI",{});var dBe=s(Uh);pfe=n(dBe,"STRONG",{});var pCt=s(pfe);tpo=r(pCt,"xlm-roberta-xl"),pCt.forEach(t),apo=r(dBe," \u2014 "),vq=n(dBe,"A",{href:!0});var _Ct=s(vq);npo=r(_Ct,"XLMRobertaXLConfig"),_Ct.forEach(t),spo=r(dBe," (XLM-RoBERTa-XL model)"),dBe.forEach(t),lpo=i(L),Hh=n(L,"LI",{});var cBe=s(Hh);_fe=n(cBe,"STRONG",{});var bCt=s(_fe);ipo=r(bCt,"xlnet"),bCt.forEach(t),dpo=r(cBe," \u2014 "),Fq=n(cBe,"A",{href:!0});var vCt=s(Fq);cpo=r(vCt,"XLNetConfig"),vCt.forEach(t),mpo=r(cBe," (XLNet model)"),cBe.forEach(t),fpo=i(L),Jh=n(L,"LI",{});var mBe=s(Jh);bfe=n(mBe,"STRONG",{});var FCt=s(bfe);gpo=r(FCt,"yolos"),FCt.forEach(t),hpo=r(mBe," \u2014 "),Tq=n(mBe,"A",{href:!0});var TCt=s(Tq);upo=r(TCt,"YolosConfig"),TCt.forEach(t),ppo=r(mBe," (YOLOS model)"),mBe.forEach(t),_po=i(L),Yh=n(L,"LI",{});var fBe=s(Yh);vfe=n(fBe,"STRONG",{});var MCt=s(vfe);bpo=r(MCt,"yoso"),MCt.forEach(t),vpo=r(fBe," \u2014 "),Mq=n(fBe,"A",{href:!0});var ECt=s(Mq);Fpo=r(ECt,"YosoConfig"),ECt.forEach(t),Tpo=r(fBe," (YOSO model)"),fBe.forEach(t),L.forEach(t),Mpo=i(ut),T(Kh.$$.fragment,ut),ut.forEach(t),Epo=i(ht),Zh=n(ht,"DIV",{class:!0});var $oo=s(Zh);T(ox.$$.fragment,$oo),Cpo=i($oo),Ffe=n($oo,"P",{});var CCt=s(Ffe);wpo=r(CCt,"Register a new configuration for this class."),CCt.forEach(t),$oo.forEach(t),ht.forEach(t),EZe=i(m),gd=n(m,"H2",{class:!0});var koo=s(gd);eu=n(koo,"A",{id:!0,class:!0,href:!0});var wCt=s(eu);Tfe=n(wCt,"SPAN",{});var ACt=s(Tfe);T(rx.$$.fragment,ACt),ACt.forEach(t),wCt.forEach(t),Apo=i(koo),Mfe=n(koo,"SPAN",{});var LCt=s(Mfe);Lpo=r(LCt,"AutoTokenizer"),LCt.forEach(t),koo.forEach(t),CZe=i(m),ko=n(m,"DIV",{class:!0});var Ml=s(ko);T(tx.$$.fragment,Ml),ypo=i(Ml),ax=n(Ml,"P",{});var Soo=s(ax);xpo=r(Soo,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),Eq=n(Soo,"A",{href:!0});var yCt=s(Eq);$po=r(yCt,"AutoTokenizer.from_pretrained()"),yCt.forEach(t),kpo=r(Soo," class method."),Soo.forEach(t),Spo=i(Ml),nx=n(Ml,"P",{});var Roo=s(nx);Rpo=r(Roo,"This class cannot be instantiated directly using "),Efe=n(Roo,"CODE",{});var xCt=s(Efe);Ppo=r(xCt,"__init__()"),xCt.forEach(t),Bpo=r(Roo," (throws an error)."),Roo.forEach(t),Ipo=i(Ml),Br=n(Ml,"DIV",{class:!0});var El=s(Br);T(sx.$$.fragment,El),Npo=i(El),Cfe=n(El,"P",{});var $Ct=s(Cfe);qpo=r($Ct,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),$Ct.forEach(t),jpo=i(El),Ua=n(El,"P",{});var Dy=s(Ua);Dpo=r(Dy,"The tokenizer class to instantiate is selected based on the "),wfe=n(Dy,"CODE",{});var kCt=s(wfe);Gpo=r(kCt,"model_type"),kCt.forEach(t),Opo=r(Dy,` property of the config object (either
passed as an argument or loaded from `),Afe=n(Dy,"CODE",{});var SCt=s(Afe);Vpo=r(SCt,"pretrained_model_name_or_path"),SCt.forEach(t),Xpo=r(Dy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lfe=n(Dy,"CODE",{});var RCt=s(Lfe);zpo=r(RCt,"pretrained_model_name_or_path"),RCt.forEach(t),Qpo=r(Dy,":"),Dy.forEach(t),Wpo=i(El),k=n(El,"UL",{});var S=s(k);ns=n(S,"LI",{});var kP=s(ns);yfe=n(kP,"STRONG",{});var PCt=s(yfe);Upo=r(PCt,"albert"),PCt.forEach(t),Hpo=r(kP," \u2014 "),Cq=n(kP,"A",{href:!0});var BCt=s(Cq);Jpo=r(BCt,"AlbertTokenizer"),BCt.forEach(t),Ypo=r(kP," or "),wq=n(kP,"A",{href:!0});var ICt=s(wq);Kpo=r(ICt,"AlbertTokenizerFast"),ICt.forEach(t),Zpo=r(kP," (ALBERT model)"),kP.forEach(t),e_o=i(S),ss=n(S,"LI",{});var SP=s(ss);xfe=n(SP,"STRONG",{});var NCt=s(xfe);o_o=r(NCt,"bart"),NCt.forEach(t),r_o=r(SP," \u2014 "),Aq=n(SP,"A",{href:!0});var qCt=s(Aq);t_o=r(qCt,"BartTokenizer"),qCt.forEach(t),a_o=r(SP," or "),Lq=n(SP,"A",{href:!0});var jCt=s(Lq);n_o=r(jCt,"BartTokenizerFast"),jCt.forEach(t),s_o=r(SP," (BART model)"),SP.forEach(t),l_o=i(S),ls=n(S,"LI",{});var RP=s(ls);$fe=n(RP,"STRONG",{});var DCt=s($fe);i_o=r(DCt,"barthez"),DCt.forEach(t),d_o=r(RP," \u2014 "),yq=n(RP,"A",{href:!0});var GCt=s(yq);c_o=r(GCt,"BarthezTokenizer"),GCt.forEach(t),m_o=r(RP," or "),xq=n(RP,"A",{href:!0});var OCt=s(xq);f_o=r(OCt,"BarthezTokenizerFast"),OCt.forEach(t),g_o=r(RP," (BARThez model)"),RP.forEach(t),h_o=i(S),ou=n(S,"LI",{});var gBe=s(ou);kfe=n(gBe,"STRONG",{});var VCt=s(kfe);u_o=r(VCt,"bartpho"),VCt.forEach(t),p_o=r(gBe," \u2014 "),$q=n(gBe,"A",{href:!0});var XCt=s($q);__o=r(XCt,"BartphoTokenizer"),XCt.forEach(t),b_o=r(gBe," (BARTpho model)"),gBe.forEach(t),v_o=i(S),is=n(S,"LI",{});var PP=s(is);Sfe=n(PP,"STRONG",{});var zCt=s(Sfe);F_o=r(zCt,"bert"),zCt.forEach(t),T_o=r(PP," \u2014 "),kq=n(PP,"A",{href:!0});var QCt=s(kq);M_o=r(QCt,"BertTokenizer"),QCt.forEach(t),E_o=r(PP," or "),Sq=n(PP,"A",{href:!0});var WCt=s(Sq);C_o=r(WCt,"BertTokenizerFast"),WCt.forEach(t),w_o=r(PP," (BERT model)"),PP.forEach(t),A_o=i(S),ru=n(S,"LI",{});var hBe=s(ru);Rfe=n(hBe,"STRONG",{});var UCt=s(Rfe);L_o=r(UCt,"bert-generation"),UCt.forEach(t),y_o=r(hBe," \u2014 "),Rq=n(hBe,"A",{href:!0});var HCt=s(Rq);x_o=r(HCt,"BertGenerationTokenizer"),HCt.forEach(t),$_o=r(hBe," (Bert Generation model)"),hBe.forEach(t),k_o=i(S),tu=n(S,"LI",{});var uBe=s(tu);Pfe=n(uBe,"STRONG",{});var JCt=s(Pfe);S_o=r(JCt,"bert-japanese"),JCt.forEach(t),R_o=r(uBe," \u2014 "),Pq=n(uBe,"A",{href:!0});var YCt=s(Pq);P_o=r(YCt,"BertJapaneseTokenizer"),YCt.forEach(t),B_o=r(uBe," (BertJapanese model)"),uBe.forEach(t),I_o=i(S),au=n(S,"LI",{});var pBe=s(au);Bfe=n(pBe,"STRONG",{});var KCt=s(Bfe);N_o=r(KCt,"bertweet"),KCt.forEach(t),q_o=r(pBe," \u2014 "),Bq=n(pBe,"A",{href:!0});var ZCt=s(Bq);j_o=r(ZCt,"BertweetTokenizer"),ZCt.forEach(t),D_o=r(pBe," (BERTweet model)"),pBe.forEach(t),G_o=i(S),ds=n(S,"LI",{});var BP=s(ds);Ife=n(BP,"STRONG",{});var e3t=s(Ife);O_o=r(e3t,"big_bird"),e3t.forEach(t),V_o=r(BP," \u2014 "),Iq=n(BP,"A",{href:!0});var o3t=s(Iq);X_o=r(o3t,"BigBirdTokenizer"),o3t.forEach(t),z_o=r(BP," or "),Nq=n(BP,"A",{href:!0});var r3t=s(Nq);Q_o=r(r3t,"BigBirdTokenizerFast"),r3t.forEach(t),W_o=r(BP," (BigBird model)"),BP.forEach(t),U_o=i(S),cs=n(S,"LI",{});var IP=s(cs);Nfe=n(IP,"STRONG",{});var t3t=s(Nfe);H_o=r(t3t,"bigbird_pegasus"),t3t.forEach(t),J_o=r(IP," \u2014 "),qq=n(IP,"A",{href:!0});var a3t=s(qq);Y_o=r(a3t,"PegasusTokenizer"),a3t.forEach(t),K_o=r(IP," or "),jq=n(IP,"A",{href:!0});var n3t=s(jq);Z_o=r(n3t,"PegasusTokenizerFast"),n3t.forEach(t),e2o=r(IP," (BigBird-Pegasus model)"),IP.forEach(t),o2o=i(S),ms=n(S,"LI",{});var NP=s(ms);qfe=n(NP,"STRONG",{});var s3t=s(qfe);r2o=r(s3t,"blenderbot"),s3t.forEach(t),t2o=r(NP," \u2014 "),Dq=n(NP,"A",{href:!0});var l3t=s(Dq);a2o=r(l3t,"BlenderbotTokenizer"),l3t.forEach(t),n2o=r(NP," or "),Gq=n(NP,"A",{href:!0});var i3t=s(Gq);s2o=r(i3t,"BlenderbotTokenizerFast"),i3t.forEach(t),l2o=r(NP," (Blenderbot model)"),NP.forEach(t),i2o=i(S),nu=n(S,"LI",{});var _Be=s(nu);jfe=n(_Be,"STRONG",{});var d3t=s(jfe);d2o=r(d3t,"blenderbot-small"),d3t.forEach(t),c2o=r(_Be," \u2014 "),Oq=n(_Be,"A",{href:!0});var c3t=s(Oq);m2o=r(c3t,"BlenderbotSmallTokenizer"),c3t.forEach(t),f2o=r(_Be," (BlenderbotSmall model)"),_Be.forEach(t),g2o=i(S),su=n(S,"LI",{});var bBe=s(su);Dfe=n(bBe,"STRONG",{});var m3t=s(Dfe);h2o=r(m3t,"bloom"),m3t.forEach(t),u2o=r(bBe," \u2014 "),Vq=n(bBe,"A",{href:!0});var f3t=s(Vq);p2o=r(f3t,"BloomTokenizerFast"),f3t.forEach(t),_2o=r(bBe," (BLOOM model)"),bBe.forEach(t),b2o=i(S),lu=n(S,"LI",{});var vBe=s(lu);Gfe=n(vBe,"STRONG",{});var g3t=s(Gfe);v2o=r(g3t,"byt5"),g3t.forEach(t),F2o=r(vBe," \u2014 "),Xq=n(vBe,"A",{href:!0});var h3t=s(Xq);T2o=r(h3t,"ByT5Tokenizer"),h3t.forEach(t),M2o=r(vBe," (ByT5 model)"),vBe.forEach(t),E2o=i(S),fs=n(S,"LI",{});var qP=s(fs);Ofe=n(qP,"STRONG",{});var u3t=s(Ofe);C2o=r(u3t,"camembert"),u3t.forEach(t),w2o=r(qP," \u2014 "),zq=n(qP,"A",{href:!0});var p3t=s(zq);A2o=r(p3t,"CamembertTokenizer"),p3t.forEach(t),L2o=r(qP," or "),Qq=n(qP,"A",{href:!0});var _3t=s(Qq);y2o=r(_3t,"CamembertTokenizerFast"),_3t.forEach(t),x2o=r(qP," (CamemBERT model)"),qP.forEach(t),$2o=i(S),iu=n(S,"LI",{});var FBe=s(iu);Vfe=n(FBe,"STRONG",{});var b3t=s(Vfe);k2o=r(b3t,"canine"),b3t.forEach(t),S2o=r(FBe," \u2014 "),Wq=n(FBe,"A",{href:!0});var v3t=s(Wq);R2o=r(v3t,"CanineTokenizer"),v3t.forEach(t),P2o=r(FBe," (CANINE model)"),FBe.forEach(t),B2o=i(S),gs=n(S,"LI",{});var jP=s(gs);Xfe=n(jP,"STRONG",{});var F3t=s(Xfe);I2o=r(F3t,"clip"),F3t.forEach(t),N2o=r(jP," \u2014 "),Uq=n(jP,"A",{href:!0});var T3t=s(Uq);q2o=r(T3t,"CLIPTokenizer"),T3t.forEach(t),j2o=r(jP," or "),Hq=n(jP,"A",{href:!0});var M3t=s(Hq);D2o=r(M3t,"CLIPTokenizerFast"),M3t.forEach(t),G2o=r(jP," (CLIP model)"),jP.forEach(t),O2o=i(S),hs=n(S,"LI",{});var DP=s(hs);zfe=n(DP,"STRONG",{});var E3t=s(zfe);V2o=r(E3t,"codegen"),E3t.forEach(t),X2o=r(DP," \u2014 "),Jq=n(DP,"A",{href:!0});var C3t=s(Jq);z2o=r(C3t,"CodeGenTokenizer"),C3t.forEach(t),Q2o=r(DP," or "),Yq=n(DP,"A",{href:!0});var w3t=s(Yq);W2o=r(w3t,"CodeGenTokenizerFast"),w3t.forEach(t),U2o=r(DP," (CodeGen model)"),DP.forEach(t),H2o=i(S),us=n(S,"LI",{});var GP=s(us);Qfe=n(GP,"STRONG",{});var A3t=s(Qfe);J2o=r(A3t,"convbert"),A3t.forEach(t),Y2o=r(GP," \u2014 "),Kq=n(GP,"A",{href:!0});var L3t=s(Kq);K2o=r(L3t,"ConvBertTokenizer"),L3t.forEach(t),Z2o=r(GP," or "),Zq=n(GP,"A",{href:!0});var y3t=s(Zq);ebo=r(y3t,"ConvBertTokenizerFast"),y3t.forEach(t),obo=r(GP," (ConvBERT model)"),GP.forEach(t),rbo=i(S),ps=n(S,"LI",{});var OP=s(ps);Wfe=n(OP,"STRONG",{});var x3t=s(Wfe);tbo=r(x3t,"cpm"),x3t.forEach(t),abo=r(OP," \u2014 "),ej=n(OP,"A",{href:!0});var $3t=s(ej);nbo=r($3t,"CpmTokenizer"),$3t.forEach(t),sbo=r(OP," or "),oj=n(OP,"A",{href:!0});var k3t=s(oj);lbo=r(k3t,"CpmTokenizerFast"),k3t.forEach(t),ibo=r(OP," (CPM model)"),OP.forEach(t),dbo=i(S),du=n(S,"LI",{});var TBe=s(du);Ufe=n(TBe,"STRONG",{});var S3t=s(Ufe);cbo=r(S3t,"ctrl"),S3t.forEach(t),mbo=r(TBe," \u2014 "),rj=n(TBe,"A",{href:!0});var R3t=s(rj);fbo=r(R3t,"CTRLTokenizer"),R3t.forEach(t),gbo=r(TBe," (CTRL model)"),TBe.forEach(t),hbo=i(S),_s=n(S,"LI",{});var VP=s(_s);Hfe=n(VP,"STRONG",{});var P3t=s(Hfe);ubo=r(P3t,"data2vec-text"),P3t.forEach(t),pbo=r(VP," \u2014 "),tj=n(VP,"A",{href:!0});var B3t=s(tj);_bo=r(B3t,"RobertaTokenizer"),B3t.forEach(t),bbo=r(VP," or "),aj=n(VP,"A",{href:!0});var I3t=s(aj);vbo=r(I3t,"RobertaTokenizerFast"),I3t.forEach(t),Fbo=r(VP," (Data2VecText model)"),VP.forEach(t),Tbo=i(S),bs=n(S,"LI",{});var XP=s(bs);Jfe=n(XP,"STRONG",{});var N3t=s(Jfe);Mbo=r(N3t,"deberta"),N3t.forEach(t),Ebo=r(XP," \u2014 "),nj=n(XP,"A",{href:!0});var q3t=s(nj);Cbo=r(q3t,"DebertaTokenizer"),q3t.forEach(t),wbo=r(XP," or "),sj=n(XP,"A",{href:!0});var j3t=s(sj);Abo=r(j3t,"DebertaTokenizerFast"),j3t.forEach(t),Lbo=r(XP," (DeBERTa model)"),XP.forEach(t),ybo=i(S),vs=n(S,"LI",{});var zP=s(vs);Yfe=n(zP,"STRONG",{});var D3t=s(Yfe);xbo=r(D3t,"deberta-v2"),D3t.forEach(t),$bo=r(zP," \u2014 "),lj=n(zP,"A",{href:!0});var G3t=s(lj);kbo=r(G3t,"DebertaV2Tokenizer"),G3t.forEach(t),Sbo=r(zP," or "),ij=n(zP,"A",{href:!0});var O3t=s(ij);Rbo=r(O3t,"DebertaV2TokenizerFast"),O3t.forEach(t),Pbo=r(zP," (DeBERTa-v2 model)"),zP.forEach(t),Bbo=i(S),Fs=n(S,"LI",{});var QP=s(Fs);Kfe=n(QP,"STRONG",{});var V3t=s(Kfe);Ibo=r(V3t,"distilbert"),V3t.forEach(t),Nbo=r(QP," \u2014 "),dj=n(QP,"A",{href:!0});var X3t=s(dj);qbo=r(X3t,"DistilBertTokenizer"),X3t.forEach(t),jbo=r(QP," or "),cj=n(QP,"A",{href:!0});var z3t=s(cj);Dbo=r(z3t,"DistilBertTokenizerFast"),z3t.forEach(t),Gbo=r(QP," (DistilBERT model)"),QP.forEach(t),Obo=i(S),Ts=n(S,"LI",{});var WP=s(Ts);Zfe=n(WP,"STRONG",{});var Q3t=s(Zfe);Vbo=r(Q3t,"dpr"),Q3t.forEach(t),Xbo=r(WP," \u2014 "),mj=n(WP,"A",{href:!0});var W3t=s(mj);zbo=r(W3t,"DPRQuestionEncoderTokenizer"),W3t.forEach(t),Qbo=r(WP," or "),fj=n(WP,"A",{href:!0});var U3t=s(fj);Wbo=r(U3t,"DPRQuestionEncoderTokenizerFast"),U3t.forEach(t),Ubo=r(WP," (DPR model)"),WP.forEach(t),Hbo=i(S),Ms=n(S,"LI",{});var UP=s(Ms);ege=n(UP,"STRONG",{});var H3t=s(ege);Jbo=r(H3t,"electra"),H3t.forEach(t),Ybo=r(UP," \u2014 "),gj=n(UP,"A",{href:!0});var J3t=s(gj);Kbo=r(J3t,"ElectraTokenizer"),J3t.forEach(t),Zbo=r(UP," or "),hj=n(UP,"A",{href:!0});var Y3t=s(hj);e1o=r(Y3t,"ElectraTokenizerFast"),Y3t.forEach(t),o1o=r(UP," (ELECTRA model)"),UP.forEach(t),r1o=i(S),Es=n(S,"LI",{});var HP=s(Es);oge=n(HP,"STRONG",{});var K3t=s(oge);t1o=r(K3t,"ernie"),K3t.forEach(t),a1o=r(HP," \u2014 "),uj=n(HP,"A",{href:!0});var Z3t=s(uj);n1o=r(Z3t,"BertTokenizer"),Z3t.forEach(t),s1o=r(HP," or "),pj=n(HP,"A",{href:!0});var e5t=s(pj);l1o=r(e5t,"BertTokenizerFast"),e5t.forEach(t),i1o=r(HP," (ERNIE model)"),HP.forEach(t),d1o=i(S),cu=n(S,"LI",{});var MBe=s(cu);rge=n(MBe,"STRONG",{});var o5t=s(rge);c1o=r(o5t,"flaubert"),o5t.forEach(t),m1o=r(MBe," \u2014 "),_j=n(MBe,"A",{href:!0});var r5t=s(_j);f1o=r(r5t,"FlaubertTokenizer"),r5t.forEach(t),g1o=r(MBe," (FlauBERT model)"),MBe.forEach(t),h1o=i(S),Cs=n(S,"LI",{});var JP=s(Cs);tge=n(JP,"STRONG",{});var t5t=s(tge);u1o=r(t5t,"fnet"),t5t.forEach(t),p1o=r(JP," \u2014 "),bj=n(JP,"A",{href:!0});var a5t=s(bj);_1o=r(a5t,"FNetTokenizer"),a5t.forEach(t),b1o=r(JP," or "),vj=n(JP,"A",{href:!0});var n5t=s(vj);v1o=r(n5t,"FNetTokenizerFast"),n5t.forEach(t),F1o=r(JP," (FNet model)"),JP.forEach(t),T1o=i(S),mu=n(S,"LI",{});var EBe=s(mu);age=n(EBe,"STRONG",{});var s5t=s(age);M1o=r(s5t,"fsmt"),s5t.forEach(t),E1o=r(EBe," \u2014 "),Fj=n(EBe,"A",{href:!0});var l5t=s(Fj);C1o=r(l5t,"FSMTTokenizer"),l5t.forEach(t),w1o=r(EBe," (FairSeq Machine-Translation model)"),EBe.forEach(t),A1o=i(S),ws=n(S,"LI",{});var YP=s(ws);nge=n(YP,"STRONG",{});var i5t=s(nge);L1o=r(i5t,"funnel"),i5t.forEach(t),y1o=r(YP," \u2014 "),Tj=n(YP,"A",{href:!0});var d5t=s(Tj);x1o=r(d5t,"FunnelTokenizer"),d5t.forEach(t),$1o=r(YP," or "),Mj=n(YP,"A",{href:!0});var c5t=s(Mj);k1o=r(c5t,"FunnelTokenizerFast"),c5t.forEach(t),S1o=r(YP," (Funnel Transformer model)"),YP.forEach(t),R1o=i(S),As=n(S,"LI",{});var KP=s(As);sge=n(KP,"STRONG",{});var m5t=s(sge);P1o=r(m5t,"gpt2"),m5t.forEach(t),B1o=r(KP," \u2014 "),Ej=n(KP,"A",{href:!0});var f5t=s(Ej);I1o=r(f5t,"GPT2Tokenizer"),f5t.forEach(t),N1o=r(KP," or "),Cj=n(KP,"A",{href:!0});var g5t=s(Cj);q1o=r(g5t,"GPT2TokenizerFast"),g5t.forEach(t),j1o=r(KP," (OpenAI GPT-2 model)"),KP.forEach(t),D1o=i(S),Ls=n(S,"LI",{});var ZP=s(Ls);lge=n(ZP,"STRONG",{});var h5t=s(lge);G1o=r(h5t,"gpt_neo"),h5t.forEach(t),O1o=r(ZP," \u2014 "),wj=n(ZP,"A",{href:!0});var u5t=s(wj);V1o=r(u5t,"GPT2Tokenizer"),u5t.forEach(t),X1o=r(ZP," or "),Aj=n(ZP,"A",{href:!0});var p5t=s(Aj);z1o=r(p5t,"GPT2TokenizerFast"),p5t.forEach(t),Q1o=r(ZP," (GPT Neo model)"),ZP.forEach(t),W1o=i(S),fu=n(S,"LI",{});var CBe=s(fu);ige=n(CBe,"STRONG",{});var _5t=s(ige);U1o=r(_5t,"gpt_neox"),_5t.forEach(t),H1o=r(CBe," \u2014 "),Lj=n(CBe,"A",{href:!0});var b5t=s(Lj);J1o=r(b5t,"GPTNeoXTokenizerFast"),b5t.forEach(t),Y1o=r(CBe," (GPT NeoX model)"),CBe.forEach(t),K1o=i(S),gu=n(S,"LI",{});var wBe=s(gu);dge=n(wBe,"STRONG",{});var v5t=s(dge);Z1o=r(v5t,"gpt_neox_japanese"),v5t.forEach(t),evo=r(wBe," \u2014 "),yj=n(wBe,"A",{href:!0});var F5t=s(yj);ovo=r(F5t,"GPTNeoXJapaneseTokenizer"),F5t.forEach(t),rvo=r(wBe," (GPT NeoX Japanese model)"),wBe.forEach(t),tvo=i(S),ys=n(S,"LI",{});var eB=s(ys);cge=n(eB,"STRONG",{});var T5t=s(cge);avo=r(T5t,"gptj"),T5t.forEach(t),nvo=r(eB," \u2014 "),xj=n(eB,"A",{href:!0});var M5t=s(xj);svo=r(M5t,"GPT2Tokenizer"),M5t.forEach(t),lvo=r(eB," or "),$j=n(eB,"A",{href:!0});var E5t=s($j);ivo=r(E5t,"GPT2TokenizerFast"),E5t.forEach(t),dvo=r(eB," (GPT-J model)"),eB.forEach(t),cvo=i(S),xs=n(S,"LI",{});var oB=s(xs);mge=n(oB,"STRONG",{});var C5t=s(mge);mvo=r(C5t,"groupvit"),C5t.forEach(t),fvo=r(oB," \u2014 "),kj=n(oB,"A",{href:!0});var w5t=s(kj);gvo=r(w5t,"CLIPTokenizer"),w5t.forEach(t),hvo=r(oB," or "),Sj=n(oB,"A",{href:!0});var A5t=s(Sj);uvo=r(A5t,"CLIPTokenizerFast"),A5t.forEach(t),pvo=r(oB," (GroupViT model)"),oB.forEach(t),_vo=i(S),$s=n(S,"LI",{});var rB=s($s);fge=n(rB,"STRONG",{});var L5t=s(fge);bvo=r(L5t,"herbert"),L5t.forEach(t),vvo=r(rB," \u2014 "),Rj=n(rB,"A",{href:!0});var y5t=s(Rj);Fvo=r(y5t,"HerbertTokenizer"),y5t.forEach(t),Tvo=r(rB," or "),Pj=n(rB,"A",{href:!0});var x5t=s(Pj);Mvo=r(x5t,"HerbertTokenizerFast"),x5t.forEach(t),Evo=r(rB," (HerBERT model)"),rB.forEach(t),Cvo=i(S),hu=n(S,"LI",{});var ABe=s(hu);gge=n(ABe,"STRONG",{});var $5t=s(gge);wvo=r($5t,"hubert"),$5t.forEach(t),Avo=r(ABe," \u2014 "),Bj=n(ABe,"A",{href:!0});var k5t=s(Bj);Lvo=r(k5t,"Wav2Vec2CTCTokenizer"),k5t.forEach(t),yvo=r(ABe," (Hubert model)"),ABe.forEach(t),xvo=i(S),ks=n(S,"LI",{});var tB=s(ks);hge=n(tB,"STRONG",{});var S5t=s(hge);$vo=r(S5t,"ibert"),S5t.forEach(t),kvo=r(tB," \u2014 "),Ij=n(tB,"A",{href:!0});var R5t=s(Ij);Svo=r(R5t,"RobertaTokenizer"),R5t.forEach(t),Rvo=r(tB," or "),Nj=n(tB,"A",{href:!0});var P5t=s(Nj);Pvo=r(P5t,"RobertaTokenizerFast"),P5t.forEach(t),Bvo=r(tB," (I-BERT model)"),tB.forEach(t),Ivo=i(S),Ss=n(S,"LI",{});var aB=s(Ss);uge=n(aB,"STRONG",{});var B5t=s(uge);Nvo=r(B5t,"layoutlm"),B5t.forEach(t),qvo=r(aB," \u2014 "),qj=n(aB,"A",{href:!0});var I5t=s(qj);jvo=r(I5t,"LayoutLMTokenizer"),I5t.forEach(t),Dvo=r(aB," or "),jj=n(aB,"A",{href:!0});var N5t=s(jj);Gvo=r(N5t,"LayoutLMTokenizerFast"),N5t.forEach(t),Ovo=r(aB," (LayoutLM model)"),aB.forEach(t),Vvo=i(S),Rs=n(S,"LI",{});var nB=s(Rs);pge=n(nB,"STRONG",{});var q5t=s(pge);Xvo=r(q5t,"layoutlmv2"),q5t.forEach(t),zvo=r(nB," \u2014 "),Dj=n(nB,"A",{href:!0});var j5t=s(Dj);Qvo=r(j5t,"LayoutLMv2Tokenizer"),j5t.forEach(t),Wvo=r(nB," or "),Gj=n(nB,"A",{href:!0});var D5t=s(Gj);Uvo=r(D5t,"LayoutLMv2TokenizerFast"),D5t.forEach(t),Hvo=r(nB," (LayoutLMv2 model)"),nB.forEach(t),Jvo=i(S),Ps=n(S,"LI",{});var sB=s(Ps);_ge=n(sB,"STRONG",{});var G5t=s(_ge);Yvo=r(G5t,"layoutlmv3"),G5t.forEach(t),Kvo=r(sB," \u2014 "),Oj=n(sB,"A",{href:!0});var O5t=s(Oj);Zvo=r(O5t,"LayoutLMv3Tokenizer"),O5t.forEach(t),eFo=r(sB," or "),Vj=n(sB,"A",{href:!0});var V5t=s(Vj);oFo=r(V5t,"LayoutLMv3TokenizerFast"),V5t.forEach(t),rFo=r(sB," (LayoutLMv3 model)"),sB.forEach(t),tFo=i(S),Bs=n(S,"LI",{});var lB=s(Bs);bge=n(lB,"STRONG",{});var X5t=s(bge);aFo=r(X5t,"layoutxlm"),X5t.forEach(t),nFo=r(lB," \u2014 "),Xj=n(lB,"A",{href:!0});var z5t=s(Xj);sFo=r(z5t,"LayoutXLMTokenizer"),z5t.forEach(t),lFo=r(lB," or "),zj=n(lB,"A",{href:!0});var Q5t=s(zj);iFo=r(Q5t,"LayoutXLMTokenizerFast"),Q5t.forEach(t),dFo=r(lB," (LayoutXLM model)"),lB.forEach(t),cFo=i(S),Is=n(S,"LI",{});var iB=s(Is);vge=n(iB,"STRONG",{});var W5t=s(vge);mFo=r(W5t,"led"),W5t.forEach(t),fFo=r(iB," \u2014 "),Qj=n(iB,"A",{href:!0});var U5t=s(Qj);gFo=r(U5t,"LEDTokenizer"),U5t.forEach(t),hFo=r(iB," or "),Wj=n(iB,"A",{href:!0});var H5t=s(Wj);uFo=r(H5t,"LEDTokenizerFast"),H5t.forEach(t),pFo=r(iB," (LED model)"),iB.forEach(t),_Fo=i(S),Ns=n(S,"LI",{});var dB=s(Ns);Fge=n(dB,"STRONG",{});var J5t=s(Fge);bFo=r(J5t,"longformer"),J5t.forEach(t),vFo=r(dB," \u2014 "),Uj=n(dB,"A",{href:!0});var Y5t=s(Uj);FFo=r(Y5t,"LongformerTokenizer"),Y5t.forEach(t),TFo=r(dB," or "),Hj=n(dB,"A",{href:!0});var K5t=s(Hj);MFo=r(K5t,"LongformerTokenizerFast"),K5t.forEach(t),EFo=r(dB," (Longformer model)"),dB.forEach(t),CFo=i(S),qs=n(S,"LI",{});var cB=s(qs);Tge=n(cB,"STRONG",{});var Z5t=s(Tge);wFo=r(Z5t,"longt5"),Z5t.forEach(t),AFo=r(cB," \u2014 "),Jj=n(cB,"A",{href:!0});var e0t=s(Jj);LFo=r(e0t,"T5Tokenizer"),e0t.forEach(t),yFo=r(cB," or "),Yj=n(cB,"A",{href:!0});var o0t=s(Yj);xFo=r(o0t,"T5TokenizerFast"),o0t.forEach(t),$Fo=r(cB," (LongT5 model)"),cB.forEach(t),kFo=i(S),uu=n(S,"LI",{});var LBe=s(uu);Mge=n(LBe,"STRONG",{});var r0t=s(Mge);SFo=r(r0t,"luke"),r0t.forEach(t),RFo=r(LBe," \u2014 "),Kj=n(LBe,"A",{href:!0});var t0t=s(Kj);PFo=r(t0t,"LukeTokenizer"),t0t.forEach(t),BFo=r(LBe," (LUKE model)"),LBe.forEach(t),IFo=i(S),js=n(S,"LI",{});var mB=s(js);Ege=n(mB,"STRONG",{});var a0t=s(Ege);NFo=r(a0t,"lxmert"),a0t.forEach(t),qFo=r(mB," \u2014 "),Zj=n(mB,"A",{href:!0});var n0t=s(Zj);jFo=r(n0t,"LxmertTokenizer"),n0t.forEach(t),DFo=r(mB," or "),eD=n(mB,"A",{href:!0});var s0t=s(eD);GFo=r(s0t,"LxmertTokenizerFast"),s0t.forEach(t),OFo=r(mB," (LXMERT model)"),mB.forEach(t),VFo=i(S),pu=n(S,"LI",{});var yBe=s(pu);Cge=n(yBe,"STRONG",{});var l0t=s(Cge);XFo=r(l0t,"m2m_100"),l0t.forEach(t),zFo=r(yBe," \u2014 "),oD=n(yBe,"A",{href:!0});var i0t=s(oD);QFo=r(i0t,"M2M100Tokenizer"),i0t.forEach(t),WFo=r(yBe," (M2M100 model)"),yBe.forEach(t),UFo=i(S),_u=n(S,"LI",{});var xBe=s(_u);wge=n(xBe,"STRONG",{});var d0t=s(wge);HFo=r(d0t,"marian"),d0t.forEach(t),JFo=r(xBe," \u2014 "),rD=n(xBe,"A",{href:!0});var c0t=s(rD);YFo=r(c0t,"MarianTokenizer"),c0t.forEach(t),KFo=r(xBe," (Marian model)"),xBe.forEach(t),ZFo=i(S),Ds=n(S,"LI",{});var fB=s(Ds);Age=n(fB,"STRONG",{});var m0t=s(Age);eTo=r(m0t,"mbart"),m0t.forEach(t),oTo=r(fB," \u2014 "),tD=n(fB,"A",{href:!0});var f0t=s(tD);rTo=r(f0t,"MBartTokenizer"),f0t.forEach(t),tTo=r(fB," or "),aD=n(fB,"A",{href:!0});var g0t=s(aD);aTo=r(g0t,"MBartTokenizerFast"),g0t.forEach(t),nTo=r(fB," (mBART model)"),fB.forEach(t),sTo=i(S),Gs=n(S,"LI",{});var gB=s(Gs);Lge=n(gB,"STRONG",{});var h0t=s(Lge);lTo=r(h0t,"mbart50"),h0t.forEach(t),iTo=r(gB," \u2014 "),nD=n(gB,"A",{href:!0});var u0t=s(nD);dTo=r(u0t,"MBart50Tokenizer"),u0t.forEach(t),cTo=r(gB," or "),sD=n(gB,"A",{href:!0});var p0t=s(sD);mTo=r(p0t,"MBart50TokenizerFast"),p0t.forEach(t),fTo=r(gB," (mBART-50 model)"),gB.forEach(t),gTo=i(S),Os=n(S,"LI",{});var hB=s(Os);yge=n(hB,"STRONG",{});var _0t=s(yge);hTo=r(_0t,"megatron-bert"),_0t.forEach(t),uTo=r(hB," \u2014 "),lD=n(hB,"A",{href:!0});var b0t=s(lD);pTo=r(b0t,"BertTokenizer"),b0t.forEach(t),_To=r(hB," or "),iD=n(hB,"A",{href:!0});var v0t=s(iD);bTo=r(v0t,"BertTokenizerFast"),v0t.forEach(t),vTo=r(hB," (Megatron-BERT model)"),hB.forEach(t),FTo=i(S),bu=n(S,"LI",{});var $Be=s(bu);xge=n($Be,"STRONG",{});var F0t=s(xge);TTo=r(F0t,"mluke"),F0t.forEach(t),MTo=r($Be," \u2014 "),dD=n($Be,"A",{href:!0});var T0t=s(dD);ETo=r(T0t,"MLukeTokenizer"),T0t.forEach(t),CTo=r($Be," (mLUKE model)"),$Be.forEach(t),wTo=i(S),Vs=n(S,"LI",{});var uB=s(Vs);$ge=n(uB,"STRONG",{});var M0t=s($ge);ATo=r(M0t,"mobilebert"),M0t.forEach(t),LTo=r(uB," \u2014 "),cD=n(uB,"A",{href:!0});var E0t=s(cD);yTo=r(E0t,"MobileBertTokenizer"),E0t.forEach(t),xTo=r(uB," or "),mD=n(uB,"A",{href:!0});var C0t=s(mD);$To=r(C0t,"MobileBertTokenizerFast"),C0t.forEach(t),kTo=r(uB," (MobileBERT model)"),uB.forEach(t),STo=i(S),Xs=n(S,"LI",{});var pB=s(Xs);kge=n(pB,"STRONG",{});var w0t=s(kge);RTo=r(w0t,"mpnet"),w0t.forEach(t),PTo=r(pB," \u2014 "),fD=n(pB,"A",{href:!0});var A0t=s(fD);BTo=r(A0t,"MPNetTokenizer"),A0t.forEach(t),ITo=r(pB," or "),gD=n(pB,"A",{href:!0});var L0t=s(gD);NTo=r(L0t,"MPNetTokenizerFast"),L0t.forEach(t),qTo=r(pB," (MPNet model)"),pB.forEach(t),jTo=i(S),zs=n(S,"LI",{});var _B=s(zs);Sge=n(_B,"STRONG",{});var y0t=s(Sge);DTo=r(y0t,"mt5"),y0t.forEach(t),GTo=r(_B," \u2014 "),hD=n(_B,"A",{href:!0});var x0t=s(hD);OTo=r(x0t,"MT5Tokenizer"),x0t.forEach(t),VTo=r(_B," or "),uD=n(_B,"A",{href:!0});var $0t=s(uD);XTo=r($0t,"MT5TokenizerFast"),$0t.forEach(t),zTo=r(_B," (MT5 model)"),_B.forEach(t),QTo=i(S),Qs=n(S,"LI",{});var bB=s(Qs);Rge=n(bB,"STRONG",{});var k0t=s(Rge);WTo=r(k0t,"mvp"),k0t.forEach(t),UTo=r(bB," \u2014 "),pD=n(bB,"A",{href:!0});var S0t=s(pD);HTo=r(S0t,"MvpTokenizer"),S0t.forEach(t),JTo=r(bB," or "),_D=n(bB,"A",{href:!0});var R0t=s(_D);YTo=r(R0t,"MvpTokenizerFast"),R0t.forEach(t),KTo=r(bB," (MVP model)"),bB.forEach(t),ZTo=i(S),Ws=n(S,"LI",{});var vB=s(Ws);Pge=n(vB,"STRONG",{});var P0t=s(Pge);eMo=r(P0t,"nezha"),P0t.forEach(t),oMo=r(vB," \u2014 "),bD=n(vB,"A",{href:!0});var B0t=s(bD);rMo=r(B0t,"BertTokenizer"),B0t.forEach(t),tMo=r(vB," or "),vD=n(vB,"A",{href:!0});var I0t=s(vD);aMo=r(I0t,"BertTokenizerFast"),I0t.forEach(t),nMo=r(vB," (Nezha model)"),vB.forEach(t),sMo=i(S),Us=n(S,"LI",{});var FB=s(Us);Bge=n(FB,"STRONG",{});var N0t=s(Bge);lMo=r(N0t,"nllb"),N0t.forEach(t),iMo=r(FB," \u2014 "),FD=n(FB,"A",{href:!0});var q0t=s(FD);dMo=r(q0t,"NllbTokenizer"),q0t.forEach(t),cMo=r(FB," or "),TD=n(FB,"A",{href:!0});var j0t=s(TD);mMo=r(j0t,"NllbTokenizerFast"),j0t.forEach(t),fMo=r(FB," (NLLB model)"),FB.forEach(t),gMo=i(S),Hs=n(S,"LI",{});var TB=s(Hs);Ige=n(TB,"STRONG",{});var D0t=s(Ige);hMo=r(D0t,"nystromformer"),D0t.forEach(t),uMo=r(TB," \u2014 "),MD=n(TB,"A",{href:!0});var G0t=s(MD);pMo=r(G0t,"AlbertTokenizer"),G0t.forEach(t),_Mo=r(TB," or "),ED=n(TB,"A",{href:!0});var O0t=s(ED);bMo=r(O0t,"AlbertTokenizerFast"),O0t.forEach(t),vMo=r(TB," (Nystr\xF6mformer model)"),TB.forEach(t),FMo=i(S),Js=n(S,"LI",{});var MB=s(Js);Nge=n(MB,"STRONG",{});var V0t=s(Nge);TMo=r(V0t,"openai-gpt"),V0t.forEach(t),MMo=r(MB," \u2014 "),CD=n(MB,"A",{href:!0});var X0t=s(CD);EMo=r(X0t,"OpenAIGPTTokenizer"),X0t.forEach(t),CMo=r(MB," or "),wD=n(MB,"A",{href:!0});var z0t=s(wD);wMo=r(z0t,"OpenAIGPTTokenizerFast"),z0t.forEach(t),AMo=r(MB," (OpenAI GPT model)"),MB.forEach(t),LMo=i(S),vu=n(S,"LI",{});var kBe=s(vu);qge=n(kBe,"STRONG",{});var Q0t=s(qge);yMo=r(Q0t,"opt"),Q0t.forEach(t),xMo=r(kBe," \u2014 "),AD=n(kBe,"A",{href:!0});var W0t=s(AD);$Mo=r(W0t,"GPT2Tokenizer"),W0t.forEach(t),kMo=r(kBe," (OPT model)"),kBe.forEach(t),SMo=i(S),Ys=n(S,"LI",{});var EB=s(Ys);jge=n(EB,"STRONG",{});var U0t=s(jge);RMo=r(U0t,"owlvit"),U0t.forEach(t),PMo=r(EB," \u2014 "),LD=n(EB,"A",{href:!0});var H0t=s(LD);BMo=r(H0t,"CLIPTokenizer"),H0t.forEach(t),IMo=r(EB," or "),yD=n(EB,"A",{href:!0});var J0t=s(yD);NMo=r(J0t,"CLIPTokenizerFast"),J0t.forEach(t),qMo=r(EB," (OWL-ViT model)"),EB.forEach(t),jMo=i(S),Ks=n(S,"LI",{});var CB=s(Ks);Dge=n(CB,"STRONG",{});var Y0t=s(Dge);DMo=r(Y0t,"pegasus"),Y0t.forEach(t),GMo=r(CB," \u2014 "),xD=n(CB,"A",{href:!0});var K0t=s(xD);OMo=r(K0t,"PegasusTokenizer"),K0t.forEach(t),VMo=r(CB," or "),$D=n(CB,"A",{href:!0});var Z0t=s($D);XMo=r(Z0t,"PegasusTokenizerFast"),Z0t.forEach(t),zMo=r(CB," (Pegasus model)"),CB.forEach(t),QMo=i(S),Fu=n(S,"LI",{});var SBe=s(Fu);Gge=n(SBe,"STRONG",{});var ewt=s(Gge);WMo=r(ewt,"perceiver"),ewt.forEach(t),UMo=r(SBe," \u2014 "),kD=n(SBe,"A",{href:!0});var owt=s(kD);HMo=r(owt,"PerceiverTokenizer"),owt.forEach(t),JMo=r(SBe," (Perceiver model)"),SBe.forEach(t),YMo=i(S),Tu=n(S,"LI",{});var RBe=s(Tu);Oge=n(RBe,"STRONG",{});var rwt=s(Oge);KMo=r(rwt,"phobert"),rwt.forEach(t),ZMo=r(RBe," \u2014 "),SD=n(RBe,"A",{href:!0});var twt=s(SD);eEo=r(twt,"PhobertTokenizer"),twt.forEach(t),oEo=r(RBe," (PhoBERT model)"),RBe.forEach(t),rEo=i(S),Mu=n(S,"LI",{});var PBe=s(Mu);Vge=n(PBe,"STRONG",{});var awt=s(Vge);tEo=r(awt,"plbart"),awt.forEach(t),aEo=r(PBe," \u2014 "),RD=n(PBe,"A",{href:!0});var nwt=s(RD);nEo=r(nwt,"PLBartTokenizer"),nwt.forEach(t),sEo=r(PBe," (PLBart model)"),PBe.forEach(t),lEo=i(S),Eu=n(S,"LI",{});var BBe=s(Eu);Xge=n(BBe,"STRONG",{});var swt=s(Xge);iEo=r(swt,"prophetnet"),swt.forEach(t),dEo=r(BBe," \u2014 "),PD=n(BBe,"A",{href:!0});var lwt=s(PD);cEo=r(lwt,"ProphetNetTokenizer"),lwt.forEach(t),mEo=r(BBe," (ProphetNet model)"),BBe.forEach(t),fEo=i(S),Zs=n(S,"LI",{});var wB=s(Zs);zge=n(wB,"STRONG",{});var iwt=s(zge);gEo=r(iwt,"qdqbert"),iwt.forEach(t),hEo=r(wB," \u2014 "),BD=n(wB,"A",{href:!0});var dwt=s(BD);uEo=r(dwt,"BertTokenizer"),dwt.forEach(t),pEo=r(wB," or "),ID=n(wB,"A",{href:!0});var cwt=s(ID);_Eo=r(cwt,"BertTokenizerFast"),cwt.forEach(t),bEo=r(wB," (QDQBert model)"),wB.forEach(t),vEo=i(S),Cu=n(S,"LI",{});var IBe=s(Cu);Qge=n(IBe,"STRONG",{});var mwt=s(Qge);FEo=r(mwt,"rag"),mwt.forEach(t),TEo=r(IBe," \u2014 "),ND=n(IBe,"A",{href:!0});var fwt=s(ND);MEo=r(fwt,"RagTokenizer"),fwt.forEach(t),EEo=r(IBe," (RAG model)"),IBe.forEach(t),CEo=i(S),el=n(S,"LI",{});var AB=s(el);Wge=n(AB,"STRONG",{});var gwt=s(Wge);wEo=r(gwt,"realm"),gwt.forEach(t),AEo=r(AB," \u2014 "),qD=n(AB,"A",{href:!0});var hwt=s(qD);LEo=r(hwt,"RealmTokenizer"),hwt.forEach(t),yEo=r(AB," or "),jD=n(AB,"A",{href:!0});var uwt=s(jD);xEo=r(uwt,"RealmTokenizerFast"),uwt.forEach(t),$Eo=r(AB," (REALM model)"),AB.forEach(t),kEo=i(S),ol=n(S,"LI",{});var LB=s(ol);Uge=n(LB,"STRONG",{});var pwt=s(Uge);SEo=r(pwt,"reformer"),pwt.forEach(t),REo=r(LB," \u2014 "),DD=n(LB,"A",{href:!0});var _wt=s(DD);PEo=r(_wt,"ReformerTokenizer"),_wt.forEach(t),BEo=r(LB," or "),GD=n(LB,"A",{href:!0});var bwt=s(GD);IEo=r(bwt,"ReformerTokenizerFast"),bwt.forEach(t),NEo=r(LB," (Reformer model)"),LB.forEach(t),qEo=i(S),rl=n(S,"LI",{});var yB=s(rl);Hge=n(yB,"STRONG",{});var vwt=s(Hge);jEo=r(vwt,"rembert"),vwt.forEach(t),DEo=r(yB," \u2014 "),OD=n(yB,"A",{href:!0});var Fwt=s(OD);GEo=r(Fwt,"RemBertTokenizer"),Fwt.forEach(t),OEo=r(yB," or "),VD=n(yB,"A",{href:!0});var Twt=s(VD);VEo=r(Twt,"RemBertTokenizerFast"),Twt.forEach(t),XEo=r(yB," (RemBERT model)"),yB.forEach(t),zEo=i(S),tl=n(S,"LI",{});var xB=s(tl);Jge=n(xB,"STRONG",{});var Mwt=s(Jge);QEo=r(Mwt,"retribert"),Mwt.forEach(t),WEo=r(xB," \u2014 "),XD=n(xB,"A",{href:!0});var Ewt=s(XD);UEo=r(Ewt,"RetriBertTokenizer"),Ewt.forEach(t),HEo=r(xB," or "),zD=n(xB,"A",{href:!0});var Cwt=s(zD);JEo=r(Cwt,"RetriBertTokenizerFast"),Cwt.forEach(t),YEo=r(xB," (RetriBERT model)"),xB.forEach(t),KEo=i(S),al=n(S,"LI",{});var $B=s(al);Yge=n($B,"STRONG",{});var wwt=s(Yge);ZEo=r(wwt,"roberta"),wwt.forEach(t),e4o=r($B," \u2014 "),QD=n($B,"A",{href:!0});var Awt=s(QD);o4o=r(Awt,"RobertaTokenizer"),Awt.forEach(t),r4o=r($B," or "),WD=n($B,"A",{href:!0});var Lwt=s(WD);t4o=r(Lwt,"RobertaTokenizerFast"),Lwt.forEach(t),a4o=r($B," (RoBERTa model)"),$B.forEach(t),n4o=i(S),nl=n(S,"LI",{});var kB=s(nl);Kge=n(kB,"STRONG",{});var ywt=s(Kge);s4o=r(ywt,"roformer"),ywt.forEach(t),l4o=r(kB," \u2014 "),UD=n(kB,"A",{href:!0});var xwt=s(UD);i4o=r(xwt,"RoFormerTokenizer"),xwt.forEach(t),d4o=r(kB," or "),HD=n(kB,"A",{href:!0});var $wt=s(HD);c4o=r($wt,"RoFormerTokenizerFast"),$wt.forEach(t),m4o=r(kB," (RoFormer model)"),kB.forEach(t),f4o=i(S),wu=n(S,"LI",{});var NBe=s(wu);Zge=n(NBe,"STRONG",{});var kwt=s(Zge);g4o=r(kwt,"speech_to_text"),kwt.forEach(t),h4o=r(NBe," \u2014 "),JD=n(NBe,"A",{href:!0});var Swt=s(JD);u4o=r(Swt,"Speech2TextTokenizer"),Swt.forEach(t),p4o=r(NBe," (Speech2Text model)"),NBe.forEach(t),_4o=i(S),Au=n(S,"LI",{});var qBe=s(Au);ehe=n(qBe,"STRONG",{});var Rwt=s(ehe);b4o=r(Rwt,"speech_to_text_2"),Rwt.forEach(t),v4o=r(qBe," \u2014 "),YD=n(qBe,"A",{href:!0});var Pwt=s(YD);F4o=r(Pwt,"Speech2Text2Tokenizer"),Pwt.forEach(t),T4o=r(qBe," (Speech2Text2 model)"),qBe.forEach(t),M4o=i(S),sl=n(S,"LI",{});var SB=s(sl);ohe=n(SB,"STRONG",{});var Bwt=s(ohe);E4o=r(Bwt,"splinter"),Bwt.forEach(t),C4o=r(SB," \u2014 "),KD=n(SB,"A",{href:!0});var Iwt=s(KD);w4o=r(Iwt,"SplinterTokenizer"),Iwt.forEach(t),A4o=r(SB," or "),ZD=n(SB,"A",{href:!0});var Nwt=s(ZD);L4o=r(Nwt,"SplinterTokenizerFast"),Nwt.forEach(t),y4o=r(SB," (Splinter model)"),SB.forEach(t),x4o=i(S),ll=n(S,"LI",{});var RB=s(ll);rhe=n(RB,"STRONG",{});var qwt=s(rhe);$4o=r(qwt,"squeezebert"),qwt.forEach(t),k4o=r(RB," \u2014 "),eG=n(RB,"A",{href:!0});var jwt=s(eG);S4o=r(jwt,"SqueezeBertTokenizer"),jwt.forEach(t),R4o=r(RB," or "),oG=n(RB,"A",{href:!0});var Dwt=s(oG);P4o=r(Dwt,"SqueezeBertTokenizerFast"),Dwt.forEach(t),B4o=r(RB," (SqueezeBERT model)"),RB.forEach(t),I4o=i(S),il=n(S,"LI",{});var PB=s(il);the=n(PB,"STRONG",{});var Gwt=s(the);N4o=r(Gwt,"t5"),Gwt.forEach(t),q4o=r(PB," \u2014 "),rG=n(PB,"A",{href:!0});var Owt=s(rG);j4o=r(Owt,"T5Tokenizer"),Owt.forEach(t),D4o=r(PB," or "),tG=n(PB,"A",{href:!0});var Vwt=s(tG);G4o=r(Vwt,"T5TokenizerFast"),Vwt.forEach(t),O4o=r(PB," (T5 model)"),PB.forEach(t),V4o=i(S),Lu=n(S,"LI",{});var jBe=s(Lu);ahe=n(jBe,"STRONG",{});var Xwt=s(ahe);X4o=r(Xwt,"tapas"),Xwt.forEach(t),z4o=r(jBe," \u2014 "),aG=n(jBe,"A",{href:!0});var zwt=s(aG);Q4o=r(zwt,"TapasTokenizer"),zwt.forEach(t),W4o=r(jBe," (TAPAS model)"),jBe.forEach(t),U4o=i(S),yu=n(S,"LI",{});var DBe=s(yu);nhe=n(DBe,"STRONG",{});var Qwt=s(nhe);H4o=r(Qwt,"tapex"),Qwt.forEach(t),J4o=r(DBe," \u2014 "),nG=n(DBe,"A",{href:!0});var Wwt=s(nG);Y4o=r(Wwt,"TapexTokenizer"),Wwt.forEach(t),K4o=r(DBe," (TAPEX model)"),DBe.forEach(t),Z4o=i(S),xu=n(S,"LI",{});var GBe=s(xu);she=n(GBe,"STRONG",{});var Uwt=s(she);eCo=r(Uwt,"transfo-xl"),Uwt.forEach(t),oCo=r(GBe," \u2014 "),sG=n(GBe,"A",{href:!0});var Hwt=s(sG);rCo=r(Hwt,"TransfoXLTokenizer"),Hwt.forEach(t),tCo=r(GBe," (Transformer-XL model)"),GBe.forEach(t),aCo=i(S),dl=n(S,"LI",{});var BB=s(dl);lhe=n(BB,"STRONG",{});var Jwt=s(lhe);nCo=r(Jwt,"vilt"),Jwt.forEach(t),sCo=r(BB," \u2014 "),lG=n(BB,"A",{href:!0});var Ywt=s(lG);lCo=r(Ywt,"BertTokenizer"),Ywt.forEach(t),iCo=r(BB," or "),iG=n(BB,"A",{href:!0});var Kwt=s(iG);dCo=r(Kwt,"BertTokenizerFast"),Kwt.forEach(t),cCo=r(BB," (ViLT model)"),BB.forEach(t),mCo=i(S),cl=n(S,"LI",{});var IB=s(cl);ihe=n(IB,"STRONG",{});var Zwt=s(ihe);fCo=r(Zwt,"visual_bert"),Zwt.forEach(t),gCo=r(IB," \u2014 "),dG=n(IB,"A",{href:!0});var eAt=s(dG);hCo=r(eAt,"BertTokenizer"),eAt.forEach(t),uCo=r(IB," or "),cG=n(IB,"A",{href:!0});var oAt=s(cG);pCo=r(oAt,"BertTokenizerFast"),oAt.forEach(t),_Co=r(IB," (VisualBERT model)"),IB.forEach(t),bCo=i(S),$u=n(S,"LI",{});var OBe=s($u);dhe=n(OBe,"STRONG",{});var rAt=s(dhe);vCo=r(rAt,"wav2vec2"),rAt.forEach(t),FCo=r(OBe," \u2014 "),mG=n(OBe,"A",{href:!0});var tAt=s(mG);TCo=r(tAt,"Wav2Vec2CTCTokenizer"),tAt.forEach(t),MCo=r(OBe," (Wav2Vec2 model)"),OBe.forEach(t),ECo=i(S),ku=n(S,"LI",{});var VBe=s(ku);che=n(VBe,"STRONG",{});var aAt=s(che);CCo=r(aAt,"wav2vec2-conformer"),aAt.forEach(t),wCo=r(VBe," \u2014 "),fG=n(VBe,"A",{href:!0});var nAt=s(fG);ACo=r(nAt,"Wav2Vec2CTCTokenizer"),nAt.forEach(t),LCo=r(VBe," (Wav2Vec2-Conformer model)"),VBe.forEach(t),yCo=i(S),Su=n(S,"LI",{});var XBe=s(Su);mhe=n(XBe,"STRONG",{});var sAt=s(mhe);xCo=r(sAt,"wav2vec2_phoneme"),sAt.forEach(t),$Co=r(XBe," \u2014 "),gG=n(XBe,"A",{href:!0});var lAt=s(gG);kCo=r(lAt,"Wav2Vec2PhonemeCTCTokenizer"),lAt.forEach(t),SCo=r(XBe," (Wav2Vec2Phoneme model)"),XBe.forEach(t),RCo=i(S),ml=n(S,"LI",{});var NB=s(ml);fhe=n(NB,"STRONG",{});var iAt=s(fhe);PCo=r(iAt,"xclip"),iAt.forEach(t),BCo=r(NB," \u2014 "),hG=n(NB,"A",{href:!0});var dAt=s(hG);ICo=r(dAt,"CLIPTokenizer"),dAt.forEach(t),NCo=r(NB," or "),uG=n(NB,"A",{href:!0});var cAt=s(uG);qCo=r(cAt,"CLIPTokenizerFast"),cAt.forEach(t),jCo=r(NB," (X-CLIP model)"),NB.forEach(t),DCo=i(S),fl=n(S,"LI",{});var qB=s(fl);ghe=n(qB,"STRONG",{});var mAt=s(ghe);GCo=r(mAt,"xglm"),mAt.forEach(t),OCo=r(qB," \u2014 "),pG=n(qB,"A",{href:!0});var fAt=s(pG);VCo=r(fAt,"XGLMTokenizer"),fAt.forEach(t),XCo=r(qB," or "),_G=n(qB,"A",{href:!0});var gAt=s(_G);zCo=r(gAt,"XGLMTokenizerFast"),gAt.forEach(t),QCo=r(qB," (XGLM model)"),qB.forEach(t),WCo=i(S),Ru=n(S,"LI",{});var zBe=s(Ru);hhe=n(zBe,"STRONG",{});var hAt=s(hhe);UCo=r(hAt,"xlm"),hAt.forEach(t),HCo=r(zBe," \u2014 "),bG=n(zBe,"A",{href:!0});var uAt=s(bG);JCo=r(uAt,"XLMTokenizer"),uAt.forEach(t),YCo=r(zBe," (XLM model)"),zBe.forEach(t),KCo=i(S),Pu=n(S,"LI",{});var QBe=s(Pu);uhe=n(QBe,"STRONG",{});var pAt=s(uhe);ZCo=r(pAt,"xlm-prophetnet"),pAt.forEach(t),e3o=r(QBe," \u2014 "),vG=n(QBe,"A",{href:!0});var _At=s(vG);o3o=r(_At,"XLMProphetNetTokenizer"),_At.forEach(t),r3o=r(QBe," (XLM-ProphetNet model)"),QBe.forEach(t),t3o=i(S),gl=n(S,"LI",{});var jB=s(gl);phe=n(jB,"STRONG",{});var bAt=s(phe);a3o=r(bAt,"xlm-roberta"),bAt.forEach(t),n3o=r(jB," \u2014 "),FG=n(jB,"A",{href:!0});var vAt=s(FG);s3o=r(vAt,"XLMRobertaTokenizer"),vAt.forEach(t),l3o=r(jB," or "),TG=n(jB,"A",{href:!0});var FAt=s(TG);i3o=r(FAt,"XLMRobertaTokenizerFast"),FAt.forEach(t),d3o=r(jB," (XLM-RoBERTa model)"),jB.forEach(t),c3o=i(S),hl=n(S,"LI",{});var DB=s(hl);_he=n(DB,"STRONG",{});var TAt=s(_he);m3o=r(TAt,"xlm-roberta-xl"),TAt.forEach(t),f3o=r(DB," \u2014 "),MG=n(DB,"A",{href:!0});var MAt=s(MG);g3o=r(MAt,"XLMRobertaTokenizer"),MAt.forEach(t),h3o=r(DB," or "),EG=n(DB,"A",{href:!0});var EAt=s(EG);u3o=r(EAt,"XLMRobertaTokenizerFast"),EAt.forEach(t),p3o=r(DB," (XLM-RoBERTa-XL model)"),DB.forEach(t),_3o=i(S),ul=n(S,"LI",{});var GB=s(ul);bhe=n(GB,"STRONG",{});var CAt=s(bhe);b3o=r(CAt,"xlnet"),CAt.forEach(t),v3o=r(GB," \u2014 "),CG=n(GB,"A",{href:!0});var wAt=s(CG);F3o=r(wAt,"XLNetTokenizer"),wAt.forEach(t),T3o=r(GB," or "),wG=n(GB,"A",{href:!0});var AAt=s(wG);M3o=r(AAt,"XLNetTokenizerFast"),AAt.forEach(t),E3o=r(GB," (XLNet model)"),GB.forEach(t),C3o=i(S),pl=n(S,"LI",{});var OB=s(pl);vhe=n(OB,"STRONG",{});var LAt=s(vhe);w3o=r(LAt,"yoso"),LAt.forEach(t),A3o=r(OB," \u2014 "),AG=n(OB,"A",{href:!0});var yAt=s(AG);L3o=r(yAt,"AlbertTokenizer"),yAt.forEach(t),y3o=r(OB," or "),LG=n(OB,"A",{href:!0});var xAt=s(LG);x3o=r(xAt,"AlbertTokenizerFast"),xAt.forEach(t),$3o=r(OB," (YOSO model)"),OB.forEach(t),S.forEach(t),k3o=i(El),T(Bu.$$.fragment,El),El.forEach(t),S3o=i(Ml),Iu=n(Ml,"DIV",{class:!0});var Poo=s(Iu);T(lx.$$.fragment,Poo),R3o=i(Poo),Fhe=n(Poo,"P",{});var $At=s(Fhe);P3o=r($At,"Register a new tokenizer in this mapping."),$At.forEach(t),Poo.forEach(t),Ml.forEach(t),wZe=i(m),hd=n(m,"H2",{class:!0});var Boo=s(hd);Nu=n(Boo,"A",{id:!0,class:!0,href:!0});var kAt=s(Nu);The=n(kAt,"SPAN",{});var SAt=s(The);T(ix.$$.fragment,SAt),SAt.forEach(t),kAt.forEach(t),B3o=i(Boo),Mhe=n(Boo,"SPAN",{});var RAt=s(Mhe);I3o=r(RAt,"AutoFeatureExtractor"),RAt.forEach(t),Boo.forEach(t),AZe=i(m),So=n(m,"DIV",{class:!0});var Cl=s(So);T(dx.$$.fragment,Cl),N3o=i(Cl),cx=n(Cl,"P",{});var Ioo=s(cx);q3o=r(Ioo,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),yG=n(Ioo,"A",{href:!0});var PAt=s(yG);j3o=r(PAt,"AutoFeatureExtractor.from_pretrained()"),PAt.forEach(t),D3o=r(Ioo," class method."),Ioo.forEach(t),G3o=i(Cl),mx=n(Cl,"P",{});var Noo=s(mx);O3o=r(Noo,"This class cannot be instantiated directly using "),Ehe=n(Noo,"CODE",{});var BAt=s(Ehe);V3o=r(BAt,"__init__()"),BAt.forEach(t),X3o=r(Noo," (throws an error)."),Noo.forEach(t),z3o=i(Cl),Ye=n(Cl,"DIV",{class:!0});var ba=s(Ye);T(fx.$$.fragment,ba),Q3o=i(ba),Che=n(ba,"P",{});var IAt=s(Che);W3o=r(IAt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),IAt.forEach(t),U3o=i(ba),Ha=n(ba,"P",{});var Gy=s(Ha);H3o=r(Gy,"The feature extractor class to instantiate is selected based on the "),whe=n(Gy,"CODE",{});var NAt=s(whe);J3o=r(NAt,"model_type"),NAt.forEach(t),Y3o=r(Gy,` property of the config object
(either passed as an argument or loaded from `),Ahe=n(Gy,"CODE",{});var qAt=s(Ahe);K3o=r(qAt,"pretrained_model_name_or_path"),qAt.forEach(t),Z3o=r(Gy,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lhe=n(Gy,"CODE",{});var jAt=s(Lhe);e5o=r(jAt,"pretrained_model_name_or_path"),jAt.forEach(t),o5o=r(Gy,":"),Gy.forEach(t),r5o=i(ba),z=n(ba,"UL",{});var W=s(z);qu=n(W,"LI",{});var WBe=s(qu);yhe=n(WBe,"STRONG",{});var DAt=s(yhe);t5o=r(DAt,"beit"),DAt.forEach(t),a5o=r(WBe," \u2014 "),xG=n(WBe,"A",{href:!0});var GAt=s(xG);n5o=r(GAt,"BeitFeatureExtractor"),GAt.forEach(t),s5o=r(WBe," (BEiT model)"),WBe.forEach(t),l5o=i(W),ju=n(W,"LI",{});var UBe=s(ju);xhe=n(UBe,"STRONG",{});var OAt=s(xhe);i5o=r(OAt,"clip"),OAt.forEach(t),d5o=r(UBe," \u2014 "),$G=n(UBe,"A",{href:!0});var VAt=s($G);c5o=r(VAt,"CLIPFeatureExtractor"),VAt.forEach(t),m5o=r(UBe," (CLIP model)"),UBe.forEach(t),f5o=i(W),Du=n(W,"LI",{});var HBe=s(Du);$he=n(HBe,"STRONG",{});var XAt=s($he);g5o=r(XAt,"conditional_detr"),XAt.forEach(t),h5o=r(HBe," \u2014 "),kG=n(HBe,"A",{href:!0});var zAt=s(kG);u5o=r(zAt,"ConditionalDetrFeatureExtractor"),zAt.forEach(t),p5o=r(HBe," (Conditional DETR model)"),HBe.forEach(t),_5o=i(W),Gu=n(W,"LI",{});var JBe=s(Gu);khe=n(JBe,"STRONG",{});var QAt=s(khe);b5o=r(QAt,"convnext"),QAt.forEach(t),v5o=r(JBe," \u2014 "),SG=n(JBe,"A",{href:!0});var WAt=s(SG);F5o=r(WAt,"ConvNextFeatureExtractor"),WAt.forEach(t),T5o=r(JBe," (ConvNeXT model)"),JBe.forEach(t),M5o=i(W),Ou=n(W,"LI",{});var YBe=s(Ou);She=n(YBe,"STRONG",{});var UAt=s(She);E5o=r(UAt,"cvt"),UAt.forEach(t),C5o=r(YBe," \u2014 "),RG=n(YBe,"A",{href:!0});var HAt=s(RG);w5o=r(HAt,"ConvNextFeatureExtractor"),HAt.forEach(t),A5o=r(YBe," (CvT model)"),YBe.forEach(t),L5o=i(W),Vu=n(W,"LI",{});var KBe=s(Vu);Rhe=n(KBe,"STRONG",{});var JAt=s(Rhe);y5o=r(JAt,"data2vec-audio"),JAt.forEach(t),x5o=r(KBe," \u2014 "),PG=n(KBe,"A",{href:!0});var YAt=s(PG);$5o=r(YAt,"Wav2Vec2FeatureExtractor"),YAt.forEach(t),k5o=r(KBe," (Data2VecAudio model)"),KBe.forEach(t),S5o=i(W),Xu=n(W,"LI",{});var ZBe=s(Xu);Phe=n(ZBe,"STRONG",{});var KAt=s(Phe);R5o=r(KAt,"data2vec-vision"),KAt.forEach(t),P5o=r(ZBe," \u2014 "),BG=n(ZBe,"A",{href:!0});var ZAt=s(BG);B5o=r(ZAt,"BeitFeatureExtractor"),ZAt.forEach(t),I5o=r(ZBe," (Data2VecVision model)"),ZBe.forEach(t),N5o=i(W),zu=n(W,"LI",{});var eIe=s(zu);Bhe=n(eIe,"STRONG",{});var e6t=s(Bhe);q5o=r(e6t,"deformable_detr"),e6t.forEach(t),j5o=r(eIe," \u2014 "),IG=n(eIe,"A",{href:!0});var o6t=s(IG);D5o=r(o6t,"DeformableDetrFeatureExtractor"),o6t.forEach(t),G5o=r(eIe," (Deformable DETR model)"),eIe.forEach(t),O5o=i(W),Qu=n(W,"LI",{});var oIe=s(Qu);Ihe=n(oIe,"STRONG",{});var r6t=s(Ihe);V5o=r(r6t,"deit"),r6t.forEach(t),X5o=r(oIe," \u2014 "),NG=n(oIe,"A",{href:!0});var t6t=s(NG);z5o=r(t6t,"DeiTFeatureExtractor"),t6t.forEach(t),Q5o=r(oIe," (DeiT model)"),oIe.forEach(t),W5o=i(W),Wu=n(W,"LI",{});var rIe=s(Wu);Nhe=n(rIe,"STRONG",{});var a6t=s(Nhe);U5o=r(a6t,"detr"),a6t.forEach(t),H5o=r(rIe," \u2014 "),qG=n(rIe,"A",{href:!0});var n6t=s(qG);J5o=r(n6t,"DetrFeatureExtractor"),n6t.forEach(t),Y5o=r(rIe," (DETR model)"),rIe.forEach(t),K5o=i(W),Uu=n(W,"LI",{});var tIe=s(Uu);qhe=n(tIe,"STRONG",{});var s6t=s(qhe);Z5o=r(s6t,"donut"),s6t.forEach(t),e0o=r(tIe," \u2014 "),jG=n(tIe,"A",{href:!0});var l6t=s(jG);o0o=r(l6t,"DonutFeatureExtractor"),l6t.forEach(t),r0o=r(tIe," (Donut model)"),tIe.forEach(t),t0o=i(W),Hu=n(W,"LI",{});var aIe=s(Hu);jhe=n(aIe,"STRONG",{});var i6t=s(jhe);a0o=r(i6t,"dpt"),i6t.forEach(t),n0o=r(aIe," \u2014 "),DG=n(aIe,"A",{href:!0});var d6t=s(DG);s0o=r(d6t,"DPTFeatureExtractor"),d6t.forEach(t),l0o=r(aIe," (DPT model)"),aIe.forEach(t),i0o=i(W),Ju=n(W,"LI",{});var nIe=s(Ju);Dhe=n(nIe,"STRONG",{});var c6t=s(Dhe);d0o=r(c6t,"flava"),c6t.forEach(t),c0o=r(nIe," \u2014 "),GG=n(nIe,"A",{href:!0});var m6t=s(GG);m0o=r(m6t,"FlavaFeatureExtractor"),m6t.forEach(t),f0o=r(nIe," (FLAVA model)"),nIe.forEach(t),g0o=i(W),Yu=n(W,"LI",{});var sIe=s(Yu);Ghe=n(sIe,"STRONG",{});var f6t=s(Ghe);h0o=r(f6t,"glpn"),f6t.forEach(t),u0o=r(sIe," \u2014 "),OG=n(sIe,"A",{href:!0});var g6t=s(OG);p0o=r(g6t,"GLPNFeatureExtractor"),g6t.forEach(t),_0o=r(sIe," (GLPN model)"),sIe.forEach(t),b0o=i(W),Ku=n(W,"LI",{});var lIe=s(Ku);Ohe=n(lIe,"STRONG",{});var h6t=s(Ohe);v0o=r(h6t,"groupvit"),h6t.forEach(t),F0o=r(lIe," \u2014 "),VG=n(lIe,"A",{href:!0});var u6t=s(VG);T0o=r(u6t,"CLIPFeatureExtractor"),u6t.forEach(t),M0o=r(lIe," (GroupViT model)"),lIe.forEach(t),E0o=i(W),Zu=n(W,"LI",{});var iIe=s(Zu);Vhe=n(iIe,"STRONG",{});var p6t=s(Vhe);C0o=r(p6t,"hubert"),p6t.forEach(t),w0o=r(iIe," \u2014 "),XG=n(iIe,"A",{href:!0});var _6t=s(XG);A0o=r(_6t,"Wav2Vec2FeatureExtractor"),_6t.forEach(t),L0o=r(iIe," (Hubert model)"),iIe.forEach(t),y0o=i(W),ep=n(W,"LI",{});var dIe=s(ep);Xhe=n(dIe,"STRONG",{});var b6t=s(Xhe);x0o=r(b6t,"imagegpt"),b6t.forEach(t),$0o=r(dIe," \u2014 "),zG=n(dIe,"A",{href:!0});var v6t=s(zG);k0o=r(v6t,"ImageGPTFeatureExtractor"),v6t.forEach(t),S0o=r(dIe," (ImageGPT model)"),dIe.forEach(t),R0o=i(W),op=n(W,"LI",{});var cIe=s(op);zhe=n(cIe,"STRONG",{});var F6t=s(zhe);P0o=r(F6t,"layoutlmv2"),F6t.forEach(t),B0o=r(cIe," \u2014 "),QG=n(cIe,"A",{href:!0});var T6t=s(QG);I0o=r(T6t,"LayoutLMv2FeatureExtractor"),T6t.forEach(t),N0o=r(cIe," (LayoutLMv2 model)"),cIe.forEach(t),q0o=i(W),rp=n(W,"LI",{});var mIe=s(rp);Qhe=n(mIe,"STRONG",{});var M6t=s(Qhe);j0o=r(M6t,"layoutlmv3"),M6t.forEach(t),D0o=r(mIe," \u2014 "),WG=n(mIe,"A",{href:!0});var E6t=s(WG);G0o=r(E6t,"LayoutLMv3FeatureExtractor"),E6t.forEach(t),O0o=r(mIe," (LayoutLMv3 model)"),mIe.forEach(t),V0o=i(W),tp=n(W,"LI",{});var fIe=s(tp);Whe=n(fIe,"STRONG",{});var C6t=s(Whe);X0o=r(C6t,"levit"),C6t.forEach(t),z0o=r(fIe," \u2014 "),UG=n(fIe,"A",{href:!0});var w6t=s(UG);Q0o=r(w6t,"LevitFeatureExtractor"),w6t.forEach(t),W0o=r(fIe," (LeViT model)"),fIe.forEach(t),U0o=i(W),ap=n(W,"LI",{});var gIe=s(ap);Uhe=n(gIe,"STRONG",{});var A6t=s(Uhe);H0o=r(A6t,"maskformer"),A6t.forEach(t),J0o=r(gIe," \u2014 "),HG=n(gIe,"A",{href:!0});var L6t=s(HG);Y0o=r(L6t,"MaskFormerFeatureExtractor"),L6t.forEach(t),K0o=r(gIe," (MaskFormer model)"),gIe.forEach(t),Z0o=i(W),np=n(W,"LI",{});var hIe=s(np);Hhe=n(hIe,"STRONG",{});var y6t=s(Hhe);ewo=r(y6t,"mctct"),y6t.forEach(t),owo=r(hIe," \u2014 "),JG=n(hIe,"A",{href:!0});var x6t=s(JG);rwo=r(x6t,"MCTCTFeatureExtractor"),x6t.forEach(t),two=r(hIe," (M-CTC-T model)"),hIe.forEach(t),awo=i(W),sp=n(W,"LI",{});var uIe=s(sp);Jhe=n(uIe,"STRONG",{});var $6t=s(Jhe);nwo=r($6t,"mobilevit"),$6t.forEach(t),swo=r(uIe," \u2014 "),YG=n(uIe,"A",{href:!0});var k6t=s(YG);lwo=r(k6t,"MobileViTFeatureExtractor"),k6t.forEach(t),iwo=r(uIe," (MobileViT model)"),uIe.forEach(t),dwo=i(W),lp=n(W,"LI",{});var pIe=s(lp);Yhe=n(pIe,"STRONG",{});var S6t=s(Yhe);cwo=r(S6t,"owlvit"),S6t.forEach(t),mwo=r(pIe," \u2014 "),KG=n(pIe,"A",{href:!0});var R6t=s(KG);fwo=r(R6t,"OwlViTFeatureExtractor"),R6t.forEach(t),gwo=r(pIe," (OWL-ViT model)"),pIe.forEach(t),hwo=i(W),ip=n(W,"LI",{});var _Ie=s(ip);Khe=n(_Ie,"STRONG",{});var P6t=s(Khe);uwo=r(P6t,"perceiver"),P6t.forEach(t),pwo=r(_Ie," \u2014 "),ZG=n(_Ie,"A",{href:!0});var B6t=s(ZG);_wo=r(B6t,"PerceiverFeatureExtractor"),B6t.forEach(t),bwo=r(_Ie," (Perceiver model)"),_Ie.forEach(t),vwo=i(W),dp=n(W,"LI",{});var bIe=s(dp);Zhe=n(bIe,"STRONG",{});var I6t=s(Zhe);Fwo=r(I6t,"poolformer"),I6t.forEach(t),Two=r(bIe," \u2014 "),eO=n(bIe,"A",{href:!0});var N6t=s(eO);Mwo=r(N6t,"PoolFormerFeatureExtractor"),N6t.forEach(t),Ewo=r(bIe," (PoolFormer model)"),bIe.forEach(t),Cwo=i(W),cp=n(W,"LI",{});var vIe=s(cp);eue=n(vIe,"STRONG",{});var q6t=s(eue);wwo=r(q6t,"regnet"),q6t.forEach(t),Awo=r(vIe," \u2014 "),oO=n(vIe,"A",{href:!0});var j6t=s(oO);Lwo=r(j6t,"ConvNextFeatureExtractor"),j6t.forEach(t),ywo=r(vIe," (RegNet model)"),vIe.forEach(t),xwo=i(W),mp=n(W,"LI",{});var FIe=s(mp);oue=n(FIe,"STRONG",{});var D6t=s(oue);$wo=r(D6t,"resnet"),D6t.forEach(t),kwo=r(FIe," \u2014 "),rO=n(FIe,"A",{href:!0});var G6t=s(rO);Swo=r(G6t,"ConvNextFeatureExtractor"),G6t.forEach(t),Rwo=r(FIe," (ResNet model)"),FIe.forEach(t),Pwo=i(W),fp=n(W,"LI",{});var TIe=s(fp);rue=n(TIe,"STRONG",{});var O6t=s(rue);Bwo=r(O6t,"segformer"),O6t.forEach(t),Iwo=r(TIe," \u2014 "),tO=n(TIe,"A",{href:!0});var V6t=s(tO);Nwo=r(V6t,"SegformerFeatureExtractor"),V6t.forEach(t),qwo=r(TIe," (SegFormer model)"),TIe.forEach(t),jwo=i(W),gp=n(W,"LI",{});var MIe=s(gp);tue=n(MIe,"STRONG",{});var X6t=s(tue);Dwo=r(X6t,"speech_to_text"),X6t.forEach(t),Gwo=r(MIe," \u2014 "),aO=n(MIe,"A",{href:!0});var z6t=s(aO);Owo=r(z6t,"Speech2TextFeatureExtractor"),z6t.forEach(t),Vwo=r(MIe," (Speech2Text model)"),MIe.forEach(t),Xwo=i(W),hp=n(W,"LI",{});var EIe=s(hp);aue=n(EIe,"STRONG",{});var Q6t=s(aue);zwo=r(Q6t,"swin"),Q6t.forEach(t),Qwo=r(EIe," \u2014 "),nO=n(EIe,"A",{href:!0});var W6t=s(nO);Wwo=r(W6t,"ViTFeatureExtractor"),W6t.forEach(t),Uwo=r(EIe," (Swin Transformer model)"),EIe.forEach(t),Hwo=i(W),up=n(W,"LI",{});var CIe=s(up);nue=n(CIe,"STRONG",{});var U6t=s(nue);Jwo=r(U6t,"swinv2"),U6t.forEach(t),Ywo=r(CIe," \u2014 "),sO=n(CIe,"A",{href:!0});var H6t=s(sO);Kwo=r(H6t,"ViTFeatureExtractor"),H6t.forEach(t),Zwo=r(CIe," (Swin Transformer V2 model)"),CIe.forEach(t),eAo=i(W),pp=n(W,"LI",{});var wIe=s(pp);sue=n(wIe,"STRONG",{});var J6t=s(sue);oAo=r(J6t,"van"),J6t.forEach(t),rAo=r(wIe," \u2014 "),lO=n(wIe,"A",{href:!0});var Y6t=s(lO);tAo=r(Y6t,"ConvNextFeatureExtractor"),Y6t.forEach(t),aAo=r(wIe," (VAN model)"),wIe.forEach(t),nAo=i(W),_p=n(W,"LI",{});var AIe=s(_p);lue=n(AIe,"STRONG",{});var K6t=s(lue);sAo=r(K6t,"videomae"),K6t.forEach(t),lAo=r(AIe," \u2014 "),iO=n(AIe,"A",{href:!0});var Z6t=s(iO);iAo=r(Z6t,"VideoMAEFeatureExtractor"),Z6t.forEach(t),dAo=r(AIe," (VideoMAE model)"),AIe.forEach(t),cAo=i(W),bp=n(W,"LI",{});var LIe=s(bp);iue=n(LIe,"STRONG",{});var e7t=s(iue);mAo=r(e7t,"vilt"),e7t.forEach(t),fAo=r(LIe," \u2014 "),dO=n(LIe,"A",{href:!0});var o7t=s(dO);gAo=r(o7t,"ViltFeatureExtractor"),o7t.forEach(t),hAo=r(LIe," (ViLT model)"),LIe.forEach(t),uAo=i(W),vp=n(W,"LI",{});var yIe=s(vp);due=n(yIe,"STRONG",{});var r7t=s(due);pAo=r(r7t,"vit"),r7t.forEach(t),_Ao=r(yIe," \u2014 "),cO=n(yIe,"A",{href:!0});var t7t=s(cO);bAo=r(t7t,"ViTFeatureExtractor"),t7t.forEach(t),vAo=r(yIe," (ViT model)"),yIe.forEach(t),FAo=i(W),Fp=n(W,"LI",{});var xIe=s(Fp);cue=n(xIe,"STRONG",{});var a7t=s(cue);TAo=r(a7t,"vit_mae"),a7t.forEach(t),MAo=r(xIe," \u2014 "),mO=n(xIe,"A",{href:!0});var n7t=s(mO);EAo=r(n7t,"ViTFeatureExtractor"),n7t.forEach(t),CAo=r(xIe," (ViTMAE model)"),xIe.forEach(t),wAo=i(W),Tp=n(W,"LI",{});var $Ie=s(Tp);mue=n($Ie,"STRONG",{});var s7t=s(mue);AAo=r(s7t,"vit_msn"),s7t.forEach(t),LAo=r($Ie," \u2014 "),fO=n($Ie,"A",{href:!0});var l7t=s(fO);yAo=r(l7t,"ViTFeatureExtractor"),l7t.forEach(t),xAo=r($Ie," (ViTMSN model)"),$Ie.forEach(t),$Ao=i(W),Mp=n(W,"LI",{});var kIe=s(Mp);fue=n(kIe,"STRONG",{});var i7t=s(fue);kAo=r(i7t,"wav2vec2"),i7t.forEach(t),SAo=r(kIe," \u2014 "),gO=n(kIe,"A",{href:!0});var d7t=s(gO);RAo=r(d7t,"Wav2Vec2FeatureExtractor"),d7t.forEach(t),PAo=r(kIe," (Wav2Vec2 model)"),kIe.forEach(t),BAo=i(W),Ep=n(W,"LI",{});var SIe=s(Ep);gue=n(SIe,"STRONG",{});var c7t=s(gue);IAo=r(c7t,"wav2vec2-conformer"),c7t.forEach(t),NAo=r(SIe," \u2014 "),hO=n(SIe,"A",{href:!0});var m7t=s(hO);qAo=r(m7t,"Wav2Vec2FeatureExtractor"),m7t.forEach(t),jAo=r(SIe," (Wav2Vec2-Conformer model)"),SIe.forEach(t),DAo=i(W),Cp=n(W,"LI",{});var RIe=s(Cp);hue=n(RIe,"STRONG",{});var f7t=s(hue);GAo=r(f7t,"xclip"),f7t.forEach(t),OAo=r(RIe," \u2014 "),uO=n(RIe,"A",{href:!0});var g7t=s(uO);VAo=r(g7t,"CLIPFeatureExtractor"),g7t.forEach(t),XAo=r(RIe," (X-CLIP model)"),RIe.forEach(t),zAo=i(W),wp=n(W,"LI",{});var PIe=s(wp);uue=n(PIe,"STRONG",{});var h7t=s(uue);QAo=r(h7t,"yolos"),h7t.forEach(t),WAo=r(PIe," \u2014 "),pO=n(PIe,"A",{href:!0});var u7t=s(pO);UAo=r(u7t,"YolosFeatureExtractor"),u7t.forEach(t),HAo=r(PIe," (YOLOS model)"),PIe.forEach(t),W.forEach(t),JAo=i(ba),T(Ap.$$.fragment,ba),YAo=i(ba),T(Lp.$$.fragment,ba),ba.forEach(t),KAo=i(Cl),yp=n(Cl,"DIV",{class:!0});var qoo=s(yp);T(gx.$$.fragment,qoo),ZAo=i(qoo),pue=n(qoo,"P",{});var p7t=s(pue);e6o=r(p7t,"Register a new feature extractor for this class."),p7t.forEach(t),qoo.forEach(t),Cl.forEach(t),LZe=i(m),ud=n(m,"H2",{class:!0});var joo=s(ud);xp=n(joo,"A",{id:!0,class:!0,href:!0});var _7t=s(xp);_ue=n(_7t,"SPAN",{});var b7t=s(_ue);T(hx.$$.fragment,b7t),b7t.forEach(t),_7t.forEach(t),o6o=i(joo),bue=n(joo,"SPAN",{});var v7t=s(bue);r6o=r(v7t,"AutoProcessor"),v7t.forEach(t),joo.forEach(t),yZe=i(m),Ro=n(m,"DIV",{class:!0});var wl=s(Ro);T(ux.$$.fragment,wl),t6o=i(wl),px=n(wl,"P",{});var Doo=s(px);a6o=r(Doo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),_O=n(Doo,"A",{href:!0});var F7t=s(_O);n6o=r(F7t,"AutoProcessor.from_pretrained()"),F7t.forEach(t),s6o=r(Doo," class method."),Doo.forEach(t),l6o=i(wl),_x=n(wl,"P",{});var Goo=s(_x);i6o=r(Goo,"This class cannot be instantiated directly using "),vue=n(Goo,"CODE",{});var T7t=s(vue);d6o=r(T7t,"__init__()"),T7t.forEach(t),c6o=r(Goo," (throws an error)."),Goo.forEach(t),m6o=i(wl),Ke=n(wl,"DIV",{class:!0});var va=s(Ke);T(bx.$$.fragment,va),f6o=i(va),Fue=n(va,"P",{});var M7t=s(Fue);g6o=r(M7t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),M7t.forEach(t),h6o=i(va),pd=n(va,"P",{});var jle=s(pd);u6o=r(jle,"The processor class to instantiate is selected based on the "),Tue=n(jle,"CODE",{});var E7t=s(Tue);p6o=r(E7t,"model_type"),E7t.forEach(t),_6o=r(jle,` property of the config object (either
passed as an argument or loaded from `),Mue=n(jle,"CODE",{});var C7t=s(Mue);b6o=r(C7t,"pretrained_model_name_or_path"),C7t.forEach(t),v6o=r(jle," if possible):"),jle.forEach(t),F6o=i(va),le=n(va,"UL",{});var me=s(le);$p=n(me,"LI",{});var BIe=s($p);Eue=n(BIe,"STRONG",{});var w7t=s(Eue);T6o=r(w7t,"clip"),w7t.forEach(t),M6o=r(BIe," \u2014 "),bO=n(BIe,"A",{href:!0});var A7t=s(bO);E6o=r(A7t,"CLIPProcessor"),A7t.forEach(t),C6o=r(BIe," (CLIP model)"),BIe.forEach(t),w6o=i(me),kp=n(me,"LI",{});var IIe=s(kp);Cue=n(IIe,"STRONG",{});var L7t=s(Cue);A6o=r(L7t,"donut"),L7t.forEach(t),L6o=r(IIe," \u2014 "),vO=n(IIe,"A",{href:!0});var y7t=s(vO);y6o=r(y7t,"DonutProcessor"),y7t.forEach(t),x6o=r(IIe," (Donut model)"),IIe.forEach(t),$6o=i(me),Sp=n(me,"LI",{});var NIe=s(Sp);wue=n(NIe,"STRONG",{});var x7t=s(wue);k6o=r(x7t,"flava"),x7t.forEach(t),S6o=r(NIe," \u2014 "),FO=n(NIe,"A",{href:!0});var $7t=s(FO);R6o=r($7t,"FlavaProcessor"),$7t.forEach(t),P6o=r(NIe," (FLAVA model)"),NIe.forEach(t),B6o=i(me),Rp=n(me,"LI",{});var qIe=s(Rp);Aue=n(qIe,"STRONG",{});var k7t=s(Aue);I6o=r(k7t,"groupvit"),k7t.forEach(t),N6o=r(qIe," \u2014 "),TO=n(qIe,"A",{href:!0});var S7t=s(TO);q6o=r(S7t,"CLIPProcessor"),S7t.forEach(t),j6o=r(qIe," (GroupViT model)"),qIe.forEach(t),D6o=i(me),Pp=n(me,"LI",{});var jIe=s(Pp);Lue=n(jIe,"STRONG",{});var R7t=s(Lue);G6o=r(R7t,"layoutlmv2"),R7t.forEach(t),O6o=r(jIe," \u2014 "),MO=n(jIe,"A",{href:!0});var P7t=s(MO);V6o=r(P7t,"LayoutLMv2Processor"),P7t.forEach(t),X6o=r(jIe," (LayoutLMv2 model)"),jIe.forEach(t),z6o=i(me),Bp=n(me,"LI",{});var DIe=s(Bp);yue=n(DIe,"STRONG",{});var B7t=s(yue);Q6o=r(B7t,"layoutlmv3"),B7t.forEach(t),W6o=r(DIe," \u2014 "),EO=n(DIe,"A",{href:!0});var I7t=s(EO);U6o=r(I7t,"LayoutLMv3Processor"),I7t.forEach(t),H6o=r(DIe," (LayoutLMv3 model)"),DIe.forEach(t),J6o=i(me),Ip=n(me,"LI",{});var GIe=s(Ip);xue=n(GIe,"STRONG",{});var N7t=s(xue);Y6o=r(N7t,"layoutxlm"),N7t.forEach(t),K6o=r(GIe," \u2014 "),CO=n(GIe,"A",{href:!0});var q7t=s(CO);Z6o=r(q7t,"LayoutXLMProcessor"),q7t.forEach(t),e7o=r(GIe," (LayoutXLM model)"),GIe.forEach(t),o7o=i(me),Np=n(me,"LI",{});var OIe=s(Np);$ue=n(OIe,"STRONG",{});var j7t=s($ue);r7o=r(j7t,"markuplm"),j7t.forEach(t),t7o=r(OIe," \u2014 "),wO=n(OIe,"A",{href:!0});var D7t=s(wO);a7o=r(D7t,"MarkupLMProcessor"),D7t.forEach(t),n7o=r(OIe," (MarkupLM model)"),OIe.forEach(t),s7o=i(me),qp=n(me,"LI",{});var VIe=s(qp);kue=n(VIe,"STRONG",{});var G7t=s(kue);l7o=r(G7t,"owlvit"),G7t.forEach(t),i7o=r(VIe," \u2014 "),AO=n(VIe,"A",{href:!0});var O7t=s(AO);d7o=r(O7t,"OwlViTProcessor"),O7t.forEach(t),c7o=r(VIe," (OWL-ViT model)"),VIe.forEach(t),m7o=i(me),jp=n(me,"LI",{});var XIe=s(jp);Sue=n(XIe,"STRONG",{});var V7t=s(Sue);f7o=r(V7t,"sew"),V7t.forEach(t),g7o=r(XIe," \u2014 "),LO=n(XIe,"A",{href:!0});var X7t=s(LO);h7o=r(X7t,"Wav2Vec2Processor"),X7t.forEach(t),u7o=r(XIe," (SEW model)"),XIe.forEach(t),p7o=i(me),Dp=n(me,"LI",{});var zIe=s(Dp);Rue=n(zIe,"STRONG",{});var z7t=s(Rue);_7o=r(z7t,"sew-d"),z7t.forEach(t),b7o=r(zIe," \u2014 "),yO=n(zIe,"A",{href:!0});var Q7t=s(yO);v7o=r(Q7t,"Wav2Vec2Processor"),Q7t.forEach(t),F7o=r(zIe," (SEW-D model)"),zIe.forEach(t),T7o=i(me),Gp=n(me,"LI",{});var QIe=s(Gp);Pue=n(QIe,"STRONG",{});var W7t=s(Pue);M7o=r(W7t,"speech_to_text"),W7t.forEach(t),E7o=r(QIe," \u2014 "),xO=n(QIe,"A",{href:!0});var U7t=s(xO);C7o=r(U7t,"Speech2TextProcessor"),U7t.forEach(t),w7o=r(QIe," (Speech2Text model)"),QIe.forEach(t),A7o=i(me),Op=n(me,"LI",{});var WIe=s(Op);Bue=n(WIe,"STRONG",{});var H7t=s(Bue);L7o=r(H7t,"speech_to_text_2"),H7t.forEach(t),y7o=r(WIe," \u2014 "),$O=n(WIe,"A",{href:!0});var J7t=s($O);x7o=r(J7t,"Speech2Text2Processor"),J7t.forEach(t),$7o=r(WIe," (Speech2Text2 model)"),WIe.forEach(t),k7o=i(me),Vp=n(me,"LI",{});var UIe=s(Vp);Iue=n(UIe,"STRONG",{});var Y7t=s(Iue);S7o=r(Y7t,"trocr"),Y7t.forEach(t),R7o=r(UIe," \u2014 "),kO=n(UIe,"A",{href:!0});var K7t=s(kO);P7o=r(K7t,"TrOCRProcessor"),K7t.forEach(t),B7o=r(UIe," (TrOCR model)"),UIe.forEach(t),I7o=i(me),Xp=n(me,"LI",{});var HIe=s(Xp);Nue=n(HIe,"STRONG",{});var Z7t=s(Nue);N7o=r(Z7t,"unispeech"),Z7t.forEach(t),q7o=r(HIe," \u2014 "),SO=n(HIe,"A",{href:!0});var eLt=s(SO);j7o=r(eLt,"Wav2Vec2Processor"),eLt.forEach(t),D7o=r(HIe," (UniSpeech model)"),HIe.forEach(t),G7o=i(me),zp=n(me,"LI",{});var JIe=s(zp);que=n(JIe,"STRONG",{});var oLt=s(que);O7o=r(oLt,"unispeech-sat"),oLt.forEach(t),V7o=r(JIe," \u2014 "),RO=n(JIe,"A",{href:!0});var rLt=s(RO);X7o=r(rLt,"Wav2Vec2Processor"),rLt.forEach(t),z7o=r(JIe," (UniSpeechSat model)"),JIe.forEach(t),Q7o=i(me),Qp=n(me,"LI",{});var YIe=s(Qp);jue=n(YIe,"STRONG",{});var tLt=s(jue);W7o=r(tLt,"vilt"),tLt.forEach(t),U7o=r(YIe," \u2014 "),PO=n(YIe,"A",{href:!0});var aLt=s(PO);H7o=r(aLt,"ViltProcessor"),aLt.forEach(t),J7o=r(YIe," (ViLT model)"),YIe.forEach(t),Y7o=i(me),Wp=n(me,"LI",{});var KIe=s(Wp);Due=n(KIe,"STRONG",{});var nLt=s(Due);K7o=r(nLt,"vision-text-dual-encoder"),nLt.forEach(t),Z7o=r(KIe," \u2014 "),BO=n(KIe,"A",{href:!0});var sLt=s(BO);eLo=r(sLt,"VisionTextDualEncoderProcessor"),sLt.forEach(t),oLo=r(KIe," (VisionTextDualEncoder model)"),KIe.forEach(t),rLo=i(me),Up=n(me,"LI",{});var ZIe=s(Up);Gue=n(ZIe,"STRONG",{});var lLt=s(Gue);tLo=r(lLt,"wav2vec2"),lLt.forEach(t),aLo=r(ZIe," \u2014 "),IO=n(ZIe,"A",{href:!0});var iLt=s(IO);nLo=r(iLt,"Wav2Vec2Processor"),iLt.forEach(t),sLo=r(ZIe," (Wav2Vec2 model)"),ZIe.forEach(t),lLo=i(me),Hp=n(me,"LI",{});var eNe=s(Hp);Oue=n(eNe,"STRONG",{});var dLt=s(Oue);iLo=r(dLt,"wav2vec2-conformer"),dLt.forEach(t),dLo=r(eNe," \u2014 "),NO=n(eNe,"A",{href:!0});var cLt=s(NO);cLo=r(cLt,"Wav2Vec2Processor"),cLt.forEach(t),mLo=r(eNe," (Wav2Vec2-Conformer model)"),eNe.forEach(t),fLo=i(me),Jp=n(me,"LI",{});var oNe=s(Jp);Vue=n(oNe,"STRONG",{});var mLt=s(Vue);gLo=r(mLt,"wavlm"),mLt.forEach(t),hLo=r(oNe," \u2014 "),qO=n(oNe,"A",{href:!0});var fLt=s(qO);uLo=r(fLt,"Wav2Vec2Processor"),fLt.forEach(t),pLo=r(oNe," (WavLM model)"),oNe.forEach(t),_Lo=i(me),Yp=n(me,"LI",{});var rNe=s(Yp);Xue=n(rNe,"STRONG",{});var gLt=s(Xue);bLo=r(gLt,"xclip"),gLt.forEach(t),vLo=r(rNe," \u2014 "),jO=n(rNe,"A",{href:!0});var hLt=s(jO);FLo=r(hLt,"CLIPProcessor"),hLt.forEach(t),TLo=r(rNe," (X-CLIP model)"),rNe.forEach(t),me.forEach(t),MLo=i(va),T(Kp.$$.fragment,va),ELo=i(va),T(Zp.$$.fragment,va),va.forEach(t),CLo=i(wl),e_=n(wl,"DIV",{class:!0});var Ooo=s(e_);T(vx.$$.fragment,Ooo),wLo=i(Ooo),zue=n(Ooo,"P",{});var uLt=s(zue);ALo=r(uLt,"Register a new processor for this class."),uLt.forEach(t),Ooo.forEach(t),wl.forEach(t),xZe=i(m),_d=n(m,"H2",{class:!0});var Voo=s(_d);o_=n(Voo,"A",{id:!0,class:!0,href:!0});var pLt=s(o_);Que=n(pLt,"SPAN",{});var _Lt=s(Que);T(Fx.$$.fragment,_Lt),_Lt.forEach(t),pLt.forEach(t),LLo=i(Voo),Wue=n(Voo,"SPAN",{});var bLt=s(Wue);yLo=r(bLt,"AutoModel"),bLt.forEach(t),Voo.forEach(t),$Ze=i(m),Po=n(m,"DIV",{class:!0});var Al=s(Po);T(Tx.$$.fragment,Al),xLo=i(Al),bd=n(Al,"P",{});var Dle=s(bd);$Lo=r(Dle,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),DO=n(Dle,"A",{href:!0});var vLt=s(DO);kLo=r(vLt,"from_pretrained()"),vLt.forEach(t),SLo=r(Dle," class method or the "),GO=n(Dle,"A",{href:!0});var FLt=s(GO);RLo=r(FLt,"from_config()"),FLt.forEach(t),PLo=r(Dle,` class
method.`),Dle.forEach(t),BLo=i(Al),Mx=n(Al,"P",{});var Xoo=s(Mx);ILo=r(Xoo,"This class cannot be instantiated directly using "),Uue=n(Xoo,"CODE",{});var TLt=s(Uue);NLo=r(TLt,"__init__()"),TLt.forEach(t),qLo=r(Xoo," (throws an error)."),Xoo.forEach(t),jLo=i(Al),_t=n(Al,"DIV",{class:!0});var Oy=s(_t);T(Ex.$$.fragment,Oy),DLo=i(Oy),Hue=n(Oy,"P",{});var MLt=s(Hue);GLo=r(MLt,"Instantiates one of the base model classes of the library from a configuration."),MLt.forEach(t),OLo=i(Oy),vd=n(Oy,"P",{});var Gle=s(vd);VLo=r(Gle,`Note:
Loading a model from its configuration file does `),Jue=n(Gle,"STRONG",{});var ELt=s(Jue);XLo=r(ELt,"not"),ELt.forEach(t),zLo=r(Gle,` load the model weights. It only affects the
model\u2019s configuration. Use `),OO=n(Gle,"A",{href:!0});var CLt=s(OO);QLo=r(CLt,"from_pretrained()"),CLt.forEach(t),WLo=r(Gle," to load the model weights."),Gle.forEach(t),ULo=i(Oy),T(r_.$$.fragment,Oy),Oy.forEach(t),HLo=i(Al),Ze=n(Al,"DIV",{class:!0});var Fa=s(Ze);T(Cx.$$.fragment,Fa),JLo=i(Fa),Yue=n(Fa,"P",{});var wLt=s(Yue);YLo=r(wLt,"Instantiate one of the base model classes of the library from a pretrained model."),wLt.forEach(t),KLo=i(Fa),Ja=n(Fa,"P",{});var Vy=s(Ja);ZLo=r(Vy,"The model class to instantiate is selected based on the "),Kue=n(Vy,"CODE",{});var ALt=s(Kue);eyo=r(ALt,"model_type"),ALt.forEach(t),oyo=r(Vy,` property of the config object (either
passed as an argument or loaded from `),Zue=n(Vy,"CODE",{});var LLt=s(Zue);ryo=r(LLt,"pretrained_model_name_or_path"),LLt.forEach(t),tyo=r(Vy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),epe=n(Vy,"CODE",{});var yLt=s(epe);ayo=r(yLt,"pretrained_model_name_or_path"),yLt.forEach(t),nyo=r(Vy,":"),Vy.forEach(t),syo=i(Fa),y=n(Fa,"UL",{});var x=s(y);t_=n(x,"LI",{});var tNe=s(t_);ope=n(tNe,"STRONG",{});var xLt=s(ope);lyo=r(xLt,"albert"),xLt.forEach(t),iyo=r(tNe," \u2014 "),VO=n(tNe,"A",{href:!0});var $Lt=s(VO);dyo=r($Lt,"AlbertModel"),$Lt.forEach(t),cyo=r(tNe," (ALBERT model)"),tNe.forEach(t),myo=i(x),a_=n(x,"LI",{});var aNe=s(a_);rpe=n(aNe,"STRONG",{});var kLt=s(rpe);fyo=r(kLt,"bart"),kLt.forEach(t),gyo=r(aNe," \u2014 "),XO=n(aNe,"A",{href:!0});var SLt=s(XO);hyo=r(SLt,"BartModel"),SLt.forEach(t),uyo=r(aNe," (BART model)"),aNe.forEach(t),pyo=i(x),n_=n(x,"LI",{});var nNe=s(n_);tpe=n(nNe,"STRONG",{});var RLt=s(tpe);_yo=r(RLt,"beit"),RLt.forEach(t),byo=r(nNe," \u2014 "),zO=n(nNe,"A",{href:!0});var PLt=s(zO);vyo=r(PLt,"BeitModel"),PLt.forEach(t),Fyo=r(nNe," (BEiT model)"),nNe.forEach(t),Tyo=i(x),s_=n(x,"LI",{});var sNe=s(s_);ape=n(sNe,"STRONG",{});var BLt=s(ape);Myo=r(BLt,"bert"),BLt.forEach(t),Eyo=r(sNe," \u2014 "),QO=n(sNe,"A",{href:!0});var ILt=s(QO);Cyo=r(ILt,"BertModel"),ILt.forEach(t),wyo=r(sNe," (BERT model)"),sNe.forEach(t),Ayo=i(x),l_=n(x,"LI",{});var lNe=s(l_);npe=n(lNe,"STRONG",{});var NLt=s(npe);Lyo=r(NLt,"bert-generation"),NLt.forEach(t),yyo=r(lNe," \u2014 "),WO=n(lNe,"A",{href:!0});var qLt=s(WO);xyo=r(qLt,"BertGenerationEncoder"),qLt.forEach(t),$yo=r(lNe," (Bert Generation model)"),lNe.forEach(t),kyo=i(x),i_=n(x,"LI",{});var iNe=s(i_);spe=n(iNe,"STRONG",{});var jLt=s(spe);Syo=r(jLt,"big_bird"),jLt.forEach(t),Ryo=r(iNe," \u2014 "),UO=n(iNe,"A",{href:!0});var DLt=s(UO);Pyo=r(DLt,"BigBirdModel"),DLt.forEach(t),Byo=r(iNe," (BigBird model)"),iNe.forEach(t),Iyo=i(x),d_=n(x,"LI",{});var dNe=s(d_);lpe=n(dNe,"STRONG",{});var GLt=s(lpe);Nyo=r(GLt,"bigbird_pegasus"),GLt.forEach(t),qyo=r(dNe," \u2014 "),HO=n(dNe,"A",{href:!0});var OLt=s(HO);jyo=r(OLt,"BigBirdPegasusModel"),OLt.forEach(t),Dyo=r(dNe," (BigBird-Pegasus model)"),dNe.forEach(t),Gyo=i(x),c_=n(x,"LI",{});var cNe=s(c_);ipe=n(cNe,"STRONG",{});var VLt=s(ipe);Oyo=r(VLt,"blenderbot"),VLt.forEach(t),Vyo=r(cNe," \u2014 "),JO=n(cNe,"A",{href:!0});var XLt=s(JO);Xyo=r(XLt,"BlenderbotModel"),XLt.forEach(t),zyo=r(cNe," (Blenderbot model)"),cNe.forEach(t),Qyo=i(x),m_=n(x,"LI",{});var mNe=s(m_);dpe=n(mNe,"STRONG",{});var zLt=s(dpe);Wyo=r(zLt,"blenderbot-small"),zLt.forEach(t),Uyo=r(mNe," \u2014 "),YO=n(mNe,"A",{href:!0});var QLt=s(YO);Hyo=r(QLt,"BlenderbotSmallModel"),QLt.forEach(t),Jyo=r(mNe," (BlenderbotSmall model)"),mNe.forEach(t),Yyo=i(x),f_=n(x,"LI",{});var fNe=s(f_);cpe=n(fNe,"STRONG",{});var WLt=s(cpe);Kyo=r(WLt,"bloom"),WLt.forEach(t),Zyo=r(fNe," \u2014 "),KO=n(fNe,"A",{href:!0});var ULt=s(KO);e8o=r(ULt,"BloomModel"),ULt.forEach(t),o8o=r(fNe," (BLOOM model)"),fNe.forEach(t),r8o=i(x),g_=n(x,"LI",{});var gNe=s(g_);mpe=n(gNe,"STRONG",{});var HLt=s(mpe);t8o=r(HLt,"camembert"),HLt.forEach(t),a8o=r(gNe," \u2014 "),ZO=n(gNe,"A",{href:!0});var JLt=s(ZO);n8o=r(JLt,"CamembertModel"),JLt.forEach(t),s8o=r(gNe," (CamemBERT model)"),gNe.forEach(t),l8o=i(x),h_=n(x,"LI",{});var hNe=s(h_);fpe=n(hNe,"STRONG",{});var YLt=s(fpe);i8o=r(YLt,"canine"),YLt.forEach(t),d8o=r(hNe," \u2014 "),eV=n(hNe,"A",{href:!0});var KLt=s(eV);c8o=r(KLt,"CanineModel"),KLt.forEach(t),m8o=r(hNe," (CANINE model)"),hNe.forEach(t),f8o=i(x),u_=n(x,"LI",{});var uNe=s(u_);gpe=n(uNe,"STRONG",{});var ZLt=s(gpe);g8o=r(ZLt,"clip"),ZLt.forEach(t),h8o=r(uNe," \u2014 "),oV=n(uNe,"A",{href:!0});var eyt=s(oV);u8o=r(eyt,"CLIPModel"),eyt.forEach(t),p8o=r(uNe," (CLIP model)"),uNe.forEach(t),_8o=i(x),p_=n(x,"LI",{});var pNe=s(p_);hpe=n(pNe,"STRONG",{});var oyt=s(hpe);b8o=r(oyt,"codegen"),oyt.forEach(t),v8o=r(pNe," \u2014 "),rV=n(pNe,"A",{href:!0});var ryt=s(rV);F8o=r(ryt,"CodeGenModel"),ryt.forEach(t),T8o=r(pNe," (CodeGen model)"),pNe.forEach(t),M8o=i(x),__=n(x,"LI",{});var _Ne=s(__);upe=n(_Ne,"STRONG",{});var tyt=s(upe);E8o=r(tyt,"conditional_detr"),tyt.forEach(t),C8o=r(_Ne," \u2014 "),tV=n(_Ne,"A",{href:!0});var ayt=s(tV);w8o=r(ayt,"ConditionalDetrModel"),ayt.forEach(t),A8o=r(_Ne," (Conditional DETR model)"),_Ne.forEach(t),L8o=i(x),b_=n(x,"LI",{});var bNe=s(b_);ppe=n(bNe,"STRONG",{});var nyt=s(ppe);y8o=r(nyt,"convbert"),nyt.forEach(t),x8o=r(bNe," \u2014 "),aV=n(bNe,"A",{href:!0});var syt=s(aV);$8o=r(syt,"ConvBertModel"),syt.forEach(t),k8o=r(bNe," (ConvBERT model)"),bNe.forEach(t),S8o=i(x),v_=n(x,"LI",{});var vNe=s(v_);_pe=n(vNe,"STRONG",{});var lyt=s(_pe);R8o=r(lyt,"convnext"),lyt.forEach(t),P8o=r(vNe," \u2014 "),nV=n(vNe,"A",{href:!0});var iyt=s(nV);B8o=r(iyt,"ConvNextModel"),iyt.forEach(t),I8o=r(vNe," (ConvNeXT model)"),vNe.forEach(t),N8o=i(x),F_=n(x,"LI",{});var FNe=s(F_);bpe=n(FNe,"STRONG",{});var dyt=s(bpe);q8o=r(dyt,"ctrl"),dyt.forEach(t),j8o=r(FNe," \u2014 "),sV=n(FNe,"A",{href:!0});var cyt=s(sV);D8o=r(cyt,"CTRLModel"),cyt.forEach(t),G8o=r(FNe," (CTRL model)"),FNe.forEach(t),O8o=i(x),T_=n(x,"LI",{});var TNe=s(T_);vpe=n(TNe,"STRONG",{});var myt=s(vpe);V8o=r(myt,"cvt"),myt.forEach(t),X8o=r(TNe," \u2014 "),lV=n(TNe,"A",{href:!0});var fyt=s(lV);z8o=r(fyt,"CvtModel"),fyt.forEach(t),Q8o=r(TNe," (CvT model)"),TNe.forEach(t),W8o=i(x),M_=n(x,"LI",{});var MNe=s(M_);Fpe=n(MNe,"STRONG",{});var gyt=s(Fpe);U8o=r(gyt,"data2vec-audio"),gyt.forEach(t),H8o=r(MNe," \u2014 "),iV=n(MNe,"A",{href:!0});var hyt=s(iV);J8o=r(hyt,"Data2VecAudioModel"),hyt.forEach(t),Y8o=r(MNe," (Data2VecAudio model)"),MNe.forEach(t),K8o=i(x),E_=n(x,"LI",{});var ENe=s(E_);Tpe=n(ENe,"STRONG",{});var uyt=s(Tpe);Z8o=r(uyt,"data2vec-text"),uyt.forEach(t),e9o=r(ENe," \u2014 "),dV=n(ENe,"A",{href:!0});var pyt=s(dV);o9o=r(pyt,"Data2VecTextModel"),pyt.forEach(t),r9o=r(ENe," (Data2VecText model)"),ENe.forEach(t),t9o=i(x),C_=n(x,"LI",{});var CNe=s(C_);Mpe=n(CNe,"STRONG",{});var _yt=s(Mpe);a9o=r(_yt,"data2vec-vision"),_yt.forEach(t),n9o=r(CNe," \u2014 "),cV=n(CNe,"A",{href:!0});var byt=s(cV);s9o=r(byt,"Data2VecVisionModel"),byt.forEach(t),l9o=r(CNe," (Data2VecVision model)"),CNe.forEach(t),i9o=i(x),w_=n(x,"LI",{});var wNe=s(w_);Epe=n(wNe,"STRONG",{});var vyt=s(Epe);d9o=r(vyt,"deberta"),vyt.forEach(t),c9o=r(wNe," \u2014 "),mV=n(wNe,"A",{href:!0});var Fyt=s(mV);m9o=r(Fyt,"DebertaModel"),Fyt.forEach(t),f9o=r(wNe," (DeBERTa model)"),wNe.forEach(t),g9o=i(x),A_=n(x,"LI",{});var ANe=s(A_);Cpe=n(ANe,"STRONG",{});var Tyt=s(Cpe);h9o=r(Tyt,"deberta-v2"),Tyt.forEach(t),u9o=r(ANe," \u2014 "),fV=n(ANe,"A",{href:!0});var Myt=s(fV);p9o=r(Myt,"DebertaV2Model"),Myt.forEach(t),_9o=r(ANe," (DeBERTa-v2 model)"),ANe.forEach(t),b9o=i(x),L_=n(x,"LI",{});var LNe=s(L_);wpe=n(LNe,"STRONG",{});var Eyt=s(wpe);v9o=r(Eyt,"decision_transformer"),Eyt.forEach(t),F9o=r(LNe," \u2014 "),gV=n(LNe,"A",{href:!0});var Cyt=s(gV);T9o=r(Cyt,"DecisionTransformerModel"),Cyt.forEach(t),M9o=r(LNe," (Decision Transformer model)"),LNe.forEach(t),E9o=i(x),y_=n(x,"LI",{});var yNe=s(y_);Ape=n(yNe,"STRONG",{});var wyt=s(Ape);C9o=r(wyt,"deformable_detr"),wyt.forEach(t),w9o=r(yNe," \u2014 "),hV=n(yNe,"A",{href:!0});var Ayt=s(hV);A9o=r(Ayt,"DeformableDetrModel"),Ayt.forEach(t),L9o=r(yNe," (Deformable DETR model)"),yNe.forEach(t),y9o=i(x),x_=n(x,"LI",{});var xNe=s(x_);Lpe=n(xNe,"STRONG",{});var Lyt=s(Lpe);x9o=r(Lyt,"deit"),Lyt.forEach(t),$9o=r(xNe," \u2014 "),uV=n(xNe,"A",{href:!0});var yyt=s(uV);k9o=r(yyt,"DeiTModel"),yyt.forEach(t),S9o=r(xNe," (DeiT model)"),xNe.forEach(t),R9o=i(x),$_=n(x,"LI",{});var $Ne=s($_);ype=n($Ne,"STRONG",{});var xyt=s(ype);P9o=r(xyt,"detr"),xyt.forEach(t),B9o=r($Ne," \u2014 "),pV=n($Ne,"A",{href:!0});var $yt=s(pV);I9o=r($yt,"DetrModel"),$yt.forEach(t),N9o=r($Ne," (DETR model)"),$Ne.forEach(t),q9o=i(x),k_=n(x,"LI",{});var kNe=s(k_);xpe=n(kNe,"STRONG",{});var kyt=s(xpe);j9o=r(kyt,"distilbert"),kyt.forEach(t),D9o=r(kNe," \u2014 "),_V=n(kNe,"A",{href:!0});var Syt=s(_V);G9o=r(Syt,"DistilBertModel"),Syt.forEach(t),O9o=r(kNe," (DistilBERT model)"),kNe.forEach(t),V9o=i(x),S_=n(x,"LI",{});var SNe=s(S_);$pe=n(SNe,"STRONG",{});var Ryt=s($pe);X9o=r(Ryt,"donut-swin"),Ryt.forEach(t),z9o=r(SNe," \u2014 "),bV=n(SNe,"A",{href:!0});var Pyt=s(bV);Q9o=r(Pyt,"DonutSwinModel"),Pyt.forEach(t),W9o=r(SNe," (DonutSwin model)"),SNe.forEach(t),U9o=i(x),R_=n(x,"LI",{});var RNe=s(R_);kpe=n(RNe,"STRONG",{});var Byt=s(kpe);H9o=r(Byt,"dpr"),Byt.forEach(t),J9o=r(RNe," \u2014 "),vV=n(RNe,"A",{href:!0});var Iyt=s(vV);Y9o=r(Iyt,"DPRQuestionEncoder"),Iyt.forEach(t),K9o=r(RNe," (DPR model)"),RNe.forEach(t),Z9o=i(x),P_=n(x,"LI",{});var PNe=s(P_);Spe=n(PNe,"STRONG",{});var Nyt=s(Spe);exo=r(Nyt,"dpt"),Nyt.forEach(t),oxo=r(PNe," \u2014 "),FV=n(PNe,"A",{href:!0});var qyt=s(FV);rxo=r(qyt,"DPTModel"),qyt.forEach(t),txo=r(PNe," (DPT model)"),PNe.forEach(t),axo=i(x),B_=n(x,"LI",{});var BNe=s(B_);Rpe=n(BNe,"STRONG",{});var jyt=s(Rpe);nxo=r(jyt,"electra"),jyt.forEach(t),sxo=r(BNe," \u2014 "),TV=n(BNe,"A",{href:!0});var Dyt=s(TV);lxo=r(Dyt,"ElectraModel"),Dyt.forEach(t),ixo=r(BNe," (ELECTRA model)"),BNe.forEach(t),dxo=i(x),I_=n(x,"LI",{});var INe=s(I_);Ppe=n(INe,"STRONG",{});var Gyt=s(Ppe);cxo=r(Gyt,"ernie"),Gyt.forEach(t),mxo=r(INe," \u2014 "),MV=n(INe,"A",{href:!0});var Oyt=s(MV);fxo=r(Oyt,"ErnieModel"),Oyt.forEach(t),gxo=r(INe," (ERNIE model)"),INe.forEach(t),hxo=i(x),N_=n(x,"LI",{});var NNe=s(N_);Bpe=n(NNe,"STRONG",{});var Vyt=s(Bpe);uxo=r(Vyt,"flaubert"),Vyt.forEach(t),pxo=r(NNe," \u2014 "),EV=n(NNe,"A",{href:!0});var Xyt=s(EV);_xo=r(Xyt,"FlaubertModel"),Xyt.forEach(t),bxo=r(NNe," (FlauBERT model)"),NNe.forEach(t),vxo=i(x),q_=n(x,"LI",{});var qNe=s(q_);Ipe=n(qNe,"STRONG",{});var zyt=s(Ipe);Fxo=r(zyt,"flava"),zyt.forEach(t),Txo=r(qNe," \u2014 "),CV=n(qNe,"A",{href:!0});var Qyt=s(CV);Mxo=r(Qyt,"FlavaModel"),Qyt.forEach(t),Exo=r(qNe," (FLAVA model)"),qNe.forEach(t),Cxo=i(x),j_=n(x,"LI",{});var jNe=s(j_);Npe=n(jNe,"STRONG",{});var Wyt=s(Npe);wxo=r(Wyt,"fnet"),Wyt.forEach(t),Axo=r(jNe," \u2014 "),wV=n(jNe,"A",{href:!0});var Uyt=s(wV);Lxo=r(Uyt,"FNetModel"),Uyt.forEach(t),yxo=r(jNe," (FNet model)"),jNe.forEach(t),xxo=i(x),D_=n(x,"LI",{});var DNe=s(D_);qpe=n(DNe,"STRONG",{});var Hyt=s(qpe);$xo=r(Hyt,"fsmt"),Hyt.forEach(t),kxo=r(DNe," \u2014 "),AV=n(DNe,"A",{href:!0});var Jyt=s(AV);Sxo=r(Jyt,"FSMTModel"),Jyt.forEach(t),Rxo=r(DNe," (FairSeq Machine-Translation model)"),DNe.forEach(t),Pxo=i(x),_l=n(x,"LI",{});var VB=s(_l);jpe=n(VB,"STRONG",{});var Yyt=s(jpe);Bxo=r(Yyt,"funnel"),Yyt.forEach(t),Ixo=r(VB," \u2014 "),LV=n(VB,"A",{href:!0});var Kyt=s(LV);Nxo=r(Kyt,"FunnelModel"),Kyt.forEach(t),qxo=r(VB," or "),yV=n(VB,"A",{href:!0});var Zyt=s(yV);jxo=r(Zyt,"FunnelBaseModel"),Zyt.forEach(t),Dxo=r(VB," (Funnel Transformer model)"),VB.forEach(t),Gxo=i(x),G_=n(x,"LI",{});var GNe=s(G_);Dpe=n(GNe,"STRONG",{});var e8t=s(Dpe);Oxo=r(e8t,"glpn"),e8t.forEach(t),Vxo=r(GNe," \u2014 "),xV=n(GNe,"A",{href:!0});var o8t=s(xV);Xxo=r(o8t,"GLPNModel"),o8t.forEach(t),zxo=r(GNe," (GLPN model)"),GNe.forEach(t),Qxo=i(x),O_=n(x,"LI",{});var ONe=s(O_);Gpe=n(ONe,"STRONG",{});var r8t=s(Gpe);Wxo=r(r8t,"gpt2"),r8t.forEach(t),Uxo=r(ONe," \u2014 "),$V=n(ONe,"A",{href:!0});var t8t=s($V);Hxo=r(t8t,"GPT2Model"),t8t.forEach(t),Jxo=r(ONe," (OpenAI GPT-2 model)"),ONe.forEach(t),Yxo=i(x),V_=n(x,"LI",{});var VNe=s(V_);Ope=n(VNe,"STRONG",{});var a8t=s(Ope);Kxo=r(a8t,"gpt_neo"),a8t.forEach(t),Zxo=r(VNe," \u2014 "),kV=n(VNe,"A",{href:!0});var n8t=s(kV);e$o=r(n8t,"GPTNeoModel"),n8t.forEach(t),o$o=r(VNe," (GPT Neo model)"),VNe.forEach(t),r$o=i(x),X_=n(x,"LI",{});var XNe=s(X_);Vpe=n(XNe,"STRONG",{});var s8t=s(Vpe);t$o=r(s8t,"gpt_neox"),s8t.forEach(t),a$o=r(XNe," \u2014 "),SV=n(XNe,"A",{href:!0});var l8t=s(SV);n$o=r(l8t,"GPTNeoXModel"),l8t.forEach(t),s$o=r(XNe," (GPT NeoX model)"),XNe.forEach(t),l$o=i(x),z_=n(x,"LI",{});var zNe=s(z_);Xpe=n(zNe,"STRONG",{});var i8t=s(Xpe);i$o=r(i8t,"gpt_neox_japanese"),i8t.forEach(t),d$o=r(zNe," \u2014 "),RV=n(zNe,"A",{href:!0});var d8t=s(RV);c$o=r(d8t,"GPTNeoXJapaneseModel"),d8t.forEach(t),m$o=r(zNe," (GPT NeoX Japanese model)"),zNe.forEach(t),f$o=i(x),Q_=n(x,"LI",{});var QNe=s(Q_);zpe=n(QNe,"STRONG",{});var c8t=s(zpe);g$o=r(c8t,"gptj"),c8t.forEach(t),h$o=r(QNe," \u2014 "),PV=n(QNe,"A",{href:!0});var m8t=s(PV);u$o=r(m8t,"GPTJModel"),m8t.forEach(t),p$o=r(QNe," (GPT-J model)"),QNe.forEach(t),_$o=i(x),W_=n(x,"LI",{});var WNe=s(W_);Qpe=n(WNe,"STRONG",{});var f8t=s(Qpe);b$o=r(f8t,"groupvit"),f8t.forEach(t),v$o=r(WNe," \u2014 "),BV=n(WNe,"A",{href:!0});var g8t=s(BV);F$o=r(g8t,"GroupViTModel"),g8t.forEach(t),T$o=r(WNe," (GroupViT model)"),WNe.forEach(t),M$o=i(x),U_=n(x,"LI",{});var UNe=s(U_);Wpe=n(UNe,"STRONG",{});var h8t=s(Wpe);E$o=r(h8t,"hubert"),h8t.forEach(t),C$o=r(UNe," \u2014 "),IV=n(UNe,"A",{href:!0});var u8t=s(IV);w$o=r(u8t,"HubertModel"),u8t.forEach(t),A$o=r(UNe," (Hubert model)"),UNe.forEach(t),L$o=i(x),H_=n(x,"LI",{});var HNe=s(H_);Upe=n(HNe,"STRONG",{});var p8t=s(Upe);y$o=r(p8t,"ibert"),p8t.forEach(t),x$o=r(HNe," \u2014 "),NV=n(HNe,"A",{href:!0});var _8t=s(NV);$$o=r(_8t,"IBertModel"),_8t.forEach(t),k$o=r(HNe," (I-BERT model)"),HNe.forEach(t),S$o=i(x),J_=n(x,"LI",{});var JNe=s(J_);Hpe=n(JNe,"STRONG",{});var b8t=s(Hpe);R$o=r(b8t,"imagegpt"),b8t.forEach(t),P$o=r(JNe," \u2014 "),qV=n(JNe,"A",{href:!0});var v8t=s(qV);B$o=r(v8t,"ImageGPTModel"),v8t.forEach(t),I$o=r(JNe," (ImageGPT model)"),JNe.forEach(t),N$o=i(x),Y_=n(x,"LI",{});var YNe=s(Y_);Jpe=n(YNe,"STRONG",{});var F8t=s(Jpe);q$o=r(F8t,"layoutlm"),F8t.forEach(t),j$o=r(YNe," \u2014 "),jV=n(YNe,"A",{href:!0});var T8t=s(jV);D$o=r(T8t,"LayoutLMModel"),T8t.forEach(t),G$o=r(YNe," (LayoutLM model)"),YNe.forEach(t),O$o=i(x),K_=n(x,"LI",{});var KNe=s(K_);Ype=n(KNe,"STRONG",{});var M8t=s(Ype);V$o=r(M8t,"layoutlmv2"),M8t.forEach(t),X$o=r(KNe," \u2014 "),DV=n(KNe,"A",{href:!0});var E8t=s(DV);z$o=r(E8t,"LayoutLMv2Model"),E8t.forEach(t),Q$o=r(KNe," (LayoutLMv2 model)"),KNe.forEach(t),W$o=i(x),Z_=n(x,"LI",{});var ZNe=s(Z_);Kpe=n(ZNe,"STRONG",{});var C8t=s(Kpe);U$o=r(C8t,"layoutlmv3"),C8t.forEach(t),H$o=r(ZNe," \u2014 "),GV=n(ZNe,"A",{href:!0});var w8t=s(GV);J$o=r(w8t,"LayoutLMv3Model"),w8t.forEach(t),Y$o=r(ZNe," (LayoutLMv3 model)"),ZNe.forEach(t),K$o=i(x),e2=n(x,"LI",{});var eqe=s(e2);Zpe=n(eqe,"STRONG",{});var A8t=s(Zpe);Z$o=r(A8t,"led"),A8t.forEach(t),eko=r(eqe," \u2014 "),OV=n(eqe,"A",{href:!0});var L8t=s(OV);oko=r(L8t,"LEDModel"),L8t.forEach(t),rko=r(eqe," (LED model)"),eqe.forEach(t),tko=i(x),o2=n(x,"LI",{});var oqe=s(o2);e_e=n(oqe,"STRONG",{});var y8t=s(e_e);ako=r(y8t,"levit"),y8t.forEach(t),nko=r(oqe," \u2014 "),VV=n(oqe,"A",{href:!0});var x8t=s(VV);sko=r(x8t,"LevitModel"),x8t.forEach(t),lko=r(oqe," (LeViT model)"),oqe.forEach(t),iko=i(x),r2=n(x,"LI",{});var rqe=s(r2);o_e=n(rqe,"STRONG",{});var $8t=s(o_e);dko=r($8t,"longformer"),$8t.forEach(t),cko=r(rqe," \u2014 "),XV=n(rqe,"A",{href:!0});var k8t=s(XV);mko=r(k8t,"LongformerModel"),k8t.forEach(t),fko=r(rqe," (Longformer model)"),rqe.forEach(t),gko=i(x),t2=n(x,"LI",{});var tqe=s(t2);r_e=n(tqe,"STRONG",{});var S8t=s(r_e);hko=r(S8t,"longt5"),S8t.forEach(t),uko=r(tqe," \u2014 "),zV=n(tqe,"A",{href:!0});var R8t=s(zV);pko=r(R8t,"LongT5Model"),R8t.forEach(t),_ko=r(tqe," (LongT5 model)"),tqe.forEach(t),bko=i(x),a2=n(x,"LI",{});var aqe=s(a2);t_e=n(aqe,"STRONG",{});var P8t=s(t_e);vko=r(P8t,"luke"),P8t.forEach(t),Fko=r(aqe," \u2014 "),QV=n(aqe,"A",{href:!0});var B8t=s(QV);Tko=r(B8t,"LukeModel"),B8t.forEach(t),Mko=r(aqe," (LUKE model)"),aqe.forEach(t),Eko=i(x),n2=n(x,"LI",{});var nqe=s(n2);a_e=n(nqe,"STRONG",{});var I8t=s(a_e);Cko=r(I8t,"lxmert"),I8t.forEach(t),wko=r(nqe," \u2014 "),WV=n(nqe,"A",{href:!0});var N8t=s(WV);Ako=r(N8t,"LxmertModel"),N8t.forEach(t),Lko=r(nqe," (LXMERT model)"),nqe.forEach(t),yko=i(x),s2=n(x,"LI",{});var sqe=s(s2);n_e=n(sqe,"STRONG",{});var q8t=s(n_e);xko=r(q8t,"m2m_100"),q8t.forEach(t),$ko=r(sqe," \u2014 "),UV=n(sqe,"A",{href:!0});var j8t=s(UV);kko=r(j8t,"M2M100Model"),j8t.forEach(t),Sko=r(sqe," (M2M100 model)"),sqe.forEach(t),Rko=i(x),l2=n(x,"LI",{});var lqe=s(l2);s_e=n(lqe,"STRONG",{});var D8t=s(s_e);Pko=r(D8t,"marian"),D8t.forEach(t),Bko=r(lqe," \u2014 "),HV=n(lqe,"A",{href:!0});var G8t=s(HV);Iko=r(G8t,"MarianModel"),G8t.forEach(t),Nko=r(lqe," (Marian model)"),lqe.forEach(t),qko=i(x),i2=n(x,"LI",{});var iqe=s(i2);l_e=n(iqe,"STRONG",{});var O8t=s(l_e);jko=r(O8t,"markuplm"),O8t.forEach(t),Dko=r(iqe," \u2014 "),JV=n(iqe,"A",{href:!0});var V8t=s(JV);Gko=r(V8t,"MarkupLMModel"),V8t.forEach(t),Oko=r(iqe," (MarkupLM model)"),iqe.forEach(t),Vko=i(x),d2=n(x,"LI",{});var dqe=s(d2);i_e=n(dqe,"STRONG",{});var X8t=s(i_e);Xko=r(X8t,"maskformer"),X8t.forEach(t),zko=r(dqe," \u2014 "),YV=n(dqe,"A",{href:!0});var z8t=s(YV);Qko=r(z8t,"MaskFormerModel"),z8t.forEach(t),Wko=r(dqe," (MaskFormer model)"),dqe.forEach(t),Uko=i(x),c2=n(x,"LI",{});var cqe=s(c2);d_e=n(cqe,"STRONG",{});var Q8t=s(d_e);Hko=r(Q8t,"mbart"),Q8t.forEach(t),Jko=r(cqe," \u2014 "),KV=n(cqe,"A",{href:!0});var W8t=s(KV);Yko=r(W8t,"MBartModel"),W8t.forEach(t),Kko=r(cqe," (mBART model)"),cqe.forEach(t),Zko=i(x),m2=n(x,"LI",{});var mqe=s(m2);c_e=n(mqe,"STRONG",{});var U8t=s(c_e);eSo=r(U8t,"mctct"),U8t.forEach(t),oSo=r(mqe," \u2014 "),ZV=n(mqe,"A",{href:!0});var H8t=s(ZV);rSo=r(H8t,"MCTCTModel"),H8t.forEach(t),tSo=r(mqe," (M-CTC-T model)"),mqe.forEach(t),aSo=i(x),f2=n(x,"LI",{});var fqe=s(f2);m_e=n(fqe,"STRONG",{});var J8t=s(m_e);nSo=r(J8t,"megatron-bert"),J8t.forEach(t),sSo=r(fqe," \u2014 "),eX=n(fqe,"A",{href:!0});var Y8t=s(eX);lSo=r(Y8t,"MegatronBertModel"),Y8t.forEach(t),iSo=r(fqe," (Megatron-BERT model)"),fqe.forEach(t),dSo=i(x),g2=n(x,"LI",{});var gqe=s(g2);f_e=n(gqe,"STRONG",{});var K8t=s(f_e);cSo=r(K8t,"mobilebert"),K8t.forEach(t),mSo=r(gqe," \u2014 "),oX=n(gqe,"A",{href:!0});var Z8t=s(oX);fSo=r(Z8t,"MobileBertModel"),Z8t.forEach(t),gSo=r(gqe," (MobileBERT model)"),gqe.forEach(t),hSo=i(x),h2=n(x,"LI",{});var hqe=s(h2);g_e=n(hqe,"STRONG",{});var e9t=s(g_e);uSo=r(e9t,"mobilevit"),e9t.forEach(t),pSo=r(hqe," \u2014 "),rX=n(hqe,"A",{href:!0});var o9t=s(rX);_So=r(o9t,"MobileViTModel"),o9t.forEach(t),bSo=r(hqe," (MobileViT model)"),hqe.forEach(t),vSo=i(x),u2=n(x,"LI",{});var uqe=s(u2);h_e=n(uqe,"STRONG",{});var r9t=s(h_e);FSo=r(r9t,"mpnet"),r9t.forEach(t),TSo=r(uqe," \u2014 "),tX=n(uqe,"A",{href:!0});var t9t=s(tX);MSo=r(t9t,"MPNetModel"),t9t.forEach(t),ESo=r(uqe," (MPNet model)"),uqe.forEach(t),CSo=i(x),p2=n(x,"LI",{});var pqe=s(p2);u_e=n(pqe,"STRONG",{});var a9t=s(u_e);wSo=r(a9t,"mt5"),a9t.forEach(t),ASo=r(pqe," \u2014 "),aX=n(pqe,"A",{href:!0});var n9t=s(aX);LSo=r(n9t,"MT5Model"),n9t.forEach(t),ySo=r(pqe," (MT5 model)"),pqe.forEach(t),xSo=i(x),_2=n(x,"LI",{});var _qe=s(_2);p_e=n(_qe,"STRONG",{});var s9t=s(p_e);$So=r(s9t,"mvp"),s9t.forEach(t),kSo=r(_qe," \u2014 "),nX=n(_qe,"A",{href:!0});var l9t=s(nX);SSo=r(l9t,"MvpModel"),l9t.forEach(t),RSo=r(_qe," (MVP model)"),_qe.forEach(t),PSo=i(x),b2=n(x,"LI",{});var bqe=s(b2);__e=n(bqe,"STRONG",{});var i9t=s(__e);BSo=r(i9t,"nezha"),i9t.forEach(t),ISo=r(bqe," \u2014 "),sX=n(bqe,"A",{href:!0});var d9t=s(sX);NSo=r(d9t,"NezhaModel"),d9t.forEach(t),qSo=r(bqe," (Nezha model)"),bqe.forEach(t),jSo=i(x),v2=n(x,"LI",{});var vqe=s(v2);b_e=n(vqe,"STRONG",{});var c9t=s(b_e);DSo=r(c9t,"nllb"),c9t.forEach(t),GSo=r(vqe," \u2014 "),lX=n(vqe,"A",{href:!0});var m9t=s(lX);OSo=r(m9t,"M2M100Model"),m9t.forEach(t),VSo=r(vqe," (NLLB model)"),vqe.forEach(t),XSo=i(x),F2=n(x,"LI",{});var Fqe=s(F2);v_e=n(Fqe,"STRONG",{});var f9t=s(v_e);zSo=r(f9t,"nystromformer"),f9t.forEach(t),QSo=r(Fqe," \u2014 "),iX=n(Fqe,"A",{href:!0});var g9t=s(iX);WSo=r(g9t,"NystromformerModel"),g9t.forEach(t),USo=r(Fqe," (Nystr\xF6mformer model)"),Fqe.forEach(t),HSo=i(x),T2=n(x,"LI",{});var Tqe=s(T2);F_e=n(Tqe,"STRONG",{});var h9t=s(F_e);JSo=r(h9t,"openai-gpt"),h9t.forEach(t),YSo=r(Tqe," \u2014 "),dX=n(Tqe,"A",{href:!0});var u9t=s(dX);KSo=r(u9t,"OpenAIGPTModel"),u9t.forEach(t),ZSo=r(Tqe," (OpenAI GPT model)"),Tqe.forEach(t),eRo=i(x),M2=n(x,"LI",{});var Mqe=s(M2);T_e=n(Mqe,"STRONG",{});var p9t=s(T_e);oRo=r(p9t,"opt"),p9t.forEach(t),rRo=r(Mqe," \u2014 "),cX=n(Mqe,"A",{href:!0});var _9t=s(cX);tRo=r(_9t,"OPTModel"),_9t.forEach(t),aRo=r(Mqe," (OPT model)"),Mqe.forEach(t),nRo=i(x),E2=n(x,"LI",{});var Eqe=s(E2);M_e=n(Eqe,"STRONG",{});var b9t=s(M_e);sRo=r(b9t,"owlvit"),b9t.forEach(t),lRo=r(Eqe," \u2014 "),mX=n(Eqe,"A",{href:!0});var v9t=s(mX);iRo=r(v9t,"OwlViTModel"),v9t.forEach(t),dRo=r(Eqe," (OWL-ViT model)"),Eqe.forEach(t),cRo=i(x),C2=n(x,"LI",{});var Cqe=s(C2);E_e=n(Cqe,"STRONG",{});var F9t=s(E_e);mRo=r(F9t,"pegasus"),F9t.forEach(t),fRo=r(Cqe," \u2014 "),fX=n(Cqe,"A",{href:!0});var T9t=s(fX);gRo=r(T9t,"PegasusModel"),T9t.forEach(t),hRo=r(Cqe," (Pegasus model)"),Cqe.forEach(t),uRo=i(x),w2=n(x,"LI",{});var wqe=s(w2);C_e=n(wqe,"STRONG",{});var M9t=s(C_e);pRo=r(M9t,"pegasus_x"),M9t.forEach(t),_Ro=r(wqe," \u2014 "),gX=n(wqe,"A",{href:!0});var E9t=s(gX);bRo=r(E9t,"PegasusXModel"),E9t.forEach(t),vRo=r(wqe," (PEGASUS-X model)"),wqe.forEach(t),FRo=i(x),A2=n(x,"LI",{});var Aqe=s(A2);w_e=n(Aqe,"STRONG",{});var C9t=s(w_e);TRo=r(C9t,"perceiver"),C9t.forEach(t),MRo=r(Aqe," \u2014 "),hX=n(Aqe,"A",{href:!0});var w9t=s(hX);ERo=r(w9t,"PerceiverModel"),w9t.forEach(t),CRo=r(Aqe," (Perceiver model)"),Aqe.forEach(t),wRo=i(x),L2=n(x,"LI",{});var Lqe=s(L2);A_e=n(Lqe,"STRONG",{});var A9t=s(A_e);ARo=r(A9t,"plbart"),A9t.forEach(t),LRo=r(Lqe," \u2014 "),uX=n(Lqe,"A",{href:!0});var L9t=s(uX);yRo=r(L9t,"PLBartModel"),L9t.forEach(t),xRo=r(Lqe," (PLBart model)"),Lqe.forEach(t),$Ro=i(x),y2=n(x,"LI",{});var yqe=s(y2);L_e=n(yqe,"STRONG",{});var y9t=s(L_e);kRo=r(y9t,"poolformer"),y9t.forEach(t),SRo=r(yqe," \u2014 "),pX=n(yqe,"A",{href:!0});var x9t=s(pX);RRo=r(x9t,"PoolFormerModel"),x9t.forEach(t),PRo=r(yqe," (PoolFormer model)"),yqe.forEach(t),BRo=i(x),x2=n(x,"LI",{});var xqe=s(x2);y_e=n(xqe,"STRONG",{});var $9t=s(y_e);IRo=r($9t,"prophetnet"),$9t.forEach(t),NRo=r(xqe," \u2014 "),_X=n(xqe,"A",{href:!0});var k9t=s(_X);qRo=r(k9t,"ProphetNetModel"),k9t.forEach(t),jRo=r(xqe," (ProphetNet model)"),xqe.forEach(t),DRo=i(x),$2=n(x,"LI",{});var $qe=s($2);x_e=n($qe,"STRONG",{});var S9t=s(x_e);GRo=r(S9t,"qdqbert"),S9t.forEach(t),ORo=r($qe," \u2014 "),bX=n($qe,"A",{href:!0});var R9t=s(bX);VRo=r(R9t,"QDQBertModel"),R9t.forEach(t),XRo=r($qe," (QDQBert model)"),$qe.forEach(t),zRo=i(x),k2=n(x,"LI",{});var kqe=s(k2);$_e=n(kqe,"STRONG",{});var P9t=s($_e);QRo=r(P9t,"reformer"),P9t.forEach(t),WRo=r(kqe," \u2014 "),vX=n(kqe,"A",{href:!0});var B9t=s(vX);URo=r(B9t,"ReformerModel"),B9t.forEach(t),HRo=r(kqe," (Reformer model)"),kqe.forEach(t),JRo=i(x),S2=n(x,"LI",{});var Sqe=s(S2);k_e=n(Sqe,"STRONG",{});var I9t=s(k_e);YRo=r(I9t,"regnet"),I9t.forEach(t),KRo=r(Sqe," \u2014 "),FX=n(Sqe,"A",{href:!0});var N9t=s(FX);ZRo=r(N9t,"RegNetModel"),N9t.forEach(t),ePo=r(Sqe," (RegNet model)"),Sqe.forEach(t),oPo=i(x),R2=n(x,"LI",{});var Rqe=s(R2);S_e=n(Rqe,"STRONG",{});var q9t=s(S_e);rPo=r(q9t,"rembert"),q9t.forEach(t),tPo=r(Rqe," \u2014 "),TX=n(Rqe,"A",{href:!0});var j9t=s(TX);aPo=r(j9t,"RemBertModel"),j9t.forEach(t),nPo=r(Rqe," (RemBERT model)"),Rqe.forEach(t),sPo=i(x),P2=n(x,"LI",{});var Pqe=s(P2);R_e=n(Pqe,"STRONG",{});var D9t=s(R_e);lPo=r(D9t,"resnet"),D9t.forEach(t),iPo=r(Pqe," \u2014 "),MX=n(Pqe,"A",{href:!0});var G9t=s(MX);dPo=r(G9t,"ResNetModel"),G9t.forEach(t),cPo=r(Pqe," (ResNet model)"),Pqe.forEach(t),mPo=i(x),B2=n(x,"LI",{});var Bqe=s(B2);P_e=n(Bqe,"STRONG",{});var O9t=s(P_e);fPo=r(O9t,"retribert"),O9t.forEach(t),gPo=r(Bqe," \u2014 "),EX=n(Bqe,"A",{href:!0});var V9t=s(EX);hPo=r(V9t,"RetriBertModel"),V9t.forEach(t),uPo=r(Bqe," (RetriBERT model)"),Bqe.forEach(t),pPo=i(x),I2=n(x,"LI",{});var Iqe=s(I2);B_e=n(Iqe,"STRONG",{});var X9t=s(B_e);_Po=r(X9t,"roberta"),X9t.forEach(t),bPo=r(Iqe," \u2014 "),CX=n(Iqe,"A",{href:!0});var z9t=s(CX);vPo=r(z9t,"RobertaModel"),z9t.forEach(t),FPo=r(Iqe," (RoBERTa model)"),Iqe.forEach(t),TPo=i(x),N2=n(x,"LI",{});var Nqe=s(N2);I_e=n(Nqe,"STRONG",{});var Q9t=s(I_e);MPo=r(Q9t,"roformer"),Q9t.forEach(t),EPo=r(Nqe," \u2014 "),wX=n(Nqe,"A",{href:!0});var W9t=s(wX);CPo=r(W9t,"RoFormerModel"),W9t.forEach(t),wPo=r(Nqe," (RoFormer model)"),Nqe.forEach(t),APo=i(x),q2=n(x,"LI",{});var qqe=s(q2);N_e=n(qqe,"STRONG",{});var U9t=s(N_e);LPo=r(U9t,"segformer"),U9t.forEach(t),yPo=r(qqe," \u2014 "),AX=n(qqe,"A",{href:!0});var H9t=s(AX);xPo=r(H9t,"SegformerModel"),H9t.forEach(t),$Po=r(qqe," (SegFormer model)"),qqe.forEach(t),kPo=i(x),j2=n(x,"LI",{});var jqe=s(j2);q_e=n(jqe,"STRONG",{});var J9t=s(q_e);SPo=r(J9t,"sew"),J9t.forEach(t),RPo=r(jqe," \u2014 "),LX=n(jqe,"A",{href:!0});var Y9t=s(LX);PPo=r(Y9t,"SEWModel"),Y9t.forEach(t),BPo=r(jqe," (SEW model)"),jqe.forEach(t),IPo=i(x),D2=n(x,"LI",{});var Dqe=s(D2);j_e=n(Dqe,"STRONG",{});var K9t=s(j_e);NPo=r(K9t,"sew-d"),K9t.forEach(t),qPo=r(Dqe," \u2014 "),yX=n(Dqe,"A",{href:!0});var Z9t=s(yX);jPo=r(Z9t,"SEWDModel"),Z9t.forEach(t),DPo=r(Dqe," (SEW-D model)"),Dqe.forEach(t),GPo=i(x),G2=n(x,"LI",{});var Gqe=s(G2);D_e=n(Gqe,"STRONG",{});var ext=s(D_e);OPo=r(ext,"speech_to_text"),ext.forEach(t),VPo=r(Gqe," \u2014 "),xX=n(Gqe,"A",{href:!0});var oxt=s(xX);XPo=r(oxt,"Speech2TextModel"),oxt.forEach(t),zPo=r(Gqe," (Speech2Text model)"),Gqe.forEach(t),QPo=i(x),O2=n(x,"LI",{});var Oqe=s(O2);G_e=n(Oqe,"STRONG",{});var rxt=s(G_e);WPo=r(rxt,"splinter"),rxt.forEach(t),UPo=r(Oqe," \u2014 "),$X=n(Oqe,"A",{href:!0});var txt=s($X);HPo=r(txt,"SplinterModel"),txt.forEach(t),JPo=r(Oqe," (Splinter model)"),Oqe.forEach(t),YPo=i(x),V2=n(x,"LI",{});var Vqe=s(V2);O_e=n(Vqe,"STRONG",{});var axt=s(O_e);KPo=r(axt,"squeezebert"),axt.forEach(t),ZPo=r(Vqe," \u2014 "),kX=n(Vqe,"A",{href:!0});var nxt=s(kX);eBo=r(nxt,"SqueezeBertModel"),nxt.forEach(t),oBo=r(Vqe," (SqueezeBERT model)"),Vqe.forEach(t),rBo=i(x),X2=n(x,"LI",{});var Xqe=s(X2);V_e=n(Xqe,"STRONG",{});var sxt=s(V_e);tBo=r(sxt,"swin"),sxt.forEach(t),aBo=r(Xqe," \u2014 "),SX=n(Xqe,"A",{href:!0});var lxt=s(SX);nBo=r(lxt,"SwinModel"),lxt.forEach(t),sBo=r(Xqe," (Swin Transformer model)"),Xqe.forEach(t),lBo=i(x),z2=n(x,"LI",{});var zqe=s(z2);X_e=n(zqe,"STRONG",{});var ixt=s(X_e);iBo=r(ixt,"swinv2"),ixt.forEach(t),dBo=r(zqe," \u2014 "),RX=n(zqe,"A",{href:!0});var dxt=s(RX);cBo=r(dxt,"Swinv2Model"),dxt.forEach(t),mBo=r(zqe," (Swin Transformer V2 model)"),zqe.forEach(t),fBo=i(x),Q2=n(x,"LI",{});var Qqe=s(Q2);z_e=n(Qqe,"STRONG",{});var cxt=s(z_e);gBo=r(cxt,"t5"),cxt.forEach(t),hBo=r(Qqe," \u2014 "),PX=n(Qqe,"A",{href:!0});var mxt=s(PX);uBo=r(mxt,"T5Model"),mxt.forEach(t),pBo=r(Qqe," (T5 model)"),Qqe.forEach(t),_Bo=i(x),W2=n(x,"LI",{});var Wqe=s(W2);Q_e=n(Wqe,"STRONG",{});var fxt=s(Q_e);bBo=r(fxt,"tapas"),fxt.forEach(t),vBo=r(Wqe," \u2014 "),BX=n(Wqe,"A",{href:!0});var gxt=s(BX);FBo=r(gxt,"TapasModel"),gxt.forEach(t),TBo=r(Wqe," (TAPAS model)"),Wqe.forEach(t),MBo=i(x),U2=n(x,"LI",{});var Uqe=s(U2);W_e=n(Uqe,"STRONG",{});var hxt=s(W_e);EBo=r(hxt,"trajectory_transformer"),hxt.forEach(t),CBo=r(Uqe," \u2014 "),IX=n(Uqe,"A",{href:!0});var uxt=s(IX);wBo=r(uxt,"TrajectoryTransformerModel"),uxt.forEach(t),ABo=r(Uqe," (Trajectory Transformer model)"),Uqe.forEach(t),LBo=i(x),H2=n(x,"LI",{});var Hqe=s(H2);U_e=n(Hqe,"STRONG",{});var pxt=s(U_e);yBo=r(pxt,"transfo-xl"),pxt.forEach(t),xBo=r(Hqe," \u2014 "),NX=n(Hqe,"A",{href:!0});var _xt=s(NX);$Bo=r(_xt,"TransfoXLModel"),_xt.forEach(t),kBo=r(Hqe," (Transformer-XL model)"),Hqe.forEach(t),SBo=i(x),J2=n(x,"LI",{});var Jqe=s(J2);H_e=n(Jqe,"STRONG",{});var bxt=s(H_e);RBo=r(bxt,"unispeech"),bxt.forEach(t),PBo=r(Jqe," \u2014 "),qX=n(Jqe,"A",{href:!0});var vxt=s(qX);BBo=r(vxt,"UniSpeechModel"),vxt.forEach(t),IBo=r(Jqe," (UniSpeech model)"),Jqe.forEach(t),NBo=i(x),Y2=n(x,"LI",{});var Yqe=s(Y2);J_e=n(Yqe,"STRONG",{});var Fxt=s(J_e);qBo=r(Fxt,"unispeech-sat"),Fxt.forEach(t),jBo=r(Yqe," \u2014 "),jX=n(Yqe,"A",{href:!0});var Txt=s(jX);DBo=r(Txt,"UniSpeechSatModel"),Txt.forEach(t),GBo=r(Yqe," (UniSpeechSat model)"),Yqe.forEach(t),OBo=i(x),K2=n(x,"LI",{});var Kqe=s(K2);Y_e=n(Kqe,"STRONG",{});var Mxt=s(Y_e);VBo=r(Mxt,"van"),Mxt.forEach(t),XBo=r(Kqe," \u2014 "),DX=n(Kqe,"A",{href:!0});var Ext=s(DX);zBo=r(Ext,"VanModel"),Ext.forEach(t),QBo=r(Kqe," (VAN model)"),Kqe.forEach(t),WBo=i(x),Z2=n(x,"LI",{});var Zqe=s(Z2);K_e=n(Zqe,"STRONG",{});var Cxt=s(K_e);UBo=r(Cxt,"videomae"),Cxt.forEach(t),HBo=r(Zqe," \u2014 "),GX=n(Zqe,"A",{href:!0});var wxt=s(GX);JBo=r(wxt,"VideoMAEModel"),wxt.forEach(t),YBo=r(Zqe," (VideoMAE model)"),Zqe.forEach(t),KBo=i(x),eb=n(x,"LI",{});var eje=s(eb);Z_e=n(eje,"STRONG",{});var Axt=s(Z_e);ZBo=r(Axt,"vilt"),Axt.forEach(t),eIo=r(eje," \u2014 "),OX=n(eje,"A",{href:!0});var Lxt=s(OX);oIo=r(Lxt,"ViltModel"),Lxt.forEach(t),rIo=r(eje," (ViLT model)"),eje.forEach(t),tIo=i(x),ob=n(x,"LI",{});var oje=s(ob);e2e=n(oje,"STRONG",{});var yxt=s(e2e);aIo=r(yxt,"vision-text-dual-encoder"),yxt.forEach(t),nIo=r(oje," \u2014 "),VX=n(oje,"A",{href:!0});var xxt=s(VX);sIo=r(xxt,"VisionTextDualEncoderModel"),xxt.forEach(t),lIo=r(oje," (VisionTextDualEncoder model)"),oje.forEach(t),iIo=i(x),rb=n(x,"LI",{});var rje=s(rb);o2e=n(rje,"STRONG",{});var $xt=s(o2e);dIo=r($xt,"visual_bert"),$xt.forEach(t),cIo=r(rje," \u2014 "),XX=n(rje,"A",{href:!0});var kxt=s(XX);mIo=r(kxt,"VisualBertModel"),kxt.forEach(t),fIo=r(rje," (VisualBERT model)"),rje.forEach(t),gIo=i(x),tb=n(x,"LI",{});var tje=s(tb);r2e=n(tje,"STRONG",{});var Sxt=s(r2e);hIo=r(Sxt,"vit"),Sxt.forEach(t),uIo=r(tje," \u2014 "),zX=n(tje,"A",{href:!0});var Rxt=s(zX);pIo=r(Rxt,"ViTModel"),Rxt.forEach(t),_Io=r(tje," (ViT model)"),tje.forEach(t),bIo=i(x),ab=n(x,"LI",{});var aje=s(ab);t2e=n(aje,"STRONG",{});var Pxt=s(t2e);vIo=r(Pxt,"vit_mae"),Pxt.forEach(t),FIo=r(aje," \u2014 "),QX=n(aje,"A",{href:!0});var Bxt=s(QX);TIo=r(Bxt,"ViTMAEModel"),Bxt.forEach(t),MIo=r(aje," (ViTMAE model)"),aje.forEach(t),EIo=i(x),nb=n(x,"LI",{});var nje=s(nb);a2e=n(nje,"STRONG",{});var Ixt=s(a2e);CIo=r(Ixt,"vit_msn"),Ixt.forEach(t),wIo=r(nje," \u2014 "),WX=n(nje,"A",{href:!0});var Nxt=s(WX);AIo=r(Nxt,"ViTMSNModel"),Nxt.forEach(t),LIo=r(nje," (ViTMSN model)"),nje.forEach(t),yIo=i(x),sb=n(x,"LI",{});var sje=s(sb);n2e=n(sje,"STRONG",{});var qxt=s(n2e);xIo=r(qxt,"wav2vec2"),qxt.forEach(t),$Io=r(sje," \u2014 "),UX=n(sje,"A",{href:!0});var jxt=s(UX);kIo=r(jxt,"Wav2Vec2Model"),jxt.forEach(t),SIo=r(sje," (Wav2Vec2 model)"),sje.forEach(t),RIo=i(x),lb=n(x,"LI",{});var lje=s(lb);s2e=n(lje,"STRONG",{});var Dxt=s(s2e);PIo=r(Dxt,"wav2vec2-conformer"),Dxt.forEach(t),BIo=r(lje," \u2014 "),HX=n(lje,"A",{href:!0});var Gxt=s(HX);IIo=r(Gxt,"Wav2Vec2ConformerModel"),Gxt.forEach(t),NIo=r(lje," (Wav2Vec2-Conformer model)"),lje.forEach(t),qIo=i(x),ib=n(x,"LI",{});var ije=s(ib);l2e=n(ije,"STRONG",{});var Oxt=s(l2e);jIo=r(Oxt,"wavlm"),Oxt.forEach(t),DIo=r(ije," \u2014 "),JX=n(ije,"A",{href:!0});var Vxt=s(JX);GIo=r(Vxt,"WavLMModel"),Vxt.forEach(t),OIo=r(ije," (WavLM model)"),ije.forEach(t),VIo=i(x),db=n(x,"LI",{});var dje=s(db);i2e=n(dje,"STRONG",{});var Xxt=s(i2e);XIo=r(Xxt,"xclip"),Xxt.forEach(t),zIo=r(dje," \u2014 "),YX=n(dje,"A",{href:!0});var zxt=s(YX);QIo=r(zxt,"XCLIPModel"),zxt.forEach(t),WIo=r(dje," (X-CLIP model)"),dje.forEach(t),UIo=i(x),cb=n(x,"LI",{});var cje=s(cb);d2e=n(cje,"STRONG",{});var Qxt=s(d2e);HIo=r(Qxt,"xglm"),Qxt.forEach(t),JIo=r(cje," \u2014 "),KX=n(cje,"A",{href:!0});var Wxt=s(KX);YIo=r(Wxt,"XGLMModel"),Wxt.forEach(t),KIo=r(cje," (XGLM model)"),cje.forEach(t),ZIo=i(x),mb=n(x,"LI",{});var mje=s(mb);c2e=n(mje,"STRONG",{});var Uxt=s(c2e);eNo=r(Uxt,"xlm"),Uxt.forEach(t),oNo=r(mje," \u2014 "),ZX=n(mje,"A",{href:!0});var Hxt=s(ZX);rNo=r(Hxt,"XLMModel"),Hxt.forEach(t),tNo=r(mje," (XLM model)"),mje.forEach(t),aNo=i(x),fb=n(x,"LI",{});var fje=s(fb);m2e=n(fje,"STRONG",{});var Jxt=s(m2e);nNo=r(Jxt,"xlm-prophetnet"),Jxt.forEach(t),sNo=r(fje," \u2014 "),ez=n(fje,"A",{href:!0});var Yxt=s(ez);lNo=r(Yxt,"XLMProphetNetModel"),Yxt.forEach(t),iNo=r(fje," (XLM-ProphetNet model)"),fje.forEach(t),dNo=i(x),gb=n(x,"LI",{});var gje=s(gb);f2e=n(gje,"STRONG",{});var Kxt=s(f2e);cNo=r(Kxt,"xlm-roberta"),Kxt.forEach(t),mNo=r(gje," \u2014 "),oz=n(gje,"A",{href:!0});var Zxt=s(oz);fNo=r(Zxt,"XLMRobertaModel"),Zxt.forEach(t),gNo=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),hNo=i(x),hb=n(x,"LI",{});var hje=s(hb);g2e=n(hje,"STRONG",{});var e$t=s(g2e);uNo=r(e$t,"xlm-roberta-xl"),e$t.forEach(t),pNo=r(hje," \u2014 "),rz=n(hje,"A",{href:!0});var o$t=s(rz);_No=r(o$t,"XLMRobertaXLModel"),o$t.forEach(t),bNo=r(hje," (XLM-RoBERTa-XL model)"),hje.forEach(t),vNo=i(x),ub=n(x,"LI",{});var uje=s(ub);h2e=n(uje,"STRONG",{});var r$t=s(h2e);FNo=r(r$t,"xlnet"),r$t.forEach(t),TNo=r(uje," \u2014 "),tz=n(uje,"A",{href:!0});var t$t=s(tz);MNo=r(t$t,"XLNetModel"),t$t.forEach(t),ENo=r(uje," (XLNet model)"),uje.forEach(t),CNo=i(x),pb=n(x,"LI",{});var pje=s(pb);u2e=n(pje,"STRONG",{});var a$t=s(u2e);wNo=r(a$t,"yolos"),a$t.forEach(t),ANo=r(pje," \u2014 "),az=n(pje,"A",{href:!0});var n$t=s(az);LNo=r(n$t,"YolosModel"),n$t.forEach(t),yNo=r(pje," (YOLOS model)"),pje.forEach(t),xNo=i(x),_b=n(x,"LI",{});var _je=s(_b);p2e=n(_je,"STRONG",{});var s$t=s(p2e);$No=r(s$t,"yoso"),s$t.forEach(t),kNo=r(_je," \u2014 "),nz=n(_je,"A",{href:!0});var l$t=s(nz);SNo=r(l$t,"YosoModel"),l$t.forEach(t),RNo=r(_je," (YOSO model)"),_je.forEach(t),x.forEach(t),PNo=i(Fa),bb=n(Fa,"P",{});var bje=s(bb);BNo=r(bje,"The model is set in evaluation mode by default using "),_2e=n(bje,"CODE",{});var i$t=s(_2e);INo=r(i$t,"model.eval()"),i$t.forEach(t),NNo=r(bje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=n(bje,"CODE",{});var d$t=s(b2e);qNo=r(d$t,"model.train()"),d$t.forEach(t),bje.forEach(t),jNo=i(Fa),T(vb.$$.fragment,Fa),Fa.forEach(t),Al.forEach(t),kZe=i(m),Fd=n(m,"H2",{class:!0});var zoo=s(Fd);Fb=n(zoo,"A",{id:!0,class:!0,href:!0});var c$t=s(Fb);v2e=n(c$t,"SPAN",{});var m$t=s(v2e);T(wx.$$.fragment,m$t),m$t.forEach(t),c$t.forEach(t),DNo=i(zoo),F2e=n(zoo,"SPAN",{});var f$t=s(F2e);GNo=r(f$t,"AutoModelForPreTraining"),f$t.forEach(t),zoo.forEach(t),SZe=i(m),Bo=n(m,"DIV",{class:!0});var Ll=s(Bo);T(Ax.$$.fragment,Ll),ONo=i(Ll),Td=n(Ll,"P",{});var Ole=s(Td);VNo=r(Ole,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),sz=n(Ole,"A",{href:!0});var g$t=s(sz);XNo=r(g$t,"from_pretrained()"),g$t.forEach(t),zNo=r(Ole," class method or the "),lz=n(Ole,"A",{href:!0});var h$t=s(lz);QNo=r(h$t,"from_config()"),h$t.forEach(t),WNo=r(Ole,` class
method.`),Ole.forEach(t),UNo=i(Ll),Lx=n(Ll,"P",{});var Qoo=s(Lx);HNo=r(Qoo,"This class cannot be instantiated directly using "),T2e=n(Qoo,"CODE",{});var u$t=s(T2e);JNo=r(u$t,"__init__()"),u$t.forEach(t),YNo=r(Qoo," (throws an error)."),Qoo.forEach(t),KNo=i(Ll),bt=n(Ll,"DIV",{class:!0});var Xy=s(bt);T(yx.$$.fragment,Xy),ZNo=i(Xy),M2e=n(Xy,"P",{});var p$t=s(M2e);eqo=r(p$t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),p$t.forEach(t),oqo=i(Xy),Md=n(Xy,"P",{});var Vle=s(Md);rqo=r(Vle,`Note:
Loading a model from its configuration file does `),E2e=n(Vle,"STRONG",{});var _$t=s(E2e);tqo=r(_$t,"not"),_$t.forEach(t),aqo=r(Vle,` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=n(Vle,"A",{href:!0});var b$t=s(iz);nqo=r(b$t,"from_pretrained()"),b$t.forEach(t),sqo=r(Vle," to load the model weights."),Vle.forEach(t),lqo=i(Xy),T(Tb.$$.fragment,Xy),Xy.forEach(t),iqo=i(Ll),eo=n(Ll,"DIV",{class:!0});var Ta=s(eo);T(xx.$$.fragment,Ta),dqo=i(Ta),C2e=n(Ta,"P",{});var v$t=s(C2e);cqo=r(v$t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),v$t.forEach(t),mqo=i(Ta),Ya=n(Ta,"P",{});var zy=s(Ya);fqo=r(zy,"The model class to instantiate is selected based on the "),w2e=n(zy,"CODE",{});var F$t=s(w2e);gqo=r(F$t,"model_type"),F$t.forEach(t),hqo=r(zy,` property of the config object (either
passed as an argument or loaded from `),A2e=n(zy,"CODE",{});var T$t=s(A2e);uqo=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),pqo=r(zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=n(zy,"CODE",{});var M$t=s(L2e);_qo=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),bqo=r(zy,":"),zy.forEach(t),vqo=i(Ta),G=n(Ta,"UL",{});var O=s(G);Mb=n(O,"LI",{});var vje=s(Mb);y2e=n(vje,"STRONG",{});var E$t=s(y2e);Fqo=r(E$t,"albert"),E$t.forEach(t),Tqo=r(vje," \u2014 "),dz=n(vje,"A",{href:!0});var C$t=s(dz);Mqo=r(C$t,"AlbertForPreTraining"),C$t.forEach(t),Eqo=r(vje," (ALBERT model)"),vje.forEach(t),Cqo=i(O),Eb=n(O,"LI",{});var Fje=s(Eb);x2e=n(Fje,"STRONG",{});var w$t=s(x2e);wqo=r(w$t,"bart"),w$t.forEach(t),Aqo=r(Fje," \u2014 "),cz=n(Fje,"A",{href:!0});var A$t=s(cz);Lqo=r(A$t,"BartForConditionalGeneration"),A$t.forEach(t),yqo=r(Fje," (BART model)"),Fje.forEach(t),xqo=i(O),Cb=n(O,"LI",{});var Tje=s(Cb);$2e=n(Tje,"STRONG",{});var L$t=s($2e);$qo=r(L$t,"bert"),L$t.forEach(t),kqo=r(Tje," \u2014 "),mz=n(Tje,"A",{href:!0});var y$t=s(mz);Sqo=r(y$t,"BertForPreTraining"),y$t.forEach(t),Rqo=r(Tje," (BERT model)"),Tje.forEach(t),Pqo=i(O),wb=n(O,"LI",{});var Mje=s(wb);k2e=n(Mje,"STRONG",{});var x$t=s(k2e);Bqo=r(x$t,"big_bird"),x$t.forEach(t),Iqo=r(Mje," \u2014 "),fz=n(Mje,"A",{href:!0});var $$t=s(fz);Nqo=r($$t,"BigBirdForPreTraining"),$$t.forEach(t),qqo=r(Mje," (BigBird model)"),Mje.forEach(t),jqo=i(O),Ab=n(O,"LI",{});var Eje=s(Ab);S2e=n(Eje,"STRONG",{});var k$t=s(S2e);Dqo=r(k$t,"bloom"),k$t.forEach(t),Gqo=r(Eje," \u2014 "),gz=n(Eje,"A",{href:!0});var S$t=s(gz);Oqo=r(S$t,"BloomForCausalLM"),S$t.forEach(t),Vqo=r(Eje," (BLOOM model)"),Eje.forEach(t),Xqo=i(O),Lb=n(O,"LI",{});var Cje=s(Lb);R2e=n(Cje,"STRONG",{});var R$t=s(R2e);zqo=r(R$t,"camembert"),R$t.forEach(t),Qqo=r(Cje," \u2014 "),hz=n(Cje,"A",{href:!0});var P$t=s(hz);Wqo=r(P$t,"CamembertForMaskedLM"),P$t.forEach(t),Uqo=r(Cje," (CamemBERT model)"),Cje.forEach(t),Hqo=i(O),yb=n(O,"LI",{});var wje=s(yb);P2e=n(wje,"STRONG",{});var B$t=s(P2e);Jqo=r(B$t,"ctrl"),B$t.forEach(t),Yqo=r(wje," \u2014 "),uz=n(wje,"A",{href:!0});var I$t=s(uz);Kqo=r(I$t,"CTRLLMHeadModel"),I$t.forEach(t),Zqo=r(wje," (CTRL model)"),wje.forEach(t),ejo=i(O),xb=n(O,"LI",{});var Aje=s(xb);B2e=n(Aje,"STRONG",{});var N$t=s(B2e);ojo=r(N$t,"data2vec-text"),N$t.forEach(t),rjo=r(Aje," \u2014 "),pz=n(Aje,"A",{href:!0});var q$t=s(pz);tjo=r(q$t,"Data2VecTextForMaskedLM"),q$t.forEach(t),ajo=r(Aje," (Data2VecText model)"),Aje.forEach(t),njo=i(O),$b=n(O,"LI",{});var Lje=s($b);I2e=n(Lje,"STRONG",{});var j$t=s(I2e);sjo=r(j$t,"deberta"),j$t.forEach(t),ljo=r(Lje," \u2014 "),_z=n(Lje,"A",{href:!0});var D$t=s(_z);ijo=r(D$t,"DebertaForMaskedLM"),D$t.forEach(t),djo=r(Lje," (DeBERTa model)"),Lje.forEach(t),cjo=i(O),kb=n(O,"LI",{});var yje=s(kb);N2e=n(yje,"STRONG",{});var G$t=s(N2e);mjo=r(G$t,"deberta-v2"),G$t.forEach(t),fjo=r(yje," \u2014 "),bz=n(yje,"A",{href:!0});var O$t=s(bz);gjo=r(O$t,"DebertaV2ForMaskedLM"),O$t.forEach(t),hjo=r(yje," (DeBERTa-v2 model)"),yje.forEach(t),ujo=i(O),Sb=n(O,"LI",{});var xje=s(Sb);q2e=n(xje,"STRONG",{});var V$t=s(q2e);pjo=r(V$t,"distilbert"),V$t.forEach(t),_jo=r(xje," \u2014 "),vz=n(xje,"A",{href:!0});var X$t=s(vz);bjo=r(X$t,"DistilBertForMaskedLM"),X$t.forEach(t),vjo=r(xje," (DistilBERT model)"),xje.forEach(t),Fjo=i(O),Rb=n(O,"LI",{});var $je=s(Rb);j2e=n($je,"STRONG",{});var z$t=s(j2e);Tjo=r(z$t,"electra"),z$t.forEach(t),Mjo=r($je," \u2014 "),Fz=n($je,"A",{href:!0});var Q$t=s(Fz);Ejo=r(Q$t,"ElectraForPreTraining"),Q$t.forEach(t),Cjo=r($je," (ELECTRA model)"),$je.forEach(t),wjo=i(O),Pb=n(O,"LI",{});var kje=s(Pb);D2e=n(kje,"STRONG",{});var W$t=s(D2e);Ajo=r(W$t,"ernie"),W$t.forEach(t),Ljo=r(kje," \u2014 "),Tz=n(kje,"A",{href:!0});var U$t=s(Tz);yjo=r(U$t,"ErnieForPreTraining"),U$t.forEach(t),xjo=r(kje," (ERNIE model)"),kje.forEach(t),$jo=i(O),Bb=n(O,"LI",{});var Sje=s(Bb);G2e=n(Sje,"STRONG",{});var H$t=s(G2e);kjo=r(H$t,"flaubert"),H$t.forEach(t),Sjo=r(Sje," \u2014 "),Mz=n(Sje,"A",{href:!0});var J$t=s(Mz);Rjo=r(J$t,"FlaubertWithLMHeadModel"),J$t.forEach(t),Pjo=r(Sje," (FlauBERT model)"),Sje.forEach(t),Bjo=i(O),Ib=n(O,"LI",{});var Rje=s(Ib);O2e=n(Rje,"STRONG",{});var Y$t=s(O2e);Ijo=r(Y$t,"flava"),Y$t.forEach(t),Njo=r(Rje," \u2014 "),Ez=n(Rje,"A",{href:!0});var K$t=s(Ez);qjo=r(K$t,"FlavaForPreTraining"),K$t.forEach(t),jjo=r(Rje," (FLAVA model)"),Rje.forEach(t),Djo=i(O),Nb=n(O,"LI",{});var Pje=s(Nb);V2e=n(Pje,"STRONG",{});var Z$t=s(V2e);Gjo=r(Z$t,"fnet"),Z$t.forEach(t),Ojo=r(Pje," \u2014 "),Cz=n(Pje,"A",{href:!0});var ekt=s(Cz);Vjo=r(ekt,"FNetForPreTraining"),ekt.forEach(t),Xjo=r(Pje," (FNet model)"),Pje.forEach(t),zjo=i(O),qb=n(O,"LI",{});var Bje=s(qb);X2e=n(Bje,"STRONG",{});var okt=s(X2e);Qjo=r(okt,"fsmt"),okt.forEach(t),Wjo=r(Bje," \u2014 "),wz=n(Bje,"A",{href:!0});var rkt=s(wz);Ujo=r(rkt,"FSMTForConditionalGeneration"),rkt.forEach(t),Hjo=r(Bje," (FairSeq Machine-Translation model)"),Bje.forEach(t),Jjo=i(O),jb=n(O,"LI",{});var Ije=s(jb);z2e=n(Ije,"STRONG",{});var tkt=s(z2e);Yjo=r(tkt,"funnel"),tkt.forEach(t),Kjo=r(Ije," \u2014 "),Az=n(Ije,"A",{href:!0});var akt=s(Az);Zjo=r(akt,"FunnelForPreTraining"),akt.forEach(t),eDo=r(Ije," (Funnel Transformer model)"),Ije.forEach(t),oDo=i(O),Db=n(O,"LI",{});var Nje=s(Db);Q2e=n(Nje,"STRONG",{});var nkt=s(Q2e);rDo=r(nkt,"gpt2"),nkt.forEach(t),tDo=r(Nje," \u2014 "),Lz=n(Nje,"A",{href:!0});var skt=s(Lz);aDo=r(skt,"GPT2LMHeadModel"),skt.forEach(t),nDo=r(Nje," (OpenAI GPT-2 model)"),Nje.forEach(t),sDo=i(O),Gb=n(O,"LI",{});var qje=s(Gb);W2e=n(qje,"STRONG",{});var lkt=s(W2e);lDo=r(lkt,"ibert"),lkt.forEach(t),iDo=r(qje," \u2014 "),yz=n(qje,"A",{href:!0});var ikt=s(yz);dDo=r(ikt,"IBertForMaskedLM"),ikt.forEach(t),cDo=r(qje," (I-BERT model)"),qje.forEach(t),mDo=i(O),Ob=n(O,"LI",{});var jje=s(Ob);U2e=n(jje,"STRONG",{});var dkt=s(U2e);fDo=r(dkt,"layoutlm"),dkt.forEach(t),gDo=r(jje," \u2014 "),xz=n(jje,"A",{href:!0});var ckt=s(xz);hDo=r(ckt,"LayoutLMForMaskedLM"),ckt.forEach(t),uDo=r(jje," (LayoutLM model)"),jje.forEach(t),pDo=i(O),Vb=n(O,"LI",{});var Dje=s(Vb);H2e=n(Dje,"STRONG",{});var mkt=s(H2e);_Do=r(mkt,"longformer"),mkt.forEach(t),bDo=r(Dje," \u2014 "),$z=n(Dje,"A",{href:!0});var fkt=s($z);vDo=r(fkt,"LongformerForMaskedLM"),fkt.forEach(t),FDo=r(Dje," (Longformer model)"),Dje.forEach(t),TDo=i(O),Xb=n(O,"LI",{});var Gje=s(Xb);J2e=n(Gje,"STRONG",{});var gkt=s(J2e);MDo=r(gkt,"luke"),gkt.forEach(t),EDo=r(Gje," \u2014 "),kz=n(Gje,"A",{href:!0});var hkt=s(kz);CDo=r(hkt,"LukeForMaskedLM"),hkt.forEach(t),wDo=r(Gje," (LUKE model)"),Gje.forEach(t),ADo=i(O),zb=n(O,"LI",{});var Oje=s(zb);Y2e=n(Oje,"STRONG",{});var ukt=s(Y2e);LDo=r(ukt,"lxmert"),ukt.forEach(t),yDo=r(Oje," \u2014 "),Sz=n(Oje,"A",{href:!0});var pkt=s(Sz);xDo=r(pkt,"LxmertForPreTraining"),pkt.forEach(t),$Do=r(Oje," (LXMERT model)"),Oje.forEach(t),kDo=i(O),Qb=n(O,"LI",{});var Vje=s(Qb);K2e=n(Vje,"STRONG",{});var _kt=s(K2e);SDo=r(_kt,"megatron-bert"),_kt.forEach(t),RDo=r(Vje," \u2014 "),Rz=n(Vje,"A",{href:!0});var bkt=s(Rz);PDo=r(bkt,"MegatronBertForPreTraining"),bkt.forEach(t),BDo=r(Vje," (Megatron-BERT model)"),Vje.forEach(t),IDo=i(O),Wb=n(O,"LI",{});var Xje=s(Wb);Z2e=n(Xje,"STRONG",{});var vkt=s(Z2e);NDo=r(vkt,"mobilebert"),vkt.forEach(t),qDo=r(Xje," \u2014 "),Pz=n(Xje,"A",{href:!0});var Fkt=s(Pz);jDo=r(Fkt,"MobileBertForPreTraining"),Fkt.forEach(t),DDo=r(Xje," (MobileBERT model)"),Xje.forEach(t),GDo=i(O),Ub=n(O,"LI",{});var zje=s(Ub);ebe=n(zje,"STRONG",{});var Tkt=s(ebe);ODo=r(Tkt,"mpnet"),Tkt.forEach(t),VDo=r(zje," \u2014 "),Bz=n(zje,"A",{href:!0});var Mkt=s(Bz);XDo=r(Mkt,"MPNetForMaskedLM"),Mkt.forEach(t),zDo=r(zje," (MPNet model)"),zje.forEach(t),QDo=i(O),Hb=n(O,"LI",{});var Qje=s(Hb);obe=n(Qje,"STRONG",{});var Ekt=s(obe);WDo=r(Ekt,"mvp"),Ekt.forEach(t),UDo=r(Qje," \u2014 "),Iz=n(Qje,"A",{href:!0});var Ckt=s(Iz);HDo=r(Ckt,"MvpForConditionalGeneration"),Ckt.forEach(t),JDo=r(Qje," (MVP model)"),Qje.forEach(t),YDo=i(O),Jb=n(O,"LI",{});var Wje=s(Jb);rbe=n(Wje,"STRONG",{});var wkt=s(rbe);KDo=r(wkt,"nezha"),wkt.forEach(t),ZDo=r(Wje," \u2014 "),Nz=n(Wje,"A",{href:!0});var Akt=s(Nz);eGo=r(Akt,"NezhaForPreTraining"),Akt.forEach(t),oGo=r(Wje," (Nezha model)"),Wje.forEach(t),rGo=i(O),Yb=n(O,"LI",{});var Uje=s(Yb);tbe=n(Uje,"STRONG",{});var Lkt=s(tbe);tGo=r(Lkt,"openai-gpt"),Lkt.forEach(t),aGo=r(Uje," \u2014 "),qz=n(Uje,"A",{href:!0});var ykt=s(qz);nGo=r(ykt,"OpenAIGPTLMHeadModel"),ykt.forEach(t),sGo=r(Uje," (OpenAI GPT model)"),Uje.forEach(t),lGo=i(O),Kb=n(O,"LI",{});var Hje=s(Kb);abe=n(Hje,"STRONG",{});var xkt=s(abe);iGo=r(xkt,"retribert"),xkt.forEach(t),dGo=r(Hje," \u2014 "),jz=n(Hje,"A",{href:!0});var $kt=s(jz);cGo=r($kt,"RetriBertModel"),$kt.forEach(t),mGo=r(Hje," (RetriBERT model)"),Hje.forEach(t),fGo=i(O),Zb=n(O,"LI",{});var Jje=s(Zb);nbe=n(Jje,"STRONG",{});var kkt=s(nbe);gGo=r(kkt,"roberta"),kkt.forEach(t),hGo=r(Jje," \u2014 "),Dz=n(Jje,"A",{href:!0});var Skt=s(Dz);uGo=r(Skt,"RobertaForMaskedLM"),Skt.forEach(t),pGo=r(Jje," (RoBERTa model)"),Jje.forEach(t),_Go=i(O),e1=n(O,"LI",{});var Yje=s(e1);sbe=n(Yje,"STRONG",{});var Rkt=s(sbe);bGo=r(Rkt,"splinter"),Rkt.forEach(t),vGo=r(Yje," \u2014 "),Gz=n(Yje,"A",{href:!0});var Pkt=s(Gz);FGo=r(Pkt,"SplinterForPreTraining"),Pkt.forEach(t),TGo=r(Yje," (Splinter model)"),Yje.forEach(t),MGo=i(O),o1=n(O,"LI",{});var Kje=s(o1);lbe=n(Kje,"STRONG",{});var Bkt=s(lbe);EGo=r(Bkt,"squeezebert"),Bkt.forEach(t),CGo=r(Kje," \u2014 "),Oz=n(Kje,"A",{href:!0});var Ikt=s(Oz);wGo=r(Ikt,"SqueezeBertForMaskedLM"),Ikt.forEach(t),AGo=r(Kje," (SqueezeBERT model)"),Kje.forEach(t),LGo=i(O),r1=n(O,"LI",{});var Zje=s(r1);ibe=n(Zje,"STRONG",{});var Nkt=s(ibe);yGo=r(Nkt,"t5"),Nkt.forEach(t),xGo=r(Zje," \u2014 "),Vz=n(Zje,"A",{href:!0});var qkt=s(Vz);$Go=r(qkt,"T5ForConditionalGeneration"),qkt.forEach(t),kGo=r(Zje," (T5 model)"),Zje.forEach(t),SGo=i(O),t1=n(O,"LI",{});var eDe=s(t1);dbe=n(eDe,"STRONG",{});var jkt=s(dbe);RGo=r(jkt,"tapas"),jkt.forEach(t),PGo=r(eDe," \u2014 "),Xz=n(eDe,"A",{href:!0});var Dkt=s(Xz);BGo=r(Dkt,"TapasForMaskedLM"),Dkt.forEach(t),IGo=r(eDe," (TAPAS model)"),eDe.forEach(t),NGo=i(O),a1=n(O,"LI",{});var oDe=s(a1);cbe=n(oDe,"STRONG",{});var Gkt=s(cbe);qGo=r(Gkt,"transfo-xl"),Gkt.forEach(t),jGo=r(oDe," \u2014 "),zz=n(oDe,"A",{href:!0});var Okt=s(zz);DGo=r(Okt,"TransfoXLLMHeadModel"),Okt.forEach(t),GGo=r(oDe," (Transformer-XL model)"),oDe.forEach(t),OGo=i(O),n1=n(O,"LI",{});var rDe=s(n1);mbe=n(rDe,"STRONG",{});var Vkt=s(mbe);VGo=r(Vkt,"unispeech"),Vkt.forEach(t),XGo=r(rDe," \u2014 "),Qz=n(rDe,"A",{href:!0});var Xkt=s(Qz);zGo=r(Xkt,"UniSpeechForPreTraining"),Xkt.forEach(t),QGo=r(rDe," (UniSpeech model)"),rDe.forEach(t),WGo=i(O),s1=n(O,"LI",{});var tDe=s(s1);fbe=n(tDe,"STRONG",{});var zkt=s(fbe);UGo=r(zkt,"unispeech-sat"),zkt.forEach(t),HGo=r(tDe," \u2014 "),Wz=n(tDe,"A",{href:!0});var Qkt=s(Wz);JGo=r(Qkt,"UniSpeechSatForPreTraining"),Qkt.forEach(t),YGo=r(tDe," (UniSpeechSat model)"),tDe.forEach(t),KGo=i(O),l1=n(O,"LI",{});var aDe=s(l1);gbe=n(aDe,"STRONG",{});var Wkt=s(gbe);ZGo=r(Wkt,"videomae"),Wkt.forEach(t),eOo=r(aDe," \u2014 "),Uz=n(aDe,"A",{href:!0});var Ukt=s(Uz);oOo=r(Ukt,"VideoMAEForPreTraining"),Ukt.forEach(t),rOo=r(aDe," (VideoMAE model)"),aDe.forEach(t),tOo=i(O),i1=n(O,"LI",{});var nDe=s(i1);hbe=n(nDe,"STRONG",{});var Hkt=s(hbe);aOo=r(Hkt,"visual_bert"),Hkt.forEach(t),nOo=r(nDe," \u2014 "),Hz=n(nDe,"A",{href:!0});var Jkt=s(Hz);sOo=r(Jkt,"VisualBertForPreTraining"),Jkt.forEach(t),lOo=r(nDe," (VisualBERT model)"),nDe.forEach(t),iOo=i(O),d1=n(O,"LI",{});var sDe=s(d1);ube=n(sDe,"STRONG",{});var Ykt=s(ube);dOo=r(Ykt,"vit_mae"),Ykt.forEach(t),cOo=r(sDe," \u2014 "),Jz=n(sDe,"A",{href:!0});var Kkt=s(Jz);mOo=r(Kkt,"ViTMAEForPreTraining"),Kkt.forEach(t),fOo=r(sDe," (ViTMAE model)"),sDe.forEach(t),gOo=i(O),c1=n(O,"LI",{});var lDe=s(c1);pbe=n(lDe,"STRONG",{});var Zkt=s(pbe);hOo=r(Zkt,"wav2vec2"),Zkt.forEach(t),uOo=r(lDe," \u2014 "),Yz=n(lDe,"A",{href:!0});var eSt=s(Yz);pOo=r(eSt,"Wav2Vec2ForPreTraining"),eSt.forEach(t),_Oo=r(lDe," (Wav2Vec2 model)"),lDe.forEach(t),bOo=i(O),m1=n(O,"LI",{});var iDe=s(m1);_be=n(iDe,"STRONG",{});var oSt=s(_be);vOo=r(oSt,"wav2vec2-conformer"),oSt.forEach(t),FOo=r(iDe," \u2014 "),Kz=n(iDe,"A",{href:!0});var rSt=s(Kz);TOo=r(rSt,"Wav2Vec2ConformerForPreTraining"),rSt.forEach(t),MOo=r(iDe," (Wav2Vec2-Conformer model)"),iDe.forEach(t),EOo=i(O),f1=n(O,"LI",{});var dDe=s(f1);bbe=n(dDe,"STRONG",{});var tSt=s(bbe);COo=r(tSt,"xlm"),tSt.forEach(t),wOo=r(dDe," \u2014 "),Zz=n(dDe,"A",{href:!0});var aSt=s(Zz);AOo=r(aSt,"XLMWithLMHeadModel"),aSt.forEach(t),LOo=r(dDe," (XLM model)"),dDe.forEach(t),yOo=i(O),g1=n(O,"LI",{});var cDe=s(g1);vbe=n(cDe,"STRONG",{});var nSt=s(vbe);xOo=r(nSt,"xlm-roberta"),nSt.forEach(t),$Oo=r(cDe," \u2014 "),eQ=n(cDe,"A",{href:!0});var sSt=s(eQ);kOo=r(sSt,"XLMRobertaForMaskedLM"),sSt.forEach(t),SOo=r(cDe," (XLM-RoBERTa model)"),cDe.forEach(t),ROo=i(O),h1=n(O,"LI",{});var mDe=s(h1);Fbe=n(mDe,"STRONG",{});var lSt=s(Fbe);POo=r(lSt,"xlm-roberta-xl"),lSt.forEach(t),BOo=r(mDe," \u2014 "),oQ=n(mDe,"A",{href:!0});var iSt=s(oQ);IOo=r(iSt,"XLMRobertaXLForMaskedLM"),iSt.forEach(t),NOo=r(mDe," (XLM-RoBERTa-XL model)"),mDe.forEach(t),qOo=i(O),u1=n(O,"LI",{});var fDe=s(u1);Tbe=n(fDe,"STRONG",{});var dSt=s(Tbe);jOo=r(dSt,"xlnet"),dSt.forEach(t),DOo=r(fDe," \u2014 "),rQ=n(fDe,"A",{href:!0});var cSt=s(rQ);GOo=r(cSt,"XLNetLMHeadModel"),cSt.forEach(t),OOo=r(fDe," (XLNet model)"),fDe.forEach(t),O.forEach(t),VOo=i(Ta),p1=n(Ta,"P",{});var gDe=s(p1);XOo=r(gDe,"The model is set in evaluation mode by default using "),Mbe=n(gDe,"CODE",{});var mSt=s(Mbe);zOo=r(mSt,"model.eval()"),mSt.forEach(t),QOo=r(gDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=n(gDe,"CODE",{});var fSt=s(Ebe);WOo=r(fSt,"model.train()"),fSt.forEach(t),gDe.forEach(t),UOo=i(Ta),T(_1.$$.fragment,Ta),Ta.forEach(t),Ll.forEach(t),RZe=i(m),Ed=n(m,"H2",{class:!0});var Woo=s(Ed);b1=n(Woo,"A",{id:!0,class:!0,href:!0});var gSt=s(b1);Cbe=n(gSt,"SPAN",{});var hSt=s(Cbe);T($x.$$.fragment,hSt),hSt.forEach(t),gSt.forEach(t),HOo=i(Woo),wbe=n(Woo,"SPAN",{});var uSt=s(wbe);JOo=r(uSt,"AutoModelForCausalLM"),uSt.forEach(t),Woo.forEach(t),PZe=i(m),Io=n(m,"DIV",{class:!0});var yl=s(Io);T(kx.$$.fragment,yl),YOo=i(yl),Cd=n(yl,"P",{});var Xle=s(Cd);KOo=r(Xle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),tQ=n(Xle,"A",{href:!0});var pSt=s(tQ);ZOo=r(pSt,"from_pretrained()"),pSt.forEach(t),eVo=r(Xle," class method or the "),aQ=n(Xle,"A",{href:!0});var _St=s(aQ);oVo=r(_St,"from_config()"),_St.forEach(t),rVo=r(Xle,` class
method.`),Xle.forEach(t),tVo=i(yl),Sx=n(yl,"P",{});var Uoo=s(Sx);aVo=r(Uoo,"This class cannot be instantiated directly using "),Abe=n(Uoo,"CODE",{});var bSt=s(Abe);nVo=r(bSt,"__init__()"),bSt.forEach(t),sVo=r(Uoo," (throws an error)."),Uoo.forEach(t),lVo=i(yl),vt=n(yl,"DIV",{class:!0});var Qy=s(vt);T(Rx.$$.fragment,Qy),iVo=i(Qy),Lbe=n(Qy,"P",{});var vSt=s(Lbe);dVo=r(vSt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vSt.forEach(t),cVo=i(Qy),wd=n(Qy,"P",{});var zle=s(wd);mVo=r(zle,`Note:
Loading a model from its configuration file does `),ybe=n(zle,"STRONG",{});var FSt=s(ybe);fVo=r(FSt,"not"),FSt.forEach(t),gVo=r(zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),nQ=n(zle,"A",{href:!0});var TSt=s(nQ);hVo=r(TSt,"from_pretrained()"),TSt.forEach(t),uVo=r(zle," to load the model weights."),zle.forEach(t),pVo=i(Qy),T(v1.$$.fragment,Qy),Qy.forEach(t),_Vo=i(yl),oo=n(yl,"DIV",{class:!0});var Ma=s(oo);T(Px.$$.fragment,Ma),bVo=i(Ma),xbe=n(Ma,"P",{});var MSt=s(xbe);vVo=r(MSt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),MSt.forEach(t),FVo=i(Ma),Ka=n(Ma,"P",{});var Wy=s(Ka);TVo=r(Wy,"The model class to instantiate is selected based on the "),$be=n(Wy,"CODE",{});var ESt=s($be);MVo=r(ESt,"model_type"),ESt.forEach(t),EVo=r(Wy,` property of the config object (either
passed as an argument or loaded from `),kbe=n(Wy,"CODE",{});var CSt=s(kbe);CVo=r(CSt,"pretrained_model_name_or_path"),CSt.forEach(t),wVo=r(Wy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=n(Wy,"CODE",{});var wSt=s(Sbe);AVo=r(wSt,"pretrained_model_name_or_path"),wSt.forEach(t),LVo=r(Wy,":"),Wy.forEach(t),yVo=i(Ma),Q=n(Ma,"UL",{});var U=s(Q);F1=n(U,"LI",{});var hDe=s(F1);Rbe=n(hDe,"STRONG",{});var ASt=s(Rbe);xVo=r(ASt,"bart"),ASt.forEach(t),$Vo=r(hDe," \u2014 "),sQ=n(hDe,"A",{href:!0});var LSt=s(sQ);kVo=r(LSt,"BartForCausalLM"),LSt.forEach(t),SVo=r(hDe," (BART model)"),hDe.forEach(t),RVo=i(U),T1=n(U,"LI",{});var uDe=s(T1);Pbe=n(uDe,"STRONG",{});var ySt=s(Pbe);PVo=r(ySt,"bert"),ySt.forEach(t),BVo=r(uDe," \u2014 "),lQ=n(uDe,"A",{href:!0});var xSt=s(lQ);IVo=r(xSt,"BertLMHeadModel"),xSt.forEach(t),NVo=r(uDe," (BERT model)"),uDe.forEach(t),qVo=i(U),M1=n(U,"LI",{});var pDe=s(M1);Bbe=n(pDe,"STRONG",{});var $St=s(Bbe);jVo=r($St,"bert-generation"),$St.forEach(t),DVo=r(pDe," \u2014 "),iQ=n(pDe,"A",{href:!0});var kSt=s(iQ);GVo=r(kSt,"BertGenerationDecoder"),kSt.forEach(t),OVo=r(pDe," (Bert Generation model)"),pDe.forEach(t),VVo=i(U),E1=n(U,"LI",{});var _De=s(E1);Ibe=n(_De,"STRONG",{});var SSt=s(Ibe);XVo=r(SSt,"big_bird"),SSt.forEach(t),zVo=r(_De," \u2014 "),dQ=n(_De,"A",{href:!0});var RSt=s(dQ);QVo=r(RSt,"BigBirdForCausalLM"),RSt.forEach(t),WVo=r(_De," (BigBird model)"),_De.forEach(t),UVo=i(U),C1=n(U,"LI",{});var bDe=s(C1);Nbe=n(bDe,"STRONG",{});var PSt=s(Nbe);HVo=r(PSt,"bigbird_pegasus"),PSt.forEach(t),JVo=r(bDe," \u2014 "),cQ=n(bDe,"A",{href:!0});var BSt=s(cQ);YVo=r(BSt,"BigBirdPegasusForCausalLM"),BSt.forEach(t),KVo=r(bDe," (BigBird-Pegasus model)"),bDe.forEach(t),ZVo=i(U),w1=n(U,"LI",{});var vDe=s(w1);qbe=n(vDe,"STRONG",{});var ISt=s(qbe);eXo=r(ISt,"blenderbot"),ISt.forEach(t),oXo=r(vDe," \u2014 "),mQ=n(vDe,"A",{href:!0});var NSt=s(mQ);rXo=r(NSt,"BlenderbotForCausalLM"),NSt.forEach(t),tXo=r(vDe," (Blenderbot model)"),vDe.forEach(t),aXo=i(U),A1=n(U,"LI",{});var FDe=s(A1);jbe=n(FDe,"STRONG",{});var qSt=s(jbe);nXo=r(qSt,"blenderbot-small"),qSt.forEach(t),sXo=r(FDe," \u2014 "),fQ=n(FDe,"A",{href:!0});var jSt=s(fQ);lXo=r(jSt,"BlenderbotSmallForCausalLM"),jSt.forEach(t),iXo=r(FDe," (BlenderbotSmall model)"),FDe.forEach(t),dXo=i(U),L1=n(U,"LI",{});var TDe=s(L1);Dbe=n(TDe,"STRONG",{});var DSt=s(Dbe);cXo=r(DSt,"bloom"),DSt.forEach(t),mXo=r(TDe," \u2014 "),gQ=n(TDe,"A",{href:!0});var GSt=s(gQ);fXo=r(GSt,"BloomForCausalLM"),GSt.forEach(t),gXo=r(TDe," (BLOOM model)"),TDe.forEach(t),hXo=i(U),y1=n(U,"LI",{});var MDe=s(y1);Gbe=n(MDe,"STRONG",{});var OSt=s(Gbe);uXo=r(OSt,"camembert"),OSt.forEach(t),pXo=r(MDe," \u2014 "),hQ=n(MDe,"A",{href:!0});var VSt=s(hQ);_Xo=r(VSt,"CamembertForCausalLM"),VSt.forEach(t),bXo=r(MDe," (CamemBERT model)"),MDe.forEach(t),vXo=i(U),x1=n(U,"LI",{});var EDe=s(x1);Obe=n(EDe,"STRONG",{});var XSt=s(Obe);FXo=r(XSt,"codegen"),XSt.forEach(t),TXo=r(EDe," \u2014 "),uQ=n(EDe,"A",{href:!0});var zSt=s(uQ);MXo=r(zSt,"CodeGenForCausalLM"),zSt.forEach(t),EXo=r(EDe," (CodeGen model)"),EDe.forEach(t),CXo=i(U),$1=n(U,"LI",{});var CDe=s($1);Vbe=n(CDe,"STRONG",{});var QSt=s(Vbe);wXo=r(QSt,"ctrl"),QSt.forEach(t),AXo=r(CDe," \u2014 "),pQ=n(CDe,"A",{href:!0});var WSt=s(pQ);LXo=r(WSt,"CTRLLMHeadModel"),WSt.forEach(t),yXo=r(CDe," (CTRL model)"),CDe.forEach(t),xXo=i(U),k1=n(U,"LI",{});var wDe=s(k1);Xbe=n(wDe,"STRONG",{});var USt=s(Xbe);$Xo=r(USt,"data2vec-text"),USt.forEach(t),kXo=r(wDe," \u2014 "),_Q=n(wDe,"A",{href:!0});var HSt=s(_Q);SXo=r(HSt,"Data2VecTextForCausalLM"),HSt.forEach(t),RXo=r(wDe," (Data2VecText model)"),wDe.forEach(t),PXo=i(U),S1=n(U,"LI",{});var ADe=s(S1);zbe=n(ADe,"STRONG",{});var JSt=s(zbe);BXo=r(JSt,"electra"),JSt.forEach(t),IXo=r(ADe," \u2014 "),bQ=n(ADe,"A",{href:!0});var YSt=s(bQ);NXo=r(YSt,"ElectraForCausalLM"),YSt.forEach(t),qXo=r(ADe," (ELECTRA model)"),ADe.forEach(t),jXo=i(U),R1=n(U,"LI",{});var LDe=s(R1);Qbe=n(LDe,"STRONG",{});var KSt=s(Qbe);DXo=r(KSt,"ernie"),KSt.forEach(t),GXo=r(LDe," \u2014 "),vQ=n(LDe,"A",{href:!0});var ZSt=s(vQ);OXo=r(ZSt,"ErnieForCausalLM"),ZSt.forEach(t),VXo=r(LDe," (ERNIE model)"),LDe.forEach(t),XXo=i(U),P1=n(U,"LI",{});var yDe=s(P1);Wbe=n(yDe,"STRONG",{});var eRt=s(Wbe);zXo=r(eRt,"gpt2"),eRt.forEach(t),QXo=r(yDe," \u2014 "),FQ=n(yDe,"A",{href:!0});var oRt=s(FQ);WXo=r(oRt,"GPT2LMHeadModel"),oRt.forEach(t),UXo=r(yDe," (OpenAI GPT-2 model)"),yDe.forEach(t),HXo=i(U),B1=n(U,"LI",{});var xDe=s(B1);Ube=n(xDe,"STRONG",{});var rRt=s(Ube);JXo=r(rRt,"gpt_neo"),rRt.forEach(t),YXo=r(xDe," \u2014 "),TQ=n(xDe,"A",{href:!0});var tRt=s(TQ);KXo=r(tRt,"GPTNeoForCausalLM"),tRt.forEach(t),ZXo=r(xDe," (GPT Neo model)"),xDe.forEach(t),ezo=i(U),I1=n(U,"LI",{});var $De=s(I1);Hbe=n($De,"STRONG",{});var aRt=s(Hbe);ozo=r(aRt,"gpt_neox"),aRt.forEach(t),rzo=r($De," \u2014 "),MQ=n($De,"A",{href:!0});var nRt=s(MQ);tzo=r(nRt,"GPTNeoXForCausalLM"),nRt.forEach(t),azo=r($De," (GPT NeoX model)"),$De.forEach(t),nzo=i(U),N1=n(U,"LI",{});var kDe=s(N1);Jbe=n(kDe,"STRONG",{});var sRt=s(Jbe);szo=r(sRt,"gpt_neox_japanese"),sRt.forEach(t),lzo=r(kDe," \u2014 "),EQ=n(kDe,"A",{href:!0});var lRt=s(EQ);izo=r(lRt,"GPTNeoXJapaneseForCausalLM"),lRt.forEach(t),dzo=r(kDe," (GPT NeoX Japanese model)"),kDe.forEach(t),czo=i(U),q1=n(U,"LI",{});var SDe=s(q1);Ybe=n(SDe,"STRONG",{});var iRt=s(Ybe);mzo=r(iRt,"gptj"),iRt.forEach(t),fzo=r(SDe," \u2014 "),CQ=n(SDe,"A",{href:!0});var dRt=s(CQ);gzo=r(dRt,"GPTJForCausalLM"),dRt.forEach(t),hzo=r(SDe," (GPT-J model)"),SDe.forEach(t),uzo=i(U),j1=n(U,"LI",{});var RDe=s(j1);Kbe=n(RDe,"STRONG",{});var cRt=s(Kbe);pzo=r(cRt,"marian"),cRt.forEach(t),_zo=r(RDe," \u2014 "),wQ=n(RDe,"A",{href:!0});var mRt=s(wQ);bzo=r(mRt,"MarianForCausalLM"),mRt.forEach(t),vzo=r(RDe," (Marian model)"),RDe.forEach(t),Fzo=i(U),D1=n(U,"LI",{});var PDe=s(D1);Zbe=n(PDe,"STRONG",{});var fRt=s(Zbe);Tzo=r(fRt,"mbart"),fRt.forEach(t),Mzo=r(PDe," \u2014 "),AQ=n(PDe,"A",{href:!0});var gRt=s(AQ);Ezo=r(gRt,"MBartForCausalLM"),gRt.forEach(t),Czo=r(PDe," (mBART model)"),PDe.forEach(t),wzo=i(U),G1=n(U,"LI",{});var BDe=s(G1);e1e=n(BDe,"STRONG",{});var hRt=s(e1e);Azo=r(hRt,"megatron-bert"),hRt.forEach(t),Lzo=r(BDe," \u2014 "),LQ=n(BDe,"A",{href:!0});var uRt=s(LQ);yzo=r(uRt,"MegatronBertForCausalLM"),uRt.forEach(t),xzo=r(BDe," (Megatron-BERT model)"),BDe.forEach(t),$zo=i(U),O1=n(U,"LI",{});var IDe=s(O1);o1e=n(IDe,"STRONG",{});var pRt=s(o1e);kzo=r(pRt,"mvp"),pRt.forEach(t),Szo=r(IDe," \u2014 "),yQ=n(IDe,"A",{href:!0});var _Rt=s(yQ);Rzo=r(_Rt,"MvpForCausalLM"),_Rt.forEach(t),Pzo=r(IDe," (MVP model)"),IDe.forEach(t),Bzo=i(U),V1=n(U,"LI",{});var NDe=s(V1);r1e=n(NDe,"STRONG",{});var bRt=s(r1e);Izo=r(bRt,"openai-gpt"),bRt.forEach(t),Nzo=r(NDe," \u2014 "),xQ=n(NDe,"A",{href:!0});var vRt=s(xQ);qzo=r(vRt,"OpenAIGPTLMHeadModel"),vRt.forEach(t),jzo=r(NDe," (OpenAI GPT model)"),NDe.forEach(t),Dzo=i(U),X1=n(U,"LI",{});var qDe=s(X1);t1e=n(qDe,"STRONG",{});var FRt=s(t1e);Gzo=r(FRt,"opt"),FRt.forEach(t),Ozo=r(qDe," \u2014 "),$Q=n(qDe,"A",{href:!0});var TRt=s($Q);Vzo=r(TRt,"OPTForCausalLM"),TRt.forEach(t),Xzo=r(qDe," (OPT model)"),qDe.forEach(t),zzo=i(U),z1=n(U,"LI",{});var jDe=s(z1);a1e=n(jDe,"STRONG",{});var MRt=s(a1e);Qzo=r(MRt,"pegasus"),MRt.forEach(t),Wzo=r(jDe," \u2014 "),kQ=n(jDe,"A",{href:!0});var ERt=s(kQ);Uzo=r(ERt,"PegasusForCausalLM"),ERt.forEach(t),Hzo=r(jDe," (Pegasus model)"),jDe.forEach(t),Jzo=i(U),Q1=n(U,"LI",{});var DDe=s(Q1);n1e=n(DDe,"STRONG",{});var CRt=s(n1e);Yzo=r(CRt,"plbart"),CRt.forEach(t),Kzo=r(DDe," \u2014 "),SQ=n(DDe,"A",{href:!0});var wRt=s(SQ);Zzo=r(wRt,"PLBartForCausalLM"),wRt.forEach(t),eQo=r(DDe," (PLBart model)"),DDe.forEach(t),oQo=i(U),W1=n(U,"LI",{});var GDe=s(W1);s1e=n(GDe,"STRONG",{});var ARt=s(s1e);rQo=r(ARt,"prophetnet"),ARt.forEach(t),tQo=r(GDe," \u2014 "),RQ=n(GDe,"A",{href:!0});var LRt=s(RQ);aQo=r(LRt,"ProphetNetForCausalLM"),LRt.forEach(t),nQo=r(GDe," (ProphetNet model)"),GDe.forEach(t),sQo=i(U),U1=n(U,"LI",{});var ODe=s(U1);l1e=n(ODe,"STRONG",{});var yRt=s(l1e);lQo=r(yRt,"qdqbert"),yRt.forEach(t),iQo=r(ODe," \u2014 "),PQ=n(ODe,"A",{href:!0});var xRt=s(PQ);dQo=r(xRt,"QDQBertLMHeadModel"),xRt.forEach(t),cQo=r(ODe," (QDQBert model)"),ODe.forEach(t),mQo=i(U),H1=n(U,"LI",{});var VDe=s(H1);i1e=n(VDe,"STRONG",{});var $Rt=s(i1e);fQo=r($Rt,"reformer"),$Rt.forEach(t),gQo=r(VDe," \u2014 "),BQ=n(VDe,"A",{href:!0});var kRt=s(BQ);hQo=r(kRt,"ReformerModelWithLMHead"),kRt.forEach(t),uQo=r(VDe," (Reformer model)"),VDe.forEach(t),pQo=i(U),J1=n(U,"LI",{});var XDe=s(J1);d1e=n(XDe,"STRONG",{});var SRt=s(d1e);_Qo=r(SRt,"rembert"),SRt.forEach(t),bQo=r(XDe," \u2014 "),IQ=n(XDe,"A",{href:!0});var RRt=s(IQ);vQo=r(RRt,"RemBertForCausalLM"),RRt.forEach(t),FQo=r(XDe," (RemBERT model)"),XDe.forEach(t),TQo=i(U),Y1=n(U,"LI",{});var zDe=s(Y1);c1e=n(zDe,"STRONG",{});var PRt=s(c1e);MQo=r(PRt,"roberta"),PRt.forEach(t),EQo=r(zDe," \u2014 "),NQ=n(zDe,"A",{href:!0});var BRt=s(NQ);CQo=r(BRt,"RobertaForCausalLM"),BRt.forEach(t),wQo=r(zDe," (RoBERTa model)"),zDe.forEach(t),AQo=i(U),K1=n(U,"LI",{});var QDe=s(K1);m1e=n(QDe,"STRONG",{});var IRt=s(m1e);LQo=r(IRt,"roformer"),IRt.forEach(t),yQo=r(QDe," \u2014 "),qQ=n(QDe,"A",{href:!0});var NRt=s(qQ);xQo=r(NRt,"RoFormerForCausalLM"),NRt.forEach(t),$Qo=r(QDe," (RoFormer model)"),QDe.forEach(t),kQo=i(U),Z1=n(U,"LI",{});var WDe=s(Z1);f1e=n(WDe,"STRONG",{});var qRt=s(f1e);SQo=r(qRt,"speech_to_text_2"),qRt.forEach(t),RQo=r(WDe," \u2014 "),jQ=n(WDe,"A",{href:!0});var jRt=s(jQ);PQo=r(jRt,"Speech2Text2ForCausalLM"),jRt.forEach(t),BQo=r(WDe," (Speech2Text2 model)"),WDe.forEach(t),IQo=i(U),ev=n(U,"LI",{});var UDe=s(ev);g1e=n(UDe,"STRONG",{});var DRt=s(g1e);NQo=r(DRt,"transfo-xl"),DRt.forEach(t),qQo=r(UDe," \u2014 "),DQ=n(UDe,"A",{href:!0});var GRt=s(DQ);jQo=r(GRt,"TransfoXLLMHeadModel"),GRt.forEach(t),DQo=r(UDe," (Transformer-XL model)"),UDe.forEach(t),GQo=i(U),ov=n(U,"LI",{});var HDe=s(ov);h1e=n(HDe,"STRONG",{});var ORt=s(h1e);OQo=r(ORt,"trocr"),ORt.forEach(t),VQo=r(HDe," \u2014 "),GQ=n(HDe,"A",{href:!0});var VRt=s(GQ);XQo=r(VRt,"TrOCRForCausalLM"),VRt.forEach(t),zQo=r(HDe," (TrOCR model)"),HDe.forEach(t),QQo=i(U),rv=n(U,"LI",{});var JDe=s(rv);u1e=n(JDe,"STRONG",{});var XRt=s(u1e);WQo=r(XRt,"xglm"),XRt.forEach(t),UQo=r(JDe," \u2014 "),OQ=n(JDe,"A",{href:!0});var zRt=s(OQ);HQo=r(zRt,"XGLMForCausalLM"),zRt.forEach(t),JQo=r(JDe," (XGLM model)"),JDe.forEach(t),YQo=i(U),tv=n(U,"LI",{});var YDe=s(tv);p1e=n(YDe,"STRONG",{});var QRt=s(p1e);KQo=r(QRt,"xlm"),QRt.forEach(t),ZQo=r(YDe," \u2014 "),VQ=n(YDe,"A",{href:!0});var WRt=s(VQ);eWo=r(WRt,"XLMWithLMHeadModel"),WRt.forEach(t),oWo=r(YDe," (XLM model)"),YDe.forEach(t),rWo=i(U),av=n(U,"LI",{});var KDe=s(av);_1e=n(KDe,"STRONG",{});var URt=s(_1e);tWo=r(URt,"xlm-prophetnet"),URt.forEach(t),aWo=r(KDe," \u2014 "),XQ=n(KDe,"A",{href:!0});var HRt=s(XQ);nWo=r(HRt,"XLMProphetNetForCausalLM"),HRt.forEach(t),sWo=r(KDe," (XLM-ProphetNet model)"),KDe.forEach(t),lWo=i(U),nv=n(U,"LI",{});var ZDe=s(nv);b1e=n(ZDe,"STRONG",{});var JRt=s(b1e);iWo=r(JRt,"xlm-roberta"),JRt.forEach(t),dWo=r(ZDe," \u2014 "),zQ=n(ZDe,"A",{href:!0});var YRt=s(zQ);cWo=r(YRt,"XLMRobertaForCausalLM"),YRt.forEach(t),mWo=r(ZDe," (XLM-RoBERTa model)"),ZDe.forEach(t),fWo=i(U),sv=n(U,"LI",{});var eGe=s(sv);v1e=n(eGe,"STRONG",{});var KRt=s(v1e);gWo=r(KRt,"xlm-roberta-xl"),KRt.forEach(t),hWo=r(eGe," \u2014 "),QQ=n(eGe,"A",{href:!0});var ZRt=s(QQ);uWo=r(ZRt,"XLMRobertaXLForCausalLM"),ZRt.forEach(t),pWo=r(eGe," (XLM-RoBERTa-XL model)"),eGe.forEach(t),_Wo=i(U),lv=n(U,"LI",{});var oGe=s(lv);F1e=n(oGe,"STRONG",{});var ePt=s(F1e);bWo=r(ePt,"xlnet"),ePt.forEach(t),vWo=r(oGe," \u2014 "),WQ=n(oGe,"A",{href:!0});var oPt=s(WQ);FWo=r(oPt,"XLNetLMHeadModel"),oPt.forEach(t),TWo=r(oGe," (XLNet model)"),oGe.forEach(t),U.forEach(t),MWo=i(Ma),iv=n(Ma,"P",{});var rGe=s(iv);EWo=r(rGe,"The model is set in evaluation mode by default using "),T1e=n(rGe,"CODE",{});var rPt=s(T1e);CWo=r(rPt,"model.eval()"),rPt.forEach(t),wWo=r(rGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M1e=n(rGe,"CODE",{});var tPt=s(M1e);AWo=r(tPt,"model.train()"),tPt.forEach(t),rGe.forEach(t),LWo=i(Ma),T(dv.$$.fragment,Ma),Ma.forEach(t),yl.forEach(t),BZe=i(m),Ad=n(m,"H2",{class:!0});var Hoo=s(Ad);cv=n(Hoo,"A",{id:!0,class:!0,href:!0});var aPt=s(cv);E1e=n(aPt,"SPAN",{});var nPt=s(E1e);T(Bx.$$.fragment,nPt),nPt.forEach(t),aPt.forEach(t),yWo=i(Hoo),C1e=n(Hoo,"SPAN",{});var sPt=s(C1e);xWo=r(sPt,"AutoModelForMaskedLM"),sPt.forEach(t),Hoo.forEach(t),IZe=i(m),No=n(m,"DIV",{class:!0});var xl=s(No);T(Ix.$$.fragment,xl),$Wo=i(xl),Ld=n(xl,"P",{});var Qle=s(Ld);kWo=r(Qle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),UQ=n(Qle,"A",{href:!0});var lPt=s(UQ);SWo=r(lPt,"from_pretrained()"),lPt.forEach(t),RWo=r(Qle," class method or the "),HQ=n(Qle,"A",{href:!0});var iPt=s(HQ);PWo=r(iPt,"from_config()"),iPt.forEach(t),BWo=r(Qle,` class
method.`),Qle.forEach(t),IWo=i(xl),Nx=n(xl,"P",{});var Joo=s(Nx);NWo=r(Joo,"This class cannot be instantiated directly using "),w1e=n(Joo,"CODE",{});var dPt=s(w1e);qWo=r(dPt,"__init__()"),dPt.forEach(t),jWo=r(Joo," (throws an error)."),Joo.forEach(t),DWo=i(xl),Ft=n(xl,"DIV",{class:!0});var Uy=s(Ft);T(qx.$$.fragment,Uy),GWo=i(Uy),A1e=n(Uy,"P",{});var cPt=s(A1e);OWo=r(cPt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),cPt.forEach(t),VWo=i(Uy),yd=n(Uy,"P",{});var Wle=s(yd);XWo=r(Wle,`Note:
Loading a model from its configuration file does `),L1e=n(Wle,"STRONG",{});var mPt=s(L1e);zWo=r(mPt,"not"),mPt.forEach(t),QWo=r(Wle,` load the model weights. It only affects the
model\u2019s configuration. Use `),JQ=n(Wle,"A",{href:!0});var fPt=s(JQ);WWo=r(fPt,"from_pretrained()"),fPt.forEach(t),UWo=r(Wle," to load the model weights."),Wle.forEach(t),HWo=i(Uy),T(mv.$$.fragment,Uy),Uy.forEach(t),JWo=i(xl),ro=n(xl,"DIV",{class:!0});var Ea=s(ro);T(jx.$$.fragment,Ea),YWo=i(Ea),y1e=n(Ea,"P",{});var gPt=s(y1e);KWo=r(gPt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),gPt.forEach(t),ZWo=i(Ea),Za=n(Ea,"P",{});var Hy=s(Za);eUo=r(Hy,"The model class to instantiate is selected based on the "),x1e=n(Hy,"CODE",{});var hPt=s(x1e);oUo=r(hPt,"model_type"),hPt.forEach(t),rUo=r(Hy,` property of the config object (either
passed as an argument or loaded from `),$1e=n(Hy,"CODE",{});var uPt=s($1e);tUo=r(uPt,"pretrained_model_name_or_path"),uPt.forEach(t),aUo=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k1e=n(Hy,"CODE",{});var pPt=s(k1e);nUo=r(pPt,"pretrained_model_name_or_path"),pPt.forEach(t),sUo=r(Hy,":"),Hy.forEach(t),lUo=i(Ea),H=n(Ea,"UL",{});var Y=s(H);fv=n(Y,"LI",{});var tGe=s(fv);S1e=n(tGe,"STRONG",{});var _Pt=s(S1e);iUo=r(_Pt,"albert"),_Pt.forEach(t),dUo=r(tGe," \u2014 "),YQ=n(tGe,"A",{href:!0});var bPt=s(YQ);cUo=r(bPt,"AlbertForMaskedLM"),bPt.forEach(t),mUo=r(tGe," (ALBERT model)"),tGe.forEach(t),fUo=i(Y),gv=n(Y,"LI",{});var aGe=s(gv);R1e=n(aGe,"STRONG",{});var vPt=s(R1e);gUo=r(vPt,"bart"),vPt.forEach(t),hUo=r(aGe," \u2014 "),KQ=n(aGe,"A",{href:!0});var FPt=s(KQ);uUo=r(FPt,"BartForConditionalGeneration"),FPt.forEach(t),pUo=r(aGe," (BART model)"),aGe.forEach(t),_Uo=i(Y),hv=n(Y,"LI",{});var nGe=s(hv);P1e=n(nGe,"STRONG",{});var TPt=s(P1e);bUo=r(TPt,"bert"),TPt.forEach(t),vUo=r(nGe," \u2014 "),ZQ=n(nGe,"A",{href:!0});var MPt=s(ZQ);FUo=r(MPt,"BertForMaskedLM"),MPt.forEach(t),TUo=r(nGe," (BERT model)"),nGe.forEach(t),MUo=i(Y),uv=n(Y,"LI",{});var sGe=s(uv);B1e=n(sGe,"STRONG",{});var EPt=s(B1e);EUo=r(EPt,"big_bird"),EPt.forEach(t),CUo=r(sGe," \u2014 "),eW=n(sGe,"A",{href:!0});var CPt=s(eW);wUo=r(CPt,"BigBirdForMaskedLM"),CPt.forEach(t),AUo=r(sGe," (BigBird model)"),sGe.forEach(t),LUo=i(Y),pv=n(Y,"LI",{});var lGe=s(pv);I1e=n(lGe,"STRONG",{});var wPt=s(I1e);yUo=r(wPt,"camembert"),wPt.forEach(t),xUo=r(lGe," \u2014 "),oW=n(lGe,"A",{href:!0});var APt=s(oW);$Uo=r(APt,"CamembertForMaskedLM"),APt.forEach(t),kUo=r(lGe," (CamemBERT model)"),lGe.forEach(t),SUo=i(Y),_v=n(Y,"LI",{});var iGe=s(_v);N1e=n(iGe,"STRONG",{});var LPt=s(N1e);RUo=r(LPt,"convbert"),LPt.forEach(t),PUo=r(iGe," \u2014 "),rW=n(iGe,"A",{href:!0});var yPt=s(rW);BUo=r(yPt,"ConvBertForMaskedLM"),yPt.forEach(t),IUo=r(iGe," (ConvBERT model)"),iGe.forEach(t),NUo=i(Y),bv=n(Y,"LI",{});var dGe=s(bv);q1e=n(dGe,"STRONG",{});var xPt=s(q1e);qUo=r(xPt,"data2vec-text"),xPt.forEach(t),jUo=r(dGe," \u2014 "),tW=n(dGe,"A",{href:!0});var $Pt=s(tW);DUo=r($Pt,"Data2VecTextForMaskedLM"),$Pt.forEach(t),GUo=r(dGe," (Data2VecText model)"),dGe.forEach(t),OUo=i(Y),vv=n(Y,"LI",{});var cGe=s(vv);j1e=n(cGe,"STRONG",{});var kPt=s(j1e);VUo=r(kPt,"deberta"),kPt.forEach(t),XUo=r(cGe," \u2014 "),aW=n(cGe,"A",{href:!0});var SPt=s(aW);zUo=r(SPt,"DebertaForMaskedLM"),SPt.forEach(t),QUo=r(cGe," (DeBERTa model)"),cGe.forEach(t),WUo=i(Y),Fv=n(Y,"LI",{});var mGe=s(Fv);D1e=n(mGe,"STRONG",{});var RPt=s(D1e);UUo=r(RPt,"deberta-v2"),RPt.forEach(t),HUo=r(mGe," \u2014 "),nW=n(mGe,"A",{href:!0});var PPt=s(nW);JUo=r(PPt,"DebertaV2ForMaskedLM"),PPt.forEach(t),YUo=r(mGe," (DeBERTa-v2 model)"),mGe.forEach(t),KUo=i(Y),Tv=n(Y,"LI",{});var fGe=s(Tv);G1e=n(fGe,"STRONG",{});var BPt=s(G1e);ZUo=r(BPt,"distilbert"),BPt.forEach(t),eHo=r(fGe," \u2014 "),sW=n(fGe,"A",{href:!0});var IPt=s(sW);oHo=r(IPt,"DistilBertForMaskedLM"),IPt.forEach(t),rHo=r(fGe," (DistilBERT model)"),fGe.forEach(t),tHo=i(Y),Mv=n(Y,"LI",{});var gGe=s(Mv);O1e=n(gGe,"STRONG",{});var NPt=s(O1e);aHo=r(NPt,"electra"),NPt.forEach(t),nHo=r(gGe," \u2014 "),lW=n(gGe,"A",{href:!0});var qPt=s(lW);sHo=r(qPt,"ElectraForMaskedLM"),qPt.forEach(t),lHo=r(gGe," (ELECTRA model)"),gGe.forEach(t),iHo=i(Y),Ev=n(Y,"LI",{});var hGe=s(Ev);V1e=n(hGe,"STRONG",{});var jPt=s(V1e);dHo=r(jPt,"ernie"),jPt.forEach(t),cHo=r(hGe," \u2014 "),iW=n(hGe,"A",{href:!0});var DPt=s(iW);mHo=r(DPt,"ErnieForMaskedLM"),DPt.forEach(t),fHo=r(hGe," (ERNIE model)"),hGe.forEach(t),gHo=i(Y),Cv=n(Y,"LI",{});var uGe=s(Cv);X1e=n(uGe,"STRONG",{});var GPt=s(X1e);hHo=r(GPt,"flaubert"),GPt.forEach(t),uHo=r(uGe," \u2014 "),dW=n(uGe,"A",{href:!0});var OPt=s(dW);pHo=r(OPt,"FlaubertWithLMHeadModel"),OPt.forEach(t),_Ho=r(uGe," (FlauBERT model)"),uGe.forEach(t),bHo=i(Y),wv=n(Y,"LI",{});var pGe=s(wv);z1e=n(pGe,"STRONG",{});var VPt=s(z1e);vHo=r(VPt,"fnet"),VPt.forEach(t),FHo=r(pGe," \u2014 "),cW=n(pGe,"A",{href:!0});var XPt=s(cW);THo=r(XPt,"FNetForMaskedLM"),XPt.forEach(t),MHo=r(pGe," (FNet model)"),pGe.forEach(t),EHo=i(Y),Av=n(Y,"LI",{});var _Ge=s(Av);Q1e=n(_Ge,"STRONG",{});var zPt=s(Q1e);CHo=r(zPt,"funnel"),zPt.forEach(t),wHo=r(_Ge," \u2014 "),mW=n(_Ge,"A",{href:!0});var QPt=s(mW);AHo=r(QPt,"FunnelForMaskedLM"),QPt.forEach(t),LHo=r(_Ge," (Funnel Transformer model)"),_Ge.forEach(t),yHo=i(Y),Lv=n(Y,"LI",{});var bGe=s(Lv);W1e=n(bGe,"STRONG",{});var WPt=s(W1e);xHo=r(WPt,"ibert"),WPt.forEach(t),$Ho=r(bGe," \u2014 "),fW=n(bGe,"A",{href:!0});var UPt=s(fW);kHo=r(UPt,"IBertForMaskedLM"),UPt.forEach(t),SHo=r(bGe," (I-BERT model)"),bGe.forEach(t),RHo=i(Y),yv=n(Y,"LI",{});var vGe=s(yv);U1e=n(vGe,"STRONG",{});var HPt=s(U1e);PHo=r(HPt,"layoutlm"),HPt.forEach(t),BHo=r(vGe," \u2014 "),gW=n(vGe,"A",{href:!0});var JPt=s(gW);IHo=r(JPt,"LayoutLMForMaskedLM"),JPt.forEach(t),NHo=r(vGe," (LayoutLM model)"),vGe.forEach(t),qHo=i(Y),xv=n(Y,"LI",{});var FGe=s(xv);H1e=n(FGe,"STRONG",{});var YPt=s(H1e);jHo=r(YPt,"longformer"),YPt.forEach(t),DHo=r(FGe," \u2014 "),hW=n(FGe,"A",{href:!0});var KPt=s(hW);GHo=r(KPt,"LongformerForMaskedLM"),KPt.forEach(t),OHo=r(FGe," (Longformer model)"),FGe.forEach(t),VHo=i(Y),$v=n(Y,"LI",{});var TGe=s($v);J1e=n(TGe,"STRONG",{});var ZPt=s(J1e);XHo=r(ZPt,"luke"),ZPt.forEach(t),zHo=r(TGe," \u2014 "),uW=n(TGe,"A",{href:!0});var eBt=s(uW);QHo=r(eBt,"LukeForMaskedLM"),eBt.forEach(t),WHo=r(TGe," (LUKE model)"),TGe.forEach(t),UHo=i(Y),kv=n(Y,"LI",{});var MGe=s(kv);Y1e=n(MGe,"STRONG",{});var oBt=s(Y1e);HHo=r(oBt,"mbart"),oBt.forEach(t),JHo=r(MGe," \u2014 "),pW=n(MGe,"A",{href:!0});var rBt=s(pW);YHo=r(rBt,"MBartForConditionalGeneration"),rBt.forEach(t),KHo=r(MGe," (mBART model)"),MGe.forEach(t),ZHo=i(Y),Sv=n(Y,"LI",{});var EGe=s(Sv);K1e=n(EGe,"STRONG",{});var tBt=s(K1e);eJo=r(tBt,"megatron-bert"),tBt.forEach(t),oJo=r(EGe," \u2014 "),_W=n(EGe,"A",{href:!0});var aBt=s(_W);rJo=r(aBt,"MegatronBertForMaskedLM"),aBt.forEach(t),tJo=r(EGe," (Megatron-BERT model)"),EGe.forEach(t),aJo=i(Y),Rv=n(Y,"LI",{});var CGe=s(Rv);Z1e=n(CGe,"STRONG",{});var nBt=s(Z1e);nJo=r(nBt,"mobilebert"),nBt.forEach(t),sJo=r(CGe," \u2014 "),bW=n(CGe,"A",{href:!0});var sBt=s(bW);lJo=r(sBt,"MobileBertForMaskedLM"),sBt.forEach(t),iJo=r(CGe," (MobileBERT model)"),CGe.forEach(t),dJo=i(Y),Pv=n(Y,"LI",{});var wGe=s(Pv);eve=n(wGe,"STRONG",{});var lBt=s(eve);cJo=r(lBt,"mpnet"),lBt.forEach(t),mJo=r(wGe," \u2014 "),vW=n(wGe,"A",{href:!0});var iBt=s(vW);fJo=r(iBt,"MPNetForMaskedLM"),iBt.forEach(t),gJo=r(wGe," (MPNet model)"),wGe.forEach(t),hJo=i(Y),Bv=n(Y,"LI",{});var AGe=s(Bv);ove=n(AGe,"STRONG",{});var dBt=s(ove);uJo=r(dBt,"mvp"),dBt.forEach(t),pJo=r(AGe," \u2014 "),FW=n(AGe,"A",{href:!0});var cBt=s(FW);_Jo=r(cBt,"MvpForConditionalGeneration"),cBt.forEach(t),bJo=r(AGe," (MVP model)"),AGe.forEach(t),vJo=i(Y),Iv=n(Y,"LI",{});var LGe=s(Iv);rve=n(LGe,"STRONG",{});var mBt=s(rve);FJo=r(mBt,"nezha"),mBt.forEach(t),TJo=r(LGe," \u2014 "),TW=n(LGe,"A",{href:!0});var fBt=s(TW);MJo=r(fBt,"NezhaForMaskedLM"),fBt.forEach(t),EJo=r(LGe," (Nezha model)"),LGe.forEach(t),CJo=i(Y),Nv=n(Y,"LI",{});var yGe=s(Nv);tve=n(yGe,"STRONG",{});var gBt=s(tve);wJo=r(gBt,"nystromformer"),gBt.forEach(t),AJo=r(yGe," \u2014 "),MW=n(yGe,"A",{href:!0});var hBt=s(MW);LJo=r(hBt,"NystromformerForMaskedLM"),hBt.forEach(t),yJo=r(yGe," (Nystr\xF6mformer model)"),yGe.forEach(t),xJo=i(Y),qv=n(Y,"LI",{});var xGe=s(qv);ave=n(xGe,"STRONG",{});var uBt=s(ave);$Jo=r(uBt,"perceiver"),uBt.forEach(t),kJo=r(xGe," \u2014 "),EW=n(xGe,"A",{href:!0});var pBt=s(EW);SJo=r(pBt,"PerceiverForMaskedLM"),pBt.forEach(t),RJo=r(xGe," (Perceiver model)"),xGe.forEach(t),PJo=i(Y),jv=n(Y,"LI",{});var $Ge=s(jv);nve=n($Ge,"STRONG",{});var _Bt=s(nve);BJo=r(_Bt,"qdqbert"),_Bt.forEach(t),IJo=r($Ge," \u2014 "),CW=n($Ge,"A",{href:!0});var bBt=s(CW);NJo=r(bBt,"QDQBertForMaskedLM"),bBt.forEach(t),qJo=r($Ge," (QDQBert model)"),$Ge.forEach(t),jJo=i(Y),Dv=n(Y,"LI",{});var kGe=s(Dv);sve=n(kGe,"STRONG",{});var vBt=s(sve);DJo=r(vBt,"reformer"),vBt.forEach(t),GJo=r(kGe," \u2014 "),wW=n(kGe,"A",{href:!0});var FBt=s(wW);OJo=r(FBt,"ReformerForMaskedLM"),FBt.forEach(t),VJo=r(kGe," (Reformer model)"),kGe.forEach(t),XJo=i(Y),Gv=n(Y,"LI",{});var SGe=s(Gv);lve=n(SGe,"STRONG",{});var TBt=s(lve);zJo=r(TBt,"rembert"),TBt.forEach(t),QJo=r(SGe," \u2014 "),AW=n(SGe,"A",{href:!0});var MBt=s(AW);WJo=r(MBt,"RemBertForMaskedLM"),MBt.forEach(t),UJo=r(SGe," (RemBERT model)"),SGe.forEach(t),HJo=i(Y),Ov=n(Y,"LI",{});var RGe=s(Ov);ive=n(RGe,"STRONG",{});var EBt=s(ive);JJo=r(EBt,"roberta"),EBt.forEach(t),YJo=r(RGe," \u2014 "),LW=n(RGe,"A",{href:!0});var CBt=s(LW);KJo=r(CBt,"RobertaForMaskedLM"),CBt.forEach(t),ZJo=r(RGe," (RoBERTa model)"),RGe.forEach(t),eYo=i(Y),Vv=n(Y,"LI",{});var PGe=s(Vv);dve=n(PGe,"STRONG",{});var wBt=s(dve);oYo=r(wBt,"roformer"),wBt.forEach(t),rYo=r(PGe," \u2014 "),yW=n(PGe,"A",{href:!0});var ABt=s(yW);tYo=r(ABt,"RoFormerForMaskedLM"),ABt.forEach(t),aYo=r(PGe," (RoFormer model)"),PGe.forEach(t),nYo=i(Y),Xv=n(Y,"LI",{});var BGe=s(Xv);cve=n(BGe,"STRONG",{});var LBt=s(cve);sYo=r(LBt,"squeezebert"),LBt.forEach(t),lYo=r(BGe," \u2014 "),xW=n(BGe,"A",{href:!0});var yBt=s(xW);iYo=r(yBt,"SqueezeBertForMaskedLM"),yBt.forEach(t),dYo=r(BGe," (SqueezeBERT model)"),BGe.forEach(t),cYo=i(Y),zv=n(Y,"LI",{});var IGe=s(zv);mve=n(IGe,"STRONG",{});var xBt=s(mve);mYo=r(xBt,"tapas"),xBt.forEach(t),fYo=r(IGe," \u2014 "),$W=n(IGe,"A",{href:!0});var $Bt=s($W);gYo=r($Bt,"TapasForMaskedLM"),$Bt.forEach(t),hYo=r(IGe," (TAPAS model)"),IGe.forEach(t),uYo=i(Y),Qv=n(Y,"LI",{});var NGe=s(Qv);fve=n(NGe,"STRONG",{});var kBt=s(fve);pYo=r(kBt,"wav2vec2"),kBt.forEach(t),_Yo=r(NGe," \u2014 "),gve=n(NGe,"CODE",{});var SBt=s(gve);bYo=r(SBt,"Wav2Vec2ForMaskedLM"),SBt.forEach(t),vYo=r(NGe," (Wav2Vec2 model)"),NGe.forEach(t),FYo=i(Y),Wv=n(Y,"LI",{});var qGe=s(Wv);hve=n(qGe,"STRONG",{});var RBt=s(hve);TYo=r(RBt,"xlm"),RBt.forEach(t),MYo=r(qGe," \u2014 "),kW=n(qGe,"A",{href:!0});var PBt=s(kW);EYo=r(PBt,"XLMWithLMHeadModel"),PBt.forEach(t),CYo=r(qGe," (XLM model)"),qGe.forEach(t),wYo=i(Y),Uv=n(Y,"LI",{});var jGe=s(Uv);uve=n(jGe,"STRONG",{});var BBt=s(uve);AYo=r(BBt,"xlm-roberta"),BBt.forEach(t),LYo=r(jGe," \u2014 "),SW=n(jGe,"A",{href:!0});var IBt=s(SW);yYo=r(IBt,"XLMRobertaForMaskedLM"),IBt.forEach(t),xYo=r(jGe," (XLM-RoBERTa model)"),jGe.forEach(t),$Yo=i(Y),Hv=n(Y,"LI",{});var DGe=s(Hv);pve=n(DGe,"STRONG",{});var NBt=s(pve);kYo=r(NBt,"xlm-roberta-xl"),NBt.forEach(t),SYo=r(DGe," \u2014 "),RW=n(DGe,"A",{href:!0});var qBt=s(RW);RYo=r(qBt,"XLMRobertaXLForMaskedLM"),qBt.forEach(t),PYo=r(DGe," (XLM-RoBERTa-XL model)"),DGe.forEach(t),BYo=i(Y),Jv=n(Y,"LI",{});var GGe=s(Jv);_ve=n(GGe,"STRONG",{});var jBt=s(_ve);IYo=r(jBt,"yoso"),jBt.forEach(t),NYo=r(GGe," \u2014 "),PW=n(GGe,"A",{href:!0});var DBt=s(PW);qYo=r(DBt,"YosoForMaskedLM"),DBt.forEach(t),jYo=r(GGe," (YOSO model)"),GGe.forEach(t),Y.forEach(t),DYo=i(Ea),Yv=n(Ea,"P",{});var OGe=s(Yv);GYo=r(OGe,"The model is set in evaluation mode by default using "),bve=n(OGe,"CODE",{});var GBt=s(bve);OYo=r(GBt,"model.eval()"),GBt.forEach(t),VYo=r(OGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vve=n(OGe,"CODE",{});var OBt=s(vve);XYo=r(OBt,"model.train()"),OBt.forEach(t),OGe.forEach(t),zYo=i(Ea),T(Kv.$$.fragment,Ea),Ea.forEach(t),xl.forEach(t),NZe=i(m),xd=n(m,"H2",{class:!0});var Yoo=s(xd);Zv=n(Yoo,"A",{id:!0,class:!0,href:!0});var VBt=s(Zv);Fve=n(VBt,"SPAN",{});var XBt=s(Fve);T(Dx.$$.fragment,XBt),XBt.forEach(t),VBt.forEach(t),QYo=i(Yoo),Tve=n(Yoo,"SPAN",{});var zBt=s(Tve);WYo=r(zBt,"AutoModelForSeq2SeqLM"),zBt.forEach(t),Yoo.forEach(t),qZe=i(m),qo=n(m,"DIV",{class:!0});var $l=s(qo);T(Gx.$$.fragment,$l),UYo=i($l),$d=n($l,"P",{});var Ule=s($d);HYo=r(Ule,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),BW=n(Ule,"A",{href:!0});var QBt=s(BW);JYo=r(QBt,"from_pretrained()"),QBt.forEach(t),YYo=r(Ule," class method or the "),IW=n(Ule,"A",{href:!0});var WBt=s(IW);KYo=r(WBt,"from_config()"),WBt.forEach(t),ZYo=r(Ule,` class
method.`),Ule.forEach(t),eKo=i($l),Ox=n($l,"P",{});var Koo=s(Ox);oKo=r(Koo,"This class cannot be instantiated directly using "),Mve=n(Koo,"CODE",{});var UBt=s(Mve);rKo=r(UBt,"__init__()"),UBt.forEach(t),tKo=r(Koo," (throws an error)."),Koo.forEach(t),aKo=i($l),Tt=n($l,"DIV",{class:!0});var Jy=s(Tt);T(Vx.$$.fragment,Jy),nKo=i(Jy),Eve=n(Jy,"P",{});var HBt=s(Eve);sKo=r(HBt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),HBt.forEach(t),lKo=i(Jy),kd=n(Jy,"P",{});var Hle=s(kd);iKo=r(Hle,`Note:
Loading a model from its configuration file does `),Cve=n(Hle,"STRONG",{});var JBt=s(Cve);dKo=r(JBt,"not"),JBt.forEach(t),cKo=r(Hle,` load the model weights. It only affects the
model\u2019s configuration. Use `),NW=n(Hle,"A",{href:!0});var YBt=s(NW);mKo=r(YBt,"from_pretrained()"),YBt.forEach(t),fKo=r(Hle," to load the model weights."),Hle.forEach(t),gKo=i(Jy),T(eF.$$.fragment,Jy),Jy.forEach(t),hKo=i($l),to=n($l,"DIV",{class:!0});var Ca=s(to);T(Xx.$$.fragment,Ca),uKo=i(Ca),wve=n(Ca,"P",{});var KBt=s(wve);pKo=r(KBt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),KBt.forEach(t),_Ko=i(Ca),en=n(Ca,"P",{});var Yy=s(en);bKo=r(Yy,"The model class to instantiate is selected based on the "),Ave=n(Yy,"CODE",{});var ZBt=s(Ave);vKo=r(ZBt,"model_type"),ZBt.forEach(t),FKo=r(Yy,` property of the config object (either
passed as an argument or loaded from `),Lve=n(Yy,"CODE",{});var eIt=s(Lve);TKo=r(eIt,"pretrained_model_name_or_path"),eIt.forEach(t),MKo=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yve=n(Yy,"CODE",{});var oIt=s(yve);EKo=r(oIt,"pretrained_model_name_or_path"),oIt.forEach(t),CKo=r(Yy,":"),Yy.forEach(t),wKo=i(Ca),fe=n(Ca,"UL",{});var pe=s(fe);oF=n(pe,"LI",{});var VGe=s(oF);xve=n(VGe,"STRONG",{});var rIt=s(xve);AKo=r(rIt,"bart"),rIt.forEach(t),LKo=r(VGe," \u2014 "),qW=n(VGe,"A",{href:!0});var tIt=s(qW);yKo=r(tIt,"BartForConditionalGeneration"),tIt.forEach(t),xKo=r(VGe," (BART model)"),VGe.forEach(t),$Ko=i(pe),rF=n(pe,"LI",{});var XGe=s(rF);$ve=n(XGe,"STRONG",{});var aIt=s($ve);kKo=r(aIt,"bigbird_pegasus"),aIt.forEach(t),SKo=r(XGe," \u2014 "),jW=n(XGe,"A",{href:!0});var nIt=s(jW);RKo=r(nIt,"BigBirdPegasusForConditionalGeneration"),nIt.forEach(t),PKo=r(XGe," (BigBird-Pegasus model)"),XGe.forEach(t),BKo=i(pe),tF=n(pe,"LI",{});var zGe=s(tF);kve=n(zGe,"STRONG",{});var sIt=s(kve);IKo=r(sIt,"blenderbot"),sIt.forEach(t),NKo=r(zGe," \u2014 "),DW=n(zGe,"A",{href:!0});var lIt=s(DW);qKo=r(lIt,"BlenderbotForConditionalGeneration"),lIt.forEach(t),jKo=r(zGe," (Blenderbot model)"),zGe.forEach(t),DKo=i(pe),aF=n(pe,"LI",{});var QGe=s(aF);Sve=n(QGe,"STRONG",{});var iIt=s(Sve);GKo=r(iIt,"blenderbot-small"),iIt.forEach(t),OKo=r(QGe," \u2014 "),GW=n(QGe,"A",{href:!0});var dIt=s(GW);VKo=r(dIt,"BlenderbotSmallForConditionalGeneration"),dIt.forEach(t),XKo=r(QGe," (BlenderbotSmall model)"),QGe.forEach(t),zKo=i(pe),nF=n(pe,"LI",{});var WGe=s(nF);Rve=n(WGe,"STRONG",{});var cIt=s(Rve);QKo=r(cIt,"encoder-decoder"),cIt.forEach(t),WKo=r(WGe," \u2014 "),OW=n(WGe,"A",{href:!0});var mIt=s(OW);UKo=r(mIt,"EncoderDecoderModel"),mIt.forEach(t),HKo=r(WGe," (Encoder decoder model)"),WGe.forEach(t),JKo=i(pe),sF=n(pe,"LI",{});var UGe=s(sF);Pve=n(UGe,"STRONG",{});var fIt=s(Pve);YKo=r(fIt,"fsmt"),fIt.forEach(t),KKo=r(UGe," \u2014 "),VW=n(UGe,"A",{href:!0});var gIt=s(VW);ZKo=r(gIt,"FSMTForConditionalGeneration"),gIt.forEach(t),eZo=r(UGe," (FairSeq Machine-Translation model)"),UGe.forEach(t),oZo=i(pe),lF=n(pe,"LI",{});var HGe=s(lF);Bve=n(HGe,"STRONG",{});var hIt=s(Bve);rZo=r(hIt,"led"),hIt.forEach(t),tZo=r(HGe," \u2014 "),XW=n(HGe,"A",{href:!0});var uIt=s(XW);aZo=r(uIt,"LEDForConditionalGeneration"),uIt.forEach(t),nZo=r(HGe," (LED model)"),HGe.forEach(t),sZo=i(pe),iF=n(pe,"LI",{});var JGe=s(iF);Ive=n(JGe,"STRONG",{});var pIt=s(Ive);lZo=r(pIt,"longt5"),pIt.forEach(t),iZo=r(JGe," \u2014 "),zW=n(JGe,"A",{href:!0});var _It=s(zW);dZo=r(_It,"LongT5ForConditionalGeneration"),_It.forEach(t),cZo=r(JGe," (LongT5 model)"),JGe.forEach(t),mZo=i(pe),dF=n(pe,"LI",{});var YGe=s(dF);Nve=n(YGe,"STRONG",{});var bIt=s(Nve);fZo=r(bIt,"m2m_100"),bIt.forEach(t),gZo=r(YGe," \u2014 "),QW=n(YGe,"A",{href:!0});var vIt=s(QW);hZo=r(vIt,"M2M100ForConditionalGeneration"),vIt.forEach(t),uZo=r(YGe," (M2M100 model)"),YGe.forEach(t),pZo=i(pe),cF=n(pe,"LI",{});var KGe=s(cF);qve=n(KGe,"STRONG",{});var FIt=s(qve);_Zo=r(FIt,"marian"),FIt.forEach(t),bZo=r(KGe," \u2014 "),WW=n(KGe,"A",{href:!0});var TIt=s(WW);vZo=r(TIt,"MarianMTModel"),TIt.forEach(t),FZo=r(KGe," (Marian model)"),KGe.forEach(t),TZo=i(pe),mF=n(pe,"LI",{});var ZGe=s(mF);jve=n(ZGe,"STRONG",{});var MIt=s(jve);MZo=r(MIt,"mbart"),MIt.forEach(t),EZo=r(ZGe," \u2014 "),UW=n(ZGe,"A",{href:!0});var EIt=s(UW);CZo=r(EIt,"MBartForConditionalGeneration"),EIt.forEach(t),wZo=r(ZGe," (mBART model)"),ZGe.forEach(t),AZo=i(pe),fF=n(pe,"LI",{});var eOe=s(fF);Dve=n(eOe,"STRONG",{});var CIt=s(Dve);LZo=r(CIt,"mt5"),CIt.forEach(t),yZo=r(eOe," \u2014 "),HW=n(eOe,"A",{href:!0});var wIt=s(HW);xZo=r(wIt,"MT5ForConditionalGeneration"),wIt.forEach(t),$Zo=r(eOe," (MT5 model)"),eOe.forEach(t),kZo=i(pe),gF=n(pe,"LI",{});var oOe=s(gF);Gve=n(oOe,"STRONG",{});var AIt=s(Gve);SZo=r(AIt,"mvp"),AIt.forEach(t),RZo=r(oOe," \u2014 "),JW=n(oOe,"A",{href:!0});var LIt=s(JW);PZo=r(LIt,"MvpForConditionalGeneration"),LIt.forEach(t),BZo=r(oOe," (MVP model)"),oOe.forEach(t),IZo=i(pe),hF=n(pe,"LI",{});var rOe=s(hF);Ove=n(rOe,"STRONG",{});var yIt=s(Ove);NZo=r(yIt,"nllb"),yIt.forEach(t),qZo=r(rOe," \u2014 "),YW=n(rOe,"A",{href:!0});var xIt=s(YW);jZo=r(xIt,"M2M100ForConditionalGeneration"),xIt.forEach(t),DZo=r(rOe," (NLLB model)"),rOe.forEach(t),GZo=i(pe),uF=n(pe,"LI",{});var tOe=s(uF);Vve=n(tOe,"STRONG",{});var $It=s(Vve);OZo=r($It,"pegasus"),$It.forEach(t),VZo=r(tOe," \u2014 "),KW=n(tOe,"A",{href:!0});var kIt=s(KW);XZo=r(kIt,"PegasusForConditionalGeneration"),kIt.forEach(t),zZo=r(tOe," (Pegasus model)"),tOe.forEach(t),QZo=i(pe),pF=n(pe,"LI",{});var aOe=s(pF);Xve=n(aOe,"STRONG",{});var SIt=s(Xve);WZo=r(SIt,"pegasus_x"),SIt.forEach(t),UZo=r(aOe," \u2014 "),ZW=n(aOe,"A",{href:!0});var RIt=s(ZW);HZo=r(RIt,"PegasusXForConditionalGeneration"),RIt.forEach(t),JZo=r(aOe," (PEGASUS-X model)"),aOe.forEach(t),YZo=i(pe),_F=n(pe,"LI",{});var nOe=s(_F);zve=n(nOe,"STRONG",{});var PIt=s(zve);KZo=r(PIt,"plbart"),PIt.forEach(t),ZZo=r(nOe," \u2014 "),eU=n(nOe,"A",{href:!0});var BIt=s(eU);eer=r(BIt,"PLBartForConditionalGeneration"),BIt.forEach(t),oer=r(nOe," (PLBart model)"),nOe.forEach(t),rer=i(pe),bF=n(pe,"LI",{});var sOe=s(bF);Qve=n(sOe,"STRONG",{});var IIt=s(Qve);ter=r(IIt,"prophetnet"),IIt.forEach(t),aer=r(sOe," \u2014 "),oU=n(sOe,"A",{href:!0});var NIt=s(oU);ner=r(NIt,"ProphetNetForConditionalGeneration"),NIt.forEach(t),ser=r(sOe," (ProphetNet model)"),sOe.forEach(t),ler=i(pe),vF=n(pe,"LI",{});var lOe=s(vF);Wve=n(lOe,"STRONG",{});var qIt=s(Wve);ier=r(qIt,"t5"),qIt.forEach(t),der=r(lOe," \u2014 "),rU=n(lOe,"A",{href:!0});var jIt=s(rU);cer=r(jIt,"T5ForConditionalGeneration"),jIt.forEach(t),mer=r(lOe," (T5 model)"),lOe.forEach(t),fer=i(pe),FF=n(pe,"LI",{});var iOe=s(FF);Uve=n(iOe,"STRONG",{});var DIt=s(Uve);ger=r(DIt,"xlm-prophetnet"),DIt.forEach(t),her=r(iOe," \u2014 "),tU=n(iOe,"A",{href:!0});var GIt=s(tU);uer=r(GIt,"XLMProphetNetForConditionalGeneration"),GIt.forEach(t),per=r(iOe," (XLM-ProphetNet model)"),iOe.forEach(t),pe.forEach(t),_er=i(Ca),TF=n(Ca,"P",{});var dOe=s(TF);ber=r(dOe,"The model is set in evaluation mode by default using "),Hve=n(dOe,"CODE",{});var OIt=s(Hve);ver=r(OIt,"model.eval()"),OIt.forEach(t),Fer=r(dOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jve=n(dOe,"CODE",{});var VIt=s(Jve);Ter=r(VIt,"model.train()"),VIt.forEach(t),dOe.forEach(t),Mer=i(Ca),T(MF.$$.fragment,Ca),Ca.forEach(t),$l.forEach(t),jZe=i(m),Sd=n(m,"H2",{class:!0});var Zoo=s(Sd);EF=n(Zoo,"A",{id:!0,class:!0,href:!0});var XIt=s(EF);Yve=n(XIt,"SPAN",{});var zIt=s(Yve);T(zx.$$.fragment,zIt),zIt.forEach(t),XIt.forEach(t),Eer=i(Zoo),Kve=n(Zoo,"SPAN",{});var QIt=s(Kve);Cer=r(QIt,"AutoModelForSequenceClassification"),QIt.forEach(t),Zoo.forEach(t),DZe=i(m),jo=n(m,"DIV",{class:!0});var kl=s(jo);T(Qx.$$.fragment,kl),wer=i(kl),Rd=n(kl,"P",{});var Jle=s(Rd);Aer=r(Jle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),aU=n(Jle,"A",{href:!0});var WIt=s(aU);Ler=r(WIt,"from_pretrained()"),WIt.forEach(t),yer=r(Jle," class method or the "),nU=n(Jle,"A",{href:!0});var UIt=s(nU);xer=r(UIt,"from_config()"),UIt.forEach(t),$er=r(Jle,` class
method.`),Jle.forEach(t),ker=i(kl),Wx=n(kl,"P",{});var ero=s(Wx);Ser=r(ero,"This class cannot be instantiated directly using "),Zve=n(ero,"CODE",{});var HIt=s(Zve);Rer=r(HIt,"__init__()"),HIt.forEach(t),Per=r(ero," (throws an error)."),ero.forEach(t),Ber=i(kl),Mt=n(kl,"DIV",{class:!0});var Ky=s(Mt);T(Ux.$$.fragment,Ky),Ier=i(Ky),eFe=n(Ky,"P",{});var JIt=s(eFe);Ner=r(JIt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),JIt.forEach(t),qer=i(Ky),Pd=n(Ky,"P",{});var Yle=s(Pd);jer=r(Yle,`Note:
Loading a model from its configuration file does `),oFe=n(Yle,"STRONG",{});var YIt=s(oFe);Der=r(YIt,"not"),YIt.forEach(t),Ger=r(Yle,` load the model weights. It only affects the
model\u2019s configuration. Use `),sU=n(Yle,"A",{href:!0});var KIt=s(sU);Oer=r(KIt,"from_pretrained()"),KIt.forEach(t),Ver=r(Yle," to load the model weights."),Yle.forEach(t),Xer=i(Ky),T(CF.$$.fragment,Ky),Ky.forEach(t),zer=i(kl),ao=n(kl,"DIV",{class:!0});var wa=s(ao);T(Hx.$$.fragment,wa),Qer=i(wa),rFe=n(wa,"P",{});var ZIt=s(rFe);Wer=r(ZIt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ZIt.forEach(t),Uer=i(wa),on=n(wa,"P",{});var Zy=s(on);Her=r(Zy,"The model class to instantiate is selected based on the "),tFe=n(Zy,"CODE",{});var eNt=s(tFe);Jer=r(eNt,"model_type"),eNt.forEach(t),Yer=r(Zy,` property of the config object (either
passed as an argument or loaded from `),aFe=n(Zy,"CODE",{});var oNt=s(aFe);Ker=r(oNt,"pretrained_model_name_or_path"),oNt.forEach(t),Zer=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nFe=n(Zy,"CODE",{});var rNt=s(nFe);eor=r(rNt,"pretrained_model_name_or_path"),rNt.forEach(t),oor=r(Zy,":"),Zy.forEach(t),ror=i(wa),q=n(wa,"UL",{});var D=s(q);wF=n(D,"LI",{});var cOe=s(wF);sFe=n(cOe,"STRONG",{});var tNt=s(sFe);tor=r(tNt,"albert"),tNt.forEach(t),aor=r(cOe," \u2014 "),lU=n(cOe,"A",{href:!0});var aNt=s(lU);nor=r(aNt,"AlbertForSequenceClassification"),aNt.forEach(t),sor=r(cOe," (ALBERT model)"),cOe.forEach(t),lor=i(D),AF=n(D,"LI",{});var mOe=s(AF);lFe=n(mOe,"STRONG",{});var nNt=s(lFe);ior=r(nNt,"bart"),nNt.forEach(t),dor=r(mOe," \u2014 "),iU=n(mOe,"A",{href:!0});var sNt=s(iU);cor=r(sNt,"BartForSequenceClassification"),sNt.forEach(t),mor=r(mOe," (BART model)"),mOe.forEach(t),gor=i(D),LF=n(D,"LI",{});var fOe=s(LF);iFe=n(fOe,"STRONG",{});var lNt=s(iFe);hor=r(lNt,"bert"),lNt.forEach(t),uor=r(fOe," \u2014 "),dU=n(fOe,"A",{href:!0});var iNt=s(dU);por=r(iNt,"BertForSequenceClassification"),iNt.forEach(t),_or=r(fOe," (BERT model)"),fOe.forEach(t),bor=i(D),yF=n(D,"LI",{});var gOe=s(yF);dFe=n(gOe,"STRONG",{});var dNt=s(dFe);vor=r(dNt,"big_bird"),dNt.forEach(t),For=r(gOe," \u2014 "),cU=n(gOe,"A",{href:!0});var cNt=s(cU);Tor=r(cNt,"BigBirdForSequenceClassification"),cNt.forEach(t),Mor=r(gOe," (BigBird model)"),gOe.forEach(t),Eor=i(D),xF=n(D,"LI",{});var hOe=s(xF);cFe=n(hOe,"STRONG",{});var mNt=s(cFe);Cor=r(mNt,"bigbird_pegasus"),mNt.forEach(t),wor=r(hOe," \u2014 "),mU=n(hOe,"A",{href:!0});var fNt=s(mU);Aor=r(fNt,"BigBirdPegasusForSequenceClassification"),fNt.forEach(t),Lor=r(hOe," (BigBird-Pegasus model)"),hOe.forEach(t),yor=i(D),$F=n(D,"LI",{});var uOe=s($F);mFe=n(uOe,"STRONG",{});var gNt=s(mFe);xor=r(gNt,"bloom"),gNt.forEach(t),$or=r(uOe," \u2014 "),fU=n(uOe,"A",{href:!0});var hNt=s(fU);kor=r(hNt,"BloomForSequenceClassification"),hNt.forEach(t),Sor=r(uOe," (BLOOM model)"),uOe.forEach(t),Ror=i(D),kF=n(D,"LI",{});var pOe=s(kF);fFe=n(pOe,"STRONG",{});var uNt=s(fFe);Por=r(uNt,"camembert"),uNt.forEach(t),Bor=r(pOe," \u2014 "),gU=n(pOe,"A",{href:!0});var pNt=s(gU);Ior=r(pNt,"CamembertForSequenceClassification"),pNt.forEach(t),Nor=r(pOe," (CamemBERT model)"),pOe.forEach(t),qor=i(D),SF=n(D,"LI",{});var _Oe=s(SF);gFe=n(_Oe,"STRONG",{});var _Nt=s(gFe);jor=r(_Nt,"canine"),_Nt.forEach(t),Dor=r(_Oe," \u2014 "),hU=n(_Oe,"A",{href:!0});var bNt=s(hU);Gor=r(bNt,"CanineForSequenceClassification"),bNt.forEach(t),Oor=r(_Oe," (CANINE model)"),_Oe.forEach(t),Vor=i(D),RF=n(D,"LI",{});var bOe=s(RF);hFe=n(bOe,"STRONG",{});var vNt=s(hFe);Xor=r(vNt,"convbert"),vNt.forEach(t),zor=r(bOe," \u2014 "),uU=n(bOe,"A",{href:!0});var FNt=s(uU);Qor=r(FNt,"ConvBertForSequenceClassification"),FNt.forEach(t),Wor=r(bOe," (ConvBERT model)"),bOe.forEach(t),Uor=i(D),PF=n(D,"LI",{});var vOe=s(PF);uFe=n(vOe,"STRONG",{});var TNt=s(uFe);Hor=r(TNt,"ctrl"),TNt.forEach(t),Jor=r(vOe," \u2014 "),pU=n(vOe,"A",{href:!0});var MNt=s(pU);Yor=r(MNt,"CTRLForSequenceClassification"),MNt.forEach(t),Kor=r(vOe," (CTRL model)"),vOe.forEach(t),Zor=i(D),BF=n(D,"LI",{});var FOe=s(BF);pFe=n(FOe,"STRONG",{});var ENt=s(pFe);err=r(ENt,"data2vec-text"),ENt.forEach(t),orr=r(FOe," \u2014 "),_U=n(FOe,"A",{href:!0});var CNt=s(_U);rrr=r(CNt,"Data2VecTextForSequenceClassification"),CNt.forEach(t),trr=r(FOe," (Data2VecText model)"),FOe.forEach(t),arr=i(D),IF=n(D,"LI",{});var TOe=s(IF);_Fe=n(TOe,"STRONG",{});var wNt=s(_Fe);nrr=r(wNt,"deberta"),wNt.forEach(t),srr=r(TOe," \u2014 "),bU=n(TOe,"A",{href:!0});var ANt=s(bU);lrr=r(ANt,"DebertaForSequenceClassification"),ANt.forEach(t),irr=r(TOe," (DeBERTa model)"),TOe.forEach(t),drr=i(D),NF=n(D,"LI",{});var MOe=s(NF);bFe=n(MOe,"STRONG",{});var LNt=s(bFe);crr=r(LNt,"deberta-v2"),LNt.forEach(t),mrr=r(MOe," \u2014 "),vU=n(MOe,"A",{href:!0});var yNt=s(vU);frr=r(yNt,"DebertaV2ForSequenceClassification"),yNt.forEach(t),grr=r(MOe," (DeBERTa-v2 model)"),MOe.forEach(t),hrr=i(D),qF=n(D,"LI",{});var EOe=s(qF);vFe=n(EOe,"STRONG",{});var xNt=s(vFe);urr=r(xNt,"distilbert"),xNt.forEach(t),prr=r(EOe," \u2014 "),FU=n(EOe,"A",{href:!0});var $Nt=s(FU);_rr=r($Nt,"DistilBertForSequenceClassification"),$Nt.forEach(t),brr=r(EOe," (DistilBERT model)"),EOe.forEach(t),vrr=i(D),jF=n(D,"LI",{});var COe=s(jF);FFe=n(COe,"STRONG",{});var kNt=s(FFe);Frr=r(kNt,"electra"),kNt.forEach(t),Trr=r(COe," \u2014 "),TU=n(COe,"A",{href:!0});var SNt=s(TU);Mrr=r(SNt,"ElectraForSequenceClassification"),SNt.forEach(t),Err=r(COe," (ELECTRA model)"),COe.forEach(t),Crr=i(D),DF=n(D,"LI",{});var wOe=s(DF);TFe=n(wOe,"STRONG",{});var RNt=s(TFe);wrr=r(RNt,"ernie"),RNt.forEach(t),Arr=r(wOe," \u2014 "),MU=n(wOe,"A",{href:!0});var PNt=s(MU);Lrr=r(PNt,"ErnieForSequenceClassification"),PNt.forEach(t),yrr=r(wOe," (ERNIE model)"),wOe.forEach(t),xrr=i(D),GF=n(D,"LI",{});var AOe=s(GF);MFe=n(AOe,"STRONG",{});var BNt=s(MFe);$rr=r(BNt,"flaubert"),BNt.forEach(t),krr=r(AOe," \u2014 "),EU=n(AOe,"A",{href:!0});var INt=s(EU);Srr=r(INt,"FlaubertForSequenceClassification"),INt.forEach(t),Rrr=r(AOe," (FlauBERT model)"),AOe.forEach(t),Prr=i(D),OF=n(D,"LI",{});var LOe=s(OF);EFe=n(LOe,"STRONG",{});var NNt=s(EFe);Brr=r(NNt,"fnet"),NNt.forEach(t),Irr=r(LOe," \u2014 "),CU=n(LOe,"A",{href:!0});var qNt=s(CU);Nrr=r(qNt,"FNetForSequenceClassification"),qNt.forEach(t),qrr=r(LOe," (FNet model)"),LOe.forEach(t),jrr=i(D),VF=n(D,"LI",{});var yOe=s(VF);CFe=n(yOe,"STRONG",{});var jNt=s(CFe);Drr=r(jNt,"funnel"),jNt.forEach(t),Grr=r(yOe," \u2014 "),wU=n(yOe,"A",{href:!0});var DNt=s(wU);Orr=r(DNt,"FunnelForSequenceClassification"),DNt.forEach(t),Vrr=r(yOe," (Funnel Transformer model)"),yOe.forEach(t),Xrr=i(D),XF=n(D,"LI",{});var xOe=s(XF);wFe=n(xOe,"STRONG",{});var GNt=s(wFe);zrr=r(GNt,"gpt2"),GNt.forEach(t),Qrr=r(xOe," \u2014 "),AU=n(xOe,"A",{href:!0});var ONt=s(AU);Wrr=r(ONt,"GPT2ForSequenceClassification"),ONt.forEach(t),Urr=r(xOe," (OpenAI GPT-2 model)"),xOe.forEach(t),Hrr=i(D),zF=n(D,"LI",{});var $Oe=s(zF);AFe=n($Oe,"STRONG",{});var VNt=s(AFe);Jrr=r(VNt,"gpt_neo"),VNt.forEach(t),Yrr=r($Oe," \u2014 "),LU=n($Oe,"A",{href:!0});var XNt=s(LU);Krr=r(XNt,"GPTNeoForSequenceClassification"),XNt.forEach(t),Zrr=r($Oe," (GPT Neo model)"),$Oe.forEach(t),etr=i(D),QF=n(D,"LI",{});var kOe=s(QF);LFe=n(kOe,"STRONG",{});var zNt=s(LFe);otr=r(zNt,"gptj"),zNt.forEach(t),rtr=r(kOe," \u2014 "),yU=n(kOe,"A",{href:!0});var QNt=s(yU);ttr=r(QNt,"GPTJForSequenceClassification"),QNt.forEach(t),atr=r(kOe," (GPT-J model)"),kOe.forEach(t),ntr=i(D),WF=n(D,"LI",{});var SOe=s(WF);yFe=n(SOe,"STRONG",{});var WNt=s(yFe);str=r(WNt,"ibert"),WNt.forEach(t),ltr=r(SOe," \u2014 "),xU=n(SOe,"A",{href:!0});var UNt=s(xU);itr=r(UNt,"IBertForSequenceClassification"),UNt.forEach(t),dtr=r(SOe," (I-BERT model)"),SOe.forEach(t),ctr=i(D),UF=n(D,"LI",{});var ROe=s(UF);xFe=n(ROe,"STRONG",{});var HNt=s(xFe);mtr=r(HNt,"layoutlm"),HNt.forEach(t),ftr=r(ROe," \u2014 "),$U=n(ROe,"A",{href:!0});var JNt=s($U);gtr=r(JNt,"LayoutLMForSequenceClassification"),JNt.forEach(t),htr=r(ROe," (LayoutLM model)"),ROe.forEach(t),utr=i(D),HF=n(D,"LI",{});var POe=s(HF);$Fe=n(POe,"STRONG",{});var YNt=s($Fe);ptr=r(YNt,"layoutlmv2"),YNt.forEach(t),_tr=r(POe," \u2014 "),kU=n(POe,"A",{href:!0});var KNt=s(kU);btr=r(KNt,"LayoutLMv2ForSequenceClassification"),KNt.forEach(t),vtr=r(POe," (LayoutLMv2 model)"),POe.forEach(t),Ftr=i(D),JF=n(D,"LI",{});var BOe=s(JF);kFe=n(BOe,"STRONG",{});var ZNt=s(kFe);Ttr=r(ZNt,"layoutlmv3"),ZNt.forEach(t),Mtr=r(BOe," \u2014 "),SU=n(BOe,"A",{href:!0});var eqt=s(SU);Etr=r(eqt,"LayoutLMv3ForSequenceClassification"),eqt.forEach(t),Ctr=r(BOe," (LayoutLMv3 model)"),BOe.forEach(t),wtr=i(D),YF=n(D,"LI",{});var IOe=s(YF);SFe=n(IOe,"STRONG",{});var oqt=s(SFe);Atr=r(oqt,"led"),oqt.forEach(t),Ltr=r(IOe," \u2014 "),RU=n(IOe,"A",{href:!0});var rqt=s(RU);ytr=r(rqt,"LEDForSequenceClassification"),rqt.forEach(t),xtr=r(IOe," (LED model)"),IOe.forEach(t),$tr=i(D),KF=n(D,"LI",{});var NOe=s(KF);RFe=n(NOe,"STRONG",{});var tqt=s(RFe);ktr=r(tqt,"longformer"),tqt.forEach(t),Str=r(NOe," \u2014 "),PU=n(NOe,"A",{href:!0});var aqt=s(PU);Rtr=r(aqt,"LongformerForSequenceClassification"),aqt.forEach(t),Ptr=r(NOe," (Longformer model)"),NOe.forEach(t),Btr=i(D),ZF=n(D,"LI",{});var qOe=s(ZF);PFe=n(qOe,"STRONG",{});var nqt=s(PFe);Itr=r(nqt,"luke"),nqt.forEach(t),Ntr=r(qOe," \u2014 "),BU=n(qOe,"A",{href:!0});var sqt=s(BU);qtr=r(sqt,"LukeForSequenceClassification"),sqt.forEach(t),jtr=r(qOe," (LUKE model)"),qOe.forEach(t),Dtr=i(D),eT=n(D,"LI",{});var jOe=s(eT);BFe=n(jOe,"STRONG",{});var lqt=s(BFe);Gtr=r(lqt,"markuplm"),lqt.forEach(t),Otr=r(jOe," \u2014 "),IU=n(jOe,"A",{href:!0});var iqt=s(IU);Vtr=r(iqt,"MarkupLMForSequenceClassification"),iqt.forEach(t),Xtr=r(jOe," (MarkupLM model)"),jOe.forEach(t),ztr=i(D),oT=n(D,"LI",{});var DOe=s(oT);IFe=n(DOe,"STRONG",{});var dqt=s(IFe);Qtr=r(dqt,"mbart"),dqt.forEach(t),Wtr=r(DOe," \u2014 "),NU=n(DOe,"A",{href:!0});var cqt=s(NU);Utr=r(cqt,"MBartForSequenceClassification"),cqt.forEach(t),Htr=r(DOe," (mBART model)"),DOe.forEach(t),Jtr=i(D),rT=n(D,"LI",{});var GOe=s(rT);NFe=n(GOe,"STRONG",{});var mqt=s(NFe);Ytr=r(mqt,"megatron-bert"),mqt.forEach(t),Ktr=r(GOe," \u2014 "),qU=n(GOe,"A",{href:!0});var fqt=s(qU);Ztr=r(fqt,"MegatronBertForSequenceClassification"),fqt.forEach(t),ear=r(GOe," (Megatron-BERT model)"),GOe.forEach(t),oar=i(D),tT=n(D,"LI",{});var OOe=s(tT);qFe=n(OOe,"STRONG",{});var gqt=s(qFe);rar=r(gqt,"mobilebert"),gqt.forEach(t),tar=r(OOe," \u2014 "),jU=n(OOe,"A",{href:!0});var hqt=s(jU);aar=r(hqt,"MobileBertForSequenceClassification"),hqt.forEach(t),nar=r(OOe," (MobileBERT model)"),OOe.forEach(t),sar=i(D),aT=n(D,"LI",{});var VOe=s(aT);jFe=n(VOe,"STRONG",{});var uqt=s(jFe);lar=r(uqt,"mpnet"),uqt.forEach(t),iar=r(VOe," \u2014 "),DU=n(VOe,"A",{href:!0});var pqt=s(DU);dar=r(pqt,"MPNetForSequenceClassification"),pqt.forEach(t),car=r(VOe," (MPNet model)"),VOe.forEach(t),mar=i(D),nT=n(D,"LI",{});var XOe=s(nT);DFe=n(XOe,"STRONG",{});var _qt=s(DFe);far=r(_qt,"mvp"),_qt.forEach(t),gar=r(XOe," \u2014 "),GU=n(XOe,"A",{href:!0});var bqt=s(GU);har=r(bqt,"MvpForSequenceClassification"),bqt.forEach(t),uar=r(XOe," (MVP model)"),XOe.forEach(t),par=i(D),sT=n(D,"LI",{});var zOe=s(sT);GFe=n(zOe,"STRONG",{});var vqt=s(GFe);_ar=r(vqt,"nezha"),vqt.forEach(t),bar=r(zOe," \u2014 "),OU=n(zOe,"A",{href:!0});var Fqt=s(OU);Far=r(Fqt,"NezhaForSequenceClassification"),Fqt.forEach(t),Tar=r(zOe," (Nezha model)"),zOe.forEach(t),Mar=i(D),lT=n(D,"LI",{});var QOe=s(lT);OFe=n(QOe,"STRONG",{});var Tqt=s(OFe);Ear=r(Tqt,"nystromformer"),Tqt.forEach(t),Car=r(QOe," \u2014 "),VU=n(QOe,"A",{href:!0});var Mqt=s(VU);war=r(Mqt,"NystromformerForSequenceClassification"),Mqt.forEach(t),Aar=r(QOe," (Nystr\xF6mformer model)"),QOe.forEach(t),Lar=i(D),iT=n(D,"LI",{});var WOe=s(iT);VFe=n(WOe,"STRONG",{});var Eqt=s(VFe);yar=r(Eqt,"openai-gpt"),Eqt.forEach(t),xar=r(WOe," \u2014 "),XU=n(WOe,"A",{href:!0});var Cqt=s(XU);$ar=r(Cqt,"OpenAIGPTForSequenceClassification"),Cqt.forEach(t),kar=r(WOe," (OpenAI GPT model)"),WOe.forEach(t),Sar=i(D),dT=n(D,"LI",{});var UOe=s(dT);XFe=n(UOe,"STRONG",{});var wqt=s(XFe);Rar=r(wqt,"opt"),wqt.forEach(t),Par=r(UOe," \u2014 "),zU=n(UOe,"A",{href:!0});var Aqt=s(zU);Bar=r(Aqt,"OPTForSequenceClassification"),Aqt.forEach(t),Iar=r(UOe," (OPT model)"),UOe.forEach(t),Nar=i(D),cT=n(D,"LI",{});var HOe=s(cT);zFe=n(HOe,"STRONG",{});var Lqt=s(zFe);qar=r(Lqt,"perceiver"),Lqt.forEach(t),jar=r(HOe," \u2014 "),QU=n(HOe,"A",{href:!0});var yqt=s(QU);Dar=r(yqt,"PerceiverForSequenceClassification"),yqt.forEach(t),Gar=r(HOe," (Perceiver model)"),HOe.forEach(t),Oar=i(D),mT=n(D,"LI",{});var JOe=s(mT);QFe=n(JOe,"STRONG",{});var xqt=s(QFe);Var=r(xqt,"plbart"),xqt.forEach(t),Xar=r(JOe," \u2014 "),WU=n(JOe,"A",{href:!0});var $qt=s(WU);zar=r($qt,"PLBartForSequenceClassification"),$qt.forEach(t),Qar=r(JOe," (PLBart model)"),JOe.forEach(t),War=i(D),fT=n(D,"LI",{});var YOe=s(fT);WFe=n(YOe,"STRONG",{});var kqt=s(WFe);Uar=r(kqt,"qdqbert"),kqt.forEach(t),Har=r(YOe," \u2014 "),UU=n(YOe,"A",{href:!0});var Sqt=s(UU);Jar=r(Sqt,"QDQBertForSequenceClassification"),Sqt.forEach(t),Yar=r(YOe," (QDQBert model)"),YOe.forEach(t),Kar=i(D),gT=n(D,"LI",{});var KOe=s(gT);UFe=n(KOe,"STRONG",{});var Rqt=s(UFe);Zar=r(Rqt,"reformer"),Rqt.forEach(t),enr=r(KOe," \u2014 "),HU=n(KOe,"A",{href:!0});var Pqt=s(HU);onr=r(Pqt,"ReformerForSequenceClassification"),Pqt.forEach(t),rnr=r(KOe," (Reformer model)"),KOe.forEach(t),tnr=i(D),hT=n(D,"LI",{});var ZOe=s(hT);HFe=n(ZOe,"STRONG",{});var Bqt=s(HFe);anr=r(Bqt,"rembert"),Bqt.forEach(t),nnr=r(ZOe," \u2014 "),JU=n(ZOe,"A",{href:!0});var Iqt=s(JU);snr=r(Iqt,"RemBertForSequenceClassification"),Iqt.forEach(t),lnr=r(ZOe," (RemBERT model)"),ZOe.forEach(t),inr=i(D),uT=n(D,"LI",{});var eVe=s(uT);JFe=n(eVe,"STRONG",{});var Nqt=s(JFe);dnr=r(Nqt,"roberta"),Nqt.forEach(t),cnr=r(eVe," \u2014 "),YU=n(eVe,"A",{href:!0});var qqt=s(YU);mnr=r(qqt,"RobertaForSequenceClassification"),qqt.forEach(t),fnr=r(eVe," (RoBERTa model)"),eVe.forEach(t),gnr=i(D),pT=n(D,"LI",{});var oVe=s(pT);YFe=n(oVe,"STRONG",{});var jqt=s(YFe);hnr=r(jqt,"roformer"),jqt.forEach(t),unr=r(oVe," \u2014 "),KU=n(oVe,"A",{href:!0});var Dqt=s(KU);pnr=r(Dqt,"RoFormerForSequenceClassification"),Dqt.forEach(t),_nr=r(oVe," (RoFormer model)"),oVe.forEach(t),bnr=i(D),_T=n(D,"LI",{});var rVe=s(_T);KFe=n(rVe,"STRONG",{});var Gqt=s(KFe);vnr=r(Gqt,"squeezebert"),Gqt.forEach(t),Fnr=r(rVe," \u2014 "),ZU=n(rVe,"A",{href:!0});var Oqt=s(ZU);Tnr=r(Oqt,"SqueezeBertForSequenceClassification"),Oqt.forEach(t),Mnr=r(rVe," (SqueezeBERT model)"),rVe.forEach(t),Enr=i(D),bT=n(D,"LI",{});var tVe=s(bT);ZFe=n(tVe,"STRONG",{});var Vqt=s(ZFe);Cnr=r(Vqt,"tapas"),Vqt.forEach(t),wnr=r(tVe," \u2014 "),eH=n(tVe,"A",{href:!0});var Xqt=s(eH);Anr=r(Xqt,"TapasForSequenceClassification"),Xqt.forEach(t),Lnr=r(tVe," (TAPAS model)"),tVe.forEach(t),ynr=i(D),vT=n(D,"LI",{});var aVe=s(vT);eTe=n(aVe,"STRONG",{});var zqt=s(eTe);xnr=r(zqt,"transfo-xl"),zqt.forEach(t),$nr=r(aVe," \u2014 "),oH=n(aVe,"A",{href:!0});var Qqt=s(oH);knr=r(Qqt,"TransfoXLForSequenceClassification"),Qqt.forEach(t),Snr=r(aVe," (Transformer-XL model)"),aVe.forEach(t),Rnr=i(D),FT=n(D,"LI",{});var nVe=s(FT);oTe=n(nVe,"STRONG",{});var Wqt=s(oTe);Pnr=r(Wqt,"xlm"),Wqt.forEach(t),Bnr=r(nVe," \u2014 "),rH=n(nVe,"A",{href:!0});var Uqt=s(rH);Inr=r(Uqt,"XLMForSequenceClassification"),Uqt.forEach(t),Nnr=r(nVe," (XLM model)"),nVe.forEach(t),qnr=i(D),TT=n(D,"LI",{});var sVe=s(TT);rTe=n(sVe,"STRONG",{});var Hqt=s(rTe);jnr=r(Hqt,"xlm-roberta"),Hqt.forEach(t),Dnr=r(sVe," \u2014 "),tH=n(sVe,"A",{href:!0});var Jqt=s(tH);Gnr=r(Jqt,"XLMRobertaForSequenceClassification"),Jqt.forEach(t),Onr=r(sVe," (XLM-RoBERTa model)"),sVe.forEach(t),Vnr=i(D),MT=n(D,"LI",{});var lVe=s(MT);tTe=n(lVe,"STRONG",{});var Yqt=s(tTe);Xnr=r(Yqt,"xlm-roberta-xl"),Yqt.forEach(t),znr=r(lVe," \u2014 "),aH=n(lVe,"A",{href:!0});var Kqt=s(aH);Qnr=r(Kqt,"XLMRobertaXLForSequenceClassification"),Kqt.forEach(t),Wnr=r(lVe," (XLM-RoBERTa-XL model)"),lVe.forEach(t),Unr=i(D),ET=n(D,"LI",{});var iVe=s(ET);aTe=n(iVe,"STRONG",{});var Zqt=s(aTe);Hnr=r(Zqt,"xlnet"),Zqt.forEach(t),Jnr=r(iVe," \u2014 "),nH=n(iVe,"A",{href:!0});var ejt=s(nH);Ynr=r(ejt,"XLNetForSequenceClassification"),ejt.forEach(t),Knr=r(iVe," (XLNet model)"),iVe.forEach(t),Znr=i(D),CT=n(D,"LI",{});var dVe=s(CT);nTe=n(dVe,"STRONG",{});var ojt=s(nTe);esr=r(ojt,"yoso"),ojt.forEach(t),osr=r(dVe," \u2014 "),sH=n(dVe,"A",{href:!0});var rjt=s(sH);rsr=r(rjt,"YosoForSequenceClassification"),rjt.forEach(t),tsr=r(dVe," (YOSO model)"),dVe.forEach(t),D.forEach(t),asr=i(wa),wT=n(wa,"P",{});var cVe=s(wT);nsr=r(cVe,"The model is set in evaluation mode by default using "),sTe=n(cVe,"CODE",{});var tjt=s(sTe);ssr=r(tjt,"model.eval()"),tjt.forEach(t),lsr=r(cVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lTe=n(cVe,"CODE",{});var ajt=s(lTe);isr=r(ajt,"model.train()"),ajt.forEach(t),cVe.forEach(t),dsr=i(wa),T(AT.$$.fragment,wa),wa.forEach(t),kl.forEach(t),GZe=i(m),Bd=n(m,"H2",{class:!0});var oro=s(Bd);LT=n(oro,"A",{id:!0,class:!0,href:!0});var njt=s(LT);iTe=n(njt,"SPAN",{});var sjt=s(iTe);T(Jx.$$.fragment,sjt),sjt.forEach(t),njt.forEach(t),csr=i(oro),dTe=n(oro,"SPAN",{});var ljt=s(dTe);msr=r(ljt,"AutoModelForMultipleChoice"),ljt.forEach(t),oro.forEach(t),OZe=i(m),Do=n(m,"DIV",{class:!0});var Sl=s(Do);T(Yx.$$.fragment,Sl),fsr=i(Sl),Id=n(Sl,"P",{});var Kle=s(Id);gsr=r(Kle,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lH=n(Kle,"A",{href:!0});var ijt=s(lH);hsr=r(ijt,"from_pretrained()"),ijt.forEach(t),usr=r(Kle," class method or the "),iH=n(Kle,"A",{href:!0});var djt=s(iH);psr=r(djt,"from_config()"),djt.forEach(t),_sr=r(Kle,` class
method.`),Kle.forEach(t),bsr=i(Sl),Kx=n(Sl,"P",{});var rro=s(Kx);vsr=r(rro,"This class cannot be instantiated directly using "),cTe=n(rro,"CODE",{});var cjt=s(cTe);Fsr=r(cjt,"__init__()"),cjt.forEach(t),Tsr=r(rro," (throws an error)."),rro.forEach(t),Msr=i(Sl),Et=n(Sl,"DIV",{class:!0});var e8=s(Et);T(Zx.$$.fragment,e8),Esr=i(e8),mTe=n(e8,"P",{});var mjt=s(mTe);Csr=r(mjt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),mjt.forEach(t),wsr=i(e8),Nd=n(e8,"P",{});var Zle=s(Nd);Asr=r(Zle,`Note:
Loading a model from its configuration file does `),fTe=n(Zle,"STRONG",{});var fjt=s(fTe);Lsr=r(fjt,"not"),fjt.forEach(t),ysr=r(Zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),dH=n(Zle,"A",{href:!0});var gjt=s(dH);xsr=r(gjt,"from_pretrained()"),gjt.forEach(t),$sr=r(Zle," to load the model weights."),Zle.forEach(t),ksr=i(e8),T(yT.$$.fragment,e8),e8.forEach(t),Ssr=i(Sl),no=n(Sl,"DIV",{class:!0});var Aa=s(no);T(e$.$$.fragment,Aa),Rsr=i(Aa),gTe=n(Aa,"P",{});var hjt=s(gTe);Psr=r(hjt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),hjt.forEach(t),Bsr=i(Aa),rn=n(Aa,"P",{});var o8=s(rn);Isr=r(o8,"The model class to instantiate is selected based on the "),hTe=n(o8,"CODE",{});var ujt=s(hTe);Nsr=r(ujt,"model_type"),ujt.forEach(t),qsr=r(o8,` property of the config object (either
passed as an argument or loaded from `),uTe=n(o8,"CODE",{});var pjt=s(uTe);jsr=r(pjt,"pretrained_model_name_or_path"),pjt.forEach(t),Dsr=r(o8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=n(o8,"CODE",{});var _jt=s(pTe);Gsr=r(_jt,"pretrained_model_name_or_path"),_jt.forEach(t),Osr=r(o8,":"),o8.forEach(t),Vsr=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);xT=n(ee,"LI",{});var mVe=s(xT);_Te=n(mVe,"STRONG",{});var bjt=s(_Te);Xsr=r(bjt,"albert"),bjt.forEach(t),zsr=r(mVe," \u2014 "),cH=n(mVe,"A",{href:!0});var vjt=s(cH);Qsr=r(vjt,"AlbertForMultipleChoice"),vjt.forEach(t),Wsr=r(mVe," (ALBERT model)"),mVe.forEach(t),Usr=i(ee),$T=n(ee,"LI",{});var fVe=s($T);bTe=n(fVe,"STRONG",{});var Fjt=s(bTe);Hsr=r(Fjt,"bert"),Fjt.forEach(t),Jsr=r(fVe," \u2014 "),mH=n(fVe,"A",{href:!0});var Tjt=s(mH);Ysr=r(Tjt,"BertForMultipleChoice"),Tjt.forEach(t),Ksr=r(fVe," (BERT model)"),fVe.forEach(t),Zsr=i(ee),kT=n(ee,"LI",{});var gVe=s(kT);vTe=n(gVe,"STRONG",{});var Mjt=s(vTe);elr=r(Mjt,"big_bird"),Mjt.forEach(t),olr=r(gVe," \u2014 "),fH=n(gVe,"A",{href:!0});var Ejt=s(fH);rlr=r(Ejt,"BigBirdForMultipleChoice"),Ejt.forEach(t),tlr=r(gVe," (BigBird model)"),gVe.forEach(t),alr=i(ee),ST=n(ee,"LI",{});var hVe=s(ST);FTe=n(hVe,"STRONG",{});var Cjt=s(FTe);nlr=r(Cjt,"camembert"),Cjt.forEach(t),slr=r(hVe," \u2014 "),gH=n(hVe,"A",{href:!0});var wjt=s(gH);llr=r(wjt,"CamembertForMultipleChoice"),wjt.forEach(t),ilr=r(hVe," (CamemBERT model)"),hVe.forEach(t),dlr=i(ee),RT=n(ee,"LI",{});var uVe=s(RT);TTe=n(uVe,"STRONG",{});var Ajt=s(TTe);clr=r(Ajt,"canine"),Ajt.forEach(t),mlr=r(uVe," \u2014 "),hH=n(uVe,"A",{href:!0});var Ljt=s(hH);flr=r(Ljt,"CanineForMultipleChoice"),Ljt.forEach(t),glr=r(uVe," (CANINE model)"),uVe.forEach(t),hlr=i(ee),PT=n(ee,"LI",{});var pVe=s(PT);MTe=n(pVe,"STRONG",{});var yjt=s(MTe);ulr=r(yjt,"convbert"),yjt.forEach(t),plr=r(pVe," \u2014 "),uH=n(pVe,"A",{href:!0});var xjt=s(uH);_lr=r(xjt,"ConvBertForMultipleChoice"),xjt.forEach(t),blr=r(pVe," (ConvBERT model)"),pVe.forEach(t),vlr=i(ee),BT=n(ee,"LI",{});var _Ve=s(BT);ETe=n(_Ve,"STRONG",{});var $jt=s(ETe);Flr=r($jt,"data2vec-text"),$jt.forEach(t),Tlr=r(_Ve," \u2014 "),pH=n(_Ve,"A",{href:!0});var kjt=s(pH);Mlr=r(kjt,"Data2VecTextForMultipleChoice"),kjt.forEach(t),Elr=r(_Ve," (Data2VecText model)"),_Ve.forEach(t),Clr=i(ee),IT=n(ee,"LI",{});var bVe=s(IT);CTe=n(bVe,"STRONG",{});var Sjt=s(CTe);wlr=r(Sjt,"deberta-v2"),Sjt.forEach(t),Alr=r(bVe," \u2014 "),_H=n(bVe,"A",{href:!0});var Rjt=s(_H);Llr=r(Rjt,"DebertaV2ForMultipleChoice"),Rjt.forEach(t),ylr=r(bVe," (DeBERTa-v2 model)"),bVe.forEach(t),xlr=i(ee),NT=n(ee,"LI",{});var vVe=s(NT);wTe=n(vVe,"STRONG",{});var Pjt=s(wTe);$lr=r(Pjt,"distilbert"),Pjt.forEach(t),klr=r(vVe," \u2014 "),bH=n(vVe,"A",{href:!0});var Bjt=s(bH);Slr=r(Bjt,"DistilBertForMultipleChoice"),Bjt.forEach(t),Rlr=r(vVe," (DistilBERT model)"),vVe.forEach(t),Plr=i(ee),qT=n(ee,"LI",{});var FVe=s(qT);ATe=n(FVe,"STRONG",{});var Ijt=s(ATe);Blr=r(Ijt,"electra"),Ijt.forEach(t),Ilr=r(FVe," \u2014 "),vH=n(FVe,"A",{href:!0});var Njt=s(vH);Nlr=r(Njt,"ElectraForMultipleChoice"),Njt.forEach(t),qlr=r(FVe," (ELECTRA model)"),FVe.forEach(t),jlr=i(ee),jT=n(ee,"LI",{});var TVe=s(jT);LTe=n(TVe,"STRONG",{});var qjt=s(LTe);Dlr=r(qjt,"ernie"),qjt.forEach(t),Glr=r(TVe," \u2014 "),FH=n(TVe,"A",{href:!0});var jjt=s(FH);Olr=r(jjt,"ErnieForMultipleChoice"),jjt.forEach(t),Vlr=r(TVe," (ERNIE model)"),TVe.forEach(t),Xlr=i(ee),DT=n(ee,"LI",{});var MVe=s(DT);yTe=n(MVe,"STRONG",{});var Djt=s(yTe);zlr=r(Djt,"flaubert"),Djt.forEach(t),Qlr=r(MVe," \u2014 "),TH=n(MVe,"A",{href:!0});var Gjt=s(TH);Wlr=r(Gjt,"FlaubertForMultipleChoice"),Gjt.forEach(t),Ulr=r(MVe," (FlauBERT model)"),MVe.forEach(t),Hlr=i(ee),GT=n(ee,"LI",{});var EVe=s(GT);xTe=n(EVe,"STRONG",{});var Ojt=s(xTe);Jlr=r(Ojt,"fnet"),Ojt.forEach(t),Ylr=r(EVe," \u2014 "),MH=n(EVe,"A",{href:!0});var Vjt=s(MH);Klr=r(Vjt,"FNetForMultipleChoice"),Vjt.forEach(t),Zlr=r(EVe," (FNet model)"),EVe.forEach(t),eir=i(ee),OT=n(ee,"LI",{});var CVe=s(OT);$Te=n(CVe,"STRONG",{});var Xjt=s($Te);oir=r(Xjt,"funnel"),Xjt.forEach(t),rir=r(CVe," \u2014 "),EH=n(CVe,"A",{href:!0});var zjt=s(EH);tir=r(zjt,"FunnelForMultipleChoice"),zjt.forEach(t),air=r(CVe," (Funnel Transformer model)"),CVe.forEach(t),nir=i(ee),VT=n(ee,"LI",{});var wVe=s(VT);kTe=n(wVe,"STRONG",{});var Qjt=s(kTe);sir=r(Qjt,"ibert"),Qjt.forEach(t),lir=r(wVe," \u2014 "),CH=n(wVe,"A",{href:!0});var Wjt=s(CH);iir=r(Wjt,"IBertForMultipleChoice"),Wjt.forEach(t),dir=r(wVe," (I-BERT model)"),wVe.forEach(t),cir=i(ee),XT=n(ee,"LI",{});var AVe=s(XT);STe=n(AVe,"STRONG",{});var Ujt=s(STe);mir=r(Ujt,"longformer"),Ujt.forEach(t),fir=r(AVe," \u2014 "),wH=n(AVe,"A",{href:!0});var Hjt=s(wH);gir=r(Hjt,"LongformerForMultipleChoice"),Hjt.forEach(t),hir=r(AVe," (Longformer model)"),AVe.forEach(t),uir=i(ee),zT=n(ee,"LI",{});var LVe=s(zT);RTe=n(LVe,"STRONG",{});var Jjt=s(RTe);pir=r(Jjt,"luke"),Jjt.forEach(t),_ir=r(LVe," \u2014 "),AH=n(LVe,"A",{href:!0});var Yjt=s(AH);bir=r(Yjt,"LukeForMultipleChoice"),Yjt.forEach(t),vir=r(LVe," (LUKE model)"),LVe.forEach(t),Fir=i(ee),QT=n(ee,"LI",{});var yVe=s(QT);PTe=n(yVe,"STRONG",{});var Kjt=s(PTe);Tir=r(Kjt,"megatron-bert"),Kjt.forEach(t),Mir=r(yVe," \u2014 "),LH=n(yVe,"A",{href:!0});var Zjt=s(LH);Eir=r(Zjt,"MegatronBertForMultipleChoice"),Zjt.forEach(t),Cir=r(yVe," (Megatron-BERT model)"),yVe.forEach(t),wir=i(ee),WT=n(ee,"LI",{});var xVe=s(WT);BTe=n(xVe,"STRONG",{});var eDt=s(BTe);Air=r(eDt,"mobilebert"),eDt.forEach(t),Lir=r(xVe," \u2014 "),yH=n(xVe,"A",{href:!0});var oDt=s(yH);yir=r(oDt,"MobileBertForMultipleChoice"),oDt.forEach(t),xir=r(xVe," (MobileBERT model)"),xVe.forEach(t),$ir=i(ee),UT=n(ee,"LI",{});var $Ve=s(UT);ITe=n($Ve,"STRONG",{});var rDt=s(ITe);kir=r(rDt,"mpnet"),rDt.forEach(t),Sir=r($Ve," \u2014 "),xH=n($Ve,"A",{href:!0});var tDt=s(xH);Rir=r(tDt,"MPNetForMultipleChoice"),tDt.forEach(t),Pir=r($Ve," (MPNet model)"),$Ve.forEach(t),Bir=i(ee),HT=n(ee,"LI",{});var kVe=s(HT);NTe=n(kVe,"STRONG",{});var aDt=s(NTe);Iir=r(aDt,"nezha"),aDt.forEach(t),Nir=r(kVe," \u2014 "),$H=n(kVe,"A",{href:!0});var nDt=s($H);qir=r(nDt,"NezhaForMultipleChoice"),nDt.forEach(t),jir=r(kVe," (Nezha model)"),kVe.forEach(t),Dir=i(ee),JT=n(ee,"LI",{});var SVe=s(JT);qTe=n(SVe,"STRONG",{});var sDt=s(qTe);Gir=r(sDt,"nystromformer"),sDt.forEach(t),Oir=r(SVe," \u2014 "),kH=n(SVe,"A",{href:!0});var lDt=s(kH);Vir=r(lDt,"NystromformerForMultipleChoice"),lDt.forEach(t),Xir=r(SVe," (Nystr\xF6mformer model)"),SVe.forEach(t),zir=i(ee),YT=n(ee,"LI",{});var RVe=s(YT);jTe=n(RVe,"STRONG",{});var iDt=s(jTe);Qir=r(iDt,"qdqbert"),iDt.forEach(t),Wir=r(RVe," \u2014 "),SH=n(RVe,"A",{href:!0});var dDt=s(SH);Uir=r(dDt,"QDQBertForMultipleChoice"),dDt.forEach(t),Hir=r(RVe," (QDQBert model)"),RVe.forEach(t),Jir=i(ee),KT=n(ee,"LI",{});var PVe=s(KT);DTe=n(PVe,"STRONG",{});var cDt=s(DTe);Yir=r(cDt,"rembert"),cDt.forEach(t),Kir=r(PVe," \u2014 "),RH=n(PVe,"A",{href:!0});var mDt=s(RH);Zir=r(mDt,"RemBertForMultipleChoice"),mDt.forEach(t),edr=r(PVe," (RemBERT model)"),PVe.forEach(t),odr=i(ee),ZT=n(ee,"LI",{});var BVe=s(ZT);GTe=n(BVe,"STRONG",{});var fDt=s(GTe);rdr=r(fDt,"roberta"),fDt.forEach(t),tdr=r(BVe," \u2014 "),PH=n(BVe,"A",{href:!0});var gDt=s(PH);adr=r(gDt,"RobertaForMultipleChoice"),gDt.forEach(t),ndr=r(BVe," (RoBERTa model)"),BVe.forEach(t),sdr=i(ee),eM=n(ee,"LI",{});var IVe=s(eM);OTe=n(IVe,"STRONG",{});var hDt=s(OTe);ldr=r(hDt,"roformer"),hDt.forEach(t),idr=r(IVe," \u2014 "),BH=n(IVe,"A",{href:!0});var uDt=s(BH);ddr=r(uDt,"RoFormerForMultipleChoice"),uDt.forEach(t),cdr=r(IVe," (RoFormer model)"),IVe.forEach(t),mdr=i(ee),oM=n(ee,"LI",{});var NVe=s(oM);VTe=n(NVe,"STRONG",{});var pDt=s(VTe);fdr=r(pDt,"squeezebert"),pDt.forEach(t),gdr=r(NVe," \u2014 "),IH=n(NVe,"A",{href:!0});var _Dt=s(IH);hdr=r(_Dt,"SqueezeBertForMultipleChoice"),_Dt.forEach(t),udr=r(NVe," (SqueezeBERT model)"),NVe.forEach(t),pdr=i(ee),rM=n(ee,"LI",{});var qVe=s(rM);XTe=n(qVe,"STRONG",{});var bDt=s(XTe);_dr=r(bDt,"xlm"),bDt.forEach(t),bdr=r(qVe," \u2014 "),NH=n(qVe,"A",{href:!0});var vDt=s(NH);vdr=r(vDt,"XLMForMultipleChoice"),vDt.forEach(t),Fdr=r(qVe," (XLM model)"),qVe.forEach(t),Tdr=i(ee),tM=n(ee,"LI",{});var jVe=s(tM);zTe=n(jVe,"STRONG",{});var FDt=s(zTe);Mdr=r(FDt,"xlm-roberta"),FDt.forEach(t),Edr=r(jVe," \u2014 "),qH=n(jVe,"A",{href:!0});var TDt=s(qH);Cdr=r(TDt,"XLMRobertaForMultipleChoice"),TDt.forEach(t),wdr=r(jVe," (XLM-RoBERTa model)"),jVe.forEach(t),Adr=i(ee),aM=n(ee,"LI",{});var DVe=s(aM);QTe=n(DVe,"STRONG",{});var MDt=s(QTe);Ldr=r(MDt,"xlm-roberta-xl"),MDt.forEach(t),ydr=r(DVe," \u2014 "),jH=n(DVe,"A",{href:!0});var EDt=s(jH);xdr=r(EDt,"XLMRobertaXLForMultipleChoice"),EDt.forEach(t),$dr=r(DVe," (XLM-RoBERTa-XL model)"),DVe.forEach(t),kdr=i(ee),nM=n(ee,"LI",{});var GVe=s(nM);WTe=n(GVe,"STRONG",{});var CDt=s(WTe);Sdr=r(CDt,"xlnet"),CDt.forEach(t),Rdr=r(GVe," \u2014 "),DH=n(GVe,"A",{href:!0});var wDt=s(DH);Pdr=r(wDt,"XLNetForMultipleChoice"),wDt.forEach(t),Bdr=r(GVe," (XLNet model)"),GVe.forEach(t),Idr=i(ee),sM=n(ee,"LI",{});var OVe=s(sM);UTe=n(OVe,"STRONG",{});var ADt=s(UTe);Ndr=r(ADt,"yoso"),ADt.forEach(t),qdr=r(OVe," \u2014 "),GH=n(OVe,"A",{href:!0});var LDt=s(GH);jdr=r(LDt,"YosoForMultipleChoice"),LDt.forEach(t),Ddr=r(OVe," (YOSO model)"),OVe.forEach(t),ee.forEach(t),Gdr=i(Aa),lM=n(Aa,"P",{});var VVe=s(lM);Odr=r(VVe,"The model is set in evaluation mode by default using "),HTe=n(VVe,"CODE",{});var yDt=s(HTe);Vdr=r(yDt,"model.eval()"),yDt.forEach(t),Xdr=r(VVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JTe=n(VVe,"CODE",{});var xDt=s(JTe);zdr=r(xDt,"model.train()"),xDt.forEach(t),VVe.forEach(t),Qdr=i(Aa),T(iM.$$.fragment,Aa),Aa.forEach(t),Sl.forEach(t),VZe=i(m),qd=n(m,"H2",{class:!0});var tro=s(qd);dM=n(tro,"A",{id:!0,class:!0,href:!0});var $Dt=s(dM);YTe=n($Dt,"SPAN",{});var kDt=s(YTe);T(o$.$$.fragment,kDt),kDt.forEach(t),$Dt.forEach(t),Wdr=i(tro),KTe=n(tro,"SPAN",{});var SDt=s(KTe);Udr=r(SDt,"AutoModelForNextSentencePrediction"),SDt.forEach(t),tro.forEach(t),XZe=i(m),Go=n(m,"DIV",{class:!0});var Rl=s(Go);T(r$.$$.fragment,Rl),Hdr=i(Rl),jd=n(Rl,"P",{});var eie=s(jd);Jdr=r(eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OH=n(eie,"A",{href:!0});var RDt=s(OH);Ydr=r(RDt,"from_pretrained()"),RDt.forEach(t),Kdr=r(eie," class method or the "),VH=n(eie,"A",{href:!0});var PDt=s(VH);Zdr=r(PDt,"from_config()"),PDt.forEach(t),ecr=r(eie,` class
method.`),eie.forEach(t),ocr=i(Rl),t$=n(Rl,"P",{});var aro=s(t$);rcr=r(aro,"This class cannot be instantiated directly using "),ZTe=n(aro,"CODE",{});var BDt=s(ZTe);tcr=r(BDt,"__init__()"),BDt.forEach(t),acr=r(aro," (throws an error)."),aro.forEach(t),ncr=i(Rl),Ct=n(Rl,"DIV",{class:!0});var r8=s(Ct);T(a$.$$.fragment,r8),scr=i(r8),eMe=n(r8,"P",{});var IDt=s(eMe);lcr=r(IDt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),IDt.forEach(t),icr=i(r8),Dd=n(r8,"P",{});var oie=s(Dd);dcr=r(oie,`Note:
Loading a model from its configuration file does `),oMe=n(oie,"STRONG",{});var NDt=s(oMe);ccr=r(NDt,"not"),NDt.forEach(t),mcr=r(oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=n(oie,"A",{href:!0});var qDt=s(XH);fcr=r(qDt,"from_pretrained()"),qDt.forEach(t),gcr=r(oie," to load the model weights."),oie.forEach(t),hcr=i(r8),T(cM.$$.fragment,r8),r8.forEach(t),ucr=i(Rl),so=n(Rl,"DIV",{class:!0});var La=s(so);T(n$.$$.fragment,La),pcr=i(La),rMe=n(La,"P",{});var jDt=s(rMe);_cr=r(jDt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),jDt.forEach(t),bcr=i(La),tn=n(La,"P",{});var t8=s(tn);vcr=r(t8,"The model class to instantiate is selected based on the "),tMe=n(t8,"CODE",{});var DDt=s(tMe);Fcr=r(DDt,"model_type"),DDt.forEach(t),Tcr=r(t8,` property of the config object (either
passed as an argument or loaded from `),aMe=n(t8,"CODE",{});var GDt=s(aMe);Mcr=r(GDt,"pretrained_model_name_or_path"),GDt.forEach(t),Ecr=r(t8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=n(t8,"CODE",{});var ODt=s(nMe);Ccr=r(ODt,"pretrained_model_name_or_path"),ODt.forEach(t),wcr=r(t8,":"),t8.forEach(t),Acr=i(La),Ue=n(La,"UL",{});var ct=s(Ue);mM=n(ct,"LI",{});var XVe=s(mM);sMe=n(XVe,"STRONG",{});var VDt=s(sMe);Lcr=r(VDt,"bert"),VDt.forEach(t),ycr=r(XVe," \u2014 "),zH=n(XVe,"A",{href:!0});var XDt=s(zH);xcr=r(XDt,"BertForNextSentencePrediction"),XDt.forEach(t),$cr=r(XVe," (BERT model)"),XVe.forEach(t),kcr=i(ct),fM=n(ct,"LI",{});var zVe=s(fM);lMe=n(zVe,"STRONG",{});var zDt=s(lMe);Scr=r(zDt,"ernie"),zDt.forEach(t),Rcr=r(zVe," \u2014 "),QH=n(zVe,"A",{href:!0});var QDt=s(QH);Pcr=r(QDt,"ErnieForNextSentencePrediction"),QDt.forEach(t),Bcr=r(zVe," (ERNIE model)"),zVe.forEach(t),Icr=i(ct),gM=n(ct,"LI",{});var QVe=s(gM);iMe=n(QVe,"STRONG",{});var WDt=s(iMe);Ncr=r(WDt,"fnet"),WDt.forEach(t),qcr=r(QVe," \u2014 "),WH=n(QVe,"A",{href:!0});var UDt=s(WH);jcr=r(UDt,"FNetForNextSentencePrediction"),UDt.forEach(t),Dcr=r(QVe," (FNet model)"),QVe.forEach(t),Gcr=i(ct),hM=n(ct,"LI",{});var WVe=s(hM);dMe=n(WVe,"STRONG",{});var HDt=s(dMe);Ocr=r(HDt,"megatron-bert"),HDt.forEach(t),Vcr=r(WVe," \u2014 "),UH=n(WVe,"A",{href:!0});var JDt=s(UH);Xcr=r(JDt,"MegatronBertForNextSentencePrediction"),JDt.forEach(t),zcr=r(WVe," (Megatron-BERT model)"),WVe.forEach(t),Qcr=i(ct),uM=n(ct,"LI",{});var UVe=s(uM);cMe=n(UVe,"STRONG",{});var YDt=s(cMe);Wcr=r(YDt,"mobilebert"),YDt.forEach(t),Ucr=r(UVe," \u2014 "),HH=n(UVe,"A",{href:!0});var KDt=s(HH);Hcr=r(KDt,"MobileBertForNextSentencePrediction"),KDt.forEach(t),Jcr=r(UVe," (MobileBERT model)"),UVe.forEach(t),Ycr=i(ct),pM=n(ct,"LI",{});var HVe=s(pM);mMe=n(HVe,"STRONG",{});var ZDt=s(mMe);Kcr=r(ZDt,"nezha"),ZDt.forEach(t),Zcr=r(HVe," \u2014 "),JH=n(HVe,"A",{href:!0});var eGt=s(JH);emr=r(eGt,"NezhaForNextSentencePrediction"),eGt.forEach(t),omr=r(HVe," (Nezha model)"),HVe.forEach(t),rmr=i(ct),_M=n(ct,"LI",{});var JVe=s(_M);fMe=n(JVe,"STRONG",{});var oGt=s(fMe);tmr=r(oGt,"qdqbert"),oGt.forEach(t),amr=r(JVe," \u2014 "),YH=n(JVe,"A",{href:!0});var rGt=s(YH);nmr=r(rGt,"QDQBertForNextSentencePrediction"),rGt.forEach(t),smr=r(JVe," (QDQBert model)"),JVe.forEach(t),ct.forEach(t),lmr=i(La),bM=n(La,"P",{});var YVe=s(bM);imr=r(YVe,"The model is set in evaluation mode by default using "),gMe=n(YVe,"CODE",{});var tGt=s(gMe);dmr=r(tGt,"model.eval()"),tGt.forEach(t),cmr=r(YVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hMe=n(YVe,"CODE",{});var aGt=s(hMe);mmr=r(aGt,"model.train()"),aGt.forEach(t),YVe.forEach(t),fmr=i(La),T(vM.$$.fragment,La),La.forEach(t),Rl.forEach(t),zZe=i(m),Gd=n(m,"H2",{class:!0});var nro=s(Gd);FM=n(nro,"A",{id:!0,class:!0,href:!0});var nGt=s(FM);uMe=n(nGt,"SPAN",{});var sGt=s(uMe);T(s$.$$.fragment,sGt),sGt.forEach(t),nGt.forEach(t),gmr=i(nro),pMe=n(nro,"SPAN",{});var lGt=s(pMe);hmr=r(lGt,"AutoModelForTokenClassification"),lGt.forEach(t),nro.forEach(t),QZe=i(m),Oo=n(m,"DIV",{class:!0});var Pl=s(Oo);T(l$.$$.fragment,Pl),umr=i(Pl),Od=n(Pl,"P",{});var rie=s(Od);pmr=r(rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),KH=n(rie,"A",{href:!0});var iGt=s(KH);_mr=r(iGt,"from_pretrained()"),iGt.forEach(t),bmr=r(rie," class method or the "),ZH=n(rie,"A",{href:!0});var dGt=s(ZH);vmr=r(dGt,"from_config()"),dGt.forEach(t),Fmr=r(rie,` class
method.`),rie.forEach(t),Tmr=i(Pl),i$=n(Pl,"P",{});var sro=s(i$);Mmr=r(sro,"This class cannot be instantiated directly using "),_Me=n(sro,"CODE",{});var cGt=s(_Me);Emr=r(cGt,"__init__()"),cGt.forEach(t),Cmr=r(sro," (throws an error)."),sro.forEach(t),wmr=i(Pl),wt=n(Pl,"DIV",{class:!0});var a8=s(wt);T(d$.$$.fragment,a8),Amr=i(a8),bMe=n(a8,"P",{});var mGt=s(bMe);Lmr=r(mGt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),mGt.forEach(t),ymr=i(a8),Vd=n(a8,"P",{});var tie=s(Vd);xmr=r(tie,`Note:
Loading a model from its configuration file does `),vMe=n(tie,"STRONG",{});var fGt=s(vMe);$mr=r(fGt,"not"),fGt.forEach(t),kmr=r(tie,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(tie,"A",{href:!0});var gGt=s(eJ);Smr=r(gGt,"from_pretrained()"),gGt.forEach(t),Rmr=r(tie," to load the model weights."),tie.forEach(t),Pmr=i(a8),T(TM.$$.fragment,a8),a8.forEach(t),Bmr=i(Pl),lo=n(Pl,"DIV",{class:!0});var ya=s(lo);T(c$.$$.fragment,ya),Imr=i(ya),FMe=n(ya,"P",{});var hGt=s(FMe);Nmr=r(hGt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),hGt.forEach(t),qmr=i(ya),an=n(ya,"P",{});var n8=s(an);jmr=r(n8,"The model class to instantiate is selected based on the "),TMe=n(n8,"CODE",{});var uGt=s(TMe);Dmr=r(uGt,"model_type"),uGt.forEach(t),Gmr=r(n8,` property of the config object (either
passed as an argument or loaded from `),MMe=n(n8,"CODE",{});var pGt=s(MMe);Omr=r(pGt,"pretrained_model_name_or_path"),pGt.forEach(t),Vmr=r(n8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EMe=n(n8,"CODE",{});var _Gt=s(EMe);Xmr=r(_Gt,"pretrained_model_name_or_path"),_Gt.forEach(t),zmr=r(n8,":"),n8.forEach(t),Qmr=i(ya),J=n(ya,"UL",{});var K=s(J);MM=n(K,"LI",{});var KVe=s(MM);CMe=n(KVe,"STRONG",{});var bGt=s(CMe);Wmr=r(bGt,"albert"),bGt.forEach(t),Umr=r(KVe," \u2014 "),oJ=n(KVe,"A",{href:!0});var vGt=s(oJ);Hmr=r(vGt,"AlbertForTokenClassification"),vGt.forEach(t),Jmr=r(KVe," (ALBERT model)"),KVe.forEach(t),Ymr=i(K),EM=n(K,"LI",{});var ZVe=s(EM);wMe=n(ZVe,"STRONG",{});var FGt=s(wMe);Kmr=r(FGt,"bert"),FGt.forEach(t),Zmr=r(ZVe," \u2014 "),rJ=n(ZVe,"A",{href:!0});var TGt=s(rJ);efr=r(TGt,"BertForTokenClassification"),TGt.forEach(t),ofr=r(ZVe," (BERT model)"),ZVe.forEach(t),rfr=i(K),CM=n(K,"LI",{});var eXe=s(CM);AMe=n(eXe,"STRONG",{});var MGt=s(AMe);tfr=r(MGt,"big_bird"),MGt.forEach(t),afr=r(eXe," \u2014 "),tJ=n(eXe,"A",{href:!0});var EGt=s(tJ);nfr=r(EGt,"BigBirdForTokenClassification"),EGt.forEach(t),sfr=r(eXe," (BigBird model)"),eXe.forEach(t),lfr=i(K),wM=n(K,"LI",{});var oXe=s(wM);LMe=n(oXe,"STRONG",{});var CGt=s(LMe);ifr=r(CGt,"bloom"),CGt.forEach(t),dfr=r(oXe," \u2014 "),aJ=n(oXe,"A",{href:!0});var wGt=s(aJ);cfr=r(wGt,"BloomForTokenClassification"),wGt.forEach(t),mfr=r(oXe," (BLOOM model)"),oXe.forEach(t),ffr=i(K),AM=n(K,"LI",{});var rXe=s(AM);yMe=n(rXe,"STRONG",{});var AGt=s(yMe);gfr=r(AGt,"camembert"),AGt.forEach(t),hfr=r(rXe," \u2014 "),nJ=n(rXe,"A",{href:!0});var LGt=s(nJ);ufr=r(LGt,"CamembertForTokenClassification"),LGt.forEach(t),pfr=r(rXe," (CamemBERT model)"),rXe.forEach(t),_fr=i(K),LM=n(K,"LI",{});var tXe=s(LM);xMe=n(tXe,"STRONG",{});var yGt=s(xMe);bfr=r(yGt,"canine"),yGt.forEach(t),vfr=r(tXe," \u2014 "),sJ=n(tXe,"A",{href:!0});var xGt=s(sJ);Ffr=r(xGt,"CanineForTokenClassification"),xGt.forEach(t),Tfr=r(tXe," (CANINE model)"),tXe.forEach(t),Mfr=i(K),yM=n(K,"LI",{});var aXe=s(yM);$Me=n(aXe,"STRONG",{});var $Gt=s($Me);Efr=r($Gt,"convbert"),$Gt.forEach(t),Cfr=r(aXe," \u2014 "),lJ=n(aXe,"A",{href:!0});var kGt=s(lJ);wfr=r(kGt,"ConvBertForTokenClassification"),kGt.forEach(t),Afr=r(aXe," (ConvBERT model)"),aXe.forEach(t),Lfr=i(K),xM=n(K,"LI",{});var nXe=s(xM);kMe=n(nXe,"STRONG",{});var SGt=s(kMe);yfr=r(SGt,"data2vec-text"),SGt.forEach(t),xfr=r(nXe," \u2014 "),iJ=n(nXe,"A",{href:!0});var RGt=s(iJ);$fr=r(RGt,"Data2VecTextForTokenClassification"),RGt.forEach(t),kfr=r(nXe," (Data2VecText model)"),nXe.forEach(t),Sfr=i(K),$M=n(K,"LI",{});var sXe=s($M);SMe=n(sXe,"STRONG",{});var PGt=s(SMe);Rfr=r(PGt,"deberta"),PGt.forEach(t),Pfr=r(sXe," \u2014 "),dJ=n(sXe,"A",{href:!0});var BGt=s(dJ);Bfr=r(BGt,"DebertaForTokenClassification"),BGt.forEach(t),Ifr=r(sXe," (DeBERTa model)"),sXe.forEach(t),Nfr=i(K),kM=n(K,"LI",{});var lXe=s(kM);RMe=n(lXe,"STRONG",{});var IGt=s(RMe);qfr=r(IGt,"deberta-v2"),IGt.forEach(t),jfr=r(lXe," \u2014 "),cJ=n(lXe,"A",{href:!0});var NGt=s(cJ);Dfr=r(NGt,"DebertaV2ForTokenClassification"),NGt.forEach(t),Gfr=r(lXe," (DeBERTa-v2 model)"),lXe.forEach(t),Ofr=i(K),SM=n(K,"LI",{});var iXe=s(SM);PMe=n(iXe,"STRONG",{});var qGt=s(PMe);Vfr=r(qGt,"distilbert"),qGt.forEach(t),Xfr=r(iXe," \u2014 "),mJ=n(iXe,"A",{href:!0});var jGt=s(mJ);zfr=r(jGt,"DistilBertForTokenClassification"),jGt.forEach(t),Qfr=r(iXe," (DistilBERT model)"),iXe.forEach(t),Wfr=i(K),RM=n(K,"LI",{});var dXe=s(RM);BMe=n(dXe,"STRONG",{});var DGt=s(BMe);Ufr=r(DGt,"electra"),DGt.forEach(t),Hfr=r(dXe," \u2014 "),fJ=n(dXe,"A",{href:!0});var GGt=s(fJ);Jfr=r(GGt,"ElectraForTokenClassification"),GGt.forEach(t),Yfr=r(dXe," (ELECTRA model)"),dXe.forEach(t),Kfr=i(K),PM=n(K,"LI",{});var cXe=s(PM);IMe=n(cXe,"STRONG",{});var OGt=s(IMe);Zfr=r(OGt,"ernie"),OGt.forEach(t),egr=r(cXe," \u2014 "),gJ=n(cXe,"A",{href:!0});var VGt=s(gJ);ogr=r(VGt,"ErnieForTokenClassification"),VGt.forEach(t),rgr=r(cXe," (ERNIE model)"),cXe.forEach(t),tgr=i(K),BM=n(K,"LI",{});var mXe=s(BM);NMe=n(mXe,"STRONG",{});var XGt=s(NMe);agr=r(XGt,"flaubert"),XGt.forEach(t),ngr=r(mXe," \u2014 "),hJ=n(mXe,"A",{href:!0});var zGt=s(hJ);sgr=r(zGt,"FlaubertForTokenClassification"),zGt.forEach(t),lgr=r(mXe," (FlauBERT model)"),mXe.forEach(t),igr=i(K),IM=n(K,"LI",{});var fXe=s(IM);qMe=n(fXe,"STRONG",{});var QGt=s(qMe);dgr=r(QGt,"fnet"),QGt.forEach(t),cgr=r(fXe," \u2014 "),uJ=n(fXe,"A",{href:!0});var WGt=s(uJ);mgr=r(WGt,"FNetForTokenClassification"),WGt.forEach(t),fgr=r(fXe," (FNet model)"),fXe.forEach(t),ggr=i(K),NM=n(K,"LI",{});var gXe=s(NM);jMe=n(gXe,"STRONG",{});var UGt=s(jMe);hgr=r(UGt,"funnel"),UGt.forEach(t),ugr=r(gXe," \u2014 "),pJ=n(gXe,"A",{href:!0});var HGt=s(pJ);pgr=r(HGt,"FunnelForTokenClassification"),HGt.forEach(t),_gr=r(gXe," (Funnel Transformer model)"),gXe.forEach(t),bgr=i(K),qM=n(K,"LI",{});var hXe=s(qM);DMe=n(hXe,"STRONG",{});var JGt=s(DMe);vgr=r(JGt,"gpt2"),JGt.forEach(t),Fgr=r(hXe," \u2014 "),_J=n(hXe,"A",{href:!0});var YGt=s(_J);Tgr=r(YGt,"GPT2ForTokenClassification"),YGt.forEach(t),Mgr=r(hXe," (OpenAI GPT-2 model)"),hXe.forEach(t),Egr=i(K),jM=n(K,"LI",{});var uXe=s(jM);GMe=n(uXe,"STRONG",{});var KGt=s(GMe);Cgr=r(KGt,"ibert"),KGt.forEach(t),wgr=r(uXe," \u2014 "),bJ=n(uXe,"A",{href:!0});var ZGt=s(bJ);Agr=r(ZGt,"IBertForTokenClassification"),ZGt.forEach(t),Lgr=r(uXe," (I-BERT model)"),uXe.forEach(t),ygr=i(K),DM=n(K,"LI",{});var pXe=s(DM);OMe=n(pXe,"STRONG",{});var eOt=s(OMe);xgr=r(eOt,"layoutlm"),eOt.forEach(t),$gr=r(pXe," \u2014 "),vJ=n(pXe,"A",{href:!0});var oOt=s(vJ);kgr=r(oOt,"LayoutLMForTokenClassification"),oOt.forEach(t),Sgr=r(pXe," (LayoutLM model)"),pXe.forEach(t),Rgr=i(K),GM=n(K,"LI",{});var _Xe=s(GM);VMe=n(_Xe,"STRONG",{});var rOt=s(VMe);Pgr=r(rOt,"layoutlmv2"),rOt.forEach(t),Bgr=r(_Xe," \u2014 "),FJ=n(_Xe,"A",{href:!0});var tOt=s(FJ);Igr=r(tOt,"LayoutLMv2ForTokenClassification"),tOt.forEach(t),Ngr=r(_Xe," (LayoutLMv2 model)"),_Xe.forEach(t),qgr=i(K),OM=n(K,"LI",{});var bXe=s(OM);XMe=n(bXe,"STRONG",{});var aOt=s(XMe);jgr=r(aOt,"layoutlmv3"),aOt.forEach(t),Dgr=r(bXe," \u2014 "),TJ=n(bXe,"A",{href:!0});var nOt=s(TJ);Ggr=r(nOt,"LayoutLMv3ForTokenClassification"),nOt.forEach(t),Ogr=r(bXe," (LayoutLMv3 model)"),bXe.forEach(t),Vgr=i(K),VM=n(K,"LI",{});var vXe=s(VM);zMe=n(vXe,"STRONG",{});var sOt=s(zMe);Xgr=r(sOt,"longformer"),sOt.forEach(t),zgr=r(vXe," \u2014 "),MJ=n(vXe,"A",{href:!0});var lOt=s(MJ);Qgr=r(lOt,"LongformerForTokenClassification"),lOt.forEach(t),Wgr=r(vXe," (Longformer model)"),vXe.forEach(t),Ugr=i(K),XM=n(K,"LI",{});var FXe=s(XM);QMe=n(FXe,"STRONG",{});var iOt=s(QMe);Hgr=r(iOt,"luke"),iOt.forEach(t),Jgr=r(FXe," \u2014 "),EJ=n(FXe,"A",{href:!0});var dOt=s(EJ);Ygr=r(dOt,"LukeForTokenClassification"),dOt.forEach(t),Kgr=r(FXe," (LUKE model)"),FXe.forEach(t),Zgr=i(K),zM=n(K,"LI",{});var TXe=s(zM);WMe=n(TXe,"STRONG",{});var cOt=s(WMe);ehr=r(cOt,"markuplm"),cOt.forEach(t),ohr=r(TXe," \u2014 "),CJ=n(TXe,"A",{href:!0});var mOt=s(CJ);rhr=r(mOt,"MarkupLMForTokenClassification"),mOt.forEach(t),thr=r(TXe," (MarkupLM model)"),TXe.forEach(t),ahr=i(K),QM=n(K,"LI",{});var MXe=s(QM);UMe=n(MXe,"STRONG",{});var fOt=s(UMe);nhr=r(fOt,"megatron-bert"),fOt.forEach(t),shr=r(MXe," \u2014 "),wJ=n(MXe,"A",{href:!0});var gOt=s(wJ);lhr=r(gOt,"MegatronBertForTokenClassification"),gOt.forEach(t),ihr=r(MXe," (Megatron-BERT model)"),MXe.forEach(t),dhr=i(K),WM=n(K,"LI",{});var EXe=s(WM);HMe=n(EXe,"STRONG",{});var hOt=s(HMe);chr=r(hOt,"mobilebert"),hOt.forEach(t),mhr=r(EXe," \u2014 "),AJ=n(EXe,"A",{href:!0});var uOt=s(AJ);fhr=r(uOt,"MobileBertForTokenClassification"),uOt.forEach(t),ghr=r(EXe," (MobileBERT model)"),EXe.forEach(t),hhr=i(K),UM=n(K,"LI",{});var CXe=s(UM);JMe=n(CXe,"STRONG",{});var pOt=s(JMe);uhr=r(pOt,"mpnet"),pOt.forEach(t),phr=r(CXe," \u2014 "),LJ=n(CXe,"A",{href:!0});var _Ot=s(LJ);_hr=r(_Ot,"MPNetForTokenClassification"),_Ot.forEach(t),bhr=r(CXe," (MPNet model)"),CXe.forEach(t),vhr=i(K),HM=n(K,"LI",{});var wXe=s(HM);YMe=n(wXe,"STRONG",{});var bOt=s(YMe);Fhr=r(bOt,"nezha"),bOt.forEach(t),Thr=r(wXe," \u2014 "),yJ=n(wXe,"A",{href:!0});var vOt=s(yJ);Mhr=r(vOt,"NezhaForTokenClassification"),vOt.forEach(t),Ehr=r(wXe," (Nezha model)"),wXe.forEach(t),Chr=i(K),JM=n(K,"LI",{});var AXe=s(JM);KMe=n(AXe,"STRONG",{});var FOt=s(KMe);whr=r(FOt,"nystromformer"),FOt.forEach(t),Ahr=r(AXe," \u2014 "),xJ=n(AXe,"A",{href:!0});var TOt=s(xJ);Lhr=r(TOt,"NystromformerForTokenClassification"),TOt.forEach(t),yhr=r(AXe," (Nystr\xF6mformer model)"),AXe.forEach(t),xhr=i(K),YM=n(K,"LI",{});var LXe=s(YM);ZMe=n(LXe,"STRONG",{});var MOt=s(ZMe);$hr=r(MOt,"qdqbert"),MOt.forEach(t),khr=r(LXe," \u2014 "),$J=n(LXe,"A",{href:!0});var EOt=s($J);Shr=r(EOt,"QDQBertForTokenClassification"),EOt.forEach(t),Rhr=r(LXe," (QDQBert model)"),LXe.forEach(t),Phr=i(K),KM=n(K,"LI",{});var yXe=s(KM);eEe=n(yXe,"STRONG",{});var COt=s(eEe);Bhr=r(COt,"rembert"),COt.forEach(t),Ihr=r(yXe," \u2014 "),kJ=n(yXe,"A",{href:!0});var wOt=s(kJ);Nhr=r(wOt,"RemBertForTokenClassification"),wOt.forEach(t),qhr=r(yXe," (RemBERT model)"),yXe.forEach(t),jhr=i(K),ZM=n(K,"LI",{});var xXe=s(ZM);oEe=n(xXe,"STRONG",{});var AOt=s(oEe);Dhr=r(AOt,"roberta"),AOt.forEach(t),Ghr=r(xXe," \u2014 "),SJ=n(xXe,"A",{href:!0});var LOt=s(SJ);Ohr=r(LOt,"RobertaForTokenClassification"),LOt.forEach(t),Vhr=r(xXe," (RoBERTa model)"),xXe.forEach(t),Xhr=i(K),eE=n(K,"LI",{});var $Xe=s(eE);rEe=n($Xe,"STRONG",{});var yOt=s(rEe);zhr=r(yOt,"roformer"),yOt.forEach(t),Qhr=r($Xe," \u2014 "),RJ=n($Xe,"A",{href:!0});var xOt=s(RJ);Whr=r(xOt,"RoFormerForTokenClassification"),xOt.forEach(t),Uhr=r($Xe," (RoFormer model)"),$Xe.forEach(t),Hhr=i(K),oE=n(K,"LI",{});var kXe=s(oE);tEe=n(kXe,"STRONG",{});var $Ot=s(tEe);Jhr=r($Ot,"squeezebert"),$Ot.forEach(t),Yhr=r(kXe," \u2014 "),PJ=n(kXe,"A",{href:!0});var kOt=s(PJ);Khr=r(kOt,"SqueezeBertForTokenClassification"),kOt.forEach(t),Zhr=r(kXe," (SqueezeBERT model)"),kXe.forEach(t),eur=i(K),rE=n(K,"LI",{});var SXe=s(rE);aEe=n(SXe,"STRONG",{});var SOt=s(aEe);our=r(SOt,"xlm"),SOt.forEach(t),rur=r(SXe," \u2014 "),BJ=n(SXe,"A",{href:!0});var ROt=s(BJ);tur=r(ROt,"XLMForTokenClassification"),ROt.forEach(t),aur=r(SXe," (XLM model)"),SXe.forEach(t),nur=i(K),tE=n(K,"LI",{});var RXe=s(tE);nEe=n(RXe,"STRONG",{});var POt=s(nEe);sur=r(POt,"xlm-roberta"),POt.forEach(t),lur=r(RXe," \u2014 "),IJ=n(RXe,"A",{href:!0});var BOt=s(IJ);iur=r(BOt,"XLMRobertaForTokenClassification"),BOt.forEach(t),dur=r(RXe," (XLM-RoBERTa model)"),RXe.forEach(t),cur=i(K),aE=n(K,"LI",{});var PXe=s(aE);sEe=n(PXe,"STRONG",{});var IOt=s(sEe);mur=r(IOt,"xlm-roberta-xl"),IOt.forEach(t),fur=r(PXe," \u2014 "),NJ=n(PXe,"A",{href:!0});var NOt=s(NJ);gur=r(NOt,"XLMRobertaXLForTokenClassification"),NOt.forEach(t),hur=r(PXe," (XLM-RoBERTa-XL model)"),PXe.forEach(t),uur=i(K),nE=n(K,"LI",{});var BXe=s(nE);lEe=n(BXe,"STRONG",{});var qOt=s(lEe);pur=r(qOt,"xlnet"),qOt.forEach(t),_ur=r(BXe," \u2014 "),qJ=n(BXe,"A",{href:!0});var jOt=s(qJ);bur=r(jOt,"XLNetForTokenClassification"),jOt.forEach(t),vur=r(BXe," (XLNet model)"),BXe.forEach(t),Fur=i(K),sE=n(K,"LI",{});var IXe=s(sE);iEe=n(IXe,"STRONG",{});var DOt=s(iEe);Tur=r(DOt,"yoso"),DOt.forEach(t),Mur=r(IXe," \u2014 "),jJ=n(IXe,"A",{href:!0});var GOt=s(jJ);Eur=r(GOt,"YosoForTokenClassification"),GOt.forEach(t),Cur=r(IXe," (YOSO model)"),IXe.forEach(t),K.forEach(t),wur=i(ya),lE=n(ya,"P",{});var NXe=s(lE);Aur=r(NXe,"The model is set in evaluation mode by default using "),dEe=n(NXe,"CODE",{});var OOt=s(dEe);Lur=r(OOt,"model.eval()"),OOt.forEach(t),yur=r(NXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cEe=n(NXe,"CODE",{});var VOt=s(cEe);xur=r(VOt,"model.train()"),VOt.forEach(t),NXe.forEach(t),$ur=i(ya),T(iE.$$.fragment,ya),ya.forEach(t),Pl.forEach(t),WZe=i(m),Xd=n(m,"H2",{class:!0});var lro=s(Xd);dE=n(lro,"A",{id:!0,class:!0,href:!0});var XOt=s(dE);mEe=n(XOt,"SPAN",{});var zOt=s(mEe);T(m$.$$.fragment,zOt),zOt.forEach(t),XOt.forEach(t),kur=i(lro),fEe=n(lro,"SPAN",{});var QOt=s(fEe);Sur=r(QOt,"AutoModelForQuestionAnswering"),QOt.forEach(t),lro.forEach(t),UZe=i(m),Vo=n(m,"DIV",{class:!0});var Bl=s(Vo);T(f$.$$.fragment,Bl),Rur=i(Bl),zd=n(Bl,"P",{});var aie=s(zd);Pur=r(aie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DJ=n(aie,"A",{href:!0});var WOt=s(DJ);Bur=r(WOt,"from_pretrained()"),WOt.forEach(t),Iur=r(aie," class method or the "),GJ=n(aie,"A",{href:!0});var UOt=s(GJ);Nur=r(UOt,"from_config()"),UOt.forEach(t),qur=r(aie,` class
method.`),aie.forEach(t),jur=i(Bl),g$=n(Bl,"P",{});var iro=s(g$);Dur=r(iro,"This class cannot be instantiated directly using "),gEe=n(iro,"CODE",{});var HOt=s(gEe);Gur=r(HOt,"__init__()"),HOt.forEach(t),Our=r(iro," (throws an error)."),iro.forEach(t),Vur=i(Bl),At=n(Bl,"DIV",{class:!0});var s8=s(At);T(h$.$$.fragment,s8),Xur=i(s8),hEe=n(s8,"P",{});var JOt=s(hEe);zur=r(JOt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),JOt.forEach(t),Qur=i(s8),Qd=n(s8,"P",{});var nie=s(Qd);Wur=r(nie,`Note:
Loading a model from its configuration file does `),uEe=n(nie,"STRONG",{});var YOt=s(uEe);Uur=r(YOt,"not"),YOt.forEach(t),Hur=r(nie,` load the model weights. It only affects the
model\u2019s configuration. Use `),OJ=n(nie,"A",{href:!0});var KOt=s(OJ);Jur=r(KOt,"from_pretrained()"),KOt.forEach(t),Yur=r(nie," to load the model weights."),nie.forEach(t),Kur=i(s8),T(cE.$$.fragment,s8),s8.forEach(t),Zur=i(Bl),io=n(Bl,"DIV",{class:!0});var xa=s(io);T(u$.$$.fragment,xa),epr=i(xa),pEe=n(xa,"P",{});var ZOt=s(pEe);opr=r(ZOt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ZOt.forEach(t),rpr=i(xa),nn=n(xa,"P",{});var l8=s(nn);tpr=r(l8,"The model class to instantiate is selected based on the "),_Ee=n(l8,"CODE",{});var eVt=s(_Ee);apr=r(eVt,"model_type"),eVt.forEach(t),npr=r(l8,` property of the config object (either
passed as an argument or loaded from `),bEe=n(l8,"CODE",{});var oVt=s(bEe);spr=r(oVt,"pretrained_model_name_or_path"),oVt.forEach(t),lpr=r(l8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vEe=n(l8,"CODE",{});var rVt=s(vEe);ipr=r(rVt,"pretrained_model_name_or_path"),rVt.forEach(t),dpr=r(l8,":"),l8.forEach(t),cpr=i(xa),V=n(xa,"UL",{});var X=s(V);mE=n(X,"LI",{});var qXe=s(mE);FEe=n(qXe,"STRONG",{});var tVt=s(FEe);mpr=r(tVt,"albert"),tVt.forEach(t),fpr=r(qXe," \u2014 "),VJ=n(qXe,"A",{href:!0});var aVt=s(VJ);gpr=r(aVt,"AlbertForQuestionAnswering"),aVt.forEach(t),hpr=r(qXe," (ALBERT model)"),qXe.forEach(t),upr=i(X),fE=n(X,"LI",{});var jXe=s(fE);TEe=n(jXe,"STRONG",{});var nVt=s(TEe);ppr=r(nVt,"bart"),nVt.forEach(t),_pr=r(jXe," \u2014 "),XJ=n(jXe,"A",{href:!0});var sVt=s(XJ);bpr=r(sVt,"BartForQuestionAnswering"),sVt.forEach(t),vpr=r(jXe," (BART model)"),jXe.forEach(t),Fpr=i(X),gE=n(X,"LI",{});var DXe=s(gE);MEe=n(DXe,"STRONG",{});var lVt=s(MEe);Tpr=r(lVt,"bert"),lVt.forEach(t),Mpr=r(DXe," \u2014 "),zJ=n(DXe,"A",{href:!0});var iVt=s(zJ);Epr=r(iVt,"BertForQuestionAnswering"),iVt.forEach(t),Cpr=r(DXe," (BERT model)"),DXe.forEach(t),wpr=i(X),hE=n(X,"LI",{});var GXe=s(hE);EEe=n(GXe,"STRONG",{});var dVt=s(EEe);Apr=r(dVt,"big_bird"),dVt.forEach(t),Lpr=r(GXe," \u2014 "),QJ=n(GXe,"A",{href:!0});var cVt=s(QJ);ypr=r(cVt,"BigBirdForQuestionAnswering"),cVt.forEach(t),xpr=r(GXe," (BigBird model)"),GXe.forEach(t),$pr=i(X),uE=n(X,"LI",{});var OXe=s(uE);CEe=n(OXe,"STRONG",{});var mVt=s(CEe);kpr=r(mVt,"bigbird_pegasus"),mVt.forEach(t),Spr=r(OXe," \u2014 "),WJ=n(OXe,"A",{href:!0});var fVt=s(WJ);Rpr=r(fVt,"BigBirdPegasusForQuestionAnswering"),fVt.forEach(t),Ppr=r(OXe," (BigBird-Pegasus model)"),OXe.forEach(t),Bpr=i(X),pE=n(X,"LI",{});var VXe=s(pE);wEe=n(VXe,"STRONG",{});var gVt=s(wEe);Ipr=r(gVt,"camembert"),gVt.forEach(t),Npr=r(VXe," \u2014 "),UJ=n(VXe,"A",{href:!0});var hVt=s(UJ);qpr=r(hVt,"CamembertForQuestionAnswering"),hVt.forEach(t),jpr=r(VXe," (CamemBERT model)"),VXe.forEach(t),Dpr=i(X),_E=n(X,"LI",{});var XXe=s(_E);AEe=n(XXe,"STRONG",{});var uVt=s(AEe);Gpr=r(uVt,"canine"),uVt.forEach(t),Opr=r(XXe," \u2014 "),HJ=n(XXe,"A",{href:!0});var pVt=s(HJ);Vpr=r(pVt,"CanineForQuestionAnswering"),pVt.forEach(t),Xpr=r(XXe," (CANINE model)"),XXe.forEach(t),zpr=i(X),bE=n(X,"LI",{});var zXe=s(bE);LEe=n(zXe,"STRONG",{});var _Vt=s(LEe);Qpr=r(_Vt,"convbert"),_Vt.forEach(t),Wpr=r(zXe," \u2014 "),JJ=n(zXe,"A",{href:!0});var bVt=s(JJ);Upr=r(bVt,"ConvBertForQuestionAnswering"),bVt.forEach(t),Hpr=r(zXe," (ConvBERT model)"),zXe.forEach(t),Jpr=i(X),vE=n(X,"LI",{});var QXe=s(vE);yEe=n(QXe,"STRONG",{});var vVt=s(yEe);Ypr=r(vVt,"data2vec-text"),vVt.forEach(t),Kpr=r(QXe," \u2014 "),YJ=n(QXe,"A",{href:!0});var FVt=s(YJ);Zpr=r(FVt,"Data2VecTextForQuestionAnswering"),FVt.forEach(t),e_r=r(QXe," (Data2VecText model)"),QXe.forEach(t),o_r=i(X),FE=n(X,"LI",{});var WXe=s(FE);xEe=n(WXe,"STRONG",{});var TVt=s(xEe);r_r=r(TVt,"deberta"),TVt.forEach(t),t_r=r(WXe," \u2014 "),KJ=n(WXe,"A",{href:!0});var MVt=s(KJ);a_r=r(MVt,"DebertaForQuestionAnswering"),MVt.forEach(t),n_r=r(WXe," (DeBERTa model)"),WXe.forEach(t),s_r=i(X),TE=n(X,"LI",{});var UXe=s(TE);$Ee=n(UXe,"STRONG",{});var EVt=s($Ee);l_r=r(EVt,"deberta-v2"),EVt.forEach(t),i_r=r(UXe," \u2014 "),ZJ=n(UXe,"A",{href:!0});var CVt=s(ZJ);d_r=r(CVt,"DebertaV2ForQuestionAnswering"),CVt.forEach(t),c_r=r(UXe," (DeBERTa-v2 model)"),UXe.forEach(t),m_r=i(X),ME=n(X,"LI",{});var HXe=s(ME);kEe=n(HXe,"STRONG",{});var wVt=s(kEe);f_r=r(wVt,"distilbert"),wVt.forEach(t),g_r=r(HXe," \u2014 "),eY=n(HXe,"A",{href:!0});var AVt=s(eY);h_r=r(AVt,"DistilBertForQuestionAnswering"),AVt.forEach(t),u_r=r(HXe," (DistilBERT model)"),HXe.forEach(t),p_r=i(X),EE=n(X,"LI",{});var JXe=s(EE);SEe=n(JXe,"STRONG",{});var LVt=s(SEe);__r=r(LVt,"electra"),LVt.forEach(t),b_r=r(JXe," \u2014 "),oY=n(JXe,"A",{href:!0});var yVt=s(oY);v_r=r(yVt,"ElectraForQuestionAnswering"),yVt.forEach(t),F_r=r(JXe," (ELECTRA model)"),JXe.forEach(t),T_r=i(X),CE=n(X,"LI",{});var YXe=s(CE);REe=n(YXe,"STRONG",{});var xVt=s(REe);M_r=r(xVt,"ernie"),xVt.forEach(t),E_r=r(YXe," \u2014 "),rY=n(YXe,"A",{href:!0});var $Vt=s(rY);C_r=r($Vt,"ErnieForQuestionAnswering"),$Vt.forEach(t),w_r=r(YXe," (ERNIE model)"),YXe.forEach(t),A_r=i(X),wE=n(X,"LI",{});var KXe=s(wE);PEe=n(KXe,"STRONG",{});var kVt=s(PEe);L_r=r(kVt,"flaubert"),kVt.forEach(t),y_r=r(KXe," \u2014 "),tY=n(KXe,"A",{href:!0});var SVt=s(tY);x_r=r(SVt,"FlaubertForQuestionAnsweringSimple"),SVt.forEach(t),$_r=r(KXe," (FlauBERT model)"),KXe.forEach(t),k_r=i(X),AE=n(X,"LI",{});var ZXe=s(AE);BEe=n(ZXe,"STRONG",{});var RVt=s(BEe);S_r=r(RVt,"fnet"),RVt.forEach(t),R_r=r(ZXe," \u2014 "),aY=n(ZXe,"A",{href:!0});var PVt=s(aY);P_r=r(PVt,"FNetForQuestionAnswering"),PVt.forEach(t),B_r=r(ZXe," (FNet model)"),ZXe.forEach(t),I_r=i(X),LE=n(X,"LI",{});var eze=s(LE);IEe=n(eze,"STRONG",{});var BVt=s(IEe);N_r=r(BVt,"funnel"),BVt.forEach(t),q_r=r(eze," \u2014 "),nY=n(eze,"A",{href:!0});var IVt=s(nY);j_r=r(IVt,"FunnelForQuestionAnswering"),IVt.forEach(t),D_r=r(eze," (Funnel Transformer model)"),eze.forEach(t),G_r=i(X),yE=n(X,"LI",{});var oze=s(yE);NEe=n(oze,"STRONG",{});var NVt=s(NEe);O_r=r(NVt,"gptj"),NVt.forEach(t),V_r=r(oze," \u2014 "),sY=n(oze,"A",{href:!0});var qVt=s(sY);X_r=r(qVt,"GPTJForQuestionAnswering"),qVt.forEach(t),z_r=r(oze," (GPT-J model)"),oze.forEach(t),Q_r=i(X),xE=n(X,"LI",{});var rze=s(xE);qEe=n(rze,"STRONG",{});var jVt=s(qEe);W_r=r(jVt,"ibert"),jVt.forEach(t),U_r=r(rze," \u2014 "),lY=n(rze,"A",{href:!0});var DVt=s(lY);H_r=r(DVt,"IBertForQuestionAnswering"),DVt.forEach(t),J_r=r(rze," (I-BERT model)"),rze.forEach(t),Y_r=i(X),$E=n(X,"LI",{});var tze=s($E);jEe=n(tze,"STRONG",{});var GVt=s(jEe);K_r=r(GVt,"layoutlmv2"),GVt.forEach(t),Z_r=r(tze," \u2014 "),iY=n(tze,"A",{href:!0});var OVt=s(iY);e2r=r(OVt,"LayoutLMv2ForQuestionAnswering"),OVt.forEach(t),o2r=r(tze," (LayoutLMv2 model)"),tze.forEach(t),r2r=i(X),kE=n(X,"LI",{});var aze=s(kE);DEe=n(aze,"STRONG",{});var VVt=s(DEe);t2r=r(VVt,"layoutlmv3"),VVt.forEach(t),a2r=r(aze," \u2014 "),dY=n(aze,"A",{href:!0});var XVt=s(dY);n2r=r(XVt,"LayoutLMv3ForQuestionAnswering"),XVt.forEach(t),s2r=r(aze," (LayoutLMv3 model)"),aze.forEach(t),l2r=i(X),SE=n(X,"LI",{});var nze=s(SE);GEe=n(nze,"STRONG",{});var zVt=s(GEe);i2r=r(zVt,"led"),zVt.forEach(t),d2r=r(nze," \u2014 "),cY=n(nze,"A",{href:!0});var QVt=s(cY);c2r=r(QVt,"LEDForQuestionAnswering"),QVt.forEach(t),m2r=r(nze," (LED model)"),nze.forEach(t),f2r=i(X),RE=n(X,"LI",{});var sze=s(RE);OEe=n(sze,"STRONG",{});var WVt=s(OEe);g2r=r(WVt,"longformer"),WVt.forEach(t),h2r=r(sze," \u2014 "),mY=n(sze,"A",{href:!0});var UVt=s(mY);u2r=r(UVt,"LongformerForQuestionAnswering"),UVt.forEach(t),p2r=r(sze," (Longformer model)"),sze.forEach(t),_2r=i(X),PE=n(X,"LI",{});var lze=s(PE);VEe=n(lze,"STRONG",{});var HVt=s(VEe);b2r=r(HVt,"luke"),HVt.forEach(t),v2r=r(lze," \u2014 "),fY=n(lze,"A",{href:!0});var JVt=s(fY);F2r=r(JVt,"LukeForQuestionAnswering"),JVt.forEach(t),T2r=r(lze," (LUKE model)"),lze.forEach(t),M2r=i(X),BE=n(X,"LI",{});var ize=s(BE);XEe=n(ize,"STRONG",{});var YVt=s(XEe);E2r=r(YVt,"lxmert"),YVt.forEach(t),C2r=r(ize," \u2014 "),gY=n(ize,"A",{href:!0});var KVt=s(gY);w2r=r(KVt,"LxmertForQuestionAnswering"),KVt.forEach(t),A2r=r(ize," (LXMERT model)"),ize.forEach(t),L2r=i(X),IE=n(X,"LI",{});var dze=s(IE);zEe=n(dze,"STRONG",{});var ZVt=s(zEe);y2r=r(ZVt,"markuplm"),ZVt.forEach(t),x2r=r(dze," \u2014 "),hY=n(dze,"A",{href:!0});var eXt=s(hY);$2r=r(eXt,"MarkupLMForQuestionAnswering"),eXt.forEach(t),k2r=r(dze," (MarkupLM model)"),dze.forEach(t),S2r=i(X),NE=n(X,"LI",{});var cze=s(NE);QEe=n(cze,"STRONG",{});var oXt=s(QEe);R2r=r(oXt,"mbart"),oXt.forEach(t),P2r=r(cze," \u2014 "),uY=n(cze,"A",{href:!0});var rXt=s(uY);B2r=r(rXt,"MBartForQuestionAnswering"),rXt.forEach(t),I2r=r(cze," (mBART model)"),cze.forEach(t),N2r=i(X),qE=n(X,"LI",{});var mze=s(qE);WEe=n(mze,"STRONG",{});var tXt=s(WEe);q2r=r(tXt,"megatron-bert"),tXt.forEach(t),j2r=r(mze," \u2014 "),pY=n(mze,"A",{href:!0});var aXt=s(pY);D2r=r(aXt,"MegatronBertForQuestionAnswering"),aXt.forEach(t),G2r=r(mze," (Megatron-BERT model)"),mze.forEach(t),O2r=i(X),jE=n(X,"LI",{});var fze=s(jE);UEe=n(fze,"STRONG",{});var nXt=s(UEe);V2r=r(nXt,"mobilebert"),nXt.forEach(t),X2r=r(fze," \u2014 "),_Y=n(fze,"A",{href:!0});var sXt=s(_Y);z2r=r(sXt,"MobileBertForQuestionAnswering"),sXt.forEach(t),Q2r=r(fze," (MobileBERT model)"),fze.forEach(t),W2r=i(X),DE=n(X,"LI",{});var gze=s(DE);HEe=n(gze,"STRONG",{});var lXt=s(HEe);U2r=r(lXt,"mpnet"),lXt.forEach(t),H2r=r(gze," \u2014 "),bY=n(gze,"A",{href:!0});var iXt=s(bY);J2r=r(iXt,"MPNetForQuestionAnswering"),iXt.forEach(t),Y2r=r(gze," (MPNet model)"),gze.forEach(t),K2r=i(X),GE=n(X,"LI",{});var hze=s(GE);JEe=n(hze,"STRONG",{});var dXt=s(JEe);Z2r=r(dXt,"mvp"),dXt.forEach(t),ebr=r(hze," \u2014 "),vY=n(hze,"A",{href:!0});var cXt=s(vY);obr=r(cXt,"MvpForQuestionAnswering"),cXt.forEach(t),rbr=r(hze," (MVP model)"),hze.forEach(t),tbr=i(X),OE=n(X,"LI",{});var uze=s(OE);YEe=n(uze,"STRONG",{});var mXt=s(YEe);abr=r(mXt,"nezha"),mXt.forEach(t),nbr=r(uze," \u2014 "),FY=n(uze,"A",{href:!0});var fXt=s(FY);sbr=r(fXt,"NezhaForQuestionAnswering"),fXt.forEach(t),lbr=r(uze," (Nezha model)"),uze.forEach(t),ibr=i(X),VE=n(X,"LI",{});var pze=s(VE);KEe=n(pze,"STRONG",{});var gXt=s(KEe);dbr=r(gXt,"nystromformer"),gXt.forEach(t),cbr=r(pze," \u2014 "),TY=n(pze,"A",{href:!0});var hXt=s(TY);mbr=r(hXt,"NystromformerForQuestionAnswering"),hXt.forEach(t),fbr=r(pze," (Nystr\xF6mformer model)"),pze.forEach(t),gbr=i(X),XE=n(X,"LI",{});var _ze=s(XE);ZEe=n(_ze,"STRONG",{});var uXt=s(ZEe);hbr=r(uXt,"qdqbert"),uXt.forEach(t),ubr=r(_ze," \u2014 "),MY=n(_ze,"A",{href:!0});var pXt=s(MY);pbr=r(pXt,"QDQBertForQuestionAnswering"),pXt.forEach(t),_br=r(_ze," (QDQBert model)"),_ze.forEach(t),bbr=i(X),zE=n(X,"LI",{});var bze=s(zE);e4e=n(bze,"STRONG",{});var _Xt=s(e4e);vbr=r(_Xt,"reformer"),_Xt.forEach(t),Fbr=r(bze," \u2014 "),EY=n(bze,"A",{href:!0});var bXt=s(EY);Tbr=r(bXt,"ReformerForQuestionAnswering"),bXt.forEach(t),Mbr=r(bze," (Reformer model)"),bze.forEach(t),Ebr=i(X),QE=n(X,"LI",{});var vze=s(QE);o4e=n(vze,"STRONG",{});var vXt=s(o4e);Cbr=r(vXt,"rembert"),vXt.forEach(t),wbr=r(vze," \u2014 "),CY=n(vze,"A",{href:!0});var FXt=s(CY);Abr=r(FXt,"RemBertForQuestionAnswering"),FXt.forEach(t),Lbr=r(vze," (RemBERT model)"),vze.forEach(t),ybr=i(X),WE=n(X,"LI",{});var Fze=s(WE);r4e=n(Fze,"STRONG",{});var TXt=s(r4e);xbr=r(TXt,"roberta"),TXt.forEach(t),$br=r(Fze," \u2014 "),wY=n(Fze,"A",{href:!0});var MXt=s(wY);kbr=r(MXt,"RobertaForQuestionAnswering"),MXt.forEach(t),Sbr=r(Fze," (RoBERTa model)"),Fze.forEach(t),Rbr=i(X),UE=n(X,"LI",{});var Tze=s(UE);t4e=n(Tze,"STRONG",{});var EXt=s(t4e);Pbr=r(EXt,"roformer"),EXt.forEach(t),Bbr=r(Tze," \u2014 "),AY=n(Tze,"A",{href:!0});var CXt=s(AY);Ibr=r(CXt,"RoFormerForQuestionAnswering"),CXt.forEach(t),Nbr=r(Tze," (RoFormer model)"),Tze.forEach(t),qbr=i(X),HE=n(X,"LI",{});var Mze=s(HE);a4e=n(Mze,"STRONG",{});var wXt=s(a4e);jbr=r(wXt,"splinter"),wXt.forEach(t),Dbr=r(Mze," \u2014 "),LY=n(Mze,"A",{href:!0});var AXt=s(LY);Gbr=r(AXt,"SplinterForQuestionAnswering"),AXt.forEach(t),Obr=r(Mze," (Splinter model)"),Mze.forEach(t),Vbr=i(X),JE=n(X,"LI",{});var Eze=s(JE);n4e=n(Eze,"STRONG",{});var LXt=s(n4e);Xbr=r(LXt,"squeezebert"),LXt.forEach(t),zbr=r(Eze," \u2014 "),yY=n(Eze,"A",{href:!0});var yXt=s(yY);Qbr=r(yXt,"SqueezeBertForQuestionAnswering"),yXt.forEach(t),Wbr=r(Eze," (SqueezeBERT model)"),Eze.forEach(t),Ubr=i(X),YE=n(X,"LI",{});var Cze=s(YE);s4e=n(Cze,"STRONG",{});var xXt=s(s4e);Hbr=r(xXt,"xlm"),xXt.forEach(t),Jbr=r(Cze," \u2014 "),xY=n(Cze,"A",{href:!0});var $Xt=s(xY);Ybr=r($Xt,"XLMForQuestionAnsweringSimple"),$Xt.forEach(t),Kbr=r(Cze," (XLM model)"),Cze.forEach(t),Zbr=i(X),KE=n(X,"LI",{});var wze=s(KE);l4e=n(wze,"STRONG",{});var kXt=s(l4e);e1r=r(kXt,"xlm-roberta"),kXt.forEach(t),o1r=r(wze," \u2014 "),$Y=n(wze,"A",{href:!0});var SXt=s($Y);r1r=r(SXt,"XLMRobertaForQuestionAnswering"),SXt.forEach(t),t1r=r(wze," (XLM-RoBERTa model)"),wze.forEach(t),a1r=i(X),ZE=n(X,"LI",{});var Aze=s(ZE);i4e=n(Aze,"STRONG",{});var RXt=s(i4e);n1r=r(RXt,"xlm-roberta-xl"),RXt.forEach(t),s1r=r(Aze," \u2014 "),kY=n(Aze,"A",{href:!0});var PXt=s(kY);l1r=r(PXt,"XLMRobertaXLForQuestionAnswering"),PXt.forEach(t),i1r=r(Aze," (XLM-RoBERTa-XL model)"),Aze.forEach(t),d1r=i(X),e4=n(X,"LI",{});var Lze=s(e4);d4e=n(Lze,"STRONG",{});var BXt=s(d4e);c1r=r(BXt,"xlnet"),BXt.forEach(t),m1r=r(Lze," \u2014 "),SY=n(Lze,"A",{href:!0});var IXt=s(SY);f1r=r(IXt,"XLNetForQuestionAnsweringSimple"),IXt.forEach(t),g1r=r(Lze," (XLNet model)"),Lze.forEach(t),h1r=i(X),o4=n(X,"LI",{});var yze=s(o4);c4e=n(yze,"STRONG",{});var NXt=s(c4e);u1r=r(NXt,"yoso"),NXt.forEach(t),p1r=r(yze," \u2014 "),RY=n(yze,"A",{href:!0});var qXt=s(RY);_1r=r(qXt,"YosoForQuestionAnswering"),qXt.forEach(t),b1r=r(yze," (YOSO model)"),yze.forEach(t),X.forEach(t),v1r=i(xa),r4=n(xa,"P",{});var xze=s(r4);F1r=r(xze,"The model is set in evaluation mode by default using "),m4e=n(xze,"CODE",{});var jXt=s(m4e);T1r=r(jXt,"model.eval()"),jXt.forEach(t),M1r=r(xze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f4e=n(xze,"CODE",{});var DXt=s(f4e);E1r=r(DXt,"model.train()"),DXt.forEach(t),xze.forEach(t),C1r=i(xa),T(t4.$$.fragment,xa),xa.forEach(t),Bl.forEach(t),HZe=i(m),Wd=n(m,"H2",{class:!0});var dro=s(Wd);a4=n(dro,"A",{id:!0,class:!0,href:!0});var GXt=s(a4);g4e=n(GXt,"SPAN",{});var OXt=s(g4e);T(p$.$$.fragment,OXt),OXt.forEach(t),GXt.forEach(t),w1r=i(dro),h4e=n(dro,"SPAN",{});var VXt=s(h4e);A1r=r(VXt,"AutoModelForTableQuestionAnswering"),VXt.forEach(t),dro.forEach(t),JZe=i(m),Xo=n(m,"DIV",{class:!0});var Il=s(Xo);T(_$.$$.fragment,Il),L1r=i(Il),Ud=n(Il,"P",{});var sie=s(Ud);y1r=r(sie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PY=n(sie,"A",{href:!0});var XXt=s(PY);x1r=r(XXt,"from_pretrained()"),XXt.forEach(t),$1r=r(sie," class method or the "),BY=n(sie,"A",{href:!0});var zXt=s(BY);k1r=r(zXt,"from_config()"),zXt.forEach(t),S1r=r(sie,` class
method.`),sie.forEach(t),R1r=i(Il),b$=n(Il,"P",{});var cro=s(b$);P1r=r(cro,"This class cannot be instantiated directly using "),u4e=n(cro,"CODE",{});var QXt=s(u4e);B1r=r(QXt,"__init__()"),QXt.forEach(t),I1r=r(cro," (throws an error)."),cro.forEach(t),N1r=i(Il),Lt=n(Il,"DIV",{class:!0});var i8=s(Lt);T(v$.$$.fragment,i8),q1r=i(i8),p4e=n(i8,"P",{});var WXt=s(p4e);j1r=r(WXt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),WXt.forEach(t),D1r=i(i8),Hd=n(i8,"P",{});var lie=s(Hd);G1r=r(lie,`Note:
Loading a model from its configuration file does `),_4e=n(lie,"STRONG",{});var UXt=s(_4e);O1r=r(UXt,"not"),UXt.forEach(t),V1r=r(lie,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(lie,"A",{href:!0});var HXt=s(IY);X1r=r(HXt,"from_pretrained()"),HXt.forEach(t),z1r=r(lie," to load the model weights."),lie.forEach(t),Q1r=i(i8),T(n4.$$.fragment,i8),i8.forEach(t),W1r=i(Il),co=n(Il,"DIV",{class:!0});var $a=s(co);T(F$.$$.fragment,$a),U1r=i($a),b4e=n($a,"P",{});var JXt=s(b4e);H1r=r(JXt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),JXt.forEach(t),J1r=i($a),sn=n($a,"P",{});var d8=s(sn);Y1r=r(d8,"The model class to instantiate is selected based on the "),v4e=n(d8,"CODE",{});var YXt=s(v4e);K1r=r(YXt,"model_type"),YXt.forEach(t),Z1r=r(d8,` property of the config object (either
passed as an argument or loaded from `),F4e=n(d8,"CODE",{});var KXt=s(F4e);evr=r(KXt,"pretrained_model_name_or_path"),KXt.forEach(t),ovr=r(d8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T4e=n(d8,"CODE",{});var ZXt=s(T4e);rvr=r(ZXt,"pretrained_model_name_or_path"),ZXt.forEach(t),tvr=r(d8,":"),d8.forEach(t),avr=i($a),M4e=n($a,"UL",{});var ezt=s(M4e);s4=n(ezt,"LI",{});var $ze=s(s4);E4e=n($ze,"STRONG",{});var ozt=s(E4e);nvr=r(ozt,"tapas"),ozt.forEach(t),svr=r($ze," \u2014 "),NY=n($ze,"A",{href:!0});var rzt=s(NY);lvr=r(rzt,"TapasForQuestionAnswering"),rzt.forEach(t),ivr=r($ze," (TAPAS model)"),$ze.forEach(t),ezt.forEach(t),dvr=i($a),l4=n($a,"P",{});var kze=s(l4);cvr=r(kze,"The model is set in evaluation mode by default using "),C4e=n(kze,"CODE",{});var tzt=s(C4e);mvr=r(tzt,"model.eval()"),tzt.forEach(t),fvr=r(kze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w4e=n(kze,"CODE",{});var azt=s(w4e);gvr=r(azt,"model.train()"),azt.forEach(t),kze.forEach(t),hvr=i($a),T(i4.$$.fragment,$a),$a.forEach(t),Il.forEach(t),YZe=i(m),Jd=n(m,"H2",{class:!0});var mro=s(Jd);d4=n(mro,"A",{id:!0,class:!0,href:!0});var nzt=s(d4);A4e=n(nzt,"SPAN",{});var szt=s(A4e);T(T$.$$.fragment,szt),szt.forEach(t),nzt.forEach(t),uvr=i(mro),L4e=n(mro,"SPAN",{});var lzt=s(L4e);pvr=r(lzt,"AutoModelForDocumentQuestionAnswering"),lzt.forEach(t),mro.forEach(t),KZe=i(m),zo=n(m,"DIV",{class:!0});var Nl=s(zo);T(M$.$$.fragment,Nl),_vr=i(Nl),Yd=n(Nl,"P",{});var iie=s(Yd);bvr=r(iie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),qY=n(iie,"A",{href:!0});var izt=s(qY);vvr=r(izt,"from_pretrained()"),izt.forEach(t),Fvr=r(iie," class method or the "),jY=n(iie,"A",{href:!0});var dzt=s(jY);Tvr=r(dzt,"from_config()"),dzt.forEach(t),Mvr=r(iie,` class
method.`),iie.forEach(t),Evr=i(Nl),E$=n(Nl,"P",{});var fro=s(E$);Cvr=r(fro,"This class cannot be instantiated directly using "),y4e=n(fro,"CODE",{});var czt=s(y4e);wvr=r(czt,"__init__()"),czt.forEach(t),Avr=r(fro," (throws an error)."),fro.forEach(t),Lvr=i(Nl),yt=n(Nl,"DIV",{class:!0});var c8=s(yt);T(C$.$$.fragment,c8),yvr=i(c8),x4e=n(c8,"P",{});var mzt=s(x4e);xvr=r(mzt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),mzt.forEach(t),$vr=i(c8),Kd=n(c8,"P",{});var die=s(Kd);kvr=r(die,`Note:
Loading a model from its configuration file does `),$4e=n(die,"STRONG",{});var fzt=s($4e);Svr=r(fzt,"not"),fzt.forEach(t),Rvr=r(die,` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=n(die,"A",{href:!0});var gzt=s(DY);Pvr=r(gzt,"from_pretrained()"),gzt.forEach(t),Bvr=r(die," to load the model weights."),die.forEach(t),Ivr=i(c8),T(c4.$$.fragment,c8),c8.forEach(t),Nvr=i(Nl),mo=n(Nl,"DIV",{class:!0});var ka=s(mo);T(w$.$$.fragment,ka),qvr=i(ka),k4e=n(ka,"P",{});var hzt=s(k4e);jvr=r(hzt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),hzt.forEach(t),Dvr=i(ka),ln=n(ka,"P",{});var m8=s(ln);Gvr=r(m8,"The model class to instantiate is selected based on the "),S4e=n(m8,"CODE",{});var uzt=s(S4e);Ovr=r(uzt,"model_type"),uzt.forEach(t),Vvr=r(m8,` property of the config object (either
passed as an argument or loaded from `),R4e=n(m8,"CODE",{});var pzt=s(R4e);Xvr=r(pzt,"pretrained_model_name_or_path"),pzt.forEach(t),zvr=r(m8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P4e=n(m8,"CODE",{});var _zt=s(P4e);Qvr=r(_zt,"pretrained_model_name_or_path"),_zt.forEach(t),Wvr=r(m8,":"),m8.forEach(t),Uvr=i(ka),Zd=n(ka,"UL",{});var cie=s(Zd);m4=n(cie,"LI",{});var Sze=s(m4);B4e=n(Sze,"STRONG",{});var bzt=s(B4e);Hvr=r(bzt,"layoutlm"),bzt.forEach(t),Jvr=r(Sze," \u2014 "),GY=n(Sze,"A",{href:!0});var vzt=s(GY);Yvr=r(vzt,"LayoutLMForQuestionAnswering"),vzt.forEach(t),Kvr=r(Sze," (LayoutLM model)"),Sze.forEach(t),Zvr=i(cie),f4=n(cie,"LI",{});var Rze=s(f4);I4e=n(Rze,"STRONG",{});var Fzt=s(I4e);eFr=r(Fzt,"layoutlmv2"),Fzt.forEach(t),oFr=r(Rze," \u2014 "),OY=n(Rze,"A",{href:!0});var Tzt=s(OY);rFr=r(Tzt,"LayoutLMv2ForQuestionAnswering"),Tzt.forEach(t),tFr=r(Rze," (LayoutLMv2 model)"),Rze.forEach(t),aFr=i(cie),g4=n(cie,"LI",{});var Pze=s(g4);N4e=n(Pze,"STRONG",{});var Mzt=s(N4e);nFr=r(Mzt,"layoutlmv3"),Mzt.forEach(t),sFr=r(Pze," \u2014 "),VY=n(Pze,"A",{href:!0});var Ezt=s(VY);lFr=r(Ezt,"LayoutLMv3ForQuestionAnswering"),Ezt.forEach(t),iFr=r(Pze," (LayoutLMv3 model)"),Pze.forEach(t),cie.forEach(t),dFr=i(ka),h4=n(ka,"P",{});var Bze=s(h4);cFr=r(Bze,"The model is set in evaluation mode by default using "),q4e=n(Bze,"CODE",{});var Czt=s(q4e);mFr=r(Czt,"model.eval()"),Czt.forEach(t),fFr=r(Bze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j4e=n(Bze,"CODE",{});var wzt=s(j4e);gFr=r(wzt,"model.train()"),wzt.forEach(t),Bze.forEach(t),hFr=i(ka),T(u4.$$.fragment,ka),ka.forEach(t),Nl.forEach(t),ZZe=i(m),ec=n(m,"H2",{class:!0});var gro=s(ec);p4=n(gro,"A",{id:!0,class:!0,href:!0});var Azt=s(p4);D4e=n(Azt,"SPAN",{});var Lzt=s(D4e);T(A$.$$.fragment,Lzt),Lzt.forEach(t),Azt.forEach(t),uFr=i(gro),G4e=n(gro,"SPAN",{});var yzt=s(G4e);pFr=r(yzt,"AutoModelForImageClassification"),yzt.forEach(t),gro.forEach(t),eeo=i(m),Qo=n(m,"DIV",{class:!0});var ql=s(Qo);T(L$.$$.fragment,ql),_Fr=i(ql),oc=n(ql,"P",{});var mie=s(oc);bFr=r(mie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),XY=n(mie,"A",{href:!0});var xzt=s(XY);vFr=r(xzt,"from_pretrained()"),xzt.forEach(t),FFr=r(mie," class method or the "),zY=n(mie,"A",{href:!0});var $zt=s(zY);TFr=r($zt,"from_config()"),$zt.forEach(t),MFr=r(mie,` class
method.`),mie.forEach(t),EFr=i(ql),y$=n(ql,"P",{});var hro=s(y$);CFr=r(hro,"This class cannot be instantiated directly using "),O4e=n(hro,"CODE",{});var kzt=s(O4e);wFr=r(kzt,"__init__()"),kzt.forEach(t),AFr=r(hro," (throws an error)."),hro.forEach(t),LFr=i(ql),xt=n(ql,"DIV",{class:!0});var f8=s(xt);T(x$.$$.fragment,f8),yFr=i(f8),V4e=n(f8,"P",{});var Szt=s(V4e);xFr=r(Szt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Szt.forEach(t),$Fr=i(f8),rc=n(f8,"P",{});var fie=s(rc);kFr=r(fie,`Note:
Loading a model from its configuration file does `),X4e=n(fie,"STRONG",{});var Rzt=s(X4e);SFr=r(Rzt,"not"),Rzt.forEach(t),RFr=r(fie,` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=n(fie,"A",{href:!0});var Pzt=s(QY);PFr=r(Pzt,"from_pretrained()"),Pzt.forEach(t),BFr=r(fie," to load the model weights."),fie.forEach(t),IFr=i(f8),T(_4.$$.fragment,f8),f8.forEach(t),NFr=i(ql),fo=n(ql,"DIV",{class:!0});var Sa=s(fo);T($$.$$.fragment,Sa),qFr=i(Sa),z4e=n(Sa,"P",{});var Bzt=s(z4e);jFr=r(Bzt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Bzt.forEach(t),DFr=i(Sa),dn=n(Sa,"P",{});var g8=s(dn);GFr=r(g8,"The model class to instantiate is selected based on the "),Q4e=n(g8,"CODE",{});var Izt=s(Q4e);OFr=r(Izt,"model_type"),Izt.forEach(t),VFr=r(g8,` property of the config object (either
passed as an argument or loaded from `),W4e=n(g8,"CODE",{});var Nzt=s(W4e);XFr=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),zFr=r(g8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U4e=n(g8,"CODE",{});var qzt=s(U4e);QFr=r(qzt,"pretrained_model_name_or_path"),qzt.forEach(t),WFr=r(g8,":"),g8.forEach(t),UFr=i(Sa),be=n(Sa,"UL",{});var Fe=s(be);b4=n(Fe,"LI",{});var Ize=s(b4);H4e=n(Ize,"STRONG",{});var jzt=s(H4e);HFr=r(jzt,"beit"),jzt.forEach(t),JFr=r(Ize," \u2014 "),WY=n(Ize,"A",{href:!0});var Dzt=s(WY);YFr=r(Dzt,"BeitForImageClassification"),Dzt.forEach(t),KFr=r(Ize," (BEiT model)"),Ize.forEach(t),ZFr=i(Fe),v4=n(Fe,"LI",{});var Nze=s(v4);J4e=n(Nze,"STRONG",{});var Gzt=s(J4e);eTr=r(Gzt,"convnext"),Gzt.forEach(t),oTr=r(Nze," \u2014 "),UY=n(Nze,"A",{href:!0});var Ozt=s(UY);rTr=r(Ozt,"ConvNextForImageClassification"),Ozt.forEach(t),tTr=r(Nze," (ConvNeXT model)"),Nze.forEach(t),aTr=i(Fe),F4=n(Fe,"LI",{});var qze=s(F4);Y4e=n(qze,"STRONG",{});var Vzt=s(Y4e);nTr=r(Vzt,"cvt"),Vzt.forEach(t),sTr=r(qze," \u2014 "),HY=n(qze,"A",{href:!0});var Xzt=s(HY);lTr=r(Xzt,"CvtForImageClassification"),Xzt.forEach(t),iTr=r(qze," (CvT model)"),qze.forEach(t),dTr=i(Fe),T4=n(Fe,"LI",{});var jze=s(T4);K4e=n(jze,"STRONG",{});var zzt=s(K4e);cTr=r(zzt,"data2vec-vision"),zzt.forEach(t),mTr=r(jze," \u2014 "),JY=n(jze,"A",{href:!0});var Qzt=s(JY);fTr=r(Qzt,"Data2VecVisionForImageClassification"),Qzt.forEach(t),gTr=r(jze," (Data2VecVision model)"),jze.forEach(t),hTr=i(Fe),bl=n(Fe,"LI",{});var XB=s(bl);Z4e=n(XB,"STRONG",{});var Wzt=s(Z4e);uTr=r(Wzt,"deit"),Wzt.forEach(t),pTr=r(XB," \u2014 "),YY=n(XB,"A",{href:!0});var Uzt=s(YY);_Tr=r(Uzt,"DeiTForImageClassification"),Uzt.forEach(t),bTr=r(XB," or "),KY=n(XB,"A",{href:!0});var Hzt=s(KY);vTr=r(Hzt,"DeiTForImageClassificationWithTeacher"),Hzt.forEach(t),FTr=r(XB," (DeiT model)"),XB.forEach(t),TTr=i(Fe),M4=n(Fe,"LI",{});var Dze=s(M4);eCe=n(Dze,"STRONG",{});var Jzt=s(eCe);MTr=r(Jzt,"imagegpt"),Jzt.forEach(t),ETr=r(Dze," \u2014 "),ZY=n(Dze,"A",{href:!0});var Yzt=s(ZY);CTr=r(Yzt,"ImageGPTForImageClassification"),Yzt.forEach(t),wTr=r(Dze," (ImageGPT model)"),Dze.forEach(t),ATr=i(Fe),vl=n(Fe,"LI",{});var zB=s(vl);oCe=n(zB,"STRONG",{});var Kzt=s(oCe);LTr=r(Kzt,"levit"),Kzt.forEach(t),yTr=r(zB," \u2014 "),eK=n(zB,"A",{href:!0});var Zzt=s(eK);xTr=r(Zzt,"LevitForImageClassification"),Zzt.forEach(t),$Tr=r(zB," or "),oK=n(zB,"A",{href:!0});var eQt=s(oK);kTr=r(eQt,"LevitForImageClassificationWithTeacher"),eQt.forEach(t),STr=r(zB," (LeViT model)"),zB.forEach(t),RTr=i(Fe),E4=n(Fe,"LI",{});var Gze=s(E4);rCe=n(Gze,"STRONG",{});var oQt=s(rCe);PTr=r(oQt,"mobilevit"),oQt.forEach(t),BTr=r(Gze," \u2014 "),rK=n(Gze,"A",{href:!0});var rQt=s(rK);ITr=r(rQt,"MobileViTForImageClassification"),rQt.forEach(t),NTr=r(Gze," (MobileViT model)"),Gze.forEach(t),qTr=i(Fe),$t=n(Fe,"LI",{});var Mf=s($t);tCe=n(Mf,"STRONG",{});var tQt=s(tCe);jTr=r(tQt,"perceiver"),tQt.forEach(t),DTr=r(Mf," \u2014 "),tK=n(Mf,"A",{href:!0});var aQt=s(tK);GTr=r(aQt,"PerceiverForImageClassificationLearned"),aQt.forEach(t),OTr=r(Mf," or "),aK=n(Mf,"A",{href:!0});var nQt=s(aK);VTr=r(nQt,"PerceiverForImageClassificationFourier"),nQt.forEach(t),XTr=r(Mf," or "),nK=n(Mf,"A",{href:!0});var sQt=s(nK);zTr=r(sQt,"PerceiverForImageClassificationConvProcessing"),sQt.forEach(t),QTr=r(Mf," (Perceiver model)"),Mf.forEach(t),WTr=i(Fe),C4=n(Fe,"LI",{});var Oze=s(C4);aCe=n(Oze,"STRONG",{});var lQt=s(aCe);UTr=r(lQt,"poolformer"),lQt.forEach(t),HTr=r(Oze," \u2014 "),sK=n(Oze,"A",{href:!0});var iQt=s(sK);JTr=r(iQt,"PoolFormerForImageClassification"),iQt.forEach(t),YTr=r(Oze," (PoolFormer model)"),Oze.forEach(t),KTr=i(Fe),w4=n(Fe,"LI",{});var Vze=s(w4);nCe=n(Vze,"STRONG",{});var dQt=s(nCe);ZTr=r(dQt,"regnet"),dQt.forEach(t),eMr=r(Vze," \u2014 "),lK=n(Vze,"A",{href:!0});var cQt=s(lK);oMr=r(cQt,"RegNetForImageClassification"),cQt.forEach(t),rMr=r(Vze," (RegNet model)"),Vze.forEach(t),tMr=i(Fe),A4=n(Fe,"LI",{});var Xze=s(A4);sCe=n(Xze,"STRONG",{});var mQt=s(sCe);aMr=r(mQt,"resnet"),mQt.forEach(t),nMr=r(Xze," \u2014 "),iK=n(Xze,"A",{href:!0});var fQt=s(iK);sMr=r(fQt,"ResNetForImageClassification"),fQt.forEach(t),lMr=r(Xze," (ResNet model)"),Xze.forEach(t),iMr=i(Fe),L4=n(Fe,"LI",{});var zze=s(L4);lCe=n(zze,"STRONG",{});var gQt=s(lCe);dMr=r(gQt,"segformer"),gQt.forEach(t),cMr=r(zze," \u2014 "),dK=n(zze,"A",{href:!0});var hQt=s(dK);mMr=r(hQt,"SegformerForImageClassification"),hQt.forEach(t),fMr=r(zze," (SegFormer model)"),zze.forEach(t),gMr=i(Fe),y4=n(Fe,"LI",{});var Qze=s(y4);iCe=n(Qze,"STRONG",{});var uQt=s(iCe);hMr=r(uQt,"swin"),uQt.forEach(t),uMr=r(Qze," \u2014 "),cK=n(Qze,"A",{href:!0});var pQt=s(cK);pMr=r(pQt,"SwinForImageClassification"),pQt.forEach(t),_Mr=r(Qze," (Swin Transformer model)"),Qze.forEach(t),bMr=i(Fe),x4=n(Fe,"LI",{});var Wze=s(x4);dCe=n(Wze,"STRONG",{});var _Qt=s(dCe);vMr=r(_Qt,"swinv2"),_Qt.forEach(t),FMr=r(Wze," \u2014 "),mK=n(Wze,"A",{href:!0});var bQt=s(mK);TMr=r(bQt,"Swinv2ForImageClassification"),bQt.forEach(t),MMr=r(Wze," (Swin Transformer V2 model)"),Wze.forEach(t),EMr=i(Fe),$4=n(Fe,"LI",{});var Uze=s($4);cCe=n(Uze,"STRONG",{});var vQt=s(cCe);CMr=r(vQt,"van"),vQt.forEach(t),wMr=r(Uze," \u2014 "),fK=n(Uze,"A",{href:!0});var FQt=s(fK);AMr=r(FQt,"VanForImageClassification"),FQt.forEach(t),LMr=r(Uze," (VAN model)"),Uze.forEach(t),yMr=i(Fe),k4=n(Fe,"LI",{});var Hze=s(k4);mCe=n(Hze,"STRONG",{});var TQt=s(mCe);xMr=r(TQt,"vit"),TQt.forEach(t),$Mr=r(Hze," \u2014 "),gK=n(Hze,"A",{href:!0});var MQt=s(gK);kMr=r(MQt,"ViTForImageClassification"),MQt.forEach(t),SMr=r(Hze," (ViT model)"),Hze.forEach(t),RMr=i(Fe),S4=n(Fe,"LI",{});var Jze=s(S4);fCe=n(Jze,"STRONG",{});var EQt=s(fCe);PMr=r(EQt,"vit_msn"),EQt.forEach(t),BMr=r(Jze," \u2014 "),hK=n(Jze,"A",{href:!0});var CQt=s(hK);IMr=r(CQt,"ViTMSNForImageClassification"),CQt.forEach(t),NMr=r(Jze," (ViTMSN model)"),Jze.forEach(t),Fe.forEach(t),qMr=i(Sa),R4=n(Sa,"P",{});var Yze=s(R4);jMr=r(Yze,"The model is set in evaluation mode by default using "),gCe=n(Yze,"CODE",{});var wQt=s(gCe);DMr=r(wQt,"model.eval()"),wQt.forEach(t),GMr=r(Yze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hCe=n(Yze,"CODE",{});var AQt=s(hCe);OMr=r(AQt,"model.train()"),AQt.forEach(t),Yze.forEach(t),VMr=i(Sa),T(P4.$$.fragment,Sa),Sa.forEach(t),ql.forEach(t),oeo=i(m),tc=n(m,"H2",{class:!0});var uro=s(tc);B4=n(uro,"A",{id:!0,class:!0,href:!0});var LQt=s(B4);uCe=n(LQt,"SPAN",{});var yQt=s(uCe);T(k$.$$.fragment,yQt),yQt.forEach(t),LQt.forEach(t),XMr=i(uro),pCe=n(uro,"SPAN",{});var xQt=s(pCe);zMr=r(xQt,"AutoModelForVideoClassification"),xQt.forEach(t),uro.forEach(t),reo=i(m),Wo=n(m,"DIV",{class:!0});var jl=s(Wo);T(S$.$$.fragment,jl),QMr=i(jl),ac=n(jl,"P",{});var gie=s(ac);WMr=r(gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),uK=n(gie,"A",{href:!0});var $Qt=s(uK);UMr=r($Qt,"from_pretrained()"),$Qt.forEach(t),HMr=r(gie," class method or the "),pK=n(gie,"A",{href:!0});var kQt=s(pK);JMr=r(kQt,"from_config()"),kQt.forEach(t),YMr=r(gie,` class
method.`),gie.forEach(t),KMr=i(jl),R$=n(jl,"P",{});var pro=s(R$);ZMr=r(pro,"This class cannot be instantiated directly using "),_Ce=n(pro,"CODE",{});var SQt=s(_Ce);eEr=r(SQt,"__init__()"),SQt.forEach(t),oEr=r(pro," (throws an error)."),pro.forEach(t),rEr=i(jl),kt=n(jl,"DIV",{class:!0});var h8=s(kt);T(P$.$$.fragment,h8),tEr=i(h8),bCe=n(h8,"P",{});var RQt=s(bCe);aEr=r(RQt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),RQt.forEach(t),nEr=i(h8),nc=n(h8,"P",{});var hie=s(nc);sEr=r(hie,`Note:
Loading a model from its configuration file does `),vCe=n(hie,"STRONG",{});var PQt=s(vCe);lEr=r(PQt,"not"),PQt.forEach(t),iEr=r(hie,` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=n(hie,"A",{href:!0});var BQt=s(_K);dEr=r(BQt,"from_pretrained()"),BQt.forEach(t),cEr=r(hie," to load the model weights."),hie.forEach(t),mEr=i(h8),T(I4.$$.fragment,h8),h8.forEach(t),fEr=i(jl),go=n(jl,"DIV",{class:!0});var Ra=s(go);T(B$.$$.fragment,Ra),gEr=i(Ra),FCe=n(Ra,"P",{});var IQt=s(FCe);hEr=r(IQt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),IQt.forEach(t),uEr=i(Ra),cn=n(Ra,"P",{});var u8=s(cn);pEr=r(u8,"The model class to instantiate is selected based on the "),TCe=n(u8,"CODE",{});var NQt=s(TCe);_Er=r(NQt,"model_type"),NQt.forEach(t),bEr=r(u8,` property of the config object (either
passed as an argument or loaded from `),MCe=n(u8,"CODE",{});var qQt=s(MCe);vEr=r(qQt,"pretrained_model_name_or_path"),qQt.forEach(t),FEr=r(u8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ECe=n(u8,"CODE",{});var jQt=s(ECe);TEr=r(jQt,"pretrained_model_name_or_path"),jQt.forEach(t),MEr=r(u8,":"),u8.forEach(t),EEr=i(Ra),CCe=n(Ra,"UL",{});var DQt=s(CCe);N4=n(DQt,"LI",{});var Kze=s(N4);wCe=n(Kze,"STRONG",{});var GQt=s(wCe);CEr=r(GQt,"videomae"),GQt.forEach(t),wEr=r(Kze," \u2014 "),bK=n(Kze,"A",{href:!0});var OQt=s(bK);AEr=r(OQt,"VideoMAEForVideoClassification"),OQt.forEach(t),LEr=r(Kze," (VideoMAE model)"),Kze.forEach(t),DQt.forEach(t),yEr=i(Ra),q4=n(Ra,"P",{});var Zze=s(q4);xEr=r(Zze,"The model is set in evaluation mode by default using "),ACe=n(Zze,"CODE",{});var VQt=s(ACe);$Er=r(VQt,"model.eval()"),VQt.forEach(t),kEr=r(Zze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LCe=n(Zze,"CODE",{});var XQt=s(LCe);SEr=r(XQt,"model.train()"),XQt.forEach(t),Zze.forEach(t),REr=i(Ra),T(j4.$$.fragment,Ra),Ra.forEach(t),jl.forEach(t),teo=i(m),sc=n(m,"H2",{class:!0});var _ro=s(sc);D4=n(_ro,"A",{id:!0,class:!0,href:!0});var zQt=s(D4);yCe=n(zQt,"SPAN",{});var QQt=s(yCe);T(I$.$$.fragment,QQt),QQt.forEach(t),zQt.forEach(t),PEr=i(_ro),xCe=n(_ro,"SPAN",{});var WQt=s(xCe);BEr=r(WQt,"AutoModelForVision2Seq"),WQt.forEach(t),_ro.forEach(t),aeo=i(m),Uo=n(m,"DIV",{class:!0});var Dl=s(Uo);T(N$.$$.fragment,Dl),IEr=i(Dl),lc=n(Dl,"P",{});var uie=s(lc);NEr=r(uie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vK=n(uie,"A",{href:!0});var UQt=s(vK);qEr=r(UQt,"from_pretrained()"),UQt.forEach(t),jEr=r(uie," class method or the "),FK=n(uie,"A",{href:!0});var HQt=s(FK);DEr=r(HQt,"from_config()"),HQt.forEach(t),GEr=r(uie,` class
method.`),uie.forEach(t),OEr=i(Dl),q$=n(Dl,"P",{});var bro=s(q$);VEr=r(bro,"This class cannot be instantiated directly using "),$Ce=n(bro,"CODE",{});var JQt=s($Ce);XEr=r(JQt,"__init__()"),JQt.forEach(t),zEr=r(bro," (throws an error)."),bro.forEach(t),QEr=i(Dl),St=n(Dl,"DIV",{class:!0});var p8=s(St);T(j$.$$.fragment,p8),WEr=i(p8),kCe=n(p8,"P",{});var YQt=s(kCe);UEr=r(YQt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),YQt.forEach(t),HEr=i(p8),ic=n(p8,"P",{});var pie=s(ic);JEr=r(pie,`Note:
Loading a model from its configuration file does `),SCe=n(pie,"STRONG",{});var KQt=s(SCe);YEr=r(KQt,"not"),KQt.forEach(t),KEr=r(pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),TK=n(pie,"A",{href:!0});var ZQt=s(TK);ZEr=r(ZQt,"from_pretrained()"),ZQt.forEach(t),e4r=r(pie," to load the model weights."),pie.forEach(t),o4r=i(p8),T(G4.$$.fragment,p8),p8.forEach(t),r4r=i(Dl),ho=n(Dl,"DIV",{class:!0});var Pa=s(ho);T(D$.$$.fragment,Pa),t4r=i(Pa),RCe=n(Pa,"P",{});var eWt=s(RCe);a4r=r(eWt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),eWt.forEach(t),n4r=i(Pa),mn=n(Pa,"P",{});var _8=s(mn);s4r=r(_8,"The model class to instantiate is selected based on the "),PCe=n(_8,"CODE",{});var oWt=s(PCe);l4r=r(oWt,"model_type"),oWt.forEach(t),i4r=r(_8,` property of the config object (either
passed as an argument or loaded from `),BCe=n(_8,"CODE",{});var rWt=s(BCe);d4r=r(rWt,"pretrained_model_name_or_path"),rWt.forEach(t),c4r=r(_8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ICe=n(_8,"CODE",{});var tWt=s(ICe);m4r=r(tWt,"pretrained_model_name_or_path"),tWt.forEach(t),f4r=r(_8,":"),_8.forEach(t),g4r=i(Pa),NCe=n(Pa,"UL",{});var aWt=s(NCe);O4=n(aWt,"LI",{});var eQe=s(O4);qCe=n(eQe,"STRONG",{});var nWt=s(qCe);h4r=r(nWt,"vision-encoder-decoder"),nWt.forEach(t),u4r=r(eQe," \u2014 "),MK=n(eQe,"A",{href:!0});var sWt=s(MK);p4r=r(sWt,"VisionEncoderDecoderModel"),sWt.forEach(t),_4r=r(eQe," (Vision Encoder decoder model)"),eQe.forEach(t),aWt.forEach(t),b4r=i(Pa),V4=n(Pa,"P",{});var oQe=s(V4);v4r=r(oQe,"The model is set in evaluation mode by default using "),jCe=n(oQe,"CODE",{});var lWt=s(jCe);F4r=r(lWt,"model.eval()"),lWt.forEach(t),T4r=r(oQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DCe=n(oQe,"CODE",{});var iWt=s(DCe);M4r=r(iWt,"model.train()"),iWt.forEach(t),oQe.forEach(t),E4r=i(Pa),T(X4.$$.fragment,Pa),Pa.forEach(t),Dl.forEach(t),neo=i(m),dc=n(m,"H2",{class:!0});var vro=s(dc);z4=n(vro,"A",{id:!0,class:!0,href:!0});var dWt=s(z4);GCe=n(dWt,"SPAN",{});var cWt=s(GCe);T(G$.$$.fragment,cWt),cWt.forEach(t),dWt.forEach(t),C4r=i(vro),OCe=n(vro,"SPAN",{});var mWt=s(OCe);w4r=r(mWt,"AutoModelForVisualQuestionAnswering"),mWt.forEach(t),vro.forEach(t),seo=i(m),Ho=n(m,"DIV",{class:!0});var Gl=s(Ho);T(O$.$$.fragment,Gl),A4r=i(Gl),cc=n(Gl,"P",{});var _ie=s(cc);L4r=r(_ie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),EK=n(_ie,"A",{href:!0});var fWt=s(EK);y4r=r(fWt,"from_pretrained()"),fWt.forEach(t),x4r=r(_ie," class method or the "),CK=n(_ie,"A",{href:!0});var gWt=s(CK);$4r=r(gWt,"from_config()"),gWt.forEach(t),k4r=r(_ie,` class
method.`),_ie.forEach(t),S4r=i(Gl),V$=n(Gl,"P",{});var Fro=s(V$);R4r=r(Fro,"This class cannot be instantiated directly using "),VCe=n(Fro,"CODE",{});var hWt=s(VCe);P4r=r(hWt,"__init__()"),hWt.forEach(t),B4r=r(Fro," (throws an error)."),Fro.forEach(t),I4r=i(Gl),Rt=n(Gl,"DIV",{class:!0});var b8=s(Rt);T(X$.$$.fragment,b8),N4r=i(b8),XCe=n(b8,"P",{});var uWt=s(XCe);q4r=r(uWt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),uWt.forEach(t),j4r=i(b8),mc=n(b8,"P",{});var bie=s(mc);D4r=r(bie,`Note:
Loading a model from its configuration file does `),zCe=n(bie,"STRONG",{});var pWt=s(zCe);G4r=r(pWt,"not"),pWt.forEach(t),O4r=r(bie,` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=n(bie,"A",{href:!0});var _Wt=s(wK);V4r=r(_Wt,"from_pretrained()"),_Wt.forEach(t),X4r=r(bie," to load the model weights."),bie.forEach(t),z4r=i(b8),T(Q4.$$.fragment,b8),b8.forEach(t),Q4r=i(Gl),uo=n(Gl,"DIV",{class:!0});var Ba=s(uo);T(z$.$$.fragment,Ba),W4r=i(Ba),QCe=n(Ba,"P",{});var bWt=s(QCe);U4r=r(bWt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),bWt.forEach(t),H4r=i(Ba),fn=n(Ba,"P",{});var v8=s(fn);J4r=r(v8,"The model class to instantiate is selected based on the "),WCe=n(v8,"CODE",{});var vWt=s(WCe);Y4r=r(vWt,"model_type"),vWt.forEach(t),K4r=r(v8,` property of the config object (either
passed as an argument or loaded from `),UCe=n(v8,"CODE",{});var FWt=s(UCe);Z4r=r(FWt,"pretrained_model_name_or_path"),FWt.forEach(t),eCr=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HCe=n(v8,"CODE",{});var TWt=s(HCe);oCr=r(TWt,"pretrained_model_name_or_path"),TWt.forEach(t),rCr=r(v8,":"),v8.forEach(t),tCr=i(Ba),JCe=n(Ba,"UL",{});var MWt=s(JCe);W4=n(MWt,"LI",{});var rQe=s(W4);YCe=n(rQe,"STRONG",{});var EWt=s(YCe);aCr=r(EWt,"vilt"),EWt.forEach(t),nCr=r(rQe," \u2014 "),AK=n(rQe,"A",{href:!0});var CWt=s(AK);sCr=r(CWt,"ViltForQuestionAnswering"),CWt.forEach(t),lCr=r(rQe," (ViLT model)"),rQe.forEach(t),MWt.forEach(t),iCr=i(Ba),U4=n(Ba,"P",{});var tQe=s(U4);dCr=r(tQe,"The model is set in evaluation mode by default using "),KCe=n(tQe,"CODE",{});var wWt=s(KCe);cCr=r(wWt,"model.eval()"),wWt.forEach(t),mCr=r(tQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZCe=n(tQe,"CODE",{});var AWt=s(ZCe);fCr=r(AWt,"model.train()"),AWt.forEach(t),tQe.forEach(t),gCr=i(Ba),T(H4.$$.fragment,Ba),Ba.forEach(t),Gl.forEach(t),leo=i(m),fc=n(m,"H2",{class:!0});var Tro=s(fc);J4=n(Tro,"A",{id:!0,class:!0,href:!0});var LWt=s(J4);e3e=n(LWt,"SPAN",{});var yWt=s(e3e);T(Q$.$$.fragment,yWt),yWt.forEach(t),LWt.forEach(t),hCr=i(Tro),o3e=n(Tro,"SPAN",{});var xWt=s(o3e);uCr=r(xWt,"AutoModelForAudioClassification"),xWt.forEach(t),Tro.forEach(t),ieo=i(m),Jo=n(m,"DIV",{class:!0});var Ol=s(Jo);T(W$.$$.fragment,Ol),pCr=i(Ol),gc=n(Ol,"P",{});var vie=s(gc);_Cr=r(vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),LK=n(vie,"A",{href:!0});var $Wt=s(LK);bCr=r($Wt,"from_pretrained()"),$Wt.forEach(t),vCr=r(vie," class method or the "),yK=n(vie,"A",{href:!0});var kWt=s(yK);FCr=r(kWt,"from_config()"),kWt.forEach(t),TCr=r(vie,` class
method.`),vie.forEach(t),MCr=i(Ol),U$=n(Ol,"P",{});var Mro=s(U$);ECr=r(Mro,"This class cannot be instantiated directly using "),r3e=n(Mro,"CODE",{});var SWt=s(r3e);CCr=r(SWt,"__init__()"),SWt.forEach(t),wCr=r(Mro," (throws an error)."),Mro.forEach(t),ACr=i(Ol),Pt=n(Ol,"DIV",{class:!0});var F8=s(Pt);T(H$.$$.fragment,F8),LCr=i(F8),t3e=n(F8,"P",{});var RWt=s(t3e);yCr=r(RWt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),RWt.forEach(t),xCr=i(F8),hc=n(F8,"P",{});var Fie=s(hc);$Cr=r(Fie,`Note:
Loading a model from its configuration file does `),a3e=n(Fie,"STRONG",{});var PWt=s(a3e);kCr=r(PWt,"not"),PWt.forEach(t),SCr=r(Fie,` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=n(Fie,"A",{href:!0});var BWt=s(xK);RCr=r(BWt,"from_pretrained()"),BWt.forEach(t),PCr=r(Fie," to load the model weights."),Fie.forEach(t),BCr=i(F8),T(Y4.$$.fragment,F8),F8.forEach(t),ICr=i(Ol),po=n(Ol,"DIV",{class:!0});var Ia=s(po);T(J$.$$.fragment,Ia),NCr=i(Ia),n3e=n(Ia,"P",{});var IWt=s(n3e);qCr=r(IWt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),IWt.forEach(t),jCr=i(Ia),gn=n(Ia,"P",{});var T8=s(gn);DCr=r(T8,"The model class to instantiate is selected based on the "),s3e=n(T8,"CODE",{});var NWt=s(s3e);GCr=r(NWt,"model_type"),NWt.forEach(t),OCr=r(T8,` property of the config object (either
passed as an argument or loaded from `),l3e=n(T8,"CODE",{});var qWt=s(l3e);VCr=r(qWt,"pretrained_model_name_or_path"),qWt.forEach(t),XCr=r(T8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i3e=n(T8,"CODE",{});var jWt=s(i3e);zCr=r(jWt,"pretrained_model_name_or_path"),jWt.forEach(t),QCr=r(T8,":"),T8.forEach(t),WCr=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);K4=n(Qe,"LI",{});var aQe=s(K4);d3e=n(aQe,"STRONG",{});var DWt=s(d3e);UCr=r(DWt,"data2vec-audio"),DWt.forEach(t),HCr=r(aQe," \u2014 "),$K=n(aQe,"A",{href:!0});var GWt=s($K);JCr=r(GWt,"Data2VecAudioForSequenceClassification"),GWt.forEach(t),YCr=r(aQe," (Data2VecAudio model)"),aQe.forEach(t),KCr=i(Qe),Z4=n(Qe,"LI",{});var nQe=s(Z4);c3e=n(nQe,"STRONG",{});var OWt=s(c3e);ZCr=r(OWt,"hubert"),OWt.forEach(t),e3r=r(nQe," \u2014 "),kK=n(nQe,"A",{href:!0});var VWt=s(kK);o3r=r(VWt,"HubertForSequenceClassification"),VWt.forEach(t),r3r=r(nQe," (Hubert model)"),nQe.forEach(t),t3r=i(Qe),eC=n(Qe,"LI",{});var sQe=s(eC);m3e=n(sQe,"STRONG",{});var XWt=s(m3e);a3r=r(XWt,"sew"),XWt.forEach(t),n3r=r(sQe," \u2014 "),SK=n(sQe,"A",{href:!0});var zWt=s(SK);s3r=r(zWt,"SEWForSequenceClassification"),zWt.forEach(t),l3r=r(sQe," (SEW model)"),sQe.forEach(t),i3r=i(Qe),oC=n(Qe,"LI",{});var lQe=s(oC);f3e=n(lQe,"STRONG",{});var QWt=s(f3e);d3r=r(QWt,"sew-d"),QWt.forEach(t),c3r=r(lQe," \u2014 "),RK=n(lQe,"A",{href:!0});var WWt=s(RK);m3r=r(WWt,"SEWDForSequenceClassification"),WWt.forEach(t),f3r=r(lQe," (SEW-D model)"),lQe.forEach(t),g3r=i(Qe),rC=n(Qe,"LI",{});var iQe=s(rC);g3e=n(iQe,"STRONG",{});var UWt=s(g3e);h3r=r(UWt,"unispeech"),UWt.forEach(t),u3r=r(iQe," \u2014 "),PK=n(iQe,"A",{href:!0});var HWt=s(PK);p3r=r(HWt,"UniSpeechForSequenceClassification"),HWt.forEach(t),_3r=r(iQe," (UniSpeech model)"),iQe.forEach(t),b3r=i(Qe),tC=n(Qe,"LI",{});var dQe=s(tC);h3e=n(dQe,"STRONG",{});var JWt=s(h3e);v3r=r(JWt,"unispeech-sat"),JWt.forEach(t),F3r=r(dQe," \u2014 "),BK=n(dQe,"A",{href:!0});var YWt=s(BK);T3r=r(YWt,"UniSpeechSatForSequenceClassification"),YWt.forEach(t),M3r=r(dQe," (UniSpeechSat model)"),dQe.forEach(t),E3r=i(Qe),aC=n(Qe,"LI",{});var cQe=s(aC);u3e=n(cQe,"STRONG",{});var KWt=s(u3e);C3r=r(KWt,"wav2vec2"),KWt.forEach(t),w3r=r(cQe," \u2014 "),IK=n(cQe,"A",{href:!0});var ZWt=s(IK);A3r=r(ZWt,"Wav2Vec2ForSequenceClassification"),ZWt.forEach(t),L3r=r(cQe," (Wav2Vec2 model)"),cQe.forEach(t),y3r=i(Qe),nC=n(Qe,"LI",{});var mQe=s(nC);p3e=n(mQe,"STRONG",{});var eUt=s(p3e);x3r=r(eUt,"wav2vec2-conformer"),eUt.forEach(t),$3r=r(mQe," \u2014 "),NK=n(mQe,"A",{href:!0});var oUt=s(NK);k3r=r(oUt,"Wav2Vec2ConformerForSequenceClassification"),oUt.forEach(t),S3r=r(mQe," (Wav2Vec2-Conformer model)"),mQe.forEach(t),R3r=i(Qe),sC=n(Qe,"LI",{});var fQe=s(sC);_3e=n(fQe,"STRONG",{});var rUt=s(_3e);P3r=r(rUt,"wavlm"),rUt.forEach(t),B3r=r(fQe," \u2014 "),qK=n(fQe,"A",{href:!0});var tUt=s(qK);I3r=r(tUt,"WavLMForSequenceClassification"),tUt.forEach(t),N3r=r(fQe," (WavLM model)"),fQe.forEach(t),Qe.forEach(t),q3r=i(Ia),lC=n(Ia,"P",{});var gQe=s(lC);j3r=r(gQe,"The model is set in evaluation mode by default using "),b3e=n(gQe,"CODE",{});var aUt=s(b3e);D3r=r(aUt,"model.eval()"),aUt.forEach(t),G3r=r(gQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v3e=n(gQe,"CODE",{});var nUt=s(v3e);O3r=r(nUt,"model.train()"),nUt.forEach(t),gQe.forEach(t),V3r=i(Ia),T(iC.$$.fragment,Ia),Ia.forEach(t),Ol.forEach(t),deo=i(m),uc=n(m,"H2",{class:!0});var Ero=s(uc);dC=n(Ero,"A",{id:!0,class:!0,href:!0});var sUt=s(dC);F3e=n(sUt,"SPAN",{});var lUt=s(F3e);T(Y$.$$.fragment,lUt),lUt.forEach(t),sUt.forEach(t),X3r=i(Ero),T3e=n(Ero,"SPAN",{});var iUt=s(T3e);z3r=r(iUt,"AutoModelForAudioFrameClassification"),iUt.forEach(t),Ero.forEach(t),ceo=i(m),Yo=n(m,"DIV",{class:!0});var Vl=s(Yo);T(K$.$$.fragment,Vl),Q3r=i(Vl),pc=n(Vl,"P",{});var Tie=s(pc);W3r=r(Tie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),jK=n(Tie,"A",{href:!0});var dUt=s(jK);U3r=r(dUt,"from_pretrained()"),dUt.forEach(t),H3r=r(Tie," class method or the "),DK=n(Tie,"A",{href:!0});var cUt=s(DK);J3r=r(cUt,"from_config()"),cUt.forEach(t),Y3r=r(Tie,` class
method.`),Tie.forEach(t),K3r=i(Vl),Z$=n(Vl,"P",{});var Cro=s(Z$);Z3r=r(Cro,"This class cannot be instantiated directly using "),M3e=n(Cro,"CODE",{});var mUt=s(M3e);e5r=r(mUt,"__init__()"),mUt.forEach(t),o5r=r(Cro," (throws an error)."),Cro.forEach(t),r5r=i(Vl),Bt=n(Vl,"DIV",{class:!0});var M8=s(Bt);T(ek.$$.fragment,M8),t5r=i(M8),E3e=n(M8,"P",{});var fUt=s(E3e);a5r=r(fUt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),fUt.forEach(t),n5r=i(M8),_c=n(M8,"P",{});var Mie=s(_c);s5r=r(Mie,`Note:
Loading a model from its configuration file does `),C3e=n(Mie,"STRONG",{});var gUt=s(C3e);l5r=r(gUt,"not"),gUt.forEach(t),i5r=r(Mie,` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=n(Mie,"A",{href:!0});var hUt=s(GK);d5r=r(hUt,"from_pretrained()"),hUt.forEach(t),c5r=r(Mie," to load the model weights."),Mie.forEach(t),m5r=i(M8),T(cC.$$.fragment,M8),M8.forEach(t),f5r=i(Vl),_o=n(Vl,"DIV",{class:!0});var Na=s(_o);T(ok.$$.fragment,Na),g5r=i(Na),w3e=n(Na,"P",{});var uUt=s(w3e);h5r=r(uUt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),uUt.forEach(t),u5r=i(Na),hn=n(Na,"P",{});var E8=s(hn);p5r=r(E8,"The model class to instantiate is selected based on the "),A3e=n(E8,"CODE",{});var pUt=s(A3e);_5r=r(pUt,"model_type"),pUt.forEach(t),b5r=r(E8,` property of the config object (either
passed as an argument or loaded from `),L3e=n(E8,"CODE",{});var _Ut=s(L3e);v5r=r(_Ut,"pretrained_model_name_or_path"),_Ut.forEach(t),F5r=r(E8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y3e=n(E8,"CODE",{});var bUt=s(y3e);T5r=r(bUt,"pretrained_model_name_or_path"),bUt.forEach(t),M5r=r(E8,":"),E8.forEach(t),E5r=i(Na),mt=n(Na,"UL",{});var Xl=s(mt);mC=n(Xl,"LI",{});var hQe=s(mC);x3e=n(hQe,"STRONG",{});var vUt=s(x3e);C5r=r(vUt,"data2vec-audio"),vUt.forEach(t),w5r=r(hQe," \u2014 "),OK=n(hQe,"A",{href:!0});var FUt=s(OK);A5r=r(FUt,"Data2VecAudioForAudioFrameClassification"),FUt.forEach(t),L5r=r(hQe," (Data2VecAudio model)"),hQe.forEach(t),y5r=i(Xl),fC=n(Xl,"LI",{});var uQe=s(fC);$3e=n(uQe,"STRONG",{});var TUt=s($3e);x5r=r(TUt,"unispeech-sat"),TUt.forEach(t),$5r=r(uQe," \u2014 "),VK=n(uQe,"A",{href:!0});var MUt=s(VK);k5r=r(MUt,"UniSpeechSatForAudioFrameClassification"),MUt.forEach(t),S5r=r(uQe," (UniSpeechSat model)"),uQe.forEach(t),R5r=i(Xl),gC=n(Xl,"LI",{});var pQe=s(gC);k3e=n(pQe,"STRONG",{});var EUt=s(k3e);P5r=r(EUt,"wav2vec2"),EUt.forEach(t),B5r=r(pQe," \u2014 "),XK=n(pQe,"A",{href:!0});var CUt=s(XK);I5r=r(CUt,"Wav2Vec2ForAudioFrameClassification"),CUt.forEach(t),N5r=r(pQe," (Wav2Vec2 model)"),pQe.forEach(t),q5r=i(Xl),hC=n(Xl,"LI",{});var _Qe=s(hC);S3e=n(_Qe,"STRONG",{});var wUt=s(S3e);j5r=r(wUt,"wav2vec2-conformer"),wUt.forEach(t),D5r=r(_Qe," \u2014 "),zK=n(_Qe,"A",{href:!0});var AUt=s(zK);G5r=r(AUt,"Wav2Vec2ConformerForAudioFrameClassification"),AUt.forEach(t),O5r=r(_Qe," (Wav2Vec2-Conformer model)"),_Qe.forEach(t),V5r=i(Xl),uC=n(Xl,"LI",{});var bQe=s(uC);R3e=n(bQe,"STRONG",{});var LUt=s(R3e);X5r=r(LUt,"wavlm"),LUt.forEach(t),z5r=r(bQe," \u2014 "),QK=n(bQe,"A",{href:!0});var yUt=s(QK);Q5r=r(yUt,"WavLMForAudioFrameClassification"),yUt.forEach(t),W5r=r(bQe," (WavLM model)"),bQe.forEach(t),Xl.forEach(t),U5r=i(Na),pC=n(Na,"P",{});var vQe=s(pC);H5r=r(vQe,"The model is set in evaluation mode by default using "),P3e=n(vQe,"CODE",{});var xUt=s(P3e);J5r=r(xUt,"model.eval()"),xUt.forEach(t),Y5r=r(vQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B3e=n(vQe,"CODE",{});var $Ut=s(B3e);K5r=r($Ut,"model.train()"),$Ut.forEach(t),vQe.forEach(t),Z5r=i(Na),T(_C.$$.fragment,Na),Na.forEach(t),Vl.forEach(t),meo=i(m),bc=n(m,"H2",{class:!0});var wro=s(bc);bC=n(wro,"A",{id:!0,class:!0,href:!0});var kUt=s(bC);I3e=n(kUt,"SPAN",{});var SUt=s(I3e);T(rk.$$.fragment,SUt),SUt.forEach(t),kUt.forEach(t),e0r=i(wro),N3e=n(wro,"SPAN",{});var RUt=s(N3e);o0r=r(RUt,"AutoModelForCTC"),RUt.forEach(t),wro.forEach(t),feo=i(m),Ko=n(m,"DIV",{class:!0});var zl=s(Ko);T(tk.$$.fragment,zl),r0r=i(zl),vc=n(zl,"P",{});var Eie=s(vc);t0r=r(Eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),WK=n(Eie,"A",{href:!0});var PUt=s(WK);a0r=r(PUt,"from_pretrained()"),PUt.forEach(t),n0r=r(Eie," class method or the "),UK=n(Eie,"A",{href:!0});var BUt=s(UK);s0r=r(BUt,"from_config()"),BUt.forEach(t),l0r=r(Eie,` class
method.`),Eie.forEach(t),i0r=i(zl),ak=n(zl,"P",{});var Aro=s(ak);d0r=r(Aro,"This class cannot be instantiated directly using "),q3e=n(Aro,"CODE",{});var IUt=s(q3e);c0r=r(IUt,"__init__()"),IUt.forEach(t),m0r=r(Aro," (throws an error)."),Aro.forEach(t),f0r=i(zl),It=n(zl,"DIV",{class:!0});var C8=s(It);T(nk.$$.fragment,C8),g0r=i(C8),j3e=n(C8,"P",{});var NUt=s(j3e);h0r=r(NUt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),NUt.forEach(t),u0r=i(C8),Fc=n(C8,"P",{});var Cie=s(Fc);p0r=r(Cie,`Note:
Loading a model from its configuration file does `),D3e=n(Cie,"STRONG",{});var qUt=s(D3e);_0r=r(qUt,"not"),qUt.forEach(t),b0r=r(Cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),HK=n(Cie,"A",{href:!0});var jUt=s(HK);v0r=r(jUt,"from_pretrained()"),jUt.forEach(t),F0r=r(Cie," to load the model weights."),Cie.forEach(t),T0r=i(C8),T(vC.$$.fragment,C8),C8.forEach(t),M0r=i(zl),bo=n(zl,"DIV",{class:!0});var qa=s(bo);T(sk.$$.fragment,qa),E0r=i(qa),G3e=n(qa,"P",{});var DUt=s(G3e);C0r=r(DUt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),DUt.forEach(t),w0r=i(qa),un=n(qa,"P",{});var w8=s(un);A0r=r(w8,"The model class to instantiate is selected based on the "),O3e=n(w8,"CODE",{});var GUt=s(O3e);L0r=r(GUt,"model_type"),GUt.forEach(t),y0r=r(w8,` property of the config object (either
passed as an argument or loaded from `),V3e=n(w8,"CODE",{});var OUt=s(V3e);x0r=r(OUt,"pretrained_model_name_or_path"),OUt.forEach(t),$0r=r(w8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X3e=n(w8,"CODE",{});var VUt=s(X3e);k0r=r(VUt,"pretrained_model_name_or_path"),VUt.forEach(t),S0r=r(w8,":"),w8.forEach(t),R0r=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);FC=n(Ie,"LI",{});var FQe=s(FC);z3e=n(FQe,"STRONG",{});var XUt=s(z3e);P0r=r(XUt,"data2vec-audio"),XUt.forEach(t),B0r=r(FQe," \u2014 "),JK=n(FQe,"A",{href:!0});var zUt=s(JK);I0r=r(zUt,"Data2VecAudioForCTC"),zUt.forEach(t),N0r=r(FQe," (Data2VecAudio model)"),FQe.forEach(t),q0r=i(Ie),TC=n(Ie,"LI",{});var TQe=s(TC);Q3e=n(TQe,"STRONG",{});var QUt=s(Q3e);j0r=r(QUt,"hubert"),QUt.forEach(t),D0r=r(TQe," \u2014 "),YK=n(TQe,"A",{href:!0});var WUt=s(YK);G0r=r(WUt,"HubertForCTC"),WUt.forEach(t),O0r=r(TQe," (Hubert model)"),TQe.forEach(t),V0r=i(Ie),MC=n(Ie,"LI",{});var MQe=s(MC);W3e=n(MQe,"STRONG",{});var UUt=s(W3e);X0r=r(UUt,"mctct"),UUt.forEach(t),z0r=r(MQe," \u2014 "),KK=n(MQe,"A",{href:!0});var HUt=s(KK);Q0r=r(HUt,"MCTCTForCTC"),HUt.forEach(t),W0r=r(MQe," (M-CTC-T model)"),MQe.forEach(t),U0r=i(Ie),EC=n(Ie,"LI",{});var EQe=s(EC);U3e=n(EQe,"STRONG",{});var JUt=s(U3e);H0r=r(JUt,"sew"),JUt.forEach(t),J0r=r(EQe," \u2014 "),ZK=n(EQe,"A",{href:!0});var YUt=s(ZK);Y0r=r(YUt,"SEWForCTC"),YUt.forEach(t),K0r=r(EQe," (SEW model)"),EQe.forEach(t),Z0r=i(Ie),CC=n(Ie,"LI",{});var CQe=s(CC);H3e=n(CQe,"STRONG",{});var KUt=s(H3e);ewr=r(KUt,"sew-d"),KUt.forEach(t),owr=r(CQe," \u2014 "),eZ=n(CQe,"A",{href:!0});var ZUt=s(eZ);rwr=r(ZUt,"SEWDForCTC"),ZUt.forEach(t),twr=r(CQe," (SEW-D model)"),CQe.forEach(t),awr=i(Ie),wC=n(Ie,"LI",{});var wQe=s(wC);J3e=n(wQe,"STRONG",{});var eHt=s(J3e);nwr=r(eHt,"unispeech"),eHt.forEach(t),swr=r(wQe," \u2014 "),oZ=n(wQe,"A",{href:!0});var oHt=s(oZ);lwr=r(oHt,"UniSpeechForCTC"),oHt.forEach(t),iwr=r(wQe," (UniSpeech model)"),wQe.forEach(t),dwr=i(Ie),AC=n(Ie,"LI",{});var AQe=s(AC);Y3e=n(AQe,"STRONG",{});var rHt=s(Y3e);cwr=r(rHt,"unispeech-sat"),rHt.forEach(t),mwr=r(AQe," \u2014 "),rZ=n(AQe,"A",{href:!0});var tHt=s(rZ);fwr=r(tHt,"UniSpeechSatForCTC"),tHt.forEach(t),gwr=r(AQe," (UniSpeechSat model)"),AQe.forEach(t),hwr=i(Ie),LC=n(Ie,"LI",{});var LQe=s(LC);K3e=n(LQe,"STRONG",{});var aHt=s(K3e);uwr=r(aHt,"wav2vec2"),aHt.forEach(t),pwr=r(LQe," \u2014 "),tZ=n(LQe,"A",{href:!0});var nHt=s(tZ);_wr=r(nHt,"Wav2Vec2ForCTC"),nHt.forEach(t),bwr=r(LQe," (Wav2Vec2 model)"),LQe.forEach(t),vwr=i(Ie),yC=n(Ie,"LI",{});var yQe=s(yC);Z3e=n(yQe,"STRONG",{});var sHt=s(Z3e);Fwr=r(sHt,"wav2vec2-conformer"),sHt.forEach(t),Twr=r(yQe," \u2014 "),aZ=n(yQe,"A",{href:!0});var lHt=s(aZ);Mwr=r(lHt,"Wav2Vec2ConformerForCTC"),lHt.forEach(t),Ewr=r(yQe," (Wav2Vec2-Conformer model)"),yQe.forEach(t),Cwr=i(Ie),xC=n(Ie,"LI",{});var xQe=s(xC);e5e=n(xQe,"STRONG",{});var iHt=s(e5e);wwr=r(iHt,"wavlm"),iHt.forEach(t),Awr=r(xQe," \u2014 "),nZ=n(xQe,"A",{href:!0});var dHt=s(nZ);Lwr=r(dHt,"WavLMForCTC"),dHt.forEach(t),ywr=r(xQe," (WavLM model)"),xQe.forEach(t),Ie.forEach(t),xwr=i(qa),$C=n(qa,"P",{});var $Qe=s($C);$wr=r($Qe,"The model is set in evaluation mode by default using "),o5e=n($Qe,"CODE",{});var cHt=s(o5e);kwr=r(cHt,"model.eval()"),cHt.forEach(t),Swr=r($Qe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r5e=n($Qe,"CODE",{});var mHt=s(r5e);Rwr=r(mHt,"model.train()"),mHt.forEach(t),$Qe.forEach(t),Pwr=i(qa),T(kC.$$.fragment,qa),qa.forEach(t),zl.forEach(t),geo=i(m),Tc=n(m,"H2",{class:!0});var Lro=s(Tc);SC=n(Lro,"A",{id:!0,class:!0,href:!0});var fHt=s(SC);t5e=n(fHt,"SPAN",{});var gHt=s(t5e);T(lk.$$.fragment,gHt),gHt.forEach(t),fHt.forEach(t),Bwr=i(Lro),a5e=n(Lro,"SPAN",{});var hHt=s(a5e);Iwr=r(hHt,"AutoModelForSpeechSeq2Seq"),hHt.forEach(t),Lro.forEach(t),heo=i(m),Zo=n(m,"DIV",{class:!0});var Ql=s(Zo);T(ik.$$.fragment,Ql),Nwr=i(Ql),Mc=n(Ql,"P",{});var wie=s(Mc);qwr=r(wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),sZ=n(wie,"A",{href:!0});var uHt=s(sZ);jwr=r(uHt,"from_pretrained()"),uHt.forEach(t),Dwr=r(wie," class method or the "),lZ=n(wie,"A",{href:!0});var pHt=s(lZ);Gwr=r(pHt,"from_config()"),pHt.forEach(t),Owr=r(wie,` class
method.`),wie.forEach(t),Vwr=i(Ql),dk=n(Ql,"P",{});var yro=s(dk);Xwr=r(yro,"This class cannot be instantiated directly using "),n5e=n(yro,"CODE",{});var _Ht=s(n5e);zwr=r(_Ht,"__init__()"),_Ht.forEach(t),Qwr=r(yro," (throws an error)."),yro.forEach(t),Wwr=i(Ql),Nt=n(Ql,"DIV",{class:!0});var A8=s(Nt);T(ck.$$.fragment,A8),Uwr=i(A8),s5e=n(A8,"P",{});var bHt=s(s5e);Hwr=r(bHt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),bHt.forEach(t),Jwr=i(A8),Ec=n(A8,"P",{});var Aie=s(Ec);Ywr=r(Aie,`Note:
Loading a model from its configuration file does `),l5e=n(Aie,"STRONG",{});var vHt=s(l5e);Kwr=r(vHt,"not"),vHt.forEach(t),Zwr=r(Aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),iZ=n(Aie,"A",{href:!0});var FHt=s(iZ);eAr=r(FHt,"from_pretrained()"),FHt.forEach(t),oAr=r(Aie," to load the model weights."),Aie.forEach(t),rAr=i(A8),T(RC.$$.fragment,A8),A8.forEach(t),tAr=i(Ql),vo=n(Ql,"DIV",{class:!0});var ja=s(vo);T(mk.$$.fragment,ja),aAr=i(ja),i5e=n(ja,"P",{});var THt=s(i5e);nAr=r(THt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),THt.forEach(t),sAr=i(ja),pn=n(ja,"P",{});var L8=s(pn);lAr=r(L8,"The model class to instantiate is selected based on the "),d5e=n(L8,"CODE",{});var MHt=s(d5e);iAr=r(MHt,"model_type"),MHt.forEach(t),dAr=r(L8,` property of the config object (either
passed as an argument or loaded from `),c5e=n(L8,"CODE",{});var EHt=s(c5e);cAr=r(EHt,"pretrained_model_name_or_path"),EHt.forEach(t),mAr=r(L8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=n(L8,"CODE",{});var CHt=s(m5e);fAr=r(CHt,"pretrained_model_name_or_path"),CHt.forEach(t),gAr=r(L8,":"),L8.forEach(t),hAr=i(ja),fk=n(ja,"UL",{});var xro=s(fk);PC=n(xro,"LI",{});var kQe=s(PC);f5e=n(kQe,"STRONG",{});var wHt=s(f5e);uAr=r(wHt,"speech-encoder-decoder"),wHt.forEach(t),pAr=r(kQe," \u2014 "),dZ=n(kQe,"A",{href:!0});var AHt=s(dZ);_Ar=r(AHt,"SpeechEncoderDecoderModel"),AHt.forEach(t),bAr=r(kQe," (Speech Encoder decoder model)"),kQe.forEach(t),vAr=i(xro),BC=n(xro,"LI",{});var SQe=s(BC);g5e=n(SQe,"STRONG",{});var LHt=s(g5e);FAr=r(LHt,"speech_to_text"),LHt.forEach(t),TAr=r(SQe," \u2014 "),cZ=n(SQe,"A",{href:!0});var yHt=s(cZ);MAr=r(yHt,"Speech2TextForConditionalGeneration"),yHt.forEach(t),EAr=r(SQe," (Speech2Text model)"),SQe.forEach(t),xro.forEach(t),CAr=i(ja),IC=n(ja,"P",{});var RQe=s(IC);wAr=r(RQe,"The model is set in evaluation mode by default using "),h5e=n(RQe,"CODE",{});var xHt=s(h5e);AAr=r(xHt,"model.eval()"),xHt.forEach(t),LAr=r(RQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u5e=n(RQe,"CODE",{});var $Ht=s(u5e);yAr=r($Ht,"model.train()"),$Ht.forEach(t),RQe.forEach(t),xAr=i(ja),T(NC.$$.fragment,ja),ja.forEach(t),Ql.forEach(t),ueo=i(m),Cc=n(m,"H2",{class:!0});var $ro=s(Cc);qC=n($ro,"A",{id:!0,class:!0,href:!0});var kHt=s(qC);p5e=n(kHt,"SPAN",{});var SHt=s(p5e);T(gk.$$.fragment,SHt),SHt.forEach(t),kHt.forEach(t),$Ar=i($ro),_5e=n($ro,"SPAN",{});var RHt=s(_5e);kAr=r(RHt,"AutoModelForAudioXVector"),RHt.forEach(t),$ro.forEach(t),peo=i(m),er=n(m,"DIV",{class:!0});var Wl=s(er);T(hk.$$.fragment,Wl),SAr=i(Wl),wc=n(Wl,"P",{});var Lie=s(wc);RAr=r(Lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),mZ=n(Lie,"A",{href:!0});var PHt=s(mZ);PAr=r(PHt,"from_pretrained()"),PHt.forEach(t),BAr=r(Lie," class method or the "),fZ=n(Lie,"A",{href:!0});var BHt=s(fZ);IAr=r(BHt,"from_config()"),BHt.forEach(t),NAr=r(Lie,` class
method.`),Lie.forEach(t),qAr=i(Wl),uk=n(Wl,"P",{});var kro=s(uk);jAr=r(kro,"This class cannot be instantiated directly using "),b5e=n(kro,"CODE",{});var IHt=s(b5e);DAr=r(IHt,"__init__()"),IHt.forEach(t),GAr=r(kro," (throws an error)."),kro.forEach(t),OAr=i(Wl),qt=n(Wl,"DIV",{class:!0});var y8=s(qt);T(pk.$$.fragment,y8),VAr=i(y8),v5e=n(y8,"P",{});var NHt=s(v5e);XAr=r(NHt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),NHt.forEach(t),zAr=i(y8),Ac=n(y8,"P",{});var yie=s(Ac);QAr=r(yie,`Note:
Loading a model from its configuration file does `),F5e=n(yie,"STRONG",{});var qHt=s(F5e);WAr=r(qHt,"not"),qHt.forEach(t),UAr=r(yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=n(yie,"A",{href:!0});var jHt=s(gZ);HAr=r(jHt,"from_pretrained()"),jHt.forEach(t),JAr=r(yie," to load the model weights."),yie.forEach(t),YAr=i(y8),T(jC.$$.fragment,y8),y8.forEach(t),KAr=i(Wl),Fo=n(Wl,"DIV",{class:!0});var Da=s(Fo);T(_k.$$.fragment,Da),ZAr=i(Da),T5e=n(Da,"P",{});var DHt=s(T5e);e6r=r(DHt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),DHt.forEach(t),o6r=i(Da),_n=n(Da,"P",{});var x8=s(_n);r6r=r(x8,"The model class to instantiate is selected based on the "),M5e=n(x8,"CODE",{});var GHt=s(M5e);t6r=r(GHt,"model_type"),GHt.forEach(t),a6r=r(x8,` property of the config object (either
passed as an argument or loaded from `),E5e=n(x8,"CODE",{});var OHt=s(E5e);n6r=r(OHt,"pretrained_model_name_or_path"),OHt.forEach(t),s6r=r(x8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C5e=n(x8,"CODE",{});var VHt=s(C5e);l6r=r(VHt,"pretrained_model_name_or_path"),VHt.forEach(t),i6r=r(x8,":"),x8.forEach(t),d6r=i(Da),ft=n(Da,"UL",{});var Ul=s(ft);DC=n(Ul,"LI",{});var PQe=s(DC);w5e=n(PQe,"STRONG",{});var XHt=s(w5e);c6r=r(XHt,"data2vec-audio"),XHt.forEach(t),m6r=r(PQe," \u2014 "),hZ=n(PQe,"A",{href:!0});var zHt=s(hZ);f6r=r(zHt,"Data2VecAudioForXVector"),zHt.forEach(t),g6r=r(PQe," (Data2VecAudio model)"),PQe.forEach(t),h6r=i(Ul),GC=n(Ul,"LI",{});var BQe=s(GC);A5e=n(BQe,"STRONG",{});var QHt=s(A5e);u6r=r(QHt,"unispeech-sat"),QHt.forEach(t),p6r=r(BQe," \u2014 "),uZ=n(BQe,"A",{href:!0});var WHt=s(uZ);_6r=r(WHt,"UniSpeechSatForXVector"),WHt.forEach(t),b6r=r(BQe," (UniSpeechSat model)"),BQe.forEach(t),v6r=i(Ul),OC=n(Ul,"LI",{});var IQe=s(OC);L5e=n(IQe,"STRONG",{});var UHt=s(L5e);F6r=r(UHt,"wav2vec2"),UHt.forEach(t),T6r=r(IQe," \u2014 "),pZ=n(IQe,"A",{href:!0});var HHt=s(pZ);M6r=r(HHt,"Wav2Vec2ForXVector"),HHt.forEach(t),E6r=r(IQe," (Wav2Vec2 model)"),IQe.forEach(t),C6r=i(Ul),VC=n(Ul,"LI",{});var NQe=s(VC);y5e=n(NQe,"STRONG",{});var JHt=s(y5e);w6r=r(JHt,"wav2vec2-conformer"),JHt.forEach(t),A6r=r(NQe," \u2014 "),_Z=n(NQe,"A",{href:!0});var YHt=s(_Z);L6r=r(YHt,"Wav2Vec2ConformerForXVector"),YHt.forEach(t),y6r=r(NQe," (Wav2Vec2-Conformer model)"),NQe.forEach(t),x6r=i(Ul),XC=n(Ul,"LI",{});var qQe=s(XC);x5e=n(qQe,"STRONG",{});var KHt=s(x5e);$6r=r(KHt,"wavlm"),KHt.forEach(t),k6r=r(qQe," \u2014 "),bZ=n(qQe,"A",{href:!0});var ZHt=s(bZ);S6r=r(ZHt,"WavLMForXVector"),ZHt.forEach(t),R6r=r(qQe," (WavLM model)"),qQe.forEach(t),Ul.forEach(t),P6r=i(Da),zC=n(Da,"P",{});var jQe=s(zC);B6r=r(jQe,"The model is set in evaluation mode by default using "),$5e=n(jQe,"CODE",{});var eJt=s($5e);I6r=r(eJt,"model.eval()"),eJt.forEach(t),N6r=r(jQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k5e=n(jQe,"CODE",{});var oJt=s(k5e);q6r=r(oJt,"model.train()"),oJt.forEach(t),jQe.forEach(t),j6r=i(Da),T(QC.$$.fragment,Da),Da.forEach(t),Wl.forEach(t),_eo=i(m),Lc=n(m,"H2",{class:!0});var Sro=s(Lc);WC=n(Sro,"A",{id:!0,class:!0,href:!0});var rJt=s(WC);S5e=n(rJt,"SPAN",{});var tJt=s(S5e);T(bk.$$.fragment,tJt),tJt.forEach(t),rJt.forEach(t),D6r=i(Sro),R5e=n(Sro,"SPAN",{});var aJt=s(R5e);G6r=r(aJt,"AutoModelForMaskedImageModeling"),aJt.forEach(t),Sro.forEach(t),beo=i(m),or=n(m,"DIV",{class:!0});var Hl=s(or);T(vk.$$.fragment,Hl),O6r=i(Hl),yc=n(Hl,"P",{});var xie=s(yc);V6r=r(xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),vZ=n(xie,"A",{href:!0});var nJt=s(vZ);X6r=r(nJt,"from_pretrained()"),nJt.forEach(t),z6r=r(xie," class method or the "),FZ=n(xie,"A",{href:!0});var sJt=s(FZ);Q6r=r(sJt,"from_config()"),sJt.forEach(t),W6r=r(xie,` class
method.`),xie.forEach(t),U6r=i(Hl),Fk=n(Hl,"P",{});var Rro=s(Fk);H6r=r(Rro,"This class cannot be instantiated directly using "),P5e=n(Rro,"CODE",{});var lJt=s(P5e);J6r=r(lJt,"__init__()"),lJt.forEach(t),Y6r=r(Rro," (throws an error)."),Rro.forEach(t),K6r=i(Hl),jt=n(Hl,"DIV",{class:!0});var $8=s(jt);T(Tk.$$.fragment,$8),Z6r=i($8),B5e=n($8,"P",{});var iJt=s(B5e);e7r=r(iJt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),iJt.forEach(t),o7r=i($8),xc=n($8,"P",{});var $ie=s(xc);r7r=r($ie,`Note:
Loading a model from its configuration file does `),I5e=n($ie,"STRONG",{});var dJt=s(I5e);t7r=r(dJt,"not"),dJt.forEach(t),a7r=r($ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),TZ=n($ie,"A",{href:!0});var cJt=s(TZ);n7r=r(cJt,"from_pretrained()"),cJt.forEach(t),s7r=r($ie," to load the model weights."),$ie.forEach(t),l7r=i($8),T(UC.$$.fragment,$8),$8.forEach(t),i7r=i(Hl),To=n(Hl,"DIV",{class:!0});var Ga=s(To);T(Mk.$$.fragment,Ga),d7r=i(Ga),N5e=n(Ga,"P",{});var mJt=s(N5e);c7r=r(mJt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),mJt.forEach(t),m7r=i(Ga),bn=n(Ga,"P",{});var k8=s(bn);f7r=r(k8,"The model class to instantiate is selected based on the "),q5e=n(k8,"CODE",{});var fJt=s(q5e);g7r=r(fJt,"model_type"),fJt.forEach(t),h7r=r(k8,` property of the config object (either
passed as an argument or loaded from `),j5e=n(k8,"CODE",{});var gJt=s(j5e);u7r=r(gJt,"pretrained_model_name_or_path"),gJt.forEach(t),p7r=r(k8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D5e=n(k8,"CODE",{});var hJt=s(D5e);_7r=r(hJt,"pretrained_model_name_or_path"),hJt.forEach(t),b7r=r(k8,":"),k8.forEach(t),v7r=i(Ga),vn=n(Ga,"UL",{});var S8=s(vn);HC=n(S8,"LI",{});var DQe=s(HC);G5e=n(DQe,"STRONG",{});var uJt=s(G5e);F7r=r(uJt,"deit"),uJt.forEach(t),T7r=r(DQe," \u2014 "),MZ=n(DQe,"A",{href:!0});var pJt=s(MZ);M7r=r(pJt,"DeiTForMaskedImageModeling"),pJt.forEach(t),E7r=r(DQe," (DeiT model)"),DQe.forEach(t),C7r=i(S8),JC=n(S8,"LI",{});var GQe=s(JC);O5e=n(GQe,"STRONG",{});var _Jt=s(O5e);w7r=r(_Jt,"swin"),_Jt.forEach(t),A7r=r(GQe," \u2014 "),EZ=n(GQe,"A",{href:!0});var bJt=s(EZ);L7r=r(bJt,"SwinForMaskedImageModeling"),bJt.forEach(t),y7r=r(GQe," (Swin Transformer model)"),GQe.forEach(t),x7r=i(S8),YC=n(S8,"LI",{});var OQe=s(YC);V5e=n(OQe,"STRONG",{});var vJt=s(V5e);$7r=r(vJt,"swinv2"),vJt.forEach(t),k7r=r(OQe," \u2014 "),CZ=n(OQe,"A",{href:!0});var FJt=s(CZ);S7r=r(FJt,"Swinv2ForMaskedImageModeling"),FJt.forEach(t),R7r=r(OQe," (Swin Transformer V2 model)"),OQe.forEach(t),P7r=i(S8),KC=n(S8,"LI",{});var VQe=s(KC);X5e=n(VQe,"STRONG",{});var TJt=s(X5e);B7r=r(TJt,"vit"),TJt.forEach(t),I7r=r(VQe," \u2014 "),wZ=n(VQe,"A",{href:!0});var MJt=s(wZ);N7r=r(MJt,"ViTForMaskedImageModeling"),MJt.forEach(t),q7r=r(VQe," (ViT model)"),VQe.forEach(t),S8.forEach(t),j7r=i(Ga),ZC=n(Ga,"P",{});var XQe=s(ZC);D7r=r(XQe,"The model is set in evaluation mode by default using "),z5e=n(XQe,"CODE",{});var EJt=s(z5e);G7r=r(EJt,"model.eval()"),EJt.forEach(t),O7r=r(XQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q5e=n(XQe,"CODE",{});var CJt=s(Q5e);V7r=r(CJt,"model.train()"),CJt.forEach(t),XQe.forEach(t),X7r=i(Ga),T(e3.$$.fragment,Ga),Ga.forEach(t),Hl.forEach(t),veo=i(m),$c=n(m,"H2",{class:!0});var Pro=s($c);o3=n(Pro,"A",{id:!0,class:!0,href:!0});var wJt=s(o3);W5e=n(wJt,"SPAN",{});var AJt=s(W5e);T(Ek.$$.fragment,AJt),AJt.forEach(t),wJt.forEach(t),z7r=i(Pro),U5e=n(Pro,"SPAN",{});var LJt=s(U5e);Q7r=r(LJt,"AutoModelForObjectDetection"),LJt.forEach(t),Pro.forEach(t),Feo=i(m),rr=n(m,"DIV",{class:!0});var Jl=s(rr);T(Ck.$$.fragment,Jl),W7r=i(Jl),kc=n(Jl,"P",{});var kie=s(kc);U7r=r(kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),AZ=n(kie,"A",{href:!0});var yJt=s(AZ);H7r=r(yJt,"from_pretrained()"),yJt.forEach(t),J7r=r(kie," class method or the "),LZ=n(kie,"A",{href:!0});var xJt=s(LZ);Y7r=r(xJt,"from_config()"),xJt.forEach(t),K7r=r(kie,` class
method.`),kie.forEach(t),Z7r=i(Jl),wk=n(Jl,"P",{});var Bro=s(wk);eLr=r(Bro,"This class cannot be instantiated directly using "),H5e=n(Bro,"CODE",{});var $Jt=s(H5e);oLr=r($Jt,"__init__()"),$Jt.forEach(t),rLr=r(Bro," (throws an error)."),Bro.forEach(t),tLr=i(Jl),Dt=n(Jl,"DIV",{class:!0});var R8=s(Dt);T(Ak.$$.fragment,R8),aLr=i(R8),J5e=n(R8,"P",{});var kJt=s(J5e);nLr=r(kJt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),kJt.forEach(t),sLr=i(R8),Sc=n(R8,"P",{});var Sie=s(Sc);lLr=r(Sie,`Note:
Loading a model from its configuration file does `),Y5e=n(Sie,"STRONG",{});var SJt=s(Y5e);iLr=r(SJt,"not"),SJt.forEach(t),dLr=r(Sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yZ=n(Sie,"A",{href:!0});var RJt=s(yZ);cLr=r(RJt,"from_pretrained()"),RJt.forEach(t),mLr=r(Sie," to load the model weights."),Sie.forEach(t),fLr=i(R8),T(r3.$$.fragment,R8),R8.forEach(t),gLr=i(Jl),Mo=n(Jl,"DIV",{class:!0});var Oa=s(Mo);T(Lk.$$.fragment,Oa),hLr=i(Oa),K5e=n(Oa,"P",{});var PJt=s(K5e);uLr=r(PJt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),PJt.forEach(t),pLr=i(Oa),Fn=n(Oa,"P",{});var P8=s(Fn);_Lr=r(P8,"The model class to instantiate is selected based on the "),Z5e=n(P8,"CODE",{});var BJt=s(Z5e);bLr=r(BJt,"model_type"),BJt.forEach(t),vLr=r(P8,` property of the config object (either
passed as an argument or loaded from `),e0e=n(P8,"CODE",{});var IJt=s(e0e);FLr=r(IJt,"pretrained_model_name_or_path"),IJt.forEach(t),TLr=r(P8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o0e=n(P8,"CODE",{});var NJt=s(o0e);MLr=r(NJt,"pretrained_model_name_or_path"),NJt.forEach(t),ELr=r(P8,":"),P8.forEach(t),CLr=i(Oa),Tn=n(Oa,"UL",{});var B8=s(Tn);t3=n(B8,"LI",{});var zQe=s(t3);r0e=n(zQe,"STRONG",{});var qJt=s(r0e);wLr=r(qJt,"conditional_detr"),qJt.forEach(t),ALr=r(zQe," \u2014 "),xZ=n(zQe,"A",{href:!0});var jJt=s(xZ);LLr=r(jJt,"ConditionalDetrForObjectDetection"),jJt.forEach(t),yLr=r(zQe," (Conditional DETR model)"),zQe.forEach(t),xLr=i(B8),a3=n(B8,"LI",{});var QQe=s(a3);t0e=n(QQe,"STRONG",{});var DJt=s(t0e);$Lr=r(DJt,"deformable_detr"),DJt.forEach(t),kLr=r(QQe," \u2014 "),$Z=n(QQe,"A",{href:!0});var GJt=s($Z);SLr=r(GJt,"DeformableDetrForObjectDetection"),GJt.forEach(t),RLr=r(QQe," (Deformable DETR model)"),QQe.forEach(t),PLr=i(B8),n3=n(B8,"LI",{});var WQe=s(n3);a0e=n(WQe,"STRONG",{});var OJt=s(a0e);BLr=r(OJt,"detr"),OJt.forEach(t),ILr=r(WQe," \u2014 "),kZ=n(WQe,"A",{href:!0});var VJt=s(kZ);NLr=r(VJt,"DetrForObjectDetection"),VJt.forEach(t),qLr=r(WQe," (DETR model)"),WQe.forEach(t),jLr=i(B8),s3=n(B8,"LI",{});var UQe=s(s3);n0e=n(UQe,"STRONG",{});var XJt=s(n0e);DLr=r(XJt,"yolos"),XJt.forEach(t),GLr=r(UQe," \u2014 "),SZ=n(UQe,"A",{href:!0});var zJt=s(SZ);OLr=r(zJt,"YolosForObjectDetection"),zJt.forEach(t),VLr=r(UQe," (YOLOS model)"),UQe.forEach(t),B8.forEach(t),XLr=i(Oa),l3=n(Oa,"P",{});var HQe=s(l3);zLr=r(HQe,"The model is set in evaluation mode by default using "),s0e=n(HQe,"CODE",{});var QJt=s(s0e);QLr=r(QJt,"model.eval()"),QJt.forEach(t),WLr=r(HQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=n(HQe,"CODE",{});var WJt=s(l0e);ULr=r(WJt,"model.train()"),WJt.forEach(t),HQe.forEach(t),HLr=i(Oa),T(i3.$$.fragment,Oa),Oa.forEach(t),Jl.forEach(t),Teo=i(m),Rc=n(m,"H2",{class:!0});var Iro=s(Rc);d3=n(Iro,"A",{id:!0,class:!0,href:!0});var UJt=s(d3);i0e=n(UJt,"SPAN",{});var HJt=s(i0e);T(yk.$$.fragment,HJt),HJt.forEach(t),UJt.forEach(t),JLr=i(Iro),d0e=n(Iro,"SPAN",{});var JJt=s(d0e);YLr=r(JJt,"AutoModelForImageSegmentation"),JJt.forEach(t),Iro.forEach(t),Meo=i(m),tr=n(m,"DIV",{class:!0});var Yl=s(tr);T(xk.$$.fragment,Yl),KLr=i(Yl),Pc=n(Yl,"P",{});var Rie=s(Pc);ZLr=r(Rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),RZ=n(Rie,"A",{href:!0});var YJt=s(RZ);eyr=r(YJt,"from_pretrained()"),YJt.forEach(t),oyr=r(Rie," class method or the "),PZ=n(Rie,"A",{href:!0});var KJt=s(PZ);ryr=r(KJt,"from_config()"),KJt.forEach(t),tyr=r(Rie,` class
method.`),Rie.forEach(t),ayr=i(Yl),$k=n(Yl,"P",{});var Nro=s($k);nyr=r(Nro,"This class cannot be instantiated directly using "),c0e=n(Nro,"CODE",{});var ZJt=s(c0e);syr=r(ZJt,"__init__()"),ZJt.forEach(t),lyr=r(Nro," (throws an error)."),Nro.forEach(t),iyr=i(Yl),Gt=n(Yl,"DIV",{class:!0});var I8=s(Gt);T(kk.$$.fragment,I8),dyr=i(I8),m0e=n(I8,"P",{});var eYt=s(m0e);cyr=r(eYt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),eYt.forEach(t),myr=i(I8),Bc=n(I8,"P",{});var Pie=s(Bc);fyr=r(Pie,`Note:
Loading a model from its configuration file does `),f0e=n(Pie,"STRONG",{});var oYt=s(f0e);gyr=r(oYt,"not"),oYt.forEach(t),hyr=r(Pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),BZ=n(Pie,"A",{href:!0});var rYt=s(BZ);uyr=r(rYt,"from_pretrained()"),rYt.forEach(t),pyr=r(Pie," to load the model weights."),Pie.forEach(t),_yr=i(I8),T(c3.$$.fragment,I8),I8.forEach(t),byr=i(Yl),Eo=n(Yl,"DIV",{class:!0});var Va=s(Eo);T(Sk.$$.fragment,Va),vyr=i(Va),g0e=n(Va,"P",{});var tYt=s(g0e);Fyr=r(tYt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),tYt.forEach(t),Tyr=i(Va),Mn=n(Va,"P",{});var N8=s(Mn);Myr=r(N8,"The model class to instantiate is selected based on the "),h0e=n(N8,"CODE",{});var aYt=s(h0e);Eyr=r(aYt,"model_type"),aYt.forEach(t),Cyr=r(N8,` property of the config object (either
passed as an argument or loaded from `),u0e=n(N8,"CODE",{});var nYt=s(u0e);wyr=r(nYt,"pretrained_model_name_or_path"),nYt.forEach(t),Ayr=r(N8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=n(N8,"CODE",{});var sYt=s(p0e);Lyr=r(sYt,"pretrained_model_name_or_path"),sYt.forEach(t),yyr=r(N8,":"),N8.forEach(t),xyr=i(Va),_0e=n(Va,"UL",{});var lYt=s(_0e);m3=n(lYt,"LI",{});var JQe=s(m3);b0e=n(JQe,"STRONG",{});var iYt=s(b0e);$yr=r(iYt,"detr"),iYt.forEach(t),kyr=r(JQe," \u2014 "),IZ=n(JQe,"A",{href:!0});var dYt=s(IZ);Syr=r(dYt,"DetrForSegmentation"),dYt.forEach(t),Ryr=r(JQe," (DETR model)"),JQe.forEach(t),lYt.forEach(t),Pyr=i(Va),f3=n(Va,"P",{});var YQe=s(f3);Byr=r(YQe,"The model is set in evaluation mode by default using "),v0e=n(YQe,"CODE",{});var cYt=s(v0e);Iyr=r(cYt,"model.eval()"),cYt.forEach(t),Nyr=r(YQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F0e=n(YQe,"CODE",{});var mYt=s(F0e);qyr=r(mYt,"model.train()"),mYt.forEach(t),YQe.forEach(t),jyr=i(Va),T(g3.$$.fragment,Va),Va.forEach(t),Yl.forEach(t),Eeo=i(m),Ic=n(m,"H2",{class:!0});var qro=s(Ic);h3=n(qro,"A",{id:!0,class:!0,href:!0});var fYt=s(h3);T0e=n(fYt,"SPAN",{});var gYt=s(T0e);T(Rk.$$.fragment,gYt),gYt.forEach(t),fYt.forEach(t),Dyr=i(qro),M0e=n(qro,"SPAN",{});var hYt=s(M0e);Gyr=r(hYt,"AutoModelForSemanticSegmentation"),hYt.forEach(t),qro.forEach(t),Ceo=i(m),ar=n(m,"DIV",{class:!0});var Kl=s(ar);T(Pk.$$.fragment,Kl),Oyr=i(Kl),Nc=n(Kl,"P",{});var Bie=s(Nc);Vyr=r(Bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),NZ=n(Bie,"A",{href:!0});var uYt=s(NZ);Xyr=r(uYt,"from_pretrained()"),uYt.forEach(t),zyr=r(Bie," class method or the "),qZ=n(Bie,"A",{href:!0});var pYt=s(qZ);Qyr=r(pYt,"from_config()"),pYt.forEach(t),Wyr=r(Bie,` class
method.`),Bie.forEach(t),Uyr=i(Kl),Bk=n(Kl,"P",{});var jro=s(Bk);Hyr=r(jro,"This class cannot be instantiated directly using "),E0e=n(jro,"CODE",{});var _Yt=s(E0e);Jyr=r(_Yt,"__init__()"),_Yt.forEach(t),Yyr=r(jro," (throws an error)."),jro.forEach(t),Kyr=i(Kl),Ot=n(Kl,"DIV",{class:!0});var q8=s(Ot);T(Ik.$$.fragment,q8),Zyr=i(q8),C0e=n(q8,"P",{});var bYt=s(C0e);e8r=r(bYt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),bYt.forEach(t),o8r=i(q8),qc=n(q8,"P",{});var Iie=s(qc);r8r=r(Iie,`Note:
Loading a model from its configuration file does `),w0e=n(Iie,"STRONG",{});var vYt=s(w0e);t8r=r(vYt,"not"),vYt.forEach(t),a8r=r(Iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),jZ=n(Iie,"A",{href:!0});var FYt=s(jZ);n8r=r(FYt,"from_pretrained()"),FYt.forEach(t),s8r=r(Iie," to load the model weights."),Iie.forEach(t),l8r=i(q8),T(u3.$$.fragment,q8),q8.forEach(t),i8r=i(Kl),Co=n(Kl,"DIV",{class:!0});var Xa=s(Co);T(Nk.$$.fragment,Xa),d8r=i(Xa),A0e=n(Xa,"P",{});var TYt=s(A0e);c8r=r(TYt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),TYt.forEach(t),m8r=i(Xa),En=n(Xa,"P",{});var j8=s(En);f8r=r(j8,"The model class to instantiate is selected based on the "),L0e=n(j8,"CODE",{});var MYt=s(L0e);g8r=r(MYt,"model_type"),MYt.forEach(t),h8r=r(j8,` property of the config object (either
passed as an argument or loaded from `),y0e=n(j8,"CODE",{});var EYt=s(y0e);u8r=r(EYt,"pretrained_model_name_or_path"),EYt.forEach(t),p8r=r(j8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=n(j8,"CODE",{});var CYt=s(x0e);_8r=r(CYt,"pretrained_model_name_or_path"),CYt.forEach(t),b8r=r(j8,":"),j8.forEach(t),v8r=i(Xa),gt=n(Xa,"UL",{});var Zl=s(gt);p3=n(Zl,"LI",{});var KQe=s(p3);$0e=n(KQe,"STRONG",{});var wYt=s($0e);F8r=r(wYt,"beit"),wYt.forEach(t),T8r=r(KQe," \u2014 "),DZ=n(KQe,"A",{href:!0});var AYt=s(DZ);M8r=r(AYt,"BeitForSemanticSegmentation"),AYt.forEach(t),E8r=r(KQe," (BEiT model)"),KQe.forEach(t),C8r=i(Zl),_3=n(Zl,"LI",{});var ZQe=s(_3);k0e=n(ZQe,"STRONG",{});var LYt=s(k0e);w8r=r(LYt,"data2vec-vision"),LYt.forEach(t),A8r=r(ZQe," \u2014 "),GZ=n(ZQe,"A",{href:!0});var yYt=s(GZ);L8r=r(yYt,"Data2VecVisionForSemanticSegmentation"),yYt.forEach(t),y8r=r(ZQe," (Data2VecVision model)"),ZQe.forEach(t),x8r=i(Zl),b3=n(Zl,"LI",{});var eWe=s(b3);S0e=n(eWe,"STRONG",{});var xYt=s(S0e);$8r=r(xYt,"dpt"),xYt.forEach(t),k8r=r(eWe," \u2014 "),OZ=n(eWe,"A",{href:!0});var $Yt=s(OZ);S8r=r($Yt,"DPTForSemanticSegmentation"),$Yt.forEach(t),R8r=r(eWe," (DPT model)"),eWe.forEach(t),P8r=i(Zl),v3=n(Zl,"LI",{});var oWe=s(v3);R0e=n(oWe,"STRONG",{});var kYt=s(R0e);B8r=r(kYt,"mobilevit"),kYt.forEach(t),I8r=r(oWe," \u2014 "),VZ=n(oWe,"A",{href:!0});var SYt=s(VZ);N8r=r(SYt,"MobileViTForSemanticSegmentation"),SYt.forEach(t),q8r=r(oWe," (MobileViT model)"),oWe.forEach(t),j8r=i(Zl),F3=n(Zl,"LI",{});var rWe=s(F3);P0e=n(rWe,"STRONG",{});var RYt=s(P0e);D8r=r(RYt,"segformer"),RYt.forEach(t),G8r=r(rWe," \u2014 "),XZ=n(rWe,"A",{href:!0});var PYt=s(XZ);O8r=r(PYt,"SegformerForSemanticSegmentation"),PYt.forEach(t),V8r=r(rWe," (SegFormer model)"),rWe.forEach(t),Zl.forEach(t),X8r=i(Xa),T3=n(Xa,"P",{});var tWe=s(T3);z8r=r(tWe,"The model is set in evaluation mode by default using "),B0e=n(tWe,"CODE",{});var BYt=s(B0e);Q8r=r(BYt,"model.eval()"),BYt.forEach(t),W8r=r(tWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I0e=n(tWe,"CODE",{});var IYt=s(I0e);U8r=r(IYt,"model.train()"),IYt.forEach(t),tWe.forEach(t),H8r=i(Xa),T(M3.$$.fragment,Xa),Xa.forEach(t),Kl.forEach(t),weo=i(m),jc=n(m,"H2",{class:!0});var Dro=s(jc);E3=n(Dro,"A",{id:!0,class:!0,href:!0});var NYt=s(E3);N0e=n(NYt,"SPAN",{});var qYt=s(N0e);T(qk.$$.fragment,qYt),qYt.forEach(t),NYt.forEach(t),J8r=i(Dro),q0e=n(Dro,"SPAN",{});var jYt=s(q0e);Y8r=r(jYt,"AutoModelForInstanceSegmentation"),jYt.forEach(t),Dro.forEach(t),Aeo=i(m),nr=n(m,"DIV",{class:!0});var ei=s(nr);T(jk.$$.fragment,ei),K8r=i(ei),Dc=n(ei,"P",{});var Nie=s(Dc);Z8r=r(Nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),zZ=n(Nie,"A",{href:!0});var DYt=s(zZ);e9r=r(DYt,"from_pretrained()"),DYt.forEach(t),o9r=r(Nie," class method or the "),QZ=n(Nie,"A",{href:!0});var GYt=s(QZ);r9r=r(GYt,"from_config()"),GYt.forEach(t),t9r=r(Nie,` class
method.`),Nie.forEach(t),a9r=i(ei),Dk=n(ei,"P",{});var Gro=s(Dk);n9r=r(Gro,"This class cannot be instantiated directly using "),j0e=n(Gro,"CODE",{});var OYt=s(j0e);s9r=r(OYt,"__init__()"),OYt.forEach(t),l9r=r(Gro," (throws an error)."),Gro.forEach(t),i9r=i(ei),Vt=n(ei,"DIV",{class:!0});var D8=s(Vt);T(Gk.$$.fragment,D8),d9r=i(D8),D0e=n(D8,"P",{});var VYt=s(D0e);c9r=r(VYt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),VYt.forEach(t),m9r=i(D8),Gc=n(D8,"P",{});var qie=s(Gc);f9r=r(qie,`Note:
Loading a model from its configuration file does `),G0e=n(qie,"STRONG",{});var XYt=s(G0e);g9r=r(XYt,"not"),XYt.forEach(t),h9r=r(qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),WZ=n(qie,"A",{href:!0});var zYt=s(WZ);u9r=r(zYt,"from_pretrained()"),zYt.forEach(t),p9r=r(qie," to load the model weights."),qie.forEach(t),_9r=i(D8),T(C3.$$.fragment,D8),D8.forEach(t),b9r=i(ei),wo=n(ei,"DIV",{class:!0});var za=s(wo);T(Ok.$$.fragment,za),v9r=i(za),O0e=n(za,"P",{});var QYt=s(O0e);F9r=r(QYt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),QYt.forEach(t),T9r=i(za),Cn=n(za,"P",{});var G8=s(Cn);M9r=r(G8,"The model class to instantiate is selected based on the "),V0e=n(G8,"CODE",{});var WYt=s(V0e);E9r=r(WYt,"model_type"),WYt.forEach(t),C9r=r(G8,` property of the config object (either
passed as an argument or loaded from `),X0e=n(G8,"CODE",{});var UYt=s(X0e);w9r=r(UYt,"pretrained_model_name_or_path"),UYt.forEach(t),A9r=r(G8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z0e=n(G8,"CODE",{});var HYt=s(z0e);L9r=r(HYt,"pretrained_model_name_or_path"),HYt.forEach(t),y9r=r(G8,":"),G8.forEach(t),x9r=i(za),Q0e=n(za,"UL",{});var JYt=s(Q0e);w3=n(JYt,"LI",{});var aWe=s(w3);W0e=n(aWe,"STRONG",{});var YYt=s(W0e);$9r=r(YYt,"maskformer"),YYt.forEach(t),k9r=r(aWe," \u2014 "),UZ=n(aWe,"A",{href:!0});var KYt=s(UZ);S9r=r(KYt,"MaskFormerForInstanceSegmentation"),KYt.forEach(t),R9r=r(aWe," (MaskFormer model)"),aWe.forEach(t),JYt.forEach(t),P9r=i(za),A3=n(za,"P",{});var nWe=s(A3);B9r=r(nWe,"The model is set in evaluation mode by default using "),U0e=n(nWe,"CODE",{});var ZYt=s(U0e);I9r=r(ZYt,"model.eval()"),ZYt.forEach(t),N9r=r(nWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H0e=n(nWe,"CODE",{});var eKt=s(H0e);q9r=r(eKt,"model.train()"),eKt.forEach(t),nWe.forEach(t),j9r=i(za),T(L3.$$.fragment,za),za.forEach(t),ei.forEach(t),Leo=i(m),Oc=n(m,"H2",{class:!0});var Oro=s(Oc);y3=n(Oro,"A",{id:!0,class:!0,href:!0});var oKt=s(y3);J0e=n(oKt,"SPAN",{});var rKt=s(J0e);T(Vk.$$.fragment,rKt),rKt.forEach(t),oKt.forEach(t),D9r=i(Oro),Y0e=n(Oro,"SPAN",{});var tKt=s(Y0e);G9r=r(tKt,"TFAutoModel"),tKt.forEach(t),Oro.forEach(t),yeo=i(m),sr=n(m,"DIV",{class:!0});var oi=s(sr);T(Xk.$$.fragment,oi),O9r=i(oi),Vc=n(oi,"P",{});var jie=s(Vc);V9r=r(jie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),HZ=n(jie,"A",{href:!0});var aKt=s(HZ);X9r=r(aKt,"from_pretrained()"),aKt.forEach(t),z9r=r(jie," class method or the "),JZ=n(jie,"A",{href:!0});var nKt=s(JZ);Q9r=r(nKt,"from_config()"),nKt.forEach(t),W9r=r(jie,` class
method.`),jie.forEach(t),U9r=i(oi),zk=n(oi,"P",{});var Vro=s(zk);H9r=r(Vro,"This class cannot be instantiated directly using "),K0e=n(Vro,"CODE",{});var sKt=s(K0e);J9r=r(sKt,"__init__()"),sKt.forEach(t),Y9r=r(Vro," (throws an error)."),Vro.forEach(t),K9r=i(oi),Xt=n(oi,"DIV",{class:!0});var O8=s(Xt);T(Qk.$$.fragment,O8),Z9r=i(O8),Z0e=n(O8,"P",{});var lKt=s(Z0e);exr=r(lKt,"Instantiates one of the base model classes of the library from a configuration."),lKt.forEach(t),oxr=i(O8),Xc=n(O8,"P",{});var Die=s(Xc);rxr=r(Die,`Note:
Loading a model from its configuration file does `),ewe=n(Die,"STRONG",{});var iKt=s(ewe);txr=r(iKt,"not"),iKt.forEach(t),axr=r(Die,` load the model weights. It only affects the
model\u2019s configuration. Use `),YZ=n(Die,"A",{href:!0});var dKt=s(YZ);nxr=r(dKt,"from_pretrained()"),dKt.forEach(t),sxr=r(Die," to load the model weights."),Die.forEach(t),lxr=i(O8),T(x3.$$.fragment,O8),O8.forEach(t),ixr=i(oi),Ir=n(oi,"DIV",{class:!0});var ri=s(Ir);T(Wk.$$.fragment,ri),dxr=i(ri),owe=n(ri,"P",{});var cKt=s(owe);cxr=r(cKt,"Instantiate one of the base model classes of the library from a pretrained model."),cKt.forEach(t),mxr=i(ri),wn=n(ri,"P",{});var V8=s(wn);fxr=r(V8,"The model class to instantiate is selected based on the "),rwe=n(V8,"CODE",{});var mKt=s(rwe);gxr=r(mKt,"model_type"),mKt.forEach(t),hxr=r(V8,` property of the config object (either
passed as an argument or loaded from `),twe=n(V8,"CODE",{});var fKt=s(twe);uxr=r(fKt,"pretrained_model_name_or_path"),fKt.forEach(t),pxr=r(V8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),awe=n(V8,"CODE",{});var gKt=s(awe);_xr=r(gKt,"pretrained_model_name_or_path"),gKt.forEach(t),bxr=r(V8,":"),V8.forEach(t),vxr=i(ri),B=n(ri,"UL",{});var j=s(B);$3=n(j,"LI",{});var sWe=s($3);nwe=n(sWe,"STRONG",{});var hKt=s(nwe);Fxr=r(hKt,"albert"),hKt.forEach(t),Txr=r(sWe," \u2014 "),KZ=n(sWe,"A",{href:!0});var uKt=s(KZ);Mxr=r(uKt,"TFAlbertModel"),uKt.forEach(t),Exr=r(sWe," (ALBERT model)"),sWe.forEach(t),Cxr=i(j),k3=n(j,"LI",{});var lWe=s(k3);swe=n(lWe,"STRONG",{});var pKt=s(swe);wxr=r(pKt,"bart"),pKt.forEach(t),Axr=r(lWe," \u2014 "),ZZ=n(lWe,"A",{href:!0});var _Kt=s(ZZ);Lxr=r(_Kt,"TFBartModel"),_Kt.forEach(t),yxr=r(lWe," (BART model)"),lWe.forEach(t),xxr=i(j),S3=n(j,"LI",{});var iWe=s(S3);lwe=n(iWe,"STRONG",{});var bKt=s(lwe);$xr=r(bKt,"bert"),bKt.forEach(t),kxr=r(iWe," \u2014 "),eee=n(iWe,"A",{href:!0});var vKt=s(eee);Sxr=r(vKt,"TFBertModel"),vKt.forEach(t),Rxr=r(iWe," (BERT model)"),iWe.forEach(t),Pxr=i(j),R3=n(j,"LI",{});var dWe=s(R3);iwe=n(dWe,"STRONG",{});var FKt=s(iwe);Bxr=r(FKt,"blenderbot"),FKt.forEach(t),Ixr=r(dWe," \u2014 "),oee=n(dWe,"A",{href:!0});var TKt=s(oee);Nxr=r(TKt,"TFBlenderbotModel"),TKt.forEach(t),qxr=r(dWe," (Blenderbot model)"),dWe.forEach(t),jxr=i(j),P3=n(j,"LI",{});var cWe=s(P3);dwe=n(cWe,"STRONG",{});var MKt=s(dwe);Dxr=r(MKt,"blenderbot-small"),MKt.forEach(t),Gxr=r(cWe," \u2014 "),ree=n(cWe,"A",{href:!0});var EKt=s(ree);Oxr=r(EKt,"TFBlenderbotSmallModel"),EKt.forEach(t),Vxr=r(cWe," (BlenderbotSmall model)"),cWe.forEach(t),Xxr=i(j),B3=n(j,"LI",{});var mWe=s(B3);cwe=n(mWe,"STRONG",{});var CKt=s(cwe);zxr=r(CKt,"camembert"),CKt.forEach(t),Qxr=r(mWe," \u2014 "),tee=n(mWe,"A",{href:!0});var wKt=s(tee);Wxr=r(wKt,"TFCamembertModel"),wKt.forEach(t),Uxr=r(mWe," (CamemBERT model)"),mWe.forEach(t),Hxr=i(j),I3=n(j,"LI",{});var fWe=s(I3);mwe=n(fWe,"STRONG",{});var AKt=s(mwe);Jxr=r(AKt,"clip"),AKt.forEach(t),Yxr=r(fWe," \u2014 "),aee=n(fWe,"A",{href:!0});var LKt=s(aee);Kxr=r(LKt,"TFCLIPModel"),LKt.forEach(t),Zxr=r(fWe," (CLIP model)"),fWe.forEach(t),e$r=i(j),N3=n(j,"LI",{});var gWe=s(N3);fwe=n(gWe,"STRONG",{});var yKt=s(fwe);o$r=r(yKt,"convbert"),yKt.forEach(t),r$r=r(gWe," \u2014 "),nee=n(gWe,"A",{href:!0});var xKt=s(nee);t$r=r(xKt,"TFConvBertModel"),xKt.forEach(t),a$r=r(gWe," (ConvBERT model)"),gWe.forEach(t),n$r=i(j),q3=n(j,"LI",{});var hWe=s(q3);gwe=n(hWe,"STRONG",{});var $Kt=s(gwe);s$r=r($Kt,"convnext"),$Kt.forEach(t),l$r=r(hWe," \u2014 "),see=n(hWe,"A",{href:!0});var kKt=s(see);i$r=r(kKt,"TFConvNextModel"),kKt.forEach(t),d$r=r(hWe," (ConvNeXT model)"),hWe.forEach(t),c$r=i(j),j3=n(j,"LI",{});var uWe=s(j3);hwe=n(uWe,"STRONG",{});var SKt=s(hwe);m$r=r(SKt,"ctrl"),SKt.forEach(t),f$r=r(uWe," \u2014 "),lee=n(uWe,"A",{href:!0});var RKt=s(lee);g$r=r(RKt,"TFCTRLModel"),RKt.forEach(t),h$r=r(uWe," (CTRL model)"),uWe.forEach(t),u$r=i(j),D3=n(j,"LI",{});var pWe=s(D3);uwe=n(pWe,"STRONG",{});var PKt=s(uwe);p$r=r(PKt,"data2vec-vision"),PKt.forEach(t),_$r=r(pWe," \u2014 "),iee=n(pWe,"A",{href:!0});var BKt=s(iee);b$r=r(BKt,"TFData2VecVisionModel"),BKt.forEach(t),v$r=r(pWe," (Data2VecVision model)"),pWe.forEach(t),F$r=i(j),G3=n(j,"LI",{});var _We=s(G3);pwe=n(_We,"STRONG",{});var IKt=s(pwe);T$r=r(IKt,"deberta"),IKt.forEach(t),M$r=r(_We," \u2014 "),dee=n(_We,"A",{href:!0});var NKt=s(dee);E$r=r(NKt,"TFDebertaModel"),NKt.forEach(t),C$r=r(_We," (DeBERTa model)"),_We.forEach(t),w$r=i(j),O3=n(j,"LI",{});var bWe=s(O3);_we=n(bWe,"STRONG",{});var qKt=s(_we);A$r=r(qKt,"deberta-v2"),qKt.forEach(t),L$r=r(bWe," \u2014 "),cee=n(bWe,"A",{href:!0});var jKt=s(cee);y$r=r(jKt,"TFDebertaV2Model"),jKt.forEach(t),x$r=r(bWe," (DeBERTa-v2 model)"),bWe.forEach(t),$$r=i(j),V3=n(j,"LI",{});var vWe=s(V3);bwe=n(vWe,"STRONG",{});var DKt=s(bwe);k$r=r(DKt,"deit"),DKt.forEach(t),S$r=r(vWe," \u2014 "),mee=n(vWe,"A",{href:!0});var GKt=s(mee);R$r=r(GKt,"TFDeiTModel"),GKt.forEach(t),P$r=r(vWe," (DeiT model)"),vWe.forEach(t),B$r=i(j),X3=n(j,"LI",{});var FWe=s(X3);vwe=n(FWe,"STRONG",{});var OKt=s(vwe);I$r=r(OKt,"distilbert"),OKt.forEach(t),N$r=r(FWe," \u2014 "),fee=n(FWe,"A",{href:!0});var VKt=s(fee);q$r=r(VKt,"TFDistilBertModel"),VKt.forEach(t),j$r=r(FWe," (DistilBERT model)"),FWe.forEach(t),D$r=i(j),z3=n(j,"LI",{});var TWe=s(z3);Fwe=n(TWe,"STRONG",{});var XKt=s(Fwe);G$r=r(XKt,"dpr"),XKt.forEach(t),O$r=r(TWe," \u2014 "),gee=n(TWe,"A",{href:!0});var zKt=s(gee);V$r=r(zKt,"TFDPRQuestionEncoder"),zKt.forEach(t),X$r=r(TWe," (DPR model)"),TWe.forEach(t),z$r=i(j),Q3=n(j,"LI",{});var MWe=s(Q3);Twe=n(MWe,"STRONG",{});var QKt=s(Twe);Q$r=r(QKt,"electra"),QKt.forEach(t),W$r=r(MWe," \u2014 "),hee=n(MWe,"A",{href:!0});var WKt=s(hee);U$r=r(WKt,"TFElectraModel"),WKt.forEach(t),H$r=r(MWe," (ELECTRA model)"),MWe.forEach(t),J$r=i(j),W3=n(j,"LI",{});var EWe=s(W3);Mwe=n(EWe,"STRONG",{});var UKt=s(Mwe);Y$r=r(UKt,"flaubert"),UKt.forEach(t),K$r=r(EWe," \u2014 "),uee=n(EWe,"A",{href:!0});var HKt=s(uee);Z$r=r(HKt,"TFFlaubertModel"),HKt.forEach(t),ekr=r(EWe," (FlauBERT model)"),EWe.forEach(t),okr=i(j),Fl=n(j,"LI",{});var QB=s(Fl);Ewe=n(QB,"STRONG",{});var JKt=s(Ewe);rkr=r(JKt,"funnel"),JKt.forEach(t),tkr=r(QB," \u2014 "),pee=n(QB,"A",{href:!0});var YKt=s(pee);akr=r(YKt,"TFFunnelModel"),YKt.forEach(t),nkr=r(QB," or "),_ee=n(QB,"A",{href:!0});var KKt=s(_ee);skr=r(KKt,"TFFunnelBaseModel"),KKt.forEach(t),lkr=r(QB," (Funnel Transformer model)"),QB.forEach(t),ikr=i(j),U3=n(j,"LI",{});var CWe=s(U3);Cwe=n(CWe,"STRONG",{});var ZKt=s(Cwe);dkr=r(ZKt,"gpt2"),ZKt.forEach(t),ckr=r(CWe," \u2014 "),bee=n(CWe,"A",{href:!0});var eZt=s(bee);mkr=r(eZt,"TFGPT2Model"),eZt.forEach(t),fkr=r(CWe," (OpenAI GPT-2 model)"),CWe.forEach(t),gkr=i(j),H3=n(j,"LI",{});var wWe=s(H3);wwe=n(wWe,"STRONG",{});var oZt=s(wwe);hkr=r(oZt,"gptj"),oZt.forEach(t),ukr=r(wWe," \u2014 "),vee=n(wWe,"A",{href:!0});var rZt=s(vee);pkr=r(rZt,"TFGPTJModel"),rZt.forEach(t),_kr=r(wWe," (GPT-J model)"),wWe.forEach(t),bkr=i(j),J3=n(j,"LI",{});var AWe=s(J3);Awe=n(AWe,"STRONG",{});var tZt=s(Awe);vkr=r(tZt,"groupvit"),tZt.forEach(t),Fkr=r(AWe," \u2014 "),Fee=n(AWe,"A",{href:!0});var aZt=s(Fee);Tkr=r(aZt,"TFGroupViTModel"),aZt.forEach(t),Mkr=r(AWe," (GroupViT model)"),AWe.forEach(t),Ekr=i(j),Y3=n(j,"LI",{});var LWe=s(Y3);Lwe=n(LWe,"STRONG",{});var nZt=s(Lwe);Ckr=r(nZt,"hubert"),nZt.forEach(t),wkr=r(LWe," \u2014 "),Tee=n(LWe,"A",{href:!0});var sZt=s(Tee);Akr=r(sZt,"TFHubertModel"),sZt.forEach(t),Lkr=r(LWe," (Hubert model)"),LWe.forEach(t),ykr=i(j),K3=n(j,"LI",{});var yWe=s(K3);ywe=n(yWe,"STRONG",{});var lZt=s(ywe);xkr=r(lZt,"layoutlm"),lZt.forEach(t),$kr=r(yWe," \u2014 "),Mee=n(yWe,"A",{href:!0});var iZt=s(Mee);kkr=r(iZt,"TFLayoutLMModel"),iZt.forEach(t),Skr=r(yWe," (LayoutLM model)"),yWe.forEach(t),Rkr=i(j),Z3=n(j,"LI",{});var xWe=s(Z3);xwe=n(xWe,"STRONG",{});var dZt=s(xwe);Pkr=r(dZt,"layoutlmv3"),dZt.forEach(t),Bkr=r(xWe," \u2014 "),Eee=n(xWe,"A",{href:!0});var cZt=s(Eee);Ikr=r(cZt,"TFLayoutLMv3Model"),cZt.forEach(t),Nkr=r(xWe," (LayoutLMv3 model)"),xWe.forEach(t),qkr=i(j),e5=n(j,"LI",{});var $We=s(e5);$we=n($We,"STRONG",{});var mZt=s($we);jkr=r(mZt,"led"),mZt.forEach(t),Dkr=r($We," \u2014 "),Cee=n($We,"A",{href:!0});var fZt=s(Cee);Gkr=r(fZt,"TFLEDModel"),fZt.forEach(t),Okr=r($We," (LED model)"),$We.forEach(t),Vkr=i(j),o5=n(j,"LI",{});var kWe=s(o5);kwe=n(kWe,"STRONG",{});var gZt=s(kwe);Xkr=r(gZt,"longformer"),gZt.forEach(t),zkr=r(kWe," \u2014 "),wee=n(kWe,"A",{href:!0});var hZt=s(wee);Qkr=r(hZt,"TFLongformerModel"),hZt.forEach(t),Wkr=r(kWe," (Longformer model)"),kWe.forEach(t),Ukr=i(j),r5=n(j,"LI",{});var SWe=s(r5);Swe=n(SWe,"STRONG",{});var uZt=s(Swe);Hkr=r(uZt,"lxmert"),uZt.forEach(t),Jkr=r(SWe," \u2014 "),Aee=n(SWe,"A",{href:!0});var pZt=s(Aee);Ykr=r(pZt,"TFLxmertModel"),pZt.forEach(t),Kkr=r(SWe," (LXMERT model)"),SWe.forEach(t),Zkr=i(j),t5=n(j,"LI",{});var RWe=s(t5);Rwe=n(RWe,"STRONG",{});var _Zt=s(Rwe);eSr=r(_Zt,"marian"),_Zt.forEach(t),oSr=r(RWe," \u2014 "),Lee=n(RWe,"A",{href:!0});var bZt=s(Lee);rSr=r(bZt,"TFMarianModel"),bZt.forEach(t),tSr=r(RWe," (Marian model)"),RWe.forEach(t),aSr=i(j),a5=n(j,"LI",{});var PWe=s(a5);Pwe=n(PWe,"STRONG",{});var vZt=s(Pwe);nSr=r(vZt,"mbart"),vZt.forEach(t),sSr=r(PWe," \u2014 "),yee=n(PWe,"A",{href:!0});var FZt=s(yee);lSr=r(FZt,"TFMBartModel"),FZt.forEach(t),iSr=r(PWe," (mBART model)"),PWe.forEach(t),dSr=i(j),n5=n(j,"LI",{});var BWe=s(n5);Bwe=n(BWe,"STRONG",{});var TZt=s(Bwe);cSr=r(TZt,"mobilebert"),TZt.forEach(t),mSr=r(BWe," \u2014 "),xee=n(BWe,"A",{href:!0});var MZt=s(xee);fSr=r(MZt,"TFMobileBertModel"),MZt.forEach(t),gSr=r(BWe," (MobileBERT model)"),BWe.forEach(t),hSr=i(j),s5=n(j,"LI",{});var IWe=s(s5);Iwe=n(IWe,"STRONG",{});var EZt=s(Iwe);uSr=r(EZt,"mobilevit"),EZt.forEach(t),pSr=r(IWe," \u2014 "),$ee=n(IWe,"A",{href:!0});var CZt=s($ee);_Sr=r(CZt,"TFMobileViTModel"),CZt.forEach(t),bSr=r(IWe," (MobileViT model)"),IWe.forEach(t),vSr=i(j),l5=n(j,"LI",{});var NWe=s(l5);Nwe=n(NWe,"STRONG",{});var wZt=s(Nwe);FSr=r(wZt,"mpnet"),wZt.forEach(t),TSr=r(NWe," \u2014 "),kee=n(NWe,"A",{href:!0});var AZt=s(kee);MSr=r(AZt,"TFMPNetModel"),AZt.forEach(t),ESr=r(NWe," (MPNet model)"),NWe.forEach(t),CSr=i(j),i5=n(j,"LI",{});var qWe=s(i5);qwe=n(qWe,"STRONG",{});var LZt=s(qwe);wSr=r(LZt,"mt5"),LZt.forEach(t),ASr=r(qWe," \u2014 "),See=n(qWe,"A",{href:!0});var yZt=s(See);LSr=r(yZt,"TFMT5Model"),yZt.forEach(t),ySr=r(qWe," (MT5 model)"),qWe.forEach(t),xSr=i(j),d5=n(j,"LI",{});var jWe=s(d5);jwe=n(jWe,"STRONG",{});var xZt=s(jwe);$Sr=r(xZt,"openai-gpt"),xZt.forEach(t),kSr=r(jWe," \u2014 "),Ree=n(jWe,"A",{href:!0});var $Zt=s(Ree);SSr=r($Zt,"TFOpenAIGPTModel"),$Zt.forEach(t),RSr=r(jWe," (OpenAI GPT model)"),jWe.forEach(t),PSr=i(j),c5=n(j,"LI",{});var DWe=s(c5);Dwe=n(DWe,"STRONG",{});var kZt=s(Dwe);BSr=r(kZt,"opt"),kZt.forEach(t),ISr=r(DWe," \u2014 "),Pee=n(DWe,"A",{href:!0});var SZt=s(Pee);NSr=r(SZt,"TFOPTModel"),SZt.forEach(t),qSr=r(DWe," (OPT model)"),DWe.forEach(t),jSr=i(j),m5=n(j,"LI",{});var GWe=s(m5);Gwe=n(GWe,"STRONG",{});var RZt=s(Gwe);DSr=r(RZt,"pegasus"),RZt.forEach(t),GSr=r(GWe," \u2014 "),Bee=n(GWe,"A",{href:!0});var PZt=s(Bee);OSr=r(PZt,"TFPegasusModel"),PZt.forEach(t),VSr=r(GWe," (Pegasus model)"),GWe.forEach(t),XSr=i(j),f5=n(j,"LI",{});var OWe=s(f5);Owe=n(OWe,"STRONG",{});var BZt=s(Owe);zSr=r(BZt,"regnet"),BZt.forEach(t),QSr=r(OWe," \u2014 "),Iee=n(OWe,"A",{href:!0});var IZt=s(Iee);WSr=r(IZt,"TFRegNetModel"),IZt.forEach(t),USr=r(OWe," (RegNet model)"),OWe.forEach(t),HSr=i(j),g5=n(j,"LI",{});var VWe=s(g5);Vwe=n(VWe,"STRONG",{});var NZt=s(Vwe);JSr=r(NZt,"rembert"),NZt.forEach(t),YSr=r(VWe," \u2014 "),Nee=n(VWe,"A",{href:!0});var qZt=s(Nee);KSr=r(qZt,"TFRemBertModel"),qZt.forEach(t),ZSr=r(VWe," (RemBERT model)"),VWe.forEach(t),eRr=i(j),h5=n(j,"LI",{});var XWe=s(h5);Xwe=n(XWe,"STRONG",{});var jZt=s(Xwe);oRr=r(jZt,"resnet"),jZt.forEach(t),rRr=r(XWe," \u2014 "),qee=n(XWe,"A",{href:!0});var DZt=s(qee);tRr=r(DZt,"TFResNetModel"),DZt.forEach(t),aRr=r(XWe," (ResNet model)"),XWe.forEach(t),nRr=i(j),u5=n(j,"LI",{});var zWe=s(u5);zwe=n(zWe,"STRONG",{});var GZt=s(zwe);sRr=r(GZt,"roberta"),GZt.forEach(t),lRr=r(zWe," \u2014 "),jee=n(zWe,"A",{href:!0});var OZt=s(jee);iRr=r(OZt,"TFRobertaModel"),OZt.forEach(t),dRr=r(zWe," (RoBERTa model)"),zWe.forEach(t),cRr=i(j),p5=n(j,"LI",{});var QWe=s(p5);Qwe=n(QWe,"STRONG",{});var VZt=s(Qwe);mRr=r(VZt,"roformer"),VZt.forEach(t),fRr=r(QWe," \u2014 "),Dee=n(QWe,"A",{href:!0});var XZt=s(Dee);gRr=r(XZt,"TFRoFormerModel"),XZt.forEach(t),hRr=r(QWe," (RoFormer model)"),QWe.forEach(t),uRr=i(j),_5=n(j,"LI",{});var WWe=s(_5);Wwe=n(WWe,"STRONG",{});var zZt=s(Wwe);pRr=r(zZt,"segformer"),zZt.forEach(t),_Rr=r(WWe," \u2014 "),Gee=n(WWe,"A",{href:!0});var QZt=s(Gee);bRr=r(QZt,"TFSegformerModel"),QZt.forEach(t),vRr=r(WWe," (SegFormer model)"),WWe.forEach(t),FRr=i(j),b5=n(j,"LI",{});var UWe=s(b5);Uwe=n(UWe,"STRONG",{});var WZt=s(Uwe);TRr=r(WZt,"speech_to_text"),WZt.forEach(t),MRr=r(UWe," \u2014 "),Oee=n(UWe,"A",{href:!0});var UZt=s(Oee);ERr=r(UZt,"TFSpeech2TextModel"),UZt.forEach(t),CRr=r(UWe," (Speech2Text model)"),UWe.forEach(t),wRr=i(j),v5=n(j,"LI",{});var HWe=s(v5);Hwe=n(HWe,"STRONG",{});var HZt=s(Hwe);ARr=r(HZt,"swin"),HZt.forEach(t),LRr=r(HWe," \u2014 "),Vee=n(HWe,"A",{href:!0});var JZt=s(Vee);yRr=r(JZt,"TFSwinModel"),JZt.forEach(t),xRr=r(HWe," (Swin Transformer model)"),HWe.forEach(t),$Rr=i(j),F5=n(j,"LI",{});var JWe=s(F5);Jwe=n(JWe,"STRONG",{});var YZt=s(Jwe);kRr=r(YZt,"t5"),YZt.forEach(t),SRr=r(JWe," \u2014 "),Xee=n(JWe,"A",{href:!0});var KZt=s(Xee);RRr=r(KZt,"TFT5Model"),KZt.forEach(t),PRr=r(JWe," (T5 model)"),JWe.forEach(t),BRr=i(j),T5=n(j,"LI",{});var YWe=s(T5);Ywe=n(YWe,"STRONG",{});var ZZt=s(Ywe);IRr=r(ZZt,"tapas"),ZZt.forEach(t),NRr=r(YWe," \u2014 "),zee=n(YWe,"A",{href:!0});var eea=s(zee);qRr=r(eea,"TFTapasModel"),eea.forEach(t),jRr=r(YWe," (TAPAS model)"),YWe.forEach(t),DRr=i(j),M5=n(j,"LI",{});var KWe=s(M5);Kwe=n(KWe,"STRONG",{});var oea=s(Kwe);GRr=r(oea,"transfo-xl"),oea.forEach(t),ORr=r(KWe," \u2014 "),Qee=n(KWe,"A",{href:!0});var rea=s(Qee);VRr=r(rea,"TFTransfoXLModel"),rea.forEach(t),XRr=r(KWe," (Transformer-XL model)"),KWe.forEach(t),zRr=i(j),E5=n(j,"LI",{});var ZWe=s(E5);Zwe=n(ZWe,"STRONG",{});var tea=s(Zwe);QRr=r(tea,"vit"),tea.forEach(t),WRr=r(ZWe," \u2014 "),Wee=n(ZWe,"A",{href:!0});var aea=s(Wee);URr=r(aea,"TFViTModel"),aea.forEach(t),HRr=r(ZWe," (ViT model)"),ZWe.forEach(t),JRr=i(j),C5=n(j,"LI",{});var eUe=s(C5);eAe=n(eUe,"STRONG",{});var nea=s(eAe);YRr=r(nea,"vit_mae"),nea.forEach(t),KRr=r(eUe," \u2014 "),Uee=n(eUe,"A",{href:!0});var sea=s(Uee);ZRr=r(sea,"TFViTMAEModel"),sea.forEach(t),ePr=r(eUe," (ViTMAE model)"),eUe.forEach(t),oPr=i(j),w5=n(j,"LI",{});var oUe=s(w5);oAe=n(oUe,"STRONG",{});var lea=s(oAe);rPr=r(lea,"wav2vec2"),lea.forEach(t),tPr=r(oUe," \u2014 "),Hee=n(oUe,"A",{href:!0});var iea=s(Hee);aPr=r(iea,"TFWav2Vec2Model"),iea.forEach(t),nPr=r(oUe," (Wav2Vec2 model)"),oUe.forEach(t),sPr=i(j),A5=n(j,"LI",{});var rUe=s(A5);rAe=n(rUe,"STRONG",{});var dea=s(rAe);lPr=r(dea,"xglm"),dea.forEach(t),iPr=r(rUe," \u2014 "),Jee=n(rUe,"A",{href:!0});var cea=s(Jee);dPr=r(cea,"TFXGLMModel"),cea.forEach(t),cPr=r(rUe," (XGLM model)"),rUe.forEach(t),mPr=i(j),L5=n(j,"LI",{});var tUe=s(L5);tAe=n(tUe,"STRONG",{});var mea=s(tAe);fPr=r(mea,"xlm"),mea.forEach(t),gPr=r(tUe," \u2014 "),Yee=n(tUe,"A",{href:!0});var fea=s(Yee);hPr=r(fea,"TFXLMModel"),fea.forEach(t),uPr=r(tUe," (XLM model)"),tUe.forEach(t),pPr=i(j),y5=n(j,"LI",{});var aUe=s(y5);aAe=n(aUe,"STRONG",{});var gea=s(aAe);_Pr=r(gea,"xlm-roberta"),gea.forEach(t),bPr=r(aUe," \u2014 "),Kee=n(aUe,"A",{href:!0});var hea=s(Kee);vPr=r(hea,"TFXLMRobertaModel"),hea.forEach(t),FPr=r(aUe," (XLM-RoBERTa model)"),aUe.forEach(t),TPr=i(j),x5=n(j,"LI",{});var nUe=s(x5);nAe=n(nUe,"STRONG",{});var uea=s(nAe);MPr=r(uea,"xlnet"),uea.forEach(t),EPr=r(nUe," \u2014 "),Zee=n(nUe,"A",{href:!0});var pea=s(Zee);CPr=r(pea,"TFXLNetModel"),pea.forEach(t),wPr=r(nUe," (XLNet model)"),nUe.forEach(t),j.forEach(t),APr=i(ri),T($5.$$.fragment,ri),ri.forEach(t),oi.forEach(t),xeo=i(m),zc=n(m,"H2",{class:!0});var Xro=s(zc);k5=n(Xro,"A",{id:!0,class:!0,href:!0});var _ea=s(k5);sAe=n(_ea,"SPAN",{});var bea=s(sAe);T(Uk.$$.fragment,bea),bea.forEach(t),_ea.forEach(t),LPr=i(Xro),lAe=n(Xro,"SPAN",{});var vea=s(lAe);yPr=r(vea,"TFAutoModelForPreTraining"),vea.forEach(t),Xro.forEach(t),$eo=i(m),lr=n(m,"DIV",{class:!0});var ti=s(lr);T(Hk.$$.fragment,ti),xPr=i(ti),Qc=n(ti,"P",{});var Gie=s(Qc);$Pr=r(Gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),eoe=n(Gie,"A",{href:!0});var Fea=s(eoe);kPr=r(Fea,"from_pretrained()"),Fea.forEach(t),SPr=r(Gie," class method or the "),ooe=n(Gie,"A",{href:!0});var Tea=s(ooe);RPr=r(Tea,"from_config()"),Tea.forEach(t),PPr=r(Gie,` class
method.`),Gie.forEach(t),BPr=i(ti),Jk=n(ti,"P",{});var zro=s(Jk);IPr=r(zro,"This class cannot be instantiated directly using "),iAe=n(zro,"CODE",{});var Mea=s(iAe);NPr=r(Mea,"__init__()"),Mea.forEach(t),qPr=r(zro," (throws an error)."),zro.forEach(t),jPr=i(ti),zt=n(ti,"DIV",{class:!0});var X8=s(zt);T(Yk.$$.fragment,X8),DPr=i(X8),dAe=n(X8,"P",{});var Eea=s(dAe);GPr=r(Eea,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Eea.forEach(t),OPr=i(X8),Wc=n(X8,"P",{});var Oie=s(Wc);VPr=r(Oie,`Note:
Loading a model from its configuration file does `),cAe=n(Oie,"STRONG",{});var Cea=s(cAe);XPr=r(Cea,"not"),Cea.forEach(t),zPr=r(Oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),roe=n(Oie,"A",{href:!0});var wea=s(roe);QPr=r(wea,"from_pretrained()"),wea.forEach(t),WPr=r(Oie," to load the model weights."),Oie.forEach(t),UPr=i(X8),T(S5.$$.fragment,X8),X8.forEach(t),HPr=i(ti),Nr=n(ti,"DIV",{class:!0});var ai=s(Nr);T(Kk.$$.fragment,ai),JPr=i(ai),mAe=n(ai,"P",{});var Aea=s(mAe);YPr=r(Aea,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Aea.forEach(t),KPr=i(ai),An=n(ai,"P",{});var z8=s(An);ZPr=r(z8,"The model class to instantiate is selected based on the "),fAe=n(z8,"CODE",{});var Lea=s(fAe);eBr=r(Lea,"model_type"),Lea.forEach(t),oBr=r(z8,` property of the config object (either
passed as an argument or loaded from `),gAe=n(z8,"CODE",{});var yea=s(gAe);rBr=r(yea,"pretrained_model_name_or_path"),yea.forEach(t),tBr=r(z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hAe=n(z8,"CODE",{});var xea=s(hAe);aBr=r(xea,"pretrained_model_name_or_path"),xea.forEach(t),nBr=r(z8,":"),z8.forEach(t),sBr=i(ai),se=n(ai,"UL",{});var ie=s(se);R5=n(ie,"LI",{});var sUe=s(R5);uAe=n(sUe,"STRONG",{});var $ea=s(uAe);lBr=r($ea,"albert"),$ea.forEach(t),iBr=r(sUe," \u2014 "),toe=n(sUe,"A",{href:!0});var kea=s(toe);dBr=r(kea,"TFAlbertForPreTraining"),kea.forEach(t),cBr=r(sUe," (ALBERT model)"),sUe.forEach(t),mBr=i(ie),P5=n(ie,"LI",{});var lUe=s(P5);pAe=n(lUe,"STRONG",{});var Sea=s(pAe);fBr=r(Sea,"bart"),Sea.forEach(t),gBr=r(lUe," \u2014 "),aoe=n(lUe,"A",{href:!0});var Rea=s(aoe);hBr=r(Rea,"TFBartForConditionalGeneration"),Rea.forEach(t),uBr=r(lUe," (BART model)"),lUe.forEach(t),pBr=i(ie),B5=n(ie,"LI",{});var iUe=s(B5);_Ae=n(iUe,"STRONG",{});var Pea=s(_Ae);_Br=r(Pea,"bert"),Pea.forEach(t),bBr=r(iUe," \u2014 "),noe=n(iUe,"A",{href:!0});var Bea=s(noe);vBr=r(Bea,"TFBertForPreTraining"),Bea.forEach(t),FBr=r(iUe," (BERT model)"),iUe.forEach(t),TBr=i(ie),I5=n(ie,"LI",{});var dUe=s(I5);bAe=n(dUe,"STRONG",{});var Iea=s(bAe);MBr=r(Iea,"camembert"),Iea.forEach(t),EBr=r(dUe," \u2014 "),soe=n(dUe,"A",{href:!0});var Nea=s(soe);CBr=r(Nea,"TFCamembertForMaskedLM"),Nea.forEach(t),wBr=r(dUe," (CamemBERT model)"),dUe.forEach(t),ABr=i(ie),N5=n(ie,"LI",{});var cUe=s(N5);vAe=n(cUe,"STRONG",{});var qea=s(vAe);LBr=r(qea,"ctrl"),qea.forEach(t),yBr=r(cUe," \u2014 "),loe=n(cUe,"A",{href:!0});var jea=s(loe);xBr=r(jea,"TFCTRLLMHeadModel"),jea.forEach(t),$Br=r(cUe," (CTRL model)"),cUe.forEach(t),kBr=i(ie),q5=n(ie,"LI",{});var mUe=s(q5);FAe=n(mUe,"STRONG",{});var Dea=s(FAe);SBr=r(Dea,"distilbert"),Dea.forEach(t),RBr=r(mUe," \u2014 "),ioe=n(mUe,"A",{href:!0});var Gea=s(ioe);PBr=r(Gea,"TFDistilBertForMaskedLM"),Gea.forEach(t),BBr=r(mUe," (DistilBERT model)"),mUe.forEach(t),IBr=i(ie),j5=n(ie,"LI",{});var fUe=s(j5);TAe=n(fUe,"STRONG",{});var Oea=s(TAe);NBr=r(Oea,"electra"),Oea.forEach(t),qBr=r(fUe," \u2014 "),doe=n(fUe,"A",{href:!0});var Vea=s(doe);jBr=r(Vea,"TFElectraForPreTraining"),Vea.forEach(t),DBr=r(fUe," (ELECTRA model)"),fUe.forEach(t),GBr=i(ie),D5=n(ie,"LI",{});var gUe=s(D5);MAe=n(gUe,"STRONG",{});var Xea=s(MAe);OBr=r(Xea,"flaubert"),Xea.forEach(t),VBr=r(gUe," \u2014 "),coe=n(gUe,"A",{href:!0});var zea=s(coe);XBr=r(zea,"TFFlaubertWithLMHeadModel"),zea.forEach(t),zBr=r(gUe," (FlauBERT model)"),gUe.forEach(t),QBr=i(ie),G5=n(ie,"LI",{});var hUe=s(G5);EAe=n(hUe,"STRONG",{});var Qea=s(EAe);WBr=r(Qea,"funnel"),Qea.forEach(t),UBr=r(hUe," \u2014 "),moe=n(hUe,"A",{href:!0});var Wea=s(moe);HBr=r(Wea,"TFFunnelForPreTraining"),Wea.forEach(t),JBr=r(hUe," (Funnel Transformer model)"),hUe.forEach(t),YBr=i(ie),O5=n(ie,"LI",{});var uUe=s(O5);CAe=n(uUe,"STRONG",{});var Uea=s(CAe);KBr=r(Uea,"gpt2"),Uea.forEach(t),ZBr=r(uUe," \u2014 "),foe=n(uUe,"A",{href:!0});var Hea=s(foe);eIr=r(Hea,"TFGPT2LMHeadModel"),Hea.forEach(t),oIr=r(uUe," (OpenAI GPT-2 model)"),uUe.forEach(t),rIr=i(ie),V5=n(ie,"LI",{});var pUe=s(V5);wAe=n(pUe,"STRONG",{});var Jea=s(wAe);tIr=r(Jea,"layoutlm"),Jea.forEach(t),aIr=r(pUe," \u2014 "),goe=n(pUe,"A",{href:!0});var Yea=s(goe);nIr=r(Yea,"TFLayoutLMForMaskedLM"),Yea.forEach(t),sIr=r(pUe," (LayoutLM model)"),pUe.forEach(t),lIr=i(ie),X5=n(ie,"LI",{});var _Ue=s(X5);AAe=n(_Ue,"STRONG",{});var Kea=s(AAe);iIr=r(Kea,"lxmert"),Kea.forEach(t),dIr=r(_Ue," \u2014 "),hoe=n(_Ue,"A",{href:!0});var Zea=s(hoe);cIr=r(Zea,"TFLxmertForPreTraining"),Zea.forEach(t),mIr=r(_Ue," (LXMERT model)"),_Ue.forEach(t),fIr=i(ie),z5=n(ie,"LI",{});var bUe=s(z5);LAe=n(bUe,"STRONG",{});var eoa=s(LAe);gIr=r(eoa,"mobilebert"),eoa.forEach(t),hIr=r(bUe," \u2014 "),uoe=n(bUe,"A",{href:!0});var ooa=s(uoe);uIr=r(ooa,"TFMobileBertForPreTraining"),ooa.forEach(t),pIr=r(bUe," (MobileBERT model)"),bUe.forEach(t),_Ir=i(ie),Q5=n(ie,"LI",{});var vUe=s(Q5);yAe=n(vUe,"STRONG",{});var roa=s(yAe);bIr=r(roa,"mpnet"),roa.forEach(t),vIr=r(vUe," \u2014 "),poe=n(vUe,"A",{href:!0});var toa=s(poe);FIr=r(toa,"TFMPNetForMaskedLM"),toa.forEach(t),TIr=r(vUe," (MPNet model)"),vUe.forEach(t),MIr=i(ie),W5=n(ie,"LI",{});var FUe=s(W5);xAe=n(FUe,"STRONG",{});var aoa=s(xAe);EIr=r(aoa,"openai-gpt"),aoa.forEach(t),CIr=r(FUe," \u2014 "),_oe=n(FUe,"A",{href:!0});var noa=s(_oe);wIr=r(noa,"TFOpenAIGPTLMHeadModel"),noa.forEach(t),AIr=r(FUe," (OpenAI GPT model)"),FUe.forEach(t),LIr=i(ie),U5=n(ie,"LI",{});var TUe=s(U5);$Ae=n(TUe,"STRONG",{});var soa=s($Ae);yIr=r(soa,"roberta"),soa.forEach(t),xIr=r(TUe," \u2014 "),boe=n(TUe,"A",{href:!0});var loa=s(boe);$Ir=r(loa,"TFRobertaForMaskedLM"),loa.forEach(t),kIr=r(TUe," (RoBERTa model)"),TUe.forEach(t),SIr=i(ie),H5=n(ie,"LI",{});var MUe=s(H5);kAe=n(MUe,"STRONG",{});var ioa=s(kAe);RIr=r(ioa,"t5"),ioa.forEach(t),PIr=r(MUe," \u2014 "),voe=n(MUe,"A",{href:!0});var doa=s(voe);BIr=r(doa,"TFT5ForConditionalGeneration"),doa.forEach(t),IIr=r(MUe," (T5 model)"),MUe.forEach(t),NIr=i(ie),J5=n(ie,"LI",{});var EUe=s(J5);SAe=n(EUe,"STRONG",{});var coa=s(SAe);qIr=r(coa,"tapas"),coa.forEach(t),jIr=r(EUe," \u2014 "),Foe=n(EUe,"A",{href:!0});var moa=s(Foe);DIr=r(moa,"TFTapasForMaskedLM"),moa.forEach(t),GIr=r(EUe," (TAPAS model)"),EUe.forEach(t),OIr=i(ie),Y5=n(ie,"LI",{});var CUe=s(Y5);RAe=n(CUe,"STRONG",{});var foa=s(RAe);VIr=r(foa,"transfo-xl"),foa.forEach(t),XIr=r(CUe," \u2014 "),Toe=n(CUe,"A",{href:!0});var goa=s(Toe);zIr=r(goa,"TFTransfoXLLMHeadModel"),goa.forEach(t),QIr=r(CUe," (Transformer-XL model)"),CUe.forEach(t),WIr=i(ie),K5=n(ie,"LI",{});var wUe=s(K5);PAe=n(wUe,"STRONG",{});var hoa=s(PAe);UIr=r(hoa,"vit_mae"),hoa.forEach(t),HIr=r(wUe," \u2014 "),Moe=n(wUe,"A",{href:!0});var uoa=s(Moe);JIr=r(uoa,"TFViTMAEForPreTraining"),uoa.forEach(t),YIr=r(wUe," (ViTMAE model)"),wUe.forEach(t),KIr=i(ie),Z5=n(ie,"LI",{});var AUe=s(Z5);BAe=n(AUe,"STRONG",{});var poa=s(BAe);ZIr=r(poa,"xlm"),poa.forEach(t),eNr=r(AUe," \u2014 "),Eoe=n(AUe,"A",{href:!0});var _oa=s(Eoe);oNr=r(_oa,"TFXLMWithLMHeadModel"),_oa.forEach(t),rNr=r(AUe," (XLM model)"),AUe.forEach(t),tNr=i(ie),e0=n(ie,"LI",{});var LUe=s(e0);IAe=n(LUe,"STRONG",{});var boa=s(IAe);aNr=r(boa,"xlm-roberta"),boa.forEach(t),nNr=r(LUe," \u2014 "),Coe=n(LUe,"A",{href:!0});var voa=s(Coe);sNr=r(voa,"TFXLMRobertaForMaskedLM"),voa.forEach(t),lNr=r(LUe," (XLM-RoBERTa model)"),LUe.forEach(t),iNr=i(ie),o0=n(ie,"LI",{});var yUe=s(o0);NAe=n(yUe,"STRONG",{});var Foa=s(NAe);dNr=r(Foa,"xlnet"),Foa.forEach(t),cNr=r(yUe," \u2014 "),woe=n(yUe,"A",{href:!0});var Toa=s(woe);mNr=r(Toa,"TFXLNetLMHeadModel"),Toa.forEach(t),fNr=r(yUe," (XLNet model)"),yUe.forEach(t),ie.forEach(t),gNr=i(ai),T(r0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),keo=i(m),Uc=n(m,"H2",{class:!0});var Qro=s(Uc);t0=n(Qro,"A",{id:!0,class:!0,href:!0});var Moa=s(t0);qAe=n(Moa,"SPAN",{});var Eoa=s(qAe);T(Zk.$$.fragment,Eoa),Eoa.forEach(t),Moa.forEach(t),hNr=i(Qro),jAe=n(Qro,"SPAN",{});var Coa=s(jAe);uNr=r(Coa,"TFAutoModelForCausalLM"),Coa.forEach(t),Qro.forEach(t),Seo=i(m),ir=n(m,"DIV",{class:!0});var ni=s(ir);T(eS.$$.fragment,ni),pNr=i(ni),Hc=n(ni,"P",{});var Vie=s(Hc);_Nr=r(Vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Aoe=n(Vie,"A",{href:!0});var woa=s(Aoe);bNr=r(woa,"from_pretrained()"),woa.forEach(t),vNr=r(Vie," class method or the "),Loe=n(Vie,"A",{href:!0});var Aoa=s(Loe);FNr=r(Aoa,"from_config()"),Aoa.forEach(t),TNr=r(Vie,` class
method.`),Vie.forEach(t),MNr=i(ni),oS=n(ni,"P",{});var Wro=s(oS);ENr=r(Wro,"This class cannot be instantiated directly using "),DAe=n(Wro,"CODE",{});var Loa=s(DAe);CNr=r(Loa,"__init__()"),Loa.forEach(t),wNr=r(Wro," (throws an error)."),Wro.forEach(t),ANr=i(ni),Qt=n(ni,"DIV",{class:!0});var Q8=s(Qt);T(rS.$$.fragment,Q8),LNr=i(Q8),GAe=n(Q8,"P",{});var yoa=s(GAe);yNr=r(yoa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yoa.forEach(t),xNr=i(Q8),Jc=n(Q8,"P",{});var Xie=s(Jc);$Nr=r(Xie,`Note:
Loading a model from its configuration file does `),OAe=n(Xie,"STRONG",{});var xoa=s(OAe);kNr=r(xoa,"not"),xoa.forEach(t),SNr=r(Xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=n(Xie,"A",{href:!0});var $oa=s(yoe);RNr=r($oa,"from_pretrained()"),$oa.forEach(t),PNr=r(Xie," to load the model weights."),Xie.forEach(t),BNr=i(Q8),T(a0.$$.fragment,Q8),Q8.forEach(t),INr=i(ni),qr=n(ni,"DIV",{class:!0});var si=s(qr);T(tS.$$.fragment,si),NNr=i(si),VAe=n(si,"P",{});var koa=s(VAe);qNr=r(koa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),koa.forEach(t),jNr=i(si),Ln=n(si,"P",{});var W8=s(Ln);DNr=r(W8,"The model class to instantiate is selected based on the "),XAe=n(W8,"CODE",{});var Soa=s(XAe);GNr=r(Soa,"model_type"),Soa.forEach(t),ONr=r(W8,` property of the config object (either
passed as an argument or loaded from `),zAe=n(W8,"CODE",{});var Roa=s(zAe);VNr=r(Roa,"pretrained_model_name_or_path"),Roa.forEach(t),XNr=r(W8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QAe=n(W8,"CODE",{});var Poa=s(QAe);zNr=r(Poa,"pretrained_model_name_or_path"),Poa.forEach(t),QNr=r(W8,":"),W8.forEach(t),WNr=i(si),Me=n(si,"UL",{});var Ce=s(Me);n0=n(Ce,"LI",{});var xUe=s(n0);WAe=n(xUe,"STRONG",{});var Boa=s(WAe);UNr=r(Boa,"bert"),Boa.forEach(t),HNr=r(xUe," \u2014 "),xoe=n(xUe,"A",{href:!0});var Ioa=s(xoe);JNr=r(Ioa,"TFBertLMHeadModel"),Ioa.forEach(t),YNr=r(xUe," (BERT model)"),xUe.forEach(t),KNr=i(Ce),s0=n(Ce,"LI",{});var $Ue=s(s0);UAe=n($Ue,"STRONG",{});var Noa=s(UAe);ZNr=r(Noa,"camembert"),Noa.forEach(t),eqr=r($Ue," \u2014 "),$oe=n($Ue,"A",{href:!0});var qoa=s($oe);oqr=r(qoa,"TFCamembertForCausalLM"),qoa.forEach(t),rqr=r($Ue," (CamemBERT model)"),$Ue.forEach(t),tqr=i(Ce),l0=n(Ce,"LI",{});var kUe=s(l0);HAe=n(kUe,"STRONG",{});var joa=s(HAe);aqr=r(joa,"ctrl"),joa.forEach(t),nqr=r(kUe," \u2014 "),koe=n(kUe,"A",{href:!0});var Doa=s(koe);sqr=r(Doa,"TFCTRLLMHeadModel"),Doa.forEach(t),lqr=r(kUe," (CTRL model)"),kUe.forEach(t),iqr=i(Ce),i0=n(Ce,"LI",{});var SUe=s(i0);JAe=n(SUe,"STRONG",{});var Goa=s(JAe);dqr=r(Goa,"gpt2"),Goa.forEach(t),cqr=r(SUe," \u2014 "),Soe=n(SUe,"A",{href:!0});var Ooa=s(Soe);mqr=r(Ooa,"TFGPT2LMHeadModel"),Ooa.forEach(t),fqr=r(SUe," (OpenAI GPT-2 model)"),SUe.forEach(t),gqr=i(Ce),d0=n(Ce,"LI",{});var RUe=s(d0);YAe=n(RUe,"STRONG",{});var Voa=s(YAe);hqr=r(Voa,"gptj"),Voa.forEach(t),uqr=r(RUe," \u2014 "),Roe=n(RUe,"A",{href:!0});var Xoa=s(Roe);pqr=r(Xoa,"TFGPTJForCausalLM"),Xoa.forEach(t),_qr=r(RUe," (GPT-J model)"),RUe.forEach(t),bqr=i(Ce),c0=n(Ce,"LI",{});var PUe=s(c0);KAe=n(PUe,"STRONG",{});var zoa=s(KAe);vqr=r(zoa,"openai-gpt"),zoa.forEach(t),Fqr=r(PUe," \u2014 "),Poe=n(PUe,"A",{href:!0});var Qoa=s(Poe);Tqr=r(Qoa,"TFOpenAIGPTLMHeadModel"),Qoa.forEach(t),Mqr=r(PUe," (OpenAI GPT model)"),PUe.forEach(t),Eqr=i(Ce),m0=n(Ce,"LI",{});var BUe=s(m0);ZAe=n(BUe,"STRONG",{});var Woa=s(ZAe);Cqr=r(Woa,"opt"),Woa.forEach(t),wqr=r(BUe," \u2014 "),Boe=n(BUe,"A",{href:!0});var Uoa=s(Boe);Aqr=r(Uoa,"TFOPTForCausalLM"),Uoa.forEach(t),Lqr=r(BUe," (OPT model)"),BUe.forEach(t),yqr=i(Ce),f0=n(Ce,"LI",{});var IUe=s(f0);e6e=n(IUe,"STRONG",{});var Hoa=s(e6e);xqr=r(Hoa,"rembert"),Hoa.forEach(t),$qr=r(IUe," \u2014 "),Ioe=n(IUe,"A",{href:!0});var Joa=s(Ioe);kqr=r(Joa,"TFRemBertForCausalLM"),Joa.forEach(t),Sqr=r(IUe," (RemBERT model)"),IUe.forEach(t),Rqr=i(Ce),g0=n(Ce,"LI",{});var NUe=s(g0);o6e=n(NUe,"STRONG",{});var Yoa=s(o6e);Pqr=r(Yoa,"roberta"),Yoa.forEach(t),Bqr=r(NUe," \u2014 "),Noe=n(NUe,"A",{href:!0});var Koa=s(Noe);Iqr=r(Koa,"TFRobertaForCausalLM"),Koa.forEach(t),Nqr=r(NUe," (RoBERTa model)"),NUe.forEach(t),qqr=i(Ce),h0=n(Ce,"LI",{});var qUe=s(h0);r6e=n(qUe,"STRONG",{});var Zoa=s(r6e);jqr=r(Zoa,"roformer"),Zoa.forEach(t),Dqr=r(qUe," \u2014 "),qoe=n(qUe,"A",{href:!0});var era=s(qoe);Gqr=r(era,"TFRoFormerForCausalLM"),era.forEach(t),Oqr=r(qUe," (RoFormer model)"),qUe.forEach(t),Vqr=i(Ce),u0=n(Ce,"LI",{});var jUe=s(u0);t6e=n(jUe,"STRONG",{});var ora=s(t6e);Xqr=r(ora,"transfo-xl"),ora.forEach(t),zqr=r(jUe," \u2014 "),joe=n(jUe,"A",{href:!0});var rra=s(joe);Qqr=r(rra,"TFTransfoXLLMHeadModel"),rra.forEach(t),Wqr=r(jUe," (Transformer-XL model)"),jUe.forEach(t),Uqr=i(Ce),p0=n(Ce,"LI",{});var DUe=s(p0);a6e=n(DUe,"STRONG",{});var tra=s(a6e);Hqr=r(tra,"xglm"),tra.forEach(t),Jqr=r(DUe," \u2014 "),Doe=n(DUe,"A",{href:!0});var ara=s(Doe);Yqr=r(ara,"TFXGLMForCausalLM"),ara.forEach(t),Kqr=r(DUe," (XGLM model)"),DUe.forEach(t),Zqr=i(Ce),_0=n(Ce,"LI",{});var GUe=s(_0);n6e=n(GUe,"STRONG",{});var nra=s(n6e);ejr=r(nra,"xlm"),nra.forEach(t),ojr=r(GUe," \u2014 "),Goe=n(GUe,"A",{href:!0});var sra=s(Goe);rjr=r(sra,"TFXLMWithLMHeadModel"),sra.forEach(t),tjr=r(GUe," (XLM model)"),GUe.forEach(t),ajr=i(Ce),b0=n(Ce,"LI",{});var OUe=s(b0);s6e=n(OUe,"STRONG",{});var lra=s(s6e);njr=r(lra,"xlnet"),lra.forEach(t),sjr=r(OUe," \u2014 "),Ooe=n(OUe,"A",{href:!0});var ira=s(Ooe);ljr=r(ira,"TFXLNetLMHeadModel"),ira.forEach(t),ijr=r(OUe," (XLNet model)"),OUe.forEach(t),Ce.forEach(t),djr=i(si),T(v0.$$.fragment,si),si.forEach(t),ni.forEach(t),Reo=i(m),Yc=n(m,"H2",{class:!0});var Uro=s(Yc);F0=n(Uro,"A",{id:!0,class:!0,href:!0});var dra=s(F0);l6e=n(dra,"SPAN",{});var cra=s(l6e);T(aS.$$.fragment,cra),cra.forEach(t),dra.forEach(t),cjr=i(Uro),i6e=n(Uro,"SPAN",{});var mra=s(i6e);mjr=r(mra,"TFAutoModelForImageClassification"),mra.forEach(t),Uro.forEach(t),Peo=i(m),dr=n(m,"DIV",{class:!0});var li=s(dr);T(nS.$$.fragment,li),fjr=i(li),Kc=n(li,"P",{});var zie=s(Kc);gjr=r(zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Voe=n(zie,"A",{href:!0});var fra=s(Voe);hjr=r(fra,"from_pretrained()"),fra.forEach(t),ujr=r(zie," class method or the "),Xoe=n(zie,"A",{href:!0});var gra=s(Xoe);pjr=r(gra,"from_config()"),gra.forEach(t),_jr=r(zie,` class
method.`),zie.forEach(t),bjr=i(li),sS=n(li,"P",{});var Hro=s(sS);vjr=r(Hro,"This class cannot be instantiated directly using "),d6e=n(Hro,"CODE",{});var hra=s(d6e);Fjr=r(hra,"__init__()"),hra.forEach(t),Tjr=r(Hro," (throws an error)."),Hro.forEach(t),Mjr=i(li),Wt=n(li,"DIV",{class:!0});var U8=s(Wt);T(lS.$$.fragment,U8),Ejr=i(U8),c6e=n(U8,"P",{});var ura=s(c6e);Cjr=r(ura,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ura.forEach(t),wjr=i(U8),Zc=n(U8,"P",{});var Qie=s(Zc);Ajr=r(Qie,`Note:
Loading a model from its configuration file does `),m6e=n(Qie,"STRONG",{});var pra=s(m6e);Ljr=r(pra,"not"),pra.forEach(t),yjr=r(Qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=n(Qie,"A",{href:!0});var _ra=s(zoe);xjr=r(_ra,"from_pretrained()"),_ra.forEach(t),$jr=r(Qie," to load the model weights."),Qie.forEach(t),kjr=i(U8),T(T0.$$.fragment,U8),U8.forEach(t),Sjr=i(li),jr=n(li,"DIV",{class:!0});var ii=s(jr);T(iS.$$.fragment,ii),Rjr=i(ii),f6e=n(ii,"P",{});var bra=s(f6e);Pjr=r(bra,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),bra.forEach(t),Bjr=i(ii),yn=n(ii,"P",{});var H8=s(yn);Ijr=r(H8,"The model class to instantiate is selected based on the "),g6e=n(H8,"CODE",{});var vra=s(g6e);Njr=r(vra,"model_type"),vra.forEach(t),qjr=r(H8,` property of the config object (either
passed as an argument or loaded from `),h6e=n(H8,"CODE",{});var Fra=s(h6e);jjr=r(Fra,"pretrained_model_name_or_path"),Fra.forEach(t),Djr=r(H8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u6e=n(H8,"CODE",{});var Tra=s(u6e);Gjr=r(Tra,"pretrained_model_name_or_path"),Tra.forEach(t),Ojr=r(H8,":"),H8.forEach(t),Vjr=i(ii),Be=n(ii,"UL",{});var We=s(Be);M0=n(We,"LI",{});var VUe=s(M0);p6e=n(VUe,"STRONG",{});var Mra=s(p6e);Xjr=r(Mra,"convnext"),Mra.forEach(t),zjr=r(VUe," \u2014 "),Qoe=n(VUe,"A",{href:!0});var Era=s(Qoe);Qjr=r(Era,"TFConvNextForImageClassification"),Era.forEach(t),Wjr=r(VUe," (ConvNeXT model)"),VUe.forEach(t),Ujr=i(We),E0=n(We,"LI",{});var XUe=s(E0);_6e=n(XUe,"STRONG",{});var Cra=s(_6e);Hjr=r(Cra,"data2vec-vision"),Cra.forEach(t),Jjr=r(XUe," \u2014 "),Woe=n(XUe,"A",{href:!0});var wra=s(Woe);Yjr=r(wra,"TFData2VecVisionForImageClassification"),wra.forEach(t),Kjr=r(XUe," (Data2VecVision model)"),XUe.forEach(t),Zjr=i(We),Tl=n(We,"LI",{});var WB=s(Tl);b6e=n(WB,"STRONG",{});var Ara=s(b6e);eDr=r(Ara,"deit"),Ara.forEach(t),oDr=r(WB," \u2014 "),Uoe=n(WB,"A",{href:!0});var Lra=s(Uoe);rDr=r(Lra,"TFDeiTForImageClassification"),Lra.forEach(t),tDr=r(WB," or "),Hoe=n(WB,"A",{href:!0});var yra=s(Hoe);aDr=r(yra,"TFDeiTForImageClassificationWithTeacher"),yra.forEach(t),nDr=r(WB," (DeiT model)"),WB.forEach(t),sDr=i(We),C0=n(We,"LI",{});var zUe=s(C0);v6e=n(zUe,"STRONG",{});var xra=s(v6e);lDr=r(xra,"mobilevit"),xra.forEach(t),iDr=r(zUe," \u2014 "),Joe=n(zUe,"A",{href:!0});var $ra=s(Joe);dDr=r($ra,"TFMobileViTForImageClassification"),$ra.forEach(t),cDr=r(zUe," (MobileViT model)"),zUe.forEach(t),mDr=i(We),w0=n(We,"LI",{});var QUe=s(w0);F6e=n(QUe,"STRONG",{});var kra=s(F6e);fDr=r(kra,"regnet"),kra.forEach(t),gDr=r(QUe," \u2014 "),Yoe=n(QUe,"A",{href:!0});var Sra=s(Yoe);hDr=r(Sra,"TFRegNetForImageClassification"),Sra.forEach(t),uDr=r(QUe," (RegNet model)"),QUe.forEach(t),pDr=i(We),A0=n(We,"LI",{});var WUe=s(A0);T6e=n(WUe,"STRONG",{});var Rra=s(T6e);_Dr=r(Rra,"resnet"),Rra.forEach(t),bDr=r(WUe," \u2014 "),Koe=n(WUe,"A",{href:!0});var Pra=s(Koe);vDr=r(Pra,"TFResNetForImageClassification"),Pra.forEach(t),FDr=r(WUe," (ResNet model)"),WUe.forEach(t),TDr=i(We),L0=n(We,"LI",{});var UUe=s(L0);M6e=n(UUe,"STRONG",{});var Bra=s(M6e);MDr=r(Bra,"segformer"),Bra.forEach(t),EDr=r(UUe," \u2014 "),Zoe=n(UUe,"A",{href:!0});var Ira=s(Zoe);CDr=r(Ira,"TFSegformerForImageClassification"),Ira.forEach(t),wDr=r(UUe," (SegFormer model)"),UUe.forEach(t),ADr=i(We),y0=n(We,"LI",{});var HUe=s(y0);E6e=n(HUe,"STRONG",{});var Nra=s(E6e);LDr=r(Nra,"swin"),Nra.forEach(t),yDr=r(HUe," \u2014 "),ere=n(HUe,"A",{href:!0});var qra=s(ere);xDr=r(qra,"TFSwinForImageClassification"),qra.forEach(t),$Dr=r(HUe," (Swin Transformer model)"),HUe.forEach(t),kDr=i(We),x0=n(We,"LI",{});var JUe=s(x0);C6e=n(JUe,"STRONG",{});var jra=s(C6e);SDr=r(jra,"vit"),jra.forEach(t),RDr=r(JUe," \u2014 "),ore=n(JUe,"A",{href:!0});var Dra=s(ore);PDr=r(Dra,"TFViTForImageClassification"),Dra.forEach(t),BDr=r(JUe," (ViT model)"),JUe.forEach(t),We.forEach(t),IDr=i(ii),T($0.$$.fragment,ii),ii.forEach(t),li.forEach(t),Beo=i(m),em=n(m,"H2",{class:!0});var Jro=s(em);k0=n(Jro,"A",{id:!0,class:!0,href:!0});var Gra=s(k0);w6e=n(Gra,"SPAN",{});var Ora=s(w6e);T(dS.$$.fragment,Ora),Ora.forEach(t),Gra.forEach(t),NDr=i(Jro),A6e=n(Jro,"SPAN",{});var Vra=s(A6e);qDr=r(Vra,"TFAutoModelForSemanticSegmentation"),Vra.forEach(t),Jro.forEach(t),Ieo=i(m),cr=n(m,"DIV",{class:!0});var di=s(cr);T(cS.$$.fragment,di),jDr=i(di),om=n(di,"P",{});var Wie=s(om);DDr=r(Wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),rre=n(Wie,"A",{href:!0});var Xra=s(rre);GDr=r(Xra,"from_pretrained()"),Xra.forEach(t),ODr=r(Wie," class method or the "),tre=n(Wie,"A",{href:!0});var zra=s(tre);VDr=r(zra,"from_config()"),zra.forEach(t),XDr=r(Wie,` class
method.`),Wie.forEach(t),zDr=i(di),mS=n(di,"P",{});var Yro=s(mS);QDr=r(Yro,"This class cannot be instantiated directly using "),L6e=n(Yro,"CODE",{});var Qra=s(L6e);WDr=r(Qra,"__init__()"),Qra.forEach(t),UDr=r(Yro," (throws an error)."),Yro.forEach(t),HDr=i(di),Ut=n(di,"DIV",{class:!0});var J8=s(Ut);T(fS.$$.fragment,J8),JDr=i(J8),y6e=n(J8,"P",{});var Wra=s(y6e);YDr=r(Wra,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Wra.forEach(t),KDr=i(J8),rm=n(J8,"P",{});var Uie=s(rm);ZDr=r(Uie,`Note:
Loading a model from its configuration file does `),x6e=n(Uie,"STRONG",{});var Ura=s(x6e);eGr=r(Ura,"not"),Ura.forEach(t),oGr=r(Uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),are=n(Uie,"A",{href:!0});var Hra=s(are);rGr=r(Hra,"from_pretrained()"),Hra.forEach(t),tGr=r(Uie," to load the model weights."),Uie.forEach(t),aGr=i(J8),T(S0.$$.fragment,J8),J8.forEach(t),nGr=i(di),Dr=n(di,"DIV",{class:!0});var ci=s(Dr);T(gS.$$.fragment,ci),sGr=i(ci),$6e=n(ci,"P",{});var Jra=s($6e);lGr=r(Jra,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Jra.forEach(t),iGr=i(ci),xn=n(ci,"P",{});var Y8=s(xn);dGr=r(Y8,"The model class to instantiate is selected based on the "),k6e=n(Y8,"CODE",{});var Yra=s(k6e);cGr=r(Yra,"model_type"),Yra.forEach(t),mGr=r(Y8,` property of the config object (either
passed as an argument or loaded from `),S6e=n(Y8,"CODE",{});var Kra=s(S6e);fGr=r(Kra,"pretrained_model_name_or_path"),Kra.forEach(t),gGr=r(Y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R6e=n(Y8,"CODE",{});var Zra=s(R6e);hGr=r(Zra,"pretrained_model_name_or_path"),Zra.forEach(t),uGr=r(Y8,":"),Y8.forEach(t),pGr=i(ci),tm=n(ci,"UL",{});var Hie=s(tm);R0=n(Hie,"LI",{});var YUe=s(R0);P6e=n(YUe,"STRONG",{});var eta=s(P6e);_Gr=r(eta,"data2vec-vision"),eta.forEach(t),bGr=r(YUe," \u2014 "),nre=n(YUe,"A",{href:!0});var ota=s(nre);vGr=r(ota,"TFData2VecVisionForSemanticSegmentation"),ota.forEach(t),FGr=r(YUe," (Data2VecVision model)"),YUe.forEach(t),TGr=i(Hie),P0=n(Hie,"LI",{});var KUe=s(P0);B6e=n(KUe,"STRONG",{});var rta=s(B6e);MGr=r(rta,"mobilevit"),rta.forEach(t),EGr=r(KUe," \u2014 "),sre=n(KUe,"A",{href:!0});var tta=s(sre);CGr=r(tta,"TFMobileViTForSemanticSegmentation"),tta.forEach(t),wGr=r(KUe," (MobileViT model)"),KUe.forEach(t),AGr=i(Hie),B0=n(Hie,"LI",{});var ZUe=s(B0);I6e=n(ZUe,"STRONG",{});var ata=s(I6e);LGr=r(ata,"segformer"),ata.forEach(t),yGr=r(ZUe," \u2014 "),lre=n(ZUe,"A",{href:!0});var nta=s(lre);xGr=r(nta,"TFSegformerForSemanticSegmentation"),nta.forEach(t),$Gr=r(ZUe," (SegFormer model)"),ZUe.forEach(t),Hie.forEach(t),kGr=i(ci),T(I0.$$.fragment,ci),ci.forEach(t),di.forEach(t),Neo=i(m),am=n(m,"H2",{class:!0});var Kro=s(am);N0=n(Kro,"A",{id:!0,class:!0,href:!0});var sta=s(N0);N6e=n(sta,"SPAN",{});var lta=s(N6e);T(hS.$$.fragment,lta),lta.forEach(t),sta.forEach(t),SGr=i(Kro),q6e=n(Kro,"SPAN",{});var ita=s(q6e);RGr=r(ita,"TFAutoModelForMaskedLM"),ita.forEach(t),Kro.forEach(t),qeo=i(m),mr=n(m,"DIV",{class:!0});var mi=s(mr);T(uS.$$.fragment,mi),PGr=i(mi),nm=n(mi,"P",{});var Jie=s(nm);BGr=r(Jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ire=n(Jie,"A",{href:!0});var dta=s(ire);IGr=r(dta,"from_pretrained()"),dta.forEach(t),NGr=r(Jie," class method or the "),dre=n(Jie,"A",{href:!0});var cta=s(dre);qGr=r(cta,"from_config()"),cta.forEach(t),jGr=r(Jie,` class
method.`),Jie.forEach(t),DGr=i(mi),pS=n(mi,"P",{});var Zro=s(pS);GGr=r(Zro,"This class cannot be instantiated directly using "),j6e=n(Zro,"CODE",{});var mta=s(j6e);OGr=r(mta,"__init__()"),mta.forEach(t),VGr=r(Zro," (throws an error)."),Zro.forEach(t),XGr=i(mi),Ht=n(mi,"DIV",{class:!0});var K8=s(Ht);T(_S.$$.fragment,K8),zGr=i(K8),D6e=n(K8,"P",{});var fta=s(D6e);QGr=r(fta,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),fta.forEach(t),WGr=i(K8),sm=n(K8,"P",{});var Yie=s(sm);UGr=r(Yie,`Note:
Loading a model from its configuration file does `),G6e=n(Yie,"STRONG",{});var gta=s(G6e);HGr=r(gta,"not"),gta.forEach(t),JGr=r(Yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cre=n(Yie,"A",{href:!0});var hta=s(cre);YGr=r(hta,"from_pretrained()"),hta.forEach(t),KGr=r(Yie," to load the model weights."),Yie.forEach(t),ZGr=i(K8),T(q0.$$.fragment,K8),K8.forEach(t),eOr=i(mi),Gr=n(mi,"DIV",{class:!0});var fi=s(Gr);T(bS.$$.fragment,fi),oOr=i(fi),O6e=n(fi,"P",{});var uta=s(O6e);rOr=r(uta,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),uta.forEach(t),tOr=i(fi),$n=n(fi,"P",{});var Z8=s($n);aOr=r(Z8,"The model class to instantiate is selected based on the "),V6e=n(Z8,"CODE",{});var pta=s(V6e);nOr=r(pta,"model_type"),pta.forEach(t),sOr=r(Z8,` property of the config object (either
passed as an argument or loaded from `),X6e=n(Z8,"CODE",{});var _ta=s(X6e);lOr=r(_ta,"pretrained_model_name_or_path"),_ta.forEach(t),iOr=r(Z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z6e=n(Z8,"CODE",{});var bta=s(z6e);dOr=r(bta,"pretrained_model_name_or_path"),bta.forEach(t),cOr=r(Z8,":"),Z8.forEach(t),mOr=i(fi),ge=n(fi,"UL",{});var _e=s(ge);j0=n(_e,"LI",{});var eHe=s(j0);Q6e=n(eHe,"STRONG",{});var vta=s(Q6e);fOr=r(vta,"albert"),vta.forEach(t),gOr=r(eHe," \u2014 "),mre=n(eHe,"A",{href:!0});var Fta=s(mre);hOr=r(Fta,"TFAlbertForMaskedLM"),Fta.forEach(t),uOr=r(eHe," (ALBERT model)"),eHe.forEach(t),pOr=i(_e),D0=n(_e,"LI",{});var oHe=s(D0);W6e=n(oHe,"STRONG",{});var Tta=s(W6e);_Or=r(Tta,"bert"),Tta.forEach(t),bOr=r(oHe," \u2014 "),fre=n(oHe,"A",{href:!0});var Mta=s(fre);vOr=r(Mta,"TFBertForMaskedLM"),Mta.forEach(t),FOr=r(oHe," (BERT model)"),oHe.forEach(t),TOr=i(_e),G0=n(_e,"LI",{});var rHe=s(G0);U6e=n(rHe,"STRONG",{});var Eta=s(U6e);MOr=r(Eta,"camembert"),Eta.forEach(t),EOr=r(rHe," \u2014 "),gre=n(rHe,"A",{href:!0});var Cta=s(gre);COr=r(Cta,"TFCamembertForMaskedLM"),Cta.forEach(t),wOr=r(rHe," (CamemBERT model)"),rHe.forEach(t),AOr=i(_e),O0=n(_e,"LI",{});var tHe=s(O0);H6e=n(tHe,"STRONG",{});var wta=s(H6e);LOr=r(wta,"convbert"),wta.forEach(t),yOr=r(tHe," \u2014 "),hre=n(tHe,"A",{href:!0});var Ata=s(hre);xOr=r(Ata,"TFConvBertForMaskedLM"),Ata.forEach(t),$Or=r(tHe," (ConvBERT model)"),tHe.forEach(t),kOr=i(_e),V0=n(_e,"LI",{});var aHe=s(V0);J6e=n(aHe,"STRONG",{});var Lta=s(J6e);SOr=r(Lta,"deberta"),Lta.forEach(t),ROr=r(aHe," \u2014 "),ure=n(aHe,"A",{href:!0});var yta=s(ure);POr=r(yta,"TFDebertaForMaskedLM"),yta.forEach(t),BOr=r(aHe," (DeBERTa model)"),aHe.forEach(t),IOr=i(_e),X0=n(_e,"LI",{});var nHe=s(X0);Y6e=n(nHe,"STRONG",{});var xta=s(Y6e);NOr=r(xta,"deberta-v2"),xta.forEach(t),qOr=r(nHe," \u2014 "),pre=n(nHe,"A",{href:!0});var $ta=s(pre);jOr=r($ta,"TFDebertaV2ForMaskedLM"),$ta.forEach(t),DOr=r(nHe," (DeBERTa-v2 model)"),nHe.forEach(t),GOr=i(_e),z0=n(_e,"LI",{});var sHe=s(z0);K6e=n(sHe,"STRONG",{});var kta=s(K6e);OOr=r(kta,"distilbert"),kta.forEach(t),VOr=r(sHe," \u2014 "),_re=n(sHe,"A",{href:!0});var Sta=s(_re);XOr=r(Sta,"TFDistilBertForMaskedLM"),Sta.forEach(t),zOr=r(sHe," (DistilBERT model)"),sHe.forEach(t),QOr=i(_e),Q0=n(_e,"LI",{});var lHe=s(Q0);Z6e=n(lHe,"STRONG",{});var Rta=s(Z6e);WOr=r(Rta,"electra"),Rta.forEach(t),UOr=r(lHe," \u2014 "),bre=n(lHe,"A",{href:!0});var Pta=s(bre);HOr=r(Pta,"TFElectraForMaskedLM"),Pta.forEach(t),JOr=r(lHe," (ELECTRA model)"),lHe.forEach(t),YOr=i(_e),W0=n(_e,"LI",{});var iHe=s(W0);e7e=n(iHe,"STRONG",{});var Bta=s(e7e);KOr=r(Bta,"flaubert"),Bta.forEach(t),ZOr=r(iHe," \u2014 "),vre=n(iHe,"A",{href:!0});var Ita=s(vre);eVr=r(Ita,"TFFlaubertWithLMHeadModel"),Ita.forEach(t),oVr=r(iHe," (FlauBERT model)"),iHe.forEach(t),rVr=i(_e),U0=n(_e,"LI",{});var dHe=s(U0);o7e=n(dHe,"STRONG",{});var Nta=s(o7e);tVr=r(Nta,"funnel"),Nta.forEach(t),aVr=r(dHe," \u2014 "),Fre=n(dHe,"A",{href:!0});var qta=s(Fre);nVr=r(qta,"TFFunnelForMaskedLM"),qta.forEach(t),sVr=r(dHe," (Funnel Transformer model)"),dHe.forEach(t),lVr=i(_e),H0=n(_e,"LI",{});var cHe=s(H0);r7e=n(cHe,"STRONG",{});var jta=s(r7e);iVr=r(jta,"layoutlm"),jta.forEach(t),dVr=r(cHe," \u2014 "),Tre=n(cHe,"A",{href:!0});var Dta=s(Tre);cVr=r(Dta,"TFLayoutLMForMaskedLM"),Dta.forEach(t),mVr=r(cHe," (LayoutLM model)"),cHe.forEach(t),fVr=i(_e),J0=n(_e,"LI",{});var mHe=s(J0);t7e=n(mHe,"STRONG",{});var Gta=s(t7e);gVr=r(Gta,"longformer"),Gta.forEach(t),hVr=r(mHe," \u2014 "),Mre=n(mHe,"A",{href:!0});var Ota=s(Mre);uVr=r(Ota,"TFLongformerForMaskedLM"),Ota.forEach(t),pVr=r(mHe," (Longformer model)"),mHe.forEach(t),_Vr=i(_e),Y0=n(_e,"LI",{});var fHe=s(Y0);a7e=n(fHe,"STRONG",{});var Vta=s(a7e);bVr=r(Vta,"mobilebert"),Vta.forEach(t),vVr=r(fHe," \u2014 "),Ere=n(fHe,"A",{href:!0});var Xta=s(Ere);FVr=r(Xta,"TFMobileBertForMaskedLM"),Xta.forEach(t),TVr=r(fHe," (MobileBERT model)"),fHe.forEach(t),MVr=i(_e),K0=n(_e,"LI",{});var gHe=s(K0);n7e=n(gHe,"STRONG",{});var zta=s(n7e);EVr=r(zta,"mpnet"),zta.forEach(t),CVr=r(gHe," \u2014 "),Cre=n(gHe,"A",{href:!0});var Qta=s(Cre);wVr=r(Qta,"TFMPNetForMaskedLM"),Qta.forEach(t),AVr=r(gHe," (MPNet model)"),gHe.forEach(t),LVr=i(_e),Z0=n(_e,"LI",{});var hHe=s(Z0);s7e=n(hHe,"STRONG",{});var Wta=s(s7e);yVr=r(Wta,"rembert"),Wta.forEach(t),xVr=r(hHe," \u2014 "),wre=n(hHe,"A",{href:!0});var Uta=s(wre);$Vr=r(Uta,"TFRemBertForMaskedLM"),Uta.forEach(t),kVr=r(hHe," (RemBERT model)"),hHe.forEach(t),SVr=i(_e),ew=n(_e,"LI",{});var uHe=s(ew);l7e=n(uHe,"STRONG",{});var Hta=s(l7e);RVr=r(Hta,"roberta"),Hta.forEach(t),PVr=r(uHe," \u2014 "),Are=n(uHe,"A",{href:!0});var Jta=s(Are);BVr=r(Jta,"TFRobertaForMaskedLM"),Jta.forEach(t),IVr=r(uHe," (RoBERTa model)"),uHe.forEach(t),NVr=i(_e),ow=n(_e,"LI",{});var pHe=s(ow);i7e=n(pHe,"STRONG",{});var Yta=s(i7e);qVr=r(Yta,"roformer"),Yta.forEach(t),jVr=r(pHe," \u2014 "),Lre=n(pHe,"A",{href:!0});var Kta=s(Lre);DVr=r(Kta,"TFRoFormerForMaskedLM"),Kta.forEach(t),GVr=r(pHe," (RoFormer model)"),pHe.forEach(t),OVr=i(_e),rw=n(_e,"LI",{});var _He=s(rw);d7e=n(_He,"STRONG",{});var Zta=s(d7e);VVr=r(Zta,"tapas"),Zta.forEach(t),XVr=r(_He," \u2014 "),yre=n(_He,"A",{href:!0});var eaa=s(yre);zVr=r(eaa,"TFTapasForMaskedLM"),eaa.forEach(t),QVr=r(_He," (TAPAS model)"),_He.forEach(t),WVr=i(_e),tw=n(_e,"LI",{});var bHe=s(tw);c7e=n(bHe,"STRONG",{});var oaa=s(c7e);UVr=r(oaa,"xlm"),oaa.forEach(t),HVr=r(bHe," \u2014 "),xre=n(bHe,"A",{href:!0});var raa=s(xre);JVr=r(raa,"TFXLMWithLMHeadModel"),raa.forEach(t),YVr=r(bHe," (XLM model)"),bHe.forEach(t),KVr=i(_e),aw=n(_e,"LI",{});var vHe=s(aw);m7e=n(vHe,"STRONG",{});var taa=s(m7e);ZVr=r(taa,"xlm-roberta"),taa.forEach(t),eXr=r(vHe," \u2014 "),$re=n(vHe,"A",{href:!0});var aaa=s($re);oXr=r(aaa,"TFXLMRobertaForMaskedLM"),aaa.forEach(t),rXr=r(vHe," (XLM-RoBERTa model)"),vHe.forEach(t),_e.forEach(t),tXr=i(fi),T(nw.$$.fragment,fi),fi.forEach(t),mi.forEach(t),jeo=i(m),lm=n(m,"H2",{class:!0});var eto=s(lm);sw=n(eto,"A",{id:!0,class:!0,href:!0});var naa=s(sw);f7e=n(naa,"SPAN",{});var saa=s(f7e);T(vS.$$.fragment,saa),saa.forEach(t),naa.forEach(t),aXr=i(eto),g7e=n(eto,"SPAN",{});var laa=s(g7e);nXr=r(laa,"TFAutoModelForSeq2SeqLM"),laa.forEach(t),eto.forEach(t),Deo=i(m),fr=n(m,"DIV",{class:!0});var gi=s(fr);T(FS.$$.fragment,gi),sXr=i(gi),im=n(gi,"P",{});var Kie=s(im);lXr=r(Kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kre=n(Kie,"A",{href:!0});var iaa=s(kre);iXr=r(iaa,"from_pretrained()"),iaa.forEach(t),dXr=r(Kie," class method or the "),Sre=n(Kie,"A",{href:!0});var daa=s(Sre);cXr=r(daa,"from_config()"),daa.forEach(t),mXr=r(Kie,` class
method.`),Kie.forEach(t),fXr=i(gi),TS=n(gi,"P",{});var oto=s(TS);gXr=r(oto,"This class cannot be instantiated directly using "),h7e=n(oto,"CODE",{});var caa=s(h7e);hXr=r(caa,"__init__()"),caa.forEach(t),uXr=r(oto," (throws an error)."),oto.forEach(t),pXr=i(gi),Jt=n(gi,"DIV",{class:!0});var e9=s(Jt);T(MS.$$.fragment,e9),_Xr=i(e9),u7e=n(e9,"P",{});var maa=s(u7e);bXr=r(maa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),maa.forEach(t),vXr=i(e9),dm=n(e9,"P",{});var Zie=s(dm);FXr=r(Zie,`Note:
Loading a model from its configuration file does `),p7e=n(Zie,"STRONG",{});var faa=s(p7e);TXr=r(faa,"not"),faa.forEach(t),MXr=r(Zie,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=n(Zie,"A",{href:!0});var gaa=s(Rre);EXr=r(gaa,"from_pretrained()"),gaa.forEach(t),CXr=r(Zie," to load the model weights."),Zie.forEach(t),wXr=i(e9),T(lw.$$.fragment,e9),e9.forEach(t),AXr=i(gi),Or=n(gi,"DIV",{class:!0});var hi=s(Or);T(ES.$$.fragment,hi),LXr=i(hi),_7e=n(hi,"P",{});var haa=s(_7e);yXr=r(haa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),haa.forEach(t),xXr=i(hi),kn=n(hi,"P",{});var o9=s(kn);$Xr=r(o9,"The model class to instantiate is selected based on the "),b7e=n(o9,"CODE",{});var uaa=s(b7e);kXr=r(uaa,"model_type"),uaa.forEach(t),SXr=r(o9,` property of the config object (either
passed as an argument or loaded from `),v7e=n(o9,"CODE",{});var paa=s(v7e);RXr=r(paa,"pretrained_model_name_or_path"),paa.forEach(t),PXr=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F7e=n(o9,"CODE",{});var _aa=s(F7e);BXr=r(_aa,"pretrained_model_name_or_path"),_aa.forEach(t),IXr=r(o9,":"),o9.forEach(t),NXr=i(hi),ye=n(hi,"UL",{});var Ne=s(ye);iw=n(Ne,"LI",{});var FHe=s(iw);T7e=n(FHe,"STRONG",{});var baa=s(T7e);qXr=r(baa,"bart"),baa.forEach(t),jXr=r(FHe," \u2014 "),Pre=n(FHe,"A",{href:!0});var vaa=s(Pre);DXr=r(vaa,"TFBartForConditionalGeneration"),vaa.forEach(t),GXr=r(FHe," (BART model)"),FHe.forEach(t),OXr=i(Ne),dw=n(Ne,"LI",{});var THe=s(dw);M7e=n(THe,"STRONG",{});var Faa=s(M7e);VXr=r(Faa,"blenderbot"),Faa.forEach(t),XXr=r(THe," \u2014 "),Bre=n(THe,"A",{href:!0});var Taa=s(Bre);zXr=r(Taa,"TFBlenderbotForConditionalGeneration"),Taa.forEach(t),QXr=r(THe," (Blenderbot model)"),THe.forEach(t),WXr=i(Ne),cw=n(Ne,"LI",{});var MHe=s(cw);E7e=n(MHe,"STRONG",{});var Maa=s(E7e);UXr=r(Maa,"blenderbot-small"),Maa.forEach(t),HXr=r(MHe," \u2014 "),Ire=n(MHe,"A",{href:!0});var Eaa=s(Ire);JXr=r(Eaa,"TFBlenderbotSmallForConditionalGeneration"),Eaa.forEach(t),YXr=r(MHe," (BlenderbotSmall model)"),MHe.forEach(t),KXr=i(Ne),mw=n(Ne,"LI",{});var EHe=s(mw);C7e=n(EHe,"STRONG",{});var Caa=s(C7e);ZXr=r(Caa,"encoder-decoder"),Caa.forEach(t),ezr=r(EHe," \u2014 "),Nre=n(EHe,"A",{href:!0});var waa=s(Nre);ozr=r(waa,"TFEncoderDecoderModel"),waa.forEach(t),rzr=r(EHe," (Encoder decoder model)"),EHe.forEach(t),tzr=i(Ne),fw=n(Ne,"LI",{});var CHe=s(fw);w7e=n(CHe,"STRONG",{});var Aaa=s(w7e);azr=r(Aaa,"led"),Aaa.forEach(t),nzr=r(CHe," \u2014 "),qre=n(CHe,"A",{href:!0});var Laa=s(qre);szr=r(Laa,"TFLEDForConditionalGeneration"),Laa.forEach(t),lzr=r(CHe," (LED model)"),CHe.forEach(t),izr=i(Ne),gw=n(Ne,"LI",{});var wHe=s(gw);A7e=n(wHe,"STRONG",{});var yaa=s(A7e);dzr=r(yaa,"marian"),yaa.forEach(t),czr=r(wHe," \u2014 "),jre=n(wHe,"A",{href:!0});var xaa=s(jre);mzr=r(xaa,"TFMarianMTModel"),xaa.forEach(t),fzr=r(wHe," (Marian model)"),wHe.forEach(t),gzr=i(Ne),hw=n(Ne,"LI",{});var AHe=s(hw);L7e=n(AHe,"STRONG",{});var $aa=s(L7e);hzr=r($aa,"mbart"),$aa.forEach(t),uzr=r(AHe," \u2014 "),Dre=n(AHe,"A",{href:!0});var kaa=s(Dre);pzr=r(kaa,"TFMBartForConditionalGeneration"),kaa.forEach(t),_zr=r(AHe," (mBART model)"),AHe.forEach(t),bzr=i(Ne),uw=n(Ne,"LI",{});var LHe=s(uw);y7e=n(LHe,"STRONG",{});var Saa=s(y7e);vzr=r(Saa,"mt5"),Saa.forEach(t),Fzr=r(LHe," \u2014 "),Gre=n(LHe,"A",{href:!0});var Raa=s(Gre);Tzr=r(Raa,"TFMT5ForConditionalGeneration"),Raa.forEach(t),Mzr=r(LHe," (MT5 model)"),LHe.forEach(t),Ezr=i(Ne),pw=n(Ne,"LI",{});var yHe=s(pw);x7e=n(yHe,"STRONG",{});var Paa=s(x7e);Czr=r(Paa,"pegasus"),Paa.forEach(t),wzr=r(yHe," \u2014 "),Ore=n(yHe,"A",{href:!0});var Baa=s(Ore);Azr=r(Baa,"TFPegasusForConditionalGeneration"),Baa.forEach(t),Lzr=r(yHe," (Pegasus model)"),yHe.forEach(t),yzr=i(Ne),_w=n(Ne,"LI",{});var xHe=s(_w);$7e=n(xHe,"STRONG",{});var Iaa=s($7e);xzr=r(Iaa,"t5"),Iaa.forEach(t),$zr=r(xHe," \u2014 "),Vre=n(xHe,"A",{href:!0});var Naa=s(Vre);kzr=r(Naa,"TFT5ForConditionalGeneration"),Naa.forEach(t),Szr=r(xHe," (T5 model)"),xHe.forEach(t),Ne.forEach(t),Rzr=i(hi),T(bw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),Geo=i(m),cm=n(m,"H2",{class:!0});var rto=s(cm);vw=n(rto,"A",{id:!0,class:!0,href:!0});var qaa=s(vw);k7e=n(qaa,"SPAN",{});var jaa=s(k7e);T(CS.$$.fragment,jaa),jaa.forEach(t),qaa.forEach(t),Pzr=i(rto),S7e=n(rto,"SPAN",{});var Daa=s(S7e);Bzr=r(Daa,"TFAutoModelForSequenceClassification"),Daa.forEach(t),rto.forEach(t),Oeo=i(m),gr=n(m,"DIV",{class:!0});var ui=s(gr);T(wS.$$.fragment,ui),Izr=i(ui),mm=n(ui,"P",{});var ede=s(mm);Nzr=r(ede,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Xre=n(ede,"A",{href:!0});var Gaa=s(Xre);qzr=r(Gaa,"from_pretrained()"),Gaa.forEach(t),jzr=r(ede," class method or the "),zre=n(ede,"A",{href:!0});var Oaa=s(zre);Dzr=r(Oaa,"from_config()"),Oaa.forEach(t),Gzr=r(ede,` class
method.`),ede.forEach(t),Ozr=i(ui),AS=n(ui,"P",{});var tto=s(AS);Vzr=r(tto,"This class cannot be instantiated directly using "),R7e=n(tto,"CODE",{});var Vaa=s(R7e);Xzr=r(Vaa,"__init__()"),Vaa.forEach(t),zzr=r(tto," (throws an error)."),tto.forEach(t),Qzr=i(ui),Yt=n(ui,"DIV",{class:!0});var r9=s(Yt);T(LS.$$.fragment,r9),Wzr=i(r9),P7e=n(r9,"P",{});var Xaa=s(P7e);Uzr=r(Xaa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Xaa.forEach(t),Hzr=i(r9),fm=n(r9,"P",{});var ode=s(fm);Jzr=r(ode,`Note:
Loading a model from its configuration file does `),B7e=n(ode,"STRONG",{});var zaa=s(B7e);Yzr=r(zaa,"not"),zaa.forEach(t),Kzr=r(ode,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qre=n(ode,"A",{href:!0});var Qaa=s(Qre);Zzr=r(Qaa,"from_pretrained()"),Qaa.forEach(t),eQr=r(ode," to load the model weights."),ode.forEach(t),oQr=i(r9),T(Fw.$$.fragment,r9),r9.forEach(t),rQr=i(ui),Vr=n(ui,"DIV",{class:!0});var pi=s(Vr);T(yS.$$.fragment,pi),tQr=i(pi),I7e=n(pi,"P",{});var Waa=s(I7e);aQr=r(Waa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Waa.forEach(t),nQr=i(pi),Sn=n(pi,"P",{});var t9=s(Sn);sQr=r(t9,"The model class to instantiate is selected based on the "),N7e=n(t9,"CODE",{});var Uaa=s(N7e);lQr=r(Uaa,"model_type"),Uaa.forEach(t),iQr=r(t9,` property of the config object (either
passed as an argument or loaded from `),q7e=n(t9,"CODE",{});var Haa=s(q7e);dQr=r(Haa,"pretrained_model_name_or_path"),Haa.forEach(t),cQr=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j7e=n(t9,"CODE",{});var Jaa=s(j7e);mQr=r(Jaa,"pretrained_model_name_or_path"),Jaa.forEach(t),fQr=r(t9,":"),t9.forEach(t),gQr=i(pi),re=n(pi,"UL",{});var ae=s(re);Tw=n(ae,"LI",{});var $He=s(Tw);D7e=n($He,"STRONG",{});var Yaa=s(D7e);hQr=r(Yaa,"albert"),Yaa.forEach(t),uQr=r($He," \u2014 "),Wre=n($He,"A",{href:!0});var Kaa=s(Wre);pQr=r(Kaa,"TFAlbertForSequenceClassification"),Kaa.forEach(t),_Qr=r($He," (ALBERT model)"),$He.forEach(t),bQr=i(ae),Mw=n(ae,"LI",{});var kHe=s(Mw);G7e=n(kHe,"STRONG",{});var Zaa=s(G7e);vQr=r(Zaa,"bert"),Zaa.forEach(t),FQr=r(kHe," \u2014 "),Ure=n(kHe,"A",{href:!0});var ena=s(Ure);TQr=r(ena,"TFBertForSequenceClassification"),ena.forEach(t),MQr=r(kHe," (BERT model)"),kHe.forEach(t),EQr=i(ae),Ew=n(ae,"LI",{});var SHe=s(Ew);O7e=n(SHe,"STRONG",{});var ona=s(O7e);CQr=r(ona,"camembert"),ona.forEach(t),wQr=r(SHe," \u2014 "),Hre=n(SHe,"A",{href:!0});var rna=s(Hre);AQr=r(rna,"TFCamembertForSequenceClassification"),rna.forEach(t),LQr=r(SHe," (CamemBERT model)"),SHe.forEach(t),yQr=i(ae),Cw=n(ae,"LI",{});var RHe=s(Cw);V7e=n(RHe,"STRONG",{});var tna=s(V7e);xQr=r(tna,"convbert"),tna.forEach(t),$Qr=r(RHe," \u2014 "),Jre=n(RHe,"A",{href:!0});var ana=s(Jre);kQr=r(ana,"TFConvBertForSequenceClassification"),ana.forEach(t),SQr=r(RHe," (ConvBERT model)"),RHe.forEach(t),RQr=i(ae),ww=n(ae,"LI",{});var PHe=s(ww);X7e=n(PHe,"STRONG",{});var nna=s(X7e);PQr=r(nna,"ctrl"),nna.forEach(t),BQr=r(PHe," \u2014 "),Yre=n(PHe,"A",{href:!0});var sna=s(Yre);IQr=r(sna,"TFCTRLForSequenceClassification"),sna.forEach(t),NQr=r(PHe," (CTRL model)"),PHe.forEach(t),qQr=i(ae),Aw=n(ae,"LI",{});var BHe=s(Aw);z7e=n(BHe,"STRONG",{});var lna=s(z7e);jQr=r(lna,"deberta"),lna.forEach(t),DQr=r(BHe," \u2014 "),Kre=n(BHe,"A",{href:!0});var ina=s(Kre);GQr=r(ina,"TFDebertaForSequenceClassification"),ina.forEach(t),OQr=r(BHe," (DeBERTa model)"),BHe.forEach(t),VQr=i(ae),Lw=n(ae,"LI",{});var IHe=s(Lw);Q7e=n(IHe,"STRONG",{});var dna=s(Q7e);XQr=r(dna,"deberta-v2"),dna.forEach(t),zQr=r(IHe," \u2014 "),Zre=n(IHe,"A",{href:!0});var cna=s(Zre);QQr=r(cna,"TFDebertaV2ForSequenceClassification"),cna.forEach(t),WQr=r(IHe," (DeBERTa-v2 model)"),IHe.forEach(t),UQr=i(ae),yw=n(ae,"LI",{});var NHe=s(yw);W7e=n(NHe,"STRONG",{});var mna=s(W7e);HQr=r(mna,"distilbert"),mna.forEach(t),JQr=r(NHe," \u2014 "),ete=n(NHe,"A",{href:!0});var fna=s(ete);YQr=r(fna,"TFDistilBertForSequenceClassification"),fna.forEach(t),KQr=r(NHe," (DistilBERT model)"),NHe.forEach(t),ZQr=i(ae),xw=n(ae,"LI",{});var qHe=s(xw);U7e=n(qHe,"STRONG",{});var gna=s(U7e);eWr=r(gna,"electra"),gna.forEach(t),oWr=r(qHe," \u2014 "),ote=n(qHe,"A",{href:!0});var hna=s(ote);rWr=r(hna,"TFElectraForSequenceClassification"),hna.forEach(t),tWr=r(qHe," (ELECTRA model)"),qHe.forEach(t),aWr=i(ae),$w=n(ae,"LI",{});var jHe=s($w);H7e=n(jHe,"STRONG",{});var una=s(H7e);nWr=r(una,"flaubert"),una.forEach(t),sWr=r(jHe," \u2014 "),rte=n(jHe,"A",{href:!0});var pna=s(rte);lWr=r(pna,"TFFlaubertForSequenceClassification"),pna.forEach(t),iWr=r(jHe," (FlauBERT model)"),jHe.forEach(t),dWr=i(ae),kw=n(ae,"LI",{});var DHe=s(kw);J7e=n(DHe,"STRONG",{});var _na=s(J7e);cWr=r(_na,"funnel"),_na.forEach(t),mWr=r(DHe," \u2014 "),tte=n(DHe,"A",{href:!0});var bna=s(tte);fWr=r(bna,"TFFunnelForSequenceClassification"),bna.forEach(t),gWr=r(DHe," (Funnel Transformer model)"),DHe.forEach(t),hWr=i(ae),Sw=n(ae,"LI",{});var GHe=s(Sw);Y7e=n(GHe,"STRONG",{});var vna=s(Y7e);uWr=r(vna,"gpt2"),vna.forEach(t),pWr=r(GHe," \u2014 "),ate=n(GHe,"A",{href:!0});var Fna=s(ate);_Wr=r(Fna,"TFGPT2ForSequenceClassification"),Fna.forEach(t),bWr=r(GHe," (OpenAI GPT-2 model)"),GHe.forEach(t),vWr=i(ae),Rw=n(ae,"LI",{});var OHe=s(Rw);K7e=n(OHe,"STRONG",{});var Tna=s(K7e);FWr=r(Tna,"gptj"),Tna.forEach(t),TWr=r(OHe," \u2014 "),nte=n(OHe,"A",{href:!0});var Mna=s(nte);MWr=r(Mna,"TFGPTJForSequenceClassification"),Mna.forEach(t),EWr=r(OHe," (GPT-J model)"),OHe.forEach(t),CWr=i(ae),Pw=n(ae,"LI",{});var VHe=s(Pw);Z7e=n(VHe,"STRONG",{});var Ena=s(Z7e);wWr=r(Ena,"layoutlm"),Ena.forEach(t),AWr=r(VHe," \u2014 "),ste=n(VHe,"A",{href:!0});var Cna=s(ste);LWr=r(Cna,"TFLayoutLMForSequenceClassification"),Cna.forEach(t),yWr=r(VHe," (LayoutLM model)"),VHe.forEach(t),xWr=i(ae),Bw=n(ae,"LI",{});var XHe=s(Bw);eLe=n(XHe,"STRONG",{});var wna=s(eLe);$Wr=r(wna,"layoutlmv3"),wna.forEach(t),kWr=r(XHe," \u2014 "),lte=n(XHe,"A",{href:!0});var Ana=s(lte);SWr=r(Ana,"TFLayoutLMv3ForSequenceClassification"),Ana.forEach(t),RWr=r(XHe," (LayoutLMv3 model)"),XHe.forEach(t),PWr=i(ae),Iw=n(ae,"LI",{});var zHe=s(Iw);oLe=n(zHe,"STRONG",{});var Lna=s(oLe);BWr=r(Lna,"longformer"),Lna.forEach(t),IWr=r(zHe," \u2014 "),ite=n(zHe,"A",{href:!0});var yna=s(ite);NWr=r(yna,"TFLongformerForSequenceClassification"),yna.forEach(t),qWr=r(zHe," (Longformer model)"),zHe.forEach(t),jWr=i(ae),Nw=n(ae,"LI",{});var QHe=s(Nw);rLe=n(QHe,"STRONG",{});var xna=s(rLe);DWr=r(xna,"mobilebert"),xna.forEach(t),GWr=r(QHe," \u2014 "),dte=n(QHe,"A",{href:!0});var $na=s(dte);OWr=r($na,"TFMobileBertForSequenceClassification"),$na.forEach(t),VWr=r(QHe," (MobileBERT model)"),QHe.forEach(t),XWr=i(ae),qw=n(ae,"LI",{});var WHe=s(qw);tLe=n(WHe,"STRONG",{});var kna=s(tLe);zWr=r(kna,"mpnet"),kna.forEach(t),QWr=r(WHe," \u2014 "),cte=n(WHe,"A",{href:!0});var Sna=s(cte);WWr=r(Sna,"TFMPNetForSequenceClassification"),Sna.forEach(t),UWr=r(WHe," (MPNet model)"),WHe.forEach(t),HWr=i(ae),jw=n(ae,"LI",{});var UHe=s(jw);aLe=n(UHe,"STRONG",{});var Rna=s(aLe);JWr=r(Rna,"openai-gpt"),Rna.forEach(t),YWr=r(UHe," \u2014 "),mte=n(UHe,"A",{href:!0});var Pna=s(mte);KWr=r(Pna,"TFOpenAIGPTForSequenceClassification"),Pna.forEach(t),ZWr=r(UHe," (OpenAI GPT model)"),UHe.forEach(t),eUr=i(ae),Dw=n(ae,"LI",{});var HHe=s(Dw);nLe=n(HHe,"STRONG",{});var Bna=s(nLe);oUr=r(Bna,"rembert"),Bna.forEach(t),rUr=r(HHe," \u2014 "),fte=n(HHe,"A",{href:!0});var Ina=s(fte);tUr=r(Ina,"TFRemBertForSequenceClassification"),Ina.forEach(t),aUr=r(HHe," (RemBERT model)"),HHe.forEach(t),nUr=i(ae),Gw=n(ae,"LI",{});var JHe=s(Gw);sLe=n(JHe,"STRONG",{});var Nna=s(sLe);sUr=r(Nna,"roberta"),Nna.forEach(t),lUr=r(JHe," \u2014 "),gte=n(JHe,"A",{href:!0});var qna=s(gte);iUr=r(qna,"TFRobertaForSequenceClassification"),qna.forEach(t),dUr=r(JHe," (RoBERTa model)"),JHe.forEach(t),cUr=i(ae),Ow=n(ae,"LI",{});var YHe=s(Ow);lLe=n(YHe,"STRONG",{});var jna=s(lLe);mUr=r(jna,"roformer"),jna.forEach(t),fUr=r(YHe," \u2014 "),hte=n(YHe,"A",{href:!0});var Dna=s(hte);gUr=r(Dna,"TFRoFormerForSequenceClassification"),Dna.forEach(t),hUr=r(YHe," (RoFormer model)"),YHe.forEach(t),uUr=i(ae),Vw=n(ae,"LI",{});var KHe=s(Vw);iLe=n(KHe,"STRONG",{});var Gna=s(iLe);pUr=r(Gna,"tapas"),Gna.forEach(t),_Ur=r(KHe," \u2014 "),ute=n(KHe,"A",{href:!0});var Ona=s(ute);bUr=r(Ona,"TFTapasForSequenceClassification"),Ona.forEach(t),vUr=r(KHe," (TAPAS model)"),KHe.forEach(t),FUr=i(ae),Xw=n(ae,"LI",{});var ZHe=s(Xw);dLe=n(ZHe,"STRONG",{});var Vna=s(dLe);TUr=r(Vna,"transfo-xl"),Vna.forEach(t),MUr=r(ZHe," \u2014 "),pte=n(ZHe,"A",{href:!0});var Xna=s(pte);EUr=r(Xna,"TFTransfoXLForSequenceClassification"),Xna.forEach(t),CUr=r(ZHe," (Transformer-XL model)"),ZHe.forEach(t),wUr=i(ae),zw=n(ae,"LI",{});var eJe=s(zw);cLe=n(eJe,"STRONG",{});var zna=s(cLe);AUr=r(zna,"xlm"),zna.forEach(t),LUr=r(eJe," \u2014 "),_te=n(eJe,"A",{href:!0});var Qna=s(_te);yUr=r(Qna,"TFXLMForSequenceClassification"),Qna.forEach(t),xUr=r(eJe," (XLM model)"),eJe.forEach(t),$Ur=i(ae),Qw=n(ae,"LI",{});var oJe=s(Qw);mLe=n(oJe,"STRONG",{});var Wna=s(mLe);kUr=r(Wna,"xlm-roberta"),Wna.forEach(t),SUr=r(oJe," \u2014 "),bte=n(oJe,"A",{href:!0});var Una=s(bte);RUr=r(Una,"TFXLMRobertaForSequenceClassification"),Una.forEach(t),PUr=r(oJe," (XLM-RoBERTa model)"),oJe.forEach(t),BUr=i(ae),Ww=n(ae,"LI",{});var rJe=s(Ww);fLe=n(rJe,"STRONG",{});var Hna=s(fLe);IUr=r(Hna,"xlnet"),Hna.forEach(t),NUr=r(rJe," \u2014 "),vte=n(rJe,"A",{href:!0});var Jna=s(vte);qUr=r(Jna,"TFXLNetForSequenceClassification"),Jna.forEach(t),jUr=r(rJe," (XLNet model)"),rJe.forEach(t),ae.forEach(t),DUr=i(pi),T(Uw.$$.fragment,pi),pi.forEach(t),ui.forEach(t),Veo=i(m),gm=n(m,"H2",{class:!0});var ato=s(gm);Hw=n(ato,"A",{id:!0,class:!0,href:!0});var Yna=s(Hw);gLe=n(Yna,"SPAN",{});var Kna=s(gLe);T(xS.$$.fragment,Kna),Kna.forEach(t),Yna.forEach(t),GUr=i(ato),hLe=n(ato,"SPAN",{});var Zna=s(hLe);OUr=r(Zna,"TFAutoModelForMultipleChoice"),Zna.forEach(t),ato.forEach(t),Xeo=i(m),hr=n(m,"DIV",{class:!0});var _i=s(hr);T($S.$$.fragment,_i),VUr=i(_i),hm=n(_i,"P",{});var rde=s(hm);XUr=r(rde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Fte=n(rde,"A",{href:!0});var esa=s(Fte);zUr=r(esa,"from_pretrained()"),esa.forEach(t),QUr=r(rde," class method or the "),Tte=n(rde,"A",{href:!0});var osa=s(Tte);WUr=r(osa,"from_config()"),osa.forEach(t),UUr=r(rde,` class
method.`),rde.forEach(t),HUr=i(_i),kS=n(_i,"P",{});var nto=s(kS);JUr=r(nto,"This class cannot be instantiated directly using "),uLe=n(nto,"CODE",{});var rsa=s(uLe);YUr=r(rsa,"__init__()"),rsa.forEach(t),KUr=r(nto," (throws an error)."),nto.forEach(t),ZUr=i(_i),Kt=n(_i,"DIV",{class:!0});var a9=s(Kt);T(SS.$$.fragment,a9),eHr=i(a9),pLe=n(a9,"P",{});var tsa=s(pLe);oHr=r(tsa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),tsa.forEach(t),rHr=i(a9),um=n(a9,"P",{});var tde=s(um);tHr=r(tde,`Note:
Loading a model from its configuration file does `),_Le=n(tde,"STRONG",{});var asa=s(_Le);aHr=r(asa,"not"),asa.forEach(t),nHr=r(tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mte=n(tde,"A",{href:!0});var nsa=s(Mte);sHr=r(nsa,"from_pretrained()"),nsa.forEach(t),lHr=r(tde," to load the model weights."),tde.forEach(t),iHr=i(a9),T(Jw.$$.fragment,a9),a9.forEach(t),dHr=i(_i),Xr=n(_i,"DIV",{class:!0});var bi=s(Xr);T(RS.$$.fragment,bi),cHr=i(bi),bLe=n(bi,"P",{});var ssa=s(bLe);mHr=r(ssa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ssa.forEach(t),fHr=i(bi),Rn=n(bi,"P",{});var n9=s(Rn);gHr=r(n9,"The model class to instantiate is selected based on the "),vLe=n(n9,"CODE",{});var lsa=s(vLe);hHr=r(lsa,"model_type"),lsa.forEach(t),uHr=r(n9,` property of the config object (either
passed as an argument or loaded from `),FLe=n(n9,"CODE",{});var isa=s(FLe);pHr=r(isa,"pretrained_model_name_or_path"),isa.forEach(t),_Hr=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TLe=n(n9,"CODE",{});var dsa=s(TLe);bHr=r(dsa,"pretrained_model_name_or_path"),dsa.forEach(t),vHr=r(n9,":"),n9.forEach(t),FHr=i(bi),ve=n(bi,"UL",{});var Te=s(ve);Yw=n(Te,"LI",{});var tJe=s(Yw);MLe=n(tJe,"STRONG",{});var csa=s(MLe);THr=r(csa,"albert"),csa.forEach(t),MHr=r(tJe," \u2014 "),Ete=n(tJe,"A",{href:!0});var msa=s(Ete);EHr=r(msa,"TFAlbertForMultipleChoice"),msa.forEach(t),CHr=r(tJe," (ALBERT model)"),tJe.forEach(t),wHr=i(Te),Kw=n(Te,"LI",{});var aJe=s(Kw);ELe=n(aJe,"STRONG",{});var fsa=s(ELe);AHr=r(fsa,"bert"),fsa.forEach(t),LHr=r(aJe," \u2014 "),Cte=n(aJe,"A",{href:!0});var gsa=s(Cte);yHr=r(gsa,"TFBertForMultipleChoice"),gsa.forEach(t),xHr=r(aJe," (BERT model)"),aJe.forEach(t),$Hr=i(Te),Zw=n(Te,"LI",{});var nJe=s(Zw);CLe=n(nJe,"STRONG",{});var hsa=s(CLe);kHr=r(hsa,"camembert"),hsa.forEach(t),SHr=r(nJe," \u2014 "),wte=n(nJe,"A",{href:!0});var usa=s(wte);RHr=r(usa,"TFCamembertForMultipleChoice"),usa.forEach(t),PHr=r(nJe," (CamemBERT model)"),nJe.forEach(t),BHr=i(Te),eA=n(Te,"LI",{});var sJe=s(eA);wLe=n(sJe,"STRONG",{});var psa=s(wLe);IHr=r(psa,"convbert"),psa.forEach(t),NHr=r(sJe," \u2014 "),Ate=n(sJe,"A",{href:!0});var _sa=s(Ate);qHr=r(_sa,"TFConvBertForMultipleChoice"),_sa.forEach(t),jHr=r(sJe," (ConvBERT model)"),sJe.forEach(t),DHr=i(Te),oA=n(Te,"LI",{});var lJe=s(oA);ALe=n(lJe,"STRONG",{});var bsa=s(ALe);GHr=r(bsa,"distilbert"),bsa.forEach(t),OHr=r(lJe," \u2014 "),Lte=n(lJe,"A",{href:!0});var vsa=s(Lte);VHr=r(vsa,"TFDistilBertForMultipleChoice"),vsa.forEach(t),XHr=r(lJe," (DistilBERT model)"),lJe.forEach(t),zHr=i(Te),rA=n(Te,"LI",{});var iJe=s(rA);LLe=n(iJe,"STRONG",{});var Fsa=s(LLe);QHr=r(Fsa,"electra"),Fsa.forEach(t),WHr=r(iJe," \u2014 "),yte=n(iJe,"A",{href:!0});var Tsa=s(yte);UHr=r(Tsa,"TFElectraForMultipleChoice"),Tsa.forEach(t),HHr=r(iJe," (ELECTRA model)"),iJe.forEach(t),JHr=i(Te),tA=n(Te,"LI",{});var dJe=s(tA);yLe=n(dJe,"STRONG",{});var Msa=s(yLe);YHr=r(Msa,"flaubert"),Msa.forEach(t),KHr=r(dJe," \u2014 "),xte=n(dJe,"A",{href:!0});var Esa=s(xte);ZHr=r(Esa,"TFFlaubertForMultipleChoice"),Esa.forEach(t),eJr=r(dJe," (FlauBERT model)"),dJe.forEach(t),oJr=i(Te),aA=n(Te,"LI",{});var cJe=s(aA);xLe=n(cJe,"STRONG",{});var Csa=s(xLe);rJr=r(Csa,"funnel"),Csa.forEach(t),tJr=r(cJe," \u2014 "),$te=n(cJe,"A",{href:!0});var wsa=s($te);aJr=r(wsa,"TFFunnelForMultipleChoice"),wsa.forEach(t),nJr=r(cJe," (Funnel Transformer model)"),cJe.forEach(t),sJr=i(Te),nA=n(Te,"LI",{});var mJe=s(nA);$Le=n(mJe,"STRONG",{});var Asa=s($Le);lJr=r(Asa,"longformer"),Asa.forEach(t),iJr=r(mJe," \u2014 "),kte=n(mJe,"A",{href:!0});var Lsa=s(kte);dJr=r(Lsa,"TFLongformerForMultipleChoice"),Lsa.forEach(t),cJr=r(mJe," (Longformer model)"),mJe.forEach(t),mJr=i(Te),sA=n(Te,"LI",{});var fJe=s(sA);kLe=n(fJe,"STRONG",{});var ysa=s(kLe);fJr=r(ysa,"mobilebert"),ysa.forEach(t),gJr=r(fJe," \u2014 "),Ste=n(fJe,"A",{href:!0});var xsa=s(Ste);hJr=r(xsa,"TFMobileBertForMultipleChoice"),xsa.forEach(t),uJr=r(fJe," (MobileBERT model)"),fJe.forEach(t),pJr=i(Te),lA=n(Te,"LI",{});var gJe=s(lA);SLe=n(gJe,"STRONG",{});var $sa=s(SLe);_Jr=r($sa,"mpnet"),$sa.forEach(t),bJr=r(gJe," \u2014 "),Rte=n(gJe,"A",{href:!0});var ksa=s(Rte);vJr=r(ksa,"TFMPNetForMultipleChoice"),ksa.forEach(t),FJr=r(gJe," (MPNet model)"),gJe.forEach(t),TJr=i(Te),iA=n(Te,"LI",{});var hJe=s(iA);RLe=n(hJe,"STRONG",{});var Ssa=s(RLe);MJr=r(Ssa,"rembert"),Ssa.forEach(t),EJr=r(hJe," \u2014 "),Pte=n(hJe,"A",{href:!0});var Rsa=s(Pte);CJr=r(Rsa,"TFRemBertForMultipleChoice"),Rsa.forEach(t),wJr=r(hJe," (RemBERT model)"),hJe.forEach(t),AJr=i(Te),dA=n(Te,"LI",{});var uJe=s(dA);PLe=n(uJe,"STRONG",{});var Psa=s(PLe);LJr=r(Psa,"roberta"),Psa.forEach(t),yJr=r(uJe," \u2014 "),Bte=n(uJe,"A",{href:!0});var Bsa=s(Bte);xJr=r(Bsa,"TFRobertaForMultipleChoice"),Bsa.forEach(t),$Jr=r(uJe," (RoBERTa model)"),uJe.forEach(t),kJr=i(Te),cA=n(Te,"LI",{});var pJe=s(cA);BLe=n(pJe,"STRONG",{});var Isa=s(BLe);SJr=r(Isa,"roformer"),Isa.forEach(t),RJr=r(pJe," \u2014 "),Ite=n(pJe,"A",{href:!0});var Nsa=s(Ite);PJr=r(Nsa,"TFRoFormerForMultipleChoice"),Nsa.forEach(t),BJr=r(pJe," (RoFormer model)"),pJe.forEach(t),IJr=i(Te),mA=n(Te,"LI",{});var _Je=s(mA);ILe=n(_Je,"STRONG",{});var qsa=s(ILe);NJr=r(qsa,"xlm"),qsa.forEach(t),qJr=r(_Je," \u2014 "),Nte=n(_Je,"A",{href:!0});var jsa=s(Nte);jJr=r(jsa,"TFXLMForMultipleChoice"),jsa.forEach(t),DJr=r(_Je," (XLM model)"),_Je.forEach(t),GJr=i(Te),fA=n(Te,"LI",{});var bJe=s(fA);NLe=n(bJe,"STRONG",{});var Dsa=s(NLe);OJr=r(Dsa,"xlm-roberta"),Dsa.forEach(t),VJr=r(bJe," \u2014 "),qte=n(bJe,"A",{href:!0});var Gsa=s(qte);XJr=r(Gsa,"TFXLMRobertaForMultipleChoice"),Gsa.forEach(t),zJr=r(bJe," (XLM-RoBERTa model)"),bJe.forEach(t),QJr=i(Te),gA=n(Te,"LI",{});var vJe=s(gA);qLe=n(vJe,"STRONG",{});var Osa=s(qLe);WJr=r(Osa,"xlnet"),Osa.forEach(t),UJr=r(vJe," \u2014 "),jte=n(vJe,"A",{href:!0});var Vsa=s(jte);HJr=r(Vsa,"TFXLNetForMultipleChoice"),Vsa.forEach(t),JJr=r(vJe," (XLNet model)"),vJe.forEach(t),Te.forEach(t),YJr=i(bi),T(hA.$$.fragment,bi),bi.forEach(t),_i.forEach(t),zeo=i(m),pm=n(m,"H2",{class:!0});var sto=s(pm);uA=n(sto,"A",{id:!0,class:!0,href:!0});var Xsa=s(uA);jLe=n(Xsa,"SPAN",{});var zsa=s(jLe);T(PS.$$.fragment,zsa),zsa.forEach(t),Xsa.forEach(t),KJr=i(sto),DLe=n(sto,"SPAN",{});var Qsa=s(DLe);ZJr=r(Qsa,"TFAutoModelForNextSentencePrediction"),Qsa.forEach(t),sto.forEach(t),Qeo=i(m),ur=n(m,"DIV",{class:!0});var vi=s(ur);T(BS.$$.fragment,vi),eYr=i(vi),_m=n(vi,"P",{});var ade=s(_m);oYr=r(ade,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Dte=n(ade,"A",{href:!0});var Wsa=s(Dte);rYr=r(Wsa,"from_pretrained()"),Wsa.forEach(t),tYr=r(ade," class method or the "),Gte=n(ade,"A",{href:!0});var Usa=s(Gte);aYr=r(Usa,"from_config()"),Usa.forEach(t),nYr=r(ade,` class
method.`),ade.forEach(t),sYr=i(vi),IS=n(vi,"P",{});var lto=s(IS);lYr=r(lto,"This class cannot be instantiated directly using "),GLe=n(lto,"CODE",{});var Hsa=s(GLe);iYr=r(Hsa,"__init__()"),Hsa.forEach(t),dYr=r(lto," (throws an error)."),lto.forEach(t),cYr=i(vi),Zt=n(vi,"DIV",{class:!0});var s9=s(Zt);T(NS.$$.fragment,s9),mYr=i(s9),OLe=n(s9,"P",{});var Jsa=s(OLe);fYr=r(Jsa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Jsa.forEach(t),gYr=i(s9),bm=n(s9,"P",{});var nde=s(bm);hYr=r(nde,`Note:
Loading a model from its configuration file does `),VLe=n(nde,"STRONG",{});var Ysa=s(VLe);uYr=r(Ysa,"not"),Ysa.forEach(t),pYr=r(nde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ote=n(nde,"A",{href:!0});var Ksa=s(Ote);_Yr=r(Ksa,"from_pretrained()"),Ksa.forEach(t),bYr=r(nde," to load the model weights."),nde.forEach(t),vYr=i(s9),T(pA.$$.fragment,s9),s9.forEach(t),FYr=i(vi),zr=n(vi,"DIV",{class:!0});var Fi=s(zr);T(qS.$$.fragment,Fi),TYr=i(Fi),XLe=n(Fi,"P",{});var Zsa=s(XLe);MYr=r(Zsa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Zsa.forEach(t),EYr=i(Fi),Pn=n(Fi,"P",{});var l9=s(Pn);CYr=r(l9,"The model class to instantiate is selected based on the "),zLe=n(l9,"CODE",{});var ela=s(zLe);wYr=r(ela,"model_type"),ela.forEach(t),AYr=r(l9,` property of the config object (either
passed as an argument or loaded from `),QLe=n(l9,"CODE",{});var ola=s(QLe);LYr=r(ola,"pretrained_model_name_or_path"),ola.forEach(t),yYr=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WLe=n(l9,"CODE",{});var rla=s(WLe);xYr=r(rla,"pretrained_model_name_or_path"),rla.forEach(t),$Yr=r(l9,":"),l9.forEach(t),kYr=i(Fi),jS=n(Fi,"UL",{});var ito=s(jS);_A=n(ito,"LI",{});var FJe=s(_A);ULe=n(FJe,"STRONG",{});var tla=s(ULe);SYr=r(tla,"bert"),tla.forEach(t),RYr=r(FJe," \u2014 "),Vte=n(FJe,"A",{href:!0});var ala=s(Vte);PYr=r(ala,"TFBertForNextSentencePrediction"),ala.forEach(t),BYr=r(FJe," (BERT model)"),FJe.forEach(t),IYr=i(ito),bA=n(ito,"LI",{});var TJe=s(bA);HLe=n(TJe,"STRONG",{});var nla=s(HLe);NYr=r(nla,"mobilebert"),nla.forEach(t),qYr=r(TJe," \u2014 "),Xte=n(TJe,"A",{href:!0});var sla=s(Xte);jYr=r(sla,"TFMobileBertForNextSentencePrediction"),sla.forEach(t),DYr=r(TJe," (MobileBERT model)"),TJe.forEach(t),ito.forEach(t),GYr=i(Fi),T(vA.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),Weo=i(m),vm=n(m,"H2",{class:!0});var dto=s(vm);FA=n(dto,"A",{id:!0,class:!0,href:!0});var lla=s(FA);JLe=n(lla,"SPAN",{});var ila=s(JLe);T(DS.$$.fragment,ila),ila.forEach(t),lla.forEach(t),OYr=i(dto),YLe=n(dto,"SPAN",{});var dla=s(YLe);VYr=r(dla,"TFAutoModelForTableQuestionAnswering"),dla.forEach(t),dto.forEach(t),Ueo=i(m),pr=n(m,"DIV",{class:!0});var Ti=s(pr);T(GS.$$.fragment,Ti),XYr=i(Ti),Fm=n(Ti,"P",{});var sde=s(Fm);zYr=r(sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),zte=n(sde,"A",{href:!0});var cla=s(zte);QYr=r(cla,"from_pretrained()"),cla.forEach(t),WYr=r(sde," class method or the "),Qte=n(sde,"A",{href:!0});var mla=s(Qte);UYr=r(mla,"from_config()"),mla.forEach(t),HYr=r(sde,` class
method.`),sde.forEach(t),JYr=i(Ti),OS=n(Ti,"P",{});var cto=s(OS);YYr=r(cto,"This class cannot be instantiated directly using "),KLe=n(cto,"CODE",{});var fla=s(KLe);KYr=r(fla,"__init__()"),fla.forEach(t),ZYr=r(cto," (throws an error)."),cto.forEach(t),eKr=i(Ti),ea=n(Ti,"DIV",{class:!0});var i9=s(ea);T(VS.$$.fragment,i9),oKr=i(i9),ZLe=n(i9,"P",{});var gla=s(ZLe);rKr=r(gla,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),gla.forEach(t),tKr=i(i9),Tm=n(i9,"P",{});var lde=s(Tm);aKr=r(lde,`Note:
Loading a model from its configuration file does `),eye=n(lde,"STRONG",{});var hla=s(eye);nKr=r(hla,"not"),hla.forEach(t),sKr=r(lde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wte=n(lde,"A",{href:!0});var ula=s(Wte);lKr=r(ula,"from_pretrained()"),ula.forEach(t),iKr=r(lde," to load the model weights."),lde.forEach(t),dKr=i(i9),T(TA.$$.fragment,i9),i9.forEach(t),cKr=i(Ti),Qr=n(Ti,"DIV",{class:!0});var Mi=s(Qr);T(XS.$$.fragment,Mi),mKr=i(Mi),oye=n(Mi,"P",{});var pla=s(oye);fKr=r(pla,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),pla.forEach(t),gKr=i(Mi),Bn=n(Mi,"P",{});var d9=s(Bn);hKr=r(d9,"The model class to instantiate is selected based on the "),rye=n(d9,"CODE",{});var _la=s(rye);uKr=r(_la,"model_type"),_la.forEach(t),pKr=r(d9,` property of the config object (either
passed as an argument or loaded from `),tye=n(d9,"CODE",{});var bla=s(tye);_Kr=r(bla,"pretrained_model_name_or_path"),bla.forEach(t),bKr=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aye=n(d9,"CODE",{});var vla=s(aye);vKr=r(vla,"pretrained_model_name_or_path"),vla.forEach(t),FKr=r(d9,":"),d9.forEach(t),TKr=i(Mi),nye=n(Mi,"UL",{});var Fla=s(nye);MA=n(Fla,"LI",{});var MJe=s(MA);sye=n(MJe,"STRONG",{});var Tla=s(sye);MKr=r(Tla,"tapas"),Tla.forEach(t),EKr=r(MJe," \u2014 "),Ute=n(MJe,"A",{href:!0});var Mla=s(Ute);CKr=r(Mla,"TFTapasForQuestionAnswering"),Mla.forEach(t),wKr=r(MJe," (TAPAS model)"),MJe.forEach(t),Fla.forEach(t),AKr=i(Mi),T(EA.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),Heo=i(m),Mm=n(m,"H2",{class:!0});var mto=s(Mm);CA=n(mto,"A",{id:!0,class:!0,href:!0});var Ela=s(CA);lye=n(Ela,"SPAN",{});var Cla=s(lye);T(zS.$$.fragment,Cla),Cla.forEach(t),Ela.forEach(t),LKr=i(mto),iye=n(mto,"SPAN",{});var wla=s(iye);yKr=r(wla,"TFAutoModelForDocumentQuestionAnswering"),wla.forEach(t),mto.forEach(t),Jeo=i(m),_r=n(m,"DIV",{class:!0});var Ei=s(_r);T(QS.$$.fragment,Ei),xKr=i(Ei),Em=n(Ei,"P",{});var ide=s(Em);$Kr=r(ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Hte=n(ide,"A",{href:!0});var Ala=s(Hte);kKr=r(Ala,"from_pretrained()"),Ala.forEach(t),SKr=r(ide," class method or the "),Jte=n(ide,"A",{href:!0});var Lla=s(Jte);RKr=r(Lla,"from_config()"),Lla.forEach(t),PKr=r(ide,` class
method.`),ide.forEach(t),BKr=i(Ei),WS=n(Ei,"P",{});var fto=s(WS);IKr=r(fto,"This class cannot be instantiated directly using "),dye=n(fto,"CODE",{});var yla=s(dye);NKr=r(yla,"__init__()"),yla.forEach(t),qKr=r(fto," (throws an error)."),fto.forEach(t),jKr=i(Ei),oa=n(Ei,"DIV",{class:!0});var c9=s(oa);T(US.$$.fragment,c9),DKr=i(c9),cye=n(c9,"P",{});var xla=s(cye);GKr=r(xla,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),xla.forEach(t),OKr=i(c9),Cm=n(c9,"P",{});var dde=s(Cm);VKr=r(dde,`Note:
Loading a model from its configuration file does `),mye=n(dde,"STRONG",{});var $la=s(mye);XKr=r($la,"not"),$la.forEach(t),zKr=r(dde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yte=n(dde,"A",{href:!0});var kla=s(Yte);QKr=r(kla,"from_pretrained()"),kla.forEach(t),WKr=r(dde," to load the model weights."),dde.forEach(t),UKr=i(c9),T(wA.$$.fragment,c9),c9.forEach(t),HKr=i(Ei),Wr=n(Ei,"DIV",{class:!0});var Ci=s(Wr);T(HS.$$.fragment,Ci),JKr=i(Ci),fye=n(Ci,"P",{});var Sla=s(fye);YKr=r(Sla,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Sla.forEach(t),KKr=i(Ci),In=n(Ci,"P",{});var m9=s(In);ZKr=r(m9,"The model class to instantiate is selected based on the "),gye=n(m9,"CODE",{});var Rla=s(gye);eZr=r(Rla,"model_type"),Rla.forEach(t),oZr=r(m9,` property of the config object (either
passed as an argument or loaded from `),hye=n(m9,"CODE",{});var Pla=s(hye);rZr=r(Pla,"pretrained_model_name_or_path"),Pla.forEach(t),tZr=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=n(m9,"CODE",{});var Bla=s(uye);aZr=r(Bla,"pretrained_model_name_or_path"),Bla.forEach(t),nZr=r(m9,":"),m9.forEach(t),sZr=i(Ci),pye=n(Ci,"UL",{});var Ila=s(pye);AA=n(Ila,"LI",{});var EJe=s(AA);_ye=n(EJe,"STRONG",{});var Nla=s(_ye);lZr=r(Nla,"layoutlm"),Nla.forEach(t),iZr=r(EJe," \u2014 "),Kte=n(EJe,"A",{href:!0});var qla=s(Kte);dZr=r(qla,"TFLayoutLMForQuestionAnswering"),qla.forEach(t),cZr=r(EJe," (LayoutLM model)"),EJe.forEach(t),Ila.forEach(t),mZr=i(Ci),T(LA.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),Yeo=i(m),wm=n(m,"H2",{class:!0});var gto=s(wm);yA=n(gto,"A",{id:!0,class:!0,href:!0});var jla=s(yA);bye=n(jla,"SPAN",{});var Dla=s(bye);T(JS.$$.fragment,Dla),Dla.forEach(t),jla.forEach(t),fZr=i(gto),vye=n(gto,"SPAN",{});var Gla=s(vye);gZr=r(Gla,"TFAutoModelForTokenClassification"),Gla.forEach(t),gto.forEach(t),Keo=i(m),br=n(m,"DIV",{class:!0});var wi=s(br);T(YS.$$.fragment,wi),hZr=i(wi),Am=n(wi,"P",{});var cde=s(Am);uZr=r(cde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Zte=n(cde,"A",{href:!0});var Ola=s(Zte);pZr=r(Ola,"from_pretrained()"),Ola.forEach(t),_Zr=r(cde," class method or the "),eae=n(cde,"A",{href:!0});var Vla=s(eae);bZr=r(Vla,"from_config()"),Vla.forEach(t),vZr=r(cde,` class
method.`),cde.forEach(t),FZr=i(wi),KS=n(wi,"P",{});var hto=s(KS);TZr=r(hto,"This class cannot be instantiated directly using "),Fye=n(hto,"CODE",{});var Xla=s(Fye);MZr=r(Xla,"__init__()"),Xla.forEach(t),EZr=r(hto," (throws an error)."),hto.forEach(t),CZr=i(wi),ra=n(wi,"DIV",{class:!0});var f9=s(ra);T(ZS.$$.fragment,f9),wZr=i(f9),Tye=n(f9,"P",{});var zla=s(Tye);AZr=r(zla,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),zla.forEach(t),LZr=i(f9),Lm=n(f9,"P",{});var mde=s(Lm);yZr=r(mde,`Note:
Loading a model from its configuration file does `),Mye=n(mde,"STRONG",{});var Qla=s(Mye);xZr=r(Qla,"not"),Qla.forEach(t),$Zr=r(mde,` load the model weights. It only affects the
model\u2019s configuration. Use `),oae=n(mde,"A",{href:!0});var Wla=s(oae);kZr=r(Wla,"from_pretrained()"),Wla.forEach(t),SZr=r(mde," to load the model weights."),mde.forEach(t),RZr=i(f9),T(xA.$$.fragment,f9),f9.forEach(t),PZr=i(wi),Ur=n(wi,"DIV",{class:!0});var Ai=s(Ur);T(eR.$$.fragment,Ai),BZr=i(Ai),Eye=n(Ai,"P",{});var Ula=s(Eye);IZr=r(Ula,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ula.forEach(t),NZr=i(Ai),Nn=n(Ai,"P",{});var g9=s(Nn);qZr=r(g9,"The model class to instantiate is selected based on the "),Cye=n(g9,"CODE",{});var Hla=s(Cye);jZr=r(Hla,"model_type"),Hla.forEach(t),DZr=r(g9,` property of the config object (either
passed as an argument or loaded from `),wye=n(g9,"CODE",{});var Jla=s(wye);GZr=r(Jla,"pretrained_model_name_or_path"),Jla.forEach(t),OZr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Aye=n(g9,"CODE",{});var Yla=s(Aye);VZr=r(Yla,"pretrained_model_name_or_path"),Yla.forEach(t),XZr=r(g9,":"),g9.forEach(t),zZr=i(Ai),de=n(Ai,"UL",{});var he=s(de);$A=n(he,"LI",{});var CJe=s($A);Lye=n(CJe,"STRONG",{});var Kla=s(Lye);QZr=r(Kla,"albert"),Kla.forEach(t),WZr=r(CJe," \u2014 "),rae=n(CJe,"A",{href:!0});var Zla=s(rae);UZr=r(Zla,"TFAlbertForTokenClassification"),Zla.forEach(t),HZr=r(CJe," (ALBERT model)"),CJe.forEach(t),JZr=i(he),kA=n(he,"LI",{});var wJe=s(kA);yye=n(wJe,"STRONG",{});var eia=s(yye);YZr=r(eia,"bert"),eia.forEach(t),KZr=r(wJe," \u2014 "),tae=n(wJe,"A",{href:!0});var oia=s(tae);ZZr=r(oia,"TFBertForTokenClassification"),oia.forEach(t),eet=r(wJe," (BERT model)"),wJe.forEach(t),oet=i(he),SA=n(he,"LI",{});var AJe=s(SA);xye=n(AJe,"STRONG",{});var ria=s(xye);ret=r(ria,"camembert"),ria.forEach(t),tet=r(AJe," \u2014 "),aae=n(AJe,"A",{href:!0});var tia=s(aae);aet=r(tia,"TFCamembertForTokenClassification"),tia.forEach(t),net=r(AJe," (CamemBERT model)"),AJe.forEach(t),set=i(he),RA=n(he,"LI",{});var LJe=s(RA);$ye=n(LJe,"STRONG",{});var aia=s($ye);iet=r(aia,"convbert"),aia.forEach(t),det=r(LJe," \u2014 "),nae=n(LJe,"A",{href:!0});var nia=s(nae);cet=r(nia,"TFConvBertForTokenClassification"),nia.forEach(t),met=r(LJe," (ConvBERT model)"),LJe.forEach(t),fet=i(he),PA=n(he,"LI",{});var yJe=s(PA);kye=n(yJe,"STRONG",{});var sia=s(kye);get=r(sia,"deberta"),sia.forEach(t),het=r(yJe," \u2014 "),sae=n(yJe,"A",{href:!0});var lia=s(sae);uet=r(lia,"TFDebertaForTokenClassification"),lia.forEach(t),pet=r(yJe," (DeBERTa model)"),yJe.forEach(t),_et=i(he),BA=n(he,"LI",{});var xJe=s(BA);Sye=n(xJe,"STRONG",{});var iia=s(Sye);bet=r(iia,"deberta-v2"),iia.forEach(t),vet=r(xJe," \u2014 "),lae=n(xJe,"A",{href:!0});var dia=s(lae);Fet=r(dia,"TFDebertaV2ForTokenClassification"),dia.forEach(t),Tet=r(xJe," (DeBERTa-v2 model)"),xJe.forEach(t),Met=i(he),IA=n(he,"LI",{});var $Je=s(IA);Rye=n($Je,"STRONG",{});var cia=s(Rye);Eet=r(cia,"distilbert"),cia.forEach(t),Cet=r($Je," \u2014 "),iae=n($Je,"A",{href:!0});var mia=s(iae);wet=r(mia,"TFDistilBertForTokenClassification"),mia.forEach(t),Aet=r($Je," (DistilBERT model)"),$Je.forEach(t),Let=i(he),NA=n(he,"LI",{});var kJe=s(NA);Pye=n(kJe,"STRONG",{});var fia=s(Pye);yet=r(fia,"electra"),fia.forEach(t),xet=r(kJe," \u2014 "),dae=n(kJe,"A",{href:!0});var gia=s(dae);$et=r(gia,"TFElectraForTokenClassification"),gia.forEach(t),ket=r(kJe," (ELECTRA model)"),kJe.forEach(t),Set=i(he),qA=n(he,"LI",{});var SJe=s(qA);Bye=n(SJe,"STRONG",{});var hia=s(Bye);Ret=r(hia,"flaubert"),hia.forEach(t),Pet=r(SJe," \u2014 "),cae=n(SJe,"A",{href:!0});var uia=s(cae);Bet=r(uia,"TFFlaubertForTokenClassification"),uia.forEach(t),Iet=r(SJe," (FlauBERT model)"),SJe.forEach(t),Net=i(he),jA=n(he,"LI",{});var RJe=s(jA);Iye=n(RJe,"STRONG",{});var pia=s(Iye);qet=r(pia,"funnel"),pia.forEach(t),jet=r(RJe," \u2014 "),mae=n(RJe,"A",{href:!0});var _ia=s(mae);Det=r(_ia,"TFFunnelForTokenClassification"),_ia.forEach(t),Get=r(RJe," (Funnel Transformer model)"),RJe.forEach(t),Oet=i(he),DA=n(he,"LI",{});var PJe=s(DA);Nye=n(PJe,"STRONG",{});var bia=s(Nye);Vet=r(bia,"layoutlm"),bia.forEach(t),Xet=r(PJe," \u2014 "),fae=n(PJe,"A",{href:!0});var via=s(fae);zet=r(via,"TFLayoutLMForTokenClassification"),via.forEach(t),Qet=r(PJe," (LayoutLM model)"),PJe.forEach(t),Wet=i(he),GA=n(he,"LI",{});var BJe=s(GA);qye=n(BJe,"STRONG",{});var Fia=s(qye);Uet=r(Fia,"layoutlmv3"),Fia.forEach(t),Het=r(BJe," \u2014 "),gae=n(BJe,"A",{href:!0});var Tia=s(gae);Jet=r(Tia,"TFLayoutLMv3ForTokenClassification"),Tia.forEach(t),Yet=r(BJe," (LayoutLMv3 model)"),BJe.forEach(t),Ket=i(he),OA=n(he,"LI",{});var IJe=s(OA);jye=n(IJe,"STRONG",{});var Mia=s(jye);Zet=r(Mia,"longformer"),Mia.forEach(t),eot=r(IJe," \u2014 "),hae=n(IJe,"A",{href:!0});var Eia=s(hae);oot=r(Eia,"TFLongformerForTokenClassification"),Eia.forEach(t),rot=r(IJe," (Longformer model)"),IJe.forEach(t),tot=i(he),VA=n(he,"LI",{});var NJe=s(VA);Dye=n(NJe,"STRONG",{});var Cia=s(Dye);aot=r(Cia,"mobilebert"),Cia.forEach(t),not=r(NJe," \u2014 "),uae=n(NJe,"A",{href:!0});var wia=s(uae);sot=r(wia,"TFMobileBertForTokenClassification"),wia.forEach(t),lot=r(NJe," (MobileBERT model)"),NJe.forEach(t),iot=i(he),XA=n(he,"LI",{});var qJe=s(XA);Gye=n(qJe,"STRONG",{});var Aia=s(Gye);dot=r(Aia,"mpnet"),Aia.forEach(t),cot=r(qJe," \u2014 "),pae=n(qJe,"A",{href:!0});var Lia=s(pae);mot=r(Lia,"TFMPNetForTokenClassification"),Lia.forEach(t),fot=r(qJe," (MPNet model)"),qJe.forEach(t),got=i(he),zA=n(he,"LI",{});var jJe=s(zA);Oye=n(jJe,"STRONG",{});var yia=s(Oye);hot=r(yia,"rembert"),yia.forEach(t),uot=r(jJe," \u2014 "),_ae=n(jJe,"A",{href:!0});var xia=s(_ae);pot=r(xia,"TFRemBertForTokenClassification"),xia.forEach(t),_ot=r(jJe," (RemBERT model)"),jJe.forEach(t),bot=i(he),QA=n(he,"LI",{});var DJe=s(QA);Vye=n(DJe,"STRONG",{});var $ia=s(Vye);vot=r($ia,"roberta"),$ia.forEach(t),Fot=r(DJe," \u2014 "),bae=n(DJe,"A",{href:!0});var kia=s(bae);Tot=r(kia,"TFRobertaForTokenClassification"),kia.forEach(t),Mot=r(DJe," (RoBERTa model)"),DJe.forEach(t),Eot=i(he),WA=n(he,"LI",{});var GJe=s(WA);Xye=n(GJe,"STRONG",{});var Sia=s(Xye);Cot=r(Sia,"roformer"),Sia.forEach(t),wot=r(GJe," \u2014 "),vae=n(GJe,"A",{href:!0});var Ria=s(vae);Aot=r(Ria,"TFRoFormerForTokenClassification"),Ria.forEach(t),Lot=r(GJe," (RoFormer model)"),GJe.forEach(t),yot=i(he),UA=n(he,"LI",{});var OJe=s(UA);zye=n(OJe,"STRONG",{});var Pia=s(zye);xot=r(Pia,"xlm"),Pia.forEach(t),$ot=r(OJe," \u2014 "),Fae=n(OJe,"A",{href:!0});var Bia=s(Fae);kot=r(Bia,"TFXLMForTokenClassification"),Bia.forEach(t),Sot=r(OJe," (XLM model)"),OJe.forEach(t),Rot=i(he),HA=n(he,"LI",{});var VJe=s(HA);Qye=n(VJe,"STRONG",{});var Iia=s(Qye);Pot=r(Iia,"xlm-roberta"),Iia.forEach(t),Bot=r(VJe," \u2014 "),Tae=n(VJe,"A",{href:!0});var Nia=s(Tae);Iot=r(Nia,"TFXLMRobertaForTokenClassification"),Nia.forEach(t),Not=r(VJe," (XLM-RoBERTa model)"),VJe.forEach(t),qot=i(he),JA=n(he,"LI",{});var XJe=s(JA);Wye=n(XJe,"STRONG",{});var qia=s(Wye);jot=r(qia,"xlnet"),qia.forEach(t),Dot=r(XJe," \u2014 "),Mae=n(XJe,"A",{href:!0});var jia=s(Mae);Got=r(jia,"TFXLNetForTokenClassification"),jia.forEach(t),Oot=r(XJe," (XLNet model)"),XJe.forEach(t),he.forEach(t),Vot=i(Ai),T(YA.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),Zeo=i(m),ym=n(m,"H2",{class:!0});var uto=s(ym);KA=n(uto,"A",{id:!0,class:!0,href:!0});var Dia=s(KA);Uye=n(Dia,"SPAN",{});var Gia=s(Uye);T(oR.$$.fragment,Gia),Gia.forEach(t),Dia.forEach(t),Xot=i(uto),Hye=n(uto,"SPAN",{});var Oia=s(Hye);zot=r(Oia,"TFAutoModelForQuestionAnswering"),Oia.forEach(t),uto.forEach(t),eoo=i(m),vr=n(m,"DIV",{class:!0});var Li=s(vr);T(rR.$$.fragment,Li),Qot=i(Li),xm=n(Li,"P",{});var fde=s(xm);Wot=r(fde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Eae=n(fde,"A",{href:!0});var Via=s(Eae);Uot=r(Via,"from_pretrained()"),Via.forEach(t),Hot=r(fde," class method or the "),Cae=n(fde,"A",{href:!0});var Xia=s(Cae);Jot=r(Xia,"from_config()"),Xia.forEach(t),Yot=r(fde,` class
method.`),fde.forEach(t),Kot=i(Li),tR=n(Li,"P",{});var pto=s(tR);Zot=r(pto,"This class cannot be instantiated directly using "),Jye=n(pto,"CODE",{});var zia=s(Jye);ert=r(zia,"__init__()"),zia.forEach(t),ort=r(pto," (throws an error)."),pto.forEach(t),rrt=i(Li),ta=n(Li,"DIV",{class:!0});var h9=s(ta);T(aR.$$.fragment,h9),trt=i(h9),Yye=n(h9,"P",{});var Qia=s(Yye);art=r(Qia,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Qia.forEach(t),nrt=i(h9),$m=n(h9,"P",{});var gde=s($m);srt=r(gde,`Note:
Loading a model from its configuration file does `),Kye=n(gde,"STRONG",{});var Wia=s(Kye);lrt=r(Wia,"not"),Wia.forEach(t),irt=r(gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),wae=n(gde,"A",{href:!0});var Uia=s(wae);drt=r(Uia,"from_pretrained()"),Uia.forEach(t),crt=r(gde," to load the model weights."),gde.forEach(t),mrt=i(h9),T(ZA.$$.fragment,h9),h9.forEach(t),frt=i(Li),Hr=n(Li,"DIV",{class:!0});var yi=s(Hr);T(nR.$$.fragment,yi),grt=i(yi),Zye=n(yi,"P",{});var Hia=s(Zye);hrt=r(Hia,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Hia.forEach(t),urt=i(yi),qn=n(yi,"P",{});var u9=s(qn);prt=r(u9,"The model class to instantiate is selected based on the "),e8e=n(u9,"CODE",{});var Jia=s(e8e);_rt=r(Jia,"model_type"),Jia.forEach(t),brt=r(u9,` property of the config object (either
passed as an argument or loaded from `),o8e=n(u9,"CODE",{});var Yia=s(o8e);vrt=r(Yia,"pretrained_model_name_or_path"),Yia.forEach(t),Frt=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r8e=n(u9,"CODE",{});var Kia=s(r8e);Trt=r(Kia,"pretrained_model_name_or_path"),Kia.forEach(t),Mrt=r(u9,":"),u9.forEach(t),Ert=i(yi),ce=n(yi,"UL",{});var ue=s(ce);e6=n(ue,"LI",{});var zJe=s(e6);t8e=n(zJe,"STRONG",{});var Zia=s(t8e);Crt=r(Zia,"albert"),Zia.forEach(t),wrt=r(zJe," \u2014 "),Aae=n(zJe,"A",{href:!0});var eda=s(Aae);Art=r(eda,"TFAlbertForQuestionAnswering"),eda.forEach(t),Lrt=r(zJe," (ALBERT model)"),zJe.forEach(t),yrt=i(ue),o6=n(ue,"LI",{});var QJe=s(o6);a8e=n(QJe,"STRONG",{});var oda=s(a8e);xrt=r(oda,"bert"),oda.forEach(t),$rt=r(QJe," \u2014 "),Lae=n(QJe,"A",{href:!0});var rda=s(Lae);krt=r(rda,"TFBertForQuestionAnswering"),rda.forEach(t),Srt=r(QJe," (BERT model)"),QJe.forEach(t),Rrt=i(ue),r6=n(ue,"LI",{});var WJe=s(r6);n8e=n(WJe,"STRONG",{});var tda=s(n8e);Prt=r(tda,"camembert"),tda.forEach(t),Brt=r(WJe," \u2014 "),yae=n(WJe,"A",{href:!0});var ada=s(yae);Irt=r(ada,"TFCamembertForQuestionAnswering"),ada.forEach(t),Nrt=r(WJe," (CamemBERT model)"),WJe.forEach(t),qrt=i(ue),t6=n(ue,"LI",{});var UJe=s(t6);s8e=n(UJe,"STRONG",{});var nda=s(s8e);jrt=r(nda,"convbert"),nda.forEach(t),Drt=r(UJe," \u2014 "),xae=n(UJe,"A",{href:!0});var sda=s(xae);Grt=r(sda,"TFConvBertForQuestionAnswering"),sda.forEach(t),Ort=r(UJe," (ConvBERT model)"),UJe.forEach(t),Vrt=i(ue),a6=n(ue,"LI",{});var HJe=s(a6);l8e=n(HJe,"STRONG",{});var lda=s(l8e);Xrt=r(lda,"deberta"),lda.forEach(t),zrt=r(HJe," \u2014 "),$ae=n(HJe,"A",{href:!0});var ida=s($ae);Qrt=r(ida,"TFDebertaForQuestionAnswering"),ida.forEach(t),Wrt=r(HJe," (DeBERTa model)"),HJe.forEach(t),Urt=i(ue),n6=n(ue,"LI",{});var JJe=s(n6);i8e=n(JJe,"STRONG",{});var dda=s(i8e);Hrt=r(dda,"deberta-v2"),dda.forEach(t),Jrt=r(JJe," \u2014 "),kae=n(JJe,"A",{href:!0});var cda=s(kae);Yrt=r(cda,"TFDebertaV2ForQuestionAnswering"),cda.forEach(t),Krt=r(JJe," (DeBERTa-v2 model)"),JJe.forEach(t),Zrt=i(ue),s6=n(ue,"LI",{});var YJe=s(s6);d8e=n(YJe,"STRONG",{});var mda=s(d8e);ett=r(mda,"distilbert"),mda.forEach(t),ott=r(YJe," \u2014 "),Sae=n(YJe,"A",{href:!0});var fda=s(Sae);rtt=r(fda,"TFDistilBertForQuestionAnswering"),fda.forEach(t),ttt=r(YJe," (DistilBERT model)"),YJe.forEach(t),att=i(ue),l6=n(ue,"LI",{});var KJe=s(l6);c8e=n(KJe,"STRONG",{});var gda=s(c8e);ntt=r(gda,"electra"),gda.forEach(t),stt=r(KJe," \u2014 "),Rae=n(KJe,"A",{href:!0});var hda=s(Rae);ltt=r(hda,"TFElectraForQuestionAnswering"),hda.forEach(t),itt=r(KJe," (ELECTRA model)"),KJe.forEach(t),dtt=i(ue),i6=n(ue,"LI",{});var ZJe=s(i6);m8e=n(ZJe,"STRONG",{});var uda=s(m8e);ctt=r(uda,"flaubert"),uda.forEach(t),mtt=r(ZJe," \u2014 "),Pae=n(ZJe,"A",{href:!0});var pda=s(Pae);ftt=r(pda,"TFFlaubertForQuestionAnsweringSimple"),pda.forEach(t),gtt=r(ZJe," (FlauBERT model)"),ZJe.forEach(t),htt=i(ue),d6=n(ue,"LI",{});var eYe=s(d6);f8e=n(eYe,"STRONG",{});var _da=s(f8e);utt=r(_da,"funnel"),_da.forEach(t),ptt=r(eYe," \u2014 "),Bae=n(eYe,"A",{href:!0});var bda=s(Bae);_tt=r(bda,"TFFunnelForQuestionAnswering"),bda.forEach(t),btt=r(eYe," (Funnel Transformer model)"),eYe.forEach(t),vtt=i(ue),c6=n(ue,"LI",{});var oYe=s(c6);g8e=n(oYe,"STRONG",{});var vda=s(g8e);Ftt=r(vda,"gptj"),vda.forEach(t),Ttt=r(oYe," \u2014 "),Iae=n(oYe,"A",{href:!0});var Fda=s(Iae);Mtt=r(Fda,"TFGPTJForQuestionAnswering"),Fda.forEach(t),Ett=r(oYe," (GPT-J model)"),oYe.forEach(t),Ctt=i(ue),m6=n(ue,"LI",{});var rYe=s(m6);h8e=n(rYe,"STRONG",{});var Tda=s(h8e);wtt=r(Tda,"layoutlmv3"),Tda.forEach(t),Att=r(rYe," \u2014 "),Nae=n(rYe,"A",{href:!0});var Mda=s(Nae);Ltt=r(Mda,"TFLayoutLMv3ForQuestionAnswering"),Mda.forEach(t),ytt=r(rYe," (LayoutLMv3 model)"),rYe.forEach(t),xtt=i(ue),f6=n(ue,"LI",{});var tYe=s(f6);u8e=n(tYe,"STRONG",{});var Eda=s(u8e);$tt=r(Eda,"longformer"),Eda.forEach(t),ktt=r(tYe," \u2014 "),qae=n(tYe,"A",{href:!0});var Cda=s(qae);Stt=r(Cda,"TFLongformerForQuestionAnswering"),Cda.forEach(t),Rtt=r(tYe," (Longformer model)"),tYe.forEach(t),Ptt=i(ue),g6=n(ue,"LI",{});var aYe=s(g6);p8e=n(aYe,"STRONG",{});var wda=s(p8e);Btt=r(wda,"mobilebert"),wda.forEach(t),Itt=r(aYe," \u2014 "),jae=n(aYe,"A",{href:!0});var Ada=s(jae);Ntt=r(Ada,"TFMobileBertForQuestionAnswering"),Ada.forEach(t),qtt=r(aYe," (MobileBERT model)"),aYe.forEach(t),jtt=i(ue),h6=n(ue,"LI",{});var nYe=s(h6);_8e=n(nYe,"STRONG",{});var Lda=s(_8e);Dtt=r(Lda,"mpnet"),Lda.forEach(t),Gtt=r(nYe," \u2014 "),Dae=n(nYe,"A",{href:!0});var yda=s(Dae);Ott=r(yda,"TFMPNetForQuestionAnswering"),yda.forEach(t),Vtt=r(nYe," (MPNet model)"),nYe.forEach(t),Xtt=i(ue),u6=n(ue,"LI",{});var sYe=s(u6);b8e=n(sYe,"STRONG",{});var xda=s(b8e);ztt=r(xda,"rembert"),xda.forEach(t),Qtt=r(sYe," \u2014 "),Gae=n(sYe,"A",{href:!0});var $da=s(Gae);Wtt=r($da,"TFRemBertForQuestionAnswering"),$da.forEach(t),Utt=r(sYe," (RemBERT model)"),sYe.forEach(t),Htt=i(ue),p6=n(ue,"LI",{});var lYe=s(p6);v8e=n(lYe,"STRONG",{});var kda=s(v8e);Jtt=r(kda,"roberta"),kda.forEach(t),Ytt=r(lYe," \u2014 "),Oae=n(lYe,"A",{href:!0});var Sda=s(Oae);Ktt=r(Sda,"TFRobertaForQuestionAnswering"),Sda.forEach(t),Ztt=r(lYe," (RoBERTa model)"),lYe.forEach(t),eat=i(ue),_6=n(ue,"LI",{});var iYe=s(_6);F8e=n(iYe,"STRONG",{});var Rda=s(F8e);oat=r(Rda,"roformer"),Rda.forEach(t),rat=r(iYe," \u2014 "),Vae=n(iYe,"A",{href:!0});var Pda=s(Vae);tat=r(Pda,"TFRoFormerForQuestionAnswering"),Pda.forEach(t),aat=r(iYe," (RoFormer model)"),iYe.forEach(t),nat=i(ue),b6=n(ue,"LI",{});var dYe=s(b6);T8e=n(dYe,"STRONG",{});var Bda=s(T8e);sat=r(Bda,"xlm"),Bda.forEach(t),lat=r(dYe," \u2014 "),Xae=n(dYe,"A",{href:!0});var Ida=s(Xae);iat=r(Ida,"TFXLMForQuestionAnsweringSimple"),Ida.forEach(t),dat=r(dYe," (XLM model)"),dYe.forEach(t),cat=i(ue),v6=n(ue,"LI",{});var cYe=s(v6);M8e=n(cYe,"STRONG",{});var Nda=s(M8e);mat=r(Nda,"xlm-roberta"),Nda.forEach(t),fat=r(cYe," \u2014 "),zae=n(cYe,"A",{href:!0});var qda=s(zae);gat=r(qda,"TFXLMRobertaForQuestionAnswering"),qda.forEach(t),hat=r(cYe," (XLM-RoBERTa model)"),cYe.forEach(t),uat=i(ue),F6=n(ue,"LI",{});var mYe=s(F6);E8e=n(mYe,"STRONG",{});var jda=s(E8e);pat=r(jda,"xlnet"),jda.forEach(t),_at=r(mYe," \u2014 "),Qae=n(mYe,"A",{href:!0});var Dda=s(Qae);bat=r(Dda,"TFXLNetForQuestionAnsweringSimple"),Dda.forEach(t),vat=r(mYe," (XLNet model)"),mYe.forEach(t),ue.forEach(t),Fat=i(yi),T(T6.$$.fragment,yi),yi.forEach(t),Li.forEach(t),ooo=i(m),km=n(m,"H2",{class:!0});var _to=s(km);M6=n(_to,"A",{id:!0,class:!0,href:!0});var Gda=s(M6);C8e=n(Gda,"SPAN",{});var Oda=s(C8e);T(sR.$$.fragment,Oda),Oda.forEach(t),Gda.forEach(t),Tat=i(_to),w8e=n(_to,"SPAN",{});var Vda=s(w8e);Mat=r(Vda,"TFAutoModelForVision2Seq"),Vda.forEach(t),_to.forEach(t),roo=i(m),Fr=n(m,"DIV",{class:!0});var xi=s(Fr);T(lR.$$.fragment,xi),Eat=i(xi),Sm=n(xi,"P",{});var hde=s(Sm);Cat=r(hde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wae=n(hde,"A",{href:!0});var Xda=s(Wae);wat=r(Xda,"from_pretrained()"),Xda.forEach(t),Aat=r(hde," class method or the "),Uae=n(hde,"A",{href:!0});var zda=s(Uae);Lat=r(zda,"from_config()"),zda.forEach(t),yat=r(hde,` class
method.`),hde.forEach(t),xat=i(xi),iR=n(xi,"P",{});var bto=s(iR);$at=r(bto,"This class cannot be instantiated directly using "),A8e=n(bto,"CODE",{});var Qda=s(A8e);kat=r(Qda,"__init__()"),Qda.forEach(t),Sat=r(bto," (throws an error)."),bto.forEach(t),Rat=i(xi),aa=n(xi,"DIV",{class:!0});var p9=s(aa);T(dR.$$.fragment,p9),Pat=i(p9),L8e=n(p9,"P",{});var Wda=s(L8e);Bat=r(Wda,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Wda.forEach(t),Iat=i(p9),Rm=n(p9,"P",{});var ude=s(Rm);Nat=r(ude,`Note:
Loading a model from its configuration file does `),y8e=n(ude,"STRONG",{});var Uda=s(y8e);qat=r(Uda,"not"),Uda.forEach(t),jat=r(ude,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hae=n(ude,"A",{href:!0});var Hda=s(Hae);Dat=r(Hda,"from_pretrained()"),Hda.forEach(t),Gat=r(ude," to load the model weights."),ude.forEach(t),Oat=i(p9),T(E6.$$.fragment,p9),p9.forEach(t),Vat=i(xi),Jr=n(xi,"DIV",{class:!0});var $i=s(Jr);T(cR.$$.fragment,$i),Xat=i($i),x8e=n($i,"P",{});var Jda=s(x8e);zat=r(Jda,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jda.forEach(t),Qat=i($i),jn=n($i,"P",{});var _9=s(jn);Wat=r(_9,"The model class to instantiate is selected based on the "),$8e=n(_9,"CODE",{});var Yda=s($8e);Uat=r(Yda,"model_type"),Yda.forEach(t),Hat=r(_9,` property of the config object (either
passed as an argument or loaded from `),k8e=n(_9,"CODE",{});var Kda=s(k8e);Jat=r(Kda,"pretrained_model_name_or_path"),Kda.forEach(t),Yat=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S8e=n(_9,"CODE",{});var Zda=s(S8e);Kat=r(Zda,"pretrained_model_name_or_path"),Zda.forEach(t),Zat=r(_9,":"),_9.forEach(t),ent=i($i),R8e=n($i,"UL",{});var eca=s(R8e);C6=n(eca,"LI",{});var fYe=s(C6);P8e=n(fYe,"STRONG",{});var oca=s(P8e);ont=r(oca,"vision-encoder-decoder"),oca.forEach(t),rnt=r(fYe," \u2014 "),Jae=n(fYe,"A",{href:!0});var rca=s(Jae);tnt=r(rca,"TFVisionEncoderDecoderModel"),rca.forEach(t),ant=r(fYe," (Vision Encoder decoder model)"),fYe.forEach(t),eca.forEach(t),nnt=i($i),T(w6.$$.fragment,$i),$i.forEach(t),xi.forEach(t),too=i(m),Pm=n(m,"H2",{class:!0});var vto=s(Pm);A6=n(vto,"A",{id:!0,class:!0,href:!0});var tca=s(A6);B8e=n(tca,"SPAN",{});var aca=s(B8e);T(mR.$$.fragment,aca),aca.forEach(t),tca.forEach(t),snt=i(vto),I8e=n(vto,"SPAN",{});var nca=s(I8e);lnt=r(nca,"TFAutoModelForSpeechSeq2Seq"),nca.forEach(t),vto.forEach(t),aoo=i(m),Tr=n(m,"DIV",{class:!0});var ki=s(Tr);T(fR.$$.fragment,ki),int=i(ki),Bm=n(ki,"P",{});var pde=s(Bm);dnt=r(pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Yae=n(pde,"A",{href:!0});var sca=s(Yae);cnt=r(sca,"from_pretrained()"),sca.forEach(t),mnt=r(pde," class method or the "),Kae=n(pde,"A",{href:!0});var lca=s(Kae);fnt=r(lca,"from_config()"),lca.forEach(t),gnt=r(pde,` class
method.`),pde.forEach(t),hnt=i(ki),gR=n(ki,"P",{});var Fto=s(gR);unt=r(Fto,"This class cannot be instantiated directly using "),N8e=n(Fto,"CODE",{});var ica=s(N8e);pnt=r(ica,"__init__()"),ica.forEach(t),_nt=r(Fto," (throws an error)."),Fto.forEach(t),bnt=i(ki),na=n(ki,"DIV",{class:!0});var b9=s(na);T(hR.$$.fragment,b9),vnt=i(b9),q8e=n(b9,"P",{});var dca=s(q8e);Fnt=r(dca,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dca.forEach(t),Tnt=i(b9),Im=n(b9,"P",{});var _de=s(Im);Mnt=r(_de,`Note:
Loading a model from its configuration file does `),j8e=n(_de,"STRONG",{});var cca=s(j8e);Ent=r(cca,"not"),cca.forEach(t),Cnt=r(_de,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zae=n(_de,"A",{href:!0});var mca=s(Zae);wnt=r(mca,"from_pretrained()"),mca.forEach(t),Ant=r(_de," to load the model weights."),_de.forEach(t),Lnt=i(b9),T(L6.$$.fragment,b9),b9.forEach(t),ynt=i(ki),Yr=n(ki,"DIV",{class:!0});var Si=s(Yr);T(uR.$$.fragment,Si),xnt=i(Si),D8e=n(Si,"P",{});var fca=s(D8e);$nt=r(fca,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fca.forEach(t),knt=i(Si),Dn=n(Si,"P",{});var v9=s(Dn);Snt=r(v9,"The model class to instantiate is selected based on the "),G8e=n(v9,"CODE",{});var gca=s(G8e);Rnt=r(gca,"model_type"),gca.forEach(t),Pnt=r(v9,` property of the config object (either
passed as an argument or loaded from `),O8e=n(v9,"CODE",{});var hca=s(O8e);Bnt=r(hca,"pretrained_model_name_or_path"),hca.forEach(t),Int=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V8e=n(v9,"CODE",{});var uca=s(V8e);Nnt=r(uca,"pretrained_model_name_or_path"),uca.forEach(t),qnt=r(v9,":"),v9.forEach(t),jnt=i(Si),X8e=n(Si,"UL",{});var pca=s(X8e);y6=n(pca,"LI",{});var gYe=s(y6);z8e=n(gYe,"STRONG",{});var _ca=s(z8e);Dnt=r(_ca,"speech_to_text"),_ca.forEach(t),Gnt=r(gYe," \u2014 "),ene=n(gYe,"A",{href:!0});var bca=s(ene);Ont=r(bca,"TFSpeech2TextForConditionalGeneration"),bca.forEach(t),Vnt=r(gYe," (Speech2Text model)"),gYe.forEach(t),pca.forEach(t),Xnt=i(Si),T(x6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),noo=i(m),Nm=n(m,"H2",{class:!0});var Tto=s(Nm);$6=n(Tto,"A",{id:!0,class:!0,href:!0});var vca=s($6);Q8e=n(vca,"SPAN",{});var Fca=s(Q8e);T(pR.$$.fragment,Fca),Fca.forEach(t),vca.forEach(t),znt=i(Tto),W8e=n(Tto,"SPAN",{});var Tca=s(W8e);Qnt=r(Tca,"FlaxAutoModel"),Tca.forEach(t),Tto.forEach(t),soo=i(m),Mr=n(m,"DIV",{class:!0});var Ri=s(Mr);T(_R.$$.fragment,Ri),Wnt=i(Ri),qm=n(Ri,"P",{});var bde=s(qm);Unt=r(bde,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),one=n(bde,"A",{href:!0});var Mca=s(one);Hnt=r(Mca,"from_pretrained()"),Mca.forEach(t),Jnt=r(bde," class method or the "),rne=n(bde,"A",{href:!0});var Eca=s(rne);Ynt=r(Eca,"from_config()"),Eca.forEach(t),Knt=r(bde,` class
method.`),bde.forEach(t),Znt=i(Ri),bR=n(Ri,"P",{});var Mto=s(bR);est=r(Mto,"This class cannot be instantiated directly using "),U8e=n(Mto,"CODE",{});var Cca=s(U8e);ost=r(Cca,"__init__()"),Cca.forEach(t),rst=r(Mto," (throws an error)."),Mto.forEach(t),tst=i(Ri),sa=n(Ri,"DIV",{class:!0});var F9=s(sa);T(vR.$$.fragment,F9),ast=i(F9),H8e=n(F9,"P",{});var wca=s(H8e);nst=r(wca,"Instantiates one of the base model classes of the library from a configuration."),wca.forEach(t),sst=i(F9),jm=n(F9,"P",{});var vde=s(jm);lst=r(vde,`Note:
Loading a model from its configuration file does `),J8e=n(vde,"STRONG",{});var Aca=s(J8e);ist=r(Aca,"not"),Aca.forEach(t),dst=r(vde,` load the model weights. It only affects the
model\u2019s configuration. Use `),tne=n(vde,"A",{href:!0});var Lca=s(tne);cst=r(Lca,"from_pretrained()"),Lca.forEach(t),mst=r(vde," to load the model weights."),vde.forEach(t),fst=i(F9),T(k6.$$.fragment,F9),F9.forEach(t),gst=i(Ri),Kr=n(Ri,"DIV",{class:!0});var Pi=s(Kr);T(FR.$$.fragment,Pi),hst=i(Pi),Y8e=n(Pi,"P",{});var yca=s(Y8e);ust=r(yca,"Instantiate one of the base model classes of the library from a pretrained model."),yca.forEach(t),pst=i(Pi),Gn=n(Pi,"P",{});var T9=s(Gn);_st=r(T9,"The model class to instantiate is selected based on the "),K8e=n(T9,"CODE",{});var xca=s(K8e);bst=r(xca,"model_type"),xca.forEach(t),vst=r(T9,` property of the config object (either
passed as an argument or loaded from `),Z8e=n(T9,"CODE",{});var $ca=s(Z8e);Fst=r($ca,"pretrained_model_name_or_path"),$ca.forEach(t),Tst=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e9e=n(T9,"CODE",{});var kca=s(e9e);Mst=r(kca,"pretrained_model_name_or_path"),kca.forEach(t),Est=r(T9,":"),T9.forEach(t),Cst=i(Pi),te=n(Pi,"UL",{});var ne=s(te);S6=n(ne,"LI",{});var hYe=s(S6);o9e=n(hYe,"STRONG",{});var Sca=s(o9e);wst=r(Sca,"albert"),Sca.forEach(t),Ast=r(hYe," \u2014 "),ane=n(hYe,"A",{href:!0});var Rca=s(ane);Lst=r(Rca,"FlaxAlbertModel"),Rca.forEach(t),yst=r(hYe," (ALBERT model)"),hYe.forEach(t),xst=i(ne),R6=n(ne,"LI",{});var uYe=s(R6);r9e=n(uYe,"STRONG",{});var Pca=s(r9e);$st=r(Pca,"bart"),Pca.forEach(t),kst=r(uYe," \u2014 "),nne=n(uYe,"A",{href:!0});var Bca=s(nne);Sst=r(Bca,"FlaxBartModel"),Bca.forEach(t),Rst=r(uYe," (BART model)"),uYe.forEach(t),Pst=i(ne),P6=n(ne,"LI",{});var pYe=s(P6);t9e=n(pYe,"STRONG",{});var Ica=s(t9e);Bst=r(Ica,"beit"),Ica.forEach(t),Ist=r(pYe," \u2014 "),sne=n(pYe,"A",{href:!0});var Nca=s(sne);Nst=r(Nca,"FlaxBeitModel"),Nca.forEach(t),qst=r(pYe," (BEiT model)"),pYe.forEach(t),jst=i(ne),B6=n(ne,"LI",{});var _Ye=s(B6);a9e=n(_Ye,"STRONG",{});var qca=s(a9e);Dst=r(qca,"bert"),qca.forEach(t),Gst=r(_Ye," \u2014 "),lne=n(_Ye,"A",{href:!0});var jca=s(lne);Ost=r(jca,"FlaxBertModel"),jca.forEach(t),Vst=r(_Ye," (BERT model)"),_Ye.forEach(t),Xst=i(ne),I6=n(ne,"LI",{});var bYe=s(I6);n9e=n(bYe,"STRONG",{});var Dca=s(n9e);zst=r(Dca,"big_bird"),Dca.forEach(t),Qst=r(bYe," \u2014 "),ine=n(bYe,"A",{href:!0});var Gca=s(ine);Wst=r(Gca,"FlaxBigBirdModel"),Gca.forEach(t),Ust=r(bYe," (BigBird model)"),bYe.forEach(t),Hst=i(ne),N6=n(ne,"LI",{});var vYe=s(N6);s9e=n(vYe,"STRONG",{});var Oca=s(s9e);Jst=r(Oca,"blenderbot"),Oca.forEach(t),Yst=r(vYe," \u2014 "),dne=n(vYe,"A",{href:!0});var Vca=s(dne);Kst=r(Vca,"FlaxBlenderbotModel"),Vca.forEach(t),Zst=r(vYe," (Blenderbot model)"),vYe.forEach(t),elt=i(ne),q6=n(ne,"LI",{});var FYe=s(q6);l9e=n(FYe,"STRONG",{});var Xca=s(l9e);olt=r(Xca,"blenderbot-small"),Xca.forEach(t),rlt=r(FYe," \u2014 "),cne=n(FYe,"A",{href:!0});var zca=s(cne);tlt=r(zca,"FlaxBlenderbotSmallModel"),zca.forEach(t),alt=r(FYe," (BlenderbotSmall model)"),FYe.forEach(t),nlt=i(ne),j6=n(ne,"LI",{});var TYe=s(j6);i9e=n(TYe,"STRONG",{});var Qca=s(i9e);slt=r(Qca,"clip"),Qca.forEach(t),llt=r(TYe," \u2014 "),mne=n(TYe,"A",{href:!0});var Wca=s(mne);ilt=r(Wca,"FlaxCLIPModel"),Wca.forEach(t),dlt=r(TYe," (CLIP model)"),TYe.forEach(t),clt=i(ne),D6=n(ne,"LI",{});var MYe=s(D6);d9e=n(MYe,"STRONG",{});var Uca=s(d9e);mlt=r(Uca,"distilbert"),Uca.forEach(t),flt=r(MYe," \u2014 "),fne=n(MYe,"A",{href:!0});var Hca=s(fne);glt=r(Hca,"FlaxDistilBertModel"),Hca.forEach(t),hlt=r(MYe," (DistilBERT model)"),MYe.forEach(t),ult=i(ne),G6=n(ne,"LI",{});var EYe=s(G6);c9e=n(EYe,"STRONG",{});var Jca=s(c9e);plt=r(Jca,"electra"),Jca.forEach(t),_lt=r(EYe," \u2014 "),gne=n(EYe,"A",{href:!0});var Yca=s(gne);blt=r(Yca,"FlaxElectraModel"),Yca.forEach(t),vlt=r(EYe," (ELECTRA model)"),EYe.forEach(t),Flt=i(ne),O6=n(ne,"LI",{});var CYe=s(O6);m9e=n(CYe,"STRONG",{});var Kca=s(m9e);Tlt=r(Kca,"gpt2"),Kca.forEach(t),Mlt=r(CYe," \u2014 "),hne=n(CYe,"A",{href:!0});var Zca=s(hne);Elt=r(Zca,"FlaxGPT2Model"),Zca.forEach(t),Clt=r(CYe," (OpenAI GPT-2 model)"),CYe.forEach(t),wlt=i(ne),V6=n(ne,"LI",{});var wYe=s(V6);f9e=n(wYe,"STRONG",{});var ema=s(f9e);Alt=r(ema,"gpt_neo"),ema.forEach(t),Llt=r(wYe," \u2014 "),une=n(wYe,"A",{href:!0});var oma=s(une);ylt=r(oma,"FlaxGPTNeoModel"),oma.forEach(t),xlt=r(wYe," (GPT Neo model)"),wYe.forEach(t),$lt=i(ne),X6=n(ne,"LI",{});var AYe=s(X6);g9e=n(AYe,"STRONG",{});var rma=s(g9e);klt=r(rma,"gptj"),rma.forEach(t),Slt=r(AYe," \u2014 "),pne=n(AYe,"A",{href:!0});var tma=s(pne);Rlt=r(tma,"FlaxGPTJModel"),tma.forEach(t),Plt=r(AYe," (GPT-J model)"),AYe.forEach(t),Blt=i(ne),z6=n(ne,"LI",{});var LYe=s(z6);h9e=n(LYe,"STRONG",{});var ama=s(h9e);Ilt=r(ama,"longt5"),ama.forEach(t),Nlt=r(LYe," \u2014 "),_ne=n(LYe,"A",{href:!0});var nma=s(_ne);qlt=r(nma,"FlaxLongT5Model"),nma.forEach(t),jlt=r(LYe," (LongT5 model)"),LYe.forEach(t),Dlt=i(ne),Q6=n(ne,"LI",{});var yYe=s(Q6);u9e=n(yYe,"STRONG",{});var sma=s(u9e);Glt=r(sma,"marian"),sma.forEach(t),Olt=r(yYe," \u2014 "),bne=n(yYe,"A",{href:!0});var lma=s(bne);Vlt=r(lma,"FlaxMarianModel"),lma.forEach(t),Xlt=r(yYe," (Marian model)"),yYe.forEach(t),zlt=i(ne),W6=n(ne,"LI",{});var xYe=s(W6);p9e=n(xYe,"STRONG",{});var ima=s(p9e);Qlt=r(ima,"mbart"),ima.forEach(t),Wlt=r(xYe," \u2014 "),vne=n(xYe,"A",{href:!0});var dma=s(vne);Ult=r(dma,"FlaxMBartModel"),dma.forEach(t),Hlt=r(xYe," (mBART model)"),xYe.forEach(t),Jlt=i(ne),U6=n(ne,"LI",{});var $Ye=s(U6);_9e=n($Ye,"STRONG",{});var cma=s(_9e);Ylt=r(cma,"mt5"),cma.forEach(t),Klt=r($Ye," \u2014 "),Fne=n($Ye,"A",{href:!0});var mma=s(Fne);Zlt=r(mma,"FlaxMT5Model"),mma.forEach(t),eit=r($Ye," (MT5 model)"),$Ye.forEach(t),oit=i(ne),H6=n(ne,"LI",{});var kYe=s(H6);b9e=n(kYe,"STRONG",{});var fma=s(b9e);rit=r(fma,"opt"),fma.forEach(t),tit=r(kYe," \u2014 "),Tne=n(kYe,"A",{href:!0});var gma=s(Tne);ait=r(gma,"FlaxOPTModel"),gma.forEach(t),nit=r(kYe," (OPT model)"),kYe.forEach(t),sit=i(ne),J6=n(ne,"LI",{});var SYe=s(J6);v9e=n(SYe,"STRONG",{});var hma=s(v9e);lit=r(hma,"pegasus"),hma.forEach(t),iit=r(SYe," \u2014 "),Mne=n(SYe,"A",{href:!0});var uma=s(Mne);dit=r(uma,"FlaxPegasusModel"),uma.forEach(t),cit=r(SYe," (Pegasus model)"),SYe.forEach(t),mit=i(ne),Y6=n(ne,"LI",{});var RYe=s(Y6);F9e=n(RYe,"STRONG",{});var pma=s(F9e);fit=r(pma,"roberta"),pma.forEach(t),git=r(RYe," \u2014 "),Ene=n(RYe,"A",{href:!0});var _ma=s(Ene);hit=r(_ma,"FlaxRobertaModel"),_ma.forEach(t),uit=r(RYe," (RoBERTa model)"),RYe.forEach(t),pit=i(ne),K6=n(ne,"LI",{});var PYe=s(K6);T9e=n(PYe,"STRONG",{});var bma=s(T9e);_it=r(bma,"roformer"),bma.forEach(t),bit=r(PYe," \u2014 "),Cne=n(PYe,"A",{href:!0});var vma=s(Cne);vit=r(vma,"FlaxRoFormerModel"),vma.forEach(t),Fit=r(PYe," (RoFormer model)"),PYe.forEach(t),Tit=i(ne),Z6=n(ne,"LI",{});var BYe=s(Z6);M9e=n(BYe,"STRONG",{});var Fma=s(M9e);Mit=r(Fma,"t5"),Fma.forEach(t),Eit=r(BYe," \u2014 "),wne=n(BYe,"A",{href:!0});var Tma=s(wne);Cit=r(Tma,"FlaxT5Model"),Tma.forEach(t),wit=r(BYe," (T5 model)"),BYe.forEach(t),Ait=i(ne),e7=n(ne,"LI",{});var IYe=s(e7);E9e=n(IYe,"STRONG",{});var Mma=s(E9e);Lit=r(Mma,"vision-text-dual-encoder"),Mma.forEach(t),yit=r(IYe," \u2014 "),Ane=n(IYe,"A",{href:!0});var Ema=s(Ane);xit=r(Ema,"FlaxVisionTextDualEncoderModel"),Ema.forEach(t),$it=r(IYe," (VisionTextDualEncoder model)"),IYe.forEach(t),kit=i(ne),o7=n(ne,"LI",{});var NYe=s(o7);C9e=n(NYe,"STRONG",{});var Cma=s(C9e);Sit=r(Cma,"vit"),Cma.forEach(t),Rit=r(NYe," \u2014 "),Lne=n(NYe,"A",{href:!0});var wma=s(Lne);Pit=r(wma,"FlaxViTModel"),wma.forEach(t),Bit=r(NYe," (ViT model)"),NYe.forEach(t),Iit=i(ne),r7=n(ne,"LI",{});var qYe=s(r7);w9e=n(qYe,"STRONG",{});var Ama=s(w9e);Nit=r(Ama,"wav2vec2"),Ama.forEach(t),qit=r(qYe," \u2014 "),yne=n(qYe,"A",{href:!0});var Lma=s(yne);jit=r(Lma,"FlaxWav2Vec2Model"),Lma.forEach(t),Dit=r(qYe," (Wav2Vec2 model)"),qYe.forEach(t),Git=i(ne),t7=n(ne,"LI",{});var jYe=s(t7);A9e=n(jYe,"STRONG",{});var yma=s(A9e);Oit=r(yma,"xglm"),yma.forEach(t),Vit=r(jYe," \u2014 "),xne=n(jYe,"A",{href:!0});var xma=s(xne);Xit=r(xma,"FlaxXGLMModel"),xma.forEach(t),zit=r(jYe," (XGLM model)"),jYe.forEach(t),Qit=i(ne),a7=n(ne,"LI",{});var DYe=s(a7);L9e=n(DYe,"STRONG",{});var $ma=s(L9e);Wit=r($ma,"xlm-roberta"),$ma.forEach(t),Uit=r(DYe," \u2014 "),$ne=n(DYe,"A",{href:!0});var kma=s($ne);Hit=r(kma,"FlaxXLMRobertaModel"),kma.forEach(t),Jit=r(DYe," (XLM-RoBERTa model)"),DYe.forEach(t),ne.forEach(t),Yit=i(Pi),T(n7.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),loo=i(m),Dm=n(m,"H2",{class:!0});var Eto=s(Dm);s7=n(Eto,"A",{id:!0,class:!0,href:!0});var Sma=s(s7);y9e=n(Sma,"SPAN",{});var Rma=s(y9e);T(TR.$$.fragment,Rma),Rma.forEach(t),Sma.forEach(t),Kit=i(Eto),x9e=n(Eto,"SPAN",{});var Pma=s(x9e);Zit=r(Pma,"FlaxAutoModelForCausalLM"),Pma.forEach(t),Eto.forEach(t),ioo=i(m),Er=n(m,"DIV",{class:!0});var Bi=s(Er);T(MR.$$.fragment,Bi),edt=i(Bi),Gm=n(Bi,"P",{});var Fde=s(Gm);odt=r(Fde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),kne=n(Fde,"A",{href:!0});var Bma=s(kne);rdt=r(Bma,"from_pretrained()"),Bma.forEach(t),tdt=r(Fde," class method or the "),Sne=n(Fde,"A",{href:!0});var Ima=s(Sne);adt=r(Ima,"from_config()"),Ima.forEach(t),ndt=r(Fde,` class
method.`),Fde.forEach(t),sdt=i(Bi),ER=n(Bi,"P",{});var Cto=s(ER);ldt=r(Cto,"This class cannot be instantiated directly using "),$9e=n(Cto,"CODE",{});var Nma=s($9e);idt=r(Nma,"__init__()"),Nma.forEach(t),ddt=r(Cto," (throws an error)."),Cto.forEach(t),cdt=i(Bi),la=n(Bi,"DIV",{class:!0});var M9=s(la);T(CR.$$.fragment,M9),mdt=i(M9),k9e=n(M9,"P",{});var qma=s(k9e);fdt=r(qma,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qma.forEach(t),gdt=i(M9),Om=n(M9,"P",{});var Tde=s(Om);hdt=r(Tde,`Note:
Loading a model from its configuration file does `),S9e=n(Tde,"STRONG",{});var jma=s(S9e);udt=r(jma,"not"),jma.forEach(t),pdt=r(Tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rne=n(Tde,"A",{href:!0});var Dma=s(Rne);_dt=r(Dma,"from_pretrained()"),Dma.forEach(t),bdt=r(Tde," to load the model weights."),Tde.forEach(t),vdt=i(M9),T(l7.$$.fragment,M9),M9.forEach(t),Fdt=i(Bi),Zr=n(Bi,"DIV",{class:!0});var Ii=s(Zr);T(wR.$$.fragment,Ii),Tdt=i(Ii),R9e=n(Ii,"P",{});var Gma=s(R9e);Mdt=r(Gma,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Gma.forEach(t),Edt=i(Ii),On=n(Ii,"P",{});var E9=s(On);Cdt=r(E9,"The model class to instantiate is selected based on the "),P9e=n(E9,"CODE",{});var Oma=s(P9e);wdt=r(Oma,"model_type"),Oma.forEach(t),Adt=r(E9,` property of the config object (either
passed as an argument or loaded from `),B9e=n(E9,"CODE",{});var Vma=s(B9e);Ldt=r(Vma,"pretrained_model_name_or_path"),Vma.forEach(t),ydt=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I9e=n(E9,"CODE",{});var Xma=s(I9e);xdt=r(Xma,"pretrained_model_name_or_path"),Xma.forEach(t),$dt=r(E9,":"),E9.forEach(t),kdt=i(Ii),xe=n(Ii,"UL",{});var qe=s(xe);i7=n(qe,"LI",{});var GYe=s(i7);N9e=n(GYe,"STRONG",{});var zma=s(N9e);Sdt=r(zma,"bart"),zma.forEach(t),Rdt=r(GYe," \u2014 "),Pne=n(GYe,"A",{href:!0});var Qma=s(Pne);Pdt=r(Qma,"FlaxBartForCausalLM"),Qma.forEach(t),Bdt=r(GYe," (BART model)"),GYe.forEach(t),Idt=i(qe),d7=n(qe,"LI",{});var OYe=s(d7);q9e=n(OYe,"STRONG",{});var Wma=s(q9e);Ndt=r(Wma,"bert"),Wma.forEach(t),qdt=r(OYe," \u2014 "),Bne=n(OYe,"A",{href:!0});var Uma=s(Bne);jdt=r(Uma,"FlaxBertForCausalLM"),Uma.forEach(t),Ddt=r(OYe," (BERT model)"),OYe.forEach(t),Gdt=i(qe),c7=n(qe,"LI",{});var VYe=s(c7);j9e=n(VYe,"STRONG",{});var Hma=s(j9e);Odt=r(Hma,"big_bird"),Hma.forEach(t),Vdt=r(VYe," \u2014 "),Ine=n(VYe,"A",{href:!0});var Jma=s(Ine);Xdt=r(Jma,"FlaxBigBirdForCausalLM"),Jma.forEach(t),zdt=r(VYe," (BigBird model)"),VYe.forEach(t),Qdt=i(qe),m7=n(qe,"LI",{});var XYe=s(m7);D9e=n(XYe,"STRONG",{});var Yma=s(D9e);Wdt=r(Yma,"electra"),Yma.forEach(t),Udt=r(XYe," \u2014 "),Nne=n(XYe,"A",{href:!0});var Kma=s(Nne);Hdt=r(Kma,"FlaxElectraForCausalLM"),Kma.forEach(t),Jdt=r(XYe," (ELECTRA model)"),XYe.forEach(t),Ydt=i(qe),f7=n(qe,"LI",{});var zYe=s(f7);G9e=n(zYe,"STRONG",{});var Zma=s(G9e);Kdt=r(Zma,"gpt2"),Zma.forEach(t),Zdt=r(zYe," \u2014 "),qne=n(zYe,"A",{href:!0});var efa=s(qne);ect=r(efa,"FlaxGPT2LMHeadModel"),efa.forEach(t),oct=r(zYe," (OpenAI GPT-2 model)"),zYe.forEach(t),rct=i(qe),g7=n(qe,"LI",{});var QYe=s(g7);O9e=n(QYe,"STRONG",{});var ofa=s(O9e);tct=r(ofa,"gpt_neo"),ofa.forEach(t),act=r(QYe," \u2014 "),jne=n(QYe,"A",{href:!0});var rfa=s(jne);nct=r(rfa,"FlaxGPTNeoForCausalLM"),rfa.forEach(t),sct=r(QYe," (GPT Neo model)"),QYe.forEach(t),lct=i(qe),h7=n(qe,"LI",{});var WYe=s(h7);V9e=n(WYe,"STRONG",{});var tfa=s(V9e);ict=r(tfa,"gptj"),tfa.forEach(t),dct=r(WYe," \u2014 "),Dne=n(WYe,"A",{href:!0});var afa=s(Dne);cct=r(afa,"FlaxGPTJForCausalLM"),afa.forEach(t),mct=r(WYe," (GPT-J model)"),WYe.forEach(t),fct=i(qe),u7=n(qe,"LI",{});var UYe=s(u7);X9e=n(UYe,"STRONG",{});var nfa=s(X9e);gct=r(nfa,"opt"),nfa.forEach(t),hct=r(UYe," \u2014 "),Gne=n(UYe,"A",{href:!0});var sfa=s(Gne);uct=r(sfa,"FlaxOPTForCausalLM"),sfa.forEach(t),pct=r(UYe," (OPT model)"),UYe.forEach(t),_ct=i(qe),p7=n(qe,"LI",{});var HYe=s(p7);z9e=n(HYe,"STRONG",{});var lfa=s(z9e);bct=r(lfa,"roberta"),lfa.forEach(t),vct=r(HYe," \u2014 "),One=n(HYe,"A",{href:!0});var ifa=s(One);Fct=r(ifa,"FlaxRobertaForCausalLM"),ifa.forEach(t),Tct=r(HYe," (RoBERTa model)"),HYe.forEach(t),Mct=i(qe),_7=n(qe,"LI",{});var JYe=s(_7);Q9e=n(JYe,"STRONG",{});var dfa=s(Q9e);Ect=r(dfa,"xglm"),dfa.forEach(t),Cct=r(JYe," \u2014 "),Vne=n(JYe,"A",{href:!0});var cfa=s(Vne);wct=r(cfa,"FlaxXGLMForCausalLM"),cfa.forEach(t),Act=r(JYe," (XGLM model)"),JYe.forEach(t),qe.forEach(t),Lct=i(Ii),T(b7.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),doo=i(m),Vm=n(m,"H2",{class:!0});var wto=s(Vm);v7=n(wto,"A",{id:!0,class:!0,href:!0});var mfa=s(v7);W9e=n(mfa,"SPAN",{});var ffa=s(W9e);T(AR.$$.fragment,ffa),ffa.forEach(t),mfa.forEach(t),yct=i(wto),U9e=n(wto,"SPAN",{});var gfa=s(U9e);xct=r(gfa,"FlaxAutoModelForPreTraining"),gfa.forEach(t),wto.forEach(t),coo=i(m),Cr=n(m,"DIV",{class:!0});var Ni=s(Cr);T(LR.$$.fragment,Ni),$ct=i(Ni),Xm=n(Ni,"P",{});var Mde=s(Xm);kct=r(Mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Xne=n(Mde,"A",{href:!0});var hfa=s(Xne);Sct=r(hfa,"from_pretrained()"),hfa.forEach(t),Rct=r(Mde," class method or the "),zne=n(Mde,"A",{href:!0});var ufa=s(zne);Pct=r(ufa,"from_config()"),ufa.forEach(t),Bct=r(Mde,` class
method.`),Mde.forEach(t),Ict=i(Ni),yR=n(Ni,"P",{});var Ato=s(yR);Nct=r(Ato,"This class cannot be instantiated directly using "),H9e=n(Ato,"CODE",{});var pfa=s(H9e);qct=r(pfa,"__init__()"),pfa.forEach(t),jct=r(Ato," (throws an error)."),Ato.forEach(t),Dct=i(Ni),ia=n(Ni,"DIV",{class:!0});var C9=s(ia);T(xR.$$.fragment,C9),Gct=i(C9),J9e=n(C9,"P",{});var _fa=s(J9e);Oct=r(_fa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_fa.forEach(t),Vct=i(C9),zm=n(C9,"P",{});var Ede=s(zm);Xct=r(Ede,`Note:
Loading a model from its configuration file does `),Y9e=n(Ede,"STRONG",{});var bfa=s(Y9e);zct=r(bfa,"not"),bfa.forEach(t),Qct=r(Ede,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qne=n(Ede,"A",{href:!0});var vfa=s(Qne);Wct=r(vfa,"from_pretrained()"),vfa.forEach(t),Uct=r(Ede," to load the model weights."),Ede.forEach(t),Hct=i(C9),T(F7.$$.fragment,C9),C9.forEach(t),Jct=i(Ni),et=n(Ni,"DIV",{class:!0});var qi=s(et);T($R.$$.fragment,qi),Yct=i(qi),K9e=n(qi,"P",{});var Ffa=s(K9e);Kct=r(Ffa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Ffa.forEach(t),Zct=i(qi),Vn=n(qi,"P",{});var w9=s(Vn);emt=r(w9,"The model class to instantiate is selected based on the "),Z9e=n(w9,"CODE",{});var Tfa=s(Z9e);omt=r(Tfa,"model_type"),Tfa.forEach(t),rmt=r(w9,` property of the config object (either
passed as an argument or loaded from `),exe=n(w9,"CODE",{});var Mfa=s(exe);tmt=r(Mfa,"pretrained_model_name_or_path"),Mfa.forEach(t),amt=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oxe=n(w9,"CODE",{});var Efa=s(oxe);nmt=r(Efa,"pretrained_model_name_or_path"),Efa.forEach(t),smt=r(w9,":"),w9.forEach(t),lmt=i(qi),Ee=n(qi,"UL",{});var we=s(Ee);T7=n(we,"LI",{});var YYe=s(T7);rxe=n(YYe,"STRONG",{});var Cfa=s(rxe);imt=r(Cfa,"albert"),Cfa.forEach(t),dmt=r(YYe," \u2014 "),Wne=n(YYe,"A",{href:!0});var wfa=s(Wne);cmt=r(wfa,"FlaxAlbertForPreTraining"),wfa.forEach(t),mmt=r(YYe," (ALBERT model)"),YYe.forEach(t),fmt=i(we),M7=n(we,"LI",{});var KYe=s(M7);txe=n(KYe,"STRONG",{});var Afa=s(txe);gmt=r(Afa,"bart"),Afa.forEach(t),hmt=r(KYe," \u2014 "),Une=n(KYe,"A",{href:!0});var Lfa=s(Une);umt=r(Lfa,"FlaxBartForConditionalGeneration"),Lfa.forEach(t),pmt=r(KYe," (BART model)"),KYe.forEach(t),_mt=i(we),E7=n(we,"LI",{});var ZYe=s(E7);axe=n(ZYe,"STRONG",{});var yfa=s(axe);bmt=r(yfa,"bert"),yfa.forEach(t),vmt=r(ZYe," \u2014 "),Hne=n(ZYe,"A",{href:!0});var xfa=s(Hne);Fmt=r(xfa,"FlaxBertForPreTraining"),xfa.forEach(t),Tmt=r(ZYe," (BERT model)"),ZYe.forEach(t),Mmt=i(we),C7=n(we,"LI",{});var eKe=s(C7);nxe=n(eKe,"STRONG",{});var $fa=s(nxe);Emt=r($fa,"big_bird"),$fa.forEach(t),Cmt=r(eKe," \u2014 "),Jne=n(eKe,"A",{href:!0});var kfa=s(Jne);wmt=r(kfa,"FlaxBigBirdForPreTraining"),kfa.forEach(t),Amt=r(eKe," (BigBird model)"),eKe.forEach(t),Lmt=i(we),w7=n(we,"LI",{});var oKe=s(w7);sxe=n(oKe,"STRONG",{});var Sfa=s(sxe);ymt=r(Sfa,"electra"),Sfa.forEach(t),xmt=r(oKe," \u2014 "),Yne=n(oKe,"A",{href:!0});var Rfa=s(Yne);$mt=r(Rfa,"FlaxElectraForPreTraining"),Rfa.forEach(t),kmt=r(oKe," (ELECTRA model)"),oKe.forEach(t),Smt=i(we),A7=n(we,"LI",{});var rKe=s(A7);lxe=n(rKe,"STRONG",{});var Pfa=s(lxe);Rmt=r(Pfa,"longt5"),Pfa.forEach(t),Pmt=r(rKe," \u2014 "),Kne=n(rKe,"A",{href:!0});var Bfa=s(Kne);Bmt=r(Bfa,"FlaxLongT5ForConditionalGeneration"),Bfa.forEach(t),Imt=r(rKe," (LongT5 model)"),rKe.forEach(t),Nmt=i(we),L7=n(we,"LI",{});var tKe=s(L7);ixe=n(tKe,"STRONG",{});var Ifa=s(ixe);qmt=r(Ifa,"mbart"),Ifa.forEach(t),jmt=r(tKe," \u2014 "),Zne=n(tKe,"A",{href:!0});var Nfa=s(Zne);Dmt=r(Nfa,"FlaxMBartForConditionalGeneration"),Nfa.forEach(t),Gmt=r(tKe," (mBART model)"),tKe.forEach(t),Omt=i(we),y7=n(we,"LI",{});var aKe=s(y7);dxe=n(aKe,"STRONG",{});var qfa=s(dxe);Vmt=r(qfa,"mt5"),qfa.forEach(t),Xmt=r(aKe," \u2014 "),ese=n(aKe,"A",{href:!0});var jfa=s(ese);zmt=r(jfa,"FlaxMT5ForConditionalGeneration"),jfa.forEach(t),Qmt=r(aKe," (MT5 model)"),aKe.forEach(t),Wmt=i(we),x7=n(we,"LI",{});var nKe=s(x7);cxe=n(nKe,"STRONG",{});var Dfa=s(cxe);Umt=r(Dfa,"roberta"),Dfa.forEach(t),Hmt=r(nKe," \u2014 "),ose=n(nKe,"A",{href:!0});var Gfa=s(ose);Jmt=r(Gfa,"FlaxRobertaForMaskedLM"),Gfa.forEach(t),Ymt=r(nKe," (RoBERTa model)"),nKe.forEach(t),Kmt=i(we),$7=n(we,"LI",{});var sKe=s($7);mxe=n(sKe,"STRONG",{});var Ofa=s(mxe);Zmt=r(Ofa,"roformer"),Ofa.forEach(t),eft=r(sKe," \u2014 "),rse=n(sKe,"A",{href:!0});var Vfa=s(rse);oft=r(Vfa,"FlaxRoFormerForMaskedLM"),Vfa.forEach(t),rft=r(sKe," (RoFormer model)"),sKe.forEach(t),tft=i(we),k7=n(we,"LI",{});var lKe=s(k7);fxe=n(lKe,"STRONG",{});var Xfa=s(fxe);aft=r(Xfa,"t5"),Xfa.forEach(t),nft=r(lKe," \u2014 "),tse=n(lKe,"A",{href:!0});var zfa=s(tse);sft=r(zfa,"FlaxT5ForConditionalGeneration"),zfa.forEach(t),lft=r(lKe," (T5 model)"),lKe.forEach(t),ift=i(we),S7=n(we,"LI",{});var iKe=s(S7);gxe=n(iKe,"STRONG",{});var Qfa=s(gxe);dft=r(Qfa,"wav2vec2"),Qfa.forEach(t),cft=r(iKe," \u2014 "),ase=n(iKe,"A",{href:!0});var Wfa=s(ase);mft=r(Wfa,"FlaxWav2Vec2ForPreTraining"),Wfa.forEach(t),fft=r(iKe," (Wav2Vec2 model)"),iKe.forEach(t),gft=i(we),R7=n(we,"LI",{});var dKe=s(R7);hxe=n(dKe,"STRONG",{});var Ufa=s(hxe);hft=r(Ufa,"xlm-roberta"),Ufa.forEach(t),uft=r(dKe," \u2014 "),nse=n(dKe,"A",{href:!0});var Hfa=s(nse);pft=r(Hfa,"FlaxXLMRobertaForMaskedLM"),Hfa.forEach(t),_ft=r(dKe," (XLM-RoBERTa model)"),dKe.forEach(t),we.forEach(t),bft=i(qi),T(P7.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),moo=i(m),Qm=n(m,"H2",{class:!0});var Lto=s(Qm);B7=n(Lto,"A",{id:!0,class:!0,href:!0});var Jfa=s(B7);uxe=n(Jfa,"SPAN",{});var Yfa=s(uxe);T(kR.$$.fragment,Yfa),Yfa.forEach(t),Jfa.forEach(t),vft=i(Lto),pxe=n(Lto,"SPAN",{});var Kfa=s(pxe);Fft=r(Kfa,"FlaxAutoModelForMaskedLM"),Kfa.forEach(t),Lto.forEach(t),foo=i(m),wr=n(m,"DIV",{class:!0});var ji=s(wr);T(SR.$$.fragment,ji),Tft=i(ji),Wm=n(ji,"P",{});var Cde=s(Wm);Mft=r(Cde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sse=n(Cde,"A",{href:!0});var Zfa=s(sse);Eft=r(Zfa,"from_pretrained()"),Zfa.forEach(t),Cft=r(Cde," class method or the "),lse=n(Cde,"A",{href:!0});var ega=s(lse);wft=r(ega,"from_config()"),ega.forEach(t),Aft=r(Cde,` class
method.`),Cde.forEach(t),Lft=i(ji),RR=n(ji,"P",{});var yto=s(RR);yft=r(yto,"This class cannot be instantiated directly using "),_xe=n(yto,"CODE",{});var oga=s(_xe);xft=r(oga,"__init__()"),oga.forEach(t),$ft=r(yto," (throws an error)."),yto.forEach(t),kft=i(ji),da=n(ji,"DIV",{class:!0});var A9=s(da);T(PR.$$.fragment,A9),Sft=i(A9),bxe=n(A9,"P",{});var rga=s(bxe);Rft=r(rga,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rga.forEach(t),Pft=i(A9),Um=n(A9,"P",{});var wde=s(Um);Bft=r(wde,`Note:
Loading a model from its configuration file does `),vxe=n(wde,"STRONG",{});var tga=s(vxe);Ift=r(tga,"not"),tga.forEach(t),Nft=r(wde,` load the model weights. It only affects the
model\u2019s configuration. Use `),ise=n(wde,"A",{href:!0});var aga=s(ise);qft=r(aga,"from_pretrained()"),aga.forEach(t),jft=r(wde," to load the model weights."),wde.forEach(t),Dft=i(A9),T(I7.$$.fragment,A9),A9.forEach(t),Gft=i(ji),ot=n(ji,"DIV",{class:!0});var Di=s(ot);T(BR.$$.fragment,Di),Oft=i(Di),Fxe=n(Di,"P",{});var nga=s(Fxe);Vft=r(nga,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nga.forEach(t),Xft=i(Di),Xn=n(Di,"P",{});var L9=s(Xn);zft=r(L9,"The model class to instantiate is selected based on the "),Txe=n(L9,"CODE",{});var sga=s(Txe);Qft=r(sga,"model_type"),sga.forEach(t),Wft=r(L9,` property of the config object (either
passed as an argument or loaded from `),Mxe=n(L9,"CODE",{});var lga=s(Mxe);Uft=r(lga,"pretrained_model_name_or_path"),lga.forEach(t),Hft=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Exe=n(L9,"CODE",{});var iga=s(Exe);Jft=r(iga,"pretrained_model_name_or_path"),iga.forEach(t),Yft=r(L9,":"),L9.forEach(t),Kft=i(Di),$e=n(Di,"UL",{});var je=s($e);N7=n(je,"LI",{});var cKe=s(N7);Cxe=n(cKe,"STRONG",{});var dga=s(Cxe);Zft=r(dga,"albert"),dga.forEach(t),egt=r(cKe," \u2014 "),dse=n(cKe,"A",{href:!0});var cga=s(dse);ogt=r(cga,"FlaxAlbertForMaskedLM"),cga.forEach(t),rgt=r(cKe," (ALBERT model)"),cKe.forEach(t),tgt=i(je),q7=n(je,"LI",{});var mKe=s(q7);wxe=n(mKe,"STRONG",{});var mga=s(wxe);agt=r(mga,"bart"),mga.forEach(t),ngt=r(mKe," \u2014 "),cse=n(mKe,"A",{href:!0});var fga=s(cse);sgt=r(fga,"FlaxBartForConditionalGeneration"),fga.forEach(t),lgt=r(mKe," (BART model)"),mKe.forEach(t),igt=i(je),j7=n(je,"LI",{});var fKe=s(j7);Axe=n(fKe,"STRONG",{});var gga=s(Axe);dgt=r(gga,"bert"),gga.forEach(t),cgt=r(fKe," \u2014 "),mse=n(fKe,"A",{href:!0});var hga=s(mse);mgt=r(hga,"FlaxBertForMaskedLM"),hga.forEach(t),fgt=r(fKe," (BERT model)"),fKe.forEach(t),ggt=i(je),D7=n(je,"LI",{});var gKe=s(D7);Lxe=n(gKe,"STRONG",{});var uga=s(Lxe);hgt=r(uga,"big_bird"),uga.forEach(t),ugt=r(gKe," \u2014 "),fse=n(gKe,"A",{href:!0});var pga=s(fse);pgt=r(pga,"FlaxBigBirdForMaskedLM"),pga.forEach(t),_gt=r(gKe," (BigBird model)"),gKe.forEach(t),bgt=i(je),G7=n(je,"LI",{});var hKe=s(G7);yxe=n(hKe,"STRONG",{});var _ga=s(yxe);vgt=r(_ga,"distilbert"),_ga.forEach(t),Fgt=r(hKe," \u2014 "),gse=n(hKe,"A",{href:!0});var bga=s(gse);Tgt=r(bga,"FlaxDistilBertForMaskedLM"),bga.forEach(t),Mgt=r(hKe," (DistilBERT model)"),hKe.forEach(t),Egt=i(je),O7=n(je,"LI",{});var uKe=s(O7);xxe=n(uKe,"STRONG",{});var vga=s(xxe);Cgt=r(vga,"electra"),vga.forEach(t),wgt=r(uKe," \u2014 "),hse=n(uKe,"A",{href:!0});var Fga=s(hse);Agt=r(Fga,"FlaxElectraForMaskedLM"),Fga.forEach(t),Lgt=r(uKe," (ELECTRA model)"),uKe.forEach(t),ygt=i(je),V7=n(je,"LI",{});var pKe=s(V7);$xe=n(pKe,"STRONG",{});var Tga=s($xe);xgt=r(Tga,"mbart"),Tga.forEach(t),$gt=r(pKe," \u2014 "),use=n(pKe,"A",{href:!0});var Mga=s(use);kgt=r(Mga,"FlaxMBartForConditionalGeneration"),Mga.forEach(t),Sgt=r(pKe," (mBART model)"),pKe.forEach(t),Rgt=i(je),X7=n(je,"LI",{});var _Ke=s(X7);kxe=n(_Ke,"STRONG",{});var Ega=s(kxe);Pgt=r(Ega,"roberta"),Ega.forEach(t),Bgt=r(_Ke," \u2014 "),pse=n(_Ke,"A",{href:!0});var Cga=s(pse);Igt=r(Cga,"FlaxRobertaForMaskedLM"),Cga.forEach(t),Ngt=r(_Ke," (RoBERTa model)"),_Ke.forEach(t),qgt=i(je),z7=n(je,"LI",{});var bKe=s(z7);Sxe=n(bKe,"STRONG",{});var wga=s(Sxe);jgt=r(wga,"roformer"),wga.forEach(t),Dgt=r(bKe," \u2014 "),_se=n(bKe,"A",{href:!0});var Aga=s(_se);Ggt=r(Aga,"FlaxRoFormerForMaskedLM"),Aga.forEach(t),Ogt=r(bKe," (RoFormer model)"),bKe.forEach(t),Vgt=i(je),Q7=n(je,"LI",{});var vKe=s(Q7);Rxe=n(vKe,"STRONG",{});var Lga=s(Rxe);Xgt=r(Lga,"xlm-roberta"),Lga.forEach(t),zgt=r(vKe," \u2014 "),bse=n(vKe,"A",{href:!0});var yga=s(bse);Qgt=r(yga,"FlaxXLMRobertaForMaskedLM"),yga.forEach(t),Wgt=r(vKe," (XLM-RoBERTa model)"),vKe.forEach(t),je.forEach(t),Ugt=i(Di),T(W7.$$.fragment,Di),Di.forEach(t),ji.forEach(t),goo=i(m),Hm=n(m,"H2",{class:!0});var xto=s(Hm);U7=n(xto,"A",{id:!0,class:!0,href:!0});var xga=s(U7);Pxe=n(xga,"SPAN",{});var $ga=s(Pxe);T(IR.$$.fragment,$ga),$ga.forEach(t),xga.forEach(t),Hgt=i(xto),Bxe=n(xto,"SPAN",{});var kga=s(Bxe);Jgt=r(kga,"FlaxAutoModelForSeq2SeqLM"),kga.forEach(t),xto.forEach(t),hoo=i(m),Ar=n(m,"DIV",{class:!0});var Gi=s(Ar);T(NR.$$.fragment,Gi),Ygt=i(Gi),Jm=n(Gi,"P",{});var Ade=s(Jm);Kgt=r(Ade,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),vse=n(Ade,"A",{href:!0});var Sga=s(vse);Zgt=r(Sga,"from_pretrained()"),Sga.forEach(t),eht=r(Ade," class method or the "),Fse=n(Ade,"A",{href:!0});var Rga=s(Fse);oht=r(Rga,"from_config()"),Rga.forEach(t),rht=r(Ade,` class
method.`),Ade.forEach(t),tht=i(Gi),qR=n(Gi,"P",{});var $to=s(qR);aht=r($to,"This class cannot be instantiated directly using "),Ixe=n($to,"CODE",{});var Pga=s(Ixe);nht=r(Pga,"__init__()"),Pga.forEach(t),sht=r($to," (throws an error)."),$to.forEach(t),lht=i(Gi),ca=n(Gi,"DIV",{class:!0});var y9=s(ca);T(jR.$$.fragment,y9),iht=i(y9),Nxe=n(y9,"P",{});var Bga=s(Nxe);dht=r(Bga,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Bga.forEach(t),cht=i(y9),Ym=n(y9,"P",{});var Lde=s(Ym);mht=r(Lde,`Note:
Loading a model from its configuration file does `),qxe=n(Lde,"STRONG",{});var Iga=s(qxe);fht=r(Iga,"not"),Iga.forEach(t),ght=r(Lde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tse=n(Lde,"A",{href:!0});var Nga=s(Tse);hht=r(Nga,"from_pretrained()"),Nga.forEach(t),uht=r(Lde," to load the model weights."),Lde.forEach(t),pht=i(y9),T(H7.$$.fragment,y9),y9.forEach(t),_ht=i(Gi),rt=n(Gi,"DIV",{class:!0});var Oi=s(rt);T(DR.$$.fragment,Oi),bht=i(Oi),jxe=n(Oi,"P",{});var qga=s(jxe);vht=r(qga,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qga.forEach(t),Fht=i(Oi),zn=n(Oi,"P",{});var x9=s(zn);Tht=r(x9,"The model class to instantiate is selected based on the "),Dxe=n(x9,"CODE",{});var jga=s(Dxe);Mht=r(jga,"model_type"),jga.forEach(t),Eht=r(x9,` property of the config object (either
passed as an argument or loaded from `),Gxe=n(x9,"CODE",{});var Dga=s(Gxe);Cht=r(Dga,"pretrained_model_name_or_path"),Dga.forEach(t),wht=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=n(x9,"CODE",{});var Gga=s(Oxe);Aht=r(Gga,"pretrained_model_name_or_path"),Gga.forEach(t),Lht=r(x9,":"),x9.forEach(t),yht=i(Oi),ke=n(Oi,"UL",{});var De=s(ke);J7=n(De,"LI",{});var FKe=s(J7);Vxe=n(FKe,"STRONG",{});var Oga=s(Vxe);xht=r(Oga,"bart"),Oga.forEach(t),$ht=r(FKe," \u2014 "),Mse=n(FKe,"A",{href:!0});var Vga=s(Mse);kht=r(Vga,"FlaxBartForConditionalGeneration"),Vga.forEach(t),Sht=r(FKe," (BART model)"),FKe.forEach(t),Rht=i(De),Y7=n(De,"LI",{});var TKe=s(Y7);Xxe=n(TKe,"STRONG",{});var Xga=s(Xxe);Pht=r(Xga,"blenderbot"),Xga.forEach(t),Bht=r(TKe," \u2014 "),Ese=n(TKe,"A",{href:!0});var zga=s(Ese);Iht=r(zga,"FlaxBlenderbotForConditionalGeneration"),zga.forEach(t),Nht=r(TKe," (Blenderbot model)"),TKe.forEach(t),qht=i(De),K7=n(De,"LI",{});var MKe=s(K7);zxe=n(MKe,"STRONG",{});var Qga=s(zxe);jht=r(Qga,"blenderbot-small"),Qga.forEach(t),Dht=r(MKe," \u2014 "),Cse=n(MKe,"A",{href:!0});var Wga=s(Cse);Ght=r(Wga,"FlaxBlenderbotSmallForConditionalGeneration"),Wga.forEach(t),Oht=r(MKe," (BlenderbotSmall model)"),MKe.forEach(t),Vht=i(De),Z7=n(De,"LI",{});var EKe=s(Z7);Qxe=n(EKe,"STRONG",{});var Uga=s(Qxe);Xht=r(Uga,"encoder-decoder"),Uga.forEach(t),zht=r(EKe," \u2014 "),wse=n(EKe,"A",{href:!0});var Hga=s(wse);Qht=r(Hga,"FlaxEncoderDecoderModel"),Hga.forEach(t),Wht=r(EKe," (Encoder decoder model)"),EKe.forEach(t),Uht=i(De),eL=n(De,"LI",{});var CKe=s(eL);Wxe=n(CKe,"STRONG",{});var Jga=s(Wxe);Hht=r(Jga,"longt5"),Jga.forEach(t),Jht=r(CKe," \u2014 "),Ase=n(CKe,"A",{href:!0});var Yga=s(Ase);Yht=r(Yga,"FlaxLongT5ForConditionalGeneration"),Yga.forEach(t),Kht=r(CKe," (LongT5 model)"),CKe.forEach(t),Zht=i(De),oL=n(De,"LI",{});var wKe=s(oL);Uxe=n(wKe,"STRONG",{});var Kga=s(Uxe);eut=r(Kga,"marian"),Kga.forEach(t),out=r(wKe," \u2014 "),Lse=n(wKe,"A",{href:!0});var Zga=s(Lse);rut=r(Zga,"FlaxMarianMTModel"),Zga.forEach(t),tut=r(wKe," (Marian model)"),wKe.forEach(t),aut=i(De),rL=n(De,"LI",{});var AKe=s(rL);Hxe=n(AKe,"STRONG",{});var eha=s(Hxe);nut=r(eha,"mbart"),eha.forEach(t),sut=r(AKe," \u2014 "),yse=n(AKe,"A",{href:!0});var oha=s(yse);lut=r(oha,"FlaxMBartForConditionalGeneration"),oha.forEach(t),iut=r(AKe," (mBART model)"),AKe.forEach(t),dut=i(De),tL=n(De,"LI",{});var LKe=s(tL);Jxe=n(LKe,"STRONG",{});var rha=s(Jxe);cut=r(rha,"mt5"),rha.forEach(t),mut=r(LKe," \u2014 "),xse=n(LKe,"A",{href:!0});var tha=s(xse);fut=r(tha,"FlaxMT5ForConditionalGeneration"),tha.forEach(t),gut=r(LKe," (MT5 model)"),LKe.forEach(t),hut=i(De),aL=n(De,"LI",{});var yKe=s(aL);Yxe=n(yKe,"STRONG",{});var aha=s(Yxe);uut=r(aha,"pegasus"),aha.forEach(t),put=r(yKe," \u2014 "),$se=n(yKe,"A",{href:!0});var nha=s($se);_ut=r(nha,"FlaxPegasusForConditionalGeneration"),nha.forEach(t),but=r(yKe," (Pegasus model)"),yKe.forEach(t),vut=i(De),nL=n(De,"LI",{});var xKe=s(nL);Kxe=n(xKe,"STRONG",{});var sha=s(Kxe);Fut=r(sha,"t5"),sha.forEach(t),Tut=r(xKe," \u2014 "),kse=n(xKe,"A",{href:!0});var lha=s(kse);Mut=r(lha,"FlaxT5ForConditionalGeneration"),lha.forEach(t),Eut=r(xKe," (T5 model)"),xKe.forEach(t),De.forEach(t),Cut=i(Oi),T(sL.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),uoo=i(m),Km=n(m,"H2",{class:!0});var kto=s(Km);lL=n(kto,"A",{id:!0,class:!0,href:!0});var iha=s(lL);Zxe=n(iha,"SPAN",{});var dha=s(Zxe);T(GR.$$.fragment,dha),dha.forEach(t),iha.forEach(t),wut=i(kto),e$e=n(kto,"SPAN",{});var cha=s(e$e);Aut=r(cha,"FlaxAutoModelForSequenceClassification"),cha.forEach(t),kto.forEach(t),poo=i(m),Lr=n(m,"DIV",{class:!0});var Vi=s(Lr);T(OR.$$.fragment,Vi),Lut=i(Vi),Zm=n(Vi,"P",{});var yde=s(Zm);yut=r(yde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Sse=n(yde,"A",{href:!0});var mha=s(Sse);xut=r(mha,"from_pretrained()"),mha.forEach(t),$ut=r(yde," class method or the "),Rse=n(yde,"A",{href:!0});var fha=s(Rse);kut=r(fha,"from_config()"),fha.forEach(t),Sut=r(yde,` class
method.`),yde.forEach(t),Rut=i(Vi),VR=n(Vi,"P",{});var Sto=s(VR);Put=r(Sto,"This class cannot be instantiated directly using "),o$e=n(Sto,"CODE",{});var gha=s(o$e);But=r(gha,"__init__()"),gha.forEach(t),Iut=r(Sto," (throws an error)."),Sto.forEach(t),Nut=i(Vi),ma=n(Vi,"DIV",{class:!0});var $9=s(ma);T(XR.$$.fragment,$9),qut=i($9),r$e=n($9,"P",{});var hha=s(r$e);jut=r(hha,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hha.forEach(t),Dut=i($9),ef=n($9,"P",{});var xde=s(ef);Gut=r(xde,`Note:
Loading a model from its configuration file does `),t$e=n(xde,"STRONG",{});var uha=s(t$e);Out=r(uha,"not"),uha.forEach(t),Vut=r(xde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pse=n(xde,"A",{href:!0});var pha=s(Pse);Xut=r(pha,"from_pretrained()"),pha.forEach(t),zut=r(xde," to load the model weights."),xde.forEach(t),Qut=i($9),T(iL.$$.fragment,$9),$9.forEach(t),Wut=i(Vi),tt=n(Vi,"DIV",{class:!0});var Xi=s(tt);T(zR.$$.fragment,Xi),Uut=i(Xi),a$e=n(Xi,"P",{});var _ha=s(a$e);Hut=r(_ha,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_ha.forEach(t),Jut=i(Xi),Qn=n(Xi,"P",{});var k9=s(Qn);Yut=r(k9,"The model class to instantiate is selected based on the "),n$e=n(k9,"CODE",{});var bha=s(n$e);Kut=r(bha,"model_type"),bha.forEach(t),Zut=r(k9,` property of the config object (either
passed as an argument or loaded from `),s$e=n(k9,"CODE",{});var vha=s(s$e);ept=r(vha,"pretrained_model_name_or_path"),vha.forEach(t),opt=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l$e=n(k9,"CODE",{});var Fha=s(l$e);rpt=r(Fha,"pretrained_model_name_or_path"),Fha.forEach(t),tpt=r(k9,":"),k9.forEach(t),apt=i(Xi),Se=n(Xi,"UL",{});var Ge=s(Se);dL=n(Ge,"LI",{});var $Ke=s(dL);i$e=n($Ke,"STRONG",{});var Tha=s(i$e);npt=r(Tha,"albert"),Tha.forEach(t),spt=r($Ke," \u2014 "),Bse=n($Ke,"A",{href:!0});var Mha=s(Bse);lpt=r(Mha,"FlaxAlbertForSequenceClassification"),Mha.forEach(t),ipt=r($Ke," (ALBERT model)"),$Ke.forEach(t),dpt=i(Ge),cL=n(Ge,"LI",{});var kKe=s(cL);d$e=n(kKe,"STRONG",{});var Eha=s(d$e);cpt=r(Eha,"bart"),Eha.forEach(t),mpt=r(kKe," \u2014 "),Ise=n(kKe,"A",{href:!0});var Cha=s(Ise);fpt=r(Cha,"FlaxBartForSequenceClassification"),Cha.forEach(t),gpt=r(kKe," (BART model)"),kKe.forEach(t),hpt=i(Ge),mL=n(Ge,"LI",{});var SKe=s(mL);c$e=n(SKe,"STRONG",{});var wha=s(c$e);upt=r(wha,"bert"),wha.forEach(t),ppt=r(SKe," \u2014 "),Nse=n(SKe,"A",{href:!0});var Aha=s(Nse);_pt=r(Aha,"FlaxBertForSequenceClassification"),Aha.forEach(t),bpt=r(SKe," (BERT model)"),SKe.forEach(t),vpt=i(Ge),fL=n(Ge,"LI",{});var RKe=s(fL);m$e=n(RKe,"STRONG",{});var Lha=s(m$e);Fpt=r(Lha,"big_bird"),Lha.forEach(t),Tpt=r(RKe," \u2014 "),qse=n(RKe,"A",{href:!0});var yha=s(qse);Mpt=r(yha,"FlaxBigBirdForSequenceClassification"),yha.forEach(t),Ept=r(RKe," (BigBird model)"),RKe.forEach(t),Cpt=i(Ge),gL=n(Ge,"LI",{});var PKe=s(gL);f$e=n(PKe,"STRONG",{});var xha=s(f$e);wpt=r(xha,"distilbert"),xha.forEach(t),Apt=r(PKe," \u2014 "),jse=n(PKe,"A",{href:!0});var $ha=s(jse);Lpt=r($ha,"FlaxDistilBertForSequenceClassification"),$ha.forEach(t),ypt=r(PKe," (DistilBERT model)"),PKe.forEach(t),xpt=i(Ge),hL=n(Ge,"LI",{});var BKe=s(hL);g$e=n(BKe,"STRONG",{});var kha=s(g$e);$pt=r(kha,"electra"),kha.forEach(t),kpt=r(BKe," \u2014 "),Dse=n(BKe,"A",{href:!0});var Sha=s(Dse);Spt=r(Sha,"FlaxElectraForSequenceClassification"),Sha.forEach(t),Rpt=r(BKe," (ELECTRA model)"),BKe.forEach(t),Ppt=i(Ge),uL=n(Ge,"LI",{});var IKe=s(uL);h$e=n(IKe,"STRONG",{});var Rha=s(h$e);Bpt=r(Rha,"mbart"),Rha.forEach(t),Ipt=r(IKe," \u2014 "),Gse=n(IKe,"A",{href:!0});var Pha=s(Gse);Npt=r(Pha,"FlaxMBartForSequenceClassification"),Pha.forEach(t),qpt=r(IKe," (mBART model)"),IKe.forEach(t),jpt=i(Ge),pL=n(Ge,"LI",{});var NKe=s(pL);u$e=n(NKe,"STRONG",{});var Bha=s(u$e);Dpt=r(Bha,"roberta"),Bha.forEach(t),Gpt=r(NKe," \u2014 "),Ose=n(NKe,"A",{href:!0});var Iha=s(Ose);Opt=r(Iha,"FlaxRobertaForSequenceClassification"),Iha.forEach(t),Vpt=r(NKe," (RoBERTa model)"),NKe.forEach(t),Xpt=i(Ge),_L=n(Ge,"LI",{});var qKe=s(_L);p$e=n(qKe,"STRONG",{});var Nha=s(p$e);zpt=r(Nha,"roformer"),Nha.forEach(t),Qpt=r(qKe," \u2014 "),Vse=n(qKe,"A",{href:!0});var qha=s(Vse);Wpt=r(qha,"FlaxRoFormerForSequenceClassification"),qha.forEach(t),Upt=r(qKe," (RoFormer model)"),qKe.forEach(t),Hpt=i(Ge),bL=n(Ge,"LI",{});var jKe=s(bL);_$e=n(jKe,"STRONG",{});var jha=s(_$e);Jpt=r(jha,"xlm-roberta"),jha.forEach(t),Ypt=r(jKe," \u2014 "),Xse=n(jKe,"A",{href:!0});var Dha=s(Xse);Kpt=r(Dha,"FlaxXLMRobertaForSequenceClassification"),Dha.forEach(t),Zpt=r(jKe," (XLM-RoBERTa model)"),jKe.forEach(t),Ge.forEach(t),e_t=i(Xi),T(vL.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),_oo=i(m),of=n(m,"H2",{class:!0});var Rto=s(of);FL=n(Rto,"A",{id:!0,class:!0,href:!0});var Gha=s(FL);b$e=n(Gha,"SPAN",{});var Oha=s(b$e);T(QR.$$.fragment,Oha),Oha.forEach(t),Gha.forEach(t),o_t=i(Rto),v$e=n(Rto,"SPAN",{});var Vha=s(v$e);r_t=r(Vha,"FlaxAutoModelForQuestionAnswering"),Vha.forEach(t),Rto.forEach(t),boo=i(m),yr=n(m,"DIV",{class:!0});var zi=s(yr);T(WR.$$.fragment,zi),t_t=i(zi),rf=n(zi,"P",{});var $de=s(rf);a_t=r($de,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),zse=n($de,"A",{href:!0});var Xha=s(zse);n_t=r(Xha,"from_pretrained()"),Xha.forEach(t),s_t=r($de," class method or the "),Qse=n($de,"A",{href:!0});var zha=s(Qse);l_t=r(zha,"from_config()"),zha.forEach(t),i_t=r($de,` class
method.`),$de.forEach(t),d_t=i(zi),UR=n(zi,"P",{});var Pto=s(UR);c_t=r(Pto,"This class cannot be instantiated directly using "),F$e=n(Pto,"CODE",{});var Qha=s(F$e);m_t=r(Qha,"__init__()"),Qha.forEach(t),f_t=r(Pto," (throws an error)."),Pto.forEach(t),g_t=i(zi),fa=n(zi,"DIV",{class:!0});var S9=s(fa);T(HR.$$.fragment,S9),h_t=i(S9),T$e=n(S9,"P",{});var Wha=s(T$e);u_t=r(Wha,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Wha.forEach(t),p_t=i(S9),tf=n(S9,"P",{});var kde=s(tf);__t=r(kde,`Note:
Loading a model from its configuration file does `),M$e=n(kde,"STRONG",{});var Uha=s(M$e);b_t=r(Uha,"not"),Uha.forEach(t),v_t=r(kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=n(kde,"A",{href:!0});var Hha=s(Wse);F_t=r(Hha,"from_pretrained()"),Hha.forEach(t),T_t=r(kde," to load the model weights."),kde.forEach(t),M_t=i(S9),T(TL.$$.fragment,S9),S9.forEach(t),E_t=i(zi),at=n(zi,"DIV",{class:!0});var Qi=s(at);T(JR.$$.fragment,Qi),C_t=i(Qi),E$e=n(Qi,"P",{});var Jha=s(E$e);w_t=r(Jha,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Jha.forEach(t),A_t=i(Qi),Wn=n(Qi,"P",{});var R9=s(Wn);L_t=r(R9,"The model class to instantiate is selected based on the "),C$e=n(R9,"CODE",{});var Yha=s(C$e);y_t=r(Yha,"model_type"),Yha.forEach(t),x_t=r(R9,` property of the config object (either
passed as an argument or loaded from `),w$e=n(R9,"CODE",{});var Kha=s(w$e);$_t=r(Kha,"pretrained_model_name_or_path"),Kha.forEach(t),k_t=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A$e=n(R9,"CODE",{});var Zha=s(A$e);S_t=r(Zha,"pretrained_model_name_or_path"),Zha.forEach(t),R_t=r(R9,":"),R9.forEach(t),P_t=i(Qi),Re=n(Qi,"UL",{});var Oe=s(Re);ML=n(Oe,"LI",{});var DKe=s(ML);L$e=n(DKe,"STRONG",{});var eua=s(L$e);B_t=r(eua,"albert"),eua.forEach(t),I_t=r(DKe," \u2014 "),Use=n(DKe,"A",{href:!0});var oua=s(Use);N_t=r(oua,"FlaxAlbertForQuestionAnswering"),oua.forEach(t),q_t=r(DKe," (ALBERT model)"),DKe.forEach(t),j_t=i(Oe),EL=n(Oe,"LI",{});var GKe=s(EL);y$e=n(GKe,"STRONG",{});var rua=s(y$e);D_t=r(rua,"bart"),rua.forEach(t),G_t=r(GKe," \u2014 "),Hse=n(GKe,"A",{href:!0});var tua=s(Hse);O_t=r(tua,"FlaxBartForQuestionAnswering"),tua.forEach(t),V_t=r(GKe," (BART model)"),GKe.forEach(t),X_t=i(Oe),CL=n(Oe,"LI",{});var OKe=s(CL);x$e=n(OKe,"STRONG",{});var aua=s(x$e);z_t=r(aua,"bert"),aua.forEach(t),Q_t=r(OKe," \u2014 "),Jse=n(OKe,"A",{href:!0});var nua=s(Jse);W_t=r(nua,"FlaxBertForQuestionAnswering"),nua.forEach(t),U_t=r(OKe," (BERT model)"),OKe.forEach(t),H_t=i(Oe),wL=n(Oe,"LI",{});var VKe=s(wL);$$e=n(VKe,"STRONG",{});var sua=s($$e);J_t=r(sua,"big_bird"),sua.forEach(t),Y_t=r(VKe," \u2014 "),Yse=n(VKe,"A",{href:!0});var lua=s(Yse);K_t=r(lua,"FlaxBigBirdForQuestionAnswering"),lua.forEach(t),Z_t=r(VKe," (BigBird model)"),VKe.forEach(t),e2t=i(Oe),AL=n(Oe,"LI",{});var XKe=s(AL);k$e=n(XKe,"STRONG",{});var iua=s(k$e);o2t=r(iua,"distilbert"),iua.forEach(t),r2t=r(XKe," \u2014 "),Kse=n(XKe,"A",{href:!0});var dua=s(Kse);t2t=r(dua,"FlaxDistilBertForQuestionAnswering"),dua.forEach(t),a2t=r(XKe," (DistilBERT model)"),XKe.forEach(t),n2t=i(Oe),LL=n(Oe,"LI",{});var zKe=s(LL);S$e=n(zKe,"STRONG",{});var cua=s(S$e);s2t=r(cua,"electra"),cua.forEach(t),l2t=r(zKe," \u2014 "),Zse=n(zKe,"A",{href:!0});var mua=s(Zse);i2t=r(mua,"FlaxElectraForQuestionAnswering"),mua.forEach(t),d2t=r(zKe," (ELECTRA model)"),zKe.forEach(t),c2t=i(Oe),yL=n(Oe,"LI",{});var QKe=s(yL);R$e=n(QKe,"STRONG",{});var fua=s(R$e);m2t=r(fua,"mbart"),fua.forEach(t),f2t=r(QKe," \u2014 "),ele=n(QKe,"A",{href:!0});var gua=s(ele);g2t=r(gua,"FlaxMBartForQuestionAnswering"),gua.forEach(t),h2t=r(QKe," (mBART model)"),QKe.forEach(t),u2t=i(Oe),xL=n(Oe,"LI",{});var WKe=s(xL);P$e=n(WKe,"STRONG",{});var hua=s(P$e);p2t=r(hua,"roberta"),hua.forEach(t),_2t=r(WKe," \u2014 "),ole=n(WKe,"A",{href:!0});var uua=s(ole);b2t=r(uua,"FlaxRobertaForQuestionAnswering"),uua.forEach(t),v2t=r(WKe," (RoBERTa model)"),WKe.forEach(t),F2t=i(Oe),$L=n(Oe,"LI",{});var UKe=s($L);B$e=n(UKe,"STRONG",{});var pua=s(B$e);T2t=r(pua,"roformer"),pua.forEach(t),M2t=r(UKe," \u2014 "),rle=n(UKe,"A",{href:!0});var _ua=s(rle);E2t=r(_ua,"FlaxRoFormerForQuestionAnswering"),_ua.forEach(t),C2t=r(UKe," (RoFormer model)"),UKe.forEach(t),w2t=i(Oe),kL=n(Oe,"LI",{});var HKe=s(kL);I$e=n(HKe,"STRONG",{});var bua=s(I$e);A2t=r(bua,"xlm-roberta"),bua.forEach(t),L2t=r(HKe," \u2014 "),tle=n(HKe,"A",{href:!0});var vua=s(tle);y2t=r(vua,"FlaxXLMRobertaForQuestionAnswering"),vua.forEach(t),x2t=r(HKe," (XLM-RoBERTa model)"),HKe.forEach(t),Oe.forEach(t),$2t=i(Qi),T(SL.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),voo=i(m),af=n(m,"H2",{class:!0});var Bto=s(af);RL=n(Bto,"A",{id:!0,class:!0,href:!0});var Fua=s(RL);N$e=n(Fua,"SPAN",{});var Tua=s(N$e);T(YR.$$.fragment,Tua),Tua.forEach(t),Fua.forEach(t),k2t=i(Bto),q$e=n(Bto,"SPAN",{});var Mua=s(q$e);S2t=r(Mua,"FlaxAutoModelForTokenClassification"),Mua.forEach(t),Bto.forEach(t),Foo=i(m),xr=n(m,"DIV",{class:!0});var Wi=s(xr);T(KR.$$.fragment,Wi),R2t=i(Wi),nf=n(Wi,"P",{});var Sde=s(nf);P2t=r(Sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ale=n(Sde,"A",{href:!0});var Eua=s(ale);B2t=r(Eua,"from_pretrained()"),Eua.forEach(t),I2t=r(Sde," class method or the "),nle=n(Sde,"A",{href:!0});var Cua=s(nle);N2t=r(Cua,"from_config()"),Cua.forEach(t),q2t=r(Sde,` class
method.`),Sde.forEach(t),j2t=i(Wi),ZR=n(Wi,"P",{});var Ito=s(ZR);D2t=r(Ito,"This class cannot be instantiated directly using "),j$e=n(Ito,"CODE",{});var wua=s(j$e);G2t=r(wua,"__init__()"),wua.forEach(t),O2t=r(Ito," (throws an error)."),Ito.forEach(t),V2t=i(Wi),ga=n(Wi,"DIV",{class:!0});var P9=s(ga);T(eP.$$.fragment,P9),X2t=i(P9),D$e=n(P9,"P",{});var Aua=s(D$e);z2t=r(Aua,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aua.forEach(t),Q2t=i(P9),sf=n(P9,"P",{});var Rde=s(sf);W2t=r(Rde,`Note:
Loading a model from its configuration file does `),G$e=n(Rde,"STRONG",{});var Lua=s(G$e);U2t=r(Lua,"not"),Lua.forEach(t),H2t=r(Rde,` load the model weights. It only affects the
model\u2019s configuration. Use `),sle=n(Rde,"A",{href:!0});var yua=s(sle);J2t=r(yua,"from_pretrained()"),yua.forEach(t),Y2t=r(Rde," to load the model weights."),Rde.forEach(t),K2t=i(P9),T(PL.$$.fragment,P9),P9.forEach(t),Z2t=i(Wi),nt=n(Wi,"DIV",{class:!0});var Ui=s(nt);T(oP.$$.fragment,Ui),ebt=i(Ui),O$e=n(Ui,"P",{});var xua=s(O$e);obt=r(xua,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xua.forEach(t),rbt=i(Ui),Un=n(Ui,"P",{});var B9=s(Un);tbt=r(B9,"The model class to instantiate is selected based on the "),V$e=n(B9,"CODE",{});var $ua=s(V$e);abt=r($ua,"model_type"),$ua.forEach(t),nbt=r(B9,` property of the config object (either
passed as an argument or loaded from `),X$e=n(B9,"CODE",{});var kua=s(X$e);sbt=r(kua,"pretrained_model_name_or_path"),kua.forEach(t),lbt=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z$e=n(B9,"CODE",{});var Sua=s(z$e);ibt=r(Sua,"pretrained_model_name_or_path"),Sua.forEach(t),dbt=r(B9,":"),B9.forEach(t),cbt=i(Ui),Xe=n(Ui,"UL",{});var Ao=s(Xe);BL=n(Ao,"LI",{});var JKe=s(BL);Q$e=n(JKe,"STRONG",{});var Rua=s(Q$e);mbt=r(Rua,"albert"),Rua.forEach(t),fbt=r(JKe," \u2014 "),lle=n(JKe,"A",{href:!0});var Pua=s(lle);gbt=r(Pua,"FlaxAlbertForTokenClassification"),Pua.forEach(t),hbt=r(JKe," (ALBERT model)"),JKe.forEach(t),ubt=i(Ao),IL=n(Ao,"LI",{});var YKe=s(IL);W$e=n(YKe,"STRONG",{});var Bua=s(W$e);pbt=r(Bua,"bert"),Bua.forEach(t),_bt=r(YKe," \u2014 "),ile=n(YKe,"A",{href:!0});var Iua=s(ile);bbt=r(Iua,"FlaxBertForTokenClassification"),Iua.forEach(t),vbt=r(YKe," (BERT model)"),YKe.forEach(t),Fbt=i(Ao),NL=n(Ao,"LI",{});var KKe=s(NL);U$e=n(KKe,"STRONG",{});var Nua=s(U$e);Tbt=r(Nua,"big_bird"),Nua.forEach(t),Mbt=r(KKe," \u2014 "),dle=n(KKe,"A",{href:!0});var qua=s(dle);Ebt=r(qua,"FlaxBigBirdForTokenClassification"),qua.forEach(t),Cbt=r(KKe," (BigBird model)"),KKe.forEach(t),wbt=i(Ao),qL=n(Ao,"LI",{});var ZKe=s(qL);H$e=n(ZKe,"STRONG",{});var jua=s(H$e);Abt=r(jua,"distilbert"),jua.forEach(t),Lbt=r(ZKe," \u2014 "),cle=n(ZKe,"A",{href:!0});var Dua=s(cle);ybt=r(Dua,"FlaxDistilBertForTokenClassification"),Dua.forEach(t),xbt=r(ZKe," (DistilBERT model)"),ZKe.forEach(t),$bt=i(Ao),jL=n(Ao,"LI",{});var eZe=s(jL);J$e=n(eZe,"STRONG",{});var Gua=s(J$e);kbt=r(Gua,"electra"),Gua.forEach(t),Sbt=r(eZe," \u2014 "),mle=n(eZe,"A",{href:!0});var Oua=s(mle);Rbt=r(Oua,"FlaxElectraForTokenClassification"),Oua.forEach(t),Pbt=r(eZe," (ELECTRA model)"),eZe.forEach(t),Bbt=i(Ao),DL=n(Ao,"LI",{});var oZe=s(DL);Y$e=n(oZe,"STRONG",{});var Vua=s(Y$e);Ibt=r(Vua,"roberta"),Vua.forEach(t),Nbt=r(oZe," \u2014 "),fle=n(oZe,"A",{href:!0});var Xua=s(fle);qbt=r(Xua,"FlaxRobertaForTokenClassification"),Xua.forEach(t),jbt=r(oZe," (RoBERTa model)"),oZe.forEach(t),Dbt=i(Ao),GL=n(Ao,"LI",{});var rZe=s(GL);K$e=n(rZe,"STRONG",{});var zua=s(K$e);Gbt=r(zua,"roformer"),zua.forEach(t),Obt=r(rZe," \u2014 "),gle=n(rZe,"A",{href:!0});var Qua=s(gle);Vbt=r(Qua,"FlaxRoFormerForTokenClassification"),Qua.forEach(t),Xbt=r(rZe," (RoFormer model)"),rZe.forEach(t),zbt=i(Ao),OL=n(Ao,"LI",{});var tZe=s(OL);Z$e=n(tZe,"STRONG",{});var Wua=s(Z$e);Qbt=r(Wua,"xlm-roberta"),Wua.forEach(t),Wbt=r(tZe," \u2014 "),hle=n(tZe,"A",{href:!0});var Uua=s(hle);Ubt=r(Uua,"FlaxXLMRobertaForTokenClassification"),Uua.forEach(t),Hbt=r(tZe," (XLM-RoBERTa model)"),tZe.forEach(t),Ao.forEach(t),Jbt=i(Ui),T(VL.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),Too=i(m),lf=n(m,"H2",{class:!0});var Nto=s(lf);XL=n(Nto,"A",{id:!0,class:!0,href:!0});var Hua=s(XL);eke=n(Hua,"SPAN",{});var Jua=s(eke);T(rP.$$.fragment,Jua),Jua.forEach(t),Hua.forEach(t),Ybt=i(Nto),oke=n(Nto,"SPAN",{});var Yua=s(oke);Kbt=r(Yua,"FlaxAutoModelForMultipleChoice"),Yua.forEach(t),Nto.forEach(t),Moo=i(m),$r=n(m,"DIV",{class:!0});var Hi=s($r);T(tP.$$.fragment,Hi),Zbt=i(Hi),df=n(Hi,"P",{});var Pde=s(df);e1t=r(Pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),ule=n(Pde,"A",{href:!0});var Kua=s(ule);o1t=r(Kua,"from_pretrained()"),Kua.forEach(t),r1t=r(Pde," class method or the "),ple=n(Pde,"A",{href:!0});var Zua=s(ple);t1t=r(Zua,"from_config()"),Zua.forEach(t),a1t=r(Pde,` class
method.`),Pde.forEach(t),n1t=i(Hi),aP=n(Hi,"P",{});var qto=s(aP);s1t=r(qto,"This class cannot be instantiated directly using "),rke=n(qto,"CODE",{});var epa=s(rke);l1t=r(epa,"__init__()"),epa.forEach(t),i1t=r(qto," (throws an error)."),qto.forEach(t),d1t=i(Hi),ha=n(Hi,"DIV",{class:!0});var I9=s(ha);T(nP.$$.fragment,I9),c1t=i(I9),tke=n(I9,"P",{});var opa=s(tke);m1t=r(opa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),opa.forEach(t),f1t=i(I9),cf=n(I9,"P",{});var Bde=s(cf);g1t=r(Bde,`Note:
Loading a model from its configuration file does `),ake=n(Bde,"STRONG",{});var rpa=s(ake);h1t=r(rpa,"not"),rpa.forEach(t),u1t=r(Bde,` load the model weights. It only affects the
model\u2019s configuration. Use `),_le=n(Bde,"A",{href:!0});var tpa=s(_le);p1t=r(tpa,"from_pretrained()"),tpa.forEach(t),_1t=r(Bde," to load the model weights."),Bde.forEach(t),b1t=i(I9),T(zL.$$.fragment,I9),I9.forEach(t),v1t=i(Hi),st=n(Hi,"DIV",{class:!0});var Ji=s(st);T(sP.$$.fragment,Ji),F1t=i(Ji),nke=n(Ji,"P",{});var apa=s(nke);T1t=r(apa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),apa.forEach(t),M1t=i(Ji),Hn=n(Ji,"P",{});var N9=s(Hn);E1t=r(N9,"The model class to instantiate is selected based on the "),ske=n(N9,"CODE",{});var npa=s(ske);C1t=r(npa,"model_type"),npa.forEach(t),w1t=r(N9,` property of the config object (either
passed as an argument or loaded from `),lke=n(N9,"CODE",{});var spa=s(lke);A1t=r(spa,"pretrained_model_name_or_path"),spa.forEach(t),L1t=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ike=n(N9,"CODE",{});var lpa=s(ike);y1t=r(lpa,"pretrained_model_name_or_path"),lpa.forEach(t),x1t=r(N9,":"),N9.forEach(t),$1t=i(Ji),ze=n(Ji,"UL",{});var Lo=s(ze);QL=n(Lo,"LI",{});var aZe=s(QL);dke=n(aZe,"STRONG",{});var ipa=s(dke);k1t=r(ipa,"albert"),ipa.forEach(t),S1t=r(aZe," \u2014 "),ble=n(aZe,"A",{href:!0});var dpa=s(ble);R1t=r(dpa,"FlaxAlbertForMultipleChoice"),dpa.forEach(t),P1t=r(aZe," (ALBERT model)"),aZe.forEach(t),B1t=i(Lo),WL=n(Lo,"LI",{});var nZe=s(WL);cke=n(nZe,"STRONG",{});var cpa=s(cke);I1t=r(cpa,"bert"),cpa.forEach(t),N1t=r(nZe," \u2014 "),vle=n(nZe,"A",{href:!0});var mpa=s(vle);q1t=r(mpa,"FlaxBertForMultipleChoice"),mpa.forEach(t),j1t=r(nZe," (BERT model)"),nZe.forEach(t),D1t=i(Lo),UL=n(Lo,"LI",{});var sZe=s(UL);mke=n(sZe,"STRONG",{});var fpa=s(mke);G1t=r(fpa,"big_bird"),fpa.forEach(t),O1t=r(sZe," \u2014 "),Fle=n(sZe,"A",{href:!0});var gpa=s(Fle);V1t=r(gpa,"FlaxBigBirdForMultipleChoice"),gpa.forEach(t),X1t=r(sZe," (BigBird model)"),sZe.forEach(t),z1t=i(Lo),HL=n(Lo,"LI",{});var lZe=s(HL);fke=n(lZe,"STRONG",{});var hpa=s(fke);Q1t=r(hpa,"distilbert"),hpa.forEach(t),W1t=r(lZe," \u2014 "),Tle=n(lZe,"A",{href:!0});var upa=s(Tle);U1t=r(upa,"FlaxDistilBertForMultipleChoice"),upa.forEach(t),H1t=r(lZe," (DistilBERT model)"),lZe.forEach(t),J1t=i(Lo),JL=n(Lo,"LI",{});var iZe=s(JL);gke=n(iZe,"STRONG",{});var ppa=s(gke);Y1t=r(ppa,"electra"),ppa.forEach(t),K1t=r(iZe," \u2014 "),Mle=n(iZe,"A",{href:!0});var _pa=s(Mle);Z1t=r(_pa,"FlaxElectraForMultipleChoice"),_pa.forEach(t),evt=r(iZe," (ELECTRA model)"),iZe.forEach(t),ovt=i(Lo),YL=n(Lo,"LI",{});var dZe=s(YL);hke=n(dZe,"STRONG",{});var bpa=s(hke);rvt=r(bpa,"roberta"),bpa.forEach(t),tvt=r(dZe," \u2014 "),Ele=n(dZe,"A",{href:!0});var vpa=s(Ele);avt=r(vpa,"FlaxRobertaForMultipleChoice"),vpa.forEach(t),nvt=r(dZe," (RoBERTa model)"),dZe.forEach(t),svt=i(Lo),KL=n(Lo,"LI",{});var cZe=s(KL);uke=n(cZe,"STRONG",{});var Fpa=s(uke);lvt=r(Fpa,"roformer"),Fpa.forEach(t),ivt=r(cZe," \u2014 "),Cle=n(cZe,"A",{href:!0});var Tpa=s(Cle);dvt=r(Tpa,"FlaxRoFormerForMultipleChoice"),Tpa.forEach(t),cvt=r(cZe," (RoFormer model)"),cZe.forEach(t),mvt=i(Lo),ZL=n(Lo,"LI",{});var mZe=s(ZL);pke=n(mZe,"STRONG",{});var Mpa=s(pke);fvt=r(Mpa,"xlm-roberta"),Mpa.forEach(t),gvt=r(mZe," \u2014 "),wle=n(mZe,"A",{href:!0});var Epa=s(wle);hvt=r(Epa,"FlaxXLMRobertaForMultipleChoice"),Epa.forEach(t),uvt=r(mZe," (XLM-RoBERTa model)"),mZe.forEach(t),Lo.forEach(t),pvt=i(Ji),T(ey.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Eoo=i(m),mf=n(m,"H2",{class:!0});var jto=s(mf);oy=n(jto,"A",{id:!0,class:!0,href:!0});var Cpa=s(oy);_ke=n(Cpa,"SPAN",{});var wpa=s(_ke);T(lP.$$.fragment,wpa),wpa.forEach(t),Cpa.forEach(t),_vt=i(jto),bke=n(jto,"SPAN",{});var Apa=s(bke);bvt=r(Apa,"FlaxAutoModelForNextSentencePrediction"),Apa.forEach(t),jto.forEach(t),Coo=i(m),kr=n(m,"DIV",{class:!0});var Yi=s(kr);T(iP.$$.fragment,Yi),vvt=i(Yi),ff=n(Yi,"P",{});var Ide=s(ff);Fvt=r(Ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Ale=n(Ide,"A",{href:!0});var Lpa=s(Ale);Tvt=r(Lpa,"from_pretrained()"),Lpa.forEach(t),Mvt=r(Ide," class method or the "),Lle=n(Ide,"A",{href:!0});var ypa=s(Lle);Evt=r(ypa,"from_config()"),ypa.forEach(t),Cvt=r(Ide,` class
method.`),Ide.forEach(t),wvt=i(Yi),dP=n(Yi,"P",{});var Dto=s(dP);Avt=r(Dto,"This class cannot be instantiated directly using "),vke=n(Dto,"CODE",{});var xpa=s(vke);Lvt=r(xpa,"__init__()"),xpa.forEach(t),yvt=r(Dto," (throws an error)."),Dto.forEach(t),xvt=i(Yi),ua=n(Yi,"DIV",{class:!0});var q9=s(ua);T(cP.$$.fragment,q9),$vt=i(q9),Fke=n(q9,"P",{});var $pa=s(Fke);kvt=r($pa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$pa.forEach(t),Svt=i(q9),gf=n(q9,"P",{});var Nde=s(gf);Rvt=r(Nde,`Note:
Loading a model from its configuration file does `),Tke=n(Nde,"STRONG",{});var kpa=s(Tke);Pvt=r(kpa,"not"),kpa.forEach(t),Bvt=r(Nde,` load the model weights. It only affects the
model\u2019s configuration. Use `),yle=n(Nde,"A",{href:!0});var Spa=s(yle);Ivt=r(Spa,"from_pretrained()"),Spa.forEach(t),Nvt=r(Nde," to load the model weights."),Nde.forEach(t),qvt=i(q9),T(ry.$$.fragment,q9),q9.forEach(t),jvt=i(Yi),lt=n(Yi,"DIV",{class:!0});var Ki=s(lt);T(mP.$$.fragment,Ki),Dvt=i(Ki),Mke=n(Ki,"P",{});var Rpa=s(Mke);Gvt=r(Rpa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rpa.forEach(t),Ovt=i(Ki),Jn=n(Ki,"P",{});var j9=s(Jn);Vvt=r(j9,"The model class to instantiate is selected based on the "),Eke=n(j9,"CODE",{});var Ppa=s(Eke);Xvt=r(Ppa,"model_type"),Ppa.forEach(t),zvt=r(j9,` property of the config object (either
passed as an argument or loaded from `),Cke=n(j9,"CODE",{});var Bpa=s(Cke);Qvt=r(Bpa,"pretrained_model_name_or_path"),Bpa.forEach(t),Wvt=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wke=n(j9,"CODE",{});var Ipa=s(wke);Uvt=r(Ipa,"pretrained_model_name_or_path"),Ipa.forEach(t),Hvt=r(j9,":"),j9.forEach(t),Jvt=i(Ki),Ake=n(Ki,"UL",{});var Npa=s(Ake);ty=n(Npa,"LI",{});var fZe=s(ty);Lke=n(fZe,"STRONG",{});var qpa=s(Lke);Yvt=r(qpa,"bert"),qpa.forEach(t),Kvt=r(fZe," \u2014 "),xle=n(fZe,"A",{href:!0});var jpa=s(xle);Zvt=r(jpa,"FlaxBertForNextSentencePrediction"),jpa.forEach(t),eFt=r(fZe," (BERT model)"),fZe.forEach(t),Npa.forEach(t),oFt=i(Ki),T(ay.$$.fragment,Ki),Ki.forEach(t),Yi.forEach(t),woo=i(m),hf=n(m,"H2",{class:!0});var Gto=s(hf);ny=n(Gto,"A",{id:!0,class:!0,href:!0});var Dpa=s(ny);yke=n(Dpa,"SPAN",{});var Gpa=s(yke);T(fP.$$.fragment,Gpa),Gpa.forEach(t),Dpa.forEach(t),rFt=i(Gto),xke=n(Gto,"SPAN",{});var Opa=s(xke);tFt=r(Opa,"FlaxAutoModelForImageClassification"),Opa.forEach(t),Gto.forEach(t),Aoo=i(m),Sr=n(m,"DIV",{class:!0});var Zi=s(Sr);T(gP.$$.fragment,Zi),aFt=i(Zi),uf=n(Zi,"P",{});var qde=s(uf);nFt=r(qde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),$le=n(qde,"A",{href:!0});var Vpa=s($le);sFt=r(Vpa,"from_pretrained()"),Vpa.forEach(t),lFt=r(qde," class method or the "),kle=n(qde,"A",{href:!0});var Xpa=s(kle);iFt=r(Xpa,"from_config()"),Xpa.forEach(t),dFt=r(qde,` class
method.`),qde.forEach(t),cFt=i(Zi),hP=n(Zi,"P",{});var Oto=s(hP);mFt=r(Oto,"This class cannot be instantiated directly using "),$ke=n(Oto,"CODE",{});var zpa=s($ke);fFt=r(zpa,"__init__()"),zpa.forEach(t),gFt=r(Oto," (throws an error)."),Oto.forEach(t),hFt=i(Zi),pa=n(Zi,"DIV",{class:!0});var D9=s(pa);T(uP.$$.fragment,D9),uFt=i(D9),kke=n(D9,"P",{});var Qpa=s(kke);pFt=r(Qpa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Qpa.forEach(t),_Ft=i(D9),pf=n(D9,"P",{});var jde=s(pf);bFt=r(jde,`Note:
Loading a model from its configuration file does `),Ske=n(jde,"STRONG",{});var Wpa=s(Ske);vFt=r(Wpa,"not"),Wpa.forEach(t),FFt=r(jde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sle=n(jde,"A",{href:!0});var Upa=s(Sle);TFt=r(Upa,"from_pretrained()"),Upa.forEach(t),MFt=r(jde," to load the model weights."),jde.forEach(t),EFt=i(D9),T(sy.$$.fragment,D9),D9.forEach(t),CFt=i(Zi),it=n(Zi,"DIV",{class:!0});var ed=s(it);T(pP.$$.fragment,ed),wFt=i(ed),Rke=n(ed,"P",{});var Hpa=s(Rke);AFt=r(Hpa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Hpa.forEach(t),LFt=i(ed),Yn=n(ed,"P",{});var G9=s(Yn);yFt=r(G9,"The model class to instantiate is selected based on the "),Pke=n(G9,"CODE",{});var Jpa=s(Pke);xFt=r(Jpa,"model_type"),Jpa.forEach(t),$Ft=r(G9,` property of the config object (either
passed as an argument or loaded from `),Bke=n(G9,"CODE",{});var Ypa=s(Bke);kFt=r(Ypa,"pretrained_model_name_or_path"),Ypa.forEach(t),SFt=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ike=n(G9,"CODE",{});var Kpa=s(Ike);RFt=r(Kpa,"pretrained_model_name_or_path"),Kpa.forEach(t),PFt=r(G9,":"),G9.forEach(t),BFt=i(ed),_P=n(ed,"UL",{});var Vto=s(_P);ly=n(Vto,"LI",{});var gZe=s(ly);Nke=n(gZe,"STRONG",{});var Zpa=s(Nke);IFt=r(Zpa,"beit"),Zpa.forEach(t),NFt=r(gZe," \u2014 "),Rle=n(gZe,"A",{href:!0});var e_a=s(Rle);qFt=r(e_a,"FlaxBeitForImageClassification"),e_a.forEach(t),jFt=r(gZe," (BEiT model)"),gZe.forEach(t),DFt=i(Vto),iy=n(Vto,"LI",{});var hZe=s(iy);qke=n(hZe,"STRONG",{});var o_a=s(qke);GFt=r(o_a,"vit"),o_a.forEach(t),OFt=r(hZe," \u2014 "),Ple=n(hZe,"A",{href:!0});var r_a=s(Ple);VFt=r(r_a,"FlaxViTForImageClassification"),r_a.forEach(t),XFt=r(hZe," (ViT model)"),hZe.forEach(t),Vto.forEach(t),zFt=i(ed),T(dy.$$.fragment,ed),ed.forEach(t),Zi.forEach(t),Loo=i(m),_f=n(m,"H2",{class:!0});var Xto=s(_f);cy=n(Xto,"A",{id:!0,class:!0,href:!0});var t_a=s(cy);jke=n(t_a,"SPAN",{});var a_a=s(jke);T(bP.$$.fragment,a_a),a_a.forEach(t),t_a.forEach(t),QFt=i(Xto),Dke=n(Xto,"SPAN",{});var n_a=s(Dke);WFt=r(n_a,"FlaxAutoModelForVision2Seq"),n_a.forEach(t),Xto.forEach(t),yoo=i(m),Rr=n(m,"DIV",{class:!0});var od=s(Rr);T(vP.$$.fragment,od),UFt=i(od),bf=n(od,"P",{});var Dde=s(bf);HFt=r(Dde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ble=n(Dde,"A",{href:!0});var s_a=s(Ble);JFt=r(s_a,"from_pretrained()"),s_a.forEach(t),YFt=r(Dde," class method or the "),Ile=n(Dde,"A",{href:!0});var l_a=s(Ile);KFt=r(l_a,"from_config()"),l_a.forEach(t),ZFt=r(Dde,` class
method.`),Dde.forEach(t),eTt=i(od),FP=n(od,"P",{});var zto=s(FP);oTt=r(zto,"This class cannot be instantiated directly using "),Gke=n(zto,"CODE",{});var i_a=s(Gke);rTt=r(i_a,"__init__()"),i_a.forEach(t),tTt=r(zto," (throws an error)."),zto.forEach(t),aTt=i(od),_a=n(od,"DIV",{class:!0});var O9=s(_a);T(TP.$$.fragment,O9),nTt=i(O9),Oke=n(O9,"P",{});var d_a=s(Oke);sTt=r(d_a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),d_a.forEach(t),lTt=i(O9),vf=n(O9,"P",{});var Gde=s(vf);iTt=r(Gde,`Note:
Loading a model from its configuration file does `),Vke=n(Gde,"STRONG",{});var c_a=s(Vke);dTt=r(c_a,"not"),c_a.forEach(t),cTt=r(Gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nle=n(Gde,"A",{href:!0});var m_a=s(Nle);mTt=r(m_a,"from_pretrained()"),m_a.forEach(t),fTt=r(Gde," to load the model weights."),Gde.forEach(t),gTt=i(O9),T(my.$$.fragment,O9),O9.forEach(t),hTt=i(od),dt=n(od,"DIV",{class:!0});var rd=s(dt);T(MP.$$.fragment,rd),uTt=i(rd),Xke=n(rd,"P",{});var f_a=s(Xke);pTt=r(f_a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),f_a.forEach(t),_Tt=i(rd),Kn=n(rd,"P",{});var V9=s(Kn);bTt=r(V9,"The model class to instantiate is selected based on the "),zke=n(V9,"CODE",{});var g_a=s(zke);vTt=r(g_a,"model_type"),g_a.forEach(t),FTt=r(V9,` property of the config object (either
passed as an argument or loaded from `),Qke=n(V9,"CODE",{});var h_a=s(Qke);TTt=r(h_a,"pretrained_model_name_or_path"),h_a.forEach(t),MTt=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wke=n(V9,"CODE",{});var u_a=s(Wke);ETt=r(u_a,"pretrained_model_name_or_path"),u_a.forEach(t),CTt=r(V9,":"),V9.forEach(t),wTt=i(rd),Uke=n(rd,"UL",{});var p_a=s(Uke);fy=n(p_a,"LI",{});var uZe=s(fy);Hke=n(uZe,"STRONG",{});var __a=s(Hke);ATt=r(__a,"vision-encoder-decoder"),__a.forEach(t),LTt=r(uZe," \u2014 "),qle=n(uZe,"A",{href:!0});var b_a=s(qle);yTt=r(b_a,"FlaxVisionEncoderDecoderModel"),b_a.forEach(t),xTt=r(uZe," (Vision Encoder decoder model)"),uZe.forEach(t),p_a.forEach(t),$Tt=i(rd),T(gy.$$.fragment,rd),rd.forEach(t),od.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Sba)),c(f,"id","auto-classes"),c(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f,"href","#auto-classes"),c(u,"class","relative group"),c(es,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),c(rs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),c(ts,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),c(dd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(Lf,"id","extending-the-auto-classes"),c(Lf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lf,"href","#extending-the-auto-classes"),c(cd,"class","relative group"),c(xf,"id","transformers.AutoConfig"),c(xf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xf,"href","#transformers.AutoConfig"),c(md,"class","relative group"),c(eI,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(oI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),c(rI,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),c(tI,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),c(aI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),c(nI,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(sI,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),c(lI,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(iI,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(dI,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(cI,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),c(mI,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),c(fI,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),c(gI,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),c(hI,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),c(uI,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),c(pI,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),c(_I,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),c(bI,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),c(vI,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),c(FI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(TI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(MI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(EI,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),c(CI,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(wI,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(AI,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(LI,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),c(yI,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),c(xI,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),c($I,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),c(kI,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),c(SI,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),c(RI,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),c(PI,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(BI,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),c(II,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),c(NI,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),c(qI,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),c(jI,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),c(DI,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),c(GI,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),c(OI,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),c(VI,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(XI,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(zI,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),c(QI,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),c(WI,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),c(UI,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),c(HI,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),c(JI,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(YI,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(KI,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(ZI,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(eN,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),c(oN,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),c(rN,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),c(tN,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),c(aN,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),c(nN,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),c(sN,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),c(lN,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),c(iN,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),c(dN,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(cN,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),c(mN,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),c(fN,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(gN,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(hN,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(uN,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),c(pN,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),c(_N,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),c(bN,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),c(vN,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(FN,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(TN,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),c(MN,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),c(EN,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),c(CN,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),c(wN,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),c(AN,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),c(LN,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(yN,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(xN,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),c($N,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),c(kN,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),c(SN,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),c(RN,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),c(PN,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),c(BN,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),c(IN,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),c(NN,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),c(qN,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),c(jN,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),c(DN,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),c(GN,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),c(ON,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(VN,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(XN,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(zN,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),c(QN,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(WN,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),c(UN,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),c(HN,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),c(JN,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),c(YN,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(KN,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(ZN,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),c(eq,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(oq,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(rq,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),c(tq,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),c(aq,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),c(nq,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(sq,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(lq,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(iq,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),c(dq,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(cq,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),c(mq,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(fq,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(gq,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),c(hq,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),c(uq,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),c(pq,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),c(_q,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(bq,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(vq,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(Fq,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),c(Tq,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),c(Mq,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eu,"id","transformers.AutoTokenizer"),c(eu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eu,"href","#transformers.AutoTokenizer"),c(gd,"class","relative group"),c(Eq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(Cq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(wq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Aq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),c(Lq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),c(yq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),c(xq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c($q,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(kq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(Sq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(Rq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(Pq,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(Bq,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(Iq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(Nq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(qq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(jq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(Dq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(Gq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(Oq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(Vq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(Xq,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(zq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),c(Qq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(Wq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),c(Uq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(Hq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Jq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(Yq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(Kq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(Zq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(ej,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),c(oj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(rj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(tj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(aj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(nj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),c(sj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(lj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(ij,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(dj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(cj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(mj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(fj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(gj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),c(hj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(uj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(pj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(_j,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(bj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),c(vj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(Fj,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(Tj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),c(Mj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(Ej,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Cj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(wj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Aj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Lj,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(yj,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),c(xj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c($j,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(kj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(Sj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(Rj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),c(Pj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(Bj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(Ij,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Nj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(jj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(Dj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(Gj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(Oj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(Vj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(Xj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(zj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(Qj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),c(Wj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),c(Uj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),c(Hj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(Jj,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(Yj,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(Kj,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),c(Zj,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(eD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(oD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(rD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),c(tD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),c(aD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(nD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(sD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(lD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(iD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(dD,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),c(cD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(mD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(fD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(gD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(hD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(uD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(pD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),c(_D,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(bD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(vD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(FD,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),c(TD,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(MD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(ED,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(CD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(wD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(AD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(LD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(yD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(xD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),c($D,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(kD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(SD,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),c(RD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),c(PD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(BD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(ID,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(ND,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),c(qD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),c(jD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),c(DD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),c(GD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(OD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),c(VD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(XD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(zD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(QD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),c(WD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(HD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(JD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(YD,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(KD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),c(ZD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(eG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(oG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(rG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),c(tG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),c(aG,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),c(nG,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),c(sG,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(lG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(iG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(dG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),c(cG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),c(mG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(fG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(gG,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(hG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),c(uG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(pG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),c(_G,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(bG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),c(vG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(FG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(TG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(MG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(EG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(CG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(wG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(AG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),c(LG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Iu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nu,"id","transformers.AutoFeatureExtractor"),c(Nu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nu,"href","#transformers.AutoFeatureExtractor"),c(hd,"class","relative group"),c(yG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(xG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c($G,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(kG,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),c(SG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(RG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(PG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(BG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(IG,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),c(NG,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(qG,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(jG,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),c(DG,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(GG,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(OG,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(VG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(XG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(zG,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(QG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(WG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(UG,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(HG,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(JG,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(YG,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(KG,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(ZG,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(eO,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(oO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(tO,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(aO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(nO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(sO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(lO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(iO,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),c(dO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(cO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(mO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(fO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(gO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(hO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(uO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(pO,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xp,"id","transformers.AutoProcessor"),c(xp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xp,"href","#transformers.AutoProcessor"),c(ud,"class","relative group"),c(_O,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(bO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(vO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),c(FO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),c(TO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(MO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(EO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(CO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(wO,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),c(AO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(LO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(yO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(xO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c($O,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(kO,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),c(SO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(RO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(PO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),c(BO,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(IO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(NO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(qO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(jO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o_,"id","transformers.AutoModel"),c(o_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o_,"href","#transformers.AutoModel"),c(_d,"class","relative group"),c(DO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),c(XO,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),c(zO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),c(QO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),c(WO,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(UO,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),c(HO,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(JO,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(YO,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(KO,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),c(ZO,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),c(eV,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),c(oV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),c(rV,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),c(tV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),c(aV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),c(nV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),c(sV,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),c(lV,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),c(iV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(dV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(cV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(mV,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),c(fV,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(gV,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(hV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),c(uV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),c(pV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),c(_V,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),c(bV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),c(vV,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(FV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),c(TV,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),c(MV,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),c(EV,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),c(CV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),c(wV,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),c(AV,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),c(LV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),c(yV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),c(xV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),c($V,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),c(kV,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(SV,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(RV,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),c(PV,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),c(BV,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),c(IV,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),c(NV,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),c(qV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(jV,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(DV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(GV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(OV,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),c(VV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),c(XV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),c(zV,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),c(QV,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),c(WV,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),c(UV,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(HV,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),c(JV,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),c(YV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),c(KV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),c(ZV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),c(eX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(oX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),c(rX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),c(tX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),c(aX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),c(nX,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),c(sX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),c(lX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),c(iX,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),c(dX,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(cX,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),c(mX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),c(fX,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),c(gX,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),c(hX,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),c(uX,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),c(pX,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),c(_X,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(bX,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),c(vX,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),c(FX,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),c(TX,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),c(MX,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),c(EX,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(CX,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),c(wX,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),c(AX,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),c(LX,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),c(yX,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),c(xX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c($X,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),c(kX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(SX,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),c(RX,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),c(PX,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),c(BX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),c(IX,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(NX,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(qX,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),c(jX,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(DX,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),c(GX,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),c(OX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),c(VX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(XX,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),c(zX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),c(QX,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(WX,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),c(UX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(HX,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(JX,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),c(YX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),c(KX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),c(ZX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),c(ez,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(oz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(rz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(tz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),c(az,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),c(nz,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fb,"id","transformers.AutoModelForPreTraining"),c(Fb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fb,"href","#transformers.AutoModelForPreTraining"),c(Fd,"class","relative group"),c(sz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dz,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),c(cz,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(mz,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),c(fz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(gz,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(hz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(uz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(pz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(_z,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(bz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(vz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Fz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),c(Tz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),c(Mz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Ez,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),c(Cz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),c(wz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(Az,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(Lz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(yz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(xz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c($z,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(kz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(Sz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(Rz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(Pz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(Bz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(Iz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(Nz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(qz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(jz,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),c(Dz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(Gz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(Oz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(Vz,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(Xz,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(zz,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(Qz,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(Wz,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(Uz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(Hz,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(Jz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(Yz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(Kz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(Zz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(eQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(oQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(rQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b1,"id","transformers.AutoModelForCausalLM"),c(b1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b1,"href","#transformers.AutoModelForCausalLM"),c(Ed,"class","relative group"),c(tQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),c(lQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),c(iQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(dQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(cQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(mQ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(fQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(gQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),c(hQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(uQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(pQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(_Q,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(bQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),c(vQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),c(FQ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(TQ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(MQ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(EQ,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),c(CQ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(wQ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),c(AQ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),c(LQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(yQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),c(xQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c($Q,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),c(kQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(SQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(RQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(PQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(BQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(IQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(NQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(qQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(jQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(DQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(GQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(OQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(VQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(XQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(zQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(QQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(WQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cv,"id","transformers.AutoModelForMaskedLM"),c(cv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cv,"href","#transformers.AutoModelForMaskedLM"),c(Ad,"class","relative group"),c(UQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(KQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(ZQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),c(eW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(oW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(rW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(tW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(aW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(nW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(sW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(lW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(iW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),c(dW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(cW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(mW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(fW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(gW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(hW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(uW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),c(pW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(_W,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(bW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(vW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(FW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(TW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(MW,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(EW,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(CW,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(wW,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(AW,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(LW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(yW,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(xW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c($W,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(kW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(SW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(RW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(PW,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zv,"id","transformers.AutoModelForSeq2SeqLM"),c(Zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zv,"href","#transformers.AutoModelForSeq2SeqLM"),c(xd,"class","relative group"),c(BW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(jW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(DW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(GW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(OW,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(VW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(XW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(zW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(QW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(WW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),c(UW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(HW,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(JW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(YW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(KW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(ZW,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),c(eU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(oU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(rU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(tU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EF,"id","transformers.AutoModelForSequenceClassification"),c(EF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EF,"href","#transformers.AutoModelForSequenceClassification"),c(Sd,"class","relative group"),c(aU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(iU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),c(dU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),c(cU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(mU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(fU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(gU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(hU,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(uU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(pU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(_U,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(bU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(vU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(FU,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(TU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(MU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),c(EU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(CU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(wU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(AU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(LU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(yU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(xU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c($U,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(kU,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(SU,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(RU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),c(PU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(BU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(IU,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),c(NU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(qU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(jU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(DU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(GU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(OU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(VU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(XU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(zU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(QU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(WU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(UU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(HU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(JU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(YU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(KU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(ZU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(eH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(oH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(rH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(tH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(aH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(nH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(sH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LT,"id","transformers.AutoModelForMultipleChoice"),c(LT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LT,"href","#transformers.AutoModelForMultipleChoice"),c(Bd,"class","relative group"),c(lH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(mH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),c(fH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(gH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(hH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(uH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(pH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(_H,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(bH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(vH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(FH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),c(TH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(MH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(EH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(CH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(wH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(AH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(LH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(yH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(xH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c($H,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(kH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(SH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(RH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(PH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(BH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(IH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(NH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(qH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(jH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(DH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(GH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dM,"id","transformers.AutoModelForNextSentencePrediction"),c(dM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dM,"href","#transformers.AutoModelForNextSentencePrediction"),c(qd,"class","relative group"),c(OH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(QH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),c(WH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(UH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(HH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(JH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(YH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FM,"id","transformers.AutoModelForTokenClassification"),c(FM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FM,"href","#transformers.AutoModelForTokenClassification"),c(Gd,"class","relative group"),c(KH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(rJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),c(tJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(aJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(nJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(sJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),c(lJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(iJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(dJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(cJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(mJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(fJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(gJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),c(hJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(uJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(pJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(_J,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(bJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(vJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(FJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(TJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(MJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(EJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),c(CJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),c(wJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(AJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(LJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(yJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(xJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c($J,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(kJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(SJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(RJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(PJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(BJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(IJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(NJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(qJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(jJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dE,"id","transformers.AutoModelForQuestionAnswering"),c(dE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dE,"href","#transformers.AutoModelForQuestionAnswering"),c(Xd,"class","relative group"),c(DJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(XJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(zJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(QJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(WJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(UJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(HJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(JJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(YJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(KJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(ZJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(eY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(oY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(rY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),c(tY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(aY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(nY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(sY,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(lY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(iY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(dY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(cY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(mY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(fY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(gY,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(hY,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),c(uY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(pY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(_Y,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(bY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(vY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(FY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(TY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(MY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(EY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(CY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(wY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(AY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(LY,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(yY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(xY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c($Y,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(kY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(SY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(RY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a4,"id","transformers.AutoModelForTableQuestionAnswering"),c(a4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a4,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Wd,"class","relative group"),c(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d4,"id","transformers.AutoModelForDocumentQuestionAnswering"),c(d4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d4,"href","#transformers.AutoModelForDocumentQuestionAnswering"),c(Jd,"class","relative group"),c(qY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),c(OY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(VY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p4,"id","transformers.AutoModelForImageClassification"),c(p4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p4,"href","#transformers.AutoModelForImageClassification"),c(ec,"class","relative group"),c(XY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WY,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),c(UY,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(HY,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),c(JY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(YY,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),c(KY,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(ZY,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(eK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),c(oK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(rK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(tK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(aK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(nK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(sK,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(lK,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(iK,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(dK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(cK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),c(mK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(fK,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),c(gK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),c(hK,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B4,"id","transformers.AutoModelForVideoClassification"),c(B4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B4,"href","#transformers.AutoModelForVideoClassification"),c(tc,"class","relative group"),c(uK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bK,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D4,"id","transformers.AutoModelForVision2Seq"),c(D4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D4,"href","#transformers.AutoModelForVision2Seq"),c(sc,"class","relative group"),c(vK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MK,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z4,"id","transformers.AutoModelForVisualQuestionAnswering"),c(z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z4,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(dc,"class","relative group"),c(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AK,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J4,"id","transformers.AutoModelForAudioClassification"),c(J4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J4,"href","#transformers.AutoModelForAudioClassification"),c(fc,"class","relative group"),c(LK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($K,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(kK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(SK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(RK,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(PK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(BK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(IK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(NK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(qK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dC,"id","transformers.AutoModelForAudioFrameClassification"),c(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dC,"href","#transformers.AutoModelForAudioFrameClassification"),c(uc,"class","relative group"),c(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(VK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(XK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(zK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(QK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bC,"id","transformers.AutoModelForCTC"),c(bC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bC,"href","#transformers.AutoModelForCTC"),c(bc,"class","relative group"),c(WK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(YK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),c(KK,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),c(ZK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),c(eZ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),c(oZ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(rZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(tZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(aZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(nZ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SC,"id","transformers.AutoModelForSpeechSeq2Seq"),c(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SC,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Tc,"class","relative group"),c(sZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dZ,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(cZ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qC,"id","transformers.AutoModelForAudioXVector"),c(qC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qC,"href","#transformers.AutoModelForAudioXVector"),c(Cc,"class","relative group"),c(mZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(uZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(pZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(_Z,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(bZ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WC,"id","transformers.AutoModelForMaskedImageModeling"),c(WC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WC,"href","#transformers.AutoModelForMaskedImageModeling"),c(Lc,"class","relative group"),c(vZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(EZ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(CZ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(wZ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o3,"id","transformers.AutoModelForObjectDetection"),c(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o3,"href","#transformers.AutoModelForObjectDetection"),c($c,"class","relative group"),c(AZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xZ,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),c($Z,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),c(kZ,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),c(SZ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d3,"id","transformers.AutoModelForImageSegmentation"),c(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d3,"href","#transformers.AutoModelForImageSegmentation"),c(Rc,"class","relative group"),c(RZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IZ,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),c(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h3,"id","transformers.AutoModelForSemanticSegmentation"),c(h3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h3,"href","#transformers.AutoModelForSemanticSegmentation"),c(Ic,"class","relative group"),c(NZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DZ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(GZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(OZ,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(VZ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(XZ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E3,"id","transformers.AutoModelForInstanceSegmentation"),c(E3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E3,"href","#transformers.AutoModelForInstanceSegmentation"),c(jc,"class","relative group"),c(zZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UZ,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y3,"id","transformers.TFAutoModel"),c(y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y3,"href","#transformers.TFAutoModel"),c(Oc,"class","relative group"),c(HZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),c(ZZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),c(eee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),c(oee,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(ree,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(tee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),c(aee,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),c(nee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),c(see,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),c(lee,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),c(iee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(dee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),c(cee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(mee,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),c(fee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(gee,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(hee,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),c(uee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(pee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),c(_ee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(bee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),c(vee,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),c(Fee,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),c(Tee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),c(Mee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(Eee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),c(Cee,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),c(wee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),c(Aee,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Lee,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),c(yee,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),c(xee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c($ee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),c(kee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),c(See,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),c(Ree,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Pee,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),c(Bee,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),c(Iee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),c(Nee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),c(qee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),c(jee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),c(Dee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),c(Gee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),c(Oee,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(Vee,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),c(Xee,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),c(zee,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),c(Qee,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(Wee,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),c(Uee,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(Hee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(Jee,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),c(Yee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),c(Kee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(Zee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k5,"id","transformers.TFAutoModelForPreTraining"),c(k5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k5,"href","#transformers.TFAutoModelForPreTraining"),c(zc,"class","relative group"),c(eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(toe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(aoe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(noe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),c(soe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(loe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(ioe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(doe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(coe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(moe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(foe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(goe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(hoe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(uoe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(poe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(_oe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(boe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(voe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Foe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(Toe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Moe,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(Eoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Coe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(woe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t0,"id","transformers.TFAutoModelForCausalLM"),c(t0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t0,"href","#transformers.TFAutoModelForCausalLM"),c(Uc,"class","relative group"),c(Aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xoe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),c($oe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(koe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(Soe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(Roe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(Poe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(Boe,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(Ioe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(Noe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(qoe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(joe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(Doe,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),c(Goe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(Ooe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F0,"id","transformers.TFAutoModelForImageClassification"),c(F0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F0,"href","#transformers.TFAutoModelForImageClassification"),c(Yc,"class","relative group"),c(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qoe,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(Woe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(Uoe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(Hoe,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(Joe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),c(Yoe,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(Koe,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(Zoe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(ere,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(ore,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k0,"id","transformers.TFAutoModelForSemanticSegmentation"),c(k0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k0,"href","#transformers.TFAutoModelForSemanticSegmentation"),c(em,"class","relative group"),c(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),c(sre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),c(lre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N0,"id","transformers.TFAutoModelForMaskedLM"),c(N0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N0,"href","#transformers.TFAutoModelForMaskedLM"),c(am,"class","relative group"),c(ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(fre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(gre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(hre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(ure,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(pre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(_re,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(bre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(vre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(Fre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(Tre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(Mre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(Ere,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(Cre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(wre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(Are,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(Lre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(yre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(xre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c($re,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sw,"id","transformers.TFAutoModelForSeq2SeqLM"),c(sw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sw,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(lm,"class","relative group"),c(kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(Bre,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(Ire,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(Nre,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(qre,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(jre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),c(Dre,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(Gre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(Ore,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(Vre,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vw,"id","transformers.TFAutoModelForSequenceClassification"),c(vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vw,"href","#transformers.TFAutoModelForSequenceClassification"),c(cm,"class","relative group"),c(Xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(Ure,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(Hre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(Jre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(Yre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(Kre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(Zre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(ete,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(ote,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(rte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(tte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(ate,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(nte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(ste,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(lte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),c(ite,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(dte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(cte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(mte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(fte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(gte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(hte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(ute,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(pte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(_te,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(bte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(vte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hw,"id","transformers.TFAutoModelForMultipleChoice"),c(Hw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hw,"href","#transformers.TFAutoModelForMultipleChoice"),c(gm,"class","relative group"),c(Fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ete,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(Cte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(wte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(Ate,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(Lte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(yte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(xte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c($te,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(kte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(Ste,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(Rte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(Pte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(Bte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(Ite,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(Nte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(qte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(jte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uA,"id","transformers.TFAutoModelForNextSentencePrediction"),c(uA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uA,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(pm,"class","relative group"),c(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ote,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(Xte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FA,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(FA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FA,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(vm,"class","relative group"),c(zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ute,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CA,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),c(CA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CA,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),c(Mm,"class","relative group"),c(Hte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yA,"id","transformers.TFAutoModelForTokenClassification"),c(yA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yA,"href","#transformers.TFAutoModelForTokenClassification"),c(wm,"class","relative group"),c(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(tae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(aae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(nae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(sae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(lae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(iae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(dae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(cae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(mae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(fae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(gae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),c(hae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(uae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(pae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(_ae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(bae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(vae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Fae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(Tae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(Mae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KA,"id","transformers.TFAutoModelForQuestionAnswering"),c(KA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KA,"href","#transformers.TFAutoModelForQuestionAnswering"),c(ym,"class","relative group"),c(Eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Lae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(yae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(xae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c($ae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(kae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Sae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Rae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(Pae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(Bae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(Iae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(Nae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),c(qae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(jae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(Dae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(Gae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(Oae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(Vae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(Xae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(zae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(Qae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M6,"id","transformers.TFAutoModelForVision2Seq"),c(M6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M6,"href","#transformers.TFAutoModelForVision2Seq"),c(km,"class","relative group"),c(Wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jae,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(A6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Pm,"class","relative group"),c(Yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ene,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($6,"id","transformers.FlaxAutoModel"),c($6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($6,"href","#transformers.FlaxAutoModel"),c(Nm,"class","relative group"),c(one,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ane,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),c(nne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),c(sne,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),c(lne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),c(ine,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(dne,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(cne,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(mne,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),c(fne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(gne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),c(hne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(une,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(pne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(_ne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(bne,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),c(vne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Fne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),c(Tne,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),c(Mne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Ene,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Cne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(wne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),c(Ane,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Lne,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),c(yne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(xne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),c($ne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s7,"id","transformers.FlaxAutoModelForCausalLM"),c(s7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s7,"href","#transformers.FlaxAutoModelForCausalLM"),c(Dm,"class","relative group"),c(kne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Sne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(Bne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(Ine,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Nne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(qne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(jne,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Dne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Gne,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(One,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Vne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v7,"id","transformers.FlaxAutoModelForPreTraining"),c(v7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v7,"href","#transformers.FlaxAutoModelForPreTraining"),c(Vm,"class","relative group"),c(Xne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wne,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(Une,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Hne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(Jne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(Yne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(Kne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Zne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(ese,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ose,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(rse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(tse,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(ase,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(nse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B7,"id","transformers.FlaxAutoModelForMaskedLM"),c(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B7,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Qm,"class","relative group"),c(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ise,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(cse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(mse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(fse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(gse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(hse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(use,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(pse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(_se,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(bse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U7,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(U7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U7,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Hm,"class","relative group"),c(vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Ese,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Cse,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(wse,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Ase,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Lse,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(yse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(xse,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c($se,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(kse,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lL,"id","transformers.FlaxAutoModelForSequenceClassification"),c(lL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lL,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Km,"class","relative group"),c(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Ise,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Nse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(qse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(jse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Dse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Gse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Ose,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Vse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Xse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FL,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(FL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(of,"class","relative group"),c(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Use,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(Hse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(Jse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Yse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Kse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Zse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(ele,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(ole,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(rle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(tle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RL,"id","transformers.FlaxAutoModelForTokenClassification"),c(RL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RL,"href","#transformers.FlaxAutoModelForTokenClassification"),c(af,"class","relative group"),c(ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(ile,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(dle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(cle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(mle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(fle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(gle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(hle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XL,"id","transformers.FlaxAutoModelForMultipleChoice"),c(XL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XL,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(lf,"class","relative group"),c(ule,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ble,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(vle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Fle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Tle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Mle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Ele,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Cle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(wle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(oy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(mf,"class","relative group"),c(Ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ny,"id","transformers.FlaxAutoModelForImageClassification"),c(ny,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ny,"href","#transformers.FlaxAutoModelForImageClassification"),c(hf,"class","relative group"),c($le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rle,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Ple,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cy,"id","transformers.FlaxAutoModelForVision2Seq"),c(cy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cy,"href","#transformers.FlaxAutoModelForVision2Seq"),c(_f,"class","relative group"),c(Ble,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ile,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(m,_){e(document.head,g),b(m,v,_),b(m,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,yo),e(yo,td),b(m,Ef,_),b(m,pt,_),e(pt,ad),e(pt,nd),e(nd,X9),e(pt,Cf),b(m,Ve,_),b(m,He,_),e(He,sd),e(He,es),e(es,z9),e(He,os),e(He,rs),e(rs,Q9),e(He,ld),e(He,ts),e(ts,W9),e(He,id),b(m,wf,_),M(Qa,m,_),b(m,Je,_),b(m,Ae,_),e(Ae,UB),e(Ae,dd),e(dd,HB),e(Ae,JB),b(m,xo,_),b(m,Wa,_),e(Wa,YB),e(Wa,Af),e(Af,KB),e(Wa,Qto),b(m,pZe,_),b(m,cd,_),e(cd,Lf),e(Lf,Ode),M(U9,Ode,null),e(cd,Wto),e(cd,Vde),e(Vde,Uto),b(m,_Ze,_),b(m,as,_),e(as,Hto),e(as,Xde),e(Xde,Jto),e(as,Yto),e(as,zde),e(zde,Kto),e(as,Zto),b(m,bZe,_),M(H9,m,_),b(m,vZe,_),b(m,ZB,_),e(ZB,eao),b(m,FZe,_),M(yf,m,_),b(m,TZe,_),b(m,md,_),e(md,xf),e(xf,Qde),M(J9,Qde,null),e(md,oao),e(md,Wde),e(Wde,rao),b(m,MZe,_),b(m,$o,_),M(Y9,$o,null),e($o,tao),e($o,K9),e(K9,aao),e(K9,eI),e(eI,nao),e(K9,sao),e($o,lao),e($o,Z9),e(Z9,iao),e(Z9,Ude),e(Ude,dao),e(Z9,cao),e($o,mao),e($o,Pr),M(ex,Pr,null),e(Pr,fao),e(Pr,Hde),e(Hde,gao),e(Pr,hao),e(Pr,fd),e(fd,uao),e(fd,Jde),e(Jde,pao),e(fd,_ao),e(fd,Yde),e(Yde,bao),e(fd,vao),e(Pr,Fao),e(Pr,A),e(A,$f),e($f,Kde),e(Kde,Tao),e($f,Mao),e($f,oI),e(oI,Eao),e($f,Cao),e(A,wao),e(A,kf),e(kf,Zde),e(Zde,Aao),e(kf,Lao),e(kf,rI),e(rI,yao),e(kf,xao),e(A,$ao),e(A,Sf),e(Sf,ece),e(ece,kao),e(Sf,Sao),e(Sf,tI),e(tI,Rao),e(Sf,Pao),e(A,Bao),e(A,Rf),e(Rf,oce),e(oce,Iao),e(Rf,Nao),e(Rf,aI),e(aI,qao),e(Rf,jao),e(A,Dao),e(A,Pf),e(Pf,rce),e(rce,Gao),e(Pf,Oao),e(Pf,nI),e(nI,Vao),e(Pf,Xao),e(A,zao),e(A,Bf),e(Bf,tce),e(tce,Qao),e(Bf,Wao),e(Bf,sI),e(sI,Uao),e(Bf,Hao),e(A,Jao),e(A,If),e(If,ace),e(ace,Yao),e(If,Kao),e(If,lI),e(lI,Zao),e(If,eno),e(A,ono),e(A,Nf),e(Nf,nce),e(nce,rno),e(Nf,tno),e(Nf,iI),e(iI,ano),e(Nf,nno),e(A,sno),e(A,qf),e(qf,sce),e(sce,lno),e(qf,ino),e(qf,dI),e(dI,dno),e(qf,cno),e(A,mno),e(A,jf),e(jf,lce),e(lce,fno),e(jf,gno),e(jf,cI),e(cI,hno),e(jf,uno),e(A,pno),e(A,Df),e(Df,ice),e(ice,_no),e(Df,bno),e(Df,mI),e(mI,vno),e(Df,Fno),e(A,Tno),e(A,Gf),e(Gf,dce),e(dce,Mno),e(Gf,Eno),e(Gf,fI),e(fI,Cno),e(Gf,wno),e(A,Ano),e(A,Of),e(Of,cce),e(cce,Lno),e(Of,yno),e(Of,gI),e(gI,xno),e(Of,$no),e(A,kno),e(A,Vf),e(Vf,mce),e(mce,Sno),e(Vf,Rno),e(Vf,hI),e(hI,Pno),e(Vf,Bno),e(A,Ino),e(A,Xf),e(Xf,fce),e(fce,Nno),e(Xf,qno),e(Xf,uI),e(uI,jno),e(Xf,Dno),e(A,Gno),e(A,zf),e(zf,gce),e(gce,Ono),e(zf,Vno),e(zf,pI),e(pI,Xno),e(zf,zno),e(A,Qno),e(A,Qf),e(Qf,hce),e(hce,Wno),e(Qf,Uno),e(Qf,_I),e(_I,Hno),e(Qf,Jno),e(A,Yno),e(A,Wf),e(Wf,uce),e(uce,Kno),e(Wf,Zno),e(Wf,bI),e(bI,eso),e(Wf,oso),e(A,rso),e(A,Uf),e(Uf,pce),e(pce,tso),e(Uf,aso),e(Uf,vI),e(vI,nso),e(Uf,sso),e(A,lso),e(A,Hf),e(Hf,_ce),e(_ce,iso),e(Hf,dso),e(Hf,FI),e(FI,cso),e(Hf,mso),e(A,fso),e(A,Jf),e(Jf,bce),e(bce,gso),e(Jf,hso),e(Jf,TI),e(TI,uso),e(Jf,pso),e(A,_so),e(A,Yf),e(Yf,vce),e(vce,bso),e(Yf,vso),e(Yf,MI),e(MI,Fso),e(Yf,Tso),e(A,Mso),e(A,Kf),e(Kf,Fce),e(Fce,Eso),e(Kf,Cso),e(Kf,EI),e(EI,wso),e(Kf,Aso),e(A,Lso),e(A,Zf),e(Zf,Tce),e(Tce,yso),e(Zf,xso),e(Zf,CI),e(CI,$so),e(Zf,kso),e(A,Sso),e(A,eg),e(eg,Mce),e(Mce,Rso),e(eg,Pso),e(eg,wI),e(wI,Bso),e(eg,Iso),e(A,Nso),e(A,og),e(og,Ece),e(Ece,qso),e(og,jso),e(og,AI),e(AI,Dso),e(og,Gso),e(A,Oso),e(A,rg),e(rg,Cce),e(Cce,Vso),e(rg,Xso),e(rg,LI),e(LI,zso),e(rg,Qso),e(A,Wso),e(A,tg),e(tg,wce),e(wce,Uso),e(tg,Hso),e(tg,yI),e(yI,Jso),e(tg,Yso),e(A,Kso),e(A,ag),e(ag,Ace),e(Ace,Zso),e(ag,elo),e(ag,xI),e(xI,olo),e(ag,rlo),e(A,tlo),e(A,ng),e(ng,Lce),e(Lce,alo),e(ng,nlo),e(ng,$I),e($I,slo),e(ng,llo),e(A,ilo),e(A,sg),e(sg,yce),e(yce,dlo),e(sg,clo),e(sg,kI),e(kI,mlo),e(sg,flo),e(A,glo),e(A,lg),e(lg,xce),e(xce,hlo),e(lg,ulo),e(lg,SI),e(SI,plo),e(lg,_lo),e(A,blo),e(A,ig),e(ig,$ce),e($ce,vlo),e(ig,Flo),e(ig,RI),e(RI,Tlo),e(ig,Mlo),e(A,Elo),e(A,dg),e(dg,kce),e(kce,Clo),e(dg,wlo),e(dg,PI),e(PI,Alo),e(dg,Llo),e(A,ylo),e(A,cg),e(cg,Sce),e(Sce,xlo),e(cg,$lo),e(cg,BI),e(BI,klo),e(cg,Slo),e(A,Rlo),e(A,mg),e(mg,Rce),e(Rce,Plo),e(mg,Blo),e(mg,II),e(II,Ilo),e(mg,Nlo),e(A,qlo),e(A,fg),e(fg,Pce),e(Pce,jlo),e(fg,Dlo),e(fg,NI),e(NI,Glo),e(fg,Olo),e(A,Vlo),e(A,gg),e(gg,Bce),e(Bce,Xlo),e(gg,zlo),e(gg,qI),e(qI,Qlo),e(gg,Wlo),e(A,Ulo),e(A,hg),e(hg,Ice),e(Ice,Hlo),e(hg,Jlo),e(hg,jI),e(jI,Ylo),e(hg,Klo),e(A,Zlo),e(A,ug),e(ug,Nce),e(Nce,eio),e(ug,oio),e(ug,DI),e(DI,rio),e(ug,tio),e(A,aio),e(A,pg),e(pg,qce),e(qce,nio),e(pg,sio),e(pg,GI),e(GI,lio),e(pg,iio),e(A,dio),e(A,_g),e(_g,jce),e(jce,cio),e(_g,mio),e(_g,OI),e(OI,fio),e(_g,gio),e(A,hio),e(A,bg),e(bg,Dce),e(Dce,uio),e(bg,pio),e(bg,VI),e(VI,_io),e(bg,bio),e(A,vio),e(A,vg),e(vg,Gce),e(Gce,Fio),e(vg,Tio),e(vg,XI),e(XI,Mio),e(vg,Eio),e(A,Cio),e(A,Fg),e(Fg,Oce),e(Oce,wio),e(Fg,Aio),e(Fg,zI),e(zI,Lio),e(Fg,yio),e(A,xio),e(A,Tg),e(Tg,Vce),e(Vce,$io),e(Tg,kio),e(Tg,QI),e(QI,Sio),e(Tg,Rio),e(A,Pio),e(A,Mg),e(Mg,Xce),e(Xce,Bio),e(Mg,Iio),e(Mg,WI),e(WI,Nio),e(Mg,qio),e(A,jio),e(A,Eg),e(Eg,zce),e(zce,Dio),e(Eg,Gio),e(Eg,UI),e(UI,Oio),e(Eg,Vio),e(A,Xio),e(A,Cg),e(Cg,Qce),e(Qce,zio),e(Cg,Qio),e(Cg,HI),e(HI,Wio),e(Cg,Uio),e(A,Hio),e(A,wg),e(wg,Wce),e(Wce,Jio),e(wg,Yio),e(wg,JI),e(JI,Kio),e(wg,Zio),e(A,edo),e(A,Ag),e(Ag,Uce),e(Uce,odo),e(Ag,rdo),e(Ag,YI),e(YI,tdo),e(Ag,ado),e(A,ndo),e(A,Lg),e(Lg,Hce),e(Hce,sdo),e(Lg,ldo),e(Lg,KI),e(KI,ido),e(Lg,ddo),e(A,cdo),e(A,yg),e(yg,Jce),e(Jce,mdo),e(yg,fdo),e(yg,ZI),e(ZI,gdo),e(yg,hdo),e(A,udo),e(A,xg),e(xg,Yce),e(Yce,pdo),e(xg,_do),e(xg,eN),e(eN,bdo),e(xg,vdo),e(A,Fdo),e(A,$g),e($g,Kce),e(Kce,Tdo),e($g,Mdo),e($g,oN),e(oN,Edo),e($g,Cdo),e(A,wdo),e(A,kg),e(kg,Zce),e(Zce,Ado),e(kg,Ldo),e(kg,rN),e(rN,ydo),e(kg,xdo),e(A,$do),e(A,Sg),e(Sg,eme),e(eme,kdo),e(Sg,Sdo),e(Sg,tN),e(tN,Rdo),e(Sg,Pdo),e(A,Bdo),e(A,Rg),e(Rg,ome),e(ome,Ido),e(Rg,Ndo),e(Rg,aN),e(aN,qdo),e(Rg,jdo),e(A,Ddo),e(A,Pg),e(Pg,rme),e(rme,Gdo),e(Pg,Odo),e(Pg,nN),e(nN,Vdo),e(Pg,Xdo),e(A,zdo),e(A,Bg),e(Bg,tme),e(tme,Qdo),e(Bg,Wdo),e(Bg,sN),e(sN,Udo),e(Bg,Hdo),e(A,Jdo),e(A,Ig),e(Ig,ame),e(ame,Ydo),e(Ig,Kdo),e(Ig,lN),e(lN,Zdo),e(Ig,eco),e(A,oco),e(A,Ng),e(Ng,nme),e(nme,rco),e(Ng,tco),e(Ng,iN),e(iN,aco),e(Ng,nco),e(A,sco),e(A,qg),e(qg,sme),e(sme,lco),e(qg,ico),e(qg,dN),e(dN,dco),e(qg,cco),e(A,mco),e(A,jg),e(jg,lme),e(lme,fco),e(jg,gco),e(jg,cN),e(cN,hco),e(jg,uco),e(A,pco),e(A,Dg),e(Dg,ime),e(ime,_co),e(Dg,bco),e(Dg,mN),e(mN,vco),e(Dg,Fco),e(A,Tco),e(A,Gg),e(Gg,dme),e(dme,Mco),e(Gg,Eco),e(Gg,fN),e(fN,Cco),e(Gg,wco),e(A,Aco),e(A,Og),e(Og,cme),e(cme,Lco),e(Og,yco),e(Og,gN),e(gN,xco),e(Og,$co),e(A,kco),e(A,Vg),e(Vg,mme),e(mme,Sco),e(Vg,Rco),e(Vg,hN),e(hN,Pco),e(Vg,Bco),e(A,Ico),e(A,Xg),e(Xg,fme),e(fme,Nco),e(Xg,qco),e(Xg,uN),e(uN,jco),e(Xg,Dco),e(A,Gco),e(A,zg),e(zg,gme),e(gme,Oco),e(zg,Vco),e(zg,pN),e(pN,Xco),e(zg,zco),e(A,Qco),e(A,Qg),e(Qg,hme),e(hme,Wco),e(Qg,Uco),e(Qg,_N),e(_N,Hco),e(Qg,Jco),e(A,Yco),e(A,Wg),e(Wg,ume),e(ume,Kco),e(Wg,Zco),e(Wg,bN),e(bN,emo),e(Wg,omo),e(A,rmo),e(A,Ug),e(Ug,pme),e(pme,tmo),e(Ug,amo),e(Ug,vN),e(vN,nmo),e(Ug,smo),e(A,lmo),e(A,Hg),e(Hg,_me),e(_me,imo),e(Hg,dmo),e(Hg,FN),e(FN,cmo),e(Hg,mmo),e(A,fmo),e(A,Jg),e(Jg,bme),e(bme,gmo),e(Jg,hmo),e(Jg,TN),e(TN,umo),e(Jg,pmo),e(A,_mo),e(A,Yg),e(Yg,vme),e(vme,bmo),e(Yg,vmo),e(Yg,MN),e(MN,Fmo),e(Yg,Tmo),e(A,Mmo),e(A,Kg),e(Kg,Fme),e(Fme,Emo),e(Kg,Cmo),e(Kg,EN),e(EN,wmo),e(Kg,Amo),e(A,Lmo),e(A,Zg),e(Zg,Tme),e(Tme,ymo),e(Zg,xmo),e(Zg,CN),e(CN,$mo),e(Zg,kmo),e(A,Smo),e(A,eh),e(eh,Mme),e(Mme,Rmo),e(eh,Pmo),e(eh,wN),e(wN,Bmo),e(eh,Imo),e(A,Nmo),e(A,oh),e(oh,Eme),e(Eme,qmo),e(oh,jmo),e(oh,AN),e(AN,Dmo),e(oh,Gmo),e(A,Omo),e(A,rh),e(rh,Cme),e(Cme,Vmo),e(rh,Xmo),e(rh,LN),e(LN,zmo),e(rh,Qmo),e(A,Wmo),e(A,th),e(th,wme),e(wme,Umo),e(th,Hmo),e(th,yN),e(yN,Jmo),e(th,Ymo),e(A,Kmo),e(A,ah),e(ah,Ame),e(Ame,Zmo),e(ah,efo),e(ah,xN),e(xN,ofo),e(ah,rfo),e(A,tfo),e(A,nh),e(nh,Lme),e(Lme,afo),e(nh,nfo),e(nh,$N),e($N,sfo),e(nh,lfo),e(A,ifo),e(A,sh),e(sh,yme),e(yme,dfo),e(sh,cfo),e(sh,kN),e(kN,mfo),e(sh,ffo),e(A,gfo),e(A,lh),e(lh,xme),e(xme,hfo),e(lh,ufo),e(lh,SN),e(SN,pfo),e(lh,_fo),e(A,bfo),e(A,ih),e(ih,$me),e($me,vfo),e(ih,Ffo),e(ih,RN),e(RN,Tfo),e(ih,Mfo),e(A,Efo),e(A,dh),e(dh,kme),e(kme,Cfo),e(dh,wfo),e(dh,PN),e(PN,Afo),e(dh,Lfo),e(A,yfo),e(A,ch),e(ch,Sme),e(Sme,xfo),e(ch,$fo),e(ch,BN),e(BN,kfo),e(ch,Sfo),e(A,Rfo),e(A,mh),e(mh,Rme),e(Rme,Pfo),e(mh,Bfo),e(mh,IN),e(IN,Ifo),e(mh,Nfo),e(A,qfo),e(A,fh),e(fh,Pme),e(Pme,jfo),e(fh,Dfo),e(fh,NN),e(NN,Gfo),e(fh,Ofo),e(A,Vfo),e(A,gh),e(gh,Bme),e(Bme,Xfo),e(gh,zfo),e(gh,qN),e(qN,Qfo),e(gh,Wfo),e(A,Ufo),e(A,hh),e(hh,Ime),e(Ime,Hfo),e(hh,Jfo),e(hh,jN),e(jN,Yfo),e(hh,Kfo),e(A,Zfo),e(A,uh),e(uh,Nme),e(Nme,ego),e(uh,ogo),e(uh,DN),e(DN,rgo),e(uh,tgo),e(A,ago),e(A,ph),e(ph,qme),e(qme,ngo),e(ph,sgo),e(ph,GN),e(GN,lgo),e(ph,igo),e(A,dgo),e(A,_h),e(_h,jme),e(jme,cgo),e(_h,mgo),e(_h,ON),e(ON,fgo),e(_h,ggo),e(A,hgo),e(A,bh),e(bh,Dme),e(Dme,ugo),e(bh,pgo),e(bh,VN),e(VN,_go),e(bh,bgo),e(A,vgo),e(A,vh),e(vh,Gme),e(Gme,Fgo),e(vh,Tgo),e(vh,XN),e(XN,Mgo),e(vh,Ego),e(A,Cgo),e(A,Fh),e(Fh,Ome),e(Ome,wgo),e(Fh,Ago),e(Fh,zN),e(zN,Lgo),e(Fh,ygo),e(A,xgo),e(A,Th),e(Th,Vme),e(Vme,$go),e(Th,kgo),e(Th,QN),e(QN,Sgo),e(Th,Rgo),e(A,Pgo),e(A,Mh),e(Mh,Xme),e(Xme,Bgo),e(Mh,Igo),e(Mh,WN),e(WN,Ngo),e(Mh,qgo),e(A,jgo),e(A,Eh),e(Eh,zme),e(zme,Dgo),e(Eh,Ggo),e(Eh,UN),e(UN,Ogo),e(Eh,Vgo),e(A,Xgo),e(A,Ch),e(Ch,Qme),e(Qme,zgo),e(Ch,Qgo),e(Ch,HN),e(HN,Wgo),e(Ch,Ugo),e(A,Hgo),e(A,wh),e(wh,Wme),e(Wme,Jgo),e(wh,Ygo),e(wh,JN),e(JN,Kgo),e(wh,Zgo),e(A,eho),e(A,Ah),e(Ah,Ume),e(Ume,oho),e(Ah,rho),e(Ah,YN),e(YN,tho),e(Ah,aho),e(A,nho),e(A,Lh),e(Lh,Hme),e(Hme,sho),e(Lh,lho),e(Lh,KN),e(KN,iho),e(Lh,dho),e(A,cho),e(A,yh),e(yh,Jme),e(Jme,mho),e(yh,fho),e(yh,ZN),e(ZN,gho),e(yh,hho),e(A,uho),e(A,xh),e(xh,Yme),e(Yme,pho),e(xh,_ho),e(xh,eq),e(eq,bho),e(xh,vho),e(A,Fho),e(A,$h),e($h,Kme),e(Kme,Tho),e($h,Mho),e($h,oq),e(oq,Eho),e($h,Cho),e(A,who),e(A,kh),e(kh,Zme),e(Zme,Aho),e(kh,Lho),e(kh,rq),e(rq,yho),e(kh,xho),e(A,$ho),e(A,Sh),e(Sh,efe),e(efe,kho),e(Sh,Sho),e(Sh,tq),e(tq,Rho),e(Sh,Pho),e(A,Bho),e(A,Rh),e(Rh,ofe),e(ofe,Iho),e(Rh,Nho),e(Rh,aq),e(aq,qho),e(Rh,jho),e(A,Dho),e(A,Ph),e(Ph,rfe),e(rfe,Gho),e(Ph,Oho),e(Ph,nq),e(nq,Vho),e(Ph,Xho),e(A,zho),e(A,Bh),e(Bh,tfe),e(tfe,Qho),e(Bh,Who),e(Bh,sq),e(sq,Uho),e(Bh,Hho),e(A,Jho),e(A,Ih),e(Ih,afe),e(afe,Yho),e(Ih,Kho),e(Ih,lq),e(lq,Zho),e(Ih,euo),e(A,ouo),e(A,Nh),e(Nh,nfe),e(nfe,ruo),e(Nh,tuo),e(Nh,iq),e(iq,auo),e(Nh,nuo),e(A,suo),e(A,qh),e(qh,sfe),e(sfe,luo),e(qh,iuo),e(qh,dq),e(dq,duo),e(qh,cuo),e(A,muo),e(A,jh),e(jh,lfe),e(lfe,fuo),e(jh,guo),e(jh,cq),e(cq,huo),e(jh,uuo),e(A,puo),e(A,Dh),e(Dh,ife),e(ife,_uo),e(Dh,buo),e(Dh,mq),e(mq,vuo),e(Dh,Fuo),e(A,Tuo),e(A,Gh),e(Gh,dfe),e(dfe,Muo),e(Gh,Euo),e(Gh,fq),e(fq,Cuo),e(Gh,wuo),e(A,Auo),e(A,Oh),e(Oh,cfe),e(cfe,Luo),e(Oh,yuo),e(Oh,gq),e(gq,xuo),e(Oh,$uo),e(A,kuo),e(A,Vh),e(Vh,mfe),e(mfe,Suo),e(Vh,Ruo),e(Vh,hq),e(hq,Puo),e(Vh,Buo),e(A,Iuo),e(A,Xh),e(Xh,ffe),e(ffe,Nuo),e(Xh,quo),e(Xh,uq),e(uq,juo),e(Xh,Duo),e(A,Guo),e(A,zh),e(zh,gfe),e(gfe,Ouo),e(zh,Vuo),e(zh,pq),e(pq,Xuo),e(zh,zuo),e(A,Quo),e(A,Qh),e(Qh,hfe),e(hfe,Wuo),e(Qh,Uuo),e(Qh,_q),e(_q,Huo),e(Qh,Juo),e(A,Yuo),e(A,Wh),e(Wh,ufe),e(ufe,Kuo),e(Wh,Zuo),e(Wh,bq),e(bq,epo),e(Wh,opo),e(A,rpo),e(A,Uh),e(Uh,pfe),e(pfe,tpo),e(Uh,apo),e(Uh,vq),e(vq,npo),e(Uh,spo),e(A,lpo),e(A,Hh),e(Hh,_fe),e(_fe,ipo),e(Hh,dpo),e(Hh,Fq),e(Fq,cpo),e(Hh,mpo),e(A,fpo),e(A,Jh),e(Jh,bfe),e(bfe,gpo),e(Jh,hpo),e(Jh,Tq),e(Tq,upo),e(Jh,ppo),e(A,_po),e(A,Yh),e(Yh,vfe),e(vfe,bpo),e(Yh,vpo),e(Yh,Mq),e(Mq,Fpo),e(Yh,Tpo),e(Pr,Mpo),M(Kh,Pr,null),e($o,Epo),e($o,Zh),M(ox,Zh,null),e(Zh,Cpo),e(Zh,Ffe),e(Ffe,wpo),b(m,EZe,_),b(m,gd,_),e(gd,eu),e(eu,Tfe),M(rx,Tfe,null),e(gd,Apo),e(gd,Mfe),e(Mfe,Lpo),b(m,CZe,_),b(m,ko,_),M(tx,ko,null),e(ko,ypo),e(ko,ax),e(ax,xpo),e(ax,Eq),e(Eq,$po),e(ax,kpo),e(ko,Spo),e(ko,nx),e(nx,Rpo),e(nx,Efe),e(Efe,Ppo),e(nx,Bpo),e(ko,Ipo),e(ko,Br),M(sx,Br,null),e(Br,Npo),e(Br,Cfe),e(Cfe,qpo),e(Br,jpo),e(Br,Ua),e(Ua,Dpo),e(Ua,wfe),e(wfe,Gpo),e(Ua,Opo),e(Ua,Afe),e(Afe,Vpo),e(Ua,Xpo),e(Ua,Lfe),e(Lfe,zpo),e(Ua,Qpo),e(Br,Wpo),e(Br,k),e(k,ns),e(ns,yfe),e(yfe,Upo),e(ns,Hpo),e(ns,Cq),e(Cq,Jpo),e(ns,Ypo),e(ns,wq),e(wq,Kpo),e(ns,Zpo),e(k,e_o),e(k,ss),e(ss,xfe),e(xfe,o_o),e(ss,r_o),e(ss,Aq),e(Aq,t_o),e(ss,a_o),e(ss,Lq),e(Lq,n_o),e(ss,s_o),e(k,l_o),e(k,ls),e(ls,$fe),e($fe,i_o),e(ls,d_o),e(ls,yq),e(yq,c_o),e(ls,m_o),e(ls,xq),e(xq,f_o),e(ls,g_o),e(k,h_o),e(k,ou),e(ou,kfe),e(kfe,u_o),e(ou,p_o),e(ou,$q),e($q,__o),e(ou,b_o),e(k,v_o),e(k,is),e(is,Sfe),e(Sfe,F_o),e(is,T_o),e(is,kq),e(kq,M_o),e(is,E_o),e(is,Sq),e(Sq,C_o),e(is,w_o),e(k,A_o),e(k,ru),e(ru,Rfe),e(Rfe,L_o),e(ru,y_o),e(ru,Rq),e(Rq,x_o),e(ru,$_o),e(k,k_o),e(k,tu),e(tu,Pfe),e(Pfe,S_o),e(tu,R_o),e(tu,Pq),e(Pq,P_o),e(tu,B_o),e(k,I_o),e(k,au),e(au,Bfe),e(Bfe,N_o),e(au,q_o),e(au,Bq),e(Bq,j_o),e(au,D_o),e(k,G_o),e(k,ds),e(ds,Ife),e(Ife,O_o),e(ds,V_o),e(ds,Iq),e(Iq,X_o),e(ds,z_o),e(ds,Nq),e(Nq,Q_o),e(ds,W_o),e(k,U_o),e(k,cs),e(cs,Nfe),e(Nfe,H_o),e(cs,J_o),e(cs,qq),e(qq,Y_o),e(cs,K_o),e(cs,jq),e(jq,Z_o),e(cs,e2o),e(k,o2o),e(k,ms),e(ms,qfe),e(qfe,r2o),e(ms,t2o),e(ms,Dq),e(Dq,a2o),e(ms,n2o),e(ms,Gq),e(Gq,s2o),e(ms,l2o),e(k,i2o),e(k,nu),e(nu,jfe),e(jfe,d2o),e(nu,c2o),e(nu,Oq),e(Oq,m2o),e(nu,f2o),e(k,g2o),e(k,su),e(su,Dfe),e(Dfe,h2o),e(su,u2o),e(su,Vq),e(Vq,p2o),e(su,_2o),e(k,b2o),e(k,lu),e(lu,Gfe),e(Gfe,v2o),e(lu,F2o),e(lu,Xq),e(Xq,T2o),e(lu,M2o),e(k,E2o),e(k,fs),e(fs,Ofe),e(Ofe,C2o),e(fs,w2o),e(fs,zq),e(zq,A2o),e(fs,L2o),e(fs,Qq),e(Qq,y2o),e(fs,x2o),e(k,$2o),e(k,iu),e(iu,Vfe),e(Vfe,k2o),e(iu,S2o),e(iu,Wq),e(Wq,R2o),e(iu,P2o),e(k,B2o),e(k,gs),e(gs,Xfe),e(Xfe,I2o),e(gs,N2o),e(gs,Uq),e(Uq,q2o),e(gs,j2o),e(gs,Hq),e(Hq,D2o),e(gs,G2o),e(k,O2o),e(k,hs),e(hs,zfe),e(zfe,V2o),e(hs,X2o),e(hs,Jq),e(Jq,z2o),e(hs,Q2o),e(hs,Yq),e(Yq,W2o),e(hs,U2o),e(k,H2o),e(k,us),e(us,Qfe),e(Qfe,J2o),e(us,Y2o),e(us,Kq),e(Kq,K2o),e(us,Z2o),e(us,Zq),e(Zq,ebo),e(us,obo),e(k,rbo),e(k,ps),e(ps,Wfe),e(Wfe,tbo),e(ps,abo),e(ps,ej),e(ej,nbo),e(ps,sbo),e(ps,oj),e(oj,lbo),e(ps,ibo),e(k,dbo),e(k,du),e(du,Ufe),e(Ufe,cbo),e(du,mbo),e(du,rj),e(rj,fbo),e(du,gbo),e(k,hbo),e(k,_s),e(_s,Hfe),e(Hfe,ubo),e(_s,pbo),e(_s,tj),e(tj,_bo),e(_s,bbo),e(_s,aj),e(aj,vbo),e(_s,Fbo),e(k,Tbo),e(k,bs),e(bs,Jfe),e(Jfe,Mbo),e(bs,Ebo),e(bs,nj),e(nj,Cbo),e(bs,wbo),e(bs,sj),e(sj,Abo),e(bs,Lbo),e(k,ybo),e(k,vs),e(vs,Yfe),e(Yfe,xbo),e(vs,$bo),e(vs,lj),e(lj,kbo),e(vs,Sbo),e(vs,ij),e(ij,Rbo),e(vs,Pbo),e(k,Bbo),e(k,Fs),e(Fs,Kfe),e(Kfe,Ibo),e(Fs,Nbo),e(Fs,dj),e(dj,qbo),e(Fs,jbo),e(Fs,cj),e(cj,Dbo),e(Fs,Gbo),e(k,Obo),e(k,Ts),e(Ts,Zfe),e(Zfe,Vbo),e(Ts,Xbo),e(Ts,mj),e(mj,zbo),e(Ts,Qbo),e(Ts,fj),e(fj,Wbo),e(Ts,Ubo),e(k,Hbo),e(k,Ms),e(Ms,ege),e(ege,Jbo),e(Ms,Ybo),e(Ms,gj),e(gj,Kbo),e(Ms,Zbo),e(Ms,hj),e(hj,e1o),e(Ms,o1o),e(k,r1o),e(k,Es),e(Es,oge),e(oge,t1o),e(Es,a1o),e(Es,uj),e(uj,n1o),e(Es,s1o),e(Es,pj),e(pj,l1o),e(Es,i1o),e(k,d1o),e(k,cu),e(cu,rge),e(rge,c1o),e(cu,m1o),e(cu,_j),e(_j,f1o),e(cu,g1o),e(k,h1o),e(k,Cs),e(Cs,tge),e(tge,u1o),e(Cs,p1o),e(Cs,bj),e(bj,_1o),e(Cs,b1o),e(Cs,vj),e(vj,v1o),e(Cs,F1o),e(k,T1o),e(k,mu),e(mu,age),e(age,M1o),e(mu,E1o),e(mu,Fj),e(Fj,C1o),e(mu,w1o),e(k,A1o),e(k,ws),e(ws,nge),e(nge,L1o),e(ws,y1o),e(ws,Tj),e(Tj,x1o),e(ws,$1o),e(ws,Mj),e(Mj,k1o),e(ws,S1o),e(k,R1o),e(k,As),e(As,sge),e(sge,P1o),e(As,B1o),e(As,Ej),e(Ej,I1o),e(As,N1o),e(As,Cj),e(Cj,q1o),e(As,j1o),e(k,D1o),e(k,Ls),e(Ls,lge),e(lge,G1o),e(Ls,O1o),e(Ls,wj),e(wj,V1o),e(Ls,X1o),e(Ls,Aj),e(Aj,z1o),e(Ls,Q1o),e(k,W1o),e(k,fu),e(fu,ige),e(ige,U1o),e(fu,H1o),e(fu,Lj),e(Lj,J1o),e(fu,Y1o),e(k,K1o),e(k,gu),e(gu,dge),e(dge,Z1o),e(gu,evo),e(gu,yj),e(yj,ovo),e(gu,rvo),e(k,tvo),e(k,ys),e(ys,cge),e(cge,avo),e(ys,nvo),e(ys,xj),e(xj,svo),e(ys,lvo),e(ys,$j),e($j,ivo),e(ys,dvo),e(k,cvo),e(k,xs),e(xs,mge),e(mge,mvo),e(xs,fvo),e(xs,kj),e(kj,gvo),e(xs,hvo),e(xs,Sj),e(Sj,uvo),e(xs,pvo),e(k,_vo),e(k,$s),e($s,fge),e(fge,bvo),e($s,vvo),e($s,Rj),e(Rj,Fvo),e($s,Tvo),e($s,Pj),e(Pj,Mvo),e($s,Evo),e(k,Cvo),e(k,hu),e(hu,gge),e(gge,wvo),e(hu,Avo),e(hu,Bj),e(Bj,Lvo),e(hu,yvo),e(k,xvo),e(k,ks),e(ks,hge),e(hge,$vo),e(ks,kvo),e(ks,Ij),e(Ij,Svo),e(ks,Rvo),e(ks,Nj),e(Nj,Pvo),e(ks,Bvo),e(k,Ivo),e(k,Ss),e(Ss,uge),e(uge,Nvo),e(Ss,qvo),e(Ss,qj),e(qj,jvo),e(Ss,Dvo),e(Ss,jj),e(jj,Gvo),e(Ss,Ovo),e(k,Vvo),e(k,Rs),e(Rs,pge),e(pge,Xvo),e(Rs,zvo),e(Rs,Dj),e(Dj,Qvo),e(Rs,Wvo),e(Rs,Gj),e(Gj,Uvo),e(Rs,Hvo),e(k,Jvo),e(k,Ps),e(Ps,_ge),e(_ge,Yvo),e(Ps,Kvo),e(Ps,Oj),e(Oj,Zvo),e(Ps,eFo),e(Ps,Vj),e(Vj,oFo),e(Ps,rFo),e(k,tFo),e(k,Bs),e(Bs,bge),e(bge,aFo),e(Bs,nFo),e(Bs,Xj),e(Xj,sFo),e(Bs,lFo),e(Bs,zj),e(zj,iFo),e(Bs,dFo),e(k,cFo),e(k,Is),e(Is,vge),e(vge,mFo),e(Is,fFo),e(Is,Qj),e(Qj,gFo),e(Is,hFo),e(Is,Wj),e(Wj,uFo),e(Is,pFo),e(k,_Fo),e(k,Ns),e(Ns,Fge),e(Fge,bFo),e(Ns,vFo),e(Ns,Uj),e(Uj,FFo),e(Ns,TFo),e(Ns,Hj),e(Hj,MFo),e(Ns,EFo),e(k,CFo),e(k,qs),e(qs,Tge),e(Tge,wFo),e(qs,AFo),e(qs,Jj),e(Jj,LFo),e(qs,yFo),e(qs,Yj),e(Yj,xFo),e(qs,$Fo),e(k,kFo),e(k,uu),e(uu,Mge),e(Mge,SFo),e(uu,RFo),e(uu,Kj),e(Kj,PFo),e(uu,BFo),e(k,IFo),e(k,js),e(js,Ege),e(Ege,NFo),e(js,qFo),e(js,Zj),e(Zj,jFo),e(js,DFo),e(js,eD),e(eD,GFo),e(js,OFo),e(k,VFo),e(k,pu),e(pu,Cge),e(Cge,XFo),e(pu,zFo),e(pu,oD),e(oD,QFo),e(pu,WFo),e(k,UFo),e(k,_u),e(_u,wge),e(wge,HFo),e(_u,JFo),e(_u,rD),e(rD,YFo),e(_u,KFo),e(k,ZFo),e(k,Ds),e(Ds,Age),e(Age,eTo),e(Ds,oTo),e(Ds,tD),e(tD,rTo),e(Ds,tTo),e(Ds,aD),e(aD,aTo),e(Ds,nTo),e(k,sTo),e(k,Gs),e(Gs,Lge),e(Lge,lTo),e(Gs,iTo),e(Gs,nD),e(nD,dTo),e(Gs,cTo),e(Gs,sD),e(sD,mTo),e(Gs,fTo),e(k,gTo),e(k,Os),e(Os,yge),e(yge,hTo),e(Os,uTo),e(Os,lD),e(lD,pTo),e(Os,_To),e(Os,iD),e(iD,bTo),e(Os,vTo),e(k,FTo),e(k,bu),e(bu,xge),e(xge,TTo),e(bu,MTo),e(bu,dD),e(dD,ETo),e(bu,CTo),e(k,wTo),e(k,Vs),e(Vs,$ge),e($ge,ATo),e(Vs,LTo),e(Vs,cD),e(cD,yTo),e(Vs,xTo),e(Vs,mD),e(mD,$To),e(Vs,kTo),e(k,STo),e(k,Xs),e(Xs,kge),e(kge,RTo),e(Xs,PTo),e(Xs,fD),e(fD,BTo),e(Xs,ITo),e(Xs,gD),e(gD,NTo),e(Xs,qTo),e(k,jTo),e(k,zs),e(zs,Sge),e(Sge,DTo),e(zs,GTo),e(zs,hD),e(hD,OTo),e(zs,VTo),e(zs,uD),e(uD,XTo),e(zs,zTo),e(k,QTo),e(k,Qs),e(Qs,Rge),e(Rge,WTo),e(Qs,UTo),e(Qs,pD),e(pD,HTo),e(Qs,JTo),e(Qs,_D),e(_D,YTo),e(Qs,KTo),e(k,ZTo),e(k,Ws),e(Ws,Pge),e(Pge,eMo),e(Ws,oMo),e(Ws,bD),e(bD,rMo),e(Ws,tMo),e(Ws,vD),e(vD,aMo),e(Ws,nMo),e(k,sMo),e(k,Us),e(Us,Bge),e(Bge,lMo),e(Us,iMo),e(Us,FD),e(FD,dMo),e(Us,cMo),e(Us,TD),e(TD,mMo),e(Us,fMo),e(k,gMo),e(k,Hs),e(Hs,Ige),e(Ige,hMo),e(Hs,uMo),e(Hs,MD),e(MD,pMo),e(Hs,_Mo),e(Hs,ED),e(ED,bMo),e(Hs,vMo),e(k,FMo),e(k,Js),e(Js,Nge),e(Nge,TMo),e(Js,MMo),e(Js,CD),e(CD,EMo),e(Js,CMo),e(Js,wD),e(wD,wMo),e(Js,AMo),e(k,LMo),e(k,vu),e(vu,qge),e(qge,yMo),e(vu,xMo),e(vu,AD),e(AD,$Mo),e(vu,kMo),e(k,SMo),e(k,Ys),e(Ys,jge),e(jge,RMo),e(Ys,PMo),e(Ys,LD),e(LD,BMo),e(Ys,IMo),e(Ys,yD),e(yD,NMo),e(Ys,qMo),e(k,jMo),e(k,Ks),e(Ks,Dge),e(Dge,DMo),e(Ks,GMo),e(Ks,xD),e(xD,OMo),e(Ks,VMo),e(Ks,$D),e($D,XMo),e(Ks,zMo),e(k,QMo),e(k,Fu),e(Fu,Gge),e(Gge,WMo),e(Fu,UMo),e(Fu,kD),e(kD,HMo),e(Fu,JMo),e(k,YMo),e(k,Tu),e(Tu,Oge),e(Oge,KMo),e(Tu,ZMo),e(Tu,SD),e(SD,eEo),e(Tu,oEo),e(k,rEo),e(k,Mu),e(Mu,Vge),e(Vge,tEo),e(Mu,aEo),e(Mu,RD),e(RD,nEo),e(Mu,sEo),e(k,lEo),e(k,Eu),e(Eu,Xge),e(Xge,iEo),e(Eu,dEo),e(Eu,PD),e(PD,cEo),e(Eu,mEo),e(k,fEo),e(k,Zs),e(Zs,zge),e(zge,gEo),e(Zs,hEo),e(Zs,BD),e(BD,uEo),e(Zs,pEo),e(Zs,ID),e(ID,_Eo),e(Zs,bEo),e(k,vEo),e(k,Cu),e(Cu,Qge),e(Qge,FEo),e(Cu,TEo),e(Cu,ND),e(ND,MEo),e(Cu,EEo),e(k,CEo),e(k,el),e(el,Wge),e(Wge,wEo),e(el,AEo),e(el,qD),e(qD,LEo),e(el,yEo),e(el,jD),e(jD,xEo),e(el,$Eo),e(k,kEo),e(k,ol),e(ol,Uge),e(Uge,SEo),e(ol,REo),e(ol,DD),e(DD,PEo),e(ol,BEo),e(ol,GD),e(GD,IEo),e(ol,NEo),e(k,qEo),e(k,rl),e(rl,Hge),e(Hge,jEo),e(rl,DEo),e(rl,OD),e(OD,GEo),e(rl,OEo),e(rl,VD),e(VD,VEo),e(rl,XEo),e(k,zEo),e(k,tl),e(tl,Jge),e(Jge,QEo),e(tl,WEo),e(tl,XD),e(XD,UEo),e(tl,HEo),e(tl,zD),e(zD,JEo),e(tl,YEo),e(k,KEo),e(k,al),e(al,Yge),e(Yge,ZEo),e(al,e4o),e(al,QD),e(QD,o4o),e(al,r4o),e(al,WD),e(WD,t4o),e(al,a4o),e(k,n4o),e(k,nl),e(nl,Kge),e(Kge,s4o),e(nl,l4o),e(nl,UD),e(UD,i4o),e(nl,d4o),e(nl,HD),e(HD,c4o),e(nl,m4o),e(k,f4o),e(k,wu),e(wu,Zge),e(Zge,g4o),e(wu,h4o),e(wu,JD),e(JD,u4o),e(wu,p4o),e(k,_4o),e(k,Au),e(Au,ehe),e(ehe,b4o),e(Au,v4o),e(Au,YD),e(YD,F4o),e(Au,T4o),e(k,M4o),e(k,sl),e(sl,ohe),e(ohe,E4o),e(sl,C4o),e(sl,KD),e(KD,w4o),e(sl,A4o),e(sl,ZD),e(ZD,L4o),e(sl,y4o),e(k,x4o),e(k,ll),e(ll,rhe),e(rhe,$4o),e(ll,k4o),e(ll,eG),e(eG,S4o),e(ll,R4o),e(ll,oG),e(oG,P4o),e(ll,B4o),e(k,I4o),e(k,il),e(il,the),e(the,N4o),e(il,q4o),e(il,rG),e(rG,j4o),e(il,D4o),e(il,tG),e(tG,G4o),e(il,O4o),e(k,V4o),e(k,Lu),e(Lu,ahe),e(ahe,X4o),e(Lu,z4o),e(Lu,aG),e(aG,Q4o),e(Lu,W4o),e(k,U4o),e(k,yu),e(yu,nhe),e(nhe,H4o),e(yu,J4o),e(yu,nG),e(nG,Y4o),e(yu,K4o),e(k,Z4o),e(k,xu),e(xu,she),e(she,eCo),e(xu,oCo),e(xu,sG),e(sG,rCo),e(xu,tCo),e(k,aCo),e(k,dl),e(dl,lhe),e(lhe,nCo),e(dl,sCo),e(dl,lG),e(lG,lCo),e(dl,iCo),e(dl,iG),e(iG,dCo),e(dl,cCo),e(k,mCo),e(k,cl),e(cl,ihe),e(ihe,fCo),e(cl,gCo),e(cl,dG),e(dG,hCo),e(cl,uCo),e(cl,cG),e(cG,pCo),e(cl,_Co),e(k,bCo),e(k,$u),e($u,dhe),e(dhe,vCo),e($u,FCo),e($u,mG),e(mG,TCo),e($u,MCo),e(k,ECo),e(k,ku),e(ku,che),e(che,CCo),e(ku,wCo),e(ku,fG),e(fG,ACo),e(ku,LCo),e(k,yCo),e(k,Su),e(Su,mhe),e(mhe,xCo),e(Su,$Co),e(Su,gG),e(gG,kCo),e(Su,SCo),e(k,RCo),e(k,ml),e(ml,fhe),e(fhe,PCo),e(ml,BCo),e(ml,hG),e(hG,ICo),e(ml,NCo),e(ml,uG),e(uG,qCo),e(ml,jCo),e(k,DCo),e(k,fl),e(fl,ghe),e(ghe,GCo),e(fl,OCo),e(fl,pG),e(pG,VCo),e(fl,XCo),e(fl,_G),e(_G,zCo),e(fl,QCo),e(k,WCo),e(k,Ru),e(Ru,hhe),e(hhe,UCo),e(Ru,HCo),e(Ru,bG),e(bG,JCo),e(Ru,YCo),e(k,KCo),e(k,Pu),e(Pu,uhe),e(uhe,ZCo),e(Pu,e3o),e(Pu,vG),e(vG,o3o),e(Pu,r3o),e(k,t3o),e(k,gl),e(gl,phe),e(phe,a3o),e(gl,n3o),e(gl,FG),e(FG,s3o),e(gl,l3o),e(gl,TG),e(TG,i3o),e(gl,d3o),e(k,c3o),e(k,hl),e(hl,_he),e(_he,m3o),e(hl,f3o),e(hl,MG),e(MG,g3o),e(hl,h3o),e(hl,EG),e(EG,u3o),e(hl,p3o),e(k,_3o),e(k,ul),e(ul,bhe),e(bhe,b3o),e(ul,v3o),e(ul,CG),e(CG,F3o),e(ul,T3o),e(ul,wG),e(wG,M3o),e(ul,E3o),e(k,C3o),e(k,pl),e(pl,vhe),e(vhe,w3o),e(pl,A3o),e(pl,AG),e(AG,L3o),e(pl,y3o),e(pl,LG),e(LG,x3o),e(pl,$3o),e(Br,k3o),M(Bu,Br,null),e(ko,S3o),e(ko,Iu),M(lx,Iu,null),e(Iu,R3o),e(Iu,Fhe),e(Fhe,P3o),b(m,wZe,_),b(m,hd,_),e(hd,Nu),e(Nu,The),M(ix,The,null),e(hd,B3o),e(hd,Mhe),e(Mhe,I3o),b(m,AZe,_),b(m,So,_),M(dx,So,null),e(So,N3o),e(So,cx),e(cx,q3o),e(cx,yG),e(yG,j3o),e(cx,D3o),e(So,G3o),e(So,mx),e(mx,O3o),e(mx,Ehe),e(Ehe,V3o),e(mx,X3o),e(So,z3o),e(So,Ye),M(fx,Ye,null),e(Ye,Q3o),e(Ye,Che),e(Che,W3o),e(Ye,U3o),e(Ye,Ha),e(Ha,H3o),e(Ha,whe),e(whe,J3o),e(Ha,Y3o),e(Ha,Ahe),e(Ahe,K3o),e(Ha,Z3o),e(Ha,Lhe),e(Lhe,e5o),e(Ha,o5o),e(Ye,r5o),e(Ye,z),e(z,qu),e(qu,yhe),e(yhe,t5o),e(qu,a5o),e(qu,xG),e(xG,n5o),e(qu,s5o),e(z,l5o),e(z,ju),e(ju,xhe),e(xhe,i5o),e(ju,d5o),e(ju,$G),e($G,c5o),e(ju,m5o),e(z,f5o),e(z,Du),e(Du,$he),e($he,g5o),e(Du,h5o),e(Du,kG),e(kG,u5o),e(Du,p5o),e(z,_5o),e(z,Gu),e(Gu,khe),e(khe,b5o),e(Gu,v5o),e(Gu,SG),e(SG,F5o),e(Gu,T5o),e(z,M5o),e(z,Ou),e(Ou,She),e(She,E5o),e(Ou,C5o),e(Ou,RG),e(RG,w5o),e(Ou,A5o),e(z,L5o),e(z,Vu),e(Vu,Rhe),e(Rhe,y5o),e(Vu,x5o),e(Vu,PG),e(PG,$5o),e(Vu,k5o),e(z,S5o),e(z,Xu),e(Xu,Phe),e(Phe,R5o),e(Xu,P5o),e(Xu,BG),e(BG,B5o),e(Xu,I5o),e(z,N5o),e(z,zu),e(zu,Bhe),e(Bhe,q5o),e(zu,j5o),e(zu,IG),e(IG,D5o),e(zu,G5o),e(z,O5o),e(z,Qu),e(Qu,Ihe),e(Ihe,V5o),e(Qu,X5o),e(Qu,NG),e(NG,z5o),e(Qu,Q5o),e(z,W5o),e(z,Wu),e(Wu,Nhe),e(Nhe,U5o),e(Wu,H5o),e(Wu,qG),e(qG,J5o),e(Wu,Y5o),e(z,K5o),e(z,Uu),e(Uu,qhe),e(qhe,Z5o),e(Uu,e0o),e(Uu,jG),e(jG,o0o),e(Uu,r0o),e(z,t0o),e(z,Hu),e(Hu,jhe),e(jhe,a0o),e(Hu,n0o),e(Hu,DG),e(DG,s0o),e(Hu,l0o),e(z,i0o),e(z,Ju),e(Ju,Dhe),e(Dhe,d0o),e(Ju,c0o),e(Ju,GG),e(GG,m0o),e(Ju,f0o),e(z,g0o),e(z,Yu),e(Yu,Ghe),e(Ghe,h0o),e(Yu,u0o),e(Yu,OG),e(OG,p0o),e(Yu,_0o),e(z,b0o),e(z,Ku),e(Ku,Ohe),e(Ohe,v0o),e(Ku,F0o),e(Ku,VG),e(VG,T0o),e(Ku,M0o),e(z,E0o),e(z,Zu),e(Zu,Vhe),e(Vhe,C0o),e(Zu,w0o),e(Zu,XG),e(XG,A0o),e(Zu,L0o),e(z,y0o),e(z,ep),e(ep,Xhe),e(Xhe,x0o),e(ep,$0o),e(ep,zG),e(zG,k0o),e(ep,S0o),e(z,R0o),e(z,op),e(op,zhe),e(zhe,P0o),e(op,B0o),e(op,QG),e(QG,I0o),e(op,N0o),e(z,q0o),e(z,rp),e(rp,Qhe),e(Qhe,j0o),e(rp,D0o),e(rp,WG),e(WG,G0o),e(rp,O0o),e(z,V0o),e(z,tp),e(tp,Whe),e(Whe,X0o),e(tp,z0o),e(tp,UG),e(UG,Q0o),e(tp,W0o),e(z,U0o),e(z,ap),e(ap,Uhe),e(Uhe,H0o),e(ap,J0o),e(ap,HG),e(HG,Y0o),e(ap,K0o),e(z,Z0o),e(z,np),e(np,Hhe),e(Hhe,ewo),e(np,owo),e(np,JG),e(JG,rwo),e(np,two),e(z,awo),e(z,sp),e(sp,Jhe),e(Jhe,nwo),e(sp,swo),e(sp,YG),e(YG,lwo),e(sp,iwo),e(z,dwo),e(z,lp),e(lp,Yhe),e(Yhe,cwo),e(lp,mwo),e(lp,KG),e(KG,fwo),e(lp,gwo),e(z,hwo),e(z,ip),e(ip,Khe),e(Khe,uwo),e(ip,pwo),e(ip,ZG),e(ZG,_wo),e(ip,bwo),e(z,vwo),e(z,dp),e(dp,Zhe),e(Zhe,Fwo),e(dp,Two),e(dp,eO),e(eO,Mwo),e(dp,Ewo),e(z,Cwo),e(z,cp),e(cp,eue),e(eue,wwo),e(cp,Awo),e(cp,oO),e(oO,Lwo),e(cp,ywo),e(z,xwo),e(z,mp),e(mp,oue),e(oue,$wo),e(mp,kwo),e(mp,rO),e(rO,Swo),e(mp,Rwo),e(z,Pwo),e(z,fp),e(fp,rue),e(rue,Bwo),e(fp,Iwo),e(fp,tO),e(tO,Nwo),e(fp,qwo),e(z,jwo),e(z,gp),e(gp,tue),e(tue,Dwo),e(gp,Gwo),e(gp,aO),e(aO,Owo),e(gp,Vwo),e(z,Xwo),e(z,hp),e(hp,aue),e(aue,zwo),e(hp,Qwo),e(hp,nO),e(nO,Wwo),e(hp,Uwo),e(z,Hwo),e(z,up),e(up,nue),e(nue,Jwo),e(up,Ywo),e(up,sO),e(sO,Kwo),e(up,Zwo),e(z,eAo),e(z,pp),e(pp,sue),e(sue,oAo),e(pp,rAo),e(pp,lO),e(lO,tAo),e(pp,aAo),e(z,nAo),e(z,_p),e(_p,lue),e(lue,sAo),e(_p,lAo),e(_p,iO),e(iO,iAo),e(_p,dAo),e(z,cAo),e(z,bp),e(bp,iue),e(iue,mAo),e(bp,fAo),e(bp,dO),e(dO,gAo),e(bp,hAo),e(z,uAo),e(z,vp),e(vp,due),e(due,pAo),e(vp,_Ao),e(vp,cO),e(cO,bAo),e(vp,vAo),e(z,FAo),e(z,Fp),e(Fp,cue),e(cue,TAo),e(Fp,MAo),e(Fp,mO),e(mO,EAo),e(Fp,CAo),e(z,wAo),e(z,Tp),e(Tp,mue),e(mue,AAo),e(Tp,LAo),e(Tp,fO),e(fO,yAo),e(Tp,xAo),e(z,$Ao),e(z,Mp),e(Mp,fue),e(fue,kAo),e(Mp,SAo),e(Mp,gO),e(gO,RAo),e(Mp,PAo),e(z,BAo),e(z,Ep),e(Ep,gue),e(gue,IAo),e(Ep,NAo),e(Ep,hO),e(hO,qAo),e(Ep,jAo),e(z,DAo),e(z,Cp),e(Cp,hue),e(hue,GAo),e(Cp,OAo),e(Cp,uO),e(uO,VAo),e(Cp,XAo),e(z,zAo),e(z,wp),e(wp,uue),e(uue,QAo),e(wp,WAo),e(wp,pO),e(pO,UAo),e(wp,HAo),e(Ye,JAo),M(Ap,Ye,null),e(Ye,YAo),M(Lp,Ye,null),e(So,KAo),e(So,yp),M(gx,yp,null),e(yp,ZAo),e(yp,pue),e(pue,e6o),b(m,LZe,_),b(m,ud,_),e(ud,xp),e(xp,_ue),M(hx,_ue,null),e(ud,o6o),e(ud,bue),e(bue,r6o),b(m,yZe,_),b(m,Ro,_),M(ux,Ro,null),e(Ro,t6o),e(Ro,px),e(px,a6o),e(px,_O),e(_O,n6o),e(px,s6o),e(Ro,l6o),e(Ro,_x),e(_x,i6o),e(_x,vue),e(vue,d6o),e(_x,c6o),e(Ro,m6o),e(Ro,Ke),M(bx,Ke,null),e(Ke,f6o),e(Ke,Fue),e(Fue,g6o),e(Ke,h6o),e(Ke,pd),e(pd,u6o),e(pd,Tue),e(Tue,p6o),e(pd,_6o),e(pd,Mue),e(Mue,b6o),e(pd,v6o),e(Ke,F6o),e(Ke,le),e(le,$p),e($p,Eue),e(Eue,T6o),e($p,M6o),e($p,bO),e(bO,E6o),e($p,C6o),e(le,w6o),e(le,kp),e(kp,Cue),e(Cue,A6o),e(kp,L6o),e(kp,vO),e(vO,y6o),e(kp,x6o),e(le,$6o),e(le,Sp),e(Sp,wue),e(wue,k6o),e(Sp,S6o),e(Sp,FO),e(FO,R6o),e(Sp,P6o),e(le,B6o),e(le,Rp),e(Rp,Aue),e(Aue,I6o),e(Rp,N6o),e(Rp,TO),e(TO,q6o),e(Rp,j6o),e(le,D6o),e(le,Pp),e(Pp,Lue),e(Lue,G6o),e(Pp,O6o),e(Pp,MO),e(MO,V6o),e(Pp,X6o),e(le,z6o),e(le,Bp),e(Bp,yue),e(yue,Q6o),e(Bp,W6o),e(Bp,EO),e(EO,U6o),e(Bp,H6o),e(le,J6o),e(le,Ip),e(Ip,xue),e(xue,Y6o),e(Ip,K6o),e(Ip,CO),e(CO,Z6o),e(Ip,e7o),e(le,o7o),e(le,Np),e(Np,$ue),e($ue,r7o),e(Np,t7o),e(Np,wO),e(wO,a7o),e(Np,n7o),e(le,s7o),e(le,qp),e(qp,kue),e(kue,l7o),e(qp,i7o),e(qp,AO),e(AO,d7o),e(qp,c7o),e(le,m7o),e(le,jp),e(jp,Sue),e(Sue,f7o),e(jp,g7o),e(jp,LO),e(LO,h7o),e(jp,u7o),e(le,p7o),e(le,Dp),e(Dp,Rue),e(Rue,_7o),e(Dp,b7o),e(Dp,yO),e(yO,v7o),e(Dp,F7o),e(le,T7o),e(le,Gp),e(Gp,Pue),e(Pue,M7o),e(Gp,E7o),e(Gp,xO),e(xO,C7o),e(Gp,w7o),e(le,A7o),e(le,Op),e(Op,Bue),e(Bue,L7o),e(Op,y7o),e(Op,$O),e($O,x7o),e(Op,$7o),e(le,k7o),e(le,Vp),e(Vp,Iue),e(Iue,S7o),e(Vp,R7o),e(Vp,kO),e(kO,P7o),e(Vp,B7o),e(le,I7o),e(le,Xp),e(Xp,Nue),e(Nue,N7o),e(Xp,q7o),e(Xp,SO),e(SO,j7o),e(Xp,D7o),e(le,G7o),e(le,zp),e(zp,que),e(que,O7o),e(zp,V7o),e(zp,RO),e(RO,X7o),e(zp,z7o),e(le,Q7o),e(le,Qp),e(Qp,jue),e(jue,W7o),e(Qp,U7o),e(Qp,PO),e(PO,H7o),e(Qp,J7o),e(le,Y7o),e(le,Wp),e(Wp,Due),e(Due,K7o),e(Wp,Z7o),e(Wp,BO),e(BO,eLo),e(Wp,oLo),e(le,rLo),e(le,Up),e(Up,Gue),e(Gue,tLo),e(Up,aLo),e(Up,IO),e(IO,nLo),e(Up,sLo),e(le,lLo),e(le,Hp),e(Hp,Oue),e(Oue,iLo),e(Hp,dLo),e(Hp,NO),e(NO,cLo),e(Hp,mLo),e(le,fLo),e(le,Jp),e(Jp,Vue),e(Vue,gLo),e(Jp,hLo),e(Jp,qO),e(qO,uLo),e(Jp,pLo),e(le,_Lo),e(le,Yp),e(Yp,Xue),e(Xue,bLo),e(Yp,vLo),e(Yp,jO),e(jO,FLo),e(Yp,TLo),e(Ke,MLo),M(Kp,Ke,null),e(Ke,ELo),M(Zp,Ke,null),e(Ro,CLo),e(Ro,e_),M(vx,e_,null),e(e_,wLo),e(e_,zue),e(zue,ALo),b(m,xZe,_),b(m,_d,_),e(_d,o_),e(o_,Que),M(Fx,Que,null),e(_d,LLo),e(_d,Wue),e(Wue,yLo),b(m,$Ze,_),b(m,Po,_),M(Tx,Po,null),e(Po,xLo),e(Po,bd),e(bd,$Lo),e(bd,DO),e(DO,kLo),e(bd,SLo),e(bd,GO),e(GO,RLo),e(bd,PLo),e(Po,BLo),e(Po,Mx),e(Mx,ILo),e(Mx,Uue),e(Uue,NLo),e(Mx,qLo),e(Po,jLo),e(Po,_t),M(Ex,_t,null),e(_t,DLo),e(_t,Hue),e(Hue,GLo),e(_t,OLo),e(_t,vd),e(vd,VLo),e(vd,Jue),e(Jue,XLo),e(vd,zLo),e(vd,OO),e(OO,QLo),e(vd,WLo),e(_t,ULo),M(r_,_t,null),e(Po,HLo),e(Po,Ze),M(Cx,Ze,null),e(Ze,JLo),e(Ze,Yue),e(Yue,YLo),e(Ze,KLo),e(Ze,Ja),e(Ja,ZLo),e(Ja,Kue),e(Kue,eyo),e(Ja,oyo),e(Ja,Zue),e(Zue,ryo),e(Ja,tyo),e(Ja,epe),e(epe,ayo),e(Ja,nyo),e(Ze,syo),e(Ze,y),e(y,t_),e(t_,ope),e(ope,lyo),e(t_,iyo),e(t_,VO),e(VO,dyo),e(t_,cyo),e(y,myo),e(y,a_),e(a_,rpe),e(rpe,fyo),e(a_,gyo),e(a_,XO),e(XO,hyo),e(a_,uyo),e(y,pyo),e(y,n_),e(n_,tpe),e(tpe,_yo),e(n_,byo),e(n_,zO),e(zO,vyo),e(n_,Fyo),e(y,Tyo),e(y,s_),e(s_,ape),e(ape,Myo),e(s_,Eyo),e(s_,QO),e(QO,Cyo),e(s_,wyo),e(y,Ayo),e(y,l_),e(l_,npe),e(npe,Lyo),e(l_,yyo),e(l_,WO),e(WO,xyo),e(l_,$yo),e(y,kyo),e(y,i_),e(i_,spe),e(spe,Syo),e(i_,Ryo),e(i_,UO),e(UO,Pyo),e(i_,Byo),e(y,Iyo),e(y,d_),e(d_,lpe),e(lpe,Nyo),e(d_,qyo),e(d_,HO),e(HO,jyo),e(d_,Dyo),e(y,Gyo),e(y,c_),e(c_,ipe),e(ipe,Oyo),e(c_,Vyo),e(c_,JO),e(JO,Xyo),e(c_,zyo),e(y,Qyo),e(y,m_),e(m_,dpe),e(dpe,Wyo),e(m_,Uyo),e(m_,YO),e(YO,Hyo),e(m_,Jyo),e(y,Yyo),e(y,f_),e(f_,cpe),e(cpe,Kyo),e(f_,Zyo),e(f_,KO),e(KO,e8o),e(f_,o8o),e(y,r8o),e(y,g_),e(g_,mpe),e(mpe,t8o),e(g_,a8o),e(g_,ZO),e(ZO,n8o),e(g_,s8o),e(y,l8o),e(y,h_),e(h_,fpe),e(fpe,i8o),e(h_,d8o),e(h_,eV),e(eV,c8o),e(h_,m8o),e(y,f8o),e(y,u_),e(u_,gpe),e(gpe,g8o),e(u_,h8o),e(u_,oV),e(oV,u8o),e(u_,p8o),e(y,_8o),e(y,p_),e(p_,hpe),e(hpe,b8o),e(p_,v8o),e(p_,rV),e(rV,F8o),e(p_,T8o),e(y,M8o),e(y,__),e(__,upe),e(upe,E8o),e(__,C8o),e(__,tV),e(tV,w8o),e(__,A8o),e(y,L8o),e(y,b_),e(b_,ppe),e(ppe,y8o),e(b_,x8o),e(b_,aV),e(aV,$8o),e(b_,k8o),e(y,S8o),e(y,v_),e(v_,_pe),e(_pe,R8o),e(v_,P8o),e(v_,nV),e(nV,B8o),e(v_,I8o),e(y,N8o),e(y,F_),e(F_,bpe),e(bpe,q8o),e(F_,j8o),e(F_,sV),e(sV,D8o),e(F_,G8o),e(y,O8o),e(y,T_),e(T_,vpe),e(vpe,V8o),e(T_,X8o),e(T_,lV),e(lV,z8o),e(T_,Q8o),e(y,W8o),e(y,M_),e(M_,Fpe),e(Fpe,U8o),e(M_,H8o),e(M_,iV),e(iV,J8o),e(M_,Y8o),e(y,K8o),e(y,E_),e(E_,Tpe),e(Tpe,Z8o),e(E_,e9o),e(E_,dV),e(dV,o9o),e(E_,r9o),e(y,t9o),e(y,C_),e(C_,Mpe),e(Mpe,a9o),e(C_,n9o),e(C_,cV),e(cV,s9o),e(C_,l9o),e(y,i9o),e(y,w_),e(w_,Epe),e(Epe,d9o),e(w_,c9o),e(w_,mV),e(mV,m9o),e(w_,f9o),e(y,g9o),e(y,A_),e(A_,Cpe),e(Cpe,h9o),e(A_,u9o),e(A_,fV),e(fV,p9o),e(A_,_9o),e(y,b9o),e(y,L_),e(L_,wpe),e(wpe,v9o),e(L_,F9o),e(L_,gV),e(gV,T9o),e(L_,M9o),e(y,E9o),e(y,y_),e(y_,Ape),e(Ape,C9o),e(y_,w9o),e(y_,hV),e(hV,A9o),e(y_,L9o),e(y,y9o),e(y,x_),e(x_,Lpe),e(Lpe,x9o),e(x_,$9o),e(x_,uV),e(uV,k9o),e(x_,S9o),e(y,R9o),e(y,$_),e($_,ype),e(ype,P9o),e($_,B9o),e($_,pV),e(pV,I9o),e($_,N9o),e(y,q9o),e(y,k_),e(k_,xpe),e(xpe,j9o),e(k_,D9o),e(k_,_V),e(_V,G9o),e(k_,O9o),e(y,V9o),e(y,S_),e(S_,$pe),e($pe,X9o),e(S_,z9o),e(S_,bV),e(bV,Q9o),e(S_,W9o),e(y,U9o),e(y,R_),e(R_,kpe),e(kpe,H9o),e(R_,J9o),e(R_,vV),e(vV,Y9o),e(R_,K9o),e(y,Z9o),e(y,P_),e(P_,Spe),e(Spe,exo),e(P_,oxo),e(P_,FV),e(FV,rxo),e(P_,txo),e(y,axo),e(y,B_),e(B_,Rpe),e(Rpe,nxo),e(B_,sxo),e(B_,TV),e(TV,lxo),e(B_,ixo),e(y,dxo),e(y,I_),e(I_,Ppe),e(Ppe,cxo),e(I_,mxo),e(I_,MV),e(MV,fxo),e(I_,gxo),e(y,hxo),e(y,N_),e(N_,Bpe),e(Bpe,uxo),e(N_,pxo),e(N_,EV),e(EV,_xo),e(N_,bxo),e(y,vxo),e(y,q_),e(q_,Ipe),e(Ipe,Fxo),e(q_,Txo),e(q_,CV),e(CV,Mxo),e(q_,Exo),e(y,Cxo),e(y,j_),e(j_,Npe),e(Npe,wxo),e(j_,Axo),e(j_,wV),e(wV,Lxo),e(j_,yxo),e(y,xxo),e(y,D_),e(D_,qpe),e(qpe,$xo),e(D_,kxo),e(D_,AV),e(AV,Sxo),e(D_,Rxo),e(y,Pxo),e(y,_l),e(_l,jpe),e(jpe,Bxo),e(_l,Ixo),e(_l,LV),e(LV,Nxo),e(_l,qxo),e(_l,yV),e(yV,jxo),e(_l,Dxo),e(y,Gxo),e(y,G_),e(G_,Dpe),e(Dpe,Oxo),e(G_,Vxo),e(G_,xV),e(xV,Xxo),e(G_,zxo),e(y,Qxo),e(y,O_),e(O_,Gpe),e(Gpe,Wxo),e(O_,Uxo),e(O_,$V),e($V,Hxo),e(O_,Jxo),e(y,Yxo),e(y,V_),e(V_,Ope),e(Ope,Kxo),e(V_,Zxo),e(V_,kV),e(kV,e$o),e(V_,o$o),e(y,r$o),e(y,X_),e(X_,Vpe),e(Vpe,t$o),e(X_,a$o),e(X_,SV),e(SV,n$o),e(X_,s$o),e(y,l$o),e(y,z_),e(z_,Xpe),e(Xpe,i$o),e(z_,d$o),e(z_,RV),e(RV,c$o),e(z_,m$o),e(y,f$o),e(y,Q_),e(Q_,zpe),e(zpe,g$o),e(Q_,h$o),e(Q_,PV),e(PV,u$o),e(Q_,p$o),e(y,_$o),e(y,W_),e(W_,Qpe),e(Qpe,b$o),e(W_,v$o),e(W_,BV),e(BV,F$o),e(W_,T$o),e(y,M$o),e(y,U_),e(U_,Wpe),e(Wpe,E$o),e(U_,C$o),e(U_,IV),e(IV,w$o),e(U_,A$o),e(y,L$o),e(y,H_),e(H_,Upe),e(Upe,y$o),e(H_,x$o),e(H_,NV),e(NV,$$o),e(H_,k$o),e(y,S$o),e(y,J_),e(J_,Hpe),e(Hpe,R$o),e(J_,P$o),e(J_,qV),e(qV,B$o),e(J_,I$o),e(y,N$o),e(y,Y_),e(Y_,Jpe),e(Jpe,q$o),e(Y_,j$o),e(Y_,jV),e(jV,D$o),e(Y_,G$o),e(y,O$o),e(y,K_),e(K_,Ype),e(Ype,V$o),e(K_,X$o),e(K_,DV),e(DV,z$o),e(K_,Q$o),e(y,W$o),e(y,Z_),e(Z_,Kpe),e(Kpe,U$o),e(Z_,H$o),e(Z_,GV),e(GV,J$o),e(Z_,Y$o),e(y,K$o),e(y,e2),e(e2,Zpe),e(Zpe,Z$o),e(e2,eko),e(e2,OV),e(OV,oko),e(e2,rko),e(y,tko),e(y,o2),e(o2,e_e),e(e_e,ako),e(o2,nko),e(o2,VV),e(VV,sko),e(o2,lko),e(y,iko),e(y,r2),e(r2,o_e),e(o_e,dko),e(r2,cko),e(r2,XV),e(XV,mko),e(r2,fko),e(y,gko),e(y,t2),e(t2,r_e),e(r_e,hko),e(t2,uko),e(t2,zV),e(zV,pko),e(t2,_ko),e(y,bko),e(y,a2),e(a2,t_e),e(t_e,vko),e(a2,Fko),e(a2,QV),e(QV,Tko),e(a2,Mko),e(y,Eko),e(y,n2),e(n2,a_e),e(a_e,Cko),e(n2,wko),e(n2,WV),e(WV,Ako),e(n2,Lko),e(y,yko),e(y,s2),e(s2,n_e),e(n_e,xko),e(s2,$ko),e(s2,UV),e(UV,kko),e(s2,Sko),e(y,Rko),e(y,l2),e(l2,s_e),e(s_e,Pko),e(l2,Bko),e(l2,HV),e(HV,Iko),e(l2,Nko),e(y,qko),e(y,i2),e(i2,l_e),e(l_e,jko),e(i2,Dko),e(i2,JV),e(JV,Gko),e(i2,Oko),e(y,Vko),e(y,d2),e(d2,i_e),e(i_e,Xko),e(d2,zko),e(d2,YV),e(YV,Qko),e(d2,Wko),e(y,Uko),e(y,c2),e(c2,d_e),e(d_e,Hko),e(c2,Jko),e(c2,KV),e(KV,Yko),e(c2,Kko),e(y,Zko),e(y,m2),e(m2,c_e),e(c_e,eSo),e(m2,oSo),e(m2,ZV),e(ZV,rSo),e(m2,tSo),e(y,aSo),e(y,f2),e(f2,m_e),e(m_e,nSo),e(f2,sSo),e(f2,eX),e(eX,lSo),e(f2,iSo),e(y,dSo),e(y,g2),e(g2,f_e),e(f_e,cSo),e(g2,mSo),e(g2,oX),e(oX,fSo),e(g2,gSo),e(y,hSo),e(y,h2),e(h2,g_e),e(g_e,uSo),e(h2,pSo),e(h2,rX),e(rX,_So),e(h2,bSo),e(y,vSo),e(y,u2),e(u2,h_e),e(h_e,FSo),e(u2,TSo),e(u2,tX),e(tX,MSo),e(u2,ESo),e(y,CSo),e(y,p2),e(p2,u_e),e(u_e,wSo),e(p2,ASo),e(p2,aX),e(aX,LSo),e(p2,ySo),e(y,xSo),e(y,_2),e(_2,p_e),e(p_e,$So),e(_2,kSo),e(_2,nX),e(nX,SSo),e(_2,RSo),e(y,PSo),e(y,b2),e(b2,__e),e(__e,BSo),e(b2,ISo),e(b2,sX),e(sX,NSo),e(b2,qSo),e(y,jSo),e(y,v2),e(v2,b_e),e(b_e,DSo),e(v2,GSo),e(v2,lX),e(lX,OSo),e(v2,VSo),e(y,XSo),e(y,F2),e(F2,v_e),e(v_e,zSo),e(F2,QSo),e(F2,iX),e(iX,WSo),e(F2,USo),e(y,HSo),e(y,T2),e(T2,F_e),e(F_e,JSo),e(T2,YSo),e(T2,dX),e(dX,KSo),e(T2,ZSo),e(y,eRo),e(y,M2),e(M2,T_e),e(T_e,oRo),e(M2,rRo),e(M2,cX),e(cX,tRo),e(M2,aRo),e(y,nRo),e(y,E2),e(E2,M_e),e(M_e,sRo),e(E2,lRo),e(E2,mX),e(mX,iRo),e(E2,dRo),e(y,cRo),e(y,C2),e(C2,E_e),e(E_e,mRo),e(C2,fRo),e(C2,fX),e(fX,gRo),e(C2,hRo),e(y,uRo),e(y,w2),e(w2,C_e),e(C_e,pRo),e(w2,_Ro),e(w2,gX),e(gX,bRo),e(w2,vRo),e(y,FRo),e(y,A2),e(A2,w_e),e(w_e,TRo),e(A2,MRo),e(A2,hX),e(hX,ERo),e(A2,CRo),e(y,wRo),e(y,L2),e(L2,A_e),e(A_e,ARo),e(L2,LRo),e(L2,uX),e(uX,yRo),e(L2,xRo),e(y,$Ro),e(y,y2),e(y2,L_e),e(L_e,kRo),e(y2,SRo),e(y2,pX),e(pX,RRo),e(y2,PRo),e(y,BRo),e(y,x2),e(x2,y_e),e(y_e,IRo),e(x2,NRo),e(x2,_X),e(_X,qRo),e(x2,jRo),e(y,DRo),e(y,$2),e($2,x_e),e(x_e,GRo),e($2,ORo),e($2,bX),e(bX,VRo),e($2,XRo),e(y,zRo),e(y,k2),e(k2,$_e),e($_e,QRo),e(k2,WRo),e(k2,vX),e(vX,URo),e(k2,HRo),e(y,JRo),e(y,S2),e(S2,k_e),e(k_e,YRo),e(S2,KRo),e(S2,FX),e(FX,ZRo),e(S2,ePo),e(y,oPo),e(y,R2),e(R2,S_e),e(S_e,rPo),e(R2,tPo),e(R2,TX),e(TX,aPo),e(R2,nPo),e(y,sPo),e(y,P2),e(P2,R_e),e(R_e,lPo),e(P2,iPo),e(P2,MX),e(MX,dPo),e(P2,cPo),e(y,mPo),e(y,B2),e(B2,P_e),e(P_e,fPo),e(B2,gPo),e(B2,EX),e(EX,hPo),e(B2,uPo),e(y,pPo),e(y,I2),e(I2,B_e),e(B_e,_Po),e(I2,bPo),e(I2,CX),e(CX,vPo),e(I2,FPo),e(y,TPo),e(y,N2),e(N2,I_e),e(I_e,MPo),e(N2,EPo),e(N2,wX),e(wX,CPo),e(N2,wPo),e(y,APo),e(y,q2),e(q2,N_e),e(N_e,LPo),e(q2,yPo),e(q2,AX),e(AX,xPo),e(q2,$Po),e(y,kPo),e(y,j2),e(j2,q_e),e(q_e,SPo),e(j2,RPo),e(j2,LX),e(LX,PPo),e(j2,BPo),e(y,IPo),e(y,D2),e(D2,j_e),e(j_e,NPo),e(D2,qPo),e(D2,yX),e(yX,jPo),e(D2,DPo),e(y,GPo),e(y,G2),e(G2,D_e),e(D_e,OPo),e(G2,VPo),e(G2,xX),e(xX,XPo),e(G2,zPo),e(y,QPo),e(y,O2),e(O2,G_e),e(G_e,WPo),e(O2,UPo),e(O2,$X),e($X,HPo),e(O2,JPo),e(y,YPo),e(y,V2),e(V2,O_e),e(O_e,KPo),e(V2,ZPo),e(V2,kX),e(kX,eBo),e(V2,oBo),e(y,rBo),e(y,X2),e(X2,V_e),e(V_e,tBo),e(X2,aBo),e(X2,SX),e(SX,nBo),e(X2,sBo),e(y,lBo),e(y,z2),e(z2,X_e),e(X_e,iBo),e(z2,dBo),e(z2,RX),e(RX,cBo),e(z2,mBo),e(y,fBo),e(y,Q2),e(Q2,z_e),e(z_e,gBo),e(Q2,hBo),e(Q2,PX),e(PX,uBo),e(Q2,pBo),e(y,_Bo),e(y,W2),e(W2,Q_e),e(Q_e,bBo),e(W2,vBo),e(W2,BX),e(BX,FBo),e(W2,TBo),e(y,MBo),e(y,U2),e(U2,W_e),e(W_e,EBo),e(U2,CBo),e(U2,IX),e(IX,wBo),e(U2,ABo),e(y,LBo),e(y,H2),e(H2,U_e),e(U_e,yBo),e(H2,xBo),e(H2,NX),e(NX,$Bo),e(H2,kBo),e(y,SBo),e(y,J2),e(J2,H_e),e(H_e,RBo),e(J2,PBo),e(J2,qX),e(qX,BBo),e(J2,IBo),e(y,NBo),e(y,Y2),e(Y2,J_e),e(J_e,qBo),e(Y2,jBo),e(Y2,jX),e(jX,DBo),e(Y2,GBo),e(y,OBo),e(y,K2),e(K2,Y_e),e(Y_e,VBo),e(K2,XBo),e(K2,DX),e(DX,zBo),e(K2,QBo),e(y,WBo),e(y,Z2),e(Z2,K_e),e(K_e,UBo),e(Z2,HBo),e(Z2,GX),e(GX,JBo),e(Z2,YBo),e(y,KBo),e(y,eb),e(eb,Z_e),e(Z_e,ZBo),e(eb,eIo),e(eb,OX),e(OX,oIo),e(eb,rIo),e(y,tIo),e(y,ob),e(ob,e2e),e(e2e,aIo),e(ob,nIo),e(ob,VX),e(VX,sIo),e(ob,lIo),e(y,iIo),e(y,rb),e(rb,o2e),e(o2e,dIo),e(rb,cIo),e(rb,XX),e(XX,mIo),e(rb,fIo),e(y,gIo),e(y,tb),e(tb,r2e),e(r2e,hIo),e(tb,uIo),e(tb,zX),e(zX,pIo),e(tb,_Io),e(y,bIo),e(y,ab),e(ab,t2e),e(t2e,vIo),e(ab,FIo),e(ab,QX),e(QX,TIo),e(ab,MIo),e(y,EIo),e(y,nb),e(nb,a2e),e(a2e,CIo),e(nb,wIo),e(nb,WX),e(WX,AIo),e(nb,LIo),e(y,yIo),e(y,sb),e(sb,n2e),e(n2e,xIo),e(sb,$Io),e(sb,UX),e(UX,kIo),e(sb,SIo),e(y,RIo),e(y,lb),e(lb,s2e),e(s2e,PIo),e(lb,BIo),e(lb,HX),e(HX,IIo),e(lb,NIo),e(y,qIo),e(y,ib),e(ib,l2e),e(l2e,jIo),e(ib,DIo),e(ib,JX),e(JX,GIo),e(ib,OIo),e(y,VIo),e(y,db),e(db,i2e),e(i2e,XIo),e(db,zIo),e(db,YX),e(YX,QIo),e(db,WIo),e(y,UIo),e(y,cb),e(cb,d2e),e(d2e,HIo),e(cb,JIo),e(cb,KX),e(KX,YIo),e(cb,KIo),e(y,ZIo),e(y,mb),e(mb,c2e),e(c2e,eNo),e(mb,oNo),e(mb,ZX),e(ZX,rNo),e(mb,tNo),e(y,aNo),e(y,fb),e(fb,m2e),e(m2e,nNo),e(fb,sNo),e(fb,ez),e(ez,lNo),e(fb,iNo),e(y,dNo),e(y,gb),e(gb,f2e),e(f2e,cNo),e(gb,mNo),e(gb,oz),e(oz,fNo),e(gb,gNo),e(y,hNo),e(y,hb),e(hb,g2e),e(g2e,uNo),e(hb,pNo),e(hb,rz),e(rz,_No),e(hb,bNo),e(y,vNo),e(y,ub),e(ub,h2e),e(h2e,FNo),e(ub,TNo),e(ub,tz),e(tz,MNo),e(ub,ENo),e(y,CNo),e(y,pb),e(pb,u2e),e(u2e,wNo),e(pb,ANo),e(pb,az),e(az,LNo),e(pb,yNo),e(y,xNo),e(y,_b),e(_b,p2e),e(p2e,$No),e(_b,kNo),e(_b,nz),e(nz,SNo),e(_b,RNo),e(Ze,PNo),e(Ze,bb),e(bb,BNo),e(bb,_2e),e(_2e,INo),e(bb,NNo),e(bb,b2e),e(b2e,qNo),e(Ze,jNo),M(vb,Ze,null),b(m,kZe,_),b(m,Fd,_),e(Fd,Fb),e(Fb,v2e),M(wx,v2e,null),e(Fd,DNo),e(Fd,F2e),e(F2e,GNo),b(m,SZe,_),b(m,Bo,_),M(Ax,Bo,null),e(Bo,ONo),e(Bo,Td),e(Td,VNo),e(Td,sz),e(sz,XNo),e(Td,zNo),e(Td,lz),e(lz,QNo),e(Td,WNo),e(Bo,UNo),e(Bo,Lx),e(Lx,HNo),e(Lx,T2e),e(T2e,JNo),e(Lx,YNo),e(Bo,KNo),e(Bo,bt),M(yx,bt,null),e(bt,ZNo),e(bt,M2e),e(M2e,eqo),e(bt,oqo),e(bt,Md),e(Md,rqo),e(Md,E2e),e(E2e,tqo),e(Md,aqo),e(Md,iz),e(iz,nqo),e(Md,sqo),e(bt,lqo),M(Tb,bt,null),e(Bo,iqo),e(Bo,eo),M(xx,eo,null),e(eo,dqo),e(eo,C2e),e(C2e,cqo),e(eo,mqo),e(eo,Ya),e(Ya,fqo),e(Ya,w2e),e(w2e,gqo),e(Ya,hqo),e(Ya,A2e),e(A2e,uqo),e(Ya,pqo),e(Ya,L2e),e(L2e,_qo),e(Ya,bqo),e(eo,vqo),e(eo,G),e(G,Mb),e(Mb,y2e),e(y2e,Fqo),e(Mb,Tqo),e(Mb,dz),e(dz,Mqo),e(Mb,Eqo),e(G,Cqo),e(G,Eb),e(Eb,x2e),e(x2e,wqo),e(Eb,Aqo),e(Eb,cz),e(cz,Lqo),e(Eb,yqo),e(G,xqo),e(G,Cb),e(Cb,$2e),e($2e,$qo),e(Cb,kqo),e(Cb,mz),e(mz,Sqo),e(Cb,Rqo),e(G,Pqo),e(G,wb),e(wb,k2e),e(k2e,Bqo),e(wb,Iqo),e(wb,fz),e(fz,Nqo),e(wb,qqo),e(G,jqo),e(G,Ab),e(Ab,S2e),e(S2e,Dqo),e(Ab,Gqo),e(Ab,gz),e(gz,Oqo),e(Ab,Vqo),e(G,Xqo),e(G,Lb),e(Lb,R2e),e(R2e,zqo),e(Lb,Qqo),e(Lb,hz),e(hz,Wqo),e(Lb,Uqo),e(G,Hqo),e(G,yb),e(yb,P2e),e(P2e,Jqo),e(yb,Yqo),e(yb,uz),e(uz,Kqo),e(yb,Zqo),e(G,ejo),e(G,xb),e(xb,B2e),e(B2e,ojo),e(xb,rjo),e(xb,pz),e(pz,tjo),e(xb,ajo),e(G,njo),e(G,$b),e($b,I2e),e(I2e,sjo),e($b,ljo),e($b,_z),e(_z,ijo),e($b,djo),e(G,cjo),e(G,kb),e(kb,N2e),e(N2e,mjo),e(kb,fjo),e(kb,bz),e(bz,gjo),e(kb,hjo),e(G,ujo),e(G,Sb),e(Sb,q2e),e(q2e,pjo),e(Sb,_jo),e(Sb,vz),e(vz,bjo),e(Sb,vjo),e(G,Fjo),e(G,Rb),e(Rb,j2e),e(j2e,Tjo),e(Rb,Mjo),e(Rb,Fz),e(Fz,Ejo),e(Rb,Cjo),e(G,wjo),e(G,Pb),e(Pb,D2e),e(D2e,Ajo),e(Pb,Ljo),e(Pb,Tz),e(Tz,yjo),e(Pb,xjo),e(G,$jo),e(G,Bb),e(Bb,G2e),e(G2e,kjo),e(Bb,Sjo),e(Bb,Mz),e(Mz,Rjo),e(Bb,Pjo),e(G,Bjo),e(G,Ib),e(Ib,O2e),e(O2e,Ijo),e(Ib,Njo),e(Ib,Ez),e(Ez,qjo),e(Ib,jjo),e(G,Djo),e(G,Nb),e(Nb,V2e),e(V2e,Gjo),e(Nb,Ojo),e(Nb,Cz),e(Cz,Vjo),e(Nb,Xjo),e(G,zjo),e(G,qb),e(qb,X2e),e(X2e,Qjo),e(qb,Wjo),e(qb,wz),e(wz,Ujo),e(qb,Hjo),e(G,Jjo),e(G,jb),e(jb,z2e),e(z2e,Yjo),e(jb,Kjo),e(jb,Az),e(Az,Zjo),e(jb,eDo),e(G,oDo),e(G,Db),e(Db,Q2e),e(Q2e,rDo),e(Db,tDo),e(Db,Lz),e(Lz,aDo),e(Db,nDo),e(G,sDo),e(G,Gb),e(Gb,W2e),e(W2e,lDo),e(Gb,iDo),e(Gb,yz),e(yz,dDo),e(Gb,cDo),e(G,mDo),e(G,Ob),e(Ob,U2e),e(U2e,fDo),e(Ob,gDo),e(Ob,xz),e(xz,hDo),e(Ob,uDo),e(G,pDo),e(G,Vb),e(Vb,H2e),e(H2e,_Do),e(Vb,bDo),e(Vb,$z),e($z,vDo),e(Vb,FDo),e(G,TDo),e(G,Xb),e(Xb,J2e),e(J2e,MDo),e(Xb,EDo),e(Xb,kz),e(kz,CDo),e(Xb,wDo),e(G,ADo),e(G,zb),e(zb,Y2e),e(Y2e,LDo),e(zb,yDo),e(zb,Sz),e(Sz,xDo),e(zb,$Do),e(G,kDo),e(G,Qb),e(Qb,K2e),e(K2e,SDo),e(Qb,RDo),e(Qb,Rz),e(Rz,PDo),e(Qb,BDo),e(G,IDo),e(G,Wb),e(Wb,Z2e),e(Z2e,NDo),e(Wb,qDo),e(Wb,Pz),e(Pz,jDo),e(Wb,DDo),e(G,GDo),e(G,Ub),e(Ub,ebe),e(ebe,ODo),e(Ub,VDo),e(Ub,Bz),e(Bz,XDo),e(Ub,zDo),e(G,QDo),e(G,Hb),e(Hb,obe),e(obe,WDo),e(Hb,UDo),e(Hb,Iz),e(Iz,HDo),e(Hb,JDo),e(G,YDo),e(G,Jb),e(Jb,rbe),e(rbe,KDo),e(Jb,ZDo),e(Jb,Nz),e(Nz,eGo),e(Jb,oGo),e(G,rGo),e(G,Yb),e(Yb,tbe),e(tbe,tGo),e(Yb,aGo),e(Yb,qz),e(qz,nGo),e(Yb,sGo),e(G,lGo),e(G,Kb),e(Kb,abe),e(abe,iGo),e(Kb,dGo),e(Kb,jz),e(jz,cGo),e(Kb,mGo),e(G,fGo),e(G,Zb),e(Zb,nbe),e(nbe,gGo),e(Zb,hGo),e(Zb,Dz),e(Dz,uGo),e(Zb,pGo),e(G,_Go),e(G,e1),e(e1,sbe),e(sbe,bGo),e(e1,vGo),e(e1,Gz),e(Gz,FGo),e(e1,TGo),e(G,MGo),e(G,o1),e(o1,lbe),e(lbe,EGo),e(o1,CGo),e(o1,Oz),e(Oz,wGo),e(o1,AGo),e(G,LGo),e(G,r1),e(r1,ibe),e(ibe,yGo),e(r1,xGo),e(r1,Vz),e(Vz,$Go),e(r1,kGo),e(G,SGo),e(G,t1),e(t1,dbe),e(dbe,RGo),e(t1,PGo),e(t1,Xz),e(Xz,BGo),e(t1,IGo),e(G,NGo),e(G,a1),e(a1,cbe),e(cbe,qGo),e(a1,jGo),e(a1,zz),e(zz,DGo),e(a1,GGo),e(G,OGo),e(G,n1),e(n1,mbe),e(mbe,VGo),e(n1,XGo),e(n1,Qz),e(Qz,zGo),e(n1,QGo),e(G,WGo),e(G,s1),e(s1,fbe),e(fbe,UGo),e(s1,HGo),e(s1,Wz),e(Wz,JGo),e(s1,YGo),e(G,KGo),e(G,l1),e(l1,gbe),e(gbe,ZGo),e(l1,eOo),e(l1,Uz),e(Uz,oOo),e(l1,rOo),e(G,tOo),e(G,i1),e(i1,hbe),e(hbe,aOo),e(i1,nOo),e(i1,Hz),e(Hz,sOo),e(i1,lOo),e(G,iOo),e(G,d1),e(d1,ube),e(ube,dOo),e(d1,cOo),e(d1,Jz),e(Jz,mOo),e(d1,fOo),e(G,gOo),e(G,c1),e(c1,pbe),e(pbe,hOo),e(c1,uOo),e(c1,Yz),e(Yz,pOo),e(c1,_Oo),e(G,bOo),e(G,m1),e(m1,_be),e(_be,vOo),e(m1,FOo),e(m1,Kz),e(Kz,TOo),e(m1,MOo),e(G,EOo),e(G,f1),e(f1,bbe),e(bbe,COo),e(f1,wOo),e(f1,Zz),e(Zz,AOo),e(f1,LOo),e(G,yOo),e(G,g1),e(g1,vbe),e(vbe,xOo),e(g1,$Oo),e(g1,eQ),e(eQ,kOo),e(g1,SOo),e(G,ROo),e(G,h1),e(h1,Fbe),e(Fbe,POo),e(h1,BOo),e(h1,oQ),e(oQ,IOo),e(h1,NOo),e(G,qOo),e(G,u1),e(u1,Tbe),e(Tbe,jOo),e(u1,DOo),e(u1,rQ),e(rQ,GOo),e(u1,OOo),e(eo,VOo),e(eo,p1),e(p1,XOo),e(p1,Mbe),e(Mbe,zOo),e(p1,QOo),e(p1,Ebe),e(Ebe,WOo),e(eo,UOo),M(_1,eo,null),b(m,RZe,_),b(m,Ed,_),e(Ed,b1),e(b1,Cbe),M($x,Cbe,null),e(Ed,HOo),e(Ed,wbe),e(wbe,JOo),b(m,PZe,_),b(m,Io,_),M(kx,Io,null),e(Io,YOo),e(Io,Cd),e(Cd,KOo),e(Cd,tQ),e(tQ,ZOo),e(Cd,eVo),e(Cd,aQ),e(aQ,oVo),e(Cd,rVo),e(Io,tVo),e(Io,Sx),e(Sx,aVo),e(Sx,Abe),e(Abe,nVo),e(Sx,sVo),e(Io,lVo),e(Io,vt),M(Rx,vt,null),e(vt,iVo),e(vt,Lbe),e(Lbe,dVo),e(vt,cVo),e(vt,wd),e(wd,mVo),e(wd,ybe),e(ybe,fVo),e(wd,gVo),e(wd,nQ),e(nQ,hVo),e(wd,uVo),e(vt,pVo),M(v1,vt,null),e(Io,_Vo),e(Io,oo),M(Px,oo,null),e(oo,bVo),e(oo,xbe),e(xbe,vVo),e(oo,FVo),e(oo,Ka),e(Ka,TVo),e(Ka,$be),e($be,MVo),e(Ka,EVo),e(Ka,kbe),e(kbe,CVo),e(Ka,wVo),e(Ka,Sbe),e(Sbe,AVo),e(Ka,LVo),e(oo,yVo),e(oo,Q),e(Q,F1),e(F1,Rbe),e(Rbe,xVo),e(F1,$Vo),e(F1,sQ),e(sQ,kVo),e(F1,SVo),e(Q,RVo),e(Q,T1),e(T1,Pbe),e(Pbe,PVo),e(T1,BVo),e(T1,lQ),e(lQ,IVo),e(T1,NVo),e(Q,qVo),e(Q,M1),e(M1,Bbe),e(Bbe,jVo),e(M1,DVo),e(M1,iQ),e(iQ,GVo),e(M1,OVo),e(Q,VVo),e(Q,E1),e(E1,Ibe),e(Ibe,XVo),e(E1,zVo),e(E1,dQ),e(dQ,QVo),e(E1,WVo),e(Q,UVo),e(Q,C1),e(C1,Nbe),e(Nbe,HVo),e(C1,JVo),e(C1,cQ),e(cQ,YVo),e(C1,KVo),e(Q,ZVo),e(Q,w1),e(w1,qbe),e(qbe,eXo),e(w1,oXo),e(w1,mQ),e(mQ,rXo),e(w1,tXo),e(Q,aXo),e(Q,A1),e(A1,jbe),e(jbe,nXo),e(A1,sXo),e(A1,fQ),e(fQ,lXo),e(A1,iXo),e(Q,dXo),e(Q,L1),e(L1,Dbe),e(Dbe,cXo),e(L1,mXo),e(L1,gQ),e(gQ,fXo),e(L1,gXo),e(Q,hXo),e(Q,y1),e(y1,Gbe),e(Gbe,uXo),e(y1,pXo),e(y1,hQ),e(hQ,_Xo),e(y1,bXo),e(Q,vXo),e(Q,x1),e(x1,Obe),e(Obe,FXo),e(x1,TXo),e(x1,uQ),e(uQ,MXo),e(x1,EXo),e(Q,CXo),e(Q,$1),e($1,Vbe),e(Vbe,wXo),e($1,AXo),e($1,pQ),e(pQ,LXo),e($1,yXo),e(Q,xXo),e(Q,k1),e(k1,Xbe),e(Xbe,$Xo),e(k1,kXo),e(k1,_Q),e(_Q,SXo),e(k1,RXo),e(Q,PXo),e(Q,S1),e(S1,zbe),e(zbe,BXo),e(S1,IXo),e(S1,bQ),e(bQ,NXo),e(S1,qXo),e(Q,jXo),e(Q,R1),e(R1,Qbe),e(Qbe,DXo),e(R1,GXo),e(R1,vQ),e(vQ,OXo),e(R1,VXo),e(Q,XXo),e(Q,P1),e(P1,Wbe),e(Wbe,zXo),e(P1,QXo),e(P1,FQ),e(FQ,WXo),e(P1,UXo),e(Q,HXo),e(Q,B1),e(B1,Ube),e(Ube,JXo),e(B1,YXo),e(B1,TQ),e(TQ,KXo),e(B1,ZXo),e(Q,ezo),e(Q,I1),e(I1,Hbe),e(Hbe,ozo),e(I1,rzo),e(I1,MQ),e(MQ,tzo),e(I1,azo),e(Q,nzo),e(Q,N1),e(N1,Jbe),e(Jbe,szo),e(N1,lzo),e(N1,EQ),e(EQ,izo),e(N1,dzo),e(Q,czo),e(Q,q1),e(q1,Ybe),e(Ybe,mzo),e(q1,fzo),e(q1,CQ),e(CQ,gzo),e(q1,hzo),e(Q,uzo),e(Q,j1),e(j1,Kbe),e(Kbe,pzo),e(j1,_zo),e(j1,wQ),e(wQ,bzo),e(j1,vzo),e(Q,Fzo),e(Q,D1),e(D1,Zbe),e(Zbe,Tzo),e(D1,Mzo),e(D1,AQ),e(AQ,Ezo),e(D1,Czo),e(Q,wzo),e(Q,G1),e(G1,e1e),e(e1e,Azo),e(G1,Lzo),e(G1,LQ),e(LQ,yzo),e(G1,xzo),e(Q,$zo),e(Q,O1),e(O1,o1e),e(o1e,kzo),e(O1,Szo),e(O1,yQ),e(yQ,Rzo),e(O1,Pzo),e(Q,Bzo),e(Q,V1),e(V1,r1e),e(r1e,Izo),e(V1,Nzo),e(V1,xQ),e(xQ,qzo),e(V1,jzo),e(Q,Dzo),e(Q,X1),e(X1,t1e),e(t1e,Gzo),e(X1,Ozo),e(X1,$Q),e($Q,Vzo),e(X1,Xzo),e(Q,zzo),e(Q,z1),e(z1,a1e),e(a1e,Qzo),e(z1,Wzo),e(z1,kQ),e(kQ,Uzo),e(z1,Hzo),e(Q,Jzo),e(Q,Q1),e(Q1,n1e),e(n1e,Yzo),e(Q1,Kzo),e(Q1,SQ),e(SQ,Zzo),e(Q1,eQo),e(Q,oQo),e(Q,W1),e(W1,s1e),e(s1e,rQo),e(W1,tQo),e(W1,RQ),e(RQ,aQo),e(W1,nQo),e(Q,sQo),e(Q,U1),e(U1,l1e),e(l1e,lQo),e(U1,iQo),e(U1,PQ),e(PQ,dQo),e(U1,cQo),e(Q,mQo),e(Q,H1),e(H1,i1e),e(i1e,fQo),e(H1,gQo),e(H1,BQ),e(BQ,hQo),e(H1,uQo),e(Q,pQo),e(Q,J1),e(J1,d1e),e(d1e,_Qo),e(J1,bQo),e(J1,IQ),e(IQ,vQo),e(J1,FQo),e(Q,TQo),e(Q,Y1),e(Y1,c1e),e(c1e,MQo),e(Y1,EQo),e(Y1,NQ),e(NQ,CQo),e(Y1,wQo),e(Q,AQo),e(Q,K1),e(K1,m1e),e(m1e,LQo),e(K1,yQo),e(K1,qQ),e(qQ,xQo),e(K1,$Qo),e(Q,kQo),e(Q,Z1),e(Z1,f1e),e(f1e,SQo),e(Z1,RQo),e(Z1,jQ),e(jQ,PQo),e(Z1,BQo),e(Q,IQo),e(Q,ev),e(ev,g1e),e(g1e,NQo),e(ev,qQo),e(ev,DQ),e(DQ,jQo),e(ev,DQo),e(Q,GQo),e(Q,ov),e(ov,h1e),e(h1e,OQo),e(ov,VQo),e(ov,GQ),e(GQ,XQo),e(ov,zQo),e(Q,QQo),e(Q,rv),e(rv,u1e),e(u1e,WQo),e(rv,UQo),e(rv,OQ),e(OQ,HQo),e(rv,JQo),e(Q,YQo),e(Q,tv),e(tv,p1e),e(p1e,KQo),e(tv,ZQo),e(tv,VQ),e(VQ,eWo),e(tv,oWo),e(Q,rWo),e(Q,av),e(av,_1e),e(_1e,tWo),e(av,aWo),e(av,XQ),e(XQ,nWo),e(av,sWo),e(Q,lWo),e(Q,nv),e(nv,b1e),e(b1e,iWo),e(nv,dWo),e(nv,zQ),e(zQ,cWo),e(nv,mWo),e(Q,fWo),e(Q,sv),e(sv,v1e),e(v1e,gWo),e(sv,hWo),e(sv,QQ),e(QQ,uWo),e(sv,pWo),e(Q,_Wo),e(Q,lv),e(lv,F1e),e(F1e,bWo),e(lv,vWo),e(lv,WQ),e(WQ,FWo),e(lv,TWo),e(oo,MWo),e(oo,iv),e(iv,EWo),e(iv,T1e),e(T1e,CWo),e(iv,wWo),e(iv,M1e),e(M1e,AWo),e(oo,LWo),M(dv,oo,null),b(m,BZe,_),b(m,Ad,_),e(Ad,cv),e(cv,E1e),M(Bx,E1e,null),e(Ad,yWo),e(Ad,C1e),e(C1e,xWo),b(m,IZe,_),b(m,No,_),M(Ix,No,null),e(No,$Wo),e(No,Ld),e(Ld,kWo),e(Ld,UQ),e(UQ,SWo),e(Ld,RWo),e(Ld,HQ),e(HQ,PWo),e(Ld,BWo),e(No,IWo),e(No,Nx),e(Nx,NWo),e(Nx,w1e),e(w1e,qWo),e(Nx,jWo),e(No,DWo),e(No,Ft),M(qx,Ft,null),e(Ft,GWo),e(Ft,A1e),e(A1e,OWo),e(Ft,VWo),e(Ft,yd),e(yd,XWo),e(yd,L1e),e(L1e,zWo),e(yd,QWo),e(yd,JQ),e(JQ,WWo),e(yd,UWo),e(Ft,HWo),M(mv,Ft,null),e(No,JWo),e(No,ro),M(jx,ro,null),e(ro,YWo),e(ro,y1e),e(y1e,KWo),e(ro,ZWo),e(ro,Za),e(Za,eUo),e(Za,x1e),e(x1e,oUo),e(Za,rUo),e(Za,$1e),e($1e,tUo),e(Za,aUo),e(Za,k1e),e(k1e,nUo),e(Za,sUo),e(ro,lUo),e(ro,H),e(H,fv),e(fv,S1e),e(S1e,iUo),e(fv,dUo),e(fv,YQ),e(YQ,cUo),e(fv,mUo),e(H,fUo),e(H,gv),e(gv,R1e),e(R1e,gUo),e(gv,hUo),e(gv,KQ),e(KQ,uUo),e(gv,pUo),e(H,_Uo),e(H,hv),e(hv,P1e),e(P1e,bUo),e(hv,vUo),e(hv,ZQ),e(ZQ,FUo),e(hv,TUo),e(H,MUo),e(H,uv),e(uv,B1e),e(B1e,EUo),e(uv,CUo),e(uv,eW),e(eW,wUo),e(uv,AUo),e(H,LUo),e(H,pv),e(pv,I1e),e(I1e,yUo),e(pv,xUo),e(pv,oW),e(oW,$Uo),e(pv,kUo),e(H,SUo),e(H,_v),e(_v,N1e),e(N1e,RUo),e(_v,PUo),e(_v,rW),e(rW,BUo),e(_v,IUo),e(H,NUo),e(H,bv),e(bv,q1e),e(q1e,qUo),e(bv,jUo),e(bv,tW),e(tW,DUo),e(bv,GUo),e(H,OUo),e(H,vv),e(vv,j1e),e(j1e,VUo),e(vv,XUo),e(vv,aW),e(aW,zUo),e(vv,QUo),e(H,WUo),e(H,Fv),e(Fv,D1e),e(D1e,UUo),e(Fv,HUo),e(Fv,nW),e(nW,JUo),e(Fv,YUo),e(H,KUo),e(H,Tv),e(Tv,G1e),e(G1e,ZUo),e(Tv,eHo),e(Tv,sW),e(sW,oHo),e(Tv,rHo),e(H,tHo),e(H,Mv),e(Mv,O1e),e(O1e,aHo),e(Mv,nHo),e(Mv,lW),e(lW,sHo),e(Mv,lHo),e(H,iHo),e(H,Ev),e(Ev,V1e),e(V1e,dHo),e(Ev,cHo),e(Ev,iW),e(iW,mHo),e(Ev,fHo),e(H,gHo),e(H,Cv),e(Cv,X1e),e(X1e,hHo),e(Cv,uHo),e(Cv,dW),e(dW,pHo),e(Cv,_Ho),e(H,bHo),e(H,wv),e(wv,z1e),e(z1e,vHo),e(wv,FHo),e(wv,cW),e(cW,THo),e(wv,MHo),e(H,EHo),e(H,Av),e(Av,Q1e),e(Q1e,CHo),e(Av,wHo),e(Av,mW),e(mW,AHo),e(Av,LHo),e(H,yHo),e(H,Lv),e(Lv,W1e),e(W1e,xHo),e(Lv,$Ho),e(Lv,fW),e(fW,kHo),e(Lv,SHo),e(H,RHo),e(H,yv),e(yv,U1e),e(U1e,PHo),e(yv,BHo),e(yv,gW),e(gW,IHo),e(yv,NHo),e(H,qHo),e(H,xv),e(xv,H1e),e(H1e,jHo),e(xv,DHo),e(xv,hW),e(hW,GHo),e(xv,OHo),e(H,VHo),e(H,$v),e($v,J1e),e(J1e,XHo),e($v,zHo),e($v,uW),e(uW,QHo),e($v,WHo),e(H,UHo),e(H,kv),e(kv,Y1e),e(Y1e,HHo),e(kv,JHo),e(kv,pW),e(pW,YHo),e(kv,KHo),e(H,ZHo),e(H,Sv),e(Sv,K1e),e(K1e,eJo),e(Sv,oJo),e(Sv,_W),e(_W,rJo),e(Sv,tJo),e(H,aJo),e(H,Rv),e(Rv,Z1e),e(Z1e,nJo),e(Rv,sJo),e(Rv,bW),e(bW,lJo),e(Rv,iJo),e(H,dJo),e(H,Pv),e(Pv,eve),e(eve,cJo),e(Pv,mJo),e(Pv,vW),e(vW,fJo),e(Pv,gJo),e(H,hJo),e(H,Bv),e(Bv,ove),e(ove,uJo),e(Bv,pJo),e(Bv,FW),e(FW,_Jo),e(Bv,bJo),e(H,vJo),e(H,Iv),e(Iv,rve),e(rve,FJo),e(Iv,TJo),e(Iv,TW),e(TW,MJo),e(Iv,EJo),e(H,CJo),e(H,Nv),e(Nv,tve),e(tve,wJo),e(Nv,AJo),e(Nv,MW),e(MW,LJo),e(Nv,yJo),e(H,xJo),e(H,qv),e(qv,ave),e(ave,$Jo),e(qv,kJo),e(qv,EW),e(EW,SJo),e(qv,RJo),e(H,PJo),e(H,jv),e(jv,nve),e(nve,BJo),e(jv,IJo),e(jv,CW),e(CW,NJo),e(jv,qJo),e(H,jJo),e(H,Dv),e(Dv,sve),e(sve,DJo),e(Dv,GJo),e(Dv,wW),e(wW,OJo),e(Dv,VJo),e(H,XJo),e(H,Gv),e(Gv,lve),e(lve,zJo),e(Gv,QJo),e(Gv,AW),e(AW,WJo),e(Gv,UJo),e(H,HJo),e(H,Ov),e(Ov,ive),e(ive,JJo),e(Ov,YJo),e(Ov,LW),e(LW,KJo),e(Ov,ZJo),e(H,eYo),e(H,Vv),e(Vv,dve),e(dve,oYo),e(Vv,rYo),e(Vv,yW),e(yW,tYo),e(Vv,aYo),e(H,nYo),e(H,Xv),e(Xv,cve),e(cve,sYo),e(Xv,lYo),e(Xv,xW),e(xW,iYo),e(Xv,dYo),e(H,cYo),e(H,zv),e(zv,mve),e(mve,mYo),e(zv,fYo),e(zv,$W),e($W,gYo),e(zv,hYo),e(H,uYo),e(H,Qv),e(Qv,fve),e(fve,pYo),e(Qv,_Yo),e(Qv,gve),e(gve,bYo),e(Qv,vYo),e(H,FYo),e(H,Wv),e(Wv,hve),e(hve,TYo),e(Wv,MYo),e(Wv,kW),e(kW,EYo),e(Wv,CYo),e(H,wYo),e(H,Uv),e(Uv,uve),e(uve,AYo),e(Uv,LYo),e(Uv,SW),e(SW,yYo),e(Uv,xYo),e(H,$Yo),e(H,Hv),e(Hv,pve),e(pve,kYo),e(Hv,SYo),e(Hv,RW),e(RW,RYo),e(Hv,PYo),e(H,BYo),e(H,Jv),e(Jv,_ve),e(_ve,IYo),e(Jv,NYo),e(Jv,PW),e(PW,qYo),e(Jv,jYo),e(ro,DYo),e(ro,Yv),e(Yv,GYo),e(Yv,bve),e(bve,OYo),e(Yv,VYo),e(Yv,vve),e(vve,XYo),e(ro,zYo),M(Kv,ro,null),b(m,NZe,_),b(m,xd,_),e(xd,Zv),e(Zv,Fve),M(Dx,Fve,null),e(xd,QYo),e(xd,Tve),e(Tve,WYo),b(m,qZe,_),b(m,qo,_),M(Gx,qo,null),e(qo,UYo),e(qo,$d),e($d,HYo),e($d,BW),e(BW,JYo),e($d,YYo),e($d,IW),e(IW,KYo),e($d,ZYo),e(qo,eKo),e(qo,Ox),e(Ox,oKo),e(Ox,Mve),e(Mve,rKo),e(Ox,tKo),e(qo,aKo),e(qo,Tt),M(Vx,Tt,null),e(Tt,nKo),e(Tt,Eve),e(Eve,sKo),e(Tt,lKo),e(Tt,kd),e(kd,iKo),e(kd,Cve),e(Cve,dKo),e(kd,cKo),e(kd,NW),e(NW,mKo),e(kd,fKo),e(Tt,gKo),M(eF,Tt,null),e(qo,hKo),e(qo,to),M(Xx,to,null),e(to,uKo),e(to,wve),e(wve,pKo),e(to,_Ko),e(to,en),e(en,bKo),e(en,Ave),e(Ave,vKo),e(en,FKo),e(en,Lve),e(Lve,TKo),e(en,MKo),e(en,yve),e(yve,EKo),e(en,CKo),e(to,wKo),e(to,fe),e(fe,oF),e(oF,xve),e(xve,AKo),e(oF,LKo),e(oF,qW),e(qW,yKo),e(oF,xKo),e(fe,$Ko),e(fe,rF),e(rF,$ve),e($ve,kKo),e(rF,SKo),e(rF,jW),e(jW,RKo),e(rF,PKo),e(fe,BKo),e(fe,tF),e(tF,kve),e(kve,IKo),e(tF,NKo),e(tF,DW),e(DW,qKo),e(tF,jKo),e(fe,DKo),e(fe,aF),e(aF,Sve),e(Sve,GKo),e(aF,OKo),e(aF,GW),e(GW,VKo),e(aF,XKo),e(fe,zKo),e(fe,nF),e(nF,Rve),e(Rve,QKo),e(nF,WKo),e(nF,OW),e(OW,UKo),e(nF,HKo),e(fe,JKo),e(fe,sF),e(sF,Pve),e(Pve,YKo),e(sF,KKo),e(sF,VW),e(VW,ZKo),e(sF,eZo),e(fe,oZo),e(fe,lF),e(lF,Bve),e(Bve,rZo),e(lF,tZo),e(lF,XW),e(XW,aZo),e(lF,nZo),e(fe,sZo),e(fe,iF),e(iF,Ive),e(Ive,lZo),e(iF,iZo),e(iF,zW),e(zW,dZo),e(iF,cZo),e(fe,mZo),e(fe,dF),e(dF,Nve),e(Nve,fZo),e(dF,gZo),e(dF,QW),e(QW,hZo),e(dF,uZo),e(fe,pZo),e(fe,cF),e(cF,qve),e(qve,_Zo),e(cF,bZo),e(cF,WW),e(WW,vZo),e(cF,FZo),e(fe,TZo),e(fe,mF),e(mF,jve),e(jve,MZo),e(mF,EZo),e(mF,UW),e(UW,CZo),e(mF,wZo),e(fe,AZo),e(fe,fF),e(fF,Dve),e(Dve,LZo),e(fF,yZo),e(fF,HW),e(HW,xZo),e(fF,$Zo),e(fe,kZo),e(fe,gF),e(gF,Gve),e(Gve,SZo),e(gF,RZo),e(gF,JW),e(JW,PZo),e(gF,BZo),e(fe,IZo),e(fe,hF),e(hF,Ove),e(Ove,NZo),e(hF,qZo),e(hF,YW),e(YW,jZo),e(hF,DZo),e(fe,GZo),e(fe,uF),e(uF,Vve),e(Vve,OZo),e(uF,VZo),e(uF,KW),e(KW,XZo),e(uF,zZo),e(fe,QZo),e(fe,pF),e(pF,Xve),e(Xve,WZo),e(pF,UZo),e(pF,ZW),e(ZW,HZo),e(pF,JZo),e(fe,YZo),e(fe,_F),e(_F,zve),e(zve,KZo),e(_F,ZZo),e(_F,eU),e(eU,eer),e(_F,oer),e(fe,rer),e(fe,bF),e(bF,Qve),e(Qve,ter),e(bF,aer),e(bF,oU),e(oU,ner),e(bF,ser),e(fe,ler),e(fe,vF),e(vF,Wve),e(Wve,ier),e(vF,der),e(vF,rU),e(rU,cer),e(vF,mer),e(fe,fer),e(fe,FF),e(FF,Uve),e(Uve,ger),e(FF,her),e(FF,tU),e(tU,uer),e(FF,per),e(to,_er),e(to,TF),e(TF,ber),e(TF,Hve),e(Hve,ver),e(TF,Fer),e(TF,Jve),e(Jve,Ter),e(to,Mer),M(MF,to,null),b(m,jZe,_),b(m,Sd,_),e(Sd,EF),e(EF,Yve),M(zx,Yve,null),e(Sd,Eer),e(Sd,Kve),e(Kve,Cer),b(m,DZe,_),b(m,jo,_),M(Qx,jo,null),e(jo,wer),e(jo,Rd),e(Rd,Aer),e(Rd,aU),e(aU,Ler),e(Rd,yer),e(Rd,nU),e(nU,xer),e(Rd,$er),e(jo,ker),e(jo,Wx),e(Wx,Ser),e(Wx,Zve),e(Zve,Rer),e(Wx,Per),e(jo,Ber),e(jo,Mt),M(Ux,Mt,null),e(Mt,Ier),e(Mt,eFe),e(eFe,Ner),e(Mt,qer),e(Mt,Pd),e(Pd,jer),e(Pd,oFe),e(oFe,Der),e(Pd,Ger),e(Pd,sU),e(sU,Oer),e(Pd,Ver),e(Mt,Xer),M(CF,Mt,null),e(jo,zer),e(jo,ao),M(Hx,ao,null),e(ao,Qer),e(ao,rFe),e(rFe,Wer),e(ao,Uer),e(ao,on),e(on,Her),e(on,tFe),e(tFe,Jer),e(on,Yer),e(on,aFe),e(aFe,Ker),e(on,Zer),e(on,nFe),e(nFe,eor),e(on,oor),e(ao,ror),e(ao,q),e(q,wF),e(wF,sFe),e(sFe,tor),e(wF,aor),e(wF,lU),e(lU,nor),e(wF,sor),e(q,lor),e(q,AF),e(AF,lFe),e(lFe,ior),e(AF,dor),e(AF,iU),e(iU,cor),e(AF,mor),e(q,gor),e(q,LF),e(LF,iFe),e(iFe,hor),e(LF,uor),e(LF,dU),e(dU,por),e(LF,_or),e(q,bor),e(q,yF),e(yF,dFe),e(dFe,vor),e(yF,For),e(yF,cU),e(cU,Tor),e(yF,Mor),e(q,Eor),e(q,xF),e(xF,cFe),e(cFe,Cor),e(xF,wor),e(xF,mU),e(mU,Aor),e(xF,Lor),e(q,yor),e(q,$F),e($F,mFe),e(mFe,xor),e($F,$or),e($F,fU),e(fU,kor),e($F,Sor),e(q,Ror),e(q,kF),e(kF,fFe),e(fFe,Por),e(kF,Bor),e(kF,gU),e(gU,Ior),e(kF,Nor),e(q,qor),e(q,SF),e(SF,gFe),e(gFe,jor),e(SF,Dor),e(SF,hU),e(hU,Gor),e(SF,Oor),e(q,Vor),e(q,RF),e(RF,hFe),e(hFe,Xor),e(RF,zor),e(RF,uU),e(uU,Qor),e(RF,Wor),e(q,Uor),e(q,PF),e(PF,uFe),e(uFe,Hor),e(PF,Jor),e(PF,pU),e(pU,Yor),e(PF,Kor),e(q,Zor),e(q,BF),e(BF,pFe),e(pFe,err),e(BF,orr),e(BF,_U),e(_U,rrr),e(BF,trr),e(q,arr),e(q,IF),e(IF,_Fe),e(_Fe,nrr),e(IF,srr),e(IF,bU),e(bU,lrr),e(IF,irr),e(q,drr),e(q,NF),e(NF,bFe),e(bFe,crr),e(NF,mrr),e(NF,vU),e(vU,frr),e(NF,grr),e(q,hrr),e(q,qF),e(qF,vFe),e(vFe,urr),e(qF,prr),e(qF,FU),e(FU,_rr),e(qF,brr),e(q,vrr),e(q,jF),e(jF,FFe),e(FFe,Frr),e(jF,Trr),e(jF,TU),e(TU,Mrr),e(jF,Err),e(q,Crr),e(q,DF),e(DF,TFe),e(TFe,wrr),e(DF,Arr),e(DF,MU),e(MU,Lrr),e(DF,yrr),e(q,xrr),e(q,GF),e(GF,MFe),e(MFe,$rr),e(GF,krr),e(GF,EU),e(EU,Srr),e(GF,Rrr),e(q,Prr),e(q,OF),e(OF,EFe),e(EFe,Brr),e(OF,Irr),e(OF,CU),e(CU,Nrr),e(OF,qrr),e(q,jrr),e(q,VF),e(VF,CFe),e(CFe,Drr),e(VF,Grr),e(VF,wU),e(wU,Orr),e(VF,Vrr),e(q,Xrr),e(q,XF),e(XF,wFe),e(wFe,zrr),e(XF,Qrr),e(XF,AU),e(AU,Wrr),e(XF,Urr),e(q,Hrr),e(q,zF),e(zF,AFe),e(AFe,Jrr),e(zF,Yrr),e(zF,LU),e(LU,Krr),e(zF,Zrr),e(q,etr),e(q,QF),e(QF,LFe),e(LFe,otr),e(QF,rtr),e(QF,yU),e(yU,ttr),e(QF,atr),e(q,ntr),e(q,WF),e(WF,yFe),e(yFe,str),e(WF,ltr),e(WF,xU),e(xU,itr),e(WF,dtr),e(q,ctr),e(q,UF),e(UF,xFe),e(xFe,mtr),e(UF,ftr),e(UF,$U),e($U,gtr),e(UF,htr),e(q,utr),e(q,HF),e(HF,$Fe),e($Fe,ptr),e(HF,_tr),e(HF,kU),e(kU,btr),e(HF,vtr),e(q,Ftr),e(q,JF),e(JF,kFe),e(kFe,Ttr),e(JF,Mtr),e(JF,SU),e(SU,Etr),e(JF,Ctr),e(q,wtr),e(q,YF),e(YF,SFe),e(SFe,Atr),e(YF,Ltr),e(YF,RU),e(RU,ytr),e(YF,xtr),e(q,$tr),e(q,KF),e(KF,RFe),e(RFe,ktr),e(KF,Str),e(KF,PU),e(PU,Rtr),e(KF,Ptr),e(q,Btr),e(q,ZF),e(ZF,PFe),e(PFe,Itr),e(ZF,Ntr),e(ZF,BU),e(BU,qtr),e(ZF,jtr),e(q,Dtr),e(q,eT),e(eT,BFe),e(BFe,Gtr),e(eT,Otr),e(eT,IU),e(IU,Vtr),e(eT,Xtr),e(q,ztr),e(q,oT),e(oT,IFe),e(IFe,Qtr),e(oT,Wtr),e(oT,NU),e(NU,Utr),e(oT,Htr),e(q,Jtr),e(q,rT),e(rT,NFe),e(NFe,Ytr),e(rT,Ktr),e(rT,qU),e(qU,Ztr),e(rT,ear),e(q,oar),e(q,tT),e(tT,qFe),e(qFe,rar),e(tT,tar),e(tT,jU),e(jU,aar),e(tT,nar),e(q,sar),e(q,aT),e(aT,jFe),e(jFe,lar),e(aT,iar),e(aT,DU),e(DU,dar),e(aT,car),e(q,mar),e(q,nT),e(nT,DFe),e(DFe,far),e(nT,gar),e(nT,GU),e(GU,har),e(nT,uar),e(q,par),e(q,sT),e(sT,GFe),e(GFe,_ar),e(sT,bar),e(sT,OU),e(OU,Far),e(sT,Tar),e(q,Mar),e(q,lT),e(lT,OFe),e(OFe,Ear),e(lT,Car),e(lT,VU),e(VU,war),e(lT,Aar),e(q,Lar),e(q,iT),e(iT,VFe),e(VFe,yar),e(iT,xar),e(iT,XU),e(XU,$ar),e(iT,kar),e(q,Sar),e(q,dT),e(dT,XFe),e(XFe,Rar),e(dT,Par),e(dT,zU),e(zU,Bar),e(dT,Iar),e(q,Nar),e(q,cT),e(cT,zFe),e(zFe,qar),e(cT,jar),e(cT,QU),e(QU,Dar),e(cT,Gar),e(q,Oar),e(q,mT),e(mT,QFe),e(QFe,Var),e(mT,Xar),e(mT,WU),e(WU,zar),e(mT,Qar),e(q,War),e(q,fT),e(fT,WFe),e(WFe,Uar),e(fT,Har),e(fT,UU),e(UU,Jar),e(fT,Yar),e(q,Kar),e(q,gT),e(gT,UFe),e(UFe,Zar),e(gT,enr),e(gT,HU),e(HU,onr),e(gT,rnr),e(q,tnr),e(q,hT),e(hT,HFe),e(HFe,anr),e(hT,nnr),e(hT,JU),e(JU,snr),e(hT,lnr),e(q,inr),e(q,uT),e(uT,JFe),e(JFe,dnr),e(uT,cnr),e(uT,YU),e(YU,mnr),e(uT,fnr),e(q,gnr),e(q,pT),e(pT,YFe),e(YFe,hnr),e(pT,unr),e(pT,KU),e(KU,pnr),e(pT,_nr),e(q,bnr),e(q,_T),e(_T,KFe),e(KFe,vnr),e(_T,Fnr),e(_T,ZU),e(ZU,Tnr),e(_T,Mnr),e(q,Enr),e(q,bT),e(bT,ZFe),e(ZFe,Cnr),e(bT,wnr),e(bT,eH),e(eH,Anr),e(bT,Lnr),e(q,ynr),e(q,vT),e(vT,eTe),e(eTe,xnr),e(vT,$nr),e(vT,oH),e(oH,knr),e(vT,Snr),e(q,Rnr),e(q,FT),e(FT,oTe),e(oTe,Pnr),e(FT,Bnr),e(FT,rH),e(rH,Inr),e(FT,Nnr),e(q,qnr),e(q,TT),e(TT,rTe),e(rTe,jnr),e(TT,Dnr),e(TT,tH),e(tH,Gnr),e(TT,Onr),e(q,Vnr),e(q,MT),e(MT,tTe),e(tTe,Xnr),e(MT,znr),e(MT,aH),e(aH,Qnr),e(MT,Wnr),e(q,Unr),e(q,ET),e(ET,aTe),e(aTe,Hnr),e(ET,Jnr),e(ET,nH),e(nH,Ynr),e(ET,Knr),e(q,Znr),e(q,CT),e(CT,nTe),e(nTe,esr),e(CT,osr),e(CT,sH),e(sH,rsr),e(CT,tsr),e(ao,asr),e(ao,wT),e(wT,nsr),e(wT,sTe),e(sTe,ssr),e(wT,lsr),e(wT,lTe),e(lTe,isr),e(ao,dsr),M(AT,ao,null),b(m,GZe,_),b(m,Bd,_),e(Bd,LT),e(LT,iTe),M(Jx,iTe,null),e(Bd,csr),e(Bd,dTe),e(dTe,msr),b(m,OZe,_),b(m,Do,_),M(Yx,Do,null),e(Do,fsr),e(Do,Id),e(Id,gsr),e(Id,lH),e(lH,hsr),e(Id,usr),e(Id,iH),e(iH,psr),e(Id,_sr),e(Do,bsr),e(Do,Kx),e(Kx,vsr),e(Kx,cTe),e(cTe,Fsr),e(Kx,Tsr),e(Do,Msr),e(Do,Et),M(Zx,Et,null),e(Et,Esr),e(Et,mTe),e(mTe,Csr),e(Et,wsr),e(Et,Nd),e(Nd,Asr),e(Nd,fTe),e(fTe,Lsr),e(Nd,ysr),e(Nd,dH),e(dH,xsr),e(Nd,$sr),e(Et,ksr),M(yT,Et,null),e(Do,Ssr),e(Do,no),M(e$,no,null),e(no,Rsr),e(no,gTe),e(gTe,Psr),e(no,Bsr),e(no,rn),e(rn,Isr),e(rn,hTe),e(hTe,Nsr),e(rn,qsr),e(rn,uTe),e(uTe,jsr),e(rn,Dsr),e(rn,pTe),e(pTe,Gsr),e(rn,Osr),e(no,Vsr),e(no,Z),e(Z,xT),e(xT,_Te),e(_Te,Xsr),e(xT,zsr),e(xT,cH),e(cH,Qsr),e(xT,Wsr),e(Z,Usr),e(Z,$T),e($T,bTe),e(bTe,Hsr),e($T,Jsr),e($T,mH),e(mH,Ysr),e($T,Ksr),e(Z,Zsr),e(Z,kT),e(kT,vTe),e(vTe,elr),e(kT,olr),e(kT,fH),e(fH,rlr),e(kT,tlr),e(Z,alr),e(Z,ST),e(ST,FTe),e(FTe,nlr),e(ST,slr),e(ST,gH),e(gH,llr),e(ST,ilr),e(Z,dlr),e(Z,RT),e(RT,TTe),e(TTe,clr),e(RT,mlr),e(RT,hH),e(hH,flr),e(RT,glr),e(Z,hlr),e(Z,PT),e(PT,MTe),e(MTe,ulr),e(PT,plr),e(PT,uH),e(uH,_lr),e(PT,blr),e(Z,vlr),e(Z,BT),e(BT,ETe),e(ETe,Flr),e(BT,Tlr),e(BT,pH),e(pH,Mlr),e(BT,Elr),e(Z,Clr),e(Z,IT),e(IT,CTe),e(CTe,wlr),e(IT,Alr),e(IT,_H),e(_H,Llr),e(IT,ylr),e(Z,xlr),e(Z,NT),e(NT,wTe),e(wTe,$lr),e(NT,klr),e(NT,bH),e(bH,Slr),e(NT,Rlr),e(Z,Plr),e(Z,qT),e(qT,ATe),e(ATe,Blr),e(qT,Ilr),e(qT,vH),e(vH,Nlr),e(qT,qlr),e(Z,jlr),e(Z,jT),e(jT,LTe),e(LTe,Dlr),e(jT,Glr),e(jT,FH),e(FH,Olr),e(jT,Vlr),e(Z,Xlr),e(Z,DT),e(DT,yTe),e(yTe,zlr),e(DT,Qlr),e(DT,TH),e(TH,Wlr),e(DT,Ulr),e(Z,Hlr),e(Z,GT),e(GT,xTe),e(xTe,Jlr),e(GT,Ylr),e(GT,MH),e(MH,Klr),e(GT,Zlr),e(Z,eir),e(Z,OT),e(OT,$Te),e($Te,oir),e(OT,rir),e(OT,EH),e(EH,tir),e(OT,air),e(Z,nir),e(Z,VT),e(VT,kTe),e(kTe,sir),e(VT,lir),e(VT,CH),e(CH,iir),e(VT,dir),e(Z,cir),e(Z,XT),e(XT,STe),e(STe,mir),e(XT,fir),e(XT,wH),e(wH,gir),e(XT,hir),e(Z,uir),e(Z,zT),e(zT,RTe),e(RTe,pir),e(zT,_ir),e(zT,AH),e(AH,bir),e(zT,vir),e(Z,Fir),e(Z,QT),e(QT,PTe),e(PTe,Tir),e(QT,Mir),e(QT,LH),e(LH,Eir),e(QT,Cir),e(Z,wir),e(Z,WT),e(WT,BTe),e(BTe,Air),e(WT,Lir),e(WT,yH),e(yH,yir),e(WT,xir),e(Z,$ir),e(Z,UT),e(UT,ITe),e(ITe,kir),e(UT,Sir),e(UT,xH),e(xH,Rir),e(UT,Pir),e(Z,Bir),e(Z,HT),e(HT,NTe),e(NTe,Iir),e(HT,Nir),e(HT,$H),e($H,qir),e(HT,jir),e(Z,Dir),e(Z,JT),e(JT,qTe),e(qTe,Gir),e(JT,Oir),e(JT,kH),e(kH,Vir),e(JT,Xir),e(Z,zir),e(Z,YT),e(YT,jTe),e(jTe,Qir),e(YT,Wir),e(YT,SH),e(SH,Uir),e(YT,Hir),e(Z,Jir),e(Z,KT),e(KT,DTe),e(DTe,Yir),e(KT,Kir),e(KT,RH),e(RH,Zir),e(KT,edr),e(Z,odr),e(Z,ZT),e(ZT,GTe),e(GTe,rdr),e(ZT,tdr),e(ZT,PH),e(PH,adr),e(ZT,ndr),e(Z,sdr),e(Z,eM),e(eM,OTe),e(OTe,ldr),e(eM,idr),e(eM,BH),e(BH,ddr),e(eM,cdr),e(Z,mdr),e(Z,oM),e(oM,VTe),e(VTe,fdr),e(oM,gdr),e(oM,IH),e(IH,hdr),e(oM,udr),e(Z,pdr),e(Z,rM),e(rM,XTe),e(XTe,_dr),e(rM,bdr),e(rM,NH),e(NH,vdr),e(rM,Fdr),e(Z,Tdr),e(Z,tM),e(tM,zTe),e(zTe,Mdr),e(tM,Edr),e(tM,qH),e(qH,Cdr),e(tM,wdr),e(Z,Adr),e(Z,aM),e(aM,QTe),e(QTe,Ldr),e(aM,ydr),e(aM,jH),e(jH,xdr),e(aM,$dr),e(Z,kdr),e(Z,nM),e(nM,WTe),e(WTe,Sdr),e(nM,Rdr),e(nM,DH),e(DH,Pdr),e(nM,Bdr),e(Z,Idr),e(Z,sM),e(sM,UTe),e(UTe,Ndr),e(sM,qdr),e(sM,GH),e(GH,jdr),e(sM,Ddr),e(no,Gdr),e(no,lM),e(lM,Odr),e(lM,HTe),e(HTe,Vdr),e(lM,Xdr),e(lM,JTe),e(JTe,zdr),e(no,Qdr),M(iM,no,null),b(m,VZe,_),b(m,qd,_),e(qd,dM),e(dM,YTe),M(o$,YTe,null),e(qd,Wdr),e(qd,KTe),e(KTe,Udr),b(m,XZe,_),b(m,Go,_),M(r$,Go,null),e(Go,Hdr),e(Go,jd),e(jd,Jdr),e(jd,OH),e(OH,Ydr),e(jd,Kdr),e(jd,VH),e(VH,Zdr),e(jd,ecr),e(Go,ocr),e(Go,t$),e(t$,rcr),e(t$,ZTe),e(ZTe,tcr),e(t$,acr),e(Go,ncr),e(Go,Ct),M(a$,Ct,null),e(Ct,scr),e(Ct,eMe),e(eMe,lcr),e(Ct,icr),e(Ct,Dd),e(Dd,dcr),e(Dd,oMe),e(oMe,ccr),e(Dd,mcr),e(Dd,XH),e(XH,fcr),e(Dd,gcr),e(Ct,hcr),M(cM,Ct,null),e(Go,ucr),e(Go,so),M(n$,so,null),e(so,pcr),e(so,rMe),e(rMe,_cr),e(so,bcr),e(so,tn),e(tn,vcr),e(tn,tMe),e(tMe,Fcr),e(tn,Tcr),e(tn,aMe),e(aMe,Mcr),e(tn,Ecr),e(tn,nMe),e(nMe,Ccr),e(tn,wcr),e(so,Acr),e(so,Ue),e(Ue,mM),e(mM,sMe),e(sMe,Lcr),e(mM,ycr),e(mM,zH),e(zH,xcr),e(mM,$cr),e(Ue,kcr),e(Ue,fM),e(fM,lMe),e(lMe,Scr),e(fM,Rcr),e(fM,QH),e(QH,Pcr),e(fM,Bcr),e(Ue,Icr),e(Ue,gM),e(gM,iMe),e(iMe,Ncr),e(gM,qcr),e(gM,WH),e(WH,jcr),e(gM,Dcr),e(Ue,Gcr),e(Ue,hM),e(hM,dMe),e(dMe,Ocr),e(hM,Vcr),e(hM,UH),e(UH,Xcr),e(hM,zcr),e(Ue,Qcr),e(Ue,uM),e(uM,cMe),e(cMe,Wcr),e(uM,Ucr),e(uM,HH),e(HH,Hcr),e(uM,Jcr),e(Ue,Ycr),e(Ue,pM),e(pM,mMe),e(mMe,Kcr),e(pM,Zcr),e(pM,JH),e(JH,emr),e(pM,omr),e(Ue,rmr),e(Ue,_M),e(_M,fMe),e(fMe,tmr),e(_M,amr),e(_M,YH),e(YH,nmr),e(_M,smr),e(so,lmr),e(so,bM),e(bM,imr),e(bM,gMe),e(gMe,dmr),e(bM,cmr),e(bM,hMe),e(hMe,mmr),e(so,fmr),M(vM,so,null),b(m,zZe,_),b(m,Gd,_),e(Gd,FM),e(FM,uMe),M(s$,uMe,null),e(Gd,gmr),e(Gd,pMe),e(pMe,hmr),b(m,QZe,_),b(m,Oo,_),M(l$,Oo,null),e(Oo,umr),e(Oo,Od),e(Od,pmr),e(Od,KH),e(KH,_mr),e(Od,bmr),e(Od,ZH),e(ZH,vmr),e(Od,Fmr),e(Oo,Tmr),e(Oo,i$),e(i$,Mmr),e(i$,_Me),e(_Me,Emr),e(i$,Cmr),e(Oo,wmr),e(Oo,wt),M(d$,wt,null),e(wt,Amr),e(wt,bMe),e(bMe,Lmr),e(wt,ymr),e(wt,Vd),e(Vd,xmr),e(Vd,vMe),e(vMe,$mr),e(Vd,kmr),e(Vd,eJ),e(eJ,Smr),e(Vd,Rmr),e(wt,Pmr),M(TM,wt,null),e(Oo,Bmr),e(Oo,lo),M(c$,lo,null),e(lo,Imr),e(lo,FMe),e(FMe,Nmr),e(lo,qmr),e(lo,an),e(an,jmr),e(an,TMe),e(TMe,Dmr),e(an,Gmr),e(an,MMe),e(MMe,Omr),e(an,Vmr),e(an,EMe),e(EMe,Xmr),e(an,zmr),e(lo,Qmr),e(lo,J),e(J,MM),e(MM,CMe),e(CMe,Wmr),e(MM,Umr),e(MM,oJ),e(oJ,Hmr),e(MM,Jmr),e(J,Ymr),e(J,EM),e(EM,wMe),e(wMe,Kmr),e(EM,Zmr),e(EM,rJ),e(rJ,efr),e(EM,ofr),e(J,rfr),e(J,CM),e(CM,AMe),e(AMe,tfr),e(CM,afr),e(CM,tJ),e(tJ,nfr),e(CM,sfr),e(J,lfr),e(J,wM),e(wM,LMe),e(LMe,ifr),e(wM,dfr),e(wM,aJ),e(aJ,cfr),e(wM,mfr),e(J,ffr),e(J,AM),e(AM,yMe),e(yMe,gfr),e(AM,hfr),e(AM,nJ),e(nJ,ufr),e(AM,pfr),e(J,_fr),e(J,LM),e(LM,xMe),e(xMe,bfr),e(LM,vfr),e(LM,sJ),e(sJ,Ffr),e(LM,Tfr),e(J,Mfr),e(J,yM),e(yM,$Me),e($Me,Efr),e(yM,Cfr),e(yM,lJ),e(lJ,wfr),e(yM,Afr),e(J,Lfr),e(J,xM),e(xM,kMe),e(kMe,yfr),e(xM,xfr),e(xM,iJ),e(iJ,$fr),e(xM,kfr),e(J,Sfr),e(J,$M),e($M,SMe),e(SMe,Rfr),e($M,Pfr),e($M,dJ),e(dJ,Bfr),e($M,Ifr),e(J,Nfr),e(J,kM),e(kM,RMe),e(RMe,qfr),e(kM,jfr),e(kM,cJ),e(cJ,Dfr),e(kM,Gfr),e(J,Ofr),e(J,SM),e(SM,PMe),e(PMe,Vfr),e(SM,Xfr),e(SM,mJ),e(mJ,zfr),e(SM,Qfr),e(J,Wfr),e(J,RM),e(RM,BMe),e(BMe,Ufr),e(RM,Hfr),e(RM,fJ),e(fJ,Jfr),e(RM,Yfr),e(J,Kfr),e(J,PM),e(PM,IMe),e(IMe,Zfr),e(PM,egr),e(PM,gJ),e(gJ,ogr),e(PM,rgr),e(J,tgr),e(J,BM),e(BM,NMe),e(NMe,agr),e(BM,ngr),e(BM,hJ),e(hJ,sgr),e(BM,lgr),e(J,igr),e(J,IM),e(IM,qMe),e(qMe,dgr),e(IM,cgr),e(IM,uJ),e(uJ,mgr),e(IM,fgr),e(J,ggr),e(J,NM),e(NM,jMe),e(jMe,hgr),e(NM,ugr),e(NM,pJ),e(pJ,pgr),e(NM,_gr),e(J,bgr),e(J,qM),e(qM,DMe),e(DMe,vgr),e(qM,Fgr),e(qM,_J),e(_J,Tgr),e(qM,Mgr),e(J,Egr),e(J,jM),e(jM,GMe),e(GMe,Cgr),e(jM,wgr),e(jM,bJ),e(bJ,Agr),e(jM,Lgr),e(J,ygr),e(J,DM),e(DM,OMe),e(OMe,xgr),e(DM,$gr),e(DM,vJ),e(vJ,kgr),e(DM,Sgr),e(J,Rgr),e(J,GM),e(GM,VMe),e(VMe,Pgr),e(GM,Bgr),e(GM,FJ),e(FJ,Igr),e(GM,Ngr),e(J,qgr),e(J,OM),e(OM,XMe),e(XMe,jgr),e(OM,Dgr),e(OM,TJ),e(TJ,Ggr),e(OM,Ogr),e(J,Vgr),e(J,VM),e(VM,zMe),e(zMe,Xgr),e(VM,zgr),e(VM,MJ),e(MJ,Qgr),e(VM,Wgr),e(J,Ugr),e(J,XM),e(XM,QMe),e(QMe,Hgr),e(XM,Jgr),e(XM,EJ),e(EJ,Ygr),e(XM,Kgr),e(J,Zgr),e(J,zM),e(zM,WMe),e(WMe,ehr),e(zM,ohr),e(zM,CJ),e(CJ,rhr),e(zM,thr),e(J,ahr),e(J,QM),e(QM,UMe),e(UMe,nhr),e(QM,shr),e(QM,wJ),e(wJ,lhr),e(QM,ihr),e(J,dhr),e(J,WM),e(WM,HMe),e(HMe,chr),e(WM,mhr),e(WM,AJ),e(AJ,fhr),e(WM,ghr),e(J,hhr),e(J,UM),e(UM,JMe),e(JMe,uhr),e(UM,phr),e(UM,LJ),e(LJ,_hr),e(UM,bhr),e(J,vhr),e(J,HM),e(HM,YMe),e(YMe,Fhr),e(HM,Thr),e(HM,yJ),e(yJ,Mhr),e(HM,Ehr),e(J,Chr),e(J,JM),e(JM,KMe),e(KMe,whr),e(JM,Ahr),e(JM,xJ),e(xJ,Lhr),e(JM,yhr),e(J,xhr),e(J,YM),e(YM,ZMe),e(ZMe,$hr),e(YM,khr),e(YM,$J),e($J,Shr),e(YM,Rhr),e(J,Phr),e(J,KM),e(KM,eEe),e(eEe,Bhr),e(KM,Ihr),e(KM,kJ),e(kJ,Nhr),e(KM,qhr),e(J,jhr),e(J,ZM),e(ZM,oEe),e(oEe,Dhr),e(ZM,Ghr),e(ZM,SJ),e(SJ,Ohr),e(ZM,Vhr),e(J,Xhr),e(J,eE),e(eE,rEe),e(rEe,zhr),e(eE,Qhr),e(eE,RJ),e(RJ,Whr),e(eE,Uhr),e(J,Hhr),e(J,oE),e(oE,tEe),e(tEe,Jhr),e(oE,Yhr),e(oE,PJ),e(PJ,Khr),e(oE,Zhr),e(J,eur),e(J,rE),e(rE,aEe),e(aEe,our),e(rE,rur),e(rE,BJ),e(BJ,tur),e(rE,aur),e(J,nur),e(J,tE),e(tE,nEe),e(nEe,sur),e(tE,lur),e(tE,IJ),e(IJ,iur),e(tE,dur),e(J,cur),e(J,aE),e(aE,sEe),e(sEe,mur),e(aE,fur),e(aE,NJ),e(NJ,gur),e(aE,hur),e(J,uur),e(J,nE),e(nE,lEe),e(lEe,pur),e(nE,_ur),e(nE,qJ),e(qJ,bur),e(nE,vur),e(J,Fur),e(J,sE),e(sE,iEe),e(iEe,Tur),e(sE,Mur),e(sE,jJ),e(jJ,Eur),e(sE,Cur),e(lo,wur),e(lo,lE),e(lE,Aur),e(lE,dEe),e(dEe,Lur),e(lE,yur),e(lE,cEe),e(cEe,xur),e(lo,$ur),M(iE,lo,null),b(m,WZe,_),b(m,Xd,_),e(Xd,dE),e(dE,mEe),M(m$,mEe,null),e(Xd,kur),e(Xd,fEe),e(fEe,Sur),b(m,UZe,_),b(m,Vo,_),M(f$,Vo,null),e(Vo,Rur),e(Vo,zd),e(zd,Pur),e(zd,DJ),e(DJ,Bur),e(zd,Iur),e(zd,GJ),e(GJ,Nur),e(zd,qur),e(Vo,jur),e(Vo,g$),e(g$,Dur),e(g$,gEe),e(gEe,Gur),e(g$,Our),e(Vo,Vur),e(Vo,At),M(h$,At,null),e(At,Xur),e(At,hEe),e(hEe,zur),e(At,Qur),e(At,Qd),e(Qd,Wur),e(Qd,uEe),e(uEe,Uur),e(Qd,Hur),e(Qd,OJ),e(OJ,Jur),e(Qd,Yur),e(At,Kur),M(cE,At,null),e(Vo,Zur),e(Vo,io),M(u$,io,null),e(io,epr),e(io,pEe),e(pEe,opr),e(io,rpr),e(io,nn),e(nn,tpr),e(nn,_Ee),e(_Ee,apr),e(nn,npr),e(nn,bEe),e(bEe,spr),e(nn,lpr),e(nn,vEe),e(vEe,ipr),e(nn,dpr),e(io,cpr),e(io,V),e(V,mE),e(mE,FEe),e(FEe,mpr),e(mE,fpr),e(mE,VJ),e(VJ,gpr),e(mE,hpr),e(V,upr),e(V,fE),e(fE,TEe),e(TEe,ppr),e(fE,_pr),e(fE,XJ),e(XJ,bpr),e(fE,vpr),e(V,Fpr),e(V,gE),e(gE,MEe),e(MEe,Tpr),e(gE,Mpr),e(gE,zJ),e(zJ,Epr),e(gE,Cpr),e(V,wpr),e(V,hE),e(hE,EEe),e(EEe,Apr),e(hE,Lpr),e(hE,QJ),e(QJ,ypr),e(hE,xpr),e(V,$pr),e(V,uE),e(uE,CEe),e(CEe,kpr),e(uE,Spr),e(uE,WJ),e(WJ,Rpr),e(uE,Ppr),e(V,Bpr),e(V,pE),e(pE,wEe),e(wEe,Ipr),e(pE,Npr),e(pE,UJ),e(UJ,qpr),e(pE,jpr),e(V,Dpr),e(V,_E),e(_E,AEe),e(AEe,Gpr),e(_E,Opr),e(_E,HJ),e(HJ,Vpr),e(_E,Xpr),e(V,zpr),e(V,bE),e(bE,LEe),e(LEe,Qpr),e(bE,Wpr),e(bE,JJ),e(JJ,Upr),e(bE,Hpr),e(V,Jpr),e(V,vE),e(vE,yEe),e(yEe,Ypr),e(vE,Kpr),e(vE,YJ),e(YJ,Zpr),e(vE,e_r),e(V,o_r),e(V,FE),e(FE,xEe),e(xEe,r_r),e(FE,t_r),e(FE,KJ),e(KJ,a_r),e(FE,n_r),e(V,s_r),e(V,TE),e(TE,$Ee),e($Ee,l_r),e(TE,i_r),e(TE,ZJ),e(ZJ,d_r),e(TE,c_r),e(V,m_r),e(V,ME),e(ME,kEe),e(kEe,f_r),e(ME,g_r),e(ME,eY),e(eY,h_r),e(ME,u_r),e(V,p_r),e(V,EE),e(EE,SEe),e(SEe,__r),e(EE,b_r),e(EE,oY),e(oY,v_r),e(EE,F_r),e(V,T_r),e(V,CE),e(CE,REe),e(REe,M_r),e(CE,E_r),e(CE,rY),e(rY,C_r),e(CE,w_r),e(V,A_r),e(V,wE),e(wE,PEe),e(PEe,L_r),e(wE,y_r),e(wE,tY),e(tY,x_r),e(wE,$_r),e(V,k_r),e(V,AE),e(AE,BEe),e(BEe,S_r),e(AE,R_r),e(AE,aY),e(aY,P_r),e(AE,B_r),e(V,I_r),e(V,LE),e(LE,IEe),e(IEe,N_r),e(LE,q_r),e(LE,nY),e(nY,j_r),e(LE,D_r),e(V,G_r),e(V,yE),e(yE,NEe),e(NEe,O_r),e(yE,V_r),e(yE,sY),e(sY,X_r),e(yE,z_r),e(V,Q_r),e(V,xE),e(xE,qEe),e(qEe,W_r),e(xE,U_r),e(xE,lY),e(lY,H_r),e(xE,J_r),e(V,Y_r),e(V,$E),e($E,jEe),e(jEe,K_r),e($E,Z_r),e($E,iY),e(iY,e2r),e($E,o2r),e(V,r2r),e(V,kE),e(kE,DEe),e(DEe,t2r),e(kE,a2r),e(kE,dY),e(dY,n2r),e(kE,s2r),e(V,l2r),e(V,SE),e(SE,GEe),e(GEe,i2r),e(SE,d2r),e(SE,cY),e(cY,c2r),e(SE,m2r),e(V,f2r),e(V,RE),e(RE,OEe),e(OEe,g2r),e(RE,h2r),e(RE,mY),e(mY,u2r),e(RE,p2r),e(V,_2r),e(V,PE),e(PE,VEe),e(VEe,b2r),e(PE,v2r),e(PE,fY),e(fY,F2r),e(PE,T2r),e(V,M2r),e(V,BE),e(BE,XEe),e(XEe,E2r),e(BE,C2r),e(BE,gY),e(gY,w2r),e(BE,A2r),e(V,L2r),e(V,IE),e(IE,zEe),e(zEe,y2r),e(IE,x2r),e(IE,hY),e(hY,$2r),e(IE,k2r),e(V,S2r),e(V,NE),e(NE,QEe),e(QEe,R2r),e(NE,P2r),e(NE,uY),e(uY,B2r),e(NE,I2r),e(V,N2r),e(V,qE),e(qE,WEe),e(WEe,q2r),e(qE,j2r),e(qE,pY),e(pY,D2r),e(qE,G2r),e(V,O2r),e(V,jE),e(jE,UEe),e(UEe,V2r),e(jE,X2r),e(jE,_Y),e(_Y,z2r),e(jE,Q2r),e(V,W2r),e(V,DE),e(DE,HEe),e(HEe,U2r),e(DE,H2r),e(DE,bY),e(bY,J2r),e(DE,Y2r),e(V,K2r),e(V,GE),e(GE,JEe),e(JEe,Z2r),e(GE,ebr),e(GE,vY),e(vY,obr),e(GE,rbr),e(V,tbr),e(V,OE),e(OE,YEe),e(YEe,abr),e(OE,nbr),e(OE,FY),e(FY,sbr),e(OE,lbr),e(V,ibr),e(V,VE),e(VE,KEe),e(KEe,dbr),e(VE,cbr),e(VE,TY),e(TY,mbr),e(VE,fbr),e(V,gbr),e(V,XE),e(XE,ZEe),e(ZEe,hbr),e(XE,ubr),e(XE,MY),e(MY,pbr),e(XE,_br),e(V,bbr),e(V,zE),e(zE,e4e),e(e4e,vbr),e(zE,Fbr),e(zE,EY),e(EY,Tbr),e(zE,Mbr),e(V,Ebr),e(V,QE),e(QE,o4e),e(o4e,Cbr),e(QE,wbr),e(QE,CY),e(CY,Abr),e(QE,Lbr),e(V,ybr),e(V,WE),e(WE,r4e),e(r4e,xbr),e(WE,$br),e(WE,wY),e(wY,kbr),e(WE,Sbr),e(V,Rbr),e(V,UE),e(UE,t4e),e(t4e,Pbr),e(UE,Bbr),e(UE,AY),e(AY,Ibr),e(UE,Nbr),e(V,qbr),e(V,HE),e(HE,a4e),e(a4e,jbr),e(HE,Dbr),e(HE,LY),e(LY,Gbr),e(HE,Obr),e(V,Vbr),e(V,JE),e(JE,n4e),e(n4e,Xbr),e(JE,zbr),e(JE,yY),e(yY,Qbr),e(JE,Wbr),e(V,Ubr),e(V,YE),e(YE,s4e),e(s4e,Hbr),e(YE,Jbr),e(YE,xY),e(xY,Ybr),e(YE,Kbr),e(V,Zbr),e(V,KE),e(KE,l4e),e(l4e,e1r),e(KE,o1r),e(KE,$Y),e($Y,r1r),e(KE,t1r),e(V,a1r),e(V,ZE),e(ZE,i4e),e(i4e,n1r),e(ZE,s1r),e(ZE,kY),e(kY,l1r),e(ZE,i1r),e(V,d1r),e(V,e4),e(e4,d4e),e(d4e,c1r),e(e4,m1r),e(e4,SY),e(SY,f1r),e(e4,g1r),e(V,h1r),e(V,o4),e(o4,c4e),e(c4e,u1r),e(o4,p1r),e(o4,RY),e(RY,_1r),e(o4,b1r),e(io,v1r),e(io,r4),e(r4,F1r),e(r4,m4e),e(m4e,T1r),e(r4,M1r),e(r4,f4e),e(f4e,E1r),e(io,C1r),M(t4,io,null),b(m,HZe,_),b(m,Wd,_),e(Wd,a4),e(a4,g4e),M(p$,g4e,null),e(Wd,w1r),e(Wd,h4e),e(h4e,A1r),b(m,JZe,_),b(m,Xo,_),M(_$,Xo,null),e(Xo,L1r),e(Xo,Ud),e(Ud,y1r),e(Ud,PY),e(PY,x1r),e(Ud,$1r),e(Ud,BY),e(BY,k1r),e(Ud,S1r),e(Xo,R1r),e(Xo,b$),e(b$,P1r),e(b$,u4e),e(u4e,B1r),e(b$,I1r),e(Xo,N1r),e(Xo,Lt),M(v$,Lt,null),e(Lt,q1r),e(Lt,p4e),e(p4e,j1r),e(Lt,D1r),e(Lt,Hd),e(Hd,G1r),e(Hd,_4e),e(_4e,O1r),e(Hd,V1r),e(Hd,IY),e(IY,X1r),e(Hd,z1r),e(Lt,Q1r),M(n4,Lt,null),e(Xo,W1r),e(Xo,co),M(F$,co,null),e(co,U1r),e(co,b4e),e(b4e,H1r),e(co,J1r),e(co,sn),e(sn,Y1r),e(sn,v4e),e(v4e,K1r),e(sn,Z1r),e(sn,F4e),e(F4e,evr),e(sn,ovr),e(sn,T4e),e(T4e,rvr),e(sn,tvr),e(co,avr),e(co,M4e),e(M4e,s4),e(s4,E4e),e(E4e,nvr),e(s4,svr),e(s4,NY),e(NY,lvr),e(s4,ivr),e(co,dvr),e(co,l4),e(l4,cvr),e(l4,C4e),e(C4e,mvr),e(l4,fvr),e(l4,w4e),e(w4e,gvr),e(co,hvr),M(i4,co,null),b(m,YZe,_),b(m,Jd,_),e(Jd,d4),e(d4,A4e),M(T$,A4e,null),e(Jd,uvr),e(Jd,L4e),e(L4e,pvr),b(m,KZe,_),b(m,zo,_),M(M$,zo,null),e(zo,_vr),e(zo,Yd),e(Yd,bvr),e(Yd,qY),e(qY,vvr),e(Yd,Fvr),e(Yd,jY),e(jY,Tvr),e(Yd,Mvr),e(zo,Evr),e(zo,E$),e(E$,Cvr),e(E$,y4e),e(y4e,wvr),e(E$,Avr),e(zo,Lvr),e(zo,yt),M(C$,yt,null),e(yt,yvr),e(yt,x4e),e(x4e,xvr),e(yt,$vr),e(yt,Kd),e(Kd,kvr),e(Kd,$4e),e($4e,Svr),e(Kd,Rvr),e(Kd,DY),e(DY,Pvr),e(Kd,Bvr),e(yt,Ivr),M(c4,yt,null),e(zo,Nvr),e(zo,mo),M(w$,mo,null),e(mo,qvr),e(mo,k4e),e(k4e,jvr),e(mo,Dvr),e(mo,ln),e(ln,Gvr),e(ln,S4e),e(S4e,Ovr),e(ln,Vvr),e(ln,R4e),e(R4e,Xvr),e(ln,zvr),e(ln,P4e),e(P4e,Qvr),e(ln,Wvr),e(mo,Uvr),e(mo,Zd),e(Zd,m4),e(m4,B4e),e(B4e,Hvr),e(m4,Jvr),e(m4,GY),e(GY,Yvr),e(m4,Kvr),e(Zd,Zvr),e(Zd,f4),e(f4,I4e),e(I4e,eFr),e(f4,oFr),e(f4,OY),e(OY,rFr),e(f4,tFr),e(Zd,aFr),e(Zd,g4),e(g4,N4e),e(N4e,nFr),e(g4,sFr),e(g4,VY),e(VY,lFr),e(g4,iFr),e(mo,dFr),e(mo,h4),e(h4,cFr),e(h4,q4e),e(q4e,mFr),e(h4,fFr),e(h4,j4e),e(j4e,gFr),e(mo,hFr),M(u4,mo,null),b(m,ZZe,_),b(m,ec,_),e(ec,p4),e(p4,D4e),M(A$,D4e,null),e(ec,uFr),e(ec,G4e),e(G4e,pFr),b(m,eeo,_),b(m,Qo,_),M(L$,Qo,null),e(Qo,_Fr),e(Qo,oc),e(oc,bFr),e(oc,XY),e(XY,vFr),e(oc,FFr),e(oc,zY),e(zY,TFr),e(oc,MFr),e(Qo,EFr),e(Qo,y$),e(y$,CFr),e(y$,O4e),e(O4e,wFr),e(y$,AFr),e(Qo,LFr),e(Qo,xt),M(x$,xt,null),e(xt,yFr),e(xt,V4e),e(V4e,xFr),e(xt,$Fr),e(xt,rc),e(rc,kFr),e(rc,X4e),e(X4e,SFr),e(rc,RFr),e(rc,QY),e(QY,PFr),e(rc,BFr),e(xt,IFr),M(_4,xt,null),e(Qo,NFr),e(Qo,fo),M($$,fo,null),e(fo,qFr),e(fo,z4e),e(z4e,jFr),e(fo,DFr),e(fo,dn),e(dn,GFr),e(dn,Q4e),e(Q4e,OFr),e(dn,VFr),e(dn,W4e),e(W4e,XFr),e(dn,zFr),e(dn,U4e),e(U4e,QFr),e(dn,WFr),e(fo,UFr),e(fo,be),e(be,b4),e(b4,H4e),e(H4e,HFr),e(b4,JFr),e(b4,WY),e(WY,YFr),e(b4,KFr),e(be,ZFr),e(be,v4),e(v4,J4e),e(J4e,eTr),e(v4,oTr),e(v4,UY),e(UY,rTr),e(v4,tTr),e(be,aTr),e(be,F4),e(F4,Y4e),e(Y4e,nTr),e(F4,sTr),e(F4,HY),e(HY,lTr),e(F4,iTr),e(be,dTr),e(be,T4),e(T4,K4e),e(K4e,cTr),e(T4,mTr),e(T4,JY),e(JY,fTr),e(T4,gTr),e(be,hTr),e(be,bl),e(bl,Z4e),e(Z4e,uTr),e(bl,pTr),e(bl,YY),e(YY,_Tr),e(bl,bTr),e(bl,KY),e(KY,vTr),e(bl,FTr),e(be,TTr),e(be,M4),e(M4,eCe),e(eCe,MTr),e(M4,ETr),e(M4,ZY),e(ZY,CTr),e(M4,wTr),e(be,ATr),e(be,vl),e(vl,oCe),e(oCe,LTr),e(vl,yTr),e(vl,eK),e(eK,xTr),e(vl,$Tr),e(vl,oK),e(oK,kTr),e(vl,STr),e(be,RTr),e(be,E4),e(E4,rCe),e(rCe,PTr),e(E4,BTr),e(E4,rK),e(rK,ITr),e(E4,NTr),e(be,qTr),e(be,$t),e($t,tCe),e(tCe,jTr),e($t,DTr),e($t,tK),e(tK,GTr),e($t,OTr),e($t,aK),e(aK,VTr),e($t,XTr),e($t,nK),e(nK,zTr),e($t,QTr),e(be,WTr),e(be,C4),e(C4,aCe),e(aCe,UTr),e(C4,HTr),e(C4,sK),e(sK,JTr),e(C4,YTr),e(be,KTr),e(be,w4),e(w4,nCe),e(nCe,ZTr),e(w4,eMr),e(w4,lK),e(lK,oMr),e(w4,rMr),e(be,tMr),e(be,A4),e(A4,sCe),e(sCe,aMr),e(A4,nMr),e(A4,iK),e(iK,sMr),e(A4,lMr),e(be,iMr),e(be,L4),e(L4,lCe),e(lCe,dMr),e(L4,cMr),e(L4,dK),e(dK,mMr),e(L4,fMr),e(be,gMr),e(be,y4),e(y4,iCe),e(iCe,hMr),e(y4,uMr),e(y4,cK),e(cK,pMr),e(y4,_Mr),e(be,bMr),e(be,x4),e(x4,dCe),e(dCe,vMr),e(x4,FMr),e(x4,mK),e(mK,TMr),e(x4,MMr),e(be,EMr),e(be,$4),e($4,cCe),e(cCe,CMr),e($4,wMr),e($4,fK),e(fK,AMr),e($4,LMr),e(be,yMr),e(be,k4),e(k4,mCe),e(mCe,xMr),e(k4,$Mr),e(k4,gK),e(gK,kMr),e(k4,SMr),e(be,RMr),e(be,S4),e(S4,fCe),e(fCe,PMr),e(S4,BMr),e(S4,hK),e(hK,IMr),e(S4,NMr),e(fo,qMr),e(fo,R4),e(R4,jMr),e(R4,gCe),e(gCe,DMr),e(R4,GMr),e(R4,hCe),e(hCe,OMr),e(fo,VMr),M(P4,fo,null),b(m,oeo,_),b(m,tc,_),e(tc,B4),e(B4,uCe),M(k$,uCe,null),e(tc,XMr),e(tc,pCe),e(pCe,zMr),b(m,reo,_),b(m,Wo,_),M(S$,Wo,null),e(Wo,QMr),e(Wo,ac),e(ac,WMr),e(ac,uK),e(uK,UMr),e(ac,HMr),e(ac,pK),e(pK,JMr),e(ac,YMr),e(Wo,KMr),e(Wo,R$),e(R$,ZMr),e(R$,_Ce),e(_Ce,eEr),e(R$,oEr),e(Wo,rEr),e(Wo,kt),M(P$,kt,null),e(kt,tEr),e(kt,bCe),e(bCe,aEr),e(kt,nEr),e(kt,nc),e(nc,sEr),e(nc,vCe),e(vCe,lEr),e(nc,iEr),e(nc,_K),e(_K,dEr),e(nc,cEr),e(kt,mEr),M(I4,kt,null),e(Wo,fEr),e(Wo,go),M(B$,go,null),e(go,gEr),e(go,FCe),e(FCe,hEr),e(go,uEr),e(go,cn),e(cn,pEr),e(cn,TCe),e(TCe,_Er),e(cn,bEr),e(cn,MCe),e(MCe,vEr),e(cn,FEr),e(cn,ECe),e(ECe,TEr),e(cn,MEr),e(go,EEr),e(go,CCe),e(CCe,N4),e(N4,wCe),e(wCe,CEr),e(N4,wEr),e(N4,bK),e(bK,AEr),e(N4,LEr),e(go,yEr),e(go,q4),e(q4,xEr),e(q4,ACe),e(ACe,$Er),e(q4,kEr),e(q4,LCe),e(LCe,SEr),e(go,REr),M(j4,go,null),b(m,teo,_),b(m,sc,_),e(sc,D4),e(D4,yCe),M(I$,yCe,null),e(sc,PEr),e(sc,xCe),e(xCe,BEr),b(m,aeo,_),b(m,Uo,_),M(N$,Uo,null),e(Uo,IEr),e(Uo,lc),e(lc,NEr),e(lc,vK),e(vK,qEr),e(lc,jEr),e(lc,FK),e(FK,DEr),e(lc,GEr),e(Uo,OEr),e(Uo,q$),e(q$,VEr),e(q$,$Ce),e($Ce,XEr),e(q$,zEr),e(Uo,QEr),e(Uo,St),M(j$,St,null),e(St,WEr),e(St,kCe),e(kCe,UEr),e(St,HEr),e(St,ic),e(ic,JEr),e(ic,SCe),e(SCe,YEr),e(ic,KEr),e(ic,TK),e(TK,ZEr),e(ic,e4r),e(St,o4r),M(G4,St,null),e(Uo,r4r),e(Uo,ho),M(D$,ho,null),e(ho,t4r),e(ho,RCe),e(RCe,a4r),e(ho,n4r),e(ho,mn),e(mn,s4r),e(mn,PCe),e(PCe,l4r),e(mn,i4r),e(mn,BCe),e(BCe,d4r),e(mn,c4r),e(mn,ICe),e(ICe,m4r),e(mn,f4r),e(ho,g4r),e(ho,NCe),e(NCe,O4),e(O4,qCe),e(qCe,h4r),e(O4,u4r),e(O4,MK),e(MK,p4r),e(O4,_4r),e(ho,b4r),e(ho,V4),e(V4,v4r),e(V4,jCe),e(jCe,F4r),e(V4,T4r),e(V4,DCe),e(DCe,M4r),e(ho,E4r),M(X4,ho,null),b(m,neo,_),b(m,dc,_),e(dc,z4),e(z4,GCe),M(G$,GCe,null),e(dc,C4r),e(dc,OCe),e(OCe,w4r),b(m,seo,_),b(m,Ho,_),M(O$,Ho,null),e(Ho,A4r),e(Ho,cc),e(cc,L4r),e(cc,EK),e(EK,y4r),e(cc,x4r),e(cc,CK),e(CK,$4r),e(cc,k4r),e(Ho,S4r),e(Ho,V$),e(V$,R4r),e(V$,VCe),e(VCe,P4r),e(V$,B4r),e(Ho,I4r),e(Ho,Rt),M(X$,Rt,null),e(Rt,N4r),e(Rt,XCe),e(XCe,q4r),e(Rt,j4r),e(Rt,mc),e(mc,D4r),e(mc,zCe),e(zCe,G4r),e(mc,O4r),e(mc,wK),e(wK,V4r),e(mc,X4r),e(Rt,z4r),M(Q4,Rt,null),e(Ho,Q4r),e(Ho,uo),M(z$,uo,null),e(uo,W4r),e(uo,QCe),e(QCe,U4r),e(uo,H4r),e(uo,fn),e(fn,J4r),e(fn,WCe),e(WCe,Y4r),e(fn,K4r),e(fn,UCe),e(UCe,Z4r),e(fn,eCr),e(fn,HCe),e(HCe,oCr),e(fn,rCr),e(uo,tCr),e(uo,JCe),e(JCe,W4),e(W4,YCe),e(YCe,aCr),e(W4,nCr),e(W4,AK),e(AK,sCr),e(W4,lCr),e(uo,iCr),e(uo,U4),e(U4,dCr),e(U4,KCe),e(KCe,cCr),e(U4,mCr),e(U4,ZCe),e(ZCe,fCr),e(uo,gCr),M(H4,uo,null),b(m,leo,_),b(m,fc,_),e(fc,J4),e(J4,e3e),M(Q$,e3e,null),e(fc,hCr),e(fc,o3e),e(o3e,uCr),b(m,ieo,_),b(m,Jo,_),M(W$,Jo,null),e(Jo,pCr),e(Jo,gc),e(gc,_Cr),e(gc,LK),e(LK,bCr),e(gc,vCr),e(gc,yK),e(yK,FCr),e(gc,TCr),e(Jo,MCr),e(Jo,U$),e(U$,ECr),e(U$,r3e),e(r3e,CCr),e(U$,wCr),e(Jo,ACr),e(Jo,Pt),M(H$,Pt,null),e(Pt,LCr),e(Pt,t3e),e(t3e,yCr),e(Pt,xCr),e(Pt,hc),e(hc,$Cr),e(hc,a3e),e(a3e,kCr),e(hc,SCr),e(hc,xK),e(xK,RCr),e(hc,PCr),e(Pt,BCr),M(Y4,Pt,null),e(Jo,ICr),e(Jo,po),M(J$,po,null),e(po,NCr),e(po,n3e),e(n3e,qCr),e(po,jCr),e(po,gn),e(gn,DCr),e(gn,s3e),e(s3e,GCr),e(gn,OCr),e(gn,l3e),e(l3e,VCr),e(gn,XCr),e(gn,i3e),e(i3e,zCr),e(gn,QCr),e(po,WCr),e(po,Pe),e(Pe,K4),e(K4,d3e),e(d3e,UCr),e(K4,HCr),e(K4,$K),e($K,JCr),e(K4,YCr),e(Pe,KCr),e(Pe,Z4),e(Z4,c3e),e(c3e,ZCr),e(Z4,e3r),e(Z4,kK),e(kK,o3r),e(Z4,r3r),e(Pe,t3r),e(Pe,eC),e(eC,m3e),e(m3e,a3r),e(eC,n3r),e(eC,SK),e(SK,s3r),e(eC,l3r),e(Pe,i3r),e(Pe,oC),e(oC,f3e),e(f3e,d3r),e(oC,c3r),e(oC,RK),e(RK,m3r),e(oC,f3r),e(Pe,g3r),e(Pe,rC),e(rC,g3e),e(g3e,h3r),e(rC,u3r),e(rC,PK),e(PK,p3r),e(rC,_3r),e(Pe,b3r),e(Pe,tC),e(tC,h3e),e(h3e,v3r),e(tC,F3r),e(tC,BK),e(BK,T3r),e(tC,M3r),e(Pe,E3r),e(Pe,aC),e(aC,u3e),e(u3e,C3r),e(aC,w3r),e(aC,IK),e(IK,A3r),e(aC,L3r),e(Pe,y3r),e(Pe,nC),e(nC,p3e),e(p3e,x3r),e(nC,$3r),e(nC,NK),e(NK,k3r),e(nC,S3r),e(Pe,R3r),e(Pe,sC),e(sC,_3e),e(_3e,P3r),e(sC,B3r),e(sC,qK),e(qK,I3r),e(sC,N3r),e(po,q3r),e(po,lC),e(lC,j3r),e(lC,b3e),e(b3e,D3r),e(lC,G3r),e(lC,v3e),e(v3e,O3r),e(po,V3r),M(iC,po,null),b(m,deo,_),b(m,uc,_),e(uc,dC),e(dC,F3e),M(Y$,F3e,null),e(uc,X3r),e(uc,T3e),e(T3e,z3r),b(m,ceo,_),b(m,Yo,_),M(K$,Yo,null),e(Yo,Q3r),e(Yo,pc),e(pc,W3r),e(pc,jK),e(jK,U3r),e(pc,H3r),e(pc,DK),e(DK,J3r),e(pc,Y3r),e(Yo,K3r),e(Yo,Z$),e(Z$,Z3r),e(Z$,M3e),e(M3e,e5r),e(Z$,o5r),e(Yo,r5r),e(Yo,Bt),M(ek,Bt,null),e(Bt,t5r),e(Bt,E3e),e(E3e,a5r),e(Bt,n5r),e(Bt,_c),e(_c,s5r),e(_c,C3e),e(C3e,l5r),e(_c,i5r),e(_c,GK),e(GK,d5r),e(_c,c5r),e(Bt,m5r),M(cC,Bt,null),e(Yo,f5r),e(Yo,_o),M(ok,_o,null),e(_o,g5r),e(_o,w3e),e(w3e,h5r),e(_o,u5r),e(_o,hn),e(hn,p5r),e(hn,A3e),e(A3e,_5r),e(hn,b5r),e(hn,L3e),e(L3e,v5r),e(hn,F5r),e(hn,y3e),e(y3e,T5r),e(hn,M5r),e(_o,E5r),e(_o,mt),e(mt,mC),e(mC,x3e),e(x3e,C5r),e(mC,w5r),e(mC,OK),e(OK,A5r),e(mC,L5r),e(mt,y5r),e(mt,fC),e(fC,$3e),e($3e,x5r),e(fC,$5r),e(fC,VK),e(VK,k5r),e(fC,S5r),e(mt,R5r),e(mt,gC),e(gC,k3e),e(k3e,P5r),e(gC,B5r),e(gC,XK),e(XK,I5r),e(gC,N5r),e(mt,q5r),e(mt,hC),e(hC,S3e),e(S3e,j5r),e(hC,D5r),e(hC,zK),e(zK,G5r),e(hC,O5r),e(mt,V5r),e(mt,uC),e(uC,R3e),e(R3e,X5r),e(uC,z5r),e(uC,QK),e(QK,Q5r),e(uC,W5r),e(_o,U5r),e(_o,pC),e(pC,H5r),e(pC,P3e),e(P3e,J5r),e(pC,Y5r),e(pC,B3e),e(B3e,K5r),e(_o,Z5r),M(_C,_o,null),b(m,meo,_),b(m,bc,_),e(bc,bC),e(bC,I3e),M(rk,I3e,null),e(bc,e0r),e(bc,N3e),e(N3e,o0r),b(m,feo,_),b(m,Ko,_),M(tk,Ko,null),e(Ko,r0r),e(Ko,vc),e(vc,t0r),e(vc,WK),e(WK,a0r),e(vc,n0r),e(vc,UK),e(UK,s0r),e(vc,l0r),e(Ko,i0r),e(Ko,ak),e(ak,d0r),e(ak,q3e),e(q3e,c0r),e(ak,m0r),e(Ko,f0r),e(Ko,It),M(nk,It,null),e(It,g0r),e(It,j3e),e(j3e,h0r),e(It,u0r),e(It,Fc),e(Fc,p0r),e(Fc,D3e),e(D3e,_0r),e(Fc,b0r),e(Fc,HK),e(HK,v0r),e(Fc,F0r),e(It,T0r),M(vC,It,null),e(Ko,M0r),e(Ko,bo),M(sk,bo,null),e(bo,E0r),e(bo,G3e),e(G3e,C0r),e(bo,w0r),e(bo,un),e(un,A0r),e(un,O3e),e(O3e,L0r),e(un,y0r),e(un,V3e),e(V3e,x0r),e(un,$0r),e(un,X3e),e(X3e,k0r),e(un,S0r),e(bo,R0r),e(bo,Le),e(Le,FC),e(FC,z3e),e(z3e,P0r),e(FC,B0r),e(FC,JK),e(JK,I0r),e(FC,N0r),e(Le,q0r),e(Le,TC),e(TC,Q3e),e(Q3e,j0r),e(TC,D0r),e(TC,YK),e(YK,G0r),e(TC,O0r),e(Le,V0r),e(Le,MC),e(MC,W3e),e(W3e,X0r),e(MC,z0r),e(MC,KK),e(KK,Q0r),e(MC,W0r),e(Le,U0r),e(Le,EC),e(EC,U3e),e(U3e,H0r),e(EC,J0r),e(EC,ZK),e(ZK,Y0r),e(EC,K0r),e(Le,Z0r),e(Le,CC),e(CC,H3e),e(H3e,ewr),e(CC,owr),e(CC,eZ),e(eZ,rwr),e(CC,twr),e(Le,awr),e(Le,wC),e(wC,J3e),e(J3e,nwr),e(wC,swr),e(wC,oZ),e(oZ,lwr),e(wC,iwr),e(Le,dwr),e(Le,AC),e(AC,Y3e),e(Y3e,cwr),e(AC,mwr),e(AC,rZ),e(rZ,fwr),e(AC,gwr),e(Le,hwr),e(Le,LC),e(LC,K3e),e(K3e,uwr),e(LC,pwr),e(LC,tZ),e(tZ,_wr),e(LC,bwr),e(Le,vwr),e(Le,yC),e(yC,Z3e),e(Z3e,Fwr),e(yC,Twr),e(yC,aZ),e(aZ,Mwr),e(yC,Ewr),e(Le,Cwr),e(Le,xC),e(xC,e5e),e(e5e,wwr),e(xC,Awr),e(xC,nZ),e(nZ,Lwr),e(xC,ywr),e(bo,xwr),e(bo,$C),e($C,$wr),e($C,o5e),e(o5e,kwr),e($C,Swr),e($C,r5e),e(r5e,Rwr),e(bo,Pwr),M(kC,bo,null),b(m,geo,_),b(m,Tc,_),e(Tc,SC),e(SC,t5e),M(lk,t5e,null),e(Tc,Bwr),e(Tc,a5e),e(a5e,Iwr),b(m,heo,_),b(m,Zo,_),M(ik,Zo,null),e(Zo,Nwr),e(Zo,Mc),e(Mc,qwr),e(Mc,sZ),e(sZ,jwr),e(Mc,Dwr),e(Mc,lZ),e(lZ,Gwr),e(Mc,Owr),e(Zo,Vwr),e(Zo,dk),e(dk,Xwr),e(dk,n5e),e(n5e,zwr),e(dk,Qwr),e(Zo,Wwr),e(Zo,Nt),M(ck,Nt,null),e(Nt,Uwr),e(Nt,s5e),e(s5e,Hwr),e(Nt,Jwr),e(Nt,Ec),e(Ec,Ywr),e(Ec,l5e),e(l5e,Kwr),e(Ec,Zwr),e(Ec,iZ),e(iZ,eAr),e(Ec,oAr),e(Nt,rAr),M(RC,Nt,null),e(Zo,tAr),e(Zo,vo),M(mk,vo,null),e(vo,aAr),e(vo,i5e),e(i5e,nAr),e(vo,sAr),e(vo,pn),e(pn,lAr),e(pn,d5e),e(d5e,iAr),e(pn,dAr),e(pn,c5e),e(c5e,cAr),e(pn,mAr),e(pn,m5e),e(m5e,fAr),e(pn,gAr),e(vo,hAr),e(vo,fk),e(fk,PC),e(PC,f5e),e(f5e,uAr),e(PC,pAr),e(PC,dZ),e(dZ,_Ar),e(PC,bAr),e(fk,vAr),e(fk,BC),e(BC,g5e),e(g5e,FAr),e(BC,TAr),e(BC,cZ),e(cZ,MAr),e(BC,EAr),e(vo,CAr),e(vo,IC),e(IC,wAr),e(IC,h5e),e(h5e,AAr),e(IC,LAr),e(IC,u5e),e(u5e,yAr),e(vo,xAr),M(NC,vo,null),b(m,ueo,_),b(m,Cc,_),e(Cc,qC),e(qC,p5e),M(gk,p5e,null),e(Cc,$Ar),e(Cc,_5e),e(_5e,kAr),b(m,peo,_),b(m,er,_),M(hk,er,null),e(er,SAr),e(er,wc),e(wc,RAr),e(wc,mZ),e(mZ,PAr),e(wc,BAr),e(wc,fZ),e(fZ,IAr),e(wc,NAr),e(er,qAr),e(er,uk),e(uk,jAr),e(uk,b5e),e(b5e,DAr),e(uk,GAr),e(er,OAr),e(er,qt),M(pk,qt,null),e(qt,VAr),e(qt,v5e),e(v5e,XAr),e(qt,zAr),e(qt,Ac),e(Ac,QAr),e(Ac,F5e),e(F5e,WAr),e(Ac,UAr),e(Ac,gZ),e(gZ,HAr),e(Ac,JAr),e(qt,YAr),M(jC,qt,null),e(er,KAr),e(er,Fo),M(_k,Fo,null),e(Fo,ZAr),e(Fo,T5e),e(T5e,e6r),e(Fo,o6r),e(Fo,_n),e(_n,r6r),e(_n,M5e),e(M5e,t6r),e(_n,a6r),e(_n,E5e),e(E5e,n6r),e(_n,s6r),e(_n,C5e),e(C5e,l6r),e(_n,i6r),e(Fo,d6r),e(Fo,ft),e(ft,DC),e(DC,w5e),e(w5e,c6r),e(DC,m6r),e(DC,hZ),e(hZ,f6r),e(DC,g6r),e(ft,h6r),e(ft,GC),e(GC,A5e),e(A5e,u6r),e(GC,p6r),e(GC,uZ),e(uZ,_6r),e(GC,b6r),e(ft,v6r),e(ft,OC),e(OC,L5e),e(L5e,F6r),e(OC,T6r),e(OC,pZ),e(pZ,M6r),e(OC,E6r),e(ft,C6r),e(ft,VC),e(VC,y5e),e(y5e,w6r),e(VC,A6r),e(VC,_Z),e(_Z,L6r),e(VC,y6r),e(ft,x6r),e(ft,XC),e(XC,x5e),e(x5e,$6r),e(XC,k6r),e(XC,bZ),e(bZ,S6r),e(XC,R6r),e(Fo,P6r),e(Fo,zC),e(zC,B6r),e(zC,$5e),e($5e,I6r),e(zC,N6r),e(zC,k5e),e(k5e,q6r),e(Fo,j6r),M(QC,Fo,null),b(m,_eo,_),b(m,Lc,_),e(Lc,WC),e(WC,S5e),M(bk,S5e,null),e(Lc,D6r),e(Lc,R5e),e(R5e,G6r),b(m,beo,_),b(m,or,_),M(vk,or,null),e(or,O6r),e(or,yc),e(yc,V6r),e(yc,vZ),e(vZ,X6r),e(yc,z6r),e(yc,FZ),e(FZ,Q6r),e(yc,W6r),e(or,U6r),e(or,Fk),e(Fk,H6r),e(Fk,P5e),e(P5e,J6r),e(Fk,Y6r),e(or,K6r),e(or,jt),M(Tk,jt,null),e(jt,Z6r),e(jt,B5e),e(B5e,e7r),e(jt,o7r),e(jt,xc),e(xc,r7r),e(xc,I5e),e(I5e,t7r),e(xc,a7r),e(xc,TZ),e(TZ,n7r),e(xc,s7r),e(jt,l7r),M(UC,jt,null),e(or,i7r),e(or,To),M(Mk,To,null),e(To,d7r),e(To,N5e),e(N5e,c7r),e(To,m7r),e(To,bn),e(bn,f7r),e(bn,q5e),e(q5e,g7r),e(bn,h7r),e(bn,j5e),e(j5e,u7r),e(bn,p7r),e(bn,D5e),e(D5e,_7r),e(bn,b7r),e(To,v7r),e(To,vn),e(vn,HC),e(HC,G5e),e(G5e,F7r),e(HC,T7r),e(HC,MZ),e(MZ,M7r),e(HC,E7r),e(vn,C7r),e(vn,JC),e(JC,O5e),e(O5e,w7r),e(JC,A7r),e(JC,EZ),e(EZ,L7r),e(JC,y7r),e(vn,x7r),e(vn,YC),e(YC,V5e),e(V5e,$7r),e(YC,k7r),e(YC,CZ),e(CZ,S7r),e(YC,R7r),e(vn,P7r),e(vn,KC),e(KC,X5e),e(X5e,B7r),e(KC,I7r),e(KC,wZ),e(wZ,N7r),e(KC,q7r),e(To,j7r),e(To,ZC),e(ZC,D7r),e(ZC,z5e),e(z5e,G7r),e(ZC,O7r),e(ZC,Q5e),e(Q5e,V7r),e(To,X7r),M(e3,To,null),b(m,veo,_),b(m,$c,_),e($c,o3),e(o3,W5e),M(Ek,W5e,null),e($c,z7r),e($c,U5e),e(U5e,Q7r),b(m,Feo,_),b(m,rr,_),M(Ck,rr,null),e(rr,W7r),e(rr,kc),e(kc,U7r),e(kc,AZ),e(AZ,H7r),e(kc,J7r),e(kc,LZ),e(LZ,Y7r),e(kc,K7r),e(rr,Z7r),e(rr,wk),e(wk,eLr),e(wk,H5e),e(H5e,oLr),e(wk,rLr),e(rr,tLr),e(rr,Dt),M(Ak,Dt,null),e(Dt,aLr),e(Dt,J5e),e(J5e,nLr),e(Dt,sLr),e(Dt,Sc),e(Sc,lLr),e(Sc,Y5e),e(Y5e,iLr),e(Sc,dLr),e(Sc,yZ),e(yZ,cLr),e(Sc,mLr),e(Dt,fLr),M(r3,Dt,null),e(rr,gLr),e(rr,Mo),M(Lk,Mo,null),e(Mo,hLr),e(Mo,K5e),e(K5e,uLr),e(Mo,pLr),e(Mo,Fn),e(Fn,_Lr),e(Fn,Z5e),e(Z5e,bLr),e(Fn,vLr),e(Fn,e0e),e(e0e,FLr),e(Fn,TLr),e(Fn,o0e),e(o0e,MLr),e(Fn,ELr),e(Mo,CLr),e(Mo,Tn),e(Tn,t3),e(t3,r0e),e(r0e,wLr),e(t3,ALr),e(t3,xZ),e(xZ,LLr),e(t3,yLr),e(Tn,xLr),e(Tn,a3),e(a3,t0e),e(t0e,$Lr),e(a3,kLr),e(a3,$Z),e($Z,SLr),e(a3,RLr),e(Tn,PLr),e(Tn,n3),e(n3,a0e),e(a0e,BLr),e(n3,ILr),e(n3,kZ),e(kZ,NLr),e(n3,qLr),e(Tn,jLr),e(Tn,s3),e(s3,n0e),e(n0e,DLr),e(s3,GLr),e(s3,SZ),e(SZ,OLr),e(s3,VLr),e(Mo,XLr),e(Mo,l3),e(l3,zLr),e(l3,s0e),e(s0e,QLr),e(l3,WLr),e(l3,l0e),e(l0e,ULr),e(Mo,HLr),M(i3,Mo,null),b(m,Teo,_),b(m,Rc,_),e(Rc,d3),e(d3,i0e),M(yk,i0e,null),e(Rc,JLr),e(Rc,d0e),e(d0e,YLr),b(m,Meo,_),b(m,tr,_),M(xk,tr,null),e(tr,KLr),e(tr,Pc),e(Pc,ZLr),e(Pc,RZ),e(RZ,eyr),e(Pc,oyr),e(Pc,PZ),e(PZ,ryr),e(Pc,tyr),e(tr,ayr),e(tr,$k),e($k,nyr),e($k,c0e),e(c0e,syr),e($k,lyr),e(tr,iyr),e(tr,Gt),M(kk,Gt,null),e(Gt,dyr),e(Gt,m0e),e(m0e,cyr),e(Gt,myr),e(Gt,Bc),e(Bc,fyr),e(Bc,f0e),e(f0e,gyr),e(Bc,hyr),e(Bc,BZ),e(BZ,uyr),e(Bc,pyr),e(Gt,_yr),M(c3,Gt,null),e(tr,byr),e(tr,Eo),M(Sk,Eo,null),e(Eo,vyr),e(Eo,g0e),e(g0e,Fyr),e(Eo,Tyr),e(Eo,Mn),e(Mn,Myr),e(Mn,h0e),e(h0e,Eyr),e(Mn,Cyr),e(Mn,u0e),e(u0e,wyr),e(Mn,Ayr),e(Mn,p0e),e(p0e,Lyr),e(Mn,yyr),e(Eo,xyr),e(Eo,_0e),e(_0e,m3),e(m3,b0e),e(b0e,$yr),e(m3,kyr),e(m3,IZ),e(IZ,Syr),e(m3,Ryr),e(Eo,Pyr),e(Eo,f3),e(f3,Byr),e(f3,v0e),e(v0e,Iyr),e(f3,Nyr),e(f3,F0e),e(F0e,qyr),e(Eo,jyr),M(g3,Eo,null),b(m,Eeo,_),b(m,Ic,_),e(Ic,h3),e(h3,T0e),M(Rk,T0e,null),e(Ic,Dyr),e(Ic,M0e),e(M0e,Gyr),b(m,Ceo,_),b(m,ar,_),M(Pk,ar,null),e(ar,Oyr),e(ar,Nc),e(Nc,Vyr),e(Nc,NZ),e(NZ,Xyr),e(Nc,zyr),e(Nc,qZ),e(qZ,Qyr),e(Nc,Wyr),e(ar,Uyr),e(ar,Bk),e(Bk,Hyr),e(Bk,E0e),e(E0e,Jyr),e(Bk,Yyr),e(ar,Kyr),e(ar,Ot),M(Ik,Ot,null),e(Ot,Zyr),e(Ot,C0e),e(C0e,e8r),e(Ot,o8r),e(Ot,qc),e(qc,r8r),e(qc,w0e),e(w0e,t8r),e(qc,a8r),e(qc,jZ),e(jZ,n8r),e(qc,s8r),e(Ot,l8r),M(u3,Ot,null),e(ar,i8r),e(ar,Co),M(Nk,Co,null),e(Co,d8r),e(Co,A0e),e(A0e,c8r),e(Co,m8r),e(Co,En),e(En,f8r),e(En,L0e),e(L0e,g8r),e(En,h8r),e(En,y0e),e(y0e,u8r),e(En,p8r),e(En,x0e),e(x0e,_8r),e(En,b8r),e(Co,v8r),e(Co,gt),e(gt,p3),e(p3,$0e),e($0e,F8r),e(p3,T8r),e(p3,DZ),e(DZ,M8r),e(p3,E8r),e(gt,C8r),e(gt,_3),e(_3,k0e),e(k0e,w8r),e(_3,A8r),e(_3,GZ),e(GZ,L8r),e(_3,y8r),e(gt,x8r),e(gt,b3),e(b3,S0e),e(S0e,$8r),e(b3,k8r),e(b3,OZ),e(OZ,S8r),e(b3,R8r),e(gt,P8r),e(gt,v3),e(v3,R0e),e(R0e,B8r),e(v3,I8r),e(v3,VZ),e(VZ,N8r),e(v3,q8r),e(gt,j8r),e(gt,F3),e(F3,P0e),e(P0e,D8r),e(F3,G8r),e(F3,XZ),e(XZ,O8r),e(F3,V8r),e(Co,X8r),e(Co,T3),e(T3,z8r),e(T3,B0e),e(B0e,Q8r),e(T3,W8r),e(T3,I0e),e(I0e,U8r),e(Co,H8r),M(M3,Co,null),b(m,weo,_),b(m,jc,_),e(jc,E3),e(E3,N0e),M(qk,N0e,null),e(jc,J8r),e(jc,q0e),e(q0e,Y8r),b(m,Aeo,_),b(m,nr,_),M(jk,nr,null),e(nr,K8r),e(nr,Dc),e(Dc,Z8r),e(Dc,zZ),e(zZ,e9r),e(Dc,o9r),e(Dc,QZ),e(QZ,r9r),e(Dc,t9r),e(nr,a9r),e(nr,Dk),e(Dk,n9r),e(Dk,j0e),e(j0e,s9r),e(Dk,l9r),e(nr,i9r),e(nr,Vt),M(Gk,Vt,null),e(Vt,d9r),e(Vt,D0e),e(D0e,c9r),e(Vt,m9r),e(Vt,Gc),e(Gc,f9r),e(Gc,G0e),e(G0e,g9r),e(Gc,h9r),e(Gc,WZ),e(WZ,u9r),e(Gc,p9r),e(Vt,_9r),M(C3,Vt,null),e(nr,b9r),e(nr,wo),M(Ok,wo,null),e(wo,v9r),e(wo,O0e),e(O0e,F9r),e(wo,T9r),e(wo,Cn),e(Cn,M9r),e(Cn,V0e),e(V0e,E9r),e(Cn,C9r),e(Cn,X0e),e(X0e,w9r),e(Cn,A9r),e(Cn,z0e),e(z0e,L9r),e(Cn,y9r),e(wo,x9r),e(wo,Q0e),e(Q0e,w3),e(w3,W0e),e(W0e,$9r),e(w3,k9r),e(w3,UZ),e(UZ,S9r),e(w3,R9r),e(wo,P9r),e(wo,A3),e(A3,B9r),e(A3,U0e),e(U0e,I9r),e(A3,N9r),e(A3,H0e),e(H0e,q9r),e(wo,j9r),M(L3,wo,null),b(m,Leo,_),b(m,Oc,_),e(Oc,y3),e(y3,J0e),M(Vk,J0e,null),e(Oc,D9r),e(Oc,Y0e),e(Y0e,G9r),b(m,yeo,_),b(m,sr,_),M(Xk,sr,null),e(sr,O9r),e(sr,Vc),e(Vc,V9r),e(Vc,HZ),e(HZ,X9r),e(Vc,z9r),e(Vc,JZ),e(JZ,Q9r),e(Vc,W9r),e(sr,U9r),e(sr,zk),e(zk,H9r),e(zk,K0e),e(K0e,J9r),e(zk,Y9r),e(sr,K9r),e(sr,Xt),M(Qk,Xt,null),e(Xt,Z9r),e(Xt,Z0e),e(Z0e,exr),e(Xt,oxr),e(Xt,Xc),e(Xc,rxr),e(Xc,ewe),e(ewe,txr),e(Xc,axr),e(Xc,YZ),e(YZ,nxr),e(Xc,sxr),e(Xt,lxr),M(x3,Xt,null),e(sr,ixr),e(sr,Ir),M(Wk,Ir,null),e(Ir,dxr),e(Ir,owe),e(owe,cxr),e(Ir,mxr),e(Ir,wn),e(wn,fxr),e(wn,rwe),e(rwe,gxr),e(wn,hxr),e(wn,twe),e(twe,uxr),e(wn,pxr),e(wn,awe),e(awe,_xr),e(wn,bxr),e(Ir,vxr),e(Ir,B),e(B,$3),e($3,nwe),e(nwe,Fxr),e($3,Txr),e($3,KZ),e(KZ,Mxr),e($3,Exr),e(B,Cxr),e(B,k3),e(k3,swe),e(swe,wxr),e(k3,Axr),e(k3,ZZ),e(ZZ,Lxr),e(k3,yxr),e(B,xxr),e(B,S3),e(S3,lwe),e(lwe,$xr),e(S3,kxr),e(S3,eee),e(eee,Sxr),e(S3,Rxr),e(B,Pxr),e(B,R3),e(R3,iwe),e(iwe,Bxr),e(R3,Ixr),e(R3,oee),e(oee,Nxr),e(R3,qxr),e(B,jxr),e(B,P3),e(P3,dwe),e(dwe,Dxr),e(P3,Gxr),e(P3,ree),e(ree,Oxr),e(P3,Vxr),e(B,Xxr),e(B,B3),e(B3,cwe),e(cwe,zxr),e(B3,Qxr),e(B3,tee),e(tee,Wxr),e(B3,Uxr),e(B,Hxr),e(B,I3),e(I3,mwe),e(mwe,Jxr),e(I3,Yxr),e(I3,aee),e(aee,Kxr),e(I3,Zxr),e(B,e$r),e(B,N3),e(N3,fwe),e(fwe,o$r),e(N3,r$r),e(N3,nee),e(nee,t$r),e(N3,a$r),e(B,n$r),e(B,q3),e(q3,gwe),e(gwe,s$r),e(q3,l$r),e(q3,see),e(see,i$r),e(q3,d$r),e(B,c$r),e(B,j3),e(j3,hwe),e(hwe,m$r),e(j3,f$r),e(j3,lee),e(lee,g$r),e(j3,h$r),e(B,u$r),e(B,D3),e(D3,uwe),e(uwe,p$r),e(D3,_$r),e(D3,iee),e(iee,b$r),e(D3,v$r),e(B,F$r),e(B,G3),e(G3,pwe),e(pwe,T$r),e(G3,M$r),e(G3,dee),e(dee,E$r),e(G3,C$r),e(B,w$r),e(B,O3),e(O3,_we),e(_we,A$r),e(O3,L$r),e(O3,cee),e(cee,y$r),e(O3,x$r),e(B,$$r),e(B,V3),e(V3,bwe),e(bwe,k$r),e(V3,S$r),e(V3,mee),e(mee,R$r),e(V3,P$r),e(B,B$r),e(B,X3),e(X3,vwe),e(vwe,I$r),e(X3,N$r),e(X3,fee),e(fee,q$r),e(X3,j$r),e(B,D$r),e(B,z3),e(z3,Fwe),e(Fwe,G$r),e(z3,O$r),e(z3,gee),e(gee,V$r),e(z3,X$r),e(B,z$r),e(B,Q3),e(Q3,Twe),e(Twe,Q$r),e(Q3,W$r),e(Q3,hee),e(hee,U$r),e(Q3,H$r),e(B,J$r),e(B,W3),e(W3,Mwe),e(Mwe,Y$r),e(W3,K$r),e(W3,uee),e(uee,Z$r),e(W3,ekr),e(B,okr),e(B,Fl),e(Fl,Ewe),e(Ewe,rkr),e(Fl,tkr),e(Fl,pee),e(pee,akr),e(Fl,nkr),e(Fl,_ee),e(_ee,skr),e(Fl,lkr),e(B,ikr),e(B,U3),e(U3,Cwe),e(Cwe,dkr),e(U3,ckr),e(U3,bee),e(bee,mkr),e(U3,fkr),e(B,gkr),e(B,H3),e(H3,wwe),e(wwe,hkr),e(H3,ukr),e(H3,vee),e(vee,pkr),e(H3,_kr),e(B,bkr),e(B,J3),e(J3,Awe),e(Awe,vkr),e(J3,Fkr),e(J3,Fee),e(Fee,Tkr),e(J3,Mkr),e(B,Ekr),e(B,Y3),e(Y3,Lwe),e(Lwe,Ckr),e(Y3,wkr),e(Y3,Tee),e(Tee,Akr),e(Y3,Lkr),e(B,ykr),e(B,K3),e(K3,ywe),e(ywe,xkr),e(K3,$kr),e(K3,Mee),e(Mee,kkr),e(K3,Skr),e(B,Rkr),e(B,Z3),e(Z3,xwe),e(xwe,Pkr),e(Z3,Bkr),e(Z3,Eee),e(Eee,Ikr),e(Z3,Nkr),e(B,qkr),e(B,e5),e(e5,$we),e($we,jkr),e(e5,Dkr),e(e5,Cee),e(Cee,Gkr),e(e5,Okr),e(B,Vkr),e(B,o5),e(o5,kwe),e(kwe,Xkr),e(o5,zkr),e(o5,wee),e(wee,Qkr),e(o5,Wkr),e(B,Ukr),e(B,r5),e(r5,Swe),e(Swe,Hkr),e(r5,Jkr),e(r5,Aee),e(Aee,Ykr),e(r5,Kkr),e(B,Zkr),e(B,t5),e(t5,Rwe),e(Rwe,eSr),e(t5,oSr),e(t5,Lee),e(Lee,rSr),e(t5,tSr),e(B,aSr),e(B,a5),e(a5,Pwe),e(Pwe,nSr),e(a5,sSr),e(a5,yee),e(yee,lSr),e(a5,iSr),e(B,dSr),e(B,n5),e(n5,Bwe),e(Bwe,cSr),e(n5,mSr),e(n5,xee),e(xee,fSr),e(n5,gSr),e(B,hSr),e(B,s5),e(s5,Iwe),e(Iwe,uSr),e(s5,pSr),e(s5,$ee),e($ee,_Sr),e(s5,bSr),e(B,vSr),e(B,l5),e(l5,Nwe),e(Nwe,FSr),e(l5,TSr),e(l5,kee),e(kee,MSr),e(l5,ESr),e(B,CSr),e(B,i5),e(i5,qwe),e(qwe,wSr),e(i5,ASr),e(i5,See),e(See,LSr),e(i5,ySr),e(B,xSr),e(B,d5),e(d5,jwe),e(jwe,$Sr),e(d5,kSr),e(d5,Ree),e(Ree,SSr),e(d5,RSr),e(B,PSr),e(B,c5),e(c5,Dwe),e(Dwe,BSr),e(c5,ISr),e(c5,Pee),e(Pee,NSr),e(c5,qSr),e(B,jSr),e(B,m5),e(m5,Gwe),e(Gwe,DSr),e(m5,GSr),e(m5,Bee),e(Bee,OSr),e(m5,VSr),e(B,XSr),e(B,f5),e(f5,Owe),e(Owe,zSr),e(f5,QSr),e(f5,Iee),e(Iee,WSr),e(f5,USr),e(B,HSr),e(B,g5),e(g5,Vwe),e(Vwe,JSr),e(g5,YSr),e(g5,Nee),e(Nee,KSr),e(g5,ZSr),e(B,eRr),e(B,h5),e(h5,Xwe),e(Xwe,oRr),e(h5,rRr),e(h5,qee),e(qee,tRr),e(h5,aRr),e(B,nRr),e(B,u5),e(u5,zwe),e(zwe,sRr),e(u5,lRr),e(u5,jee),e(jee,iRr),e(u5,dRr),e(B,cRr),e(B,p5),e(p5,Qwe),e(Qwe,mRr),e(p5,fRr),e(p5,Dee),e(Dee,gRr),e(p5,hRr),e(B,uRr),e(B,_5),e(_5,Wwe),e(Wwe,pRr),e(_5,_Rr),e(_5,Gee),e(Gee,bRr),e(_5,vRr),e(B,FRr),e(B,b5),e(b5,Uwe),e(Uwe,TRr),e(b5,MRr),e(b5,Oee),e(Oee,ERr),e(b5,CRr),e(B,wRr),e(B,v5),e(v5,Hwe),e(Hwe,ARr),e(v5,LRr),e(v5,Vee),e(Vee,yRr),e(v5,xRr),e(B,$Rr),e(B,F5),e(F5,Jwe),e(Jwe,kRr),e(F5,SRr),e(F5,Xee),e(Xee,RRr),e(F5,PRr),e(B,BRr),e(B,T5),e(T5,Ywe),e(Ywe,IRr),e(T5,NRr),e(T5,zee),e(zee,qRr),e(T5,jRr),e(B,DRr),e(B,M5),e(M5,Kwe),e(Kwe,GRr),e(M5,ORr),e(M5,Qee),e(Qee,VRr),e(M5,XRr),e(B,zRr),e(B,E5),e(E5,Zwe),e(Zwe,QRr),e(E5,WRr),e(E5,Wee),e(Wee,URr),e(E5,HRr),e(B,JRr),e(B,C5),e(C5,eAe),e(eAe,YRr),e(C5,KRr),e(C5,Uee),e(Uee,ZRr),e(C5,ePr),e(B,oPr),e(B,w5),e(w5,oAe),e(oAe,rPr),e(w5,tPr),e(w5,Hee),e(Hee,aPr),e(w5,nPr),e(B,sPr),e(B,A5),e(A5,rAe),e(rAe,lPr),e(A5,iPr),e(A5,Jee),e(Jee,dPr),e(A5,cPr),e(B,mPr),e(B,L5),e(L5,tAe),e(tAe,fPr),e(L5,gPr),e(L5,Yee),e(Yee,hPr),e(L5,uPr),e(B,pPr),e(B,y5),e(y5,aAe),e(aAe,_Pr),e(y5,bPr),e(y5,Kee),e(Kee,vPr),e(y5,FPr),e(B,TPr),e(B,x5),e(x5,nAe),e(nAe,MPr),e(x5,EPr),e(x5,Zee),e(Zee,CPr),e(x5,wPr),e(Ir,APr),M($5,Ir,null),b(m,xeo,_),b(m,zc,_),e(zc,k5),e(k5,sAe),M(Uk,sAe,null),e(zc,LPr),e(zc,lAe),e(lAe,yPr),b(m,$eo,_),b(m,lr,_),M(Hk,lr,null),e(lr,xPr),e(lr,Qc),e(Qc,$Pr),e(Qc,eoe),e(eoe,kPr),e(Qc,SPr),e(Qc,ooe),e(ooe,RPr),e(Qc,PPr),e(lr,BPr),e(lr,Jk),e(Jk,IPr),e(Jk,iAe),e(iAe,NPr),e(Jk,qPr),e(lr,jPr),e(lr,zt),M(Yk,zt,null),e(zt,DPr),e(zt,dAe),e(dAe,GPr),e(zt,OPr),e(zt,Wc),e(Wc,VPr),e(Wc,cAe),e(cAe,XPr),e(Wc,zPr),e(Wc,roe),e(roe,QPr),e(Wc,WPr),e(zt,UPr),M(S5,zt,null),e(lr,HPr),e(lr,Nr),M(Kk,Nr,null),e(Nr,JPr),e(Nr,mAe),e(mAe,YPr),e(Nr,KPr),e(Nr,An),e(An,ZPr),e(An,fAe),e(fAe,eBr),e(An,oBr),e(An,gAe),e(gAe,rBr),e(An,tBr),e(An,hAe),e(hAe,aBr),e(An,nBr),e(Nr,sBr),e(Nr,se),e(se,R5),e(R5,uAe),e(uAe,lBr),e(R5,iBr),e(R5,toe),e(toe,dBr),e(R5,cBr),e(se,mBr),e(se,P5),e(P5,pAe),e(pAe,fBr),e(P5,gBr),e(P5,aoe),e(aoe,hBr),e(P5,uBr),e(se,pBr),e(se,B5),e(B5,_Ae),e(_Ae,_Br),e(B5,bBr),e(B5,noe),e(noe,vBr),e(B5,FBr),e(se,TBr),e(se,I5),e(I5,bAe),e(bAe,MBr),e(I5,EBr),e(I5,soe),e(soe,CBr),e(I5,wBr),e(se,ABr),e(se,N5),e(N5,vAe),e(vAe,LBr),e(N5,yBr),e(N5,loe),e(loe,xBr),e(N5,$Br),e(se,kBr),e(se,q5),e(q5,FAe),e(FAe,SBr),e(q5,RBr),e(q5,ioe),e(ioe,PBr),e(q5,BBr),e(se,IBr),e(se,j5),e(j5,TAe),e(TAe,NBr),e(j5,qBr),e(j5,doe),e(doe,jBr),e(j5,DBr),e(se,GBr),e(se,D5),e(D5,MAe),e(MAe,OBr),e(D5,VBr),e(D5,coe),e(coe,XBr),e(D5,zBr),e(se,QBr),e(se,G5),e(G5,EAe),e(EAe,WBr),e(G5,UBr),e(G5,moe),e(moe,HBr),e(G5,JBr),e(se,YBr),e(se,O5),e(O5,CAe),e(CAe,KBr),e(O5,ZBr),e(O5,foe),e(foe,eIr),e(O5,oIr),e(se,rIr),e(se,V5),e(V5,wAe),e(wAe,tIr),e(V5,aIr),e(V5,goe),e(goe,nIr),e(V5,sIr),e(se,lIr),e(se,X5),e(X5,AAe),e(AAe,iIr),e(X5,dIr),e(X5,hoe),e(hoe,cIr),e(X5,mIr),e(se,fIr),e(se,z5),e(z5,LAe),e(LAe,gIr),e(z5,hIr),e(z5,uoe),e(uoe,uIr),e(z5,pIr),e(se,_Ir),e(se,Q5),e(Q5,yAe),e(yAe,bIr),e(Q5,vIr),e(Q5,poe),e(poe,FIr),e(Q5,TIr),e(se,MIr),e(se,W5),e(W5,xAe),e(xAe,EIr),e(W5,CIr),e(W5,_oe),e(_oe,wIr),e(W5,AIr),e(se,LIr),e(se,U5),e(U5,$Ae),e($Ae,yIr),e(U5,xIr),e(U5,boe),e(boe,$Ir),e(U5,kIr),e(se,SIr),e(se,H5),e(H5,kAe),e(kAe,RIr),e(H5,PIr),e(H5,voe),e(voe,BIr),e(H5,IIr),e(se,NIr),e(se,J5),e(J5,SAe),e(SAe,qIr),e(J5,jIr),e(J5,Foe),e(Foe,DIr),e(J5,GIr),e(se,OIr),e(se,Y5),e(Y5,RAe),e(RAe,VIr),e(Y5,XIr),e(Y5,Toe),e(Toe,zIr),e(Y5,QIr),e(se,WIr),e(se,K5),e(K5,PAe),e(PAe,UIr),e(K5,HIr),e(K5,Moe),e(Moe,JIr),e(K5,YIr),e(se,KIr),e(se,Z5),e(Z5,BAe),e(BAe,ZIr),e(Z5,eNr),e(Z5,Eoe),e(Eoe,oNr),e(Z5,rNr),e(se,tNr),e(se,e0),e(e0,IAe),e(IAe,aNr),e(e0,nNr),e(e0,Coe),e(Coe,sNr),e(e0,lNr),e(se,iNr),e(se,o0),e(o0,NAe),e(NAe,dNr),e(o0,cNr),e(o0,woe),e(woe,mNr),e(o0,fNr),e(Nr,gNr),M(r0,Nr,null),b(m,keo,_),b(m,Uc,_),e(Uc,t0),e(t0,qAe),M(Zk,qAe,null),e(Uc,hNr),e(Uc,jAe),e(jAe,uNr),b(m,Seo,_),b(m,ir,_),M(eS,ir,null),e(ir,pNr),e(ir,Hc),e(Hc,_Nr),e(Hc,Aoe),e(Aoe,bNr),e(Hc,vNr),e(Hc,Loe),e(Loe,FNr),e(Hc,TNr),e(ir,MNr),e(ir,oS),e(oS,ENr),e(oS,DAe),e(DAe,CNr),e(oS,wNr),e(ir,ANr),e(ir,Qt),M(rS,Qt,null),e(Qt,LNr),e(Qt,GAe),e(GAe,yNr),e(Qt,xNr),e(Qt,Jc),e(Jc,$Nr),e(Jc,OAe),e(OAe,kNr),e(Jc,SNr),e(Jc,yoe),e(yoe,RNr),e(Jc,PNr),e(Qt,BNr),M(a0,Qt,null),e(ir,INr),e(ir,qr),M(tS,qr,null),e(qr,NNr),e(qr,VAe),e(VAe,qNr),e(qr,jNr),e(qr,Ln),e(Ln,DNr),e(Ln,XAe),e(XAe,GNr),e(Ln,ONr),e(Ln,zAe),e(zAe,VNr),e(Ln,XNr),e(Ln,QAe),e(QAe,zNr),e(Ln,QNr),e(qr,WNr),e(qr,Me),e(Me,n0),e(n0,WAe),e(WAe,UNr),e(n0,HNr),e(n0,xoe),e(xoe,JNr),e(n0,YNr),e(Me,KNr),e(Me,s0),e(s0,UAe),e(UAe,ZNr),e(s0,eqr),e(s0,$oe),e($oe,oqr),e(s0,rqr),e(Me,tqr),e(Me,l0),e(l0,HAe),e(HAe,aqr),e(l0,nqr),e(l0,koe),e(koe,sqr),e(l0,lqr),e(Me,iqr),e(Me,i0),e(i0,JAe),e(JAe,dqr),e(i0,cqr),e(i0,Soe),e(Soe,mqr),e(i0,fqr),e(Me,gqr),e(Me,d0),e(d0,YAe),e(YAe,hqr),e(d0,uqr),e(d0,Roe),e(Roe,pqr),e(d0,_qr),e(Me,bqr),e(Me,c0),e(c0,KAe),e(KAe,vqr),e(c0,Fqr),e(c0,Poe),e(Poe,Tqr),e(c0,Mqr),e(Me,Eqr),e(Me,m0),e(m0,ZAe),e(ZAe,Cqr),e(m0,wqr),e(m0,Boe),e(Boe,Aqr),e(m0,Lqr),e(Me,yqr),e(Me,f0),e(f0,e6e),e(e6e,xqr),e(f0,$qr),e(f0,Ioe),e(Ioe,kqr),e(f0,Sqr),e(Me,Rqr),e(Me,g0),e(g0,o6e),e(o6e,Pqr),e(g0,Bqr),e(g0,Noe),e(Noe,Iqr),e(g0,Nqr),e(Me,qqr),e(Me,h0),e(h0,r6e),e(r6e,jqr),e(h0,Dqr),e(h0,qoe),e(qoe,Gqr),e(h0,Oqr),e(Me,Vqr),e(Me,u0),e(u0,t6e),e(t6e,Xqr),e(u0,zqr),e(u0,joe),e(joe,Qqr),e(u0,Wqr),e(Me,Uqr),e(Me,p0),e(p0,a6e),e(a6e,Hqr),e(p0,Jqr),e(p0,Doe),e(Doe,Yqr),e(p0,Kqr),e(Me,Zqr),e(Me,_0),e(_0,n6e),e(n6e,ejr),e(_0,ojr),e(_0,Goe),e(Goe,rjr),e(_0,tjr),e(Me,ajr),e(Me,b0),e(b0,s6e),e(s6e,njr),e(b0,sjr),e(b0,Ooe),e(Ooe,ljr),e(b0,ijr),e(qr,djr),M(v0,qr,null),b(m,Reo,_),b(m,Yc,_),e(Yc,F0),e(F0,l6e),M(aS,l6e,null),e(Yc,cjr),e(Yc,i6e),e(i6e,mjr),b(m,Peo,_),b(m,dr,_),M(nS,dr,null),e(dr,fjr),e(dr,Kc),e(Kc,gjr),e(Kc,Voe),e(Voe,hjr),e(Kc,ujr),e(Kc,Xoe),e(Xoe,pjr),e(Kc,_jr),e(dr,bjr),e(dr,sS),e(sS,vjr),e(sS,d6e),e(d6e,Fjr),e(sS,Tjr),e(dr,Mjr),e(dr,Wt),M(lS,Wt,null),e(Wt,Ejr),e(Wt,c6e),e(c6e,Cjr),e(Wt,wjr),e(Wt,Zc),e(Zc,Ajr),e(Zc,m6e),e(m6e,Ljr),e(Zc,yjr),e(Zc,zoe),e(zoe,xjr),e(Zc,$jr),e(Wt,kjr),M(T0,Wt,null),e(dr,Sjr),e(dr,jr),M(iS,jr,null),e(jr,Rjr),e(jr,f6e),e(f6e,Pjr),e(jr,Bjr),e(jr,yn),e(yn,Ijr),e(yn,g6e),e(g6e,Njr),e(yn,qjr),e(yn,h6e),e(h6e,jjr),e(yn,Djr),e(yn,u6e),e(u6e,Gjr),e(yn,Ojr),e(jr,Vjr),e(jr,Be),e(Be,M0),e(M0,p6e),e(p6e,Xjr),e(M0,zjr),e(M0,Qoe),e(Qoe,Qjr),e(M0,Wjr),e(Be,Ujr),e(Be,E0),e(E0,_6e),e(_6e,Hjr),e(E0,Jjr),e(E0,Woe),e(Woe,Yjr),e(E0,Kjr),e(Be,Zjr),e(Be,Tl),e(Tl,b6e),e(b6e,eDr),e(Tl,oDr),e(Tl,Uoe),e(Uoe,rDr),e(Tl,tDr),e(Tl,Hoe),e(Hoe,aDr),e(Tl,nDr),e(Be,sDr),e(Be,C0),e(C0,v6e),e(v6e,lDr),e(C0,iDr),e(C0,Joe),e(Joe,dDr),e(C0,cDr),e(Be,mDr),e(Be,w0),e(w0,F6e),e(F6e,fDr),e(w0,gDr),e(w0,Yoe),e(Yoe,hDr),e(w0,uDr),e(Be,pDr),e(Be,A0),e(A0,T6e),e(T6e,_Dr),e(A0,bDr),e(A0,Koe),e(Koe,vDr),e(A0,FDr),e(Be,TDr),e(Be,L0),e(L0,M6e),e(M6e,MDr),e(L0,EDr),e(L0,Zoe),e(Zoe,CDr),e(L0,wDr),e(Be,ADr),e(Be,y0),e(y0,E6e),e(E6e,LDr),e(y0,yDr),e(y0,ere),e(ere,xDr),e(y0,$Dr),e(Be,kDr),e(Be,x0),e(x0,C6e),e(C6e,SDr),e(x0,RDr),e(x0,ore),e(ore,PDr),e(x0,BDr),e(jr,IDr),M($0,jr,null),b(m,Beo,_),b(m,em,_),e(em,k0),e(k0,w6e),M(dS,w6e,null),e(em,NDr),e(em,A6e),e(A6e,qDr),b(m,Ieo,_),b(m,cr,_),M(cS,cr,null),e(cr,jDr),e(cr,om),e(om,DDr),e(om,rre),e(rre,GDr),e(om,ODr),e(om,tre),e(tre,VDr),e(om,XDr),e(cr,zDr),e(cr,mS),e(mS,QDr),e(mS,L6e),e(L6e,WDr),e(mS,UDr),e(cr,HDr),e(cr,Ut),M(fS,Ut,null),e(Ut,JDr),e(Ut,y6e),e(y6e,YDr),e(Ut,KDr),e(Ut,rm),e(rm,ZDr),e(rm,x6e),e(x6e,eGr),e(rm,oGr),e(rm,are),e(are,rGr),e(rm,tGr),e(Ut,aGr),M(S0,Ut,null),e(cr,nGr),e(cr,Dr),M(gS,Dr,null),e(Dr,sGr),e(Dr,$6e),e($6e,lGr),e(Dr,iGr),e(Dr,xn),e(xn,dGr),e(xn,k6e),e(k6e,cGr),e(xn,mGr),e(xn,S6e),e(S6e,fGr),e(xn,gGr),e(xn,R6e),e(R6e,hGr),e(xn,uGr),e(Dr,pGr),e(Dr,tm),e(tm,R0),e(R0,P6e),e(P6e,_Gr),e(R0,bGr),e(R0,nre),e(nre,vGr),e(R0,FGr),e(tm,TGr),e(tm,P0),e(P0,B6e),e(B6e,MGr),e(P0,EGr),e(P0,sre),e(sre,CGr),e(P0,wGr),e(tm,AGr),e(tm,B0),e(B0,I6e),e(I6e,LGr),e(B0,yGr),e(B0,lre),e(lre,xGr),e(B0,$Gr),e(Dr,kGr),M(I0,Dr,null),b(m,Neo,_),b(m,am,_),e(am,N0),e(N0,N6e),M(hS,N6e,null),e(am,SGr),e(am,q6e),e(q6e,RGr),b(m,qeo,_),b(m,mr,_),M(uS,mr,null),e(mr,PGr),e(mr,nm),e(nm,BGr),e(nm,ire),e(ire,IGr),e(nm,NGr),e(nm,dre),e(dre,qGr),e(nm,jGr),e(mr,DGr),e(mr,pS),e(pS,GGr),e(pS,j6e),e(j6e,OGr),e(pS,VGr),e(mr,XGr),e(mr,Ht),M(_S,Ht,null),e(Ht,zGr),e(Ht,D6e),e(D6e,QGr),e(Ht,WGr),e(Ht,sm),e(sm,UGr),e(sm,G6e),e(G6e,HGr),e(sm,JGr),e(sm,cre),e(cre,YGr),e(sm,KGr),e(Ht,ZGr),M(q0,Ht,null),e(mr,eOr),e(mr,Gr),M(bS,Gr,null),e(Gr,oOr),e(Gr,O6e),e(O6e,rOr),e(Gr,tOr),e(Gr,$n),e($n,aOr),e($n,V6e),e(V6e,nOr),e($n,sOr),e($n,X6e),e(X6e,lOr),e($n,iOr),e($n,z6e),e(z6e,dOr),e($n,cOr),e(Gr,mOr),e(Gr,ge),e(ge,j0),e(j0,Q6e),e(Q6e,fOr),e(j0,gOr),e(j0,mre),e(mre,hOr),e(j0,uOr),e(ge,pOr),e(ge,D0),e(D0,W6e),e(W6e,_Or),e(D0,bOr),e(D0,fre),e(fre,vOr),e(D0,FOr),e(ge,TOr),e(ge,G0),e(G0,U6e),e(U6e,MOr),e(G0,EOr),e(G0,gre),e(gre,COr),e(G0,wOr),e(ge,AOr),e(ge,O0),e(O0,H6e),e(H6e,LOr),e(O0,yOr),e(O0,hre),e(hre,xOr),e(O0,$Or),e(ge,kOr),e(ge,V0),e(V0,J6e),e(J6e,SOr),e(V0,ROr),e(V0,ure),e(ure,POr),e(V0,BOr),e(ge,IOr),e(ge,X0),e(X0,Y6e),e(Y6e,NOr),e(X0,qOr),e(X0,pre),e(pre,jOr),e(X0,DOr),e(ge,GOr),e(ge,z0),e(z0,K6e),e(K6e,OOr),e(z0,VOr),e(z0,_re),e(_re,XOr),e(z0,zOr),e(ge,QOr),e(ge,Q0),e(Q0,Z6e),e(Z6e,WOr),e(Q0,UOr),e(Q0,bre),e(bre,HOr),e(Q0,JOr),e(ge,YOr),e(ge,W0),e(W0,e7e),e(e7e,KOr),e(W0,ZOr),e(W0,vre),e(vre,eVr),e(W0,oVr),e(ge,rVr),e(ge,U0),e(U0,o7e),e(o7e,tVr),e(U0,aVr),e(U0,Fre),e(Fre,nVr),e(U0,sVr),e(ge,lVr),e(ge,H0),e(H0,r7e),e(r7e,iVr),e(H0,dVr),e(H0,Tre),e(Tre,cVr),e(H0,mVr),e(ge,fVr),e(ge,J0),e(J0,t7e),e(t7e,gVr),e(J0,hVr),e(J0,Mre),e(Mre,uVr),e(J0,pVr),e(ge,_Vr),e(ge,Y0),e(Y0,a7e),e(a7e,bVr),e(Y0,vVr),e(Y0,Ere),e(Ere,FVr),e(Y0,TVr),e(ge,MVr),e(ge,K0),e(K0,n7e),e(n7e,EVr),e(K0,CVr),e(K0,Cre),e(Cre,wVr),e(K0,AVr),e(ge,LVr),e(ge,Z0),e(Z0,s7e),e(s7e,yVr),e(Z0,xVr),e(Z0,wre),e(wre,$Vr),e(Z0,kVr),e(ge,SVr),e(ge,ew),e(ew,l7e),e(l7e,RVr),e(ew,PVr),e(ew,Are),e(Are,BVr),e(ew,IVr),e(ge,NVr),e(ge,ow),e(ow,i7e),e(i7e,qVr),e(ow,jVr),e(ow,Lre),e(Lre,DVr),e(ow,GVr),e(ge,OVr),e(ge,rw),e(rw,d7e),e(d7e,VVr),e(rw,XVr),e(rw,yre),e(yre,zVr),e(rw,QVr),e(ge,WVr),e(ge,tw),e(tw,c7e),e(c7e,UVr),e(tw,HVr),e(tw,xre),e(xre,JVr),e(tw,YVr),e(ge,KVr),e(ge,aw),e(aw,m7e),e(m7e,ZVr),e(aw,eXr),e(aw,$re),e($re,oXr),e(aw,rXr),e(Gr,tXr),M(nw,Gr,null),b(m,jeo,_),b(m,lm,_),e(lm,sw),e(sw,f7e),M(vS,f7e,null),e(lm,aXr),e(lm,g7e),e(g7e,nXr),b(m,Deo,_),b(m,fr,_),M(FS,fr,null),e(fr,sXr),e(fr,im),e(im,lXr),e(im,kre),e(kre,iXr),e(im,dXr),e(im,Sre),e(Sre,cXr),e(im,mXr),e(fr,fXr),e(fr,TS),e(TS,gXr),e(TS,h7e),e(h7e,hXr),e(TS,uXr),e(fr,pXr),e(fr,Jt),M(MS,Jt,null),e(Jt,_Xr),e(Jt,u7e),e(u7e,bXr),e(Jt,vXr),e(Jt,dm),e(dm,FXr),e(dm,p7e),e(p7e,TXr),e(dm,MXr),e(dm,Rre),e(Rre,EXr),e(dm,CXr),e(Jt,wXr),M(lw,Jt,null),e(fr,AXr),e(fr,Or),M(ES,Or,null),e(Or,LXr),e(Or,_7e),e(_7e,yXr),e(Or,xXr),e(Or,kn),e(kn,$Xr),e(kn,b7e),e(b7e,kXr),e(kn,SXr),e(kn,v7e),e(v7e,RXr),e(kn,PXr),e(kn,F7e),e(F7e,BXr),e(kn,IXr),e(Or,NXr),e(Or,ye),e(ye,iw),e(iw,T7e),e(T7e,qXr),e(iw,jXr),e(iw,Pre),e(Pre,DXr),e(iw,GXr),e(ye,OXr),e(ye,dw),e(dw,M7e),e(M7e,VXr),e(dw,XXr),e(dw,Bre),e(Bre,zXr),e(dw,QXr),e(ye,WXr),e(ye,cw),e(cw,E7e),e(E7e,UXr),e(cw,HXr),e(cw,Ire),e(Ire,JXr),e(cw,YXr),e(ye,KXr),e(ye,mw),e(mw,C7e),e(C7e,ZXr),e(mw,ezr),e(mw,Nre),e(Nre,ozr),e(mw,rzr),e(ye,tzr),e(ye,fw),e(fw,w7e),e(w7e,azr),e(fw,nzr),e(fw,qre),e(qre,szr),e(fw,lzr),e(ye,izr),e(ye,gw),e(gw,A7e),e(A7e,dzr),e(gw,czr),e(gw,jre),e(jre,mzr),e(gw,fzr),e(ye,gzr),e(ye,hw),e(hw,L7e),e(L7e,hzr),e(hw,uzr),e(hw,Dre),e(Dre,pzr),e(hw,_zr),e(ye,bzr),e(ye,uw),e(uw,y7e),e(y7e,vzr),e(uw,Fzr),e(uw,Gre),e(Gre,Tzr),e(uw,Mzr),e(ye,Ezr),e(ye,pw),e(pw,x7e),e(x7e,Czr),e(pw,wzr),e(pw,Ore),e(Ore,Azr),e(pw,Lzr),e(ye,yzr),e(ye,_w),e(_w,$7e),e($7e,xzr),e(_w,$zr),e(_w,Vre),e(Vre,kzr),e(_w,Szr),e(Or,Rzr),M(bw,Or,null),b(m,Geo,_),b(m,cm,_),e(cm,vw),e(vw,k7e),M(CS,k7e,null),e(cm,Pzr),e(cm,S7e),e(S7e,Bzr),b(m,Oeo,_),b(m,gr,_),M(wS,gr,null),e(gr,Izr),e(gr,mm),e(mm,Nzr),e(mm,Xre),e(Xre,qzr),e(mm,jzr),e(mm,zre),e(zre,Dzr),e(mm,Gzr),e(gr,Ozr),e(gr,AS),e(AS,Vzr),e(AS,R7e),e(R7e,Xzr),e(AS,zzr),e(gr,Qzr),e(gr,Yt),M(LS,Yt,null),e(Yt,Wzr),e(Yt,P7e),e(P7e,Uzr),e(Yt,Hzr),e(Yt,fm),e(fm,Jzr),e(fm,B7e),e(B7e,Yzr),e(fm,Kzr),e(fm,Qre),e(Qre,Zzr),e(fm,eQr),e(Yt,oQr),M(Fw,Yt,null),e(gr,rQr),e(gr,Vr),M(yS,Vr,null),e(Vr,tQr),e(Vr,I7e),e(I7e,aQr),e(Vr,nQr),e(Vr,Sn),e(Sn,sQr),e(Sn,N7e),e(N7e,lQr),e(Sn,iQr),e(Sn,q7e),e(q7e,dQr),e(Sn,cQr),e(Sn,j7e),e(j7e,mQr),e(Sn,fQr),e(Vr,gQr),e(Vr,re),e(re,Tw),e(Tw,D7e),e(D7e,hQr),e(Tw,uQr),e(Tw,Wre),e(Wre,pQr),e(Tw,_Qr),e(re,bQr),e(re,Mw),e(Mw,G7e),e(G7e,vQr),e(Mw,FQr),e(Mw,Ure),e(Ure,TQr),e(Mw,MQr),e(re,EQr),e(re,Ew),e(Ew,O7e),e(O7e,CQr),e(Ew,wQr),e(Ew,Hre),e(Hre,AQr),e(Ew,LQr),e(re,yQr),e(re,Cw),e(Cw,V7e),e(V7e,xQr),e(Cw,$Qr),e(Cw,Jre),e(Jre,kQr),e(Cw,SQr),e(re,RQr),e(re,ww),e(ww,X7e),e(X7e,PQr),e(ww,BQr),e(ww,Yre),e(Yre,IQr),e(ww,NQr),e(re,qQr),e(re,Aw),e(Aw,z7e),e(z7e,jQr),e(Aw,DQr),e(Aw,Kre),e(Kre,GQr),e(Aw,OQr),e(re,VQr),e(re,Lw),e(Lw,Q7e),e(Q7e,XQr),e(Lw,zQr),e(Lw,Zre),e(Zre,QQr),e(Lw,WQr),e(re,UQr),e(re,yw),e(yw,W7e),e(W7e,HQr),e(yw,JQr),e(yw,ete),e(ete,YQr),e(yw,KQr),e(re,ZQr),e(re,xw),e(xw,U7e),e(U7e,eWr),e(xw,oWr),e(xw,ote),e(ote,rWr),e(xw,tWr),e(re,aWr),e(re,$w),e($w,H7e),e(H7e,nWr),e($w,sWr),e($w,rte),e(rte,lWr),e($w,iWr),e(re,dWr),e(re,kw),e(kw,J7e),e(J7e,cWr),e(kw,mWr),e(kw,tte),e(tte,fWr),e(kw,gWr),e(re,hWr),e(re,Sw),e(Sw,Y7e),e(Y7e,uWr),e(Sw,pWr),e(Sw,ate),e(ate,_Wr),e(Sw,bWr),e(re,vWr),e(re,Rw),e(Rw,K7e),e(K7e,FWr),e(Rw,TWr),e(Rw,nte),e(nte,MWr),e(Rw,EWr),e(re,CWr),e(re,Pw),e(Pw,Z7e),e(Z7e,wWr),e(Pw,AWr),e(Pw,ste),e(ste,LWr),e(Pw,yWr),e(re,xWr),e(re,Bw),e(Bw,eLe),e(eLe,$Wr),e(Bw,kWr),e(Bw,lte),e(lte,SWr),e(Bw,RWr),e(re,PWr),e(re,Iw),e(Iw,oLe),e(oLe,BWr),e(Iw,IWr),e(Iw,ite),e(ite,NWr),e(Iw,qWr),e(re,jWr),e(re,Nw),e(Nw,rLe),e(rLe,DWr),e(Nw,GWr),e(Nw,dte),e(dte,OWr),e(Nw,VWr),e(re,XWr),e(re,qw),e(qw,tLe),e(tLe,zWr),e(qw,QWr),e(qw,cte),e(cte,WWr),e(qw,UWr),e(re,HWr),e(re,jw),e(jw,aLe),e(aLe,JWr),e(jw,YWr),e(jw,mte),e(mte,KWr),e(jw,ZWr),e(re,eUr),e(re,Dw),e(Dw,nLe),e(nLe,oUr),e(Dw,rUr),e(Dw,fte),e(fte,tUr),e(Dw,aUr),e(re,nUr),e(re,Gw),e(Gw,sLe),e(sLe,sUr),e(Gw,lUr),e(Gw,gte),e(gte,iUr),e(Gw,dUr),e(re,cUr),e(re,Ow),e(Ow,lLe),e(lLe,mUr),e(Ow,fUr),e(Ow,hte),e(hte,gUr),e(Ow,hUr),e(re,uUr),e(re,Vw),e(Vw,iLe),e(iLe,pUr),e(Vw,_Ur),e(Vw,ute),e(ute,bUr),e(Vw,vUr),e(re,FUr),e(re,Xw),e(Xw,dLe),e(dLe,TUr),e(Xw,MUr),e(Xw,pte),e(pte,EUr),e(Xw,CUr),e(re,wUr),e(re,zw),e(zw,cLe),e(cLe,AUr),e(zw,LUr),e(zw,_te),e(_te,yUr),e(zw,xUr),e(re,$Ur),e(re,Qw),e(Qw,mLe),e(mLe,kUr),e(Qw,SUr),e(Qw,bte),e(bte,RUr),e(Qw,PUr),e(re,BUr),e(re,Ww),e(Ww,fLe),e(fLe,IUr),e(Ww,NUr),e(Ww,vte),e(vte,qUr),e(Ww,jUr),e(Vr,DUr),M(Uw,Vr,null),b(m,Veo,_),b(m,gm,_),e(gm,Hw),e(Hw,gLe),M(xS,gLe,null),e(gm,GUr),e(gm,hLe),e(hLe,OUr),b(m,Xeo,_),b(m,hr,_),M($S,hr,null),e(hr,VUr),e(hr,hm),e(hm,XUr),e(hm,Fte),e(Fte,zUr),e(hm,QUr),e(hm,Tte),e(Tte,WUr),e(hm,UUr),e(hr,HUr),e(hr,kS),e(kS,JUr),e(kS,uLe),e(uLe,YUr),e(kS,KUr),e(hr,ZUr),e(hr,Kt),M(SS,Kt,null),e(Kt,eHr),e(Kt,pLe),e(pLe,oHr),e(Kt,rHr),e(Kt,um),e(um,tHr),e(um,_Le),e(_Le,aHr),e(um,nHr),e(um,Mte),e(Mte,sHr),e(um,lHr),e(Kt,iHr),M(Jw,Kt,null),e(hr,dHr),e(hr,Xr),M(RS,Xr,null),e(Xr,cHr),e(Xr,bLe),e(bLe,mHr),e(Xr,fHr),e(Xr,Rn),e(Rn,gHr),e(Rn,vLe),e(vLe,hHr),e(Rn,uHr),e(Rn,FLe),e(FLe,pHr),e(Rn,_Hr),e(Rn,TLe),e(TLe,bHr),e(Rn,vHr),e(Xr,FHr),e(Xr,ve),e(ve,Yw),e(Yw,MLe),e(MLe,THr),e(Yw,MHr),e(Yw,Ete),e(Ete,EHr),e(Yw,CHr),e(ve,wHr),e(ve,Kw),e(Kw,ELe),e(ELe,AHr),e(Kw,LHr),e(Kw,Cte),e(Cte,yHr),e(Kw,xHr),e(ve,$Hr),e(ve,Zw),e(Zw,CLe),e(CLe,kHr),e(Zw,SHr),e(Zw,wte),e(wte,RHr),e(Zw,PHr),e(ve,BHr),e(ve,eA),e(eA,wLe),e(wLe,IHr),e(eA,NHr),e(eA,Ate),e(Ate,qHr),e(eA,jHr),e(ve,DHr),e(ve,oA),e(oA,ALe),e(ALe,GHr),e(oA,OHr),e(oA,Lte),e(Lte,VHr),e(oA,XHr),e(ve,zHr),e(ve,rA),e(rA,LLe),e(LLe,QHr),e(rA,WHr),e(rA,yte),e(yte,UHr),e(rA,HHr),e(ve,JHr),e(ve,tA),e(tA,yLe),e(yLe,YHr),e(tA,KHr),e(tA,xte),e(xte,ZHr),e(tA,eJr),e(ve,oJr),e(ve,aA),e(aA,xLe),e(xLe,rJr),e(aA,tJr),e(aA,$te),e($te,aJr),e(aA,nJr),e(ve,sJr),e(ve,nA),e(nA,$Le),e($Le,lJr),e(nA,iJr),e(nA,kte),e(kte,dJr),e(nA,cJr),e(ve,mJr),e(ve,sA),e(sA,kLe),e(kLe,fJr),e(sA,gJr),e(sA,Ste),e(Ste,hJr),e(sA,uJr),e(ve,pJr),e(ve,lA),e(lA,SLe),e(SLe,_Jr),e(lA,bJr),e(lA,Rte),e(Rte,vJr),e(lA,FJr),e(ve,TJr),e(ve,iA),e(iA,RLe),e(RLe,MJr),e(iA,EJr),e(iA,Pte),e(Pte,CJr),e(iA,wJr),e(ve,AJr),e(ve,dA),e(dA,PLe),e(PLe,LJr),e(dA,yJr),e(dA,Bte),e(Bte,xJr),e(dA,$Jr),e(ve,kJr),e(ve,cA),e(cA,BLe),e(BLe,SJr),e(cA,RJr),e(cA,Ite),e(Ite,PJr),e(cA,BJr),e(ve,IJr),e(ve,mA),e(mA,ILe),e(ILe,NJr),e(mA,qJr),e(mA,Nte),e(Nte,jJr),e(mA,DJr),e(ve,GJr),e(ve,fA),e(fA,NLe),e(NLe,OJr),e(fA,VJr),e(fA,qte),e(qte,XJr),e(fA,zJr),e(ve,QJr),e(ve,gA),e(gA,qLe),e(qLe,WJr),e(gA,UJr),e(gA,jte),e(jte,HJr),e(gA,JJr),e(Xr,YJr),M(hA,Xr,null),b(m,zeo,_),b(m,pm,_),e(pm,uA),e(uA,jLe),M(PS,jLe,null),e(pm,KJr),e(pm,DLe),e(DLe,ZJr),b(m,Qeo,_),b(m,ur,_),M(BS,ur,null),e(ur,eYr),e(ur,_m),e(_m,oYr),e(_m,Dte),e(Dte,rYr),e(_m,tYr),e(_m,Gte),e(Gte,aYr),e(_m,nYr),e(ur,sYr),e(ur,IS),e(IS,lYr),e(IS,GLe),e(GLe,iYr),e(IS,dYr),e(ur,cYr),e(ur,Zt),M(NS,Zt,null),e(Zt,mYr),e(Zt,OLe),e(OLe,fYr),e(Zt,gYr),e(Zt,bm),e(bm,hYr),e(bm,VLe),e(VLe,uYr),e(bm,pYr),e(bm,Ote),e(Ote,_Yr),e(bm,bYr),e(Zt,vYr),M(pA,Zt,null),e(ur,FYr),e(ur,zr),M(qS,zr,null),e(zr,TYr),e(zr,XLe),e(XLe,MYr),e(zr,EYr),e(zr,Pn),e(Pn,CYr),e(Pn,zLe),e(zLe,wYr),e(Pn,AYr),e(Pn,QLe),e(QLe,LYr),e(Pn,yYr),e(Pn,WLe),e(WLe,xYr),e(Pn,$Yr),e(zr,kYr),e(zr,jS),e(jS,_A),e(_A,ULe),e(ULe,SYr),e(_A,RYr),e(_A,Vte),e(Vte,PYr),e(_A,BYr),e(jS,IYr),e(jS,bA),e(bA,HLe),e(HLe,NYr),e(bA,qYr),e(bA,Xte),e(Xte,jYr),e(bA,DYr),e(zr,GYr),M(vA,zr,null),b(m,Weo,_),b(m,vm,_),e(vm,FA),e(FA,JLe),M(DS,JLe,null),e(vm,OYr),e(vm,YLe),e(YLe,VYr),b(m,Ueo,_),b(m,pr,_),M(GS,pr,null),e(pr,XYr),e(pr,Fm),e(Fm,zYr),e(Fm,zte),e(zte,QYr),e(Fm,WYr),e(Fm,Qte),e(Qte,UYr),e(Fm,HYr),e(pr,JYr),e(pr,OS),e(OS,YYr),e(OS,KLe),e(KLe,KYr),e(OS,ZYr),e(pr,eKr),e(pr,ea),M(VS,ea,null),e(ea,oKr),e(ea,ZLe),e(ZLe,rKr),e(ea,tKr),e(ea,Tm),e(Tm,aKr),e(Tm,eye),e(eye,nKr),e(Tm,sKr),e(Tm,Wte),e(Wte,lKr),e(Tm,iKr),e(ea,dKr),M(TA,ea,null),e(pr,cKr),e(pr,Qr),M(XS,Qr,null),e(Qr,mKr),e(Qr,oye),e(oye,fKr),e(Qr,gKr),e(Qr,Bn),e(Bn,hKr),e(Bn,rye),e(rye,uKr),e(Bn,pKr),e(Bn,tye),e(tye,_Kr),e(Bn,bKr),e(Bn,aye),e(aye,vKr),e(Bn,FKr),e(Qr,TKr),e(Qr,nye),e(nye,MA),e(MA,sye),e(sye,MKr),e(MA,EKr),e(MA,Ute),e(Ute,CKr),e(MA,wKr),e(Qr,AKr),M(EA,Qr,null),b(m,Heo,_),b(m,Mm,_),e(Mm,CA),e(CA,lye),M(zS,lye,null),e(Mm,LKr),e(Mm,iye),e(iye,yKr),b(m,Jeo,_),b(m,_r,_),M(QS,_r,null),e(_r,xKr),e(_r,Em),e(Em,$Kr),e(Em,Hte),e(Hte,kKr),e(Em,SKr),e(Em,Jte),e(Jte,RKr),e(Em,PKr),e(_r,BKr),e(_r,WS),e(WS,IKr),e(WS,dye),e(dye,NKr),e(WS,qKr),e(_r,jKr),e(_r,oa),M(US,oa,null),e(oa,DKr),e(oa,cye),e(cye,GKr),e(oa,OKr),e(oa,Cm),e(Cm,VKr),e(Cm,mye),e(mye,XKr),e(Cm,zKr),e(Cm,Yte),e(Yte,QKr),e(Cm,WKr),e(oa,UKr),M(wA,oa,null),e(_r,HKr),e(_r,Wr),M(HS,Wr,null),e(Wr,JKr),e(Wr,fye),e(fye,YKr),e(Wr,KKr),e(Wr,In),e(In,ZKr),e(In,gye),e(gye,eZr),e(In,oZr),e(In,hye),e(hye,rZr),e(In,tZr),e(In,uye),e(uye,aZr),e(In,nZr),e(Wr,sZr),e(Wr,pye),e(pye,AA),e(AA,_ye),e(_ye,lZr),e(AA,iZr),e(AA,Kte),e(Kte,dZr),e(AA,cZr),e(Wr,mZr),M(LA,Wr,null),b(m,Yeo,_),b(m,wm,_),e(wm,yA),e(yA,bye),M(JS,bye,null),e(wm,fZr),e(wm,vye),e(vye,gZr),b(m,Keo,_),b(m,br,_),M(YS,br,null),e(br,hZr),e(br,Am),e(Am,uZr),e(Am,Zte),e(Zte,pZr),e(Am,_Zr),e(Am,eae),e(eae,bZr),e(Am,vZr),e(br,FZr),e(br,KS),e(KS,TZr),e(KS,Fye),e(Fye,MZr),e(KS,EZr),e(br,CZr),e(br,ra),M(ZS,ra,null),e(ra,wZr),e(ra,Tye),e(Tye,AZr),e(ra,LZr),e(ra,Lm),e(Lm,yZr),e(Lm,Mye),e(Mye,xZr),e(Lm,$Zr),e(Lm,oae),e(oae,kZr),e(Lm,SZr),e(ra,RZr),M(xA,ra,null),e(br,PZr),e(br,Ur),M(eR,Ur,null),e(Ur,BZr),e(Ur,Eye),e(Eye,IZr),e(Ur,NZr),e(Ur,Nn),e(Nn,qZr),e(Nn,Cye),e(Cye,jZr),e(Nn,DZr),e(Nn,wye),e(wye,GZr),e(Nn,OZr),e(Nn,Aye),e(Aye,VZr),e(Nn,XZr),e(Ur,zZr),e(Ur,de),e(de,$A),e($A,Lye),e(Lye,QZr),e($A,WZr),e($A,rae),e(rae,UZr),e($A,HZr),e(de,JZr),e(de,kA),e(kA,yye),e(yye,YZr),e(kA,KZr),e(kA,tae),e(tae,ZZr),e(kA,eet),e(de,oet),e(de,SA),e(SA,xye),e(xye,ret),e(SA,tet),e(SA,aae),e(aae,aet),e(SA,net),e(de,set),e(de,RA),e(RA,$ye),e($ye,iet),e(RA,det),e(RA,nae),e(nae,cet),e(RA,met),e(de,fet),e(de,PA),e(PA,kye),e(kye,get),e(PA,het),e(PA,sae),e(sae,uet),e(PA,pet),e(de,_et),e(de,BA),e(BA,Sye),e(Sye,bet),e(BA,vet),e(BA,lae),e(lae,Fet),e(BA,Tet),e(de,Met),e(de,IA),e(IA,Rye),e(Rye,Eet),e(IA,Cet),e(IA,iae),e(iae,wet),e(IA,Aet),e(de,Let),e(de,NA),e(NA,Pye),e(Pye,yet),e(NA,xet),e(NA,dae),e(dae,$et),e(NA,ket),e(de,Set),e(de,qA),e(qA,Bye),e(Bye,Ret),e(qA,Pet),e(qA,cae),e(cae,Bet),e(qA,Iet),e(de,Net),e(de,jA),e(jA,Iye),e(Iye,qet),e(jA,jet),e(jA,mae),e(mae,Det),e(jA,Get),e(de,Oet),e(de,DA),e(DA,Nye),e(Nye,Vet),e(DA,Xet),e(DA,fae),e(fae,zet),e(DA,Qet),e(de,Wet),e(de,GA),e(GA,qye),e(qye,Uet),e(GA,Het),e(GA,gae),e(gae,Jet),e(GA,Yet),e(de,Ket),e(de,OA),e(OA,jye),e(jye,Zet),e(OA,eot),e(OA,hae),e(hae,oot),e(OA,rot),e(de,tot),e(de,VA),e(VA,Dye),e(Dye,aot),e(VA,not),e(VA,uae),e(uae,sot),e(VA,lot),e(de,iot),e(de,XA),e(XA,Gye),e(Gye,dot),e(XA,cot),e(XA,pae),e(pae,mot),e(XA,fot),e(de,got),e(de,zA),e(zA,Oye),e(Oye,hot),e(zA,uot),e(zA,_ae),e(_ae,pot),e(zA,_ot),e(de,bot),e(de,QA),e(QA,Vye),e(Vye,vot),e(QA,Fot),e(QA,bae),e(bae,Tot),e(QA,Mot),e(de,Eot),e(de,WA),e(WA,Xye),e(Xye,Cot),e(WA,wot),e(WA,vae),e(vae,Aot),e(WA,Lot),e(de,yot),e(de,UA),e(UA,zye),e(zye,xot),e(UA,$ot),e(UA,Fae),e(Fae,kot),e(UA,Sot),e(de,Rot),e(de,HA),e(HA,Qye),e(Qye,Pot),e(HA,Bot),e(HA,Tae),e(Tae,Iot),e(HA,Not),e(de,qot),e(de,JA),e(JA,Wye),e(Wye,jot),e(JA,Dot),e(JA,Mae),e(Mae,Got),e(JA,Oot),e(Ur,Vot),M(YA,Ur,null),b(m,Zeo,_),b(m,ym,_),e(ym,KA),e(KA,Uye),M(oR,Uye,null),e(ym,Xot),e(ym,Hye),e(Hye,zot),b(m,eoo,_),b(m,vr,_),M(rR,vr,null),e(vr,Qot),e(vr,xm),e(xm,Wot),e(xm,Eae),e(Eae,Uot),e(xm,Hot),e(xm,Cae),e(Cae,Jot),e(xm,Yot),e(vr,Kot),e(vr,tR),e(tR,Zot),e(tR,Jye),e(Jye,ert),e(tR,ort),e(vr,rrt),e(vr,ta),M(aR,ta,null),e(ta,trt),e(ta,Yye),e(Yye,art),e(ta,nrt),e(ta,$m),e($m,srt),e($m,Kye),e(Kye,lrt),e($m,irt),e($m,wae),e(wae,drt),e($m,crt),e(ta,mrt),M(ZA,ta,null),e(vr,frt),e(vr,Hr),M(nR,Hr,null),e(Hr,grt),e(Hr,Zye),e(Zye,hrt),e(Hr,urt),e(Hr,qn),e(qn,prt),e(qn,e8e),e(e8e,_rt),e(qn,brt),e(qn,o8e),e(o8e,vrt),e(qn,Frt),e(qn,r8e),e(r8e,Trt),e(qn,Mrt),e(Hr,Ert),e(Hr,ce),e(ce,e6),e(e6,t8e),e(t8e,Crt),e(e6,wrt),e(e6,Aae),e(Aae,Art),e(e6,Lrt),e(ce,yrt),e(ce,o6),e(o6,a8e),e(a8e,xrt),e(o6,$rt),e(o6,Lae),e(Lae,krt),e(o6,Srt),e(ce,Rrt),e(ce,r6),e(r6,n8e),e(n8e,Prt),e(r6,Brt),e(r6,yae),e(yae,Irt),e(r6,Nrt),e(ce,qrt),e(ce,t6),e(t6,s8e),e(s8e,jrt),e(t6,Drt),e(t6,xae),e(xae,Grt),e(t6,Ort),e(ce,Vrt),e(ce,a6),e(a6,l8e),e(l8e,Xrt),e(a6,zrt),e(a6,$ae),e($ae,Qrt),e(a6,Wrt),e(ce,Urt),e(ce,n6),e(n6,i8e),e(i8e,Hrt),e(n6,Jrt),e(n6,kae),e(kae,Yrt),e(n6,Krt),e(ce,Zrt),e(ce,s6),e(s6,d8e),e(d8e,ett),e(s6,ott),e(s6,Sae),e(Sae,rtt),e(s6,ttt),e(ce,att),e(ce,l6),e(l6,c8e),e(c8e,ntt),e(l6,stt),e(l6,Rae),e(Rae,ltt),e(l6,itt),e(ce,dtt),e(ce,i6),e(i6,m8e),e(m8e,ctt),e(i6,mtt),e(i6,Pae),e(Pae,ftt),e(i6,gtt),e(ce,htt),e(ce,d6),e(d6,f8e),e(f8e,utt),e(d6,ptt),e(d6,Bae),e(Bae,_tt),e(d6,btt),e(ce,vtt),e(ce,c6),e(c6,g8e),e(g8e,Ftt),e(c6,Ttt),e(c6,Iae),e(Iae,Mtt),e(c6,Ett),e(ce,Ctt),e(ce,m6),e(m6,h8e),e(h8e,wtt),e(m6,Att),e(m6,Nae),e(Nae,Ltt),e(m6,ytt),e(ce,xtt),e(ce,f6),e(f6,u8e),e(u8e,$tt),e(f6,ktt),e(f6,qae),e(qae,Stt),e(f6,Rtt),e(ce,Ptt),e(ce,g6),e(g6,p8e),e(p8e,Btt),e(g6,Itt),e(g6,jae),e(jae,Ntt),e(g6,qtt),e(ce,jtt),e(ce,h6),e(h6,_8e),e(_8e,Dtt),e(h6,Gtt),e(h6,Dae),e(Dae,Ott),e(h6,Vtt),e(ce,Xtt),e(ce,u6),e(u6,b8e),e(b8e,ztt),e(u6,Qtt),e(u6,Gae),e(Gae,Wtt),e(u6,Utt),e(ce,Htt),e(ce,p6),e(p6,v8e),e(v8e,Jtt),e(p6,Ytt),e(p6,Oae),e(Oae,Ktt),e(p6,Ztt),e(ce,eat),e(ce,_6),e(_6,F8e),e(F8e,oat),e(_6,rat),e(_6,Vae),e(Vae,tat),e(_6,aat),e(ce,nat),e(ce,b6),e(b6,T8e),e(T8e,sat),e(b6,lat),e(b6,Xae),e(Xae,iat),e(b6,dat),e(ce,cat),e(ce,v6),e(v6,M8e),e(M8e,mat),e(v6,fat),e(v6,zae),e(zae,gat),e(v6,hat),e(ce,uat),e(ce,F6),e(F6,E8e),e(E8e,pat),e(F6,_at),e(F6,Qae),e(Qae,bat),e(F6,vat),e(Hr,Fat),M(T6,Hr,null),b(m,ooo,_),b(m,km,_),e(km,M6),e(M6,C8e),M(sR,C8e,null),e(km,Tat),e(km,w8e),e(w8e,Mat),b(m,roo,_),b(m,Fr,_),M(lR,Fr,null),e(Fr,Eat),e(Fr,Sm),e(Sm,Cat),e(Sm,Wae),e(Wae,wat),e(Sm,Aat),e(Sm,Uae),e(Uae,Lat),e(Sm,yat),e(Fr,xat),e(Fr,iR),e(iR,$at),e(iR,A8e),e(A8e,kat),e(iR,Sat),e(Fr,Rat),e(Fr,aa),M(dR,aa,null),e(aa,Pat),e(aa,L8e),e(L8e,Bat),e(aa,Iat),e(aa,Rm),e(Rm,Nat),e(Rm,y8e),e(y8e,qat),e(Rm,jat),e(Rm,Hae),e(Hae,Dat),e(Rm,Gat),e(aa,Oat),M(E6,aa,null),e(Fr,Vat),e(Fr,Jr),M(cR,Jr,null),e(Jr,Xat),e(Jr,x8e),e(x8e,zat),e(Jr,Qat),e(Jr,jn),e(jn,Wat),e(jn,$8e),e($8e,Uat),e(jn,Hat),e(jn,k8e),e(k8e,Jat),e(jn,Yat),e(jn,S8e),e(S8e,Kat),e(jn,Zat),e(Jr,ent),e(Jr,R8e),e(R8e,C6),e(C6,P8e),e(P8e,ont),e(C6,rnt),e(C6,Jae),e(Jae,tnt),e(C6,ant),e(Jr,nnt),M(w6,Jr,null),b(m,too,_),b(m,Pm,_),e(Pm,A6),e(A6,B8e),M(mR,B8e,null),e(Pm,snt),e(Pm,I8e),e(I8e,lnt),b(m,aoo,_),b(m,Tr,_),M(fR,Tr,null),e(Tr,int),e(Tr,Bm),e(Bm,dnt),e(Bm,Yae),e(Yae,cnt),e(Bm,mnt),e(Bm,Kae),e(Kae,fnt),e(Bm,gnt),e(Tr,hnt),e(Tr,gR),e(gR,unt),e(gR,N8e),e(N8e,pnt),e(gR,_nt),e(Tr,bnt),e(Tr,na),M(hR,na,null),e(na,vnt),e(na,q8e),e(q8e,Fnt),e(na,Tnt),e(na,Im),e(Im,Mnt),e(Im,j8e),e(j8e,Ent),e(Im,Cnt),e(Im,Zae),e(Zae,wnt),e(Im,Ant),e(na,Lnt),M(L6,na,null),e(Tr,ynt),e(Tr,Yr),M(uR,Yr,null),e(Yr,xnt),e(Yr,D8e),e(D8e,$nt),e(Yr,knt),e(Yr,Dn),e(Dn,Snt),e(Dn,G8e),e(G8e,Rnt),e(Dn,Pnt),e(Dn,O8e),e(O8e,Bnt),e(Dn,Int),e(Dn,V8e),e(V8e,Nnt),e(Dn,qnt),e(Yr,jnt),e(Yr,X8e),e(X8e,y6),e(y6,z8e),e(z8e,Dnt),e(y6,Gnt),e(y6,ene),e(ene,Ont),e(y6,Vnt),e(Yr,Xnt),M(x6,Yr,null),b(m,noo,_),b(m,Nm,_),e(Nm,$6),e($6,Q8e),M(pR,Q8e,null),e(Nm,znt),e(Nm,W8e),e(W8e,Qnt),b(m,soo,_),b(m,Mr,_),M(_R,Mr,null),e(Mr,Wnt),e(Mr,qm),e(qm,Unt),e(qm,one),e(one,Hnt),e(qm,Jnt),e(qm,rne),e(rne,Ynt),e(qm,Knt),e(Mr,Znt),e(Mr,bR),e(bR,est),e(bR,U8e),e(U8e,ost),e(bR,rst),e(Mr,tst),e(Mr,sa),M(vR,sa,null),e(sa,ast),e(sa,H8e),e(H8e,nst),e(sa,sst),e(sa,jm),e(jm,lst),e(jm,J8e),e(J8e,ist),e(jm,dst),e(jm,tne),e(tne,cst),e(jm,mst),e(sa,fst),M(k6,sa,null),e(Mr,gst),e(Mr,Kr),M(FR,Kr,null),e(Kr,hst),e(Kr,Y8e),e(Y8e,ust),e(Kr,pst),e(Kr,Gn),e(Gn,_st),e(Gn,K8e),e(K8e,bst),e(Gn,vst),e(Gn,Z8e),e(Z8e,Fst),e(Gn,Tst),e(Gn,e9e),e(e9e,Mst),e(Gn,Est),e(Kr,Cst),e(Kr,te),e(te,S6),e(S6,o9e),e(o9e,wst),e(S6,Ast),e(S6,ane),e(ane,Lst),e(S6,yst),e(te,xst),e(te,R6),e(R6,r9e),e(r9e,$st),e(R6,kst),e(R6,nne),e(nne,Sst),e(R6,Rst),e(te,Pst),e(te,P6),e(P6,t9e),e(t9e,Bst),e(P6,Ist),e(P6,sne),e(sne,Nst),e(P6,qst),e(te,jst),e(te,B6),e(B6,a9e),e(a9e,Dst),e(B6,Gst),e(B6,lne),e(lne,Ost),e(B6,Vst),e(te,Xst),e(te,I6),e(I6,n9e),e(n9e,zst),e(I6,Qst),e(I6,ine),e(ine,Wst),e(I6,Ust),e(te,Hst),e(te,N6),e(N6,s9e),e(s9e,Jst),e(N6,Yst),e(N6,dne),e(dne,Kst),e(N6,Zst),e(te,elt),e(te,q6),e(q6,l9e),e(l9e,olt),e(q6,rlt),e(q6,cne),e(cne,tlt),e(q6,alt),e(te,nlt),e(te,j6),e(j6,i9e),e(i9e,slt),e(j6,llt),e(j6,mne),e(mne,ilt),e(j6,dlt),e(te,clt),e(te,D6),e(D6,d9e),e(d9e,mlt),e(D6,flt),e(D6,fne),e(fne,glt),e(D6,hlt),e(te,ult),e(te,G6),e(G6,c9e),e(c9e,plt),e(G6,_lt),e(G6,gne),e(gne,blt),e(G6,vlt),e(te,Flt),e(te,O6),e(O6,m9e),e(m9e,Tlt),e(O6,Mlt),e(O6,hne),e(hne,Elt),e(O6,Clt),e(te,wlt),e(te,V6),e(V6,f9e),e(f9e,Alt),e(V6,Llt),e(V6,une),e(une,ylt),e(V6,xlt),e(te,$lt),e(te,X6),e(X6,g9e),e(g9e,klt),e(X6,Slt),e(X6,pne),e(pne,Rlt),e(X6,Plt),e(te,Blt),e(te,z6),e(z6,h9e),e(h9e,Ilt),e(z6,Nlt),e(z6,_ne),e(_ne,qlt),e(z6,jlt),e(te,Dlt),e(te,Q6),e(Q6,u9e),e(u9e,Glt),e(Q6,Olt),e(Q6,bne),e(bne,Vlt),e(Q6,Xlt),e(te,zlt),e(te,W6),e(W6,p9e),e(p9e,Qlt),e(W6,Wlt),e(W6,vne),e(vne,Ult),e(W6,Hlt),e(te,Jlt),e(te,U6),e(U6,_9e),e(_9e,Ylt),e(U6,Klt),e(U6,Fne),e(Fne,Zlt),e(U6,eit),e(te,oit),e(te,H6),e(H6,b9e),e(b9e,rit),e(H6,tit),e(H6,Tne),e(Tne,ait),e(H6,nit),e(te,sit),e(te,J6),e(J6,v9e),e(v9e,lit),e(J6,iit),e(J6,Mne),e(Mne,dit),e(J6,cit),e(te,mit),e(te,Y6),e(Y6,F9e),e(F9e,fit),e(Y6,git),e(Y6,Ene),e(Ene,hit),e(Y6,uit),e(te,pit),e(te,K6),e(K6,T9e),e(T9e,_it),e(K6,bit),e(K6,Cne),e(Cne,vit),e(K6,Fit),e(te,Tit),e(te,Z6),e(Z6,M9e),e(M9e,Mit),e(Z6,Eit),e(Z6,wne),e(wne,Cit),e(Z6,wit),e(te,Ait),e(te,e7),e(e7,E9e),e(E9e,Lit),e(e7,yit),e(e7,Ane),e(Ane,xit),e(e7,$it),e(te,kit),e(te,o7),e(o7,C9e),e(C9e,Sit),e(o7,Rit),e(o7,Lne),e(Lne,Pit),e(o7,Bit),e(te,Iit),e(te,r7),e(r7,w9e),e(w9e,Nit),e(r7,qit),e(r7,yne),e(yne,jit),e(r7,Dit),e(te,Git),e(te,t7),e(t7,A9e),e(A9e,Oit),e(t7,Vit),e(t7,xne),e(xne,Xit),e(t7,zit),e(te,Qit),e(te,a7),e(a7,L9e),e(L9e,Wit),e(a7,Uit),e(a7,$ne),e($ne,Hit),e(a7,Jit),e(Kr,Yit),M(n7,Kr,null),b(m,loo,_),b(m,Dm,_),e(Dm,s7),e(s7,y9e),M(TR,y9e,null),e(Dm,Kit),e(Dm,x9e),e(x9e,Zit),b(m,ioo,_),b(m,Er,_),M(MR,Er,null),e(Er,edt),e(Er,Gm),e(Gm,odt),e(Gm,kne),e(kne,rdt),e(Gm,tdt),e(Gm,Sne),e(Sne,adt),e(Gm,ndt),e(Er,sdt),e(Er,ER),e(ER,ldt),e(ER,$9e),e($9e,idt),e(ER,ddt),e(Er,cdt),e(Er,la),M(CR,la,null),e(la,mdt),e(la,k9e),e(k9e,fdt),e(la,gdt),e(la,Om),e(Om,hdt),e(Om,S9e),e(S9e,udt),e(Om,pdt),e(Om,Rne),e(Rne,_dt),e(Om,bdt),e(la,vdt),M(l7,la,null),e(Er,Fdt),e(Er,Zr),M(wR,Zr,null),e(Zr,Tdt),e(Zr,R9e),e(R9e,Mdt),e(Zr,Edt),e(Zr,On),e(On,Cdt),e(On,P9e),e(P9e,wdt),e(On,Adt),e(On,B9e),e(B9e,Ldt),e(On,ydt),e(On,I9e),e(I9e,xdt),e(On,$dt),e(Zr,kdt),e(Zr,xe),e(xe,i7),e(i7,N9e),e(N9e,Sdt),e(i7,Rdt),e(i7,Pne),e(Pne,Pdt),e(i7,Bdt),e(xe,Idt),e(xe,d7),e(d7,q9e),e(q9e,Ndt),e(d7,qdt),e(d7,Bne),e(Bne,jdt),e(d7,Ddt),e(xe,Gdt),e(xe,c7),e(c7,j9e),e(j9e,Odt),e(c7,Vdt),e(c7,Ine),e(Ine,Xdt),e(c7,zdt),e(xe,Qdt),e(xe,m7),e(m7,D9e),e(D9e,Wdt),e(m7,Udt),e(m7,Nne),e(Nne,Hdt),e(m7,Jdt),e(xe,Ydt),e(xe,f7),e(f7,G9e),e(G9e,Kdt),e(f7,Zdt),e(f7,qne),e(qne,ect),e(f7,oct),e(xe,rct),e(xe,g7),e(g7,O9e),e(O9e,tct),e(g7,act),e(g7,jne),e(jne,nct),e(g7,sct),e(xe,lct),e(xe,h7),e(h7,V9e),e(V9e,ict),e(h7,dct),e(h7,Dne),e(Dne,cct),e(h7,mct),e(xe,fct),e(xe,u7),e(u7,X9e),e(X9e,gct),e(u7,hct),e(u7,Gne),e(Gne,uct),e(u7,pct),e(xe,_ct),e(xe,p7),e(p7,z9e),e(z9e,bct),e(p7,vct),e(p7,One),e(One,Fct),e(p7,Tct),e(xe,Mct),e(xe,_7),e(_7,Q9e),e(Q9e,Ect),e(_7,Cct),e(_7,Vne),e(Vne,wct),e(_7,Act),e(Zr,Lct),M(b7,Zr,null),b(m,doo,_),b(m,Vm,_),e(Vm,v7),e(v7,W9e),M(AR,W9e,null),e(Vm,yct),e(Vm,U9e),e(U9e,xct),b(m,coo,_),b(m,Cr,_),M(LR,Cr,null),e(Cr,$ct),e(Cr,Xm),e(Xm,kct),e(Xm,Xne),e(Xne,Sct),e(Xm,Rct),e(Xm,zne),e(zne,Pct),e(Xm,Bct),e(Cr,Ict),e(Cr,yR),e(yR,Nct),e(yR,H9e),e(H9e,qct),e(yR,jct),e(Cr,Dct),e(Cr,ia),M(xR,ia,null),e(ia,Gct),e(ia,J9e),e(J9e,Oct),e(ia,Vct),e(ia,zm),e(zm,Xct),e(zm,Y9e),e(Y9e,zct),e(zm,Qct),e(zm,Qne),e(Qne,Wct),e(zm,Uct),e(ia,Hct),M(F7,ia,null),e(Cr,Jct),e(Cr,et),M($R,et,null),e(et,Yct),e(et,K9e),e(K9e,Kct),e(et,Zct),e(et,Vn),e(Vn,emt),e(Vn,Z9e),e(Z9e,omt),e(Vn,rmt),e(Vn,exe),e(exe,tmt),e(Vn,amt),e(Vn,oxe),e(oxe,nmt),e(Vn,smt),e(et,lmt),e(et,Ee),e(Ee,T7),e(T7,rxe),e(rxe,imt),e(T7,dmt),e(T7,Wne),e(Wne,cmt),e(T7,mmt),e(Ee,fmt),e(Ee,M7),e(M7,txe),e(txe,gmt),e(M7,hmt),e(M7,Une),e(Une,umt),e(M7,pmt),e(Ee,_mt),e(Ee,E7),e(E7,axe),e(axe,bmt),e(E7,vmt),e(E7,Hne),e(Hne,Fmt),e(E7,Tmt),e(Ee,Mmt),e(Ee,C7),e(C7,nxe),e(nxe,Emt),e(C7,Cmt),e(C7,Jne),e(Jne,wmt),e(C7,Amt),e(Ee,Lmt),e(Ee,w7),e(w7,sxe),e(sxe,ymt),e(w7,xmt),e(w7,Yne),e(Yne,$mt),e(w7,kmt),e(Ee,Smt),e(Ee,A7),e(A7,lxe),e(lxe,Rmt),e(A7,Pmt),e(A7,Kne),e(Kne,Bmt),e(A7,Imt),e(Ee,Nmt),e(Ee,L7),e(L7,ixe),e(ixe,qmt),e(L7,jmt),e(L7,Zne),e(Zne,Dmt),e(L7,Gmt),e(Ee,Omt),e(Ee,y7),e(y7,dxe),e(dxe,Vmt),e(y7,Xmt),e(y7,ese),e(ese,zmt),e(y7,Qmt),e(Ee,Wmt),e(Ee,x7),e(x7,cxe),e(cxe,Umt),e(x7,Hmt),e(x7,ose),e(ose,Jmt),e(x7,Ymt),e(Ee,Kmt),e(Ee,$7),e($7,mxe),e(mxe,Zmt),e($7,eft),e($7,rse),e(rse,oft),e($7,rft),e(Ee,tft),e(Ee,k7),e(k7,fxe),e(fxe,aft),e(k7,nft),e(k7,tse),e(tse,sft),e(k7,lft),e(Ee,ift),e(Ee,S7),e(S7,gxe),e(gxe,dft),e(S7,cft),e(S7,ase),e(ase,mft),e(S7,fft),e(Ee,gft),e(Ee,R7),e(R7,hxe),e(hxe,hft),e(R7,uft),e(R7,nse),e(nse,pft),e(R7,_ft),e(et,bft),M(P7,et,null),b(m,moo,_),b(m,Qm,_),e(Qm,B7),e(B7,uxe),M(kR,uxe,null),e(Qm,vft),e(Qm,pxe),e(pxe,Fft),b(m,foo,_),b(m,wr,_),M(SR,wr,null),e(wr,Tft),e(wr,Wm),e(Wm,Mft),e(Wm,sse),e(sse,Eft),e(Wm,Cft),e(Wm,lse),e(lse,wft),e(Wm,Aft),e(wr,Lft),e(wr,RR),e(RR,yft),e(RR,_xe),e(_xe,xft),e(RR,$ft),e(wr,kft),e(wr,da),M(PR,da,null),e(da,Sft),e(da,bxe),e(bxe,Rft),e(da,Pft),e(da,Um),e(Um,Bft),e(Um,vxe),e(vxe,Ift),e(Um,Nft),e(Um,ise),e(ise,qft),e(Um,jft),e(da,Dft),M(I7,da,null),e(wr,Gft),e(wr,ot),M(BR,ot,null),e(ot,Oft),e(ot,Fxe),e(Fxe,Vft),e(ot,Xft),e(ot,Xn),e(Xn,zft),e(Xn,Txe),e(Txe,Qft),e(Xn,Wft),e(Xn,Mxe),e(Mxe,Uft),e(Xn,Hft),e(Xn,Exe),e(Exe,Jft),e(Xn,Yft),e(ot,Kft),e(ot,$e),e($e,N7),e(N7,Cxe),e(Cxe,Zft),e(N7,egt),e(N7,dse),e(dse,ogt),e(N7,rgt),e($e,tgt),e($e,q7),e(q7,wxe),e(wxe,agt),e(q7,ngt),e(q7,cse),e(cse,sgt),e(q7,lgt),e($e,igt),e($e,j7),e(j7,Axe),e(Axe,dgt),e(j7,cgt),e(j7,mse),e(mse,mgt),e(j7,fgt),e($e,ggt),e($e,D7),e(D7,Lxe),e(Lxe,hgt),e(D7,ugt),e(D7,fse),e(fse,pgt),e(D7,_gt),e($e,bgt),e($e,G7),e(G7,yxe),e(yxe,vgt),e(G7,Fgt),e(G7,gse),e(gse,Tgt),e(G7,Mgt),e($e,Egt),e($e,O7),e(O7,xxe),e(xxe,Cgt),e(O7,wgt),e(O7,hse),e(hse,Agt),e(O7,Lgt),e($e,ygt),e($e,V7),e(V7,$xe),e($xe,xgt),e(V7,$gt),e(V7,use),e(use,kgt),e(V7,Sgt),e($e,Rgt),e($e,X7),e(X7,kxe),e(kxe,Pgt),e(X7,Bgt),e(X7,pse),e(pse,Igt),e(X7,Ngt),e($e,qgt),e($e,z7),e(z7,Sxe),e(Sxe,jgt),e(z7,Dgt),e(z7,_se),e(_se,Ggt),e(z7,Ogt),e($e,Vgt),e($e,Q7),e(Q7,Rxe),e(Rxe,Xgt),e(Q7,zgt),e(Q7,bse),e(bse,Qgt),e(Q7,Wgt),e(ot,Ugt),M(W7,ot,null),b(m,goo,_),b(m,Hm,_),e(Hm,U7),e(U7,Pxe),M(IR,Pxe,null),e(Hm,Hgt),e(Hm,Bxe),e(Bxe,Jgt),b(m,hoo,_),b(m,Ar,_),M(NR,Ar,null),e(Ar,Ygt),e(Ar,Jm),e(Jm,Kgt),e(Jm,vse),e(vse,Zgt),e(Jm,eht),e(Jm,Fse),e(Fse,oht),e(Jm,rht),e(Ar,tht),e(Ar,qR),e(qR,aht),e(qR,Ixe),e(Ixe,nht),e(qR,sht),e(Ar,lht),e(Ar,ca),M(jR,ca,null),e(ca,iht),e(ca,Nxe),e(Nxe,dht),e(ca,cht),e(ca,Ym),e(Ym,mht),e(Ym,qxe),e(qxe,fht),e(Ym,ght),e(Ym,Tse),e(Tse,hht),e(Ym,uht),e(ca,pht),M(H7,ca,null),e(Ar,_ht),e(Ar,rt),M(DR,rt,null),e(rt,bht),e(rt,jxe),e(jxe,vht),e(rt,Fht),e(rt,zn),e(zn,Tht),e(zn,Dxe),e(Dxe,Mht),e(zn,Eht),e(zn,Gxe),e(Gxe,Cht),e(zn,wht),e(zn,Oxe),e(Oxe,Aht),e(zn,Lht),e(rt,yht),e(rt,ke),e(ke,J7),e(J7,Vxe),e(Vxe,xht),e(J7,$ht),e(J7,Mse),e(Mse,kht),e(J7,Sht),e(ke,Rht),e(ke,Y7),e(Y7,Xxe),e(Xxe,Pht),e(Y7,Bht),e(Y7,Ese),e(Ese,Iht),e(Y7,Nht),e(ke,qht),e(ke,K7),e(K7,zxe),e(zxe,jht),e(K7,Dht),e(K7,Cse),e(Cse,Ght),e(K7,Oht),e(ke,Vht),e(ke,Z7),e(Z7,Qxe),e(Qxe,Xht),e(Z7,zht),e(Z7,wse),e(wse,Qht),e(Z7,Wht),e(ke,Uht),e(ke,eL),e(eL,Wxe),e(Wxe,Hht),e(eL,Jht),e(eL,Ase),e(Ase,Yht),e(eL,Kht),e(ke,Zht),e(ke,oL),e(oL,Uxe),e(Uxe,eut),e(oL,out),e(oL,Lse),e(Lse,rut),e(oL,tut),e(ke,aut),e(ke,rL),e(rL,Hxe),e(Hxe,nut),e(rL,sut),e(rL,yse),e(yse,lut),e(rL,iut),e(ke,dut),e(ke,tL),e(tL,Jxe),e(Jxe,cut),e(tL,mut),e(tL,xse),e(xse,fut),e(tL,gut),e(ke,hut),e(ke,aL),e(aL,Yxe),e(Yxe,uut),e(aL,put),e(aL,$se),e($se,_ut),e(aL,but),e(ke,vut),e(ke,nL),e(nL,Kxe),e(Kxe,Fut),e(nL,Tut),e(nL,kse),e(kse,Mut),e(nL,Eut),e(rt,Cut),M(sL,rt,null),b(m,uoo,_),b(m,Km,_),e(Km,lL),e(lL,Zxe),M(GR,Zxe,null),e(Km,wut),e(Km,e$e),e(e$e,Aut),b(m,poo,_),b(m,Lr,_),M(OR,Lr,null),e(Lr,Lut),e(Lr,Zm),e(Zm,yut),e(Zm,Sse),e(Sse,xut),e(Zm,$ut),e(Zm,Rse),e(Rse,kut),e(Zm,Sut),e(Lr,Rut),e(Lr,VR),e(VR,Put),e(VR,o$e),e(o$e,But),e(VR,Iut),e(Lr,Nut),e(Lr,ma),M(XR,ma,null),e(ma,qut),e(ma,r$e),e(r$e,jut),e(ma,Dut),e(ma,ef),e(ef,Gut),e(ef,t$e),e(t$e,Out),e(ef,Vut),e(ef,Pse),e(Pse,Xut),e(ef,zut),e(ma,Qut),M(iL,ma,null),e(Lr,Wut),e(Lr,tt),M(zR,tt,null),e(tt,Uut),e(tt,a$e),e(a$e,Hut),e(tt,Jut),e(tt,Qn),e(Qn,Yut),e(Qn,n$e),e(n$e,Kut),e(Qn,Zut),e(Qn,s$e),e(s$e,ept),e(Qn,opt),e(Qn,l$e),e(l$e,rpt),e(Qn,tpt),e(tt,apt),e(tt,Se),e(Se,dL),e(dL,i$e),e(i$e,npt),e(dL,spt),e(dL,Bse),e(Bse,lpt),e(dL,ipt),e(Se,dpt),e(Se,cL),e(cL,d$e),e(d$e,cpt),e(cL,mpt),e(cL,Ise),e(Ise,fpt),e(cL,gpt),e(Se,hpt),e(Se,mL),e(mL,c$e),e(c$e,upt),e(mL,ppt),e(mL,Nse),e(Nse,_pt),e(mL,bpt),e(Se,vpt),e(Se,fL),e(fL,m$e),e(m$e,Fpt),e(fL,Tpt),e(fL,qse),e(qse,Mpt),e(fL,Ept),e(Se,Cpt),e(Se,gL),e(gL,f$e),e(f$e,wpt),e(gL,Apt),e(gL,jse),e(jse,Lpt),e(gL,ypt),e(Se,xpt),e(Se,hL),e(hL,g$e),e(g$e,$pt),e(hL,kpt),e(hL,Dse),e(Dse,Spt),e(hL,Rpt),e(Se,Ppt),e(Se,uL),e(uL,h$e),e(h$e,Bpt),e(uL,Ipt),e(uL,Gse),e(Gse,Npt),e(uL,qpt),e(Se,jpt),e(Se,pL),e(pL,u$e),e(u$e,Dpt),e(pL,Gpt),e(pL,Ose),e(Ose,Opt),e(pL,Vpt),e(Se,Xpt),e(Se,_L),e(_L,p$e),e(p$e,zpt),e(_L,Qpt),e(_L,Vse),e(Vse,Wpt),e(_L,Upt),e(Se,Hpt),e(Se,bL),e(bL,_$e),e(_$e,Jpt),e(bL,Ypt),e(bL,Xse),e(Xse,Kpt),e(bL,Zpt),e(tt,e_t),M(vL,tt,null),b(m,_oo,_),b(m,of,_),e(of,FL),e(FL,b$e),M(QR,b$e,null),e(of,o_t),e(of,v$e),e(v$e,r_t),b(m,boo,_),b(m,yr,_),M(WR,yr,null),e(yr,t_t),e(yr,rf),e(rf,a_t),e(rf,zse),e(zse,n_t),e(rf,s_t),e(rf,Qse),e(Qse,l_t),e(rf,i_t),e(yr,d_t),e(yr,UR),e(UR,c_t),e(UR,F$e),e(F$e,m_t),e(UR,f_t),e(yr,g_t),e(yr,fa),M(HR,fa,null),e(fa,h_t),e(fa,T$e),e(T$e,u_t),e(fa,p_t),e(fa,tf),e(tf,__t),e(tf,M$e),e(M$e,b_t),e(tf,v_t),e(tf,Wse),e(Wse,F_t),e(tf,T_t),e(fa,M_t),M(TL,fa,null),e(yr,E_t),e(yr,at),M(JR,at,null),e(at,C_t),e(at,E$e),e(E$e,w_t),e(at,A_t),e(at,Wn),e(Wn,L_t),e(Wn,C$e),e(C$e,y_t),e(Wn,x_t),e(Wn,w$e),e(w$e,$_t),e(Wn,k_t),e(Wn,A$e),e(A$e,S_t),e(Wn,R_t),e(at,P_t),e(at,Re),e(Re,ML),e(ML,L$e),e(L$e,B_t),e(ML,I_t),e(ML,Use),e(Use,N_t),e(ML,q_t),e(Re,j_t),e(Re,EL),e(EL,y$e),e(y$e,D_t),e(EL,G_t),e(EL,Hse),e(Hse,O_t),e(EL,V_t),e(Re,X_t),e(Re,CL),e(CL,x$e),e(x$e,z_t),e(CL,Q_t),e(CL,Jse),e(Jse,W_t),e(CL,U_t),e(Re,H_t),e(Re,wL),e(wL,$$e),e($$e,J_t),e(wL,Y_t),e(wL,Yse),e(Yse,K_t),e(wL,Z_t),e(Re,e2t),e(Re,AL),e(AL,k$e),e(k$e,o2t),e(AL,r2t),e(AL,Kse),e(Kse,t2t),e(AL,a2t),e(Re,n2t),e(Re,LL),e(LL,S$e),e(S$e,s2t),e(LL,l2t),e(LL,Zse),e(Zse,i2t),e(LL,d2t),e(Re,c2t),e(Re,yL),e(yL,R$e),e(R$e,m2t),e(yL,f2t),e(yL,ele),e(ele,g2t),e(yL,h2t),e(Re,u2t),e(Re,xL),e(xL,P$e),e(P$e,p2t),e(xL,_2t),e(xL,ole),e(ole,b2t),e(xL,v2t),e(Re,F2t),e(Re,$L),e($L,B$e),e(B$e,T2t),e($L,M2t),e($L,rle),e(rle,E2t),e($L,C2t),e(Re,w2t),e(Re,kL),e(kL,I$e),e(I$e,A2t),e(kL,L2t),e(kL,tle),e(tle,y2t),e(kL,x2t),e(at,$2t),M(SL,at,null),b(m,voo,_),b(m,af,_),e(af,RL),e(RL,N$e),M(YR,N$e,null),e(af,k2t),e(af,q$e),e(q$e,S2t),b(m,Foo,_),b(m,xr,_),M(KR,xr,null),e(xr,R2t),e(xr,nf),e(nf,P2t),e(nf,ale),e(ale,B2t),e(nf,I2t),e(nf,nle),e(nle,N2t),e(nf,q2t),e(xr,j2t),e(xr,ZR),e(ZR,D2t),e(ZR,j$e),e(j$e,G2t),e(ZR,O2t),e(xr,V2t),e(xr,ga),M(eP,ga,null),e(ga,X2t),e(ga,D$e),e(D$e,z2t),e(ga,Q2t),e(ga,sf),e(sf,W2t),e(sf,G$e),e(G$e,U2t),e(sf,H2t),e(sf,sle),e(sle,J2t),e(sf,Y2t),e(ga,K2t),M(PL,ga,null),e(xr,Z2t),e(xr,nt),M(oP,nt,null),e(nt,ebt),e(nt,O$e),e(O$e,obt),e(nt,rbt),e(nt,Un),e(Un,tbt),e(Un,V$e),e(V$e,abt),e(Un,nbt),e(Un,X$e),e(X$e,sbt),e(Un,lbt),e(Un,z$e),e(z$e,ibt),e(Un,dbt),e(nt,cbt),e(nt,Xe),e(Xe,BL),e(BL,Q$e),e(Q$e,mbt),e(BL,fbt),e(BL,lle),e(lle,gbt),e(BL,hbt),e(Xe,ubt),e(Xe,IL),e(IL,W$e),e(W$e,pbt),e(IL,_bt),e(IL,ile),e(ile,bbt),e(IL,vbt),e(Xe,Fbt),e(Xe,NL),e(NL,U$e),e(U$e,Tbt),e(NL,Mbt),e(NL,dle),e(dle,Ebt),e(NL,Cbt),e(Xe,wbt),e(Xe,qL),e(qL,H$e),e(H$e,Abt),e(qL,Lbt),e(qL,cle),e(cle,ybt),e(qL,xbt),e(Xe,$bt),e(Xe,jL),e(jL,J$e),e(J$e,kbt),e(jL,Sbt),e(jL,mle),e(mle,Rbt),e(jL,Pbt),e(Xe,Bbt),e(Xe,DL),e(DL,Y$e),e(Y$e,Ibt),e(DL,Nbt),e(DL,fle),e(fle,qbt),e(DL,jbt),e(Xe,Dbt),e(Xe,GL),e(GL,K$e),e(K$e,Gbt),e(GL,Obt),e(GL,gle),e(gle,Vbt),e(GL,Xbt),e(Xe,zbt),e(Xe,OL),e(OL,Z$e),e(Z$e,Qbt),e(OL,Wbt),e(OL,hle),e(hle,Ubt),e(OL,Hbt),e(nt,Jbt),M(VL,nt,null),b(m,Too,_),b(m,lf,_),e(lf,XL),e(XL,eke),M(rP,eke,null),e(lf,Ybt),e(lf,oke),e(oke,Kbt),b(m,Moo,_),b(m,$r,_),M(tP,$r,null),e($r,Zbt),e($r,df),e(df,e1t),e(df,ule),e(ule,o1t),e(df,r1t),e(df,ple),e(ple,t1t),e(df,a1t),e($r,n1t),e($r,aP),e(aP,s1t),e(aP,rke),e(rke,l1t),e(aP,i1t),e($r,d1t),e($r,ha),M(nP,ha,null),e(ha,c1t),e(ha,tke),e(tke,m1t),e(ha,f1t),e(ha,cf),e(cf,g1t),e(cf,ake),e(ake,h1t),e(cf,u1t),e(cf,_le),e(_le,p1t),e(cf,_1t),e(ha,b1t),M(zL,ha,null),e($r,v1t),e($r,st),M(sP,st,null),e(st,F1t),e(st,nke),e(nke,T1t),e(st,M1t),e(st,Hn),e(Hn,E1t),e(Hn,ske),e(ske,C1t),e(Hn,w1t),e(Hn,lke),e(lke,A1t),e(Hn,L1t),e(Hn,ike),e(ike,y1t),e(Hn,x1t),e(st,$1t),e(st,ze),e(ze,QL),e(QL,dke),e(dke,k1t),e(QL,S1t),e(QL,ble),e(ble,R1t),e(QL,P1t),e(ze,B1t),e(ze,WL),e(WL,cke),e(cke,I1t),e(WL,N1t),e(WL,vle),e(vle,q1t),e(WL,j1t),e(ze,D1t),e(ze,UL),e(UL,mke),e(mke,G1t),e(UL,O1t),e(UL,Fle),e(Fle,V1t),e(UL,X1t),e(ze,z1t),e(ze,HL),e(HL,fke),e(fke,Q1t),e(HL,W1t),e(HL,Tle),e(Tle,U1t),e(HL,H1t),e(ze,J1t),e(ze,JL),e(JL,gke),e(gke,Y1t),e(JL,K1t),e(JL,Mle),e(Mle,Z1t),e(JL,evt),e(ze,ovt),e(ze,YL),e(YL,hke),e(hke,rvt),e(YL,tvt),e(YL,Ele),e(Ele,avt),e(YL,nvt),e(ze,svt),e(ze,KL),e(KL,uke),e(uke,lvt),e(KL,ivt),e(KL,Cle),e(Cle,dvt),e(KL,cvt),e(ze,mvt),e(ze,ZL),e(ZL,pke),e(pke,fvt),e(ZL,gvt),e(ZL,wle),e(wle,hvt),e(ZL,uvt),e(st,pvt),M(ey,st,null),b(m,Eoo,_),b(m,mf,_),e(mf,oy),e(oy,_ke),M(lP,_ke,null),e(mf,_vt),e(mf,bke),e(bke,bvt),b(m,Coo,_),b(m,kr,_),M(iP,kr,null),e(kr,vvt),e(kr,ff),e(ff,Fvt),e(ff,Ale),e(Ale,Tvt),e(ff,Mvt),e(ff,Lle),e(Lle,Evt),e(ff,Cvt),e(kr,wvt),e(kr,dP),e(dP,Avt),e(dP,vke),e(vke,Lvt),e(dP,yvt),e(kr,xvt),e(kr,ua),M(cP,ua,null),e(ua,$vt),e(ua,Fke),e(Fke,kvt),e(ua,Svt),e(ua,gf),e(gf,Rvt),e(gf,Tke),e(Tke,Pvt),e(gf,Bvt),e(gf,yle),e(yle,Ivt),e(gf,Nvt),e(ua,qvt),M(ry,ua,null),e(kr,jvt),e(kr,lt),M(mP,lt,null),e(lt,Dvt),e(lt,Mke),e(Mke,Gvt),e(lt,Ovt),e(lt,Jn),e(Jn,Vvt),e(Jn,Eke),e(Eke,Xvt),e(Jn,zvt),e(Jn,Cke),e(Cke,Qvt),e(Jn,Wvt),e(Jn,wke),e(wke,Uvt),e(Jn,Hvt),e(lt,Jvt),e(lt,Ake),e(Ake,ty),e(ty,Lke),e(Lke,Yvt),e(ty,Kvt),e(ty,xle),e(xle,Zvt),e(ty,eFt),e(lt,oFt),M(ay,lt,null),b(m,woo,_),b(m,hf,_),e(hf,ny),e(ny,yke),M(fP,yke,null),e(hf,rFt),e(hf,xke),e(xke,tFt),b(m,Aoo,_),b(m,Sr,_),M(gP,Sr,null),e(Sr,aFt),e(Sr,uf),e(uf,nFt),e(uf,$le),e($le,sFt),e(uf,lFt),e(uf,kle),e(kle,iFt),e(uf,dFt),e(Sr,cFt),e(Sr,hP),e(hP,mFt),e(hP,$ke),e($ke,fFt),e(hP,gFt),e(Sr,hFt),e(Sr,pa),M(uP,pa,null),e(pa,uFt),e(pa,kke),e(kke,pFt),e(pa,_Ft),e(pa,pf),e(pf,bFt),e(pf,Ske),e(Ske,vFt),e(pf,FFt),e(pf,Sle),e(Sle,TFt),e(pf,MFt),e(pa,EFt),M(sy,pa,null),e(Sr,CFt),e(Sr,it),M(pP,it,null),e(it,wFt),e(it,Rke),e(Rke,AFt),e(it,LFt),e(it,Yn),e(Yn,yFt),e(Yn,Pke),e(Pke,xFt),e(Yn,$Ft),e(Yn,Bke),e(Bke,kFt),e(Yn,SFt),e(Yn,Ike),e(Ike,RFt),e(Yn,PFt),e(it,BFt),e(it,_P),e(_P,ly),e(ly,Nke),e(Nke,IFt),e(ly,NFt),e(ly,Rle),e(Rle,qFt),e(ly,jFt),e(_P,DFt),e(_P,iy),e(iy,qke),e(qke,GFt),e(iy,OFt),e(iy,Ple),e(Ple,VFt),e(iy,XFt),e(it,zFt),M(dy,it,null),b(m,Loo,_),b(m,_f,_),e(_f,cy),e(cy,jke),M(bP,jke,null),e(_f,QFt),e(_f,Dke),e(Dke,WFt),b(m,yoo,_),b(m,Rr,_),M(vP,Rr,null),e(Rr,UFt),e(Rr,bf),e(bf,HFt),e(bf,Ble),e(Ble,JFt),e(bf,YFt),e(bf,Ile),e(Ile,KFt),e(bf,ZFt),e(Rr,eTt),e(Rr,FP),e(FP,oTt),e(FP,Gke),e(Gke,rTt),e(FP,tTt),e(Rr,aTt),e(Rr,_a),M(TP,_a,null),e(_a,nTt),e(_a,Oke),e(Oke,sTt),e(_a,lTt),e(_a,vf),e(vf,iTt),e(vf,Vke),e(Vke,dTt),e(vf,cTt),e(vf,Nle),e(Nle,mTt),e(vf,fTt),e(_a,gTt),M(my,_a,null),e(Rr,hTt),e(Rr,dt),M(MP,dt,null),e(dt,uTt),e(dt,Xke),e(Xke,pTt),e(dt,_Tt),e(dt,Kn),e(Kn,bTt),e(Kn,zke),e(zke,vTt),e(Kn,FTt),e(Kn,Qke),e(Qke,TTt),e(Kn,MTt),e(Kn,Wke),e(Wke,ETt),e(Kn,CTt),e(dt,wTt),e(dt,Uke),e(Uke,fy),e(fy,Hke),e(Hke,ATt),e(fy,LTt),e(fy,qle),e(qle,yTt),e(fy,xTt),e(dt,$Tt),M(gy,dt,null),xoo=!0},p(m,[_]){const EP={};_&2&&(EP.$$scope={dirty:_,ctx:m}),yf.$set(EP);const Jke={};_&2&&(Jke.$$scope={dirty:_,ctx:m}),Kh.$set(Jke);const Yke={};_&2&&(Yke.$$scope={dirty:_,ctx:m}),Bu.$set(Yke);const Kke={};_&2&&(Kke.$$scope={dirty:_,ctx:m}),Ap.$set(Kke);const CP={};_&2&&(CP.$$scope={dirty:_,ctx:m}),Lp.$set(CP);const Zke={};_&2&&(Zke.$$scope={dirty:_,ctx:m}),Kp.$set(Zke);const Zn={};_&2&&(Zn.$$scope={dirty:_,ctx:m}),Zp.$set(Zn);const eSe={};_&2&&(eSe.$$scope={dirty:_,ctx:m}),r_.$set(eSe);const oSe={};_&2&&(oSe.$$scope={dirty:_,ctx:m}),vb.$set(oSe);const rSe={};_&2&&(rSe.$$scope={dirty:_,ctx:m}),Tb.$set(rSe);const wP={};_&2&&(wP.$$scope={dirty:_,ctx:m}),_1.$set(wP);const tSe={};_&2&&(tSe.$$scope={dirty:_,ctx:m}),v1.$set(tSe);const AP={};_&2&&(AP.$$scope={dirty:_,ctx:m}),dv.$set(AP);const aSe={};_&2&&(aSe.$$scope={dirty:_,ctx:m}),mv.$set(aSe);const LP={};_&2&&(LP.$$scope={dirty:_,ctx:m}),Kv.$set(LP);const nSe={};_&2&&(nSe.$$scope={dirty:_,ctx:m}),eF.$set(nSe);const sSe={};_&2&&(sSe.$$scope={dirty:_,ctx:m}),MF.$set(sSe);const lSe={};_&2&&(lSe.$$scope={dirty:_,ctx:m}),CF.$set(lSe);const Ff={};_&2&&(Ff.$$scope={dirty:_,ctx:m}),AT.$set(Ff);const iSe={};_&2&&(iSe.$$scope={dirty:_,ctx:m}),yT.$set(iSe);const dSe={};_&2&&(dSe.$$scope={dirty:_,ctx:m}),iM.$set(dSe);const cSe={};_&2&&(cSe.$$scope={dirty:_,ctx:m}),cM.$set(cSe);const yP={};_&2&&(yP.$$scope={dirty:_,ctx:m}),vM.$set(yP);const mSe={};_&2&&(mSe.$$scope={dirty:_,ctx:m}),TM.$set(mSe);const fSe={};_&2&&(fSe.$$scope={dirty:_,ctx:m}),iE.$set(fSe);const gSe={};_&2&&(gSe.$$scope={dirty:_,ctx:m}),cE.$set(gSe);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:m}),t4.$set(ht);const xP={};_&2&&(xP.$$scope={dirty:_,ctx:m}),n4.$set(xP);const hSe={};_&2&&(hSe.$$scope={dirty:_,ctx:m}),i4.$set(hSe);const $P={};_&2&&($P.$$scope={dirty:_,ctx:m}),c4.$set($P);const uSe={};_&2&&(uSe.$$scope={dirty:_,ctx:m}),u4.$set(uSe);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:m}),_4.$set(ut);const pSe={};_&2&&(pSe.$$scope={dirty:_,ctx:m}),P4.$set(pSe);const Tf={};_&2&&(Tf.$$scope={dirty:_,ctx:m}),I4.$set(Tf);const _Se={};_&2&&(_Se.$$scope={dirty:_,ctx:m}),j4.$set(_Se);const bSe={};_&2&&(bSe.$$scope={dirty:_,ctx:m}),G4.$set(bSe);const L={};_&2&&(L.$$scope={dirty:_,ctx:m}),X4.$set(L);const hy={};_&2&&(hy.$$scope={dirty:_,ctx:m}),Q4.$set(hy);const vSe={};_&2&&(vSe.$$scope={dirty:_,ctx:m}),H4.$set(vSe);const FSe={};_&2&&(FSe.$$scope={dirty:_,ctx:m}),Y4.$set(FSe);const uy={};_&2&&(uy.$$scope={dirty:_,ctx:m}),iC.$set(uy);const TSe={};_&2&&(TSe.$$scope={dirty:_,ctx:m}),cC.$set(TSe);const MSe={};_&2&&(MSe.$$scope={dirty:_,ctx:m}),_C.$set(MSe);const py={};_&2&&(py.$$scope={dirty:_,ctx:m}),vC.$set(py);const ESe={};_&2&&(ESe.$$scope={dirty:_,ctx:m}),kC.$set(ESe);const CSe={};_&2&&(CSe.$$scope={dirty:_,ctx:m}),RC.$set(CSe);const _y={};_&2&&(_y.$$scope={dirty:_,ctx:m}),NC.$set(_y);const wSe={};_&2&&(wSe.$$scope={dirty:_,ctx:m}),jC.$set(wSe);const ASe={};_&2&&(ASe.$$scope={dirty:_,ctx:m}),QC.$set(ASe);const by={};_&2&&(by.$$scope={dirty:_,ctx:m}),UC.$set(by);const LSe={};_&2&&(LSe.$$scope={dirty:_,ctx:m}),e3.$set(LSe);const ySe={};_&2&&(ySe.$$scope={dirty:_,ctx:m}),r3.$set(ySe);const vy={};_&2&&(vy.$$scope={dirty:_,ctx:m}),i3.$set(vy);const xSe={};_&2&&(xSe.$$scope={dirty:_,ctx:m}),c3.$set(xSe);const $Se={};_&2&&($Se.$$scope={dirty:_,ctx:m}),g3.$set($Se);const Fy={};_&2&&(Fy.$$scope={dirty:_,ctx:m}),u3.$set(Fy);const kSe={};_&2&&(kSe.$$scope={dirty:_,ctx:m}),M3.$set(kSe);const SSe={};_&2&&(SSe.$$scope={dirty:_,ctx:m}),C3.$set(SSe);const Ty={};_&2&&(Ty.$$scope={dirty:_,ctx:m}),L3.$set(Ty);const RSe={};_&2&&(RSe.$$scope={dirty:_,ctx:m}),x3.$set(RSe);const PSe={};_&2&&(PSe.$$scope={dirty:_,ctx:m}),$5.$set(PSe);const My={};_&2&&(My.$$scope={dirty:_,ctx:m}),S5.$set(My);const BSe={};_&2&&(BSe.$$scope={dirty:_,ctx:m}),r0.$set(BSe);const ISe={};_&2&&(ISe.$$scope={dirty:_,ctx:m}),a0.$set(ISe);const Ey={};_&2&&(Ey.$$scope={dirty:_,ctx:m}),v0.$set(Ey);const NSe={};_&2&&(NSe.$$scope={dirty:_,ctx:m}),T0.$set(NSe);const qSe={};_&2&&(qSe.$$scope={dirty:_,ctx:m}),$0.$set(qSe);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:m}),S0.$set(Cy);const jSe={};_&2&&(jSe.$$scope={dirty:_,ctx:m}),I0.$set(jSe);const DSe={};_&2&&(DSe.$$scope={dirty:_,ctx:m}),q0.$set(DSe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:m}),nw.$set(wy);const GSe={};_&2&&(GSe.$$scope={dirty:_,ctx:m}),lw.$set(GSe);const OSe={};_&2&&(OSe.$$scope={dirty:_,ctx:m}),bw.$set(OSe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:m}),Fw.$set(Ay);const VSe={};_&2&&(VSe.$$scope={dirty:_,ctx:m}),Uw.$set(VSe);const XSe={};_&2&&(XSe.$$scope={dirty:_,ctx:m}),Jw.$set(XSe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:m}),hA.$set(Ly);const zSe={};_&2&&(zSe.$$scope={dirty:_,ctx:m}),pA.$set(zSe);const QSe={};_&2&&(QSe.$$scope={dirty:_,ctx:m}),vA.$set(QSe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:m}),TA.$set(yy);const WSe={};_&2&&(WSe.$$scope={dirty:_,ctx:m}),EA.$set(WSe);const USe={};_&2&&(USe.$$scope={dirty:_,ctx:m}),wA.$set(USe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:m}),LA.$set(xy);const HSe={};_&2&&(HSe.$$scope={dirty:_,ctx:m}),xA.$set(HSe);const JSe={};_&2&&(JSe.$$scope={dirty:_,ctx:m}),YA.$set(JSe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:m}),ZA.$set($y);const YSe={};_&2&&(YSe.$$scope={dirty:_,ctx:m}),T6.$set(YSe);const KSe={};_&2&&(KSe.$$scope={dirty:_,ctx:m}),E6.$set(KSe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:m}),w6.$set(ky);const ZSe={};_&2&&(ZSe.$$scope={dirty:_,ctx:m}),L6.$set(ZSe);const eRe={};_&2&&(eRe.$$scope={dirty:_,ctx:m}),x6.$set(eRe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:m}),k6.$set(Sy);const oRe={};_&2&&(oRe.$$scope={dirty:_,ctx:m}),n7.$set(oRe);const rRe={};_&2&&(rRe.$$scope={dirty:_,ctx:m}),l7.$set(rRe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:m}),b7.$set(Ry);const tRe={};_&2&&(tRe.$$scope={dirty:_,ctx:m}),F7.$set(tRe);const aRe={};_&2&&(aRe.$$scope={dirty:_,ctx:m}),P7.$set(aRe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:m}),I7.$set(Py);const nRe={};_&2&&(nRe.$$scope={dirty:_,ctx:m}),W7.$set(nRe);const sRe={};_&2&&(sRe.$$scope={dirty:_,ctx:m}),H7.$set(sRe);const By={};_&2&&(By.$$scope={dirty:_,ctx:m}),sL.$set(By);const lRe={};_&2&&(lRe.$$scope={dirty:_,ctx:m}),iL.$set(lRe);const iRe={};_&2&&(iRe.$$scope={dirty:_,ctx:m}),vL.$set(iRe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:m}),TL.$set(Iy);const dRe={};_&2&&(dRe.$$scope={dirty:_,ctx:m}),SL.$set(dRe);const cRe={};_&2&&(cRe.$$scope={dirty:_,ctx:m}),PL.$set(cRe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:m}),VL.$set(Ny);const mRe={};_&2&&(mRe.$$scope={dirty:_,ctx:m}),zL.$set(mRe);const fRe={};_&2&&(fRe.$$scope={dirty:_,ctx:m}),ey.$set(fRe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:m}),ry.$set(qy);const gRe={};_&2&&(gRe.$$scope={dirty:_,ctx:m}),ay.$set(gRe);const hRe={};_&2&&(hRe.$$scope={dirty:_,ctx:m}),sy.$set(hRe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:m}),dy.$set(jy);const uRe={};_&2&&(uRe.$$scope={dirty:_,ctx:m}),my.$set(uRe);const pRe={};_&2&&(pRe.$$scope={dirty:_,ctx:m}),gy.$set(pRe)},i(m){xoo||(E(d.$$.fragment,m),E(Qa.$$.fragment,m),E(U9.$$.fragment,m),E(H9.$$.fragment,m),E(yf.$$.fragment,m),E(J9.$$.fragment,m),E(Y9.$$.fragment,m),E(ex.$$.fragment,m),E(Kh.$$.fragment,m),E(ox.$$.fragment,m),E(rx.$$.fragment,m),E(tx.$$.fragment,m),E(sx.$$.fragment,m),E(Bu.$$.fragment,m),E(lx.$$.fragment,m),E(ix.$$.fragment,m),E(dx.$$.fragment,m),E(fx.$$.fragment,m),E(Ap.$$.fragment,m),E(Lp.$$.fragment,m),E(gx.$$.fragment,m),E(hx.$$.fragment,m),E(ux.$$.fragment,m),E(bx.$$.fragment,m),E(Kp.$$.fragment,m),E(Zp.$$.fragment,m),E(vx.$$.fragment,m),E(Fx.$$.fragment,m),E(Tx.$$.fragment,m),E(Ex.$$.fragment,m),E(r_.$$.fragment,m),E(Cx.$$.fragment,m),E(vb.$$.fragment,m),E(wx.$$.fragment,m),E(Ax.$$.fragment,m),E(yx.$$.fragment,m),E(Tb.$$.fragment,m),E(xx.$$.fragment,m),E(_1.$$.fragment,m),E($x.$$.fragment,m),E(kx.$$.fragment,m),E(Rx.$$.fragment,m),E(v1.$$.fragment,m),E(Px.$$.fragment,m),E(dv.$$.fragment,m),E(Bx.$$.fragment,m),E(Ix.$$.fragment,m),E(qx.$$.fragment,m),E(mv.$$.fragment,m),E(jx.$$.fragment,m),E(Kv.$$.fragment,m),E(Dx.$$.fragment,m),E(Gx.$$.fragment,m),E(Vx.$$.fragment,m),E(eF.$$.fragment,m),E(Xx.$$.fragment,m),E(MF.$$.fragment,m),E(zx.$$.fragment,m),E(Qx.$$.fragment,m),E(Ux.$$.fragment,m),E(CF.$$.fragment,m),E(Hx.$$.fragment,m),E(AT.$$.fragment,m),E(Jx.$$.fragment,m),E(Yx.$$.fragment,m),E(Zx.$$.fragment,m),E(yT.$$.fragment,m),E(e$.$$.fragment,m),E(iM.$$.fragment,m),E(o$.$$.fragment,m),E(r$.$$.fragment,m),E(a$.$$.fragment,m),E(cM.$$.fragment,m),E(n$.$$.fragment,m),E(vM.$$.fragment,m),E(s$.$$.fragment,m),E(l$.$$.fragment,m),E(d$.$$.fragment,m),E(TM.$$.fragment,m),E(c$.$$.fragment,m),E(iE.$$.fragment,m),E(m$.$$.fragment,m),E(f$.$$.fragment,m),E(h$.$$.fragment,m),E(cE.$$.fragment,m),E(u$.$$.fragment,m),E(t4.$$.fragment,m),E(p$.$$.fragment,m),E(_$.$$.fragment,m),E(v$.$$.fragment,m),E(n4.$$.fragment,m),E(F$.$$.fragment,m),E(i4.$$.fragment,m),E(T$.$$.fragment,m),E(M$.$$.fragment,m),E(C$.$$.fragment,m),E(c4.$$.fragment,m),E(w$.$$.fragment,m),E(u4.$$.fragment,m),E(A$.$$.fragment,m),E(L$.$$.fragment,m),E(x$.$$.fragment,m),E(_4.$$.fragment,m),E($$.$$.fragment,m),E(P4.$$.fragment,m),E(k$.$$.fragment,m),E(S$.$$.fragment,m),E(P$.$$.fragment,m),E(I4.$$.fragment,m),E(B$.$$.fragment,m),E(j4.$$.fragment,m),E(I$.$$.fragment,m),E(N$.$$.fragment,m),E(j$.$$.fragment,m),E(G4.$$.fragment,m),E(D$.$$.fragment,m),E(X4.$$.fragment,m),E(G$.$$.fragment,m),E(O$.$$.fragment,m),E(X$.$$.fragment,m),E(Q4.$$.fragment,m),E(z$.$$.fragment,m),E(H4.$$.fragment,m),E(Q$.$$.fragment,m),E(W$.$$.fragment,m),E(H$.$$.fragment,m),E(Y4.$$.fragment,m),E(J$.$$.fragment,m),E(iC.$$.fragment,m),E(Y$.$$.fragment,m),E(K$.$$.fragment,m),E(ek.$$.fragment,m),E(cC.$$.fragment,m),E(ok.$$.fragment,m),E(_C.$$.fragment,m),E(rk.$$.fragment,m),E(tk.$$.fragment,m),E(nk.$$.fragment,m),E(vC.$$.fragment,m),E(sk.$$.fragment,m),E(kC.$$.fragment,m),E(lk.$$.fragment,m),E(ik.$$.fragment,m),E(ck.$$.fragment,m),E(RC.$$.fragment,m),E(mk.$$.fragment,m),E(NC.$$.fragment,m),E(gk.$$.fragment,m),E(hk.$$.fragment,m),E(pk.$$.fragment,m),E(jC.$$.fragment,m),E(_k.$$.fragment,m),E(QC.$$.fragment,m),E(bk.$$.fragment,m),E(vk.$$.fragment,m),E(Tk.$$.fragment,m),E(UC.$$.fragment,m),E(Mk.$$.fragment,m),E(e3.$$.fragment,m),E(Ek.$$.fragment,m),E(Ck.$$.fragment,m),E(Ak.$$.fragment,m),E(r3.$$.fragment,m),E(Lk.$$.fragment,m),E(i3.$$.fragment,m),E(yk.$$.fragment,m),E(xk.$$.fragment,m),E(kk.$$.fragment,m),E(c3.$$.fragment,m),E(Sk.$$.fragment,m),E(g3.$$.fragment,m),E(Rk.$$.fragment,m),E(Pk.$$.fragment,m),E(Ik.$$.fragment,m),E(u3.$$.fragment,m),E(Nk.$$.fragment,m),E(M3.$$.fragment,m),E(qk.$$.fragment,m),E(jk.$$.fragment,m),E(Gk.$$.fragment,m),E(C3.$$.fragment,m),E(Ok.$$.fragment,m),E(L3.$$.fragment,m),E(Vk.$$.fragment,m),E(Xk.$$.fragment,m),E(Qk.$$.fragment,m),E(x3.$$.fragment,m),E(Wk.$$.fragment,m),E($5.$$.fragment,m),E(Uk.$$.fragment,m),E(Hk.$$.fragment,m),E(Yk.$$.fragment,m),E(S5.$$.fragment,m),E(Kk.$$.fragment,m),E(r0.$$.fragment,m),E(Zk.$$.fragment,m),E(eS.$$.fragment,m),E(rS.$$.fragment,m),E(a0.$$.fragment,m),E(tS.$$.fragment,m),E(v0.$$.fragment,m),E(aS.$$.fragment,m),E(nS.$$.fragment,m),E(lS.$$.fragment,m),E(T0.$$.fragment,m),E(iS.$$.fragment,m),E($0.$$.fragment,m),E(dS.$$.fragment,m),E(cS.$$.fragment,m),E(fS.$$.fragment,m),E(S0.$$.fragment,m),E(gS.$$.fragment,m),E(I0.$$.fragment,m),E(hS.$$.fragment,m),E(uS.$$.fragment,m),E(_S.$$.fragment,m),E(q0.$$.fragment,m),E(bS.$$.fragment,m),E(nw.$$.fragment,m),E(vS.$$.fragment,m),E(FS.$$.fragment,m),E(MS.$$.fragment,m),E(lw.$$.fragment,m),E(ES.$$.fragment,m),E(bw.$$.fragment,m),E(CS.$$.fragment,m),E(wS.$$.fragment,m),E(LS.$$.fragment,m),E(Fw.$$.fragment,m),E(yS.$$.fragment,m),E(Uw.$$.fragment,m),E(xS.$$.fragment,m),E($S.$$.fragment,m),E(SS.$$.fragment,m),E(Jw.$$.fragment,m),E(RS.$$.fragment,m),E(hA.$$.fragment,m),E(PS.$$.fragment,m),E(BS.$$.fragment,m),E(NS.$$.fragment,m),E(pA.$$.fragment,m),E(qS.$$.fragment,m),E(vA.$$.fragment,m),E(DS.$$.fragment,m),E(GS.$$.fragment,m),E(VS.$$.fragment,m),E(TA.$$.fragment,m),E(XS.$$.fragment,m),E(EA.$$.fragment,m),E(zS.$$.fragment,m),E(QS.$$.fragment,m),E(US.$$.fragment,m),E(wA.$$.fragment,m),E(HS.$$.fragment,m),E(LA.$$.fragment,m),E(JS.$$.fragment,m),E(YS.$$.fragment,m),E(ZS.$$.fragment,m),E(xA.$$.fragment,m),E(eR.$$.fragment,m),E(YA.$$.fragment,m),E(oR.$$.fragment,m),E(rR.$$.fragment,m),E(aR.$$.fragment,m),E(ZA.$$.fragment,m),E(nR.$$.fragment,m),E(T6.$$.fragment,m),E(sR.$$.fragment,m),E(lR.$$.fragment,m),E(dR.$$.fragment,m),E(E6.$$.fragment,m),E(cR.$$.fragment,m),E(w6.$$.fragment,m),E(mR.$$.fragment,m),E(fR.$$.fragment,m),E(hR.$$.fragment,m),E(L6.$$.fragment,m),E(uR.$$.fragment,m),E(x6.$$.fragment,m),E(pR.$$.fragment,m),E(_R.$$.fragment,m),E(vR.$$.fragment,m),E(k6.$$.fragment,m),E(FR.$$.fragment,m),E(n7.$$.fragment,m),E(TR.$$.fragment,m),E(MR.$$.fragment,m),E(CR.$$.fragment,m),E(l7.$$.fragment,m),E(wR.$$.fragment,m),E(b7.$$.fragment,m),E(AR.$$.fragment,m),E(LR.$$.fragment,m),E(xR.$$.fragment,m),E(F7.$$.fragment,m),E($R.$$.fragment,m),E(P7.$$.fragment,m),E(kR.$$.fragment,m),E(SR.$$.fragment,m),E(PR.$$.fragment,m),E(I7.$$.fragment,m),E(BR.$$.fragment,m),E(W7.$$.fragment,m),E(IR.$$.fragment,m),E(NR.$$.fragment,m),E(jR.$$.fragment,m),E(H7.$$.fragment,m),E(DR.$$.fragment,m),E(sL.$$.fragment,m),E(GR.$$.fragment,m),E(OR.$$.fragment,m),E(XR.$$.fragment,m),E(iL.$$.fragment,m),E(zR.$$.fragment,m),E(vL.$$.fragment,m),E(QR.$$.fragment,m),E(WR.$$.fragment,m),E(HR.$$.fragment,m),E(TL.$$.fragment,m),E(JR.$$.fragment,m),E(SL.$$.fragment,m),E(YR.$$.fragment,m),E(KR.$$.fragment,m),E(eP.$$.fragment,m),E(PL.$$.fragment,m),E(oP.$$.fragment,m),E(VL.$$.fragment,m),E(rP.$$.fragment,m),E(tP.$$.fragment,m),E(nP.$$.fragment,m),E(zL.$$.fragment,m),E(sP.$$.fragment,m),E(ey.$$.fragment,m),E(lP.$$.fragment,m),E(iP.$$.fragment,m),E(cP.$$.fragment,m),E(ry.$$.fragment,m),E(mP.$$.fragment,m),E(ay.$$.fragment,m),E(fP.$$.fragment,m),E(gP.$$.fragment,m),E(uP.$$.fragment,m),E(sy.$$.fragment,m),E(pP.$$.fragment,m),E(dy.$$.fragment,m),E(bP.$$.fragment,m),E(vP.$$.fragment,m),E(TP.$$.fragment,m),E(my.$$.fragment,m),E(MP.$$.fragment,m),E(gy.$$.fragment,m),xoo=!0)},o(m){C(d.$$.fragment,m),C(Qa.$$.fragment,m),C(U9.$$.fragment,m),C(H9.$$.fragment,m),C(yf.$$.fragment,m),C(J9.$$.fragment,m),C(Y9.$$.fragment,m),C(ex.$$.fragment,m),C(Kh.$$.fragment,m),C(ox.$$.fragment,m),C(rx.$$.fragment,m),C(tx.$$.fragment,m),C(sx.$$.fragment,m),C(Bu.$$.fragment,m),C(lx.$$.fragment,m),C(ix.$$.fragment,m),C(dx.$$.fragment,m),C(fx.$$.fragment,m),C(Ap.$$.fragment,m),C(Lp.$$.fragment,m),C(gx.$$.fragment,m),C(hx.$$.fragment,m),C(ux.$$.fragment,m),C(bx.$$.fragment,m),C(Kp.$$.fragment,m),C(Zp.$$.fragment,m),C(vx.$$.fragment,m),C(Fx.$$.fragment,m),C(Tx.$$.fragment,m),C(Ex.$$.fragment,m),C(r_.$$.fragment,m),C(Cx.$$.fragment,m),C(vb.$$.fragment,m),C(wx.$$.fragment,m),C(Ax.$$.fragment,m),C(yx.$$.fragment,m),C(Tb.$$.fragment,m),C(xx.$$.fragment,m),C(_1.$$.fragment,m),C($x.$$.fragment,m),C(kx.$$.fragment,m),C(Rx.$$.fragment,m),C(v1.$$.fragment,m),C(Px.$$.fragment,m),C(dv.$$.fragment,m),C(Bx.$$.fragment,m),C(Ix.$$.fragment,m),C(qx.$$.fragment,m),C(mv.$$.fragment,m),C(jx.$$.fragment,m),C(Kv.$$.fragment,m),C(Dx.$$.fragment,m),C(Gx.$$.fragment,m),C(Vx.$$.fragment,m),C(eF.$$.fragment,m),C(Xx.$$.fragment,m),C(MF.$$.fragment,m),C(zx.$$.fragment,m),C(Qx.$$.fragment,m),C(Ux.$$.fragment,m),C(CF.$$.fragment,m),C(Hx.$$.fragment,m),C(AT.$$.fragment,m),C(Jx.$$.fragment,m),C(Yx.$$.fragment,m),C(Zx.$$.fragment,m),C(yT.$$.fragment,m),C(e$.$$.fragment,m),C(iM.$$.fragment,m),C(o$.$$.fragment,m),C(r$.$$.fragment,m),C(a$.$$.fragment,m),C(cM.$$.fragment,m),C(n$.$$.fragment,m),C(vM.$$.fragment,m),C(s$.$$.fragment,m),C(l$.$$.fragment,m),C(d$.$$.fragment,m),C(TM.$$.fragment,m),C(c$.$$.fragment,m),C(iE.$$.fragment,m),C(m$.$$.fragment,m),C(f$.$$.fragment,m),C(h$.$$.fragment,m),C(cE.$$.fragment,m),C(u$.$$.fragment,m),C(t4.$$.fragment,m),C(p$.$$.fragment,m),C(_$.$$.fragment,m),C(v$.$$.fragment,m),C(n4.$$.fragment,m),C(F$.$$.fragment,m),C(i4.$$.fragment,m),C(T$.$$.fragment,m),C(M$.$$.fragment,m),C(C$.$$.fragment,m),C(c4.$$.fragment,m),C(w$.$$.fragment,m),C(u4.$$.fragment,m),C(A$.$$.fragment,m),C(L$.$$.fragment,m),C(x$.$$.fragment,m),C(_4.$$.fragment,m),C($$.$$.fragment,m),C(P4.$$.fragment,m),C(k$.$$.fragment,m),C(S$.$$.fragment,m),C(P$.$$.fragment,m),C(I4.$$.fragment,m),C(B$.$$.fragment,m),C(j4.$$.fragment,m),C(I$.$$.fragment,m),C(N$.$$.fragment,m),C(j$.$$.fragment,m),C(G4.$$.fragment,m),C(D$.$$.fragment,m),C(X4.$$.fragment,m),C(G$.$$.fragment,m),C(O$.$$.fragment,m),C(X$.$$.fragment,m),C(Q4.$$.fragment,m),C(z$.$$.fragment,m),C(H4.$$.fragment,m),C(Q$.$$.fragment,m),C(W$.$$.fragment,m),C(H$.$$.fragment,m),C(Y4.$$.fragment,m),C(J$.$$.fragment,m),C(iC.$$.fragment,m),C(Y$.$$.fragment,m),C(K$.$$.fragment,m),C(ek.$$.fragment,m),C(cC.$$.fragment,m),C(ok.$$.fragment,m),C(_C.$$.fragment,m),C(rk.$$.fragment,m),C(tk.$$.fragment,m),C(nk.$$.fragment,m),C(vC.$$.fragment,m),C(sk.$$.fragment,m),C(kC.$$.fragment,m),C(lk.$$.fragment,m),C(ik.$$.fragment,m),C(ck.$$.fragment,m),C(RC.$$.fragment,m),C(mk.$$.fragment,m),C(NC.$$.fragment,m),C(gk.$$.fragment,m),C(hk.$$.fragment,m),C(pk.$$.fragment,m),C(jC.$$.fragment,m),C(_k.$$.fragment,m),C(QC.$$.fragment,m),C(bk.$$.fragment,m),C(vk.$$.fragment,m),C(Tk.$$.fragment,m),C(UC.$$.fragment,m),C(Mk.$$.fragment,m),C(e3.$$.fragment,m),C(Ek.$$.fragment,m),C(Ck.$$.fragment,m),C(Ak.$$.fragment,m),C(r3.$$.fragment,m),C(Lk.$$.fragment,m),C(i3.$$.fragment,m),C(yk.$$.fragment,m),C(xk.$$.fragment,m),C(kk.$$.fragment,m),C(c3.$$.fragment,m),C(Sk.$$.fragment,m),C(g3.$$.fragment,m),C(Rk.$$.fragment,m),C(Pk.$$.fragment,m),C(Ik.$$.fragment,m),C(u3.$$.fragment,m),C(Nk.$$.fragment,m),C(M3.$$.fragment,m),C(qk.$$.fragment,m),C(jk.$$.fragment,m),C(Gk.$$.fragment,m),C(C3.$$.fragment,m),C(Ok.$$.fragment,m),C(L3.$$.fragment,m),C(Vk.$$.fragment,m),C(Xk.$$.fragment,m),C(Qk.$$.fragment,m),C(x3.$$.fragment,m),C(Wk.$$.fragment,m),C($5.$$.fragment,m),C(Uk.$$.fragment,m),C(Hk.$$.fragment,m),C(Yk.$$.fragment,m),C(S5.$$.fragment,m),C(Kk.$$.fragment,m),C(r0.$$.fragment,m),C(Zk.$$.fragment,m),C(eS.$$.fragment,m),C(rS.$$.fragment,m),C(a0.$$.fragment,m),C(tS.$$.fragment,m),C(v0.$$.fragment,m),C(aS.$$.fragment,m),C(nS.$$.fragment,m),C(lS.$$.fragment,m),C(T0.$$.fragment,m),C(iS.$$.fragment,m),C($0.$$.fragment,m),C(dS.$$.fragment,m),C(cS.$$.fragment,m),C(fS.$$.fragment,m),C(S0.$$.fragment,m),C(gS.$$.fragment,m),C(I0.$$.fragment,m),C(hS.$$.fragment,m),C(uS.$$.fragment,m),C(_S.$$.fragment,m),C(q0.$$.fragment,m),C(bS.$$.fragment,m),C(nw.$$.fragment,m),C(vS.$$.fragment,m),C(FS.$$.fragment,m),C(MS.$$.fragment,m),C(lw.$$.fragment,m),C(ES.$$.fragment,m),C(bw.$$.fragment,m),C(CS.$$.fragment,m),C(wS.$$.fragment,m),C(LS.$$.fragment,m),C(Fw.$$.fragment,m),C(yS.$$.fragment,m),C(Uw.$$.fragment,m),C(xS.$$.fragment,m),C($S.$$.fragment,m),C(SS.$$.fragment,m),C(Jw.$$.fragment,m),C(RS.$$.fragment,m),C(hA.$$.fragment,m),C(PS.$$.fragment,m),C(BS.$$.fragment,m),C(NS.$$.fragment,m),C(pA.$$.fragment,m),C(qS.$$.fragment,m),C(vA.$$.fragment,m),C(DS.$$.fragment,m),C(GS.$$.fragment,m),C(VS.$$.fragment,m),C(TA.$$.fragment,m),C(XS.$$.fragment,m),C(EA.$$.fragment,m),C(zS.$$.fragment,m),C(QS.$$.fragment,m),C(US.$$.fragment,m),C(wA.$$.fragment,m),C(HS.$$.fragment,m),C(LA.$$.fragment,m),C(JS.$$.fragment,m),C(YS.$$.fragment,m),C(ZS.$$.fragment,m),C(xA.$$.fragment,m),C(eR.$$.fragment,m),C(YA.$$.fragment,m),C(oR.$$.fragment,m),C(rR.$$.fragment,m),C(aR.$$.fragment,m),C(ZA.$$.fragment,m),C(nR.$$.fragment,m),C(T6.$$.fragment,m),C(sR.$$.fragment,m),C(lR.$$.fragment,m),C(dR.$$.fragment,m),C(E6.$$.fragment,m),C(cR.$$.fragment,m),C(w6.$$.fragment,m),C(mR.$$.fragment,m),C(fR.$$.fragment,m),C(hR.$$.fragment,m),C(L6.$$.fragment,m),C(uR.$$.fragment,m),C(x6.$$.fragment,m),C(pR.$$.fragment,m),C(_R.$$.fragment,m),C(vR.$$.fragment,m),C(k6.$$.fragment,m),C(FR.$$.fragment,m),C(n7.$$.fragment,m),C(TR.$$.fragment,m),C(MR.$$.fragment,m),C(CR.$$.fragment,m),C(l7.$$.fragment,m),C(wR.$$.fragment,m),C(b7.$$.fragment,m),C(AR.$$.fragment,m),C(LR.$$.fragment,m),C(xR.$$.fragment,m),C(F7.$$.fragment,m),C($R.$$.fragment,m),C(P7.$$.fragment,m),C(kR.$$.fragment,m),C(SR.$$.fragment,m),C(PR.$$.fragment,m),C(I7.$$.fragment,m),C(BR.$$.fragment,m),C(W7.$$.fragment,m),C(IR.$$.fragment,m),C(NR.$$.fragment,m),C(jR.$$.fragment,m),C(H7.$$.fragment,m),C(DR.$$.fragment,m),C(sL.$$.fragment,m),C(GR.$$.fragment,m),C(OR.$$.fragment,m),C(XR.$$.fragment,m),C(iL.$$.fragment,m),C(zR.$$.fragment,m),C(vL.$$.fragment,m),C(QR.$$.fragment,m),C(WR.$$.fragment,m),C(HR.$$.fragment,m),C(TL.$$.fragment,m),C(JR.$$.fragment,m),C(SL.$$.fragment,m),C(YR.$$.fragment,m),C(KR.$$.fragment,m),C(eP.$$.fragment,m),C(PL.$$.fragment,m),C(oP.$$.fragment,m),C(VL.$$.fragment,m),C(rP.$$.fragment,m),C(tP.$$.fragment,m),C(nP.$$.fragment,m),C(zL.$$.fragment,m),C(sP.$$.fragment,m),C(ey.$$.fragment,m),C(lP.$$.fragment,m),C(iP.$$.fragment,m),C(cP.$$.fragment,m),C(ry.$$.fragment,m),C(mP.$$.fragment,m),C(ay.$$.fragment,m),C(fP.$$.fragment,m),C(gP.$$.fragment,m),C(uP.$$.fragment,m),C(sy.$$.fragment,m),C(pP.$$.fragment,m),C(dy.$$.fragment,m),C(bP.$$.fragment,m),C(vP.$$.fragment,m),C(TP.$$.fragment,m),C(my.$$.fragment,m),C(MP.$$.fragment,m),C(gy.$$.fragment,m),xoo=!1},d(m){t(g),m&&t(v),m&&t(u),w(d),m&&t(Ef),m&&t(pt),m&&t(Ve),m&&t(He),m&&t(wf),w(Qa,m),m&&t(Je),m&&t(Ae),m&&t(xo),m&&t(Wa),m&&t(pZe),m&&t(cd),w(U9),m&&t(_Ze),m&&t(as),m&&t(bZe),w(H9,m),m&&t(vZe),m&&t(ZB),m&&t(FZe),w(yf,m),m&&t(TZe),m&&t(md),w(J9),m&&t(MZe),m&&t($o),w(Y9),w(ex),w(Kh),w(ox),m&&t(EZe),m&&t(gd),w(rx),m&&t(CZe),m&&t(ko),w(tx),w(sx),w(Bu),w(lx),m&&t(wZe),m&&t(hd),w(ix),m&&t(AZe),m&&t(So),w(dx),w(fx),w(Ap),w(Lp),w(gx),m&&t(LZe),m&&t(ud),w(hx),m&&t(yZe),m&&t(Ro),w(ux),w(bx),w(Kp),w(Zp),w(vx),m&&t(xZe),m&&t(_d),w(Fx),m&&t($Ze),m&&t(Po),w(Tx),w(Ex),w(r_),w(Cx),w(vb),m&&t(kZe),m&&t(Fd),w(wx),m&&t(SZe),m&&t(Bo),w(Ax),w(yx),w(Tb),w(xx),w(_1),m&&t(RZe),m&&t(Ed),w($x),m&&t(PZe),m&&t(Io),w(kx),w(Rx),w(v1),w(Px),w(dv),m&&t(BZe),m&&t(Ad),w(Bx),m&&t(IZe),m&&t(No),w(Ix),w(qx),w(mv),w(jx),w(Kv),m&&t(NZe),m&&t(xd),w(Dx),m&&t(qZe),m&&t(qo),w(Gx),w(Vx),w(eF),w(Xx),w(MF),m&&t(jZe),m&&t(Sd),w(zx),m&&t(DZe),m&&t(jo),w(Qx),w(Ux),w(CF),w(Hx),w(AT),m&&t(GZe),m&&t(Bd),w(Jx),m&&t(OZe),m&&t(Do),w(Yx),w(Zx),w(yT),w(e$),w(iM),m&&t(VZe),m&&t(qd),w(o$),m&&t(XZe),m&&t(Go),w(r$),w(a$),w(cM),w(n$),w(vM),m&&t(zZe),m&&t(Gd),w(s$),m&&t(QZe),m&&t(Oo),w(l$),w(d$),w(TM),w(c$),w(iE),m&&t(WZe),m&&t(Xd),w(m$),m&&t(UZe),m&&t(Vo),w(f$),w(h$),w(cE),w(u$),w(t4),m&&t(HZe),m&&t(Wd),w(p$),m&&t(JZe),m&&t(Xo),w(_$),w(v$),w(n4),w(F$),w(i4),m&&t(YZe),m&&t(Jd),w(T$),m&&t(KZe),m&&t(zo),w(M$),w(C$),w(c4),w(w$),w(u4),m&&t(ZZe),m&&t(ec),w(A$),m&&t(eeo),m&&t(Qo),w(L$),w(x$),w(_4),w($$),w(P4),m&&t(oeo),m&&t(tc),w(k$),m&&t(reo),m&&t(Wo),w(S$),w(P$),w(I4),w(B$),w(j4),m&&t(teo),m&&t(sc),w(I$),m&&t(aeo),m&&t(Uo),w(N$),w(j$),w(G4),w(D$),w(X4),m&&t(neo),m&&t(dc),w(G$),m&&t(seo),m&&t(Ho),w(O$),w(X$),w(Q4),w(z$),w(H4),m&&t(leo),m&&t(fc),w(Q$),m&&t(ieo),m&&t(Jo),w(W$),w(H$),w(Y4),w(J$),w(iC),m&&t(deo),m&&t(uc),w(Y$),m&&t(ceo),m&&t(Yo),w(K$),w(ek),w(cC),w(ok),w(_C),m&&t(meo),m&&t(bc),w(rk),m&&t(feo),m&&t(Ko),w(tk),w(nk),w(vC),w(sk),w(kC),m&&t(geo),m&&t(Tc),w(lk),m&&t(heo),m&&t(Zo),w(ik),w(ck),w(RC),w(mk),w(NC),m&&t(ueo),m&&t(Cc),w(gk),m&&t(peo),m&&t(er),w(hk),w(pk),w(jC),w(_k),w(QC),m&&t(_eo),m&&t(Lc),w(bk),m&&t(beo),m&&t(or),w(vk),w(Tk),w(UC),w(Mk),w(e3),m&&t(veo),m&&t($c),w(Ek),m&&t(Feo),m&&t(rr),w(Ck),w(Ak),w(r3),w(Lk),w(i3),m&&t(Teo),m&&t(Rc),w(yk),m&&t(Meo),m&&t(tr),w(xk),w(kk),w(c3),w(Sk),w(g3),m&&t(Eeo),m&&t(Ic),w(Rk),m&&t(Ceo),m&&t(ar),w(Pk),w(Ik),w(u3),w(Nk),w(M3),m&&t(weo),m&&t(jc),w(qk),m&&t(Aeo),m&&t(nr),w(jk),w(Gk),w(C3),w(Ok),w(L3),m&&t(Leo),m&&t(Oc),w(Vk),m&&t(yeo),m&&t(sr),w(Xk),w(Qk),w(x3),w(Wk),w($5),m&&t(xeo),m&&t(zc),w(Uk),m&&t($eo),m&&t(lr),w(Hk),w(Yk),w(S5),w(Kk),w(r0),m&&t(keo),m&&t(Uc),w(Zk),m&&t(Seo),m&&t(ir),w(eS),w(rS),w(a0),w(tS),w(v0),m&&t(Reo),m&&t(Yc),w(aS),m&&t(Peo),m&&t(dr),w(nS),w(lS),w(T0),w(iS),w($0),m&&t(Beo),m&&t(em),w(dS),m&&t(Ieo),m&&t(cr),w(cS),w(fS),w(S0),w(gS),w(I0),m&&t(Neo),m&&t(am),w(hS),m&&t(qeo),m&&t(mr),w(uS),w(_S),w(q0),w(bS),w(nw),m&&t(jeo),m&&t(lm),w(vS),m&&t(Deo),m&&t(fr),w(FS),w(MS),w(lw),w(ES),w(bw),m&&t(Geo),m&&t(cm),w(CS),m&&t(Oeo),m&&t(gr),w(wS),w(LS),w(Fw),w(yS),w(Uw),m&&t(Veo),m&&t(gm),w(xS),m&&t(Xeo),m&&t(hr),w($S),w(SS),w(Jw),w(RS),w(hA),m&&t(zeo),m&&t(pm),w(PS),m&&t(Qeo),m&&t(ur),w(BS),w(NS),w(pA),w(qS),w(vA),m&&t(Weo),m&&t(vm),w(DS),m&&t(Ueo),m&&t(pr),w(GS),w(VS),w(TA),w(XS),w(EA),m&&t(Heo),m&&t(Mm),w(zS),m&&t(Jeo),m&&t(_r),w(QS),w(US),w(wA),w(HS),w(LA),m&&t(Yeo),m&&t(wm),w(JS),m&&t(Keo),m&&t(br),w(YS),w(ZS),w(xA),w(eR),w(YA),m&&t(Zeo),m&&t(ym),w(oR),m&&t(eoo),m&&t(vr),w(rR),w(aR),w(ZA),w(nR),w(T6),m&&t(ooo),m&&t(km),w(sR),m&&t(roo),m&&t(Fr),w(lR),w(dR),w(E6),w(cR),w(w6),m&&t(too),m&&t(Pm),w(mR),m&&t(aoo),m&&t(Tr),w(fR),w(hR),w(L6),w(uR),w(x6),m&&t(noo),m&&t(Nm),w(pR),m&&t(soo),m&&t(Mr),w(_R),w(vR),w(k6),w(FR),w(n7),m&&t(loo),m&&t(Dm),w(TR),m&&t(ioo),m&&t(Er),w(MR),w(CR),w(l7),w(wR),w(b7),m&&t(doo),m&&t(Vm),w(AR),m&&t(coo),m&&t(Cr),w(LR),w(xR),w(F7),w($R),w(P7),m&&t(moo),m&&t(Qm),w(kR),m&&t(foo),m&&t(wr),w(SR),w(PR),w(I7),w(BR),w(W7),m&&t(goo),m&&t(Hm),w(IR),m&&t(hoo),m&&t(Ar),w(NR),w(jR),w(H7),w(DR),w(sL),m&&t(uoo),m&&t(Km),w(GR),m&&t(poo),m&&t(Lr),w(OR),w(XR),w(iL),w(zR),w(vL),m&&t(_oo),m&&t(of),w(QR),m&&t(boo),m&&t(yr),w(WR),w(HR),w(TL),w(JR),w(SL),m&&t(voo),m&&t(af),w(YR),m&&t(Foo),m&&t(xr),w(KR),w(eP),w(PL),w(oP),w(VL),m&&t(Too),m&&t(lf),w(rP),m&&t(Moo),m&&t($r),w(tP),w(nP),w(zL),w(sP),w(ey),m&&t(Eoo),m&&t(mf),w(lP),m&&t(Coo),m&&t(kr),w(iP),w(cP),w(ry),w(mP),w(ay),m&&t(woo),m&&t(hf),w(fP),m&&t(Aoo),m&&t(Sr),w(gP),w(uP),w(sy),w(pP),w(dy),m&&t(Loo),m&&t(_f),w(bP),m&&t(yoo),m&&t(Rr),w(vP),w(TP),w(my),w(MP),w(gy)}}}const Sba={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Rba($){return E_a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Dba extends v_a{constructor(g){super();F_a(this,g,Rba,kba,T_a,{})}}export{Dba as default,Sba as metadata};
