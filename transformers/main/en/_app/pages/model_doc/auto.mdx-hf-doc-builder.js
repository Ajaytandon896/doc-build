import{S as k2a,i as S2a,s as R2a,e as a,k as l,w as F,t as o,M as P2a,c as n,d as t,m as i,a as s,x as T,h as r,b as m,G as e,g as b,y as M,q as E,o as C,B as w,v as B2a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as kMt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function I2a($){let g,v,u,f,p,d,h,yo,td,Ef,pt,ad,nd,J9,Cf,Ve,He,sd,es,Y9,os,rs,K9,ld,ts,Z9,id,wf,Qa;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),yo=o(`, make sure its
`),td=a("code"),Ef=o("model_type"),pt=o(" attribute is set to the same key you use when registering the config (here "),ad=a("code"),nd=o('"new-model"'),J9=o(")."),Cf=l(),Ve=a("p"),He=o("Likewise, if your "),sd=a("code"),es=o("NewModel"),Y9=o(" is a subclass of "),os=a("a"),rs=o("PreTrainedModel"),K9=o(`, make sure its
`),ld=a("code"),ts=o("config_class"),Z9=o(` attribute is set to the same class you use when registering the model (here
`),id=a("code"),wf=o("NewModelConfig"),Qa=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var eI=s(u);f=r(eI,"NewModelConfig"),eI.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var dd=s(d);h=r(dd,"PretrainedConfig"),dd.forEach(t),yo=r(Ae,`, make sure its
`),td=n(Ae,"CODE",{});var oI=s(td);Ef=r(oI,"model_type"),oI.forEach(t),pt=r(Ae," attribute is set to the same key you use when registering the config (here "),ad=n(Ae,"CODE",{});var rI=s(ad);nd=r(rI,'"new-model"'),rI.forEach(t),J9=r(Ae,")."),Ae.forEach(t),Cf=i(Je),Ve=n(Je,"P",{});var xo=s(Ve);He=r(xo,"Likewise, if your "),sd=n(xo,"CODE",{});var Wa=s(sd);es=r(Wa,"NewModel"),Wa.forEach(t),Y9=r(xo," is a subclass of "),os=n(xo,"A",{href:!0});var tI=s(os);rs=r(tI,"PreTrainedModel"),tI.forEach(t),K9=r(xo,`, make sure its
`),ld=n(xo,"CODE",{});var Af=s(ld);ts=r(Af,"config_class"),Af.forEach(t),Z9=r(xo,` attribute is set to the same class you use when registering the model (here
`),id=n(xo,"CODE",{});var aI=s(id);wf=r(aI,"NewModelConfig"),aI.forEach(t),Qa=r(xo,")."),xo.forEach(t),this.h()},h(){m(os,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,yo),e(g,td),e(td,Ef),e(g,pt),e(g,ad),e(ad,nd),e(g,J9),b(Je,Cf,Ae),b(Je,Ve,Ae),e(Ve,He),e(Ve,sd),e(sd,es),e(Ve,Y9),e(Ve,os),e(os,rs),e(Ve,K9),e(Ve,ld),e(ld,ts),e(Ve,Z9),e(Ve,id),e(id,wf),e(Ve,Qa)},d(Je){Je&&t(g),Je&&t(Cf),Je&&t(Ve)}}}function N2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j2a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function D2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G2a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var yo=s(u);f=r(yo,"use_auth_token=True"),yo.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function O2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z2a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z1a($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function eba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function oba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function tba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function aba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function sba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _ba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Tba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Eba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Aba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function yba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $ba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Sba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Bba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Nba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Dba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Gba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Oba($){let g,v,u,f,p;return f=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vba($){let g,v,u,f,p,d,h,yo,td,Ef,pt,ad,nd,J9,Cf,Ve,He,sd,es,Y9,os,rs,K9,ld,ts,Z9,id,wf,Qa,Je,Ae,eI,dd,oI,rI,xo,Wa,tI,Af,aI,pao,DZe,md,Lf,eme,ex,_ao,ome,bao,GZe,as,vao,rme,Fao,Tao,tme,Mao,Eao,OZe,ox,VZe,nI,Cao,XZe,yf,zZe,cd,xf,ame,rx,wao,nme,Aao,QZe,$o,tx,Lao,ax,yao,sI,xao,$ao,kao,nx,Sao,sme,Rao,Pao,Bao,Pr,sx,Iao,lme,Nao,qao,fd,jao,ime,Dao,Gao,dme,Oao,Vao,Xao,A,$f,mme,zao,Qao,lI,Wao,Uao,Hao,kf,cme,Jao,Yao,iI,Kao,Zao,eno,Sf,fme,ono,rno,dI,tno,ano,nno,Rf,gme,sno,lno,mI,ino,dno,mno,Pf,hme,cno,fno,cI,gno,hno,uno,Bf,ume,pno,_no,fI,bno,vno,Fno,If,pme,Tno,Mno,gI,Eno,Cno,wno,Nf,_me,Ano,Lno,hI,yno,xno,$no,qf,bme,kno,Sno,uI,Rno,Pno,Bno,jf,vme,Ino,Nno,pI,qno,jno,Dno,Df,Fme,Gno,Ono,_I,Vno,Xno,zno,Gf,Tme,Qno,Wno,bI,Uno,Hno,Jno,Of,Mme,Yno,Kno,vI,Zno,eso,oso,Vf,Eme,rso,tso,FI,aso,nso,sso,Xf,Cme,lso,iso,TI,dso,mso,cso,zf,wme,fso,gso,MI,hso,uso,pso,Qf,Ame,_so,bso,EI,vso,Fso,Tso,Wf,Lme,Mso,Eso,CI,Cso,wso,Aso,Uf,yme,Lso,yso,wI,xso,$so,kso,Hf,xme,Sso,Rso,AI,Pso,Bso,Iso,Jf,$me,Nso,qso,LI,jso,Dso,Gso,Yf,kme,Oso,Vso,yI,Xso,zso,Qso,Kf,Sme,Wso,Uso,xI,Hso,Jso,Yso,Zf,Rme,Kso,Zso,$I,elo,olo,rlo,eg,Pme,tlo,alo,kI,nlo,slo,llo,og,Bme,ilo,dlo,SI,mlo,clo,flo,rg,Ime,glo,hlo,RI,ulo,plo,_lo,tg,Nme,blo,vlo,PI,Flo,Tlo,Mlo,ag,qme,Elo,Clo,BI,wlo,Alo,Llo,ng,jme,ylo,xlo,II,$lo,klo,Slo,sg,Dme,Rlo,Plo,NI,Blo,Ilo,Nlo,lg,Gme,qlo,jlo,qI,Dlo,Glo,Olo,ig,Ome,Vlo,Xlo,jI,zlo,Qlo,Wlo,dg,Vme,Ulo,Hlo,DI,Jlo,Ylo,Klo,mg,Xme,Zlo,eio,GI,oio,rio,tio,cg,zme,aio,nio,OI,sio,lio,iio,fg,Qme,dio,mio,VI,cio,fio,gio,gg,Wme,hio,uio,XI,pio,_io,bio,hg,Ume,vio,Fio,zI,Tio,Mio,Eio,ug,Hme,Cio,wio,QI,Aio,Lio,yio,pg,Jme,xio,$io,WI,kio,Sio,Rio,_g,Yme,Pio,Bio,UI,Iio,Nio,qio,bg,Kme,jio,Dio,HI,Gio,Oio,Vio,vg,Zme,Xio,zio,JI,Qio,Wio,Uio,Fg,ece,Hio,Jio,YI,Yio,Kio,Zio,Tg,oce,edo,odo,KI,rdo,tdo,ado,Mg,rce,ndo,sdo,ZI,ldo,ido,ddo,Eg,tce,mdo,cdo,eN,fdo,gdo,hdo,Cg,ace,udo,pdo,oN,_do,bdo,vdo,wg,nce,Fdo,Tdo,rN,Mdo,Edo,Cdo,Ag,sce,wdo,Ado,tN,Ldo,ydo,xdo,Lg,lce,$do,kdo,aN,Sdo,Rdo,Pdo,yg,ice,Bdo,Ido,nN,Ndo,qdo,jdo,xg,dce,Ddo,Gdo,sN,Odo,Vdo,Xdo,$g,mce,zdo,Qdo,lN,Wdo,Udo,Hdo,kg,cce,Jdo,Ydo,iN,Kdo,Zdo,emo,Sg,fce,omo,rmo,dN,tmo,amo,nmo,Rg,gce,smo,lmo,mN,imo,dmo,mmo,Pg,hce,cmo,fmo,cN,gmo,hmo,umo,Bg,uce,pmo,_mo,fN,bmo,vmo,Fmo,Ig,pce,Tmo,Mmo,gN,Emo,Cmo,wmo,Ng,_ce,Amo,Lmo,hN,ymo,xmo,$mo,qg,bce,kmo,Smo,uN,Rmo,Pmo,Bmo,jg,vce,Imo,Nmo,pN,qmo,jmo,Dmo,Dg,Fce,Gmo,Omo,_N,Vmo,Xmo,zmo,Gg,Tce,Qmo,Wmo,bN,Umo,Hmo,Jmo,Og,Mce,Ymo,Kmo,vN,Zmo,eco,oco,Vg,Ece,rco,tco,FN,aco,nco,sco,Xg,Cce,lco,ico,TN,dco,mco,cco,zg,wce,fco,gco,MN,hco,uco,pco,Qg,Ace,_co,bco,EN,vco,Fco,Tco,Wg,Lce,Mco,Eco,CN,Cco,wco,Aco,Ug,yce,Lco,yco,wN,xco,$co,kco,Hg,xce,Sco,Rco,AN,Pco,Bco,Ico,Jg,$ce,Nco,qco,LN,jco,Dco,Gco,Yg,kce,Oco,Vco,yN,Xco,zco,Qco,Kg,Sce,Wco,Uco,xN,Hco,Jco,Yco,Zg,Rce,Kco,Zco,$N,efo,ofo,rfo,eh,Pce,tfo,afo,kN,nfo,sfo,lfo,oh,Bce,ifo,dfo,SN,mfo,cfo,ffo,rh,Ice,gfo,hfo,RN,ufo,pfo,_fo,th,Nce,bfo,vfo,PN,Ffo,Tfo,Mfo,ah,qce,Efo,Cfo,BN,wfo,Afo,Lfo,nh,jce,yfo,xfo,IN,$fo,kfo,Sfo,sh,Dce,Rfo,Pfo,NN,Bfo,Ifo,Nfo,lh,Gce,qfo,jfo,qN,Dfo,Gfo,Ofo,ih,Oce,Vfo,Xfo,jN,zfo,Qfo,Wfo,dh,Vce,Ufo,Hfo,DN,Jfo,Yfo,Kfo,mh,Xce,Zfo,ego,GN,ogo,rgo,tgo,ch,zce,ago,ngo,ON,sgo,lgo,igo,fh,Qce,dgo,mgo,VN,cgo,fgo,ggo,gh,Wce,hgo,ugo,XN,pgo,_go,bgo,hh,Uce,vgo,Fgo,zN,Tgo,Mgo,Ego,uh,Hce,Cgo,wgo,QN,Ago,Lgo,ygo,ph,Jce,xgo,$go,WN,kgo,Sgo,Rgo,_h,Yce,Pgo,Bgo,UN,Igo,Ngo,qgo,bh,Kce,jgo,Dgo,HN,Ggo,Ogo,Vgo,vh,Zce,Xgo,zgo,JN,Qgo,Wgo,Ugo,Fh,efe,Hgo,Jgo,YN,Ygo,Kgo,Zgo,Th,ofe,eho,oho,KN,rho,tho,aho,Mh,rfe,nho,sho,ZN,lho,iho,dho,Eh,tfe,mho,cho,eq,fho,gho,hho,Ch,afe,uho,pho,oq,_ho,bho,vho,wh,nfe,Fho,Tho,rq,Mho,Eho,Cho,Ah,sfe,who,Aho,tq,Lho,yho,xho,Lh,lfe,$ho,kho,aq,Sho,Rho,Pho,yh,ife,Bho,Iho,nq,Nho,qho,jho,xh,dfe,Dho,Gho,sq,Oho,Vho,Xho,$h,mfe,zho,Qho,lq,Who,Uho,Hho,kh,cfe,Jho,Yho,iq,Kho,Zho,euo,Sh,ffe,ouo,ruo,dq,tuo,auo,nuo,Rh,gfe,suo,luo,mq,iuo,duo,muo,Ph,hfe,cuo,fuo,cq,guo,huo,uuo,Bh,ufe,puo,_uo,fq,buo,vuo,Fuo,Ih,pfe,Tuo,Muo,gq,Euo,Cuo,wuo,Nh,_fe,Auo,Luo,hq,yuo,xuo,$uo,qh,bfe,kuo,Suo,uq,Ruo,Puo,Buo,jh,vfe,Iuo,Nuo,pq,quo,juo,Duo,Dh,Ffe,Guo,Ouo,_q,Vuo,Xuo,zuo,Gh,Tfe,Quo,Wuo,bq,Uuo,Huo,Juo,Oh,Mfe,Yuo,Kuo,vq,Zuo,epo,opo,Vh,Efe,rpo,tpo,Fq,apo,npo,spo,Xh,Cfe,lpo,ipo,Tq,dpo,mpo,cpo,zh,wfe,fpo,gpo,Mq,hpo,upo,ppo,Qh,Afe,_po,bpo,Eq,vpo,Fpo,Tpo,Wh,Lfe,Mpo,Epo,Cq,Cpo,wpo,Apo,Uh,yfe,Lpo,ypo,wq,xpo,$po,kpo,Hh,xfe,Spo,Rpo,Aq,Ppo,Bpo,Ipo,Jh,$fe,Npo,qpo,Lq,jpo,Dpo,Gpo,Yh,kfe,Opo,Vpo,yq,Xpo,zpo,Qpo,Kh,Sfe,Wpo,Upo,xq,Hpo,Jpo,Ypo,Zh,Rfe,Kpo,Zpo,$q,e_o,o_o,r_o,eu,t_o,ou,lx,a_o,Pfe,n_o,WZe,gd,ru,Bfe,ix,s_o,Ife,l_o,UZe,ko,dx,i_o,mx,d_o,kq,m_o,c_o,f_o,cx,g_o,Nfe,h_o,u_o,p_o,Br,fx,__o,qfe,b_o,v_o,Ua,F_o,jfe,T_o,M_o,Dfe,E_o,C_o,Gfe,w_o,A_o,L_o,k,ns,Ofe,y_o,x_o,Sq,$_o,k_o,Rq,S_o,R_o,P_o,ss,Vfe,B_o,I_o,Pq,N_o,q_o,Bq,j_o,D_o,G_o,ls,Xfe,O_o,V_o,Iq,X_o,z_o,Nq,Q_o,W_o,U_o,tu,zfe,H_o,J_o,qq,Y_o,K_o,Z_o,is,Qfe,e2o,o2o,jq,r2o,t2o,Dq,a2o,n2o,s2o,au,Wfe,l2o,i2o,Gq,d2o,m2o,c2o,nu,Ufe,f2o,g2o,Oq,h2o,u2o,p2o,su,Hfe,_2o,b2o,Vq,v2o,F2o,T2o,ds,Jfe,M2o,E2o,Xq,C2o,w2o,zq,A2o,L2o,y2o,ms,Yfe,x2o,$2o,Qq,k2o,S2o,Wq,R2o,P2o,B2o,cs,Kfe,I2o,N2o,Uq,q2o,j2o,Hq,D2o,G2o,O2o,lu,Zfe,V2o,X2o,Jq,z2o,Q2o,W2o,iu,ege,U2o,H2o,Yq,J2o,Y2o,K2o,du,oge,Z2o,e1o,Kq,o1o,r1o,t1o,fs,rge,a1o,n1o,Zq,s1o,l1o,ej,i1o,d1o,m1o,mu,tge,c1o,f1o,oj,g1o,h1o,u1o,gs,age,p1o,_1o,rj,b1o,v1o,tj,F1o,T1o,M1o,hs,nge,E1o,C1o,aj,w1o,A1o,nj,L1o,y1o,x1o,us,sge,$1o,k1o,sj,S1o,R1o,lj,P1o,B1o,I1o,ps,lge,N1o,q1o,ij,j1o,D1o,dj,G1o,O1o,V1o,cu,ige,X1o,z1o,mj,Q1o,W1o,U1o,_s,dge,H1o,J1o,cj,Y1o,K1o,fj,Z1o,ebo,obo,bs,mge,rbo,tbo,gj,abo,nbo,hj,sbo,lbo,ibo,vs,cge,dbo,mbo,uj,cbo,fbo,pj,gbo,hbo,ubo,Fs,fge,pbo,_bo,_j,bbo,vbo,bj,Fbo,Tbo,Mbo,Ts,gge,Ebo,Cbo,vj,wbo,Abo,Fj,Lbo,ybo,xbo,Ms,hge,$bo,kbo,Tj,Sbo,Rbo,Mj,Pbo,Bbo,Ibo,Es,uge,Nbo,qbo,Ej,jbo,Dbo,Cj,Gbo,Obo,Vbo,fu,pge,Xbo,zbo,wj,Qbo,Wbo,Ubo,Cs,_ge,Hbo,Jbo,Aj,Ybo,Kbo,Lj,Zbo,evo,ovo,gu,bge,rvo,tvo,yj,avo,nvo,svo,ws,vge,lvo,ivo,xj,dvo,mvo,$j,cvo,fvo,gvo,As,Fge,hvo,uvo,kj,pvo,_vo,Sj,bvo,vvo,Fvo,Ls,Tge,Tvo,Mvo,Rj,Evo,Cvo,Pj,wvo,Avo,Lvo,hu,Mge,yvo,xvo,Bj,$vo,kvo,Svo,uu,Ege,Rvo,Pvo,Ij,Bvo,Ivo,Nvo,ys,Cge,qvo,jvo,Nj,Dvo,Gvo,qj,Ovo,Vvo,Xvo,xs,wge,zvo,Qvo,jj,Wvo,Uvo,Dj,Hvo,Jvo,Yvo,$s,Age,Kvo,Zvo,Gj,eFo,oFo,Oj,rFo,tFo,aFo,pu,Lge,nFo,sFo,Vj,lFo,iFo,dFo,ks,yge,mFo,cFo,Xj,fFo,gFo,zj,hFo,uFo,pFo,Ss,xge,_Fo,bFo,Qj,vFo,FFo,Wj,TFo,MFo,EFo,Rs,$ge,CFo,wFo,Uj,AFo,LFo,Hj,yFo,xFo,$Fo,Ps,kge,kFo,SFo,Jj,RFo,PFo,Yj,BFo,IFo,NFo,Bs,Sge,qFo,jFo,Kj,DFo,GFo,Zj,OFo,VFo,XFo,Is,Rge,zFo,QFo,eD,WFo,UFo,oD,HFo,JFo,YFo,Ns,Pge,KFo,ZFo,rD,eTo,oTo,tD,rTo,tTo,aTo,qs,Bge,nTo,sTo,aD,lTo,iTo,nD,dTo,mTo,cTo,_u,Ige,fTo,gTo,sD,hTo,uTo,pTo,js,Nge,_To,bTo,lD,vTo,FTo,iD,TTo,MTo,ETo,bu,qge,CTo,wTo,dD,ATo,LTo,yTo,vu,jge,xTo,$To,mD,kTo,STo,RTo,Ds,Dge,PTo,BTo,cD,ITo,NTo,fD,qTo,jTo,DTo,Gs,Gge,GTo,OTo,gD,VTo,XTo,hD,zTo,QTo,WTo,Os,Oge,UTo,HTo,uD,JTo,YTo,pD,KTo,ZTo,eMo,Fu,Vge,oMo,rMo,_D,tMo,aMo,nMo,Vs,Xge,sMo,lMo,bD,iMo,dMo,vD,mMo,cMo,fMo,Xs,zge,gMo,hMo,FD,uMo,pMo,TD,_Mo,bMo,vMo,zs,Qge,FMo,TMo,MD,MMo,EMo,ED,CMo,wMo,AMo,Qs,Wge,LMo,yMo,CD,xMo,$Mo,wD,kMo,SMo,RMo,Ws,Uge,PMo,BMo,AD,IMo,NMo,LD,qMo,jMo,DMo,Us,Hge,GMo,OMo,yD,VMo,XMo,xD,zMo,QMo,WMo,Hs,Jge,UMo,HMo,$D,JMo,YMo,kD,KMo,ZMo,eEo,Js,Yge,oEo,rEo,SD,tEo,aEo,RD,nEo,sEo,lEo,Tu,Kge,iEo,dEo,PD,mEo,cEo,fEo,Ys,Zge,gEo,hEo,BD,uEo,pEo,ID,_Eo,bEo,vEo,Ks,ehe,FEo,TEo,ND,MEo,EEo,qD,CEo,wEo,AEo,Mu,ohe,LEo,yEo,jD,xEo,$Eo,kEo,Eu,rhe,SEo,REo,DD,PEo,BEo,IEo,Cu,the,NEo,qEo,GD,jEo,DEo,GEo,wu,ahe,OEo,VEo,OD,XEo,zEo,QEo,Zs,nhe,WEo,UEo,VD,HEo,JEo,XD,YEo,KEo,ZEo,Au,she,e4o,o4o,zD,r4o,t4o,a4o,el,lhe,n4o,s4o,QD,l4o,i4o,WD,d4o,m4o,c4o,ol,ihe,f4o,g4o,UD,h4o,u4o,HD,p4o,_4o,b4o,rl,dhe,v4o,F4o,JD,T4o,M4o,YD,E4o,C4o,w4o,tl,mhe,A4o,L4o,KD,y4o,x4o,ZD,$4o,k4o,S4o,al,che,R4o,P4o,eG,B4o,I4o,oG,N4o,q4o,j4o,nl,fhe,D4o,G4o,rG,O4o,V4o,tG,X4o,z4o,Q4o,Lu,ghe,W4o,U4o,aG,H4o,J4o,Y4o,yu,hhe,K4o,Z4o,nG,eCo,oCo,rCo,sl,uhe,tCo,aCo,sG,nCo,sCo,lG,lCo,iCo,dCo,ll,phe,mCo,cCo,iG,fCo,gCo,dG,hCo,uCo,pCo,il,_he,_Co,bCo,mG,vCo,FCo,cG,TCo,MCo,ECo,xu,bhe,CCo,wCo,fG,ACo,LCo,yCo,$u,vhe,xCo,$Co,gG,kCo,SCo,RCo,ku,Fhe,PCo,BCo,hG,ICo,NCo,qCo,dl,The,jCo,DCo,uG,GCo,OCo,pG,VCo,XCo,zCo,ml,Mhe,QCo,WCo,_G,UCo,HCo,bG,JCo,YCo,KCo,Su,Ehe,ZCo,e3o,vG,o3o,r3o,t3o,Ru,Che,a3o,n3o,FG,s3o,l3o,i3o,Pu,whe,d3o,m3o,TG,c3o,f3o,g3o,cl,Ahe,h3o,u3o,MG,p3o,_3o,EG,b3o,v3o,F3o,fl,Lhe,T3o,M3o,CG,E3o,C3o,wG,w3o,A3o,L3o,Bu,yhe,y3o,x3o,AG,$3o,k3o,S3o,Iu,xhe,R3o,P3o,LG,B3o,I3o,N3o,gl,$he,q3o,j3o,yG,D3o,G3o,xG,O3o,V3o,X3o,hl,khe,z3o,Q3o,$G,W3o,U3o,kG,H3o,J3o,Y3o,ul,She,K3o,Z3o,SG,e5o,o5o,RG,r5o,t5o,a5o,pl,Rhe,n5o,s5o,PG,l5o,i5o,BG,d5o,m5o,c5o,Nu,f5o,qu,gx,g5o,Phe,h5o,HZe,hd,ju,Bhe,hx,u5o,Ihe,p5o,JZe,So,ux,_5o,px,b5o,IG,v5o,F5o,T5o,_x,M5o,Nhe,E5o,C5o,w5o,Ye,bx,A5o,qhe,L5o,y5o,Ha,x5o,jhe,$5o,k5o,Dhe,S5o,R5o,Ghe,P5o,B5o,I5o,z,Du,Ohe,N5o,q5o,NG,j5o,D5o,G5o,Gu,Vhe,O5o,V5o,qG,X5o,z5o,Q5o,Ou,Xhe,W5o,U5o,jG,H5o,J5o,Y5o,Vu,zhe,K5o,Z5o,DG,e0o,o0o,r0o,Xu,Qhe,t0o,a0o,GG,n0o,s0o,l0o,zu,Whe,i0o,d0o,OG,m0o,c0o,f0o,Qu,Uhe,g0o,h0o,VG,u0o,p0o,_0o,Wu,Hhe,b0o,v0o,XG,F0o,T0o,M0o,Uu,Jhe,E0o,C0o,zG,w0o,A0o,L0o,Hu,Yhe,y0o,x0o,QG,$0o,k0o,S0o,Ju,Khe,R0o,P0o,WG,B0o,I0o,N0o,Yu,Zhe,q0o,j0o,UG,D0o,G0o,O0o,Ku,eue,V0o,X0o,HG,z0o,Q0o,W0o,Zu,oue,U0o,H0o,JG,J0o,Y0o,K0o,ep,rue,Z0o,ewo,YG,owo,rwo,two,op,tue,awo,nwo,KG,swo,lwo,iwo,rp,aue,dwo,mwo,ZG,cwo,fwo,gwo,tp,nue,hwo,uwo,eO,pwo,_wo,bwo,ap,sue,vwo,Fwo,oO,Two,Mwo,Ewo,np,lue,Cwo,wwo,rO,Awo,Lwo,ywo,sp,iue,xwo,$wo,tO,kwo,Swo,Rwo,lp,due,Pwo,Bwo,aO,Iwo,Nwo,qwo,ip,mue,jwo,Dwo,nO,Gwo,Owo,Vwo,dp,cue,Xwo,zwo,sO,Qwo,Wwo,Uwo,mp,fue,Hwo,Jwo,lO,Ywo,Kwo,Zwo,cp,gue,eAo,oAo,iO,rAo,tAo,aAo,fp,hue,nAo,sAo,dO,lAo,iAo,dAo,gp,uue,mAo,cAo,mO,fAo,gAo,hAo,hp,pue,uAo,pAo,cO,_Ao,bAo,vAo,up,_ue,FAo,TAo,fO,MAo,EAo,CAo,pp,bue,wAo,AAo,gO,LAo,yAo,xAo,_p,vue,$Ao,kAo,hO,SAo,RAo,PAo,bp,Fue,BAo,IAo,uO,NAo,qAo,jAo,vp,Tue,DAo,GAo,pO,OAo,VAo,XAo,Fp,Mue,zAo,QAo,_O,WAo,UAo,HAo,Tp,Eue,JAo,YAo,bO,KAo,ZAo,e6o,Mp,Cue,o6o,r6o,vO,t6o,a6o,n6o,Ep,wue,s6o,l6o,FO,i6o,d6o,m6o,Cp,Aue,c6o,f6o,TO,g6o,h6o,u6o,wp,Lue,p6o,_6o,MO,b6o,v6o,F6o,Ap,yue,T6o,M6o,EO,E6o,C6o,w6o,Lp,xue,A6o,L6o,CO,y6o,x6o,$6o,yp,k6o,xp,S6o,$p,vx,R6o,$ue,P6o,YZe,ud,kp,kue,Fx,B6o,Sue,I6o,KZe,Ro,Tx,N6o,Mx,q6o,wO,j6o,D6o,G6o,Ex,O6o,Rue,V6o,X6o,z6o,Ke,Cx,Q6o,Pue,W6o,U6o,pd,H6o,Bue,J6o,Y6o,Iue,K6o,Z6o,e7o,le,Sp,Nue,o7o,r7o,AO,t7o,a7o,n7o,Rp,que,s7o,l7o,LO,i7o,d7o,m7o,Pp,jue,c7o,f7o,yO,g7o,h7o,u7o,Bp,Due,p7o,_7o,xO,b7o,v7o,F7o,Ip,Gue,T7o,M7o,$O,E7o,C7o,w7o,Np,Oue,A7o,L7o,kO,y7o,x7o,$7o,qp,Vue,k7o,S7o,SO,R7o,P7o,B7o,jp,Xue,I7o,N7o,RO,q7o,j7o,D7o,Dp,zue,G7o,O7o,PO,V7o,X7o,z7o,Gp,Que,Q7o,W7o,BO,U7o,H7o,J7o,Op,Wue,Y7o,K7o,IO,Z7o,eLo,oLo,Vp,Uue,rLo,tLo,NO,aLo,nLo,sLo,Xp,Hue,lLo,iLo,qO,dLo,mLo,cLo,zp,Jue,fLo,gLo,jO,hLo,uLo,pLo,Qp,Yue,_Lo,bLo,DO,vLo,FLo,TLo,Wp,Kue,MLo,ELo,GO,CLo,wLo,ALo,Up,Zue,LLo,yLo,OO,xLo,$Lo,kLo,Hp,epe,SLo,RLo,VO,PLo,BLo,ILo,Jp,ope,NLo,qLo,XO,jLo,DLo,GLo,Yp,rpe,OLo,VLo,zO,XLo,zLo,QLo,Kp,tpe,WLo,ULo,QO,HLo,JLo,YLo,Zp,ape,KLo,ZLo,WO,eyo,oyo,ryo,e_,tyo,o_,ayo,r_,wx,nyo,npe,syo,ZZe,_d,t_,spe,Ax,lyo,lpe,iyo,eeo,Po,Lx,dyo,bd,myo,UO,cyo,fyo,HO,gyo,hyo,uyo,yx,pyo,ipe,_yo,byo,vyo,_t,xx,Fyo,dpe,Tyo,Myo,vd,Eyo,mpe,Cyo,wyo,JO,Ayo,Lyo,yyo,a_,xyo,Ze,$x,$yo,cpe,kyo,Syo,Ja,Ryo,fpe,Pyo,Byo,gpe,Iyo,Nyo,hpe,qyo,jyo,Dyo,y,n_,upe,Gyo,Oyo,YO,Vyo,Xyo,zyo,s_,ppe,Qyo,Wyo,KO,Uyo,Hyo,Jyo,l_,_pe,Yyo,Kyo,ZO,Zyo,e8o,o8o,i_,bpe,r8o,t8o,eV,a8o,n8o,s8o,d_,vpe,l8o,i8o,oV,d8o,m8o,c8o,m_,Fpe,f8o,g8o,rV,h8o,u8o,p8o,c_,Tpe,_8o,b8o,tV,v8o,F8o,T8o,f_,Mpe,M8o,E8o,aV,C8o,w8o,A8o,g_,Epe,L8o,y8o,nV,x8o,$8o,k8o,h_,Cpe,S8o,R8o,sV,P8o,B8o,I8o,u_,wpe,N8o,q8o,lV,j8o,D8o,G8o,p_,Ape,O8o,V8o,iV,X8o,z8o,Q8o,__,Lpe,W8o,U8o,dV,H8o,J8o,Y8o,b_,ype,K8o,Z8o,mV,e9o,o9o,r9o,v_,xpe,t9o,a9o,cV,n9o,s9o,l9o,F_,$pe,i9o,d9o,fV,m9o,c9o,f9o,T_,kpe,g9o,h9o,gV,u9o,p9o,_9o,M_,Spe,b9o,v9o,hV,F9o,T9o,M9o,E_,Rpe,E9o,C9o,uV,w9o,A9o,L9o,C_,Ppe,y9o,x9o,pV,$9o,k9o,S9o,w_,Bpe,R9o,P9o,_V,B9o,I9o,N9o,A_,Ipe,q9o,j9o,bV,D9o,G9o,O9o,L_,Npe,V9o,X9o,vV,z9o,Q9o,W9o,y_,qpe,U9o,H9o,FV,J9o,Y9o,K9o,x_,jpe,Z9o,exo,TV,oxo,rxo,txo,$_,Dpe,axo,nxo,MV,sxo,lxo,ixo,k_,Gpe,dxo,mxo,EV,cxo,fxo,gxo,S_,Ope,hxo,uxo,CV,pxo,_xo,bxo,R_,Vpe,vxo,Fxo,wV,Txo,Mxo,Exo,P_,Xpe,Cxo,wxo,AV,Axo,Lxo,yxo,B_,zpe,xxo,$xo,LV,kxo,Sxo,Rxo,I_,Qpe,Pxo,Bxo,yV,Ixo,Nxo,qxo,N_,Wpe,jxo,Dxo,xV,Gxo,Oxo,Vxo,q_,Upe,Xxo,zxo,$V,Qxo,Wxo,Uxo,j_,Hpe,Hxo,Jxo,kV,Yxo,Kxo,Zxo,D_,Jpe,e$o,o$o,SV,r$o,t$o,a$o,G_,Ype,n$o,s$o,RV,l$o,i$o,d$o,O_,Kpe,m$o,c$o,PV,f$o,g$o,h$o,V_,Zpe,u$o,p$o,BV,_$o,b$o,v$o,_l,e_e,F$o,T$o,IV,M$o,E$o,NV,C$o,w$o,A$o,X_,o_e,L$o,y$o,qV,x$o,$$o,k$o,z_,r_e,S$o,R$o,jV,P$o,B$o,I$o,Q_,t_e,N$o,q$o,DV,j$o,D$o,G$o,W_,a_e,O$o,V$o,GV,X$o,z$o,Q$o,U_,n_e,W$o,U$o,OV,H$o,J$o,Y$o,H_,s_e,K$o,Z$o,VV,eko,oko,rko,J_,l_e,tko,ako,XV,nko,sko,lko,Y_,i_e,iko,dko,zV,mko,cko,fko,K_,d_e,gko,hko,QV,uko,pko,_ko,Z_,m_e,bko,vko,WV,Fko,Tko,Mko,e2,c_e,Eko,Cko,UV,wko,Ako,Lko,o2,f_e,yko,xko,HV,$ko,kko,Sko,r2,g_e,Rko,Pko,JV,Bko,Iko,Nko,t2,h_e,qko,jko,YV,Dko,Gko,Oko,a2,u_e,Vko,Xko,KV,zko,Qko,Wko,n2,p_e,Uko,Hko,ZV,Jko,Yko,Kko,s2,__e,Zko,eSo,eX,oSo,rSo,tSo,l2,b_e,aSo,nSo,oX,sSo,lSo,iSo,i2,v_e,dSo,mSo,rX,cSo,fSo,gSo,d2,F_e,hSo,uSo,tX,pSo,_So,bSo,m2,T_e,vSo,FSo,aX,TSo,MSo,ESo,c2,M_e,CSo,wSo,nX,ASo,LSo,ySo,f2,E_e,xSo,$So,sX,kSo,SSo,RSo,g2,C_e,PSo,BSo,lX,ISo,NSo,qSo,h2,w_e,jSo,DSo,iX,GSo,OSo,VSo,u2,A_e,XSo,zSo,dX,QSo,WSo,USo,p2,L_e,HSo,JSo,mX,YSo,KSo,ZSo,_2,y_e,eRo,oRo,cX,rRo,tRo,aRo,b2,x_e,nRo,sRo,fX,lRo,iRo,dRo,v2,$_e,mRo,cRo,gX,fRo,gRo,hRo,F2,k_e,uRo,pRo,hX,_Ro,bRo,vRo,T2,S_e,FRo,TRo,uX,MRo,ERo,CRo,M2,R_e,wRo,ARo,pX,LRo,yRo,xRo,E2,P_e,$Ro,kRo,_X,SRo,RRo,PRo,C2,B_e,BRo,IRo,bX,NRo,qRo,jRo,w2,I_e,DRo,GRo,vX,ORo,VRo,XRo,A2,N_e,zRo,QRo,FX,WRo,URo,HRo,L2,q_e,JRo,YRo,TX,KRo,ZRo,ePo,y2,j_e,oPo,rPo,MX,tPo,aPo,nPo,x2,D_e,sPo,lPo,EX,iPo,dPo,mPo,$2,G_e,cPo,fPo,CX,gPo,hPo,uPo,k2,O_e,pPo,_Po,wX,bPo,vPo,FPo,S2,V_e,TPo,MPo,AX,EPo,CPo,wPo,R2,X_e,APo,LPo,LX,yPo,xPo,$Po,P2,z_e,kPo,SPo,yX,RPo,PPo,BPo,B2,Q_e,IPo,NPo,xX,qPo,jPo,DPo,I2,W_e,GPo,OPo,$X,VPo,XPo,zPo,N2,U_e,QPo,WPo,kX,UPo,HPo,JPo,q2,H_e,YPo,KPo,SX,ZPo,eBo,oBo,j2,J_e,rBo,tBo,RX,aBo,nBo,sBo,D2,Y_e,lBo,iBo,PX,dBo,mBo,cBo,G2,K_e,fBo,gBo,BX,hBo,uBo,pBo,O2,Z_e,_Bo,bBo,IX,vBo,FBo,TBo,V2,e2e,MBo,EBo,NX,CBo,wBo,ABo,X2,o2e,LBo,yBo,qX,xBo,$Bo,kBo,z2,r2e,SBo,RBo,jX,PBo,BBo,IBo,Q2,t2e,NBo,qBo,DX,jBo,DBo,GBo,W2,a2e,OBo,VBo,GX,XBo,zBo,QBo,U2,n2e,WBo,UBo,OX,HBo,JBo,YBo,H2,s2e,KBo,ZBo,VX,eIo,oIo,rIo,J2,l2e,tIo,aIo,XX,nIo,sIo,lIo,Y2,i2e,iIo,dIo,zX,mIo,cIo,fIo,K2,d2e,gIo,hIo,QX,uIo,pIo,_Io,Z2,m2e,bIo,vIo,WX,FIo,TIo,MIo,e1,c2e,EIo,CIo,UX,wIo,AIo,LIo,o1,f2e,yIo,xIo,HX,$Io,kIo,SIo,r1,g2e,RIo,PIo,JX,BIo,IIo,NIo,t1,h2e,qIo,jIo,YX,DIo,GIo,OIo,a1,u2e,VIo,XIo,KX,zIo,QIo,WIo,n1,p2e,UIo,HIo,ZX,JIo,YIo,KIo,s1,_2e,ZIo,eNo,ez,oNo,rNo,tNo,l1,b2e,aNo,nNo,oz,sNo,lNo,iNo,i1,v2e,dNo,mNo,rz,cNo,fNo,gNo,d1,F2e,hNo,uNo,tz,pNo,_No,bNo,m1,T2e,vNo,FNo,az,TNo,MNo,ENo,c1,M2e,CNo,wNo,nz,ANo,LNo,yNo,f1,E2e,xNo,$No,sz,kNo,SNo,RNo,g1,C2e,PNo,BNo,lz,INo,NNo,qNo,h1,w2e,jNo,DNo,iz,GNo,ONo,VNo,u1,A2e,XNo,zNo,dz,QNo,WNo,UNo,p1,L2e,HNo,JNo,mz,YNo,KNo,ZNo,_1,y2e,eqo,oqo,cz,rqo,tqo,aqo,b1,x2e,nqo,sqo,fz,lqo,iqo,dqo,v1,$2e,mqo,cqo,gz,fqo,gqo,hqo,F1,k2e,uqo,pqo,hz,_qo,bqo,vqo,T1,S2e,Fqo,Tqo,uz,Mqo,Eqo,Cqo,M1,wqo,R2e,Aqo,Lqo,P2e,yqo,xqo,E1,oeo,Fd,C1,B2e,kx,$qo,I2e,kqo,reo,Bo,Sx,Sqo,Td,Rqo,pz,Pqo,Bqo,_z,Iqo,Nqo,qqo,Rx,jqo,N2e,Dqo,Gqo,Oqo,bt,Px,Vqo,q2e,Xqo,zqo,Md,Qqo,j2e,Wqo,Uqo,bz,Hqo,Jqo,Yqo,w1,Kqo,eo,Bx,Zqo,D2e,ejo,ojo,Ya,rjo,G2e,tjo,ajo,O2e,njo,sjo,V2e,ljo,ijo,djo,G,A1,X2e,mjo,cjo,vz,fjo,gjo,hjo,L1,z2e,ujo,pjo,Fz,_jo,bjo,vjo,y1,Q2e,Fjo,Tjo,Tz,Mjo,Ejo,Cjo,x1,W2e,wjo,Ajo,Mz,Ljo,yjo,xjo,$1,U2e,$jo,kjo,Ez,Sjo,Rjo,Pjo,k1,H2e,Bjo,Ijo,Cz,Njo,qjo,jjo,S1,J2e,Djo,Gjo,wz,Ojo,Vjo,Xjo,R1,Y2e,zjo,Qjo,Az,Wjo,Ujo,Hjo,P1,K2e,Jjo,Yjo,Lz,Kjo,Zjo,eDo,B1,Z2e,oDo,rDo,yz,tDo,aDo,nDo,I1,e1e,sDo,lDo,xz,iDo,dDo,mDo,N1,o1e,cDo,fDo,$z,gDo,hDo,uDo,q1,r1e,pDo,_Do,kz,bDo,vDo,FDo,j1,t1e,TDo,MDo,Sz,EDo,CDo,wDo,D1,a1e,ADo,LDo,Rz,yDo,xDo,$Do,G1,n1e,kDo,SDo,Pz,RDo,PDo,BDo,O1,s1e,IDo,NDo,Bz,qDo,jDo,DDo,V1,l1e,GDo,ODo,Iz,VDo,XDo,zDo,X1,i1e,QDo,WDo,Nz,UDo,HDo,JDo,z1,d1e,YDo,KDo,qz,ZDo,eGo,oGo,Q1,m1e,rGo,tGo,jz,aGo,nGo,sGo,W1,c1e,lGo,iGo,Dz,dGo,mGo,cGo,U1,f1e,fGo,gGo,Gz,hGo,uGo,pGo,H1,g1e,_Go,bGo,Oz,vGo,FGo,TGo,J1,h1e,MGo,EGo,Vz,CGo,wGo,AGo,Y1,u1e,LGo,yGo,Xz,xGo,$Go,kGo,K1,p1e,SGo,RGo,zz,PGo,BGo,IGo,Z1,_1e,NGo,qGo,Qz,jGo,DGo,GGo,eb,b1e,OGo,VGo,Wz,XGo,zGo,QGo,ob,v1e,WGo,UGo,Uz,HGo,JGo,YGo,rb,F1e,KGo,ZGo,Hz,eOo,oOo,rOo,tb,T1e,tOo,aOo,Jz,nOo,sOo,lOo,ab,M1e,iOo,dOo,Yz,mOo,cOo,fOo,nb,E1e,gOo,hOo,Kz,uOo,pOo,_Oo,sb,C1e,bOo,vOo,Zz,FOo,TOo,MOo,lb,w1e,EOo,COo,eQ,wOo,AOo,LOo,ib,A1e,yOo,xOo,oQ,$Oo,kOo,SOo,db,L1e,ROo,POo,rQ,BOo,IOo,NOo,mb,y1e,qOo,jOo,tQ,DOo,GOo,OOo,cb,x1e,VOo,XOo,aQ,zOo,QOo,WOo,fb,$1e,UOo,HOo,nQ,JOo,YOo,KOo,gb,k1e,ZOo,eVo,sQ,oVo,rVo,tVo,hb,S1e,aVo,nVo,lQ,sVo,lVo,iVo,ub,R1e,dVo,mVo,iQ,cVo,fVo,gVo,pb,P1e,hVo,uVo,dQ,pVo,_Vo,bVo,_b,B1e,vVo,FVo,mQ,TVo,MVo,EVo,bb,I1e,CVo,wVo,cQ,AVo,LVo,yVo,vb,N1e,xVo,$Vo,fQ,kVo,SVo,RVo,Fb,PVo,q1e,BVo,IVo,j1e,NVo,qVo,Tb,teo,Ed,Mb,D1e,Ix,jVo,G1e,DVo,aeo,Io,Nx,GVo,Cd,OVo,gQ,VVo,XVo,hQ,zVo,QVo,WVo,qx,UVo,O1e,HVo,JVo,YVo,vt,jx,KVo,V1e,ZVo,eXo,wd,oXo,X1e,rXo,tXo,uQ,aXo,nXo,sXo,Eb,lXo,oo,Dx,iXo,z1e,dXo,mXo,Ka,cXo,Q1e,fXo,gXo,W1e,hXo,uXo,U1e,pXo,_Xo,bXo,Q,Cb,H1e,vXo,FXo,pQ,TXo,MXo,EXo,wb,J1e,CXo,wXo,_Q,AXo,LXo,yXo,Ab,Y1e,xXo,$Xo,bQ,kXo,SXo,RXo,Lb,K1e,PXo,BXo,vQ,IXo,NXo,qXo,yb,Z1e,jXo,DXo,FQ,GXo,OXo,VXo,xb,ebe,XXo,zXo,TQ,QXo,WXo,UXo,$b,obe,HXo,JXo,MQ,YXo,KXo,ZXo,kb,rbe,ezo,ozo,EQ,rzo,tzo,azo,Sb,tbe,nzo,szo,CQ,lzo,izo,dzo,Rb,abe,mzo,czo,wQ,fzo,gzo,hzo,Pb,nbe,uzo,pzo,AQ,_zo,bzo,vzo,Bb,sbe,Fzo,Tzo,LQ,Mzo,Ezo,Czo,Ib,lbe,wzo,Azo,yQ,Lzo,yzo,xzo,Nb,ibe,$zo,kzo,xQ,Szo,Rzo,Pzo,qb,dbe,Bzo,Izo,$Q,Nzo,qzo,jzo,jb,mbe,Dzo,Gzo,kQ,Ozo,Vzo,Xzo,Db,cbe,zzo,Qzo,SQ,Wzo,Uzo,Hzo,Gb,fbe,Jzo,Yzo,RQ,Kzo,Zzo,eQo,Ob,gbe,oQo,rQo,PQ,tQo,aQo,nQo,Vb,hbe,sQo,lQo,BQ,iQo,dQo,mQo,Xb,ube,cQo,fQo,IQ,gQo,hQo,uQo,zb,pbe,pQo,_Qo,NQ,bQo,vQo,FQo,Qb,_be,TQo,MQo,qQ,EQo,CQo,wQo,Wb,bbe,AQo,LQo,jQ,yQo,xQo,$Qo,Ub,vbe,kQo,SQo,DQ,RQo,PQo,BQo,Hb,Fbe,IQo,NQo,GQ,qQo,jQo,DQo,Jb,Tbe,GQo,OQo,OQ,VQo,XQo,zQo,Yb,Mbe,QQo,WQo,VQ,UQo,HQo,JQo,Kb,Ebe,YQo,KQo,XQ,ZQo,eWo,oWo,Zb,Cbe,rWo,tWo,zQ,aWo,nWo,sWo,ev,wbe,lWo,iWo,QQ,dWo,mWo,cWo,ov,Abe,fWo,gWo,WQ,hWo,uWo,pWo,rv,Lbe,_Wo,bWo,UQ,vWo,FWo,TWo,tv,ybe,MWo,EWo,HQ,CWo,wWo,AWo,av,xbe,LWo,yWo,JQ,xWo,$Wo,kWo,nv,$be,SWo,RWo,YQ,PWo,BWo,IWo,sv,kbe,NWo,qWo,KQ,jWo,DWo,GWo,lv,Sbe,OWo,VWo,ZQ,XWo,zWo,QWo,iv,Rbe,WWo,UWo,eW,HWo,JWo,YWo,dv,Pbe,KWo,ZWo,oW,eUo,oUo,rUo,mv,Bbe,tUo,aUo,rW,nUo,sUo,lUo,cv,Ibe,iUo,dUo,tW,mUo,cUo,fUo,fv,gUo,Nbe,hUo,uUo,qbe,pUo,_Uo,gv,neo,Ad,hv,jbe,Gx,bUo,Dbe,vUo,seo,No,Ox,FUo,Ld,TUo,aW,MUo,EUo,nW,CUo,wUo,AUo,Vx,LUo,Gbe,yUo,xUo,$Uo,Ft,Xx,kUo,Obe,SUo,RUo,yd,PUo,Vbe,BUo,IUo,sW,NUo,qUo,jUo,uv,DUo,ro,zx,GUo,Xbe,OUo,VUo,Za,XUo,zbe,zUo,QUo,Qbe,WUo,UUo,Wbe,HUo,JUo,YUo,J,pv,Ube,KUo,ZUo,lW,eHo,oHo,rHo,_v,Hbe,tHo,aHo,iW,nHo,sHo,lHo,bv,Jbe,iHo,dHo,dW,mHo,cHo,fHo,vv,Ybe,gHo,hHo,mW,uHo,pHo,_Ho,Fv,Kbe,bHo,vHo,cW,FHo,THo,MHo,Tv,Zbe,EHo,CHo,fW,wHo,AHo,LHo,Mv,eve,yHo,xHo,gW,$Ho,kHo,SHo,Ev,ove,RHo,PHo,hW,BHo,IHo,NHo,Cv,rve,qHo,jHo,uW,DHo,GHo,OHo,wv,tve,VHo,XHo,pW,zHo,QHo,WHo,Av,ave,UHo,HHo,_W,JHo,YHo,KHo,Lv,nve,ZHo,eJo,bW,oJo,rJo,tJo,yv,sve,aJo,nJo,vW,sJo,lJo,iJo,xv,lve,dJo,mJo,FW,cJo,fJo,gJo,$v,ive,hJo,uJo,TW,pJo,_Jo,bJo,kv,dve,vJo,FJo,MW,TJo,MJo,EJo,Sv,mve,CJo,wJo,EW,AJo,LJo,yJo,Rv,cve,xJo,$Jo,CW,kJo,SJo,RJo,Pv,fve,PJo,BJo,wW,IJo,NJo,qJo,Bv,gve,jJo,DJo,AW,GJo,OJo,VJo,Iv,hve,XJo,zJo,LW,QJo,WJo,UJo,Nv,uve,HJo,JJo,yW,YJo,KJo,ZJo,qv,pve,eYo,oYo,xW,rYo,tYo,aYo,jv,_ve,nYo,sYo,$W,lYo,iYo,dYo,Dv,bve,mYo,cYo,kW,fYo,gYo,hYo,Gv,vve,uYo,pYo,SW,_Yo,bYo,vYo,Ov,Fve,FYo,TYo,RW,MYo,EYo,CYo,Vv,Tve,wYo,AYo,PW,LYo,yYo,xYo,Xv,Mve,$Yo,kYo,BW,SYo,RYo,PYo,zv,Eve,BYo,IYo,IW,NYo,qYo,jYo,Qv,Cve,DYo,GYo,NW,OYo,VYo,XYo,Wv,wve,zYo,QYo,qW,WYo,UYo,HYo,Uv,Ave,JYo,YYo,jW,KYo,ZYo,eKo,Hv,Lve,oKo,rKo,DW,tKo,aKo,nKo,Jv,yve,sKo,lKo,xve,iKo,dKo,mKo,Yv,$ve,cKo,fKo,GW,gKo,hKo,uKo,Kv,kve,pKo,_Ko,OW,bKo,vKo,FKo,Zv,Sve,TKo,MKo,VW,EKo,CKo,wKo,eF,Rve,AKo,LKo,XW,yKo,xKo,$Ko,oF,kKo,Pve,SKo,RKo,Bve,PKo,BKo,rF,leo,xd,tF,Ive,Qx,IKo,Nve,NKo,ieo,qo,Wx,qKo,$d,jKo,zW,DKo,GKo,QW,OKo,VKo,XKo,Ux,zKo,qve,QKo,WKo,UKo,Tt,Hx,HKo,jve,JKo,YKo,kd,KKo,Dve,ZKo,eZo,WW,oZo,rZo,tZo,aF,aZo,to,Jx,nZo,Gve,sZo,lZo,en,iZo,Ove,dZo,mZo,Vve,cZo,fZo,Xve,gZo,hZo,uZo,fe,nF,zve,pZo,_Zo,UW,bZo,vZo,FZo,sF,Qve,TZo,MZo,HW,EZo,CZo,wZo,lF,Wve,AZo,LZo,JW,yZo,xZo,$Zo,iF,Uve,kZo,SZo,YW,RZo,PZo,BZo,dF,Hve,IZo,NZo,KW,qZo,jZo,DZo,mF,Jve,GZo,OZo,ZW,VZo,XZo,zZo,cF,Yve,QZo,WZo,eU,UZo,HZo,JZo,fF,Kve,YZo,KZo,oU,ZZo,eer,oer,gF,Zve,rer,ter,rU,aer,ner,ser,hF,eFe,ler,ier,tU,der,mer,cer,uF,oFe,fer,ger,aU,her,uer,per,pF,rFe,_er,ber,nU,ver,Fer,Ter,_F,tFe,Mer,Eer,sU,Cer,wer,Aer,bF,aFe,Ler,yer,lU,xer,$er,ker,vF,nFe,Ser,Rer,iU,Per,Ber,Ier,FF,sFe,Ner,qer,dU,jer,Der,Ger,TF,lFe,Oer,Ver,mU,Xer,zer,Qer,MF,iFe,Wer,Uer,cU,Her,Jer,Yer,EF,dFe,Ker,Zer,fU,eor,oor,ror,CF,mFe,tor,aor,gU,nor,sor,lor,wF,ior,cFe,dor,mor,fFe,cor,gor,AF,deo,Sd,LF,gFe,Yx,hor,hFe,uor,meo,jo,Kx,por,Rd,_or,hU,bor,vor,uU,For,Tor,Mor,Zx,Eor,uFe,Cor,wor,Aor,Mt,e$,Lor,pFe,yor,xor,Pd,$or,_Fe,kor,Sor,pU,Ror,Por,Bor,yF,Ior,ao,o$,Nor,bFe,qor,jor,on,Dor,vFe,Gor,Oor,FFe,Vor,Xor,TFe,zor,Qor,Wor,B,xF,MFe,Uor,Hor,_U,Jor,Yor,Kor,$F,EFe,Zor,err,bU,orr,rrr,trr,kF,CFe,arr,nrr,vU,srr,lrr,irr,SF,wFe,drr,mrr,FU,crr,frr,grr,RF,AFe,hrr,urr,TU,prr,_rr,brr,PF,LFe,vrr,Frr,MU,Trr,Mrr,Err,BF,yFe,Crr,wrr,EU,Arr,Lrr,yrr,IF,xFe,xrr,$rr,CU,krr,Srr,Rrr,NF,$Fe,Prr,Brr,wU,Irr,Nrr,qrr,qF,kFe,jrr,Drr,AU,Grr,Orr,Vrr,jF,SFe,Xrr,zrr,LU,Qrr,Wrr,Urr,DF,RFe,Hrr,Jrr,yU,Yrr,Krr,Zrr,GF,PFe,etr,otr,xU,rtr,ttr,atr,OF,BFe,ntr,str,$U,ltr,itr,dtr,VF,IFe,mtr,ctr,kU,ftr,gtr,htr,XF,NFe,utr,ptr,SU,_tr,btr,vtr,zF,qFe,Ftr,Ttr,RU,Mtr,Etr,Ctr,QF,jFe,wtr,Atr,PU,Ltr,ytr,xtr,WF,DFe,$tr,ktr,BU,Str,Rtr,Ptr,UF,GFe,Btr,Itr,IU,Ntr,qtr,jtr,HF,OFe,Dtr,Gtr,NU,Otr,Vtr,Xtr,JF,VFe,ztr,Qtr,qU,Wtr,Utr,Htr,YF,XFe,Jtr,Ytr,jU,Ktr,Ztr,ear,KF,zFe,oar,rar,DU,tar,aar,nar,ZF,QFe,sar,lar,GU,iar,dar,mar,eT,WFe,car,far,OU,gar,har,uar,oT,UFe,par,_ar,VU,bar,Far,Tar,rT,HFe,Mar,Ear,XU,Car,war,Aar,tT,JFe,Lar,yar,zU,xar,$ar,kar,aT,YFe,Sar,Rar,QU,Par,Bar,Iar,nT,KFe,Nar,qar,WU,jar,Dar,Gar,sT,ZFe,Oar,Var,UU,Xar,zar,Qar,lT,eTe,War,Uar,HU,Har,Jar,Yar,iT,oTe,Kar,Zar,JU,enr,onr,rnr,dT,rTe,tnr,anr,YU,nnr,snr,lnr,mT,tTe,inr,dnr,KU,mnr,cnr,fnr,cT,aTe,gnr,hnr,ZU,unr,pnr,_nr,fT,nTe,bnr,vnr,eH,Fnr,Tnr,Mnr,gT,sTe,Enr,Cnr,oH,wnr,Anr,Lnr,hT,lTe,ynr,xnr,rH,$nr,knr,Snr,uT,iTe,Rnr,Pnr,tH,Bnr,Inr,Nnr,pT,dTe,qnr,jnr,aH,Dnr,Gnr,Onr,_T,mTe,Vnr,Xnr,nH,znr,Qnr,Wnr,bT,cTe,Unr,Hnr,sH,Jnr,Ynr,Knr,vT,fTe,Znr,esr,lH,osr,rsr,tsr,FT,gTe,asr,nsr,iH,ssr,lsr,isr,TT,hTe,dsr,msr,dH,csr,fsr,gsr,MT,uTe,hsr,usr,mH,psr,_sr,bsr,ET,pTe,vsr,Fsr,cH,Tsr,Msr,Esr,CT,_Te,Csr,wsr,fH,Asr,Lsr,ysr,wT,bTe,xsr,$sr,gH,ksr,Ssr,Rsr,AT,vTe,Psr,Bsr,hH,Isr,Nsr,qsr,LT,FTe,jsr,Dsr,uH,Gsr,Osr,Vsr,yT,TTe,Xsr,zsr,pH,Qsr,Wsr,Usr,xT,MTe,Hsr,Jsr,_H,Ysr,Ksr,Zsr,$T,elr,ETe,olr,rlr,CTe,tlr,alr,kT,ceo,Bd,ST,wTe,r$,nlr,ATe,slr,feo,Do,t$,llr,Id,ilr,bH,dlr,mlr,vH,clr,flr,glr,a$,hlr,LTe,ulr,plr,_lr,Et,n$,blr,yTe,vlr,Flr,Nd,Tlr,xTe,Mlr,Elr,FH,Clr,wlr,Alr,RT,Llr,no,s$,ylr,$Te,xlr,$lr,rn,klr,kTe,Slr,Rlr,STe,Plr,Blr,RTe,Ilr,Nlr,qlr,Z,PT,PTe,jlr,Dlr,TH,Glr,Olr,Vlr,BT,BTe,Xlr,zlr,MH,Qlr,Wlr,Ulr,IT,ITe,Hlr,Jlr,EH,Ylr,Klr,Zlr,NT,NTe,eir,oir,CH,rir,tir,air,qT,qTe,nir,sir,wH,lir,iir,dir,jT,jTe,mir,cir,AH,fir,gir,hir,DT,DTe,uir,pir,LH,_ir,bir,vir,GT,GTe,Fir,Tir,yH,Mir,Eir,Cir,OT,OTe,wir,Air,xH,Lir,yir,xir,VT,VTe,$ir,kir,$H,Sir,Rir,Pir,XT,XTe,Bir,Iir,kH,Nir,qir,jir,zT,zTe,Dir,Gir,SH,Oir,Vir,Xir,QT,QTe,zir,Qir,RH,Wir,Uir,Hir,WT,WTe,Jir,Yir,PH,Kir,Zir,edr,UT,UTe,odr,rdr,BH,tdr,adr,ndr,HT,HTe,sdr,ldr,IH,idr,ddr,mdr,JT,JTe,cdr,fdr,NH,gdr,hdr,udr,YT,YTe,pdr,_dr,qH,bdr,vdr,Fdr,KT,KTe,Tdr,Mdr,jH,Edr,Cdr,wdr,ZT,ZTe,Adr,Ldr,DH,ydr,xdr,$dr,eM,eMe,kdr,Sdr,GH,Rdr,Pdr,Bdr,oM,oMe,Idr,Ndr,OH,qdr,jdr,Ddr,rM,rMe,Gdr,Odr,VH,Vdr,Xdr,zdr,tM,tMe,Qdr,Wdr,XH,Udr,Hdr,Jdr,aM,aMe,Ydr,Kdr,zH,Zdr,emr,omr,nM,nMe,rmr,tmr,QH,amr,nmr,smr,sM,sMe,lmr,imr,WH,dmr,mmr,cmr,lM,lMe,fmr,gmr,UH,hmr,umr,pmr,iM,iMe,_mr,bmr,HH,vmr,Fmr,Tmr,dM,dMe,Mmr,Emr,JH,Cmr,wmr,Amr,mM,mMe,Lmr,ymr,YH,xmr,$mr,kmr,cM,cMe,Smr,Rmr,KH,Pmr,Bmr,Imr,fM,Nmr,fMe,qmr,jmr,gMe,Dmr,Gmr,gM,geo,qd,hM,hMe,l$,Omr,uMe,Vmr,heo,Go,i$,Xmr,jd,zmr,ZH,Qmr,Wmr,eJ,Umr,Hmr,Jmr,d$,Ymr,pMe,Kmr,Zmr,ecr,Ct,m$,ocr,_Me,rcr,tcr,Dd,acr,bMe,ncr,scr,oJ,lcr,icr,dcr,uM,mcr,so,c$,ccr,vMe,fcr,gcr,tn,hcr,FMe,ucr,pcr,TMe,_cr,bcr,MMe,vcr,Fcr,Tcr,Ue,pM,EMe,Mcr,Ecr,rJ,Ccr,wcr,Acr,_M,CMe,Lcr,ycr,tJ,xcr,$cr,kcr,bM,wMe,Scr,Rcr,aJ,Pcr,Bcr,Icr,vM,AMe,Ncr,qcr,nJ,jcr,Dcr,Gcr,FM,LMe,Ocr,Vcr,sJ,Xcr,zcr,Qcr,TM,yMe,Wcr,Ucr,lJ,Hcr,Jcr,Ycr,MM,xMe,Kcr,Zcr,iJ,efr,ofr,rfr,EM,tfr,$Me,afr,nfr,kMe,sfr,lfr,CM,ueo,Gd,wM,SMe,f$,ifr,RMe,dfr,peo,Oo,g$,mfr,Od,cfr,dJ,ffr,gfr,mJ,hfr,ufr,pfr,h$,_fr,PMe,bfr,vfr,Ffr,wt,u$,Tfr,BMe,Mfr,Efr,Vd,Cfr,IMe,wfr,Afr,cJ,Lfr,yfr,xfr,AM,$fr,lo,p$,kfr,NMe,Sfr,Rfr,an,Pfr,qMe,Bfr,Ifr,jMe,Nfr,qfr,DMe,jfr,Dfr,Gfr,H,LM,GMe,Ofr,Vfr,fJ,Xfr,zfr,Qfr,yM,OMe,Wfr,Ufr,gJ,Hfr,Jfr,Yfr,xM,VMe,Kfr,Zfr,hJ,egr,ogr,rgr,$M,XMe,tgr,agr,uJ,ngr,sgr,lgr,kM,zMe,igr,dgr,pJ,mgr,cgr,fgr,SM,QMe,ggr,hgr,_J,ugr,pgr,_gr,RM,WMe,bgr,vgr,bJ,Fgr,Tgr,Mgr,PM,UMe,Egr,Cgr,vJ,wgr,Agr,Lgr,BM,HMe,ygr,xgr,FJ,$gr,kgr,Sgr,IM,JMe,Rgr,Pgr,TJ,Bgr,Igr,Ngr,NM,YMe,qgr,jgr,MJ,Dgr,Ggr,Ogr,qM,KMe,Vgr,Xgr,EJ,zgr,Qgr,Wgr,jM,ZMe,Ugr,Hgr,CJ,Jgr,Ygr,Kgr,DM,eEe,Zgr,ehr,wJ,ohr,rhr,thr,GM,oEe,ahr,nhr,AJ,shr,lhr,ihr,OM,rEe,dhr,mhr,LJ,chr,fhr,ghr,VM,tEe,hhr,uhr,yJ,phr,_hr,bhr,XM,aEe,vhr,Fhr,xJ,Thr,Mhr,Ehr,zM,nEe,Chr,whr,$J,Ahr,Lhr,yhr,QM,sEe,xhr,$hr,kJ,khr,Shr,Rhr,WM,lEe,Phr,Bhr,SJ,Ihr,Nhr,qhr,UM,iEe,jhr,Dhr,RJ,Ghr,Ohr,Vhr,HM,dEe,Xhr,zhr,PJ,Qhr,Whr,Uhr,JM,mEe,Hhr,Jhr,BJ,Yhr,Khr,Zhr,YM,cEe,eur,our,IJ,rur,tur,aur,KM,fEe,nur,sur,NJ,lur,iur,dur,ZM,gEe,mur,cur,qJ,fur,gur,hur,eE,hEe,uur,pur,jJ,_ur,bur,vur,oE,uEe,Fur,Tur,DJ,Mur,Eur,Cur,rE,pEe,wur,Aur,GJ,Lur,yur,xur,tE,_Ee,$ur,kur,OJ,Sur,Rur,Pur,aE,bEe,Bur,Iur,VJ,Nur,qur,jur,nE,vEe,Dur,Gur,XJ,Our,Vur,Xur,sE,FEe,zur,Qur,zJ,Wur,Uur,Hur,lE,TEe,Jur,Yur,QJ,Kur,Zur,epr,iE,MEe,opr,rpr,WJ,tpr,apr,npr,dE,EEe,spr,lpr,UJ,ipr,dpr,mpr,mE,CEe,cpr,fpr,HJ,gpr,hpr,upr,cE,wEe,ppr,_pr,JJ,bpr,vpr,Fpr,fE,AEe,Tpr,Mpr,YJ,Epr,Cpr,wpr,gE,Apr,LEe,Lpr,ypr,yEe,xpr,$pr,hE,_eo,Xd,uE,xEe,_$,kpr,$Ee,Spr,beo,Vo,b$,Rpr,zd,Ppr,KJ,Bpr,Ipr,ZJ,Npr,qpr,jpr,v$,Dpr,kEe,Gpr,Opr,Vpr,At,F$,Xpr,SEe,zpr,Qpr,Qd,Wpr,REe,Upr,Hpr,eY,Jpr,Ypr,Kpr,pE,Zpr,io,T$,e_r,PEe,o_r,r_r,nn,t_r,BEe,a_r,n_r,IEe,s_r,l_r,NEe,i_r,d_r,m_r,V,_E,qEe,c_r,f_r,oY,g_r,h_r,u_r,bE,jEe,p_r,__r,rY,b_r,v_r,F_r,vE,DEe,T_r,M_r,tY,E_r,C_r,w_r,FE,GEe,A_r,L_r,aY,y_r,x_r,$_r,TE,OEe,k_r,S_r,nY,R_r,P_r,B_r,ME,VEe,I_r,N_r,sY,q_r,j_r,D_r,EE,XEe,G_r,O_r,lY,V_r,X_r,z_r,CE,zEe,Q_r,W_r,iY,U_r,H_r,J_r,wE,QEe,Y_r,K_r,dY,Z_r,e2r,o2r,AE,WEe,r2r,t2r,mY,a2r,n2r,s2r,LE,UEe,l2r,i2r,cY,d2r,m2r,c2r,yE,HEe,f2r,g2r,fY,h2r,u2r,p2r,xE,JEe,_2r,b2r,gY,v2r,F2r,T2r,$E,YEe,M2r,E2r,hY,C2r,w2r,A2r,kE,KEe,L2r,y2r,uY,x2r,$2r,k2r,SE,ZEe,S2r,R2r,pY,P2r,B2r,I2r,RE,e4e,N2r,q2r,_Y,j2r,D2r,G2r,PE,o4e,O2r,V2r,bY,X2r,z2r,Q2r,BE,r4e,W2r,U2r,vY,H2r,J2r,Y2r,IE,t4e,K2r,Z2r,FY,e1r,o1r,r1r,NE,a4e,t1r,a1r,TY,n1r,s1r,l1r,qE,n4e,i1r,d1r,MY,m1r,c1r,f1r,jE,s4e,g1r,h1r,EY,u1r,p1r,_1r,DE,l4e,b1r,v1r,CY,F1r,T1r,M1r,GE,i4e,E1r,C1r,wY,w1r,A1r,L1r,OE,d4e,y1r,x1r,AY,$1r,k1r,S1r,VE,m4e,R1r,P1r,LY,B1r,I1r,N1r,XE,c4e,q1r,j1r,yY,D1r,G1r,O1r,zE,f4e,V1r,X1r,xY,z1r,Q1r,W1r,QE,g4e,U1r,H1r,$Y,J1r,Y1r,K1r,WE,h4e,Z1r,ebr,kY,obr,rbr,tbr,UE,u4e,abr,nbr,SY,sbr,lbr,ibr,HE,p4e,dbr,mbr,RY,cbr,fbr,gbr,JE,_4e,hbr,ubr,PY,pbr,_br,bbr,YE,b4e,vbr,Fbr,BY,Tbr,Mbr,Ebr,KE,v4e,Cbr,wbr,IY,Abr,Lbr,ybr,ZE,F4e,xbr,$br,NY,kbr,Sbr,Rbr,e4,T4e,Pbr,Bbr,qY,Ibr,Nbr,qbr,o4,M4e,jbr,Dbr,jY,Gbr,Obr,Vbr,r4,E4e,Xbr,zbr,DY,Qbr,Wbr,Ubr,t4,C4e,Hbr,Jbr,GY,Ybr,Kbr,Zbr,a4,w4e,evr,ovr,OY,rvr,tvr,avr,n4,A4e,nvr,svr,VY,lvr,ivr,dvr,s4,L4e,mvr,cvr,XY,fvr,gvr,hvr,l4,y4e,uvr,pvr,zY,_vr,bvr,vvr,i4,Fvr,x4e,Tvr,Mvr,$4e,Evr,Cvr,d4,veo,Wd,m4,k4e,M$,wvr,S4e,Avr,Feo,Xo,E$,Lvr,Ud,yvr,QY,xvr,$vr,WY,kvr,Svr,Rvr,C$,Pvr,R4e,Bvr,Ivr,Nvr,Lt,w$,qvr,P4e,jvr,Dvr,Hd,Gvr,B4e,Ovr,Vvr,UY,Xvr,zvr,Qvr,c4,Wvr,mo,A$,Uvr,I4e,Hvr,Jvr,sn,Yvr,N4e,Kvr,Zvr,q4e,eFr,oFr,j4e,rFr,tFr,aFr,D4e,f4,G4e,nFr,sFr,HY,lFr,iFr,dFr,g4,mFr,O4e,cFr,fFr,V4e,gFr,hFr,h4,Teo,Jd,u4,X4e,L$,uFr,z4e,pFr,Meo,zo,y$,_Fr,Yd,bFr,JY,vFr,FFr,YY,TFr,MFr,EFr,x$,CFr,Q4e,wFr,AFr,LFr,yt,$$,yFr,W4e,xFr,$Fr,Kd,kFr,U4e,SFr,RFr,KY,PFr,BFr,IFr,p4,NFr,co,k$,qFr,H4e,jFr,DFr,ln,GFr,J4e,OFr,VFr,Y4e,XFr,zFr,K4e,QFr,WFr,UFr,Zd,_4,Z4e,HFr,JFr,ZY,YFr,KFr,ZFr,b4,eCe,eTr,oTr,eK,rTr,tTr,aTr,v4,oCe,nTr,sTr,oK,lTr,iTr,dTr,F4,mTr,rCe,cTr,fTr,tCe,gTr,hTr,T4,Eeo,em,M4,aCe,S$,uTr,nCe,pTr,Ceo,Qo,R$,_Tr,om,bTr,rK,vTr,FTr,tK,TTr,MTr,ETr,P$,CTr,sCe,wTr,ATr,LTr,xt,B$,yTr,lCe,xTr,$Tr,rm,kTr,iCe,STr,RTr,aK,PTr,BTr,ITr,E4,NTr,fo,I$,qTr,dCe,jTr,DTr,dn,GTr,mCe,OTr,VTr,cCe,XTr,zTr,fCe,QTr,WTr,UTr,be,C4,gCe,HTr,JTr,nK,YTr,KTr,ZTr,w4,hCe,eMr,oMr,sK,rMr,tMr,aMr,A4,uCe,nMr,sMr,lK,lMr,iMr,dMr,L4,pCe,mMr,cMr,iK,fMr,gMr,hMr,bl,_Ce,uMr,pMr,dK,_Mr,bMr,mK,vMr,FMr,TMr,y4,bCe,MMr,EMr,cK,CMr,wMr,AMr,vl,vCe,LMr,yMr,fK,xMr,$Mr,gK,kMr,SMr,RMr,x4,FCe,PMr,BMr,hK,IMr,NMr,qMr,$t,TCe,jMr,DMr,uK,GMr,OMr,pK,VMr,XMr,_K,zMr,QMr,WMr,$4,MCe,UMr,HMr,bK,JMr,YMr,KMr,k4,ECe,ZMr,eEr,vK,oEr,rEr,tEr,S4,CCe,aEr,nEr,FK,sEr,lEr,iEr,R4,wCe,dEr,mEr,TK,cEr,fEr,gEr,P4,ACe,hEr,uEr,MK,pEr,_Er,bEr,B4,LCe,vEr,FEr,EK,TEr,MEr,EEr,I4,yCe,CEr,wEr,CK,AEr,LEr,yEr,N4,xCe,xEr,$Er,wK,kEr,SEr,REr,q4,$Ce,PEr,BEr,AK,IEr,NEr,qEr,j4,jEr,kCe,DEr,GEr,SCe,OEr,VEr,D4,weo,tm,G4,RCe,N$,XEr,PCe,zEr,Aeo,Wo,q$,QEr,am,WEr,LK,UEr,HEr,yK,JEr,YEr,KEr,j$,ZEr,BCe,e4r,o4r,r4r,kt,D$,t4r,ICe,a4r,n4r,nm,s4r,NCe,l4r,i4r,xK,d4r,m4r,c4r,O4,f4r,go,G$,g4r,qCe,h4r,u4r,mn,p4r,jCe,_4r,b4r,DCe,v4r,F4r,GCe,T4r,M4r,E4r,OCe,V4,VCe,C4r,w4r,$K,A4r,L4r,y4r,X4,x4r,XCe,$4r,k4r,zCe,S4r,R4r,z4,Leo,sm,Q4,QCe,O$,P4r,WCe,B4r,yeo,Uo,V$,I4r,lm,N4r,kK,q4r,j4r,SK,D4r,G4r,O4r,X$,V4r,UCe,X4r,z4r,Q4r,St,z$,W4r,HCe,U4r,H4r,im,J4r,JCe,Y4r,K4r,RK,Z4r,eCr,oCr,W4,rCr,ho,Q$,tCr,YCe,aCr,nCr,cn,sCr,KCe,lCr,iCr,ZCe,dCr,mCr,e3e,cCr,fCr,gCr,o3e,U4,r3e,hCr,uCr,PK,pCr,_Cr,bCr,H4,vCr,t3e,FCr,TCr,a3e,MCr,ECr,J4,xeo,dm,Y4,n3e,W$,CCr,s3e,wCr,$eo,Ho,U$,ACr,mm,LCr,BK,yCr,xCr,IK,$Cr,kCr,SCr,H$,RCr,l3e,PCr,BCr,ICr,Rt,J$,NCr,i3e,qCr,jCr,cm,DCr,d3e,GCr,OCr,NK,VCr,XCr,zCr,K4,QCr,uo,Y$,WCr,m3e,UCr,HCr,fn,JCr,c3e,YCr,KCr,f3e,ZCr,e3r,g3e,o3r,r3r,t3r,h3e,Z4,u3e,a3r,n3r,qK,s3r,l3r,i3r,eC,d3r,p3e,m3r,c3r,_3e,f3r,g3r,oC,keo,fm,rC,b3e,K$,h3r,v3e,u3r,Seo,Jo,Z$,p3r,gm,_3r,jK,b3r,v3r,DK,F3r,T3r,M3r,ek,E3r,F3e,C3r,w3r,A3r,Pt,ok,L3r,T3e,y3r,x3r,hm,$3r,M3e,k3r,S3r,GK,R3r,P3r,B3r,tC,I3r,po,rk,N3r,E3e,q3r,j3r,gn,D3r,C3e,G3r,O3r,w3e,V3r,X3r,A3e,z3r,Q3r,W3r,Pe,aC,L3e,U3r,H3r,OK,J3r,Y3r,K3r,nC,y3e,Z3r,e5r,VK,o5r,r5r,t5r,sC,x3e,a5r,n5r,XK,s5r,l5r,i5r,lC,$3e,d5r,m5r,zK,c5r,f5r,g5r,iC,k3e,h5r,u5r,QK,p5r,_5r,b5r,dC,S3e,v5r,F5r,WK,T5r,M5r,E5r,mC,R3e,C5r,w5r,UK,A5r,L5r,y5r,cC,P3e,x5r,$5r,HK,k5r,S5r,R5r,fC,B3e,P5r,B5r,JK,I5r,N5r,q5r,gC,j5r,I3e,D5r,G5r,N3e,O5r,V5r,hC,Reo,um,uC,q3e,tk,X5r,j3e,z5r,Peo,Yo,ak,Q5r,pm,W5r,YK,U5r,H5r,KK,J5r,Y5r,K5r,nk,Z5r,D3e,e0r,o0r,r0r,Bt,sk,t0r,G3e,a0r,n0r,_m,s0r,O3e,l0r,i0r,ZK,d0r,m0r,c0r,pC,f0r,_o,lk,g0r,V3e,h0r,u0r,hn,p0r,X3e,_0r,b0r,z3e,v0r,F0r,Q3e,T0r,M0r,E0r,ct,_C,W3e,C0r,w0r,eZ,A0r,L0r,y0r,bC,U3e,x0r,$0r,oZ,k0r,S0r,R0r,vC,H3e,P0r,B0r,rZ,I0r,N0r,q0r,FC,J3e,j0r,D0r,tZ,G0r,O0r,V0r,TC,Y3e,X0r,z0r,aZ,Q0r,W0r,U0r,MC,H0r,K3e,J0r,Y0r,Z3e,K0r,Z0r,EC,Beo,bm,CC,e5e,ik,ewr,o5e,owr,Ieo,Ko,dk,rwr,vm,twr,nZ,awr,nwr,sZ,swr,lwr,iwr,mk,dwr,r5e,mwr,cwr,fwr,It,ck,gwr,t5e,hwr,uwr,Fm,pwr,a5e,_wr,bwr,lZ,vwr,Fwr,Twr,wC,Mwr,bo,fk,Ewr,n5e,Cwr,wwr,un,Awr,s5e,Lwr,ywr,l5e,xwr,$wr,i5e,kwr,Swr,Rwr,Le,AC,d5e,Pwr,Bwr,iZ,Iwr,Nwr,qwr,LC,m5e,jwr,Dwr,dZ,Gwr,Owr,Vwr,yC,c5e,Xwr,zwr,mZ,Qwr,Wwr,Uwr,xC,f5e,Hwr,Jwr,cZ,Ywr,Kwr,Zwr,$C,g5e,eAr,oAr,fZ,rAr,tAr,aAr,kC,h5e,nAr,sAr,gZ,lAr,iAr,dAr,SC,u5e,mAr,cAr,hZ,fAr,gAr,hAr,RC,p5e,uAr,pAr,uZ,_Ar,bAr,vAr,PC,_5e,FAr,TAr,pZ,MAr,EAr,CAr,BC,b5e,wAr,AAr,_Z,LAr,yAr,xAr,IC,$Ar,v5e,kAr,SAr,F5e,RAr,PAr,NC,Neo,Tm,qC,T5e,gk,BAr,M5e,IAr,qeo,Zo,hk,NAr,Mm,qAr,bZ,jAr,DAr,vZ,GAr,OAr,VAr,uk,XAr,E5e,zAr,QAr,WAr,Nt,pk,UAr,C5e,HAr,JAr,Em,YAr,w5e,KAr,ZAr,FZ,e6r,o6r,r6r,jC,t6r,vo,_k,a6r,A5e,n6r,s6r,pn,l6r,L5e,i6r,d6r,y5e,m6r,c6r,x5e,f6r,g6r,h6r,bk,DC,$5e,u6r,p6r,TZ,_6r,b6r,v6r,GC,k5e,F6r,T6r,MZ,M6r,E6r,C6r,OC,w6r,S5e,A6r,L6r,R5e,y6r,x6r,VC,jeo,Cm,XC,P5e,vk,$6r,B5e,k6r,Deo,er,Fk,S6r,wm,R6r,EZ,P6r,B6r,CZ,I6r,N6r,q6r,Tk,j6r,I5e,D6r,G6r,O6r,qt,Mk,V6r,N5e,X6r,z6r,Am,Q6r,q5e,W6r,U6r,wZ,H6r,J6r,Y6r,zC,K6r,Fo,Ek,Z6r,j5e,e7r,o7r,_n,r7r,D5e,t7r,a7r,G5e,n7r,s7r,O5e,l7r,i7r,d7r,ft,QC,V5e,m7r,c7r,AZ,f7r,g7r,h7r,WC,X5e,u7r,p7r,LZ,_7r,b7r,v7r,UC,z5e,F7r,T7r,yZ,M7r,E7r,C7r,HC,Q5e,w7r,A7r,xZ,L7r,y7r,x7r,JC,W5e,$7r,k7r,$Z,S7r,R7r,P7r,YC,B7r,U5e,I7r,N7r,H5e,q7r,j7r,KC,Geo,Lm,ZC,J5e,Ck,D7r,Y5e,G7r,Oeo,or,wk,O7r,ym,V7r,kZ,X7r,z7r,SZ,Q7r,W7r,U7r,Ak,H7r,K5e,J7r,Y7r,K7r,jt,Lk,Z7r,Z5e,eLr,oLr,xm,rLr,e0e,tLr,aLr,RZ,nLr,sLr,lLr,e3,iLr,To,yk,dLr,o0e,mLr,cLr,bn,fLr,r0e,gLr,hLr,t0e,uLr,pLr,a0e,_Lr,bLr,vLr,vn,o3,n0e,FLr,TLr,PZ,MLr,ELr,CLr,r3,s0e,wLr,ALr,BZ,LLr,yLr,xLr,t3,l0e,$Lr,kLr,IZ,SLr,RLr,PLr,a3,i0e,BLr,ILr,NZ,NLr,qLr,jLr,n3,DLr,d0e,GLr,OLr,m0e,VLr,XLr,s3,Veo,$m,l3,c0e,xk,zLr,f0e,QLr,Xeo,rr,$k,WLr,km,ULr,qZ,HLr,JLr,jZ,YLr,KLr,ZLr,kk,eyr,g0e,oyr,ryr,tyr,Dt,Sk,ayr,h0e,nyr,syr,Sm,lyr,u0e,iyr,dyr,DZ,myr,cyr,fyr,i3,gyr,Mo,Rk,hyr,p0e,uyr,pyr,Fn,_yr,_0e,byr,vyr,b0e,Fyr,Tyr,v0e,Myr,Eyr,Cyr,Tn,d3,F0e,wyr,Ayr,GZ,Lyr,yyr,xyr,m3,T0e,$yr,kyr,OZ,Syr,Ryr,Pyr,c3,M0e,Byr,Iyr,VZ,Nyr,qyr,jyr,f3,E0e,Dyr,Gyr,XZ,Oyr,Vyr,Xyr,g3,zyr,C0e,Qyr,Wyr,w0e,Uyr,Hyr,h3,zeo,Rm,u3,A0e,Pk,Jyr,L0e,Yyr,Qeo,tr,Bk,Kyr,Pm,Zyr,zZ,e8r,o8r,QZ,r8r,t8r,a8r,Ik,n8r,y0e,s8r,l8r,i8r,Gt,Nk,d8r,x0e,m8r,c8r,Bm,f8r,$0e,g8r,h8r,WZ,u8r,p8r,_8r,p3,b8r,Eo,qk,v8r,k0e,F8r,T8r,Mn,M8r,S0e,E8r,C8r,R0e,w8r,A8r,P0e,L8r,y8r,x8r,B0e,_3,I0e,$8r,k8r,UZ,S8r,R8r,P8r,b3,B8r,N0e,I8r,N8r,q0e,q8r,j8r,v3,Weo,Im,F3,j0e,jk,D8r,D0e,G8r,Ueo,ar,Dk,O8r,Nm,V8r,HZ,X8r,z8r,JZ,Q8r,W8r,U8r,Gk,H8r,G0e,J8r,Y8r,K8r,Ot,Ok,Z8r,O0e,e9r,o9r,qm,r9r,V0e,t9r,a9r,YZ,n9r,s9r,l9r,T3,i9r,Co,Vk,d9r,X0e,m9r,c9r,En,f9r,z0e,g9r,h9r,Q0e,u9r,p9r,W0e,_9r,b9r,v9r,gt,M3,U0e,F9r,T9r,KZ,M9r,E9r,C9r,E3,H0e,w9r,A9r,ZZ,L9r,y9r,x9r,C3,J0e,$9r,k9r,eee,S9r,R9r,P9r,w3,Y0e,B9r,I9r,oee,N9r,q9r,j9r,A3,K0e,D9r,G9r,ree,O9r,V9r,X9r,L3,z9r,Z0e,Q9r,W9r,ewe,U9r,H9r,y3,Heo,jm,x3,owe,Xk,J9r,rwe,Y9r,Jeo,nr,zk,K9r,Dm,Z9r,tee,exr,oxr,aee,rxr,txr,axr,Qk,nxr,twe,sxr,lxr,ixr,Vt,Wk,dxr,awe,mxr,cxr,Gm,fxr,nwe,gxr,hxr,nee,uxr,pxr,_xr,$3,bxr,wo,Uk,vxr,swe,Fxr,Txr,Cn,Mxr,lwe,Exr,Cxr,iwe,wxr,Axr,dwe,Lxr,yxr,xxr,mwe,k3,cwe,$xr,kxr,see,Sxr,Rxr,Pxr,S3,Bxr,fwe,Ixr,Nxr,gwe,qxr,jxr,R3,Yeo,Om,P3,hwe,Hk,Dxr,uwe,Gxr,Keo,sr,Jk,Oxr,Vm,Vxr,lee,Xxr,zxr,iee,Qxr,Wxr,Uxr,Yk,Hxr,pwe,Jxr,Yxr,Kxr,Xt,Kk,Zxr,_we,e$r,o$r,Xm,r$r,bwe,t$r,a$r,dee,n$r,s$r,l$r,B3,i$r,Ir,Zk,d$r,vwe,m$r,c$r,wn,f$r,Fwe,g$r,h$r,Twe,u$r,p$r,Mwe,_$r,b$r,v$r,I,I3,Ewe,F$r,T$r,mee,M$r,E$r,C$r,N3,Cwe,w$r,A$r,cee,L$r,y$r,x$r,q3,wwe,$$r,k$r,fee,S$r,R$r,P$r,j3,Awe,B$r,I$r,gee,N$r,q$r,j$r,D3,Lwe,D$r,G$r,hee,O$r,V$r,X$r,G3,ywe,z$r,Q$r,uee,W$r,U$r,H$r,O3,xwe,J$r,Y$r,pee,K$r,Z$r,ekr,V3,$we,okr,rkr,_ee,tkr,akr,nkr,X3,kwe,skr,lkr,bee,ikr,dkr,mkr,z3,Swe,ckr,fkr,vee,gkr,hkr,ukr,Q3,Rwe,pkr,_kr,Fee,bkr,vkr,Fkr,W3,Pwe,Tkr,Mkr,Tee,Ekr,Ckr,wkr,U3,Bwe,Akr,Lkr,Mee,ykr,xkr,$kr,H3,Iwe,kkr,Skr,Eee,Rkr,Pkr,Bkr,J3,Nwe,Ikr,Nkr,Cee,qkr,jkr,Dkr,Y3,qwe,Gkr,Okr,wee,Vkr,Xkr,zkr,K3,jwe,Qkr,Wkr,Aee,Ukr,Hkr,Jkr,Z3,Dwe,Ykr,Kkr,Lee,Zkr,eSr,oSr,Fl,Gwe,rSr,tSr,yee,aSr,nSr,xee,sSr,lSr,iSr,e5,Owe,dSr,mSr,$ee,cSr,fSr,gSr,o5,Vwe,hSr,uSr,kee,pSr,_Sr,bSr,r5,Xwe,vSr,FSr,See,TSr,MSr,ESr,t5,zwe,CSr,wSr,Ree,ASr,LSr,ySr,a5,Qwe,xSr,$Sr,Pee,kSr,SSr,RSr,n5,Wwe,PSr,BSr,Bee,ISr,NSr,qSr,s5,Uwe,jSr,DSr,Iee,GSr,OSr,VSr,l5,Hwe,XSr,zSr,Nee,QSr,WSr,USr,i5,Jwe,HSr,JSr,qee,YSr,KSr,ZSr,d5,Ywe,eRr,oRr,jee,rRr,tRr,aRr,m5,Kwe,nRr,sRr,Dee,lRr,iRr,dRr,c5,Zwe,mRr,cRr,Gee,fRr,gRr,hRr,f5,eAe,uRr,pRr,Oee,_Rr,bRr,vRr,g5,oAe,FRr,TRr,Vee,MRr,ERr,CRr,h5,rAe,wRr,ARr,Xee,LRr,yRr,xRr,u5,tAe,$Rr,kRr,zee,SRr,RRr,PRr,p5,aAe,BRr,IRr,Qee,NRr,qRr,jRr,_5,nAe,DRr,GRr,Wee,ORr,VRr,XRr,b5,sAe,zRr,QRr,Uee,WRr,URr,HRr,v5,lAe,JRr,YRr,Hee,KRr,ZRr,ePr,F5,iAe,oPr,rPr,Jee,tPr,aPr,nPr,T5,dAe,sPr,lPr,Yee,iPr,dPr,mPr,M5,mAe,cPr,fPr,Kee,gPr,hPr,uPr,E5,cAe,pPr,_Pr,Zee,bPr,vPr,FPr,C5,fAe,TPr,MPr,eoe,EPr,CPr,wPr,w5,gAe,APr,LPr,ooe,yPr,xPr,$Pr,A5,hAe,kPr,SPr,roe,RPr,PPr,BPr,L5,uAe,IPr,NPr,toe,qPr,jPr,DPr,y5,pAe,GPr,OPr,aoe,VPr,XPr,zPr,x5,_Ae,QPr,WPr,noe,UPr,HPr,JPr,$5,bAe,YPr,KPr,soe,ZPr,eBr,oBr,k5,vAe,rBr,tBr,loe,aBr,nBr,sBr,S5,FAe,lBr,iBr,ioe,dBr,mBr,cBr,R5,TAe,fBr,gBr,doe,hBr,uBr,pBr,P5,MAe,_Br,bBr,moe,vBr,FBr,TBr,B5,EAe,MBr,EBr,coe,CBr,wBr,ABr,I5,Zeo,zm,N5,CAe,eS,LBr,wAe,yBr,eoo,lr,oS,xBr,Qm,$Br,foe,kBr,SBr,goe,RBr,PBr,BBr,rS,IBr,AAe,NBr,qBr,jBr,zt,tS,DBr,LAe,GBr,OBr,Wm,VBr,yAe,XBr,zBr,hoe,QBr,WBr,UBr,q5,HBr,Nr,aS,JBr,xAe,YBr,KBr,An,ZBr,$Ae,eIr,oIr,kAe,rIr,tIr,SAe,aIr,nIr,sIr,se,j5,RAe,lIr,iIr,uoe,dIr,mIr,cIr,D5,PAe,fIr,gIr,poe,hIr,uIr,pIr,G5,BAe,_Ir,bIr,_oe,vIr,FIr,TIr,O5,IAe,MIr,EIr,boe,CIr,wIr,AIr,V5,NAe,LIr,yIr,voe,xIr,$Ir,kIr,X5,qAe,SIr,RIr,Foe,PIr,BIr,IIr,z5,jAe,NIr,qIr,Toe,jIr,DIr,GIr,Q5,DAe,OIr,VIr,Moe,XIr,zIr,QIr,W5,GAe,WIr,UIr,Eoe,HIr,JIr,YIr,U5,OAe,KIr,ZIr,Coe,eNr,oNr,rNr,H5,VAe,tNr,aNr,woe,nNr,sNr,lNr,J5,XAe,iNr,dNr,Aoe,mNr,cNr,fNr,Y5,zAe,gNr,hNr,Loe,uNr,pNr,_Nr,K5,QAe,bNr,vNr,yoe,FNr,TNr,MNr,Z5,WAe,ENr,CNr,xoe,wNr,ANr,LNr,e0,UAe,yNr,xNr,$oe,$Nr,kNr,SNr,o0,HAe,RNr,PNr,koe,BNr,INr,NNr,r0,JAe,qNr,jNr,Soe,DNr,GNr,ONr,t0,YAe,VNr,XNr,Roe,zNr,QNr,WNr,a0,KAe,UNr,HNr,Poe,JNr,YNr,KNr,n0,ZAe,ZNr,eqr,Boe,oqr,rqr,tqr,s0,e6e,aqr,nqr,Ioe,sqr,lqr,iqr,l0,o6e,dqr,mqr,Noe,cqr,fqr,gqr,i0,ooo,Um,d0,r6e,nS,hqr,t6e,uqr,roo,ir,sS,pqr,Hm,_qr,qoe,bqr,vqr,joe,Fqr,Tqr,Mqr,lS,Eqr,a6e,Cqr,wqr,Aqr,Qt,iS,Lqr,n6e,yqr,xqr,Jm,$qr,s6e,kqr,Sqr,Doe,Rqr,Pqr,Bqr,m0,Iqr,qr,dS,Nqr,l6e,qqr,jqr,Ln,Dqr,i6e,Gqr,Oqr,d6e,Vqr,Xqr,m6e,zqr,Qqr,Wqr,Me,c0,c6e,Uqr,Hqr,Goe,Jqr,Yqr,Kqr,f0,f6e,Zqr,ejr,Ooe,ojr,rjr,tjr,g0,g6e,ajr,njr,Voe,sjr,ljr,ijr,h0,h6e,djr,mjr,Xoe,cjr,fjr,gjr,u0,u6e,hjr,ujr,zoe,pjr,_jr,bjr,p0,p6e,vjr,Fjr,Qoe,Tjr,Mjr,Ejr,_0,_6e,Cjr,wjr,Woe,Ajr,Ljr,yjr,b0,b6e,xjr,$jr,Uoe,kjr,Sjr,Rjr,v0,v6e,Pjr,Bjr,Hoe,Ijr,Njr,qjr,F0,F6e,jjr,Djr,Joe,Gjr,Ojr,Vjr,T0,T6e,Xjr,zjr,Yoe,Qjr,Wjr,Ujr,M0,M6e,Hjr,Jjr,Koe,Yjr,Kjr,Zjr,E0,E6e,eDr,oDr,Zoe,rDr,tDr,aDr,C0,C6e,nDr,sDr,ere,lDr,iDr,dDr,w0,too,Ym,A0,w6e,mS,mDr,A6e,cDr,aoo,dr,cS,fDr,Km,gDr,ore,hDr,uDr,rre,pDr,_Dr,bDr,fS,vDr,L6e,FDr,TDr,MDr,Wt,gS,EDr,y6e,CDr,wDr,Zm,ADr,x6e,LDr,yDr,tre,xDr,$Dr,kDr,L0,SDr,jr,hS,RDr,$6e,PDr,BDr,yn,IDr,k6e,NDr,qDr,S6e,jDr,DDr,R6e,GDr,ODr,VDr,Be,y0,P6e,XDr,zDr,are,QDr,WDr,UDr,x0,B6e,HDr,JDr,nre,YDr,KDr,ZDr,Tl,I6e,eGr,oGr,sre,rGr,tGr,lre,aGr,nGr,sGr,$0,N6e,lGr,iGr,ire,dGr,mGr,cGr,k0,q6e,fGr,gGr,dre,hGr,uGr,pGr,S0,j6e,_Gr,bGr,mre,vGr,FGr,TGr,R0,D6e,MGr,EGr,cre,CGr,wGr,AGr,P0,G6e,LGr,yGr,fre,xGr,$Gr,kGr,B0,O6e,SGr,RGr,gre,PGr,BGr,IGr,I0,noo,ec,N0,V6e,uS,NGr,X6e,qGr,soo,mr,pS,jGr,oc,DGr,hre,GGr,OGr,ure,VGr,XGr,zGr,_S,QGr,z6e,WGr,UGr,HGr,Ut,bS,JGr,Q6e,YGr,KGr,rc,ZGr,W6e,eOr,oOr,pre,rOr,tOr,aOr,q0,nOr,Dr,vS,sOr,U6e,lOr,iOr,xn,dOr,H6e,mOr,cOr,J6e,fOr,gOr,Y6e,hOr,uOr,pOr,tc,j0,K6e,_Or,bOr,_re,vOr,FOr,TOr,D0,Z6e,MOr,EOr,bre,COr,wOr,AOr,G0,e7e,LOr,yOr,vre,xOr,$Or,kOr,O0,loo,ac,V0,o7e,FS,SOr,r7e,ROr,ioo,cr,TS,POr,nc,BOr,Fre,IOr,NOr,Tre,qOr,jOr,DOr,MS,GOr,t7e,OOr,VOr,XOr,Ht,ES,zOr,a7e,QOr,WOr,sc,UOr,n7e,HOr,JOr,Mre,YOr,KOr,ZOr,X0,eVr,Gr,CS,oVr,s7e,rVr,tVr,$n,aVr,l7e,nVr,sVr,i7e,lVr,iVr,d7e,dVr,mVr,cVr,ge,z0,m7e,fVr,gVr,Ere,hVr,uVr,pVr,Q0,c7e,_Vr,bVr,Cre,vVr,FVr,TVr,W0,f7e,MVr,EVr,wre,CVr,wVr,AVr,U0,g7e,LVr,yVr,Are,xVr,$Vr,kVr,H0,h7e,SVr,RVr,Lre,PVr,BVr,IVr,J0,u7e,NVr,qVr,yre,jVr,DVr,GVr,Y0,p7e,OVr,VVr,xre,XVr,zVr,QVr,K0,_7e,WVr,UVr,$re,HVr,JVr,YVr,Z0,b7e,KVr,ZVr,kre,eXr,oXr,rXr,ew,v7e,tXr,aXr,Sre,nXr,sXr,lXr,ow,F7e,iXr,dXr,Rre,mXr,cXr,fXr,rw,T7e,gXr,hXr,Pre,uXr,pXr,_Xr,tw,M7e,bXr,vXr,Bre,FXr,TXr,MXr,aw,E7e,EXr,CXr,Ire,wXr,AXr,LXr,nw,C7e,yXr,xXr,Nre,$Xr,kXr,SXr,sw,w7e,RXr,PXr,qre,BXr,IXr,NXr,lw,A7e,qXr,jXr,jre,DXr,GXr,OXr,iw,L7e,VXr,XXr,Dre,zXr,QXr,WXr,dw,y7e,UXr,HXr,Gre,JXr,YXr,KXr,mw,x7e,ZXr,ezr,Ore,ozr,rzr,tzr,cw,doo,lc,fw,$7e,wS,azr,k7e,nzr,moo,fr,AS,szr,ic,lzr,Vre,izr,dzr,Xre,mzr,czr,fzr,LS,gzr,S7e,hzr,uzr,pzr,Jt,yS,_zr,R7e,bzr,vzr,dc,Fzr,P7e,Tzr,Mzr,zre,Ezr,Czr,wzr,gw,Azr,Or,xS,Lzr,B7e,yzr,xzr,kn,$zr,I7e,kzr,Szr,N7e,Rzr,Pzr,q7e,Bzr,Izr,Nzr,ye,hw,j7e,qzr,jzr,Qre,Dzr,Gzr,Ozr,uw,D7e,Vzr,Xzr,Wre,zzr,Qzr,Wzr,pw,G7e,Uzr,Hzr,Ure,Jzr,Yzr,Kzr,_w,O7e,Zzr,eQr,Hre,oQr,rQr,tQr,bw,V7e,aQr,nQr,Jre,sQr,lQr,iQr,vw,X7e,dQr,mQr,Yre,cQr,fQr,gQr,Fw,z7e,hQr,uQr,Kre,pQr,_Qr,bQr,Tw,Q7e,vQr,FQr,Zre,TQr,MQr,EQr,Mw,W7e,CQr,wQr,ete,AQr,LQr,yQr,Ew,U7e,xQr,$Qr,ote,kQr,SQr,RQr,Cw,coo,mc,ww,H7e,$S,PQr,J7e,BQr,foo,gr,kS,IQr,cc,NQr,rte,qQr,jQr,tte,DQr,GQr,OQr,SS,VQr,Y7e,XQr,zQr,QQr,Yt,RS,WQr,K7e,UQr,HQr,fc,JQr,Z7e,YQr,KQr,ate,ZQr,eWr,oWr,Aw,rWr,Vr,PS,tWr,eLe,aWr,nWr,Sn,sWr,oLe,lWr,iWr,rLe,dWr,mWr,tLe,cWr,fWr,gWr,re,Lw,aLe,hWr,uWr,nte,pWr,_Wr,bWr,yw,nLe,vWr,FWr,ste,TWr,MWr,EWr,xw,sLe,CWr,wWr,lte,AWr,LWr,yWr,$w,lLe,xWr,$Wr,ite,kWr,SWr,RWr,kw,iLe,PWr,BWr,dte,IWr,NWr,qWr,Sw,dLe,jWr,DWr,mte,GWr,OWr,VWr,Rw,mLe,XWr,zWr,cte,QWr,WWr,UWr,Pw,cLe,HWr,JWr,fte,YWr,KWr,ZWr,Bw,fLe,eUr,oUr,gte,rUr,tUr,aUr,Iw,gLe,nUr,sUr,hte,lUr,iUr,dUr,Nw,hLe,mUr,cUr,ute,fUr,gUr,hUr,qw,uLe,uUr,pUr,pte,_Ur,bUr,vUr,jw,pLe,FUr,TUr,_te,MUr,EUr,CUr,Dw,_Le,wUr,AUr,bte,LUr,yUr,xUr,Gw,bLe,$Ur,kUr,vte,SUr,RUr,PUr,Ow,vLe,BUr,IUr,Fte,NUr,qUr,jUr,Vw,FLe,DUr,GUr,Tte,OUr,VUr,XUr,Xw,TLe,zUr,QUr,Mte,WUr,UUr,HUr,zw,MLe,JUr,YUr,Ete,KUr,ZUr,eHr,Qw,ELe,oHr,rHr,Cte,tHr,aHr,nHr,Ww,CLe,sHr,lHr,wte,iHr,dHr,mHr,Uw,wLe,cHr,fHr,Ate,gHr,hHr,uHr,Hw,ALe,pHr,_Hr,Lte,bHr,vHr,FHr,Jw,LLe,THr,MHr,yte,EHr,CHr,wHr,Yw,yLe,AHr,LHr,xte,yHr,xHr,$Hr,Kw,xLe,kHr,SHr,$te,RHr,PHr,BHr,Zw,$Le,IHr,NHr,kte,qHr,jHr,DHr,eA,goo,gc,oA,kLe,BS,GHr,SLe,OHr,hoo,hr,IS,VHr,hc,XHr,Ste,zHr,QHr,Rte,WHr,UHr,HHr,NS,JHr,RLe,YHr,KHr,ZHr,Kt,qS,eJr,PLe,oJr,rJr,uc,tJr,BLe,aJr,nJr,Pte,sJr,lJr,iJr,rA,dJr,Xr,jS,mJr,ILe,cJr,fJr,Rn,gJr,NLe,hJr,uJr,qLe,pJr,_Jr,jLe,bJr,vJr,FJr,ve,tA,DLe,TJr,MJr,Bte,EJr,CJr,wJr,aA,GLe,AJr,LJr,Ite,yJr,xJr,$Jr,nA,OLe,kJr,SJr,Nte,RJr,PJr,BJr,sA,VLe,IJr,NJr,qte,qJr,jJr,DJr,lA,XLe,GJr,OJr,jte,VJr,XJr,zJr,iA,zLe,QJr,WJr,Dte,UJr,HJr,JJr,dA,QLe,YJr,KJr,Gte,ZJr,eYr,oYr,mA,WLe,rYr,tYr,Ote,aYr,nYr,sYr,cA,ULe,lYr,iYr,Vte,dYr,mYr,cYr,fA,HLe,fYr,gYr,Xte,hYr,uYr,pYr,gA,JLe,_Yr,bYr,zte,vYr,FYr,TYr,hA,YLe,MYr,EYr,Qte,CYr,wYr,AYr,uA,KLe,LYr,yYr,Wte,xYr,$Yr,kYr,pA,ZLe,SYr,RYr,Ute,PYr,BYr,IYr,_A,eye,NYr,qYr,Hte,jYr,DYr,GYr,bA,oye,OYr,VYr,Jte,XYr,zYr,QYr,vA,rye,WYr,UYr,Yte,HYr,JYr,YYr,FA,uoo,pc,TA,tye,DS,KYr,aye,ZYr,poo,ur,GS,eKr,_c,oKr,Kte,rKr,tKr,Zte,aKr,nKr,sKr,OS,lKr,nye,iKr,dKr,mKr,Zt,VS,cKr,sye,fKr,gKr,bc,hKr,lye,uKr,pKr,eae,_Kr,bKr,vKr,MA,FKr,zr,XS,TKr,iye,MKr,EKr,Pn,CKr,dye,wKr,AKr,mye,LKr,yKr,cye,xKr,$Kr,kKr,zS,EA,fye,SKr,RKr,oae,PKr,BKr,IKr,CA,gye,NKr,qKr,rae,jKr,DKr,GKr,wA,_oo,vc,AA,hye,QS,OKr,uye,VKr,boo,pr,WS,XKr,Fc,zKr,tae,QKr,WKr,aae,UKr,HKr,JKr,US,YKr,pye,KKr,ZKr,eZr,ea,HS,oZr,_ye,rZr,tZr,Tc,aZr,bye,nZr,sZr,nae,lZr,iZr,dZr,LA,mZr,Qr,JS,cZr,vye,fZr,gZr,Bn,hZr,Fye,uZr,pZr,Tye,_Zr,bZr,Mye,vZr,FZr,TZr,Eye,yA,Cye,MZr,EZr,sae,CZr,wZr,AZr,xA,voo,Mc,$A,wye,YS,LZr,Aye,yZr,Foo,_r,KS,xZr,Ec,$Zr,lae,kZr,SZr,iae,RZr,PZr,BZr,ZS,IZr,Lye,NZr,qZr,jZr,oa,eR,DZr,yye,GZr,OZr,Cc,VZr,xye,XZr,zZr,dae,QZr,WZr,UZr,kA,HZr,Wr,oR,JZr,$ye,YZr,KZr,In,ZZr,kye,eet,oet,Sye,ret,tet,Rye,aet,net,set,Pye,SA,Bye,iet,det,mae,met,cet,fet,RA,Too,wc,PA,Iye,rR,get,Nye,het,Moo,br,tR,uet,Ac,pet,cae,_et,bet,fae,vet,Fet,Tet,aR,Met,qye,Eet,Cet,wet,ra,nR,Aet,jye,Let,yet,Lc,xet,Dye,$et,ket,gae,Set,Ret,Pet,BA,Bet,Ur,sR,Iet,Gye,Net,qet,Nn,jet,Oye,Det,Get,Vye,Oet,Vet,Xye,Xet,zet,Qet,de,IA,zye,Wet,Uet,hae,Het,Jet,Yet,NA,Qye,Ket,Zet,uae,eot,oot,rot,qA,Wye,tot,aot,pae,not,sot,lot,jA,Uye,iot,dot,_ae,mot,cot,fot,DA,Hye,got,hot,bae,uot,pot,_ot,GA,Jye,bot,vot,vae,Fot,Tot,Mot,OA,Yye,Eot,Cot,Fae,wot,Aot,Lot,VA,Kye,yot,xot,Tae,$ot,kot,Sot,XA,Zye,Rot,Pot,Mae,Bot,Iot,Not,zA,e8e,qot,jot,Eae,Dot,Got,Oot,QA,o8e,Vot,Xot,Cae,zot,Qot,Wot,WA,r8e,Uot,Hot,wae,Jot,Yot,Kot,UA,t8e,Zot,ert,Aae,ort,rrt,trt,HA,a8e,art,nrt,Lae,srt,lrt,irt,JA,n8e,drt,mrt,yae,crt,frt,grt,YA,s8e,hrt,urt,xae,prt,_rt,brt,KA,l8e,vrt,Frt,$ae,Trt,Mrt,Ert,ZA,i8e,Crt,wrt,kae,Art,Lrt,yrt,e6,d8e,xrt,$rt,Sae,krt,Srt,Rrt,o6,m8e,Prt,Brt,Rae,Irt,Nrt,qrt,r6,c8e,jrt,Drt,Pae,Grt,Ort,Vrt,t6,Eoo,yc,a6,f8e,lR,Xrt,g8e,zrt,Coo,vr,iR,Qrt,xc,Wrt,Bae,Urt,Hrt,Iae,Jrt,Yrt,Krt,dR,Zrt,h8e,ett,ott,rtt,ta,mR,ttt,u8e,att,ntt,$c,stt,p8e,ltt,itt,Nae,dtt,mtt,ctt,n6,ftt,Hr,cR,gtt,_8e,htt,utt,qn,ptt,b8e,_tt,btt,v8e,vtt,Ftt,F8e,Ttt,Mtt,Ett,me,s6,T8e,Ctt,wtt,qae,Att,Ltt,ytt,l6,M8e,xtt,$tt,jae,ktt,Stt,Rtt,i6,E8e,Ptt,Btt,Dae,Itt,Ntt,qtt,d6,C8e,jtt,Dtt,Gae,Gtt,Ott,Vtt,m6,w8e,Xtt,ztt,Oae,Qtt,Wtt,Utt,c6,A8e,Htt,Jtt,Vae,Ytt,Ktt,Ztt,f6,L8e,eat,oat,Xae,rat,tat,aat,g6,y8e,nat,sat,zae,lat,iat,dat,h6,x8e,mat,cat,Qae,fat,gat,hat,u6,$8e,uat,pat,Wae,_at,bat,vat,p6,k8e,Fat,Tat,Uae,Mat,Eat,Cat,_6,S8e,wat,Aat,Hae,Lat,yat,xat,b6,R8e,$at,kat,Jae,Sat,Rat,Pat,v6,P8e,Bat,Iat,Yae,Nat,qat,jat,F6,B8e,Dat,Gat,Kae,Oat,Vat,Xat,T6,I8e,zat,Qat,Zae,Wat,Uat,Hat,M6,N8e,Jat,Yat,ene,Kat,Zat,ent,E6,q8e,ont,rnt,one,tnt,ant,nnt,C6,j8e,snt,lnt,rne,int,dnt,mnt,w6,D8e,cnt,fnt,tne,gnt,hnt,unt,A6,G8e,pnt,_nt,ane,bnt,vnt,Fnt,L6,woo,kc,y6,O8e,fR,Tnt,V8e,Mnt,Aoo,Fr,gR,Ent,Sc,Cnt,nne,wnt,Ant,sne,Lnt,ynt,xnt,hR,$nt,X8e,knt,Snt,Rnt,aa,uR,Pnt,z8e,Bnt,Int,Rc,Nnt,Q8e,qnt,jnt,lne,Dnt,Gnt,Ont,x6,Vnt,Jr,pR,Xnt,W8e,znt,Qnt,jn,Wnt,U8e,Unt,Hnt,H8e,Jnt,Ynt,J8e,Knt,Znt,est,Y8e,$6,K8e,ost,rst,ine,tst,ast,nst,k6,Loo,Pc,S6,Z8e,_R,sst,e9e,lst,yoo,Tr,bR,ist,Bc,dst,dne,mst,cst,mne,fst,gst,hst,vR,ust,o9e,pst,_st,bst,na,FR,vst,r9e,Fst,Tst,Ic,Mst,t9e,Est,Cst,cne,wst,Ast,Lst,R6,yst,Yr,TR,xst,a9e,$st,kst,Dn,Sst,n9e,Rst,Pst,s9e,Bst,Ist,l9e,Nst,qst,jst,i9e,P6,d9e,Dst,Gst,fne,Ost,Vst,Xst,B6,xoo,Nc,I6,m9e,MR,zst,c9e,Qst,$oo,Mr,ER,Wst,qc,Ust,gne,Hst,Jst,hne,Yst,Kst,Zst,CR,elt,f9e,olt,rlt,tlt,sa,wR,alt,g9e,nlt,slt,jc,llt,h9e,ilt,dlt,une,mlt,clt,flt,N6,glt,Kr,AR,hlt,u9e,ult,plt,Gn,_lt,p9e,blt,vlt,_9e,Flt,Tlt,b9e,Mlt,Elt,Clt,te,q6,v9e,wlt,Alt,pne,Llt,ylt,xlt,j6,F9e,$lt,klt,_ne,Slt,Rlt,Plt,D6,T9e,Blt,Ilt,bne,Nlt,qlt,jlt,G6,M9e,Dlt,Glt,vne,Olt,Vlt,Xlt,O6,E9e,zlt,Qlt,Fne,Wlt,Ult,Hlt,V6,C9e,Jlt,Ylt,Tne,Klt,Zlt,eit,X6,w9e,oit,rit,Mne,tit,ait,nit,z6,A9e,sit,lit,Ene,iit,dit,mit,Q6,L9e,cit,fit,Cne,git,hit,uit,W6,y9e,pit,_it,wne,bit,vit,Fit,U6,x9e,Tit,Mit,Ane,Eit,Cit,wit,H6,$9e,Ait,Lit,Lne,yit,xit,$it,J6,k9e,kit,Sit,yne,Rit,Pit,Bit,Y6,S9e,Iit,Nit,xne,qit,jit,Dit,K6,R9e,Git,Oit,$ne,Vit,Xit,zit,Z6,P9e,Qit,Wit,kne,Uit,Hit,Jit,e7,B9e,Yit,Kit,Sne,Zit,edt,odt,o7,I9e,rdt,tdt,Rne,adt,ndt,sdt,r7,N9e,ldt,idt,Pne,ddt,mdt,cdt,t7,q9e,fdt,gdt,Bne,hdt,udt,pdt,a7,j9e,_dt,bdt,Ine,vdt,Fdt,Tdt,n7,D9e,Mdt,Edt,Nne,Cdt,wdt,Adt,s7,G9e,Ldt,ydt,qne,xdt,$dt,kdt,l7,O9e,Sdt,Rdt,jne,Pdt,Bdt,Idt,i7,V9e,Ndt,qdt,Dne,jdt,Ddt,Gdt,d7,X9e,Odt,Vdt,Gne,Xdt,zdt,Qdt,m7,z9e,Wdt,Udt,One,Hdt,Jdt,Ydt,c7,koo,Dc,f7,Q9e,LR,Kdt,W9e,Zdt,Soo,Er,yR,emt,Gc,omt,Vne,rmt,tmt,Xne,amt,nmt,smt,xR,lmt,U9e,imt,dmt,mmt,la,$R,cmt,H9e,fmt,gmt,Oc,hmt,J9e,umt,pmt,zne,_mt,bmt,vmt,g7,Fmt,Zr,kR,Tmt,Y9e,Mmt,Emt,On,Cmt,K9e,wmt,Amt,Z9e,Lmt,ymt,exe,xmt,$mt,kmt,xe,h7,oxe,Smt,Rmt,Qne,Pmt,Bmt,Imt,u7,rxe,Nmt,qmt,Wne,jmt,Dmt,Gmt,p7,txe,Omt,Vmt,Une,Xmt,zmt,Qmt,_7,axe,Wmt,Umt,Hne,Hmt,Jmt,Ymt,b7,nxe,Kmt,Zmt,Jne,ect,oct,rct,v7,sxe,tct,act,Yne,nct,sct,lct,F7,lxe,ict,dct,Kne,mct,cct,fct,T7,ixe,gct,hct,Zne,uct,pct,_ct,M7,dxe,bct,vct,ese,Fct,Tct,Mct,E7,mxe,Ect,Cct,ose,wct,Act,Lct,C7,Roo,Vc,w7,cxe,SR,yct,fxe,xct,Poo,Cr,RR,$ct,Xc,kct,rse,Sct,Rct,tse,Pct,Bct,Ict,PR,Nct,gxe,qct,jct,Dct,ia,BR,Gct,hxe,Oct,Vct,zc,Xct,uxe,zct,Qct,ase,Wct,Uct,Hct,A7,Jct,et,IR,Yct,pxe,Kct,Zct,Vn,eft,_xe,oft,rft,bxe,tft,aft,vxe,nft,sft,lft,Ee,L7,Fxe,ift,dft,nse,mft,cft,fft,y7,Txe,gft,hft,sse,uft,pft,_ft,x7,Mxe,bft,vft,lse,Fft,Tft,Mft,$7,Exe,Eft,Cft,ise,wft,Aft,Lft,k7,Cxe,yft,xft,dse,$ft,kft,Sft,S7,wxe,Rft,Pft,mse,Bft,Ift,Nft,R7,Axe,qft,jft,cse,Dft,Gft,Oft,P7,Lxe,Vft,Xft,fse,zft,Qft,Wft,B7,yxe,Uft,Hft,gse,Jft,Yft,Kft,I7,xxe,Zft,egt,hse,ogt,rgt,tgt,N7,$xe,agt,ngt,use,sgt,lgt,igt,q7,kxe,dgt,mgt,pse,cgt,fgt,ggt,j7,Sxe,hgt,ugt,_se,pgt,_gt,bgt,D7,Boo,Qc,G7,Rxe,NR,vgt,Pxe,Fgt,Ioo,wr,qR,Tgt,Wc,Mgt,bse,Egt,Cgt,vse,wgt,Agt,Lgt,jR,ygt,Bxe,xgt,$gt,kgt,da,DR,Sgt,Ixe,Rgt,Pgt,Uc,Bgt,Nxe,Igt,Ngt,Fse,qgt,jgt,Dgt,O7,Ggt,ot,GR,Ogt,qxe,Vgt,Xgt,Xn,zgt,jxe,Qgt,Wgt,Dxe,Ugt,Hgt,Gxe,Jgt,Ygt,Kgt,$e,V7,Oxe,Zgt,eht,Tse,oht,rht,tht,X7,Vxe,aht,nht,Mse,sht,lht,iht,z7,Xxe,dht,mht,Ese,cht,fht,ght,Q7,zxe,hht,uht,Cse,pht,_ht,bht,W7,Qxe,vht,Fht,wse,Tht,Mht,Eht,U7,Wxe,Cht,wht,Ase,Aht,Lht,yht,H7,Uxe,xht,$ht,Lse,kht,Sht,Rht,J7,Hxe,Pht,Bht,yse,Iht,Nht,qht,Y7,Jxe,jht,Dht,xse,Ght,Oht,Vht,K7,Yxe,Xht,zht,$se,Qht,Wht,Uht,Z7,Noo,Hc,eL,Kxe,OR,Hht,Zxe,Jht,qoo,Ar,VR,Yht,Jc,Kht,kse,Zht,eut,Sse,out,rut,tut,XR,aut,e$e,nut,sut,lut,ma,zR,iut,o$e,dut,mut,Yc,cut,r$e,fut,gut,Rse,hut,uut,put,oL,_ut,rt,QR,but,t$e,vut,Fut,zn,Tut,a$e,Mut,Eut,n$e,Cut,wut,s$e,Aut,Lut,yut,ke,rL,l$e,xut,$ut,Pse,kut,Sut,Rut,tL,i$e,Put,But,Bse,Iut,Nut,qut,aL,d$e,jut,Dut,Ise,Gut,Out,Vut,nL,m$e,Xut,zut,Nse,Qut,Wut,Uut,sL,c$e,Hut,Jut,qse,Yut,Kut,Zut,lL,f$e,ept,opt,jse,rpt,tpt,apt,iL,g$e,npt,spt,Dse,lpt,ipt,dpt,dL,h$e,mpt,cpt,Gse,fpt,gpt,hpt,mL,u$e,upt,ppt,Ose,_pt,bpt,vpt,cL,p$e,Fpt,Tpt,Vse,Mpt,Ept,Cpt,fL,joo,Kc,gL,_$e,WR,wpt,b$e,Apt,Doo,Lr,UR,Lpt,Zc,ypt,Xse,xpt,$pt,zse,kpt,Spt,Rpt,HR,Ppt,v$e,Bpt,Ipt,Npt,ca,JR,qpt,F$e,jpt,Dpt,ef,Gpt,T$e,Opt,Vpt,Qse,Xpt,zpt,Qpt,hL,Wpt,tt,YR,Upt,M$e,Hpt,Jpt,Qn,Ypt,E$e,Kpt,Zpt,C$e,e_t,o_t,w$e,r_t,t_t,a_t,Se,uL,A$e,n_t,s_t,Wse,l_t,i_t,d_t,pL,L$e,m_t,c_t,Use,f_t,g_t,h_t,_L,y$e,u_t,p_t,Hse,__t,b_t,v_t,bL,x$e,F_t,T_t,Jse,M_t,E_t,C_t,vL,$$e,w_t,A_t,Yse,L_t,y_t,x_t,FL,k$e,$_t,k_t,Kse,S_t,R_t,P_t,TL,S$e,B_t,I_t,Zse,N_t,q_t,j_t,ML,R$e,D_t,G_t,ele,O_t,V_t,X_t,EL,P$e,z_t,Q_t,ole,W_t,U_t,H_t,CL,B$e,J_t,Y_t,rle,K_t,Z_t,e2t,wL,Goo,of,AL,I$e,KR,o2t,N$e,r2t,Ooo,yr,ZR,t2t,rf,a2t,tle,n2t,s2t,ale,l2t,i2t,d2t,eP,m2t,q$e,c2t,f2t,g2t,fa,oP,h2t,j$e,u2t,p2t,tf,_2t,D$e,b2t,v2t,nle,F2t,T2t,M2t,LL,E2t,at,rP,C2t,G$e,w2t,A2t,Wn,L2t,O$e,y2t,x2t,V$e,$2t,k2t,X$e,S2t,R2t,P2t,Re,yL,z$e,B2t,I2t,sle,N2t,q2t,j2t,xL,Q$e,D2t,G2t,lle,O2t,V2t,X2t,$L,W$e,z2t,Q2t,ile,W2t,U2t,H2t,kL,U$e,J2t,Y2t,dle,K2t,Z2t,e1t,SL,H$e,o1t,r1t,mle,t1t,a1t,n1t,RL,J$e,s1t,l1t,cle,i1t,d1t,m1t,PL,Y$e,c1t,f1t,fle,g1t,h1t,u1t,BL,K$e,p1t,_1t,gle,b1t,v1t,F1t,IL,Z$e,T1t,M1t,hle,E1t,C1t,w1t,NL,eke,A1t,L1t,ule,y1t,x1t,$1t,qL,Voo,af,jL,oke,tP,k1t,rke,S1t,Xoo,xr,aP,R1t,nf,P1t,ple,B1t,I1t,_le,N1t,q1t,j1t,nP,D1t,tke,G1t,O1t,V1t,ga,sP,X1t,ake,z1t,Q1t,sf,W1t,nke,U1t,H1t,ble,J1t,Y1t,K1t,DL,Z1t,nt,lP,ebt,ske,obt,rbt,Un,tbt,lke,abt,nbt,ike,sbt,lbt,dke,ibt,dbt,mbt,Xe,GL,mke,cbt,fbt,vle,gbt,hbt,ubt,OL,cke,pbt,_bt,Fle,bbt,vbt,Fbt,VL,fke,Tbt,Mbt,Tle,Ebt,Cbt,wbt,XL,gke,Abt,Lbt,Mle,ybt,xbt,$bt,zL,hke,kbt,Sbt,Ele,Rbt,Pbt,Bbt,QL,uke,Ibt,Nbt,Cle,qbt,jbt,Dbt,WL,pke,Gbt,Obt,wle,Vbt,Xbt,zbt,UL,_ke,Qbt,Wbt,Ale,Ubt,Hbt,Jbt,HL,zoo,lf,JL,bke,iP,Ybt,vke,Kbt,Qoo,$r,dP,Zbt,df,evt,Lle,ovt,rvt,yle,tvt,avt,nvt,mP,svt,Fke,lvt,ivt,dvt,ha,cP,mvt,Tke,cvt,fvt,mf,gvt,Mke,hvt,uvt,xle,pvt,_vt,bvt,YL,vvt,st,fP,Fvt,Eke,Tvt,Mvt,Hn,Evt,Cke,Cvt,wvt,wke,Avt,Lvt,Ake,yvt,xvt,$vt,ze,KL,Lke,kvt,Svt,$le,Rvt,Pvt,Bvt,ZL,yke,Ivt,Nvt,kle,qvt,jvt,Dvt,ey,xke,Gvt,Ovt,Sle,Vvt,Xvt,zvt,oy,$ke,Qvt,Wvt,Rle,Uvt,Hvt,Jvt,ry,kke,Yvt,Kvt,Ple,Zvt,eFt,oFt,ty,Ske,rFt,tFt,Ble,aFt,nFt,sFt,ay,Rke,lFt,iFt,Ile,dFt,mFt,cFt,ny,Pke,fFt,gFt,Nle,hFt,uFt,pFt,sy,Woo,cf,ly,Bke,gP,_Ft,Ike,bFt,Uoo,kr,hP,vFt,ff,FFt,qle,TFt,MFt,jle,EFt,CFt,wFt,uP,AFt,Nke,LFt,yFt,xFt,ua,pP,$Ft,qke,kFt,SFt,gf,RFt,jke,PFt,BFt,Dle,IFt,NFt,qFt,iy,jFt,lt,_P,DFt,Dke,GFt,OFt,Jn,VFt,Gke,XFt,zFt,Oke,QFt,WFt,Vke,UFt,HFt,JFt,Xke,dy,zke,YFt,KFt,Gle,ZFt,eTt,oTt,my,Hoo,hf,cy,Qke,bP,rTt,Wke,tTt,Joo,Sr,vP,aTt,uf,nTt,Ole,sTt,lTt,Vle,iTt,dTt,mTt,FP,cTt,Uke,fTt,gTt,hTt,pa,TP,uTt,Hke,pTt,_Tt,pf,bTt,Jke,vTt,FTt,Xle,TTt,MTt,ETt,fy,CTt,it,MP,wTt,Yke,ATt,LTt,Yn,yTt,Kke,xTt,$Tt,Zke,kTt,STt,eSe,RTt,PTt,BTt,EP,gy,oSe,ITt,NTt,zle,qTt,jTt,DTt,hy,rSe,GTt,OTt,Qle,VTt,XTt,zTt,uy,Yoo,_f,py,tSe,CP,QTt,aSe,WTt,Koo,Rr,wP,UTt,bf,HTt,Wle,JTt,YTt,Ule,KTt,ZTt,eMt,AP,oMt,nSe,rMt,tMt,aMt,_a,LP,nMt,sSe,sMt,lMt,vf,iMt,lSe,dMt,mMt,Hle,cMt,fMt,gMt,_y,hMt,dt,yP,uMt,iSe,pMt,_Mt,Kn,bMt,dSe,vMt,FMt,mSe,TMt,MMt,cSe,EMt,CMt,wMt,fSe,by,gSe,AMt,LMt,Jle,yMt,xMt,$Mt,vy,Zoo;return d=new oe({}),Qa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),ex=new oe({}),ox=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),yf=new kMt({props:{warning:!0,$$slots:{default:[I2a]},$$scope:{ctx:$}}}),rx=new oe({}),tx=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L656"}}),sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L679"}}),eu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[N2a]},$$scope:{ctx:$}}}),lx=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L802"}}),ix=new oe({}),dx=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L427"}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L441"}}),Nu=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[q2a]},$$scope:{ctx:$}}}),gx=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L642"}}),hx=new oe({}),ux=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L202"}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L216"}}),yp=new kMt({props:{$$slots:{default:[j2a]},$$scope:{ctx:$}}}),xp=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[D2a]},$$scope:{ctx:$}}}),vx=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L343"}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L95"}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L109"}}),e_=new kMt({props:{$$slots:{default:[G2a]},$$scope:{ctx:$}}}),o_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[O2a]},$$scope:{ctx:$}}}),wx=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L276"}}),Ax=new oe({}),Lx=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L859"}}),xx=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[V2a]},$$scope:{ctx:$}}}),$x=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E1=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[X2a]},$$scope:{ctx:$}}}),kx=new oe({}),Sx=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L866"}}),Px=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w1=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[z2a]},$$scope:{ctx:$}}}),Bx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Tb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Q2a]},$$scope:{ctx:$}}}),Ix=new oe({}),Nx=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L881"}}),jx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Eb=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[W2a]},$$scope:{ctx:$}}}),Dx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[U2a]},$$scope:{ctx:$}}}),Gx=new oe({}),Ox=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L888"}}),Xx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uv=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[H2a]},$$scope:{ctx:$}}}),zx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),rF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[J2a]},$$scope:{ctx:$}}}),Qx=new oe({}),Wx=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L895"}}),Hx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),aF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Y2a]},$$scope:{ctx:$}}}),Jx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[K2a]},$$scope:{ctx:$}}}),Yx=new oe({}),Kx=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L904"}}),e$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yF=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Z2a]},$$scope:{ctx:$}}}),o$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),kT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[e1a]},$$scope:{ctx:$}}}),r$=new oe({}),t$=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L960"}}),n$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),RT=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[o1a]},$$scope:{ctx:$}}}),s$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[r1a]},$$scope:{ctx:$}}}),l$=new oe({}),i$=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L967"}}),m$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uM=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[t1a]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),CM=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[a1a]},$$scope:{ctx:$}}}),f$=new oe({}),g$=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L953"}}),u$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),AM=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[n1a]},$$scope:{ctx:$}}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[s1a]},$$scope:{ctx:$}}}),_$=new oe({}),b$=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L913"}}),F$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pE=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[l1a]},$$scope:{ctx:$}}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),d4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[i1a]},$$scope:{ctx:$}}}),M$=new oe({}),E$=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L920"}}),w$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),c4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[d1a]},$$scope:{ctx:$}}}),A$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),h4=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[m1a]},$$scope:{ctx:$}}}),L$=new oe({}),y$=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L942"}}),$$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),p4=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[c1a]},$$scope:{ctx:$}}}),k$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T4=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[f1a]},$$scope:{ctx:$}}}),S$=new oe({}),R$=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L976"}}),B$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E4=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[g1a]},$$scope:{ctx:$}}}),I$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D4=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[h1a]},$$scope:{ctx:$}}}),N$=new oe({}),q$=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1015"}}),D$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O4=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[u1a]},$$scope:{ctx:$}}}),G$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z4=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[p1a]},$$scope:{ctx:$}}}),O$=new oe({}),V$=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1022"}}),z$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W4=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[_1a]},$$scope:{ctx:$}}}),Q$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J4=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[b1a]},$$scope:{ctx:$}}}),W$=new oe({}),U$=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L931"}}),J$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),K4=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[v1a]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),oC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[F1a]},$$scope:{ctx:$}}}),K$=new oe({}),Z$=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1029"}}),ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),tC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[T1a]},$$scope:{ctx:$}}}),rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[M1a]},$$scope:{ctx:$}}}),tk=new oe({}),ak=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1052"}}),sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[E1a]},$$scope:{ctx:$}}}),lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),EC=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[C1a]},$$scope:{ctx:$}}}),ik=new oe({}),dk=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1036"}}),ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),wC=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[w1a]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),NC=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[A1a]},$$scope:{ctx:$}}}),gk=new oe({}),hk=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1043"}}),pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jC=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[L1a]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VC=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[y1a]},$$scope:{ctx:$}}}),vk=new oe({}),Fk=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1061"}}),Mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zC=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[x1a]},$$scope:{ctx:$}}}),Ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KC=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[$1a]},$$scope:{ctx:$}}}),Ck=new oe({}),wk=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1068"}}),Lk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[k1a]},$$scope:{ctx:$}}}),yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[S1a]},$$scope:{ctx:$}}}),xk=new oe({}),$k=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1008"}}),Sk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[R1a]},$$scope:{ctx:$}}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),h3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[P1a]},$$scope:{ctx:$}}}),Pk=new oe({}),Bk=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L983"}}),Nk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),p3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[B1a]},$$scope:{ctx:$}}}),qk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v3=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[I1a]},$$scope:{ctx:$}}}),jk=new oe({}),Dk=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L990"}}),Ok=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[N1a]},$$scope:{ctx:$}}}),Vk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y3=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[q1a]},$$scope:{ctx:$}}}),Xk=new oe({}),zk=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L999"}}),Wk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[j1a]},$$scope:{ctx:$}}}),Uk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R3=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[D1a]},$$scope:{ctx:$}}}),Hk=new oe({}),Jk=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L434"}}),Kk=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B3=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[G1a]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I5=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[O1a]},$$scope:{ctx:$}}}),eS=new oe({}),oS=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),tS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q5=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[V1a]},$$scope:{ctx:$}}}),aS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[X1a]},$$scope:{ctx:$}}}),nS=new oe({}),sS=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),iS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m0=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[z1a]},$$scope:{ctx:$}}}),dS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w0=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Q1a]},$$scope:{ctx:$}}}),mS=new oe({}),cS=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),gS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),L0=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[W1a]},$$scope:{ctx:$}}}),hS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I0=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[U1a]},$$scope:{ctx:$}}}),uS=new oe({}),pS=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),bS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q0=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[H1a]},$$scope:{ctx:$}}}),vS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),O0=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[J1a]},$$scope:{ctx:$}}}),FS=new oe({}),TS=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L497"}}),ES=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),X0=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Y1a]},$$scope:{ctx:$}}}),CS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),cw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[K1a]},$$scope:{ctx:$}}}),wS=new oe({}),AS=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),yS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),gw=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Z1a]},$$scope:{ctx:$}}}),xS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[eba]},$$scope:{ctx:$}}}),$S=new oe({}),kS=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L513"}}),RS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[oba]},$$scope:{ctx:$}}}),PS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),eA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[rba]},$$scope:{ctx:$}}}),BS=new oe({}),IS=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L560"}}),qS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[tba]},$$scope:{ctx:$}}}),jS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FA=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[aba]},$$scope:{ctx:$}}}),DS=new oe({}),GS=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L567"}}),VS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),MA=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[nba]},$$scope:{ctx:$}}}),XS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wA=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[sba]},$$scope:{ctx:$}}}),QS=new oe({}),WS=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L540"}}),HS=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LA=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[lba]},$$scope:{ctx:$}}}),JS=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xA=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[iba]},$$scope:{ctx:$}}}),YS=new oe({}),KS=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L529"}}),eR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kA=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[dba]},$$scope:{ctx:$}}}),oR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),RA=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[mba]},$$scope:{ctx:$}}}),rR=new oe({}),tR=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L551"}}),nR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),BA=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[cba]},$$scope:{ctx:$}}}),sR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[fba]},$$scope:{ctx:$}}}),lR=new oe({}),iR=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),mR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n6=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[gba]},$$scope:{ctx:$}}}),cR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[hba]},$$scope:{ctx:$}}}),fR=new oe({}),gR=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L490"}}),uR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[uba]},$$scope:{ctx:$}}}),pR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k6=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[pba]},$$scope:{ctx:$}}}),_R=new oe({}),bR=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L576"}}),FR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R6=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[_ba]},$$scope:{ctx:$}}}),TR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[bba]},$$scope:{ctx:$}}}),MR=new oe({}),ER=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),wR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[vba]},$$scope:{ctx:$}}}),AR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c7=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Fba]},$$scope:{ctx:$}}}),LR=new oe({}),yR=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),$R=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g7=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Tba]},$$scope:{ctx:$}}}),kR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C7=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Mba]},$$scope:{ctx:$}}}),SR=new oe({}),RR=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),BR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A7=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Eba]},$$scope:{ctx:$}}}),IR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D7=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Cba]},$$scope:{ctx:$}}}),NR=new oe({}),qR=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),DR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O7=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[wba]},$$scope:{ctx:$}}}),GR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z7=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Aba]},$$scope:{ctx:$}}}),OR=new oe({}),VR=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),zR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Lba]},$$scope:{ctx:$}}}),QR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[yba]},$$scope:{ctx:$}}}),WR=new oe({}),UR=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),JR=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[xba]},$$scope:{ctx:$}}}),YR=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[$ba]},$$scope:{ctx:$}}}),KR=new oe({}),ZR=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),oP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[kba]},$$scope:{ctx:$}}}),rP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Sba]},$$scope:{ctx:$}}}),tP=new oe({}),aP=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),sP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),DL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Rba]},$$scope:{ctx:$}}}),lP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Pba]},$$scope:{ctx:$}}}),iP=new oe({}),dP=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),cP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YL=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Bba]},$$scope:{ctx:$}}}),fP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Iba]},$$scope:{ctx:$}}}),gP=new oe({}),hP=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),pP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),iy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Nba]},$$scope:{ctx:$}}}),_P=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),my=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[qba]},$$scope:{ctx:$}}}),bP=new oe({}),vP=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),TP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[jba]},$$scope:{ctx:$}}}),MP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Dba]},$$scope:{ctx:$}}}),CP=new oe({}),wP=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),LP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_y=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Gba]},$$scope:{ctx:$}}}),yP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vy=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Oba]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),yo=a("span"),td=o("Auto Classes"),Ef=l(),pt=a("p"),ad=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),nd=a("code"),J9=o("from_pretrained()"),Cf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ve=l(),He=a("p"),sd=o("Instantiating one of "),es=a("a"),Y9=o("AutoConfig"),os=o(", "),rs=a("a"),K9=o("AutoModel"),ld=o(`, and
`),ts=a("a"),Z9=o("AutoTokenizer"),id=o(" will directly create a class of the relevant architecture. For instance"),wf=l(),F(Qa.$$.fragment),Je=l(),Ae=a("p"),eI=o("will create a model that is an instance of "),dd=a("a"),oI=o("BertModel"),rI=o("."),xo=l(),Wa=a("p"),tI=o("There is one class of "),Af=a("code"),aI=o("AutoModel"),pao=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),DZe=l(),md=a("h2"),Lf=a("a"),eme=a("span"),F(ex.$$.fragment),_ao=l(),ome=a("span"),bao=o("Extending the Auto Classes"),GZe=l(),as=a("p"),vao=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),rme=a("code"),Fao=o("NewModel"),Tao=o(", make sure you have a "),tme=a("code"),Mao=o("NewModelConfig"),Eao=o(` then you can add those to the auto
classes like this:`),OZe=l(),F(ox.$$.fragment),VZe=l(),nI=a("p"),Cao=o("You will then be able to use the auto classes like you would usually do!"),XZe=l(),F(yf.$$.fragment),zZe=l(),cd=a("h2"),xf=a("a"),ame=a("span"),F(rx.$$.fragment),wao=l(),nme=a("span"),Aao=o("AutoConfig"),QZe=l(),$o=a("div"),F(tx.$$.fragment),Lao=l(),ax=a("p"),yao=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),sI=a("a"),xao=o("from_pretrained()"),$ao=o(" class method."),kao=l(),nx=a("p"),Sao=o("This class cannot be instantiated directly using "),sme=a("code"),Rao=o("__init__()"),Pao=o(" (throws an error)."),Bao=l(),Pr=a("div"),F(sx.$$.fragment),Iao=l(),lme=a("p"),Nao=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),qao=l(),fd=a("p"),jao=o("The configuration class to instantiate is selected based on the "),ime=a("code"),Dao=o("model_type"),Gao=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),dme=a("code"),Oao=o("pretrained_model_name_or_path"),Vao=o(":"),Xao=l(),A=a("ul"),$f=a("li"),mme=a("strong"),zao=o("albert"),Qao=o(" \u2014 "),lI=a("a"),Wao=o("AlbertConfig"),Uao=o(" (ALBERT model)"),Hao=l(),kf=a("li"),cme=a("strong"),Jao=o("bart"),Yao=o(" \u2014 "),iI=a("a"),Kao=o("BartConfig"),Zao=o(" (BART model)"),eno=l(),Sf=a("li"),fme=a("strong"),ono=o("beit"),rno=o(" \u2014 "),dI=a("a"),tno=o("BeitConfig"),ano=o(" (BEiT model)"),nno=l(),Rf=a("li"),gme=a("strong"),sno=o("bert"),lno=o(" \u2014 "),mI=a("a"),ino=o("BertConfig"),dno=o(" (BERT model)"),mno=l(),Pf=a("li"),hme=a("strong"),cno=o("bert-generation"),fno=o(" \u2014 "),cI=a("a"),gno=o("BertGenerationConfig"),hno=o(" (Bert Generation model)"),uno=l(),Bf=a("li"),ume=a("strong"),pno=o("big_bird"),_no=o(" \u2014 "),fI=a("a"),bno=o("BigBirdConfig"),vno=o(" (BigBird model)"),Fno=l(),If=a("li"),pme=a("strong"),Tno=o("bigbird_pegasus"),Mno=o(" \u2014 "),gI=a("a"),Eno=o("BigBirdPegasusConfig"),Cno=o(" (BigBird-Pegasus model)"),wno=l(),Nf=a("li"),_me=a("strong"),Ano=o("blenderbot"),Lno=o(" \u2014 "),hI=a("a"),yno=o("BlenderbotConfig"),xno=o(" (Blenderbot model)"),$no=l(),qf=a("li"),bme=a("strong"),kno=o("blenderbot-small"),Sno=o(" \u2014 "),uI=a("a"),Rno=o("BlenderbotSmallConfig"),Pno=o(" (BlenderbotSmall model)"),Bno=l(),jf=a("li"),vme=a("strong"),Ino=o("bloom"),Nno=o(" \u2014 "),pI=a("a"),qno=o("BloomConfig"),jno=o(" (BLOOM model)"),Dno=l(),Df=a("li"),Fme=a("strong"),Gno=o("camembert"),Ono=o(" \u2014 "),_I=a("a"),Vno=o("CamembertConfig"),Xno=o(" (CamemBERT model)"),zno=l(),Gf=a("li"),Tme=a("strong"),Qno=o("canine"),Wno=o(" \u2014 "),bI=a("a"),Uno=o("CanineConfig"),Hno=o(" (CANINE model)"),Jno=l(),Of=a("li"),Mme=a("strong"),Yno=o("clip"),Kno=o(" \u2014 "),vI=a("a"),Zno=o("CLIPConfig"),eso=o(" (CLIP model)"),oso=l(),Vf=a("li"),Eme=a("strong"),rso=o("codegen"),tso=o(" \u2014 "),FI=a("a"),aso=o("CodeGenConfig"),nso=o(" (CodeGen model)"),sso=l(),Xf=a("li"),Cme=a("strong"),lso=o("conditional_detr"),iso=o(" \u2014 "),TI=a("a"),dso=o("ConditionalDetrConfig"),mso=o(" (Conditional DETR model)"),cso=l(),zf=a("li"),wme=a("strong"),fso=o("convbert"),gso=o(" \u2014 "),MI=a("a"),hso=o("ConvBertConfig"),uso=o(" (ConvBERT model)"),pso=l(),Qf=a("li"),Ame=a("strong"),_so=o("convnext"),bso=o(" \u2014 "),EI=a("a"),vso=o("ConvNextConfig"),Fso=o(" (ConvNeXT model)"),Tso=l(),Wf=a("li"),Lme=a("strong"),Mso=o("ctrl"),Eso=o(" \u2014 "),CI=a("a"),Cso=o("CTRLConfig"),wso=o(" (CTRL model)"),Aso=l(),Uf=a("li"),yme=a("strong"),Lso=o("cvt"),yso=o(" \u2014 "),wI=a("a"),xso=o("CvtConfig"),$so=o(" (CvT model)"),kso=l(),Hf=a("li"),xme=a("strong"),Sso=o("data2vec-audio"),Rso=o(" \u2014 "),AI=a("a"),Pso=o("Data2VecAudioConfig"),Bso=o(" (Data2VecAudio model)"),Iso=l(),Jf=a("li"),$me=a("strong"),Nso=o("data2vec-text"),qso=o(" \u2014 "),LI=a("a"),jso=o("Data2VecTextConfig"),Dso=o(" (Data2VecText model)"),Gso=l(),Yf=a("li"),kme=a("strong"),Oso=o("data2vec-vision"),Vso=o(" \u2014 "),yI=a("a"),Xso=o("Data2VecVisionConfig"),zso=o(" (Data2VecVision model)"),Qso=l(),Kf=a("li"),Sme=a("strong"),Wso=o("deberta"),Uso=o(" \u2014 "),xI=a("a"),Hso=o("DebertaConfig"),Jso=o(" (DeBERTa model)"),Yso=l(),Zf=a("li"),Rme=a("strong"),Kso=o("deberta-v2"),Zso=o(" \u2014 "),$I=a("a"),elo=o("DebertaV2Config"),olo=o(" (DeBERTa-v2 model)"),rlo=l(),eg=a("li"),Pme=a("strong"),tlo=o("decision_transformer"),alo=o(" \u2014 "),kI=a("a"),nlo=o("DecisionTransformerConfig"),slo=o(" (Decision Transformer model)"),llo=l(),og=a("li"),Bme=a("strong"),ilo=o("deformable_detr"),dlo=o(" \u2014 "),SI=a("a"),mlo=o("DeformableDetrConfig"),clo=o(" (Deformable DETR model)"),flo=l(),rg=a("li"),Ime=a("strong"),glo=o("deit"),hlo=o(" \u2014 "),RI=a("a"),ulo=o("DeiTConfig"),plo=o(" (DeiT model)"),_lo=l(),tg=a("li"),Nme=a("strong"),blo=o("detr"),vlo=o(" \u2014 "),PI=a("a"),Flo=o("DetrConfig"),Tlo=o(" (DETR model)"),Mlo=l(),ag=a("li"),qme=a("strong"),Elo=o("distilbert"),Clo=o(" \u2014 "),BI=a("a"),wlo=o("DistilBertConfig"),Alo=o(" (DistilBERT model)"),Llo=l(),ng=a("li"),jme=a("strong"),ylo=o("donut-swin"),xlo=o(" \u2014 "),II=a("a"),$lo=o("DonutSwinConfig"),klo=o(" (DonutSwin model)"),Slo=l(),sg=a("li"),Dme=a("strong"),Rlo=o("dpr"),Plo=o(" \u2014 "),NI=a("a"),Blo=o("DPRConfig"),Ilo=o(" (DPR model)"),Nlo=l(),lg=a("li"),Gme=a("strong"),qlo=o("dpt"),jlo=o(" \u2014 "),qI=a("a"),Dlo=o("DPTConfig"),Glo=o(" (DPT model)"),Olo=l(),ig=a("li"),Ome=a("strong"),Vlo=o("electra"),Xlo=o(" \u2014 "),jI=a("a"),zlo=o("ElectraConfig"),Qlo=o(" (ELECTRA model)"),Wlo=l(),dg=a("li"),Vme=a("strong"),Ulo=o("encoder-decoder"),Hlo=o(" \u2014 "),DI=a("a"),Jlo=o("EncoderDecoderConfig"),Ylo=o(" (Encoder decoder model)"),Klo=l(),mg=a("li"),Xme=a("strong"),Zlo=o("ernie"),eio=o(" \u2014 "),GI=a("a"),oio=o("ErnieConfig"),rio=o(" (ERNIE model)"),tio=l(),cg=a("li"),zme=a("strong"),aio=o("esm"),nio=o(" \u2014 "),OI=a("a"),sio=o("EsmConfig"),lio=o(" (ESM model)"),iio=l(),fg=a("li"),Qme=a("strong"),dio=o("flaubert"),mio=o(" \u2014 "),VI=a("a"),cio=o("FlaubertConfig"),fio=o(" (FlauBERT model)"),gio=l(),gg=a("li"),Wme=a("strong"),hio=o("flava"),uio=o(" \u2014 "),XI=a("a"),pio=o("FlavaConfig"),_io=o(" (FLAVA model)"),bio=l(),hg=a("li"),Ume=a("strong"),vio=o("fnet"),Fio=o(" \u2014 "),zI=a("a"),Tio=o("FNetConfig"),Mio=o(" (FNet model)"),Eio=l(),ug=a("li"),Hme=a("strong"),Cio=o("fsmt"),wio=o(" \u2014 "),QI=a("a"),Aio=o("FSMTConfig"),Lio=o(" (FairSeq Machine-Translation model)"),yio=l(),pg=a("li"),Jme=a("strong"),xio=o("funnel"),$io=o(" \u2014 "),WI=a("a"),kio=o("FunnelConfig"),Sio=o(" (Funnel Transformer model)"),Rio=l(),_g=a("li"),Yme=a("strong"),Pio=o("glpn"),Bio=o(" \u2014 "),UI=a("a"),Iio=o("GLPNConfig"),Nio=o(" (GLPN model)"),qio=l(),bg=a("li"),Kme=a("strong"),jio=o("gpt2"),Dio=o(" \u2014 "),HI=a("a"),Gio=o("GPT2Config"),Oio=o(" (OpenAI GPT-2 model)"),Vio=l(),vg=a("li"),Zme=a("strong"),Xio=o("gpt_neo"),zio=o(" \u2014 "),JI=a("a"),Qio=o("GPTNeoConfig"),Wio=o(" (GPT Neo model)"),Uio=l(),Fg=a("li"),ece=a("strong"),Hio=o("gpt_neox"),Jio=o(" \u2014 "),YI=a("a"),Yio=o("GPTNeoXConfig"),Kio=o(" (GPT NeoX model)"),Zio=l(),Tg=a("li"),oce=a("strong"),edo=o("gpt_neox_japanese"),odo=o(" \u2014 "),KI=a("a"),rdo=o("GPTNeoXJapaneseConfig"),tdo=o(" (GPT NeoX Japanese model)"),ado=l(),Mg=a("li"),rce=a("strong"),ndo=o("gptj"),sdo=o(" \u2014 "),ZI=a("a"),ldo=o("GPTJConfig"),ido=o(" (GPT-J model)"),ddo=l(),Eg=a("li"),tce=a("strong"),mdo=o("groupvit"),cdo=o(" \u2014 "),eN=a("a"),fdo=o("GroupViTConfig"),gdo=o(" (GroupViT model)"),hdo=l(),Cg=a("li"),ace=a("strong"),udo=o("hubert"),pdo=o(" \u2014 "),oN=a("a"),_do=o("HubertConfig"),bdo=o(" (Hubert model)"),vdo=l(),wg=a("li"),nce=a("strong"),Fdo=o("ibert"),Tdo=o(" \u2014 "),rN=a("a"),Mdo=o("IBertConfig"),Edo=o(" (I-BERT model)"),Cdo=l(),Ag=a("li"),sce=a("strong"),wdo=o("imagegpt"),Ado=o(" \u2014 "),tN=a("a"),Ldo=o("ImageGPTConfig"),ydo=o(" (ImageGPT model)"),xdo=l(),Lg=a("li"),lce=a("strong"),$do=o("layoutlm"),kdo=o(" \u2014 "),aN=a("a"),Sdo=o("LayoutLMConfig"),Rdo=o(" (LayoutLM model)"),Pdo=l(),yg=a("li"),ice=a("strong"),Bdo=o("layoutlmv2"),Ido=o(" \u2014 "),nN=a("a"),Ndo=o("LayoutLMv2Config"),qdo=o(" (LayoutLMv2 model)"),jdo=l(),xg=a("li"),dce=a("strong"),Ddo=o("layoutlmv3"),Gdo=o(" \u2014 "),sN=a("a"),Odo=o("LayoutLMv3Config"),Vdo=o(" (LayoutLMv3 model)"),Xdo=l(),$g=a("li"),mce=a("strong"),zdo=o("led"),Qdo=o(" \u2014 "),lN=a("a"),Wdo=o("LEDConfig"),Udo=o(" (LED model)"),Hdo=l(),kg=a("li"),cce=a("strong"),Jdo=o("levit"),Ydo=o(" \u2014 "),iN=a("a"),Kdo=o("LevitConfig"),Zdo=o(" (LeViT model)"),emo=l(),Sg=a("li"),fce=a("strong"),omo=o("longformer"),rmo=o(" \u2014 "),dN=a("a"),tmo=o("LongformerConfig"),amo=o(" (Longformer model)"),nmo=l(),Rg=a("li"),gce=a("strong"),smo=o("longt5"),lmo=o(" \u2014 "),mN=a("a"),imo=o("LongT5Config"),dmo=o(" (LongT5 model)"),mmo=l(),Pg=a("li"),hce=a("strong"),cmo=o("luke"),fmo=o(" \u2014 "),cN=a("a"),gmo=o("LukeConfig"),hmo=o(" (LUKE model)"),umo=l(),Bg=a("li"),uce=a("strong"),pmo=o("lxmert"),_mo=o(" \u2014 "),fN=a("a"),bmo=o("LxmertConfig"),vmo=o(" (LXMERT model)"),Fmo=l(),Ig=a("li"),pce=a("strong"),Tmo=o("m2m_100"),Mmo=o(" \u2014 "),gN=a("a"),Emo=o("M2M100Config"),Cmo=o(" (M2M100 model)"),wmo=l(),Ng=a("li"),_ce=a("strong"),Amo=o("marian"),Lmo=o(" \u2014 "),hN=a("a"),ymo=o("MarianConfig"),xmo=o(" (Marian model)"),$mo=l(),qg=a("li"),bce=a("strong"),kmo=o("markuplm"),Smo=o(" \u2014 "),uN=a("a"),Rmo=o("MarkupLMConfig"),Pmo=o(" (MarkupLM model)"),Bmo=l(),jg=a("li"),vce=a("strong"),Imo=o("maskformer"),Nmo=o(" \u2014 "),pN=a("a"),qmo=o("MaskFormerConfig"),jmo=o(" (MaskFormer model)"),Dmo=l(),Dg=a("li"),Fce=a("strong"),Gmo=o("mbart"),Omo=o(" \u2014 "),_N=a("a"),Vmo=o("MBartConfig"),Xmo=o(" (mBART model)"),zmo=l(),Gg=a("li"),Tce=a("strong"),Qmo=o("mctct"),Wmo=o(" \u2014 "),bN=a("a"),Umo=o("MCTCTConfig"),Hmo=o(" (M-CTC-T model)"),Jmo=l(),Og=a("li"),Mce=a("strong"),Ymo=o("megatron-bert"),Kmo=o(" \u2014 "),vN=a("a"),Zmo=o("MegatronBertConfig"),eco=o(" (Megatron-BERT model)"),oco=l(),Vg=a("li"),Ece=a("strong"),rco=o("mobilebert"),tco=o(" \u2014 "),FN=a("a"),aco=o("MobileBertConfig"),nco=o(" (MobileBERT model)"),sco=l(),Xg=a("li"),Cce=a("strong"),lco=o("mobilevit"),ico=o(" \u2014 "),TN=a("a"),dco=o("MobileViTConfig"),mco=o(" (MobileViT model)"),cco=l(),zg=a("li"),wce=a("strong"),fco=o("mpnet"),gco=o(" \u2014 "),MN=a("a"),hco=o("MPNetConfig"),uco=o(" (MPNet model)"),pco=l(),Qg=a("li"),Ace=a("strong"),_co=o("mt5"),bco=o(" \u2014 "),EN=a("a"),vco=o("MT5Config"),Fco=o(" (MT5 model)"),Tco=l(),Wg=a("li"),Lce=a("strong"),Mco=o("mvp"),Eco=o(" \u2014 "),CN=a("a"),Cco=o("MvpConfig"),wco=o(" (MVP model)"),Aco=l(),Ug=a("li"),yce=a("strong"),Lco=o("nezha"),yco=o(" \u2014 "),wN=a("a"),xco=o("NezhaConfig"),$co=o(" (Nezha model)"),kco=l(),Hg=a("li"),xce=a("strong"),Sco=o("nystromformer"),Rco=o(" \u2014 "),AN=a("a"),Pco=o("NystromformerConfig"),Bco=o(" (Nystr\xF6mformer model)"),Ico=l(),Jg=a("li"),$ce=a("strong"),Nco=o("openai-gpt"),qco=o(" \u2014 "),LN=a("a"),jco=o("OpenAIGPTConfig"),Dco=o(" (OpenAI GPT model)"),Gco=l(),Yg=a("li"),kce=a("strong"),Oco=o("opt"),Vco=o(" \u2014 "),yN=a("a"),Xco=o("OPTConfig"),zco=o(" (OPT model)"),Qco=l(),Kg=a("li"),Sce=a("strong"),Wco=o("owlvit"),Uco=o(" \u2014 "),xN=a("a"),Hco=o("OwlViTConfig"),Jco=o(" (OWL-ViT model)"),Yco=l(),Zg=a("li"),Rce=a("strong"),Kco=o("pegasus"),Zco=o(" \u2014 "),$N=a("a"),efo=o("PegasusConfig"),ofo=o(" (Pegasus model)"),rfo=l(),eh=a("li"),Pce=a("strong"),tfo=o("pegasus_x"),afo=o(" \u2014 "),kN=a("a"),nfo=o("PegasusXConfig"),sfo=o(" (PEGASUS-X model)"),lfo=l(),oh=a("li"),Bce=a("strong"),ifo=o("perceiver"),dfo=o(" \u2014 "),SN=a("a"),mfo=o("PerceiverConfig"),cfo=o(" (Perceiver model)"),ffo=l(),rh=a("li"),Ice=a("strong"),gfo=o("plbart"),hfo=o(" \u2014 "),RN=a("a"),ufo=o("PLBartConfig"),pfo=o(" (PLBart model)"),_fo=l(),th=a("li"),Nce=a("strong"),bfo=o("poolformer"),vfo=o(" \u2014 "),PN=a("a"),Ffo=o("PoolFormerConfig"),Tfo=o(" (PoolFormer model)"),Mfo=l(),ah=a("li"),qce=a("strong"),Efo=o("prophetnet"),Cfo=o(" \u2014 "),BN=a("a"),wfo=o("ProphetNetConfig"),Afo=o(" (ProphetNet model)"),Lfo=l(),nh=a("li"),jce=a("strong"),yfo=o("qdqbert"),xfo=o(" \u2014 "),IN=a("a"),$fo=o("QDQBertConfig"),kfo=o(" (QDQBert model)"),Sfo=l(),sh=a("li"),Dce=a("strong"),Rfo=o("rag"),Pfo=o(" \u2014 "),NN=a("a"),Bfo=o("RagConfig"),Ifo=o(" (RAG model)"),Nfo=l(),lh=a("li"),Gce=a("strong"),qfo=o("realm"),jfo=o(" \u2014 "),qN=a("a"),Dfo=o("RealmConfig"),Gfo=o(" (REALM model)"),Ofo=l(),ih=a("li"),Oce=a("strong"),Vfo=o("reformer"),Xfo=o(" \u2014 "),jN=a("a"),zfo=o("ReformerConfig"),Qfo=o(" (Reformer model)"),Wfo=l(),dh=a("li"),Vce=a("strong"),Ufo=o("regnet"),Hfo=o(" \u2014 "),DN=a("a"),Jfo=o("RegNetConfig"),Yfo=o(" (RegNet model)"),Kfo=l(),mh=a("li"),Xce=a("strong"),Zfo=o("rembert"),ego=o(" \u2014 "),GN=a("a"),ogo=o("RemBertConfig"),rgo=o(" (RemBERT model)"),tgo=l(),ch=a("li"),zce=a("strong"),ago=o("resnet"),ngo=o(" \u2014 "),ON=a("a"),sgo=o("ResNetConfig"),lgo=o(" (ResNet model)"),igo=l(),fh=a("li"),Qce=a("strong"),dgo=o("retribert"),mgo=o(" \u2014 "),VN=a("a"),cgo=o("RetriBertConfig"),fgo=o(" (RetriBERT model)"),ggo=l(),gh=a("li"),Wce=a("strong"),hgo=o("roberta"),ugo=o(" \u2014 "),XN=a("a"),pgo=o("RobertaConfig"),_go=o(" (RoBERTa model)"),bgo=l(),hh=a("li"),Uce=a("strong"),vgo=o("roformer"),Fgo=o(" \u2014 "),zN=a("a"),Tgo=o("RoFormerConfig"),Mgo=o(" (RoFormer model)"),Ego=l(),uh=a("li"),Hce=a("strong"),Cgo=o("segformer"),wgo=o(" \u2014 "),QN=a("a"),Ago=o("SegformerConfig"),Lgo=o(" (SegFormer model)"),ygo=l(),ph=a("li"),Jce=a("strong"),xgo=o("sew"),$go=o(" \u2014 "),WN=a("a"),kgo=o("SEWConfig"),Sgo=o(" (SEW model)"),Rgo=l(),_h=a("li"),Yce=a("strong"),Pgo=o("sew-d"),Bgo=o(" \u2014 "),UN=a("a"),Igo=o("SEWDConfig"),Ngo=o(" (SEW-D model)"),qgo=l(),bh=a("li"),Kce=a("strong"),jgo=o("speech-encoder-decoder"),Dgo=o(" \u2014 "),HN=a("a"),Ggo=o("SpeechEncoderDecoderConfig"),Ogo=o(" (Speech Encoder decoder model)"),Vgo=l(),vh=a("li"),Zce=a("strong"),Xgo=o("speech_to_text"),zgo=o(" \u2014 "),JN=a("a"),Qgo=o("Speech2TextConfig"),Wgo=o(" (Speech2Text model)"),Ugo=l(),Fh=a("li"),efe=a("strong"),Hgo=o("speech_to_text_2"),Jgo=o(" \u2014 "),YN=a("a"),Ygo=o("Speech2Text2Config"),Kgo=o(" (Speech2Text2 model)"),Zgo=l(),Th=a("li"),ofe=a("strong"),eho=o("splinter"),oho=o(" \u2014 "),KN=a("a"),rho=o("SplinterConfig"),tho=o(" (Splinter model)"),aho=l(),Mh=a("li"),rfe=a("strong"),nho=o("squeezebert"),sho=o(" \u2014 "),ZN=a("a"),lho=o("SqueezeBertConfig"),iho=o(" (SqueezeBERT model)"),dho=l(),Eh=a("li"),tfe=a("strong"),mho=o("swin"),cho=o(" \u2014 "),eq=a("a"),fho=o("SwinConfig"),gho=o(" (Swin Transformer model)"),hho=l(),Ch=a("li"),afe=a("strong"),uho=o("swinv2"),pho=o(" \u2014 "),oq=a("a"),_ho=o("Swinv2Config"),bho=o(" (Swin Transformer V2 model)"),vho=l(),wh=a("li"),nfe=a("strong"),Fho=o("t5"),Tho=o(" \u2014 "),rq=a("a"),Mho=o("T5Config"),Eho=o(" (T5 model)"),Cho=l(),Ah=a("li"),sfe=a("strong"),who=o("tapas"),Aho=o(" \u2014 "),tq=a("a"),Lho=o("TapasConfig"),yho=o(" (TAPAS model)"),xho=l(),Lh=a("li"),lfe=a("strong"),$ho=o("time_series_transformer"),kho=o(" \u2014 "),aq=a("a"),Sho=o("TimeSeriesTransformerConfig"),Rho=o(" (Time Series Transformer model)"),Pho=l(),yh=a("li"),ife=a("strong"),Bho=o("trajectory_transformer"),Iho=o(" \u2014 "),nq=a("a"),Nho=o("TrajectoryTransformerConfig"),qho=o(" (Trajectory Transformer model)"),jho=l(),xh=a("li"),dfe=a("strong"),Dho=o("transfo-xl"),Gho=o(" \u2014 "),sq=a("a"),Oho=o("TransfoXLConfig"),Vho=o(" (Transformer-XL model)"),Xho=l(),$h=a("li"),mfe=a("strong"),zho=o("trocr"),Qho=o(" \u2014 "),lq=a("a"),Who=o("TrOCRConfig"),Uho=o(" (TrOCR model)"),Hho=l(),kh=a("li"),cfe=a("strong"),Jho=o("unispeech"),Yho=o(" \u2014 "),iq=a("a"),Kho=o("UniSpeechConfig"),Zho=o(" (UniSpeech model)"),euo=l(),Sh=a("li"),ffe=a("strong"),ouo=o("unispeech-sat"),ruo=o(" \u2014 "),dq=a("a"),tuo=o("UniSpeechSatConfig"),auo=o(" (UniSpeechSat model)"),nuo=l(),Rh=a("li"),gfe=a("strong"),suo=o("van"),luo=o(" \u2014 "),mq=a("a"),iuo=o("VanConfig"),duo=o(" (VAN model)"),muo=l(),Ph=a("li"),hfe=a("strong"),cuo=o("videomae"),fuo=o(" \u2014 "),cq=a("a"),guo=o("VideoMAEConfig"),huo=o(" (VideoMAE model)"),uuo=l(),Bh=a("li"),ufe=a("strong"),puo=o("vilt"),_uo=o(" \u2014 "),fq=a("a"),buo=o("ViltConfig"),vuo=o(" (ViLT model)"),Fuo=l(),Ih=a("li"),pfe=a("strong"),Tuo=o("vision-encoder-decoder"),Muo=o(" \u2014 "),gq=a("a"),Euo=o("VisionEncoderDecoderConfig"),Cuo=o(" (Vision Encoder decoder model)"),wuo=l(),Nh=a("li"),_fe=a("strong"),Auo=o("vision-text-dual-encoder"),Luo=o(" \u2014 "),hq=a("a"),yuo=o("VisionTextDualEncoderConfig"),xuo=o(" (VisionTextDualEncoder model)"),$uo=l(),qh=a("li"),bfe=a("strong"),kuo=o("visual_bert"),Suo=o(" \u2014 "),uq=a("a"),Ruo=o("VisualBertConfig"),Puo=o(" (VisualBERT model)"),Buo=l(),jh=a("li"),vfe=a("strong"),Iuo=o("vit"),Nuo=o(" \u2014 "),pq=a("a"),quo=o("ViTConfig"),juo=o(" (ViT model)"),Duo=l(),Dh=a("li"),Ffe=a("strong"),Guo=o("vit_mae"),Ouo=o(" \u2014 "),_q=a("a"),Vuo=o("ViTMAEConfig"),Xuo=o(" (ViTMAE model)"),zuo=l(),Gh=a("li"),Tfe=a("strong"),Quo=o("vit_msn"),Wuo=o(" \u2014 "),bq=a("a"),Uuo=o("ViTMSNConfig"),Huo=o(" (ViTMSN model)"),Juo=l(),Oh=a("li"),Mfe=a("strong"),Yuo=o("wav2vec2"),Kuo=o(" \u2014 "),vq=a("a"),Zuo=o("Wav2Vec2Config"),epo=o(" (Wav2Vec2 model)"),opo=l(),Vh=a("li"),Efe=a("strong"),rpo=o("wav2vec2-conformer"),tpo=o(" \u2014 "),Fq=a("a"),apo=o("Wav2Vec2ConformerConfig"),npo=o(" (Wav2Vec2-Conformer model)"),spo=l(),Xh=a("li"),Cfe=a("strong"),lpo=o("wavlm"),ipo=o(" \u2014 "),Tq=a("a"),dpo=o("WavLMConfig"),mpo=o(" (WavLM model)"),cpo=l(),zh=a("li"),wfe=a("strong"),fpo=o("xclip"),gpo=o(" \u2014 "),Mq=a("a"),hpo=o("XCLIPConfig"),upo=o(" (X-CLIP model)"),ppo=l(),Qh=a("li"),Afe=a("strong"),_po=o("xglm"),bpo=o(" \u2014 "),Eq=a("a"),vpo=o("XGLMConfig"),Fpo=o(" (XGLM model)"),Tpo=l(),Wh=a("li"),Lfe=a("strong"),Mpo=o("xlm"),Epo=o(" \u2014 "),Cq=a("a"),Cpo=o("XLMConfig"),wpo=o(" (XLM model)"),Apo=l(),Uh=a("li"),yfe=a("strong"),Lpo=o("xlm-prophetnet"),ypo=o(" \u2014 "),wq=a("a"),xpo=o("XLMProphetNetConfig"),$po=o(" (XLM-ProphetNet model)"),kpo=l(),Hh=a("li"),xfe=a("strong"),Spo=o("xlm-roberta"),Rpo=o(" \u2014 "),Aq=a("a"),Ppo=o("XLMRobertaConfig"),Bpo=o(" (XLM-RoBERTa model)"),Ipo=l(),Jh=a("li"),$fe=a("strong"),Npo=o("xlm-roberta-xl"),qpo=o(" \u2014 "),Lq=a("a"),jpo=o("XLMRobertaXLConfig"),Dpo=o(" (XLM-RoBERTa-XL model)"),Gpo=l(),Yh=a("li"),kfe=a("strong"),Opo=o("xlnet"),Vpo=o(" \u2014 "),yq=a("a"),Xpo=o("XLNetConfig"),zpo=o(" (XLNet model)"),Qpo=l(),Kh=a("li"),Sfe=a("strong"),Wpo=o("yolos"),Upo=o(" \u2014 "),xq=a("a"),Hpo=o("YolosConfig"),Jpo=o(" (YOLOS model)"),Ypo=l(),Zh=a("li"),Rfe=a("strong"),Kpo=o("yoso"),Zpo=o(" \u2014 "),$q=a("a"),e_o=o("YosoConfig"),o_o=o(" (YOSO model)"),r_o=l(),F(eu.$$.fragment),t_o=l(),ou=a("div"),F(lx.$$.fragment),a_o=l(),Pfe=a("p"),n_o=o("Register a new configuration for this class."),WZe=l(),gd=a("h2"),ru=a("a"),Bfe=a("span"),F(ix.$$.fragment),s_o=l(),Ife=a("span"),l_o=o("AutoTokenizer"),UZe=l(),ko=a("div"),F(dx.$$.fragment),i_o=l(),mx=a("p"),d_o=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),kq=a("a"),m_o=o("AutoTokenizer.from_pretrained()"),c_o=o(" class method."),f_o=l(),cx=a("p"),g_o=o("This class cannot be instantiated directly using "),Nfe=a("code"),h_o=o("__init__()"),u_o=o(" (throws an error)."),p_o=l(),Br=a("div"),F(fx.$$.fragment),__o=l(),qfe=a("p"),b_o=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),v_o=l(),Ua=a("p"),F_o=o("The tokenizer class to instantiate is selected based on the "),jfe=a("code"),T_o=o("model_type"),M_o=o(` property of the config object (either
passed as an argument or loaded from `),Dfe=a("code"),E_o=o("pretrained_model_name_or_path"),C_o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gfe=a("code"),w_o=o("pretrained_model_name_or_path"),A_o=o(":"),L_o=l(),k=a("ul"),ns=a("li"),Ofe=a("strong"),y_o=o("albert"),x_o=o(" \u2014 "),Sq=a("a"),$_o=o("AlbertTokenizer"),k_o=o(" or "),Rq=a("a"),S_o=o("AlbertTokenizerFast"),R_o=o(" (ALBERT model)"),P_o=l(),ss=a("li"),Vfe=a("strong"),B_o=o("bart"),I_o=o(" \u2014 "),Pq=a("a"),N_o=o("BartTokenizer"),q_o=o(" or "),Bq=a("a"),j_o=o("BartTokenizerFast"),D_o=o(" (BART model)"),G_o=l(),ls=a("li"),Xfe=a("strong"),O_o=o("barthez"),V_o=o(" \u2014 "),Iq=a("a"),X_o=o("BarthezTokenizer"),z_o=o(" or "),Nq=a("a"),Q_o=o("BarthezTokenizerFast"),W_o=o(" (BARThez model)"),U_o=l(),tu=a("li"),zfe=a("strong"),H_o=o("bartpho"),J_o=o(" \u2014 "),qq=a("a"),Y_o=o("BartphoTokenizer"),K_o=o(" (BARTpho model)"),Z_o=l(),is=a("li"),Qfe=a("strong"),e2o=o("bert"),o2o=o(" \u2014 "),jq=a("a"),r2o=o("BertTokenizer"),t2o=o(" or "),Dq=a("a"),a2o=o("BertTokenizerFast"),n2o=o(" (BERT model)"),s2o=l(),au=a("li"),Wfe=a("strong"),l2o=o("bert-generation"),i2o=o(" \u2014 "),Gq=a("a"),d2o=o("BertGenerationTokenizer"),m2o=o(" (Bert Generation model)"),c2o=l(),nu=a("li"),Ufe=a("strong"),f2o=o("bert-japanese"),g2o=o(" \u2014 "),Oq=a("a"),h2o=o("BertJapaneseTokenizer"),u2o=o(" (BertJapanese model)"),p2o=l(),su=a("li"),Hfe=a("strong"),_2o=o("bertweet"),b2o=o(" \u2014 "),Vq=a("a"),v2o=o("BertweetTokenizer"),F2o=o(" (BERTweet model)"),T2o=l(),ds=a("li"),Jfe=a("strong"),M2o=o("big_bird"),E2o=o(" \u2014 "),Xq=a("a"),C2o=o("BigBirdTokenizer"),w2o=o(" or "),zq=a("a"),A2o=o("BigBirdTokenizerFast"),L2o=o(" (BigBird model)"),y2o=l(),ms=a("li"),Yfe=a("strong"),x2o=o("bigbird_pegasus"),$2o=o(" \u2014 "),Qq=a("a"),k2o=o("PegasusTokenizer"),S2o=o(" or "),Wq=a("a"),R2o=o("PegasusTokenizerFast"),P2o=o(" (BigBird-Pegasus model)"),B2o=l(),cs=a("li"),Kfe=a("strong"),I2o=o("blenderbot"),N2o=o(" \u2014 "),Uq=a("a"),q2o=o("BlenderbotTokenizer"),j2o=o(" or "),Hq=a("a"),D2o=o("BlenderbotTokenizerFast"),G2o=o(" (Blenderbot model)"),O2o=l(),lu=a("li"),Zfe=a("strong"),V2o=o("blenderbot-small"),X2o=o(" \u2014 "),Jq=a("a"),z2o=o("BlenderbotSmallTokenizer"),Q2o=o(" (BlenderbotSmall model)"),W2o=l(),iu=a("li"),ege=a("strong"),U2o=o("bloom"),H2o=o(" \u2014 "),Yq=a("a"),J2o=o("BloomTokenizerFast"),Y2o=o(" (BLOOM model)"),K2o=l(),du=a("li"),oge=a("strong"),Z2o=o("byt5"),e1o=o(" \u2014 "),Kq=a("a"),o1o=o("ByT5Tokenizer"),r1o=o(" (ByT5 model)"),t1o=l(),fs=a("li"),rge=a("strong"),a1o=o("camembert"),n1o=o(" \u2014 "),Zq=a("a"),s1o=o("CamembertTokenizer"),l1o=o(" or "),ej=a("a"),i1o=o("CamembertTokenizerFast"),d1o=o(" (CamemBERT model)"),m1o=l(),mu=a("li"),tge=a("strong"),c1o=o("canine"),f1o=o(" \u2014 "),oj=a("a"),g1o=o("CanineTokenizer"),h1o=o(" (CANINE model)"),u1o=l(),gs=a("li"),age=a("strong"),p1o=o("clip"),_1o=o(" \u2014 "),rj=a("a"),b1o=o("CLIPTokenizer"),v1o=o(" or "),tj=a("a"),F1o=o("CLIPTokenizerFast"),T1o=o(" (CLIP model)"),M1o=l(),hs=a("li"),nge=a("strong"),E1o=o("codegen"),C1o=o(" \u2014 "),aj=a("a"),w1o=o("CodeGenTokenizer"),A1o=o(" or "),nj=a("a"),L1o=o("CodeGenTokenizerFast"),y1o=o(" (CodeGen model)"),x1o=l(),us=a("li"),sge=a("strong"),$1o=o("convbert"),k1o=o(" \u2014 "),sj=a("a"),S1o=o("ConvBertTokenizer"),R1o=o(" or "),lj=a("a"),P1o=o("ConvBertTokenizerFast"),B1o=o(" (ConvBERT model)"),I1o=l(),ps=a("li"),lge=a("strong"),N1o=o("cpm"),q1o=o(" \u2014 "),ij=a("a"),j1o=o("CpmTokenizer"),D1o=o(" or "),dj=a("a"),G1o=o("CpmTokenizerFast"),O1o=o(" (CPM model)"),V1o=l(),cu=a("li"),ige=a("strong"),X1o=o("ctrl"),z1o=o(" \u2014 "),mj=a("a"),Q1o=o("CTRLTokenizer"),W1o=o(" (CTRL model)"),U1o=l(),_s=a("li"),dge=a("strong"),H1o=o("data2vec-text"),J1o=o(" \u2014 "),cj=a("a"),Y1o=o("RobertaTokenizer"),K1o=o(" or "),fj=a("a"),Z1o=o("RobertaTokenizerFast"),ebo=o(" (Data2VecText model)"),obo=l(),bs=a("li"),mge=a("strong"),rbo=o("deberta"),tbo=o(" \u2014 "),gj=a("a"),abo=o("DebertaTokenizer"),nbo=o(" or "),hj=a("a"),sbo=o("DebertaTokenizerFast"),lbo=o(" (DeBERTa model)"),ibo=l(),vs=a("li"),cge=a("strong"),dbo=o("deberta-v2"),mbo=o(" \u2014 "),uj=a("a"),cbo=o("DebertaV2Tokenizer"),fbo=o(" or "),pj=a("a"),gbo=o("DebertaV2TokenizerFast"),hbo=o(" (DeBERTa-v2 model)"),ubo=l(),Fs=a("li"),fge=a("strong"),pbo=o("distilbert"),_bo=o(" \u2014 "),_j=a("a"),bbo=o("DistilBertTokenizer"),vbo=o(" or "),bj=a("a"),Fbo=o("DistilBertTokenizerFast"),Tbo=o(" (DistilBERT model)"),Mbo=l(),Ts=a("li"),gge=a("strong"),Ebo=o("dpr"),Cbo=o(" \u2014 "),vj=a("a"),wbo=o("DPRQuestionEncoderTokenizer"),Abo=o(" or "),Fj=a("a"),Lbo=o("DPRQuestionEncoderTokenizerFast"),ybo=o(" (DPR model)"),xbo=l(),Ms=a("li"),hge=a("strong"),$bo=o("electra"),kbo=o(" \u2014 "),Tj=a("a"),Sbo=o("ElectraTokenizer"),Rbo=o(" or "),Mj=a("a"),Pbo=o("ElectraTokenizerFast"),Bbo=o(" (ELECTRA model)"),Ibo=l(),Es=a("li"),uge=a("strong"),Nbo=o("ernie"),qbo=o(" \u2014 "),Ej=a("a"),jbo=o("BertTokenizer"),Dbo=o(" or "),Cj=a("a"),Gbo=o("BertTokenizerFast"),Obo=o(" (ERNIE model)"),Vbo=l(),fu=a("li"),pge=a("strong"),Xbo=o("flaubert"),zbo=o(" \u2014 "),wj=a("a"),Qbo=o("FlaubertTokenizer"),Wbo=o(" (FlauBERT model)"),Ubo=l(),Cs=a("li"),_ge=a("strong"),Hbo=o("fnet"),Jbo=o(" \u2014 "),Aj=a("a"),Ybo=o("FNetTokenizer"),Kbo=o(" or "),Lj=a("a"),Zbo=o("FNetTokenizerFast"),evo=o(" (FNet model)"),ovo=l(),gu=a("li"),bge=a("strong"),rvo=o("fsmt"),tvo=o(" \u2014 "),yj=a("a"),avo=o("FSMTTokenizer"),nvo=o(" (FairSeq Machine-Translation model)"),svo=l(),ws=a("li"),vge=a("strong"),lvo=o("funnel"),ivo=o(" \u2014 "),xj=a("a"),dvo=o("FunnelTokenizer"),mvo=o(" or "),$j=a("a"),cvo=o("FunnelTokenizerFast"),fvo=o(" (Funnel Transformer model)"),gvo=l(),As=a("li"),Fge=a("strong"),hvo=o("gpt2"),uvo=o(" \u2014 "),kj=a("a"),pvo=o("GPT2Tokenizer"),_vo=o(" or "),Sj=a("a"),bvo=o("GPT2TokenizerFast"),vvo=o(" (OpenAI GPT-2 model)"),Fvo=l(),Ls=a("li"),Tge=a("strong"),Tvo=o("gpt_neo"),Mvo=o(" \u2014 "),Rj=a("a"),Evo=o("GPT2Tokenizer"),Cvo=o(" or "),Pj=a("a"),wvo=o("GPT2TokenizerFast"),Avo=o(" (GPT Neo model)"),Lvo=l(),hu=a("li"),Mge=a("strong"),yvo=o("gpt_neox"),xvo=o(" \u2014 "),Bj=a("a"),$vo=o("GPTNeoXTokenizerFast"),kvo=o(" (GPT NeoX model)"),Svo=l(),uu=a("li"),Ege=a("strong"),Rvo=o("gpt_neox_japanese"),Pvo=o(" \u2014 "),Ij=a("a"),Bvo=o("GPTNeoXJapaneseTokenizer"),Ivo=o(" (GPT NeoX Japanese model)"),Nvo=l(),ys=a("li"),Cge=a("strong"),qvo=o("gptj"),jvo=o(" \u2014 "),Nj=a("a"),Dvo=o("GPT2Tokenizer"),Gvo=o(" or "),qj=a("a"),Ovo=o("GPT2TokenizerFast"),Vvo=o(" (GPT-J model)"),Xvo=l(),xs=a("li"),wge=a("strong"),zvo=o("groupvit"),Qvo=o(" \u2014 "),jj=a("a"),Wvo=o("CLIPTokenizer"),Uvo=o(" or "),Dj=a("a"),Hvo=o("CLIPTokenizerFast"),Jvo=o(" (GroupViT model)"),Yvo=l(),$s=a("li"),Age=a("strong"),Kvo=o("herbert"),Zvo=o(" \u2014 "),Gj=a("a"),eFo=o("HerbertTokenizer"),oFo=o(" or "),Oj=a("a"),rFo=o("HerbertTokenizerFast"),tFo=o(" (HerBERT model)"),aFo=l(),pu=a("li"),Lge=a("strong"),nFo=o("hubert"),sFo=o(" \u2014 "),Vj=a("a"),lFo=o("Wav2Vec2CTCTokenizer"),iFo=o(" (Hubert model)"),dFo=l(),ks=a("li"),yge=a("strong"),mFo=o("ibert"),cFo=o(" \u2014 "),Xj=a("a"),fFo=o("RobertaTokenizer"),gFo=o(" or "),zj=a("a"),hFo=o("RobertaTokenizerFast"),uFo=o(" (I-BERT model)"),pFo=l(),Ss=a("li"),xge=a("strong"),_Fo=o("layoutlm"),bFo=o(" \u2014 "),Qj=a("a"),vFo=o("LayoutLMTokenizer"),FFo=o(" or "),Wj=a("a"),TFo=o("LayoutLMTokenizerFast"),MFo=o(" (LayoutLM model)"),EFo=l(),Rs=a("li"),$ge=a("strong"),CFo=o("layoutlmv2"),wFo=o(" \u2014 "),Uj=a("a"),AFo=o("LayoutLMv2Tokenizer"),LFo=o(" or "),Hj=a("a"),yFo=o("LayoutLMv2TokenizerFast"),xFo=o(" (LayoutLMv2 model)"),$Fo=l(),Ps=a("li"),kge=a("strong"),kFo=o("layoutlmv3"),SFo=o(" \u2014 "),Jj=a("a"),RFo=o("LayoutLMv3Tokenizer"),PFo=o(" or "),Yj=a("a"),BFo=o("LayoutLMv3TokenizerFast"),IFo=o(" (LayoutLMv3 model)"),NFo=l(),Bs=a("li"),Sge=a("strong"),qFo=o("layoutxlm"),jFo=o(" \u2014 "),Kj=a("a"),DFo=o("LayoutXLMTokenizer"),GFo=o(" or "),Zj=a("a"),OFo=o("LayoutXLMTokenizerFast"),VFo=o(" (LayoutXLM model)"),XFo=l(),Is=a("li"),Rge=a("strong"),zFo=o("led"),QFo=o(" \u2014 "),eD=a("a"),WFo=o("LEDTokenizer"),UFo=o(" or "),oD=a("a"),HFo=o("LEDTokenizerFast"),JFo=o(" (LED model)"),YFo=l(),Ns=a("li"),Pge=a("strong"),KFo=o("longformer"),ZFo=o(" \u2014 "),rD=a("a"),eTo=o("LongformerTokenizer"),oTo=o(" or "),tD=a("a"),rTo=o("LongformerTokenizerFast"),tTo=o(" (Longformer model)"),aTo=l(),qs=a("li"),Bge=a("strong"),nTo=o("longt5"),sTo=o(" \u2014 "),aD=a("a"),lTo=o("T5Tokenizer"),iTo=o(" or "),nD=a("a"),dTo=o("T5TokenizerFast"),mTo=o(" (LongT5 model)"),cTo=l(),_u=a("li"),Ige=a("strong"),fTo=o("luke"),gTo=o(" \u2014 "),sD=a("a"),hTo=o("LukeTokenizer"),uTo=o(" (LUKE model)"),pTo=l(),js=a("li"),Nge=a("strong"),_To=o("lxmert"),bTo=o(" \u2014 "),lD=a("a"),vTo=o("LxmertTokenizer"),FTo=o(" or "),iD=a("a"),TTo=o("LxmertTokenizerFast"),MTo=o(" (LXMERT model)"),ETo=l(),bu=a("li"),qge=a("strong"),CTo=o("m2m_100"),wTo=o(" \u2014 "),dD=a("a"),ATo=o("M2M100Tokenizer"),LTo=o(" (M2M100 model)"),yTo=l(),vu=a("li"),jge=a("strong"),xTo=o("marian"),$To=o(" \u2014 "),mD=a("a"),kTo=o("MarianTokenizer"),STo=o(" (Marian model)"),RTo=l(),Ds=a("li"),Dge=a("strong"),PTo=o("mbart"),BTo=o(" \u2014 "),cD=a("a"),ITo=o("MBartTokenizer"),NTo=o(" or "),fD=a("a"),qTo=o("MBartTokenizerFast"),jTo=o(" (mBART model)"),DTo=l(),Gs=a("li"),Gge=a("strong"),GTo=o("mbart50"),OTo=o(" \u2014 "),gD=a("a"),VTo=o("MBart50Tokenizer"),XTo=o(" or "),hD=a("a"),zTo=o("MBart50TokenizerFast"),QTo=o(" (mBART-50 model)"),WTo=l(),Os=a("li"),Oge=a("strong"),UTo=o("megatron-bert"),HTo=o(" \u2014 "),uD=a("a"),JTo=o("BertTokenizer"),YTo=o(" or "),pD=a("a"),KTo=o("BertTokenizerFast"),ZTo=o(" (Megatron-BERT model)"),eMo=l(),Fu=a("li"),Vge=a("strong"),oMo=o("mluke"),rMo=o(" \u2014 "),_D=a("a"),tMo=o("MLukeTokenizer"),aMo=o(" (mLUKE model)"),nMo=l(),Vs=a("li"),Xge=a("strong"),sMo=o("mobilebert"),lMo=o(" \u2014 "),bD=a("a"),iMo=o("MobileBertTokenizer"),dMo=o(" or "),vD=a("a"),mMo=o("MobileBertTokenizerFast"),cMo=o(" (MobileBERT model)"),fMo=l(),Xs=a("li"),zge=a("strong"),gMo=o("mpnet"),hMo=o(" \u2014 "),FD=a("a"),uMo=o("MPNetTokenizer"),pMo=o(" or "),TD=a("a"),_Mo=o("MPNetTokenizerFast"),bMo=o(" (MPNet model)"),vMo=l(),zs=a("li"),Qge=a("strong"),FMo=o("mt5"),TMo=o(" \u2014 "),MD=a("a"),MMo=o("MT5Tokenizer"),EMo=o(" or "),ED=a("a"),CMo=o("MT5TokenizerFast"),wMo=o(" (MT5 model)"),AMo=l(),Qs=a("li"),Wge=a("strong"),LMo=o("mvp"),yMo=o(" \u2014 "),CD=a("a"),xMo=o("MvpTokenizer"),$Mo=o(" or "),wD=a("a"),kMo=o("MvpTokenizerFast"),SMo=o(" (MVP model)"),RMo=l(),Ws=a("li"),Uge=a("strong"),PMo=o("nezha"),BMo=o(" \u2014 "),AD=a("a"),IMo=o("BertTokenizer"),NMo=o(" or "),LD=a("a"),qMo=o("BertTokenizerFast"),jMo=o(" (Nezha model)"),DMo=l(),Us=a("li"),Hge=a("strong"),GMo=o("nllb"),OMo=o(" \u2014 "),yD=a("a"),VMo=o("NllbTokenizer"),XMo=o(" or "),xD=a("a"),zMo=o("NllbTokenizerFast"),QMo=o(" (NLLB model)"),WMo=l(),Hs=a("li"),Jge=a("strong"),UMo=o("nystromformer"),HMo=o(" \u2014 "),$D=a("a"),JMo=o("AlbertTokenizer"),YMo=o(" or "),kD=a("a"),KMo=o("AlbertTokenizerFast"),ZMo=o(" (Nystr\xF6mformer model)"),eEo=l(),Js=a("li"),Yge=a("strong"),oEo=o("openai-gpt"),rEo=o(" \u2014 "),SD=a("a"),tEo=o("OpenAIGPTTokenizer"),aEo=o(" or "),RD=a("a"),nEo=o("OpenAIGPTTokenizerFast"),sEo=o(" (OpenAI GPT model)"),lEo=l(),Tu=a("li"),Kge=a("strong"),iEo=o("opt"),dEo=o(" \u2014 "),PD=a("a"),mEo=o("GPT2Tokenizer"),cEo=o(" (OPT model)"),fEo=l(),Ys=a("li"),Zge=a("strong"),gEo=o("owlvit"),hEo=o(" \u2014 "),BD=a("a"),uEo=o("CLIPTokenizer"),pEo=o(" or "),ID=a("a"),_Eo=o("CLIPTokenizerFast"),bEo=o(" (OWL-ViT model)"),vEo=l(),Ks=a("li"),ehe=a("strong"),FEo=o("pegasus"),TEo=o(" \u2014 "),ND=a("a"),MEo=o("PegasusTokenizer"),EEo=o(" or "),qD=a("a"),CEo=o("PegasusTokenizerFast"),wEo=o(" (Pegasus model)"),AEo=l(),Mu=a("li"),ohe=a("strong"),LEo=o("perceiver"),yEo=o(" \u2014 "),jD=a("a"),xEo=o("PerceiverTokenizer"),$Eo=o(" (Perceiver model)"),kEo=l(),Eu=a("li"),rhe=a("strong"),SEo=o("phobert"),REo=o(" \u2014 "),DD=a("a"),PEo=o("PhobertTokenizer"),BEo=o(" (PhoBERT model)"),IEo=l(),Cu=a("li"),the=a("strong"),NEo=o("plbart"),qEo=o(" \u2014 "),GD=a("a"),jEo=o("PLBartTokenizer"),DEo=o(" (PLBart model)"),GEo=l(),wu=a("li"),ahe=a("strong"),OEo=o("prophetnet"),VEo=o(" \u2014 "),OD=a("a"),XEo=o("ProphetNetTokenizer"),zEo=o(" (ProphetNet model)"),QEo=l(),Zs=a("li"),nhe=a("strong"),WEo=o("qdqbert"),UEo=o(" \u2014 "),VD=a("a"),HEo=o("BertTokenizer"),JEo=o(" or "),XD=a("a"),YEo=o("BertTokenizerFast"),KEo=o(" (QDQBert model)"),ZEo=l(),Au=a("li"),she=a("strong"),e4o=o("rag"),o4o=o(" \u2014 "),zD=a("a"),r4o=o("RagTokenizer"),t4o=o(" (RAG model)"),a4o=l(),el=a("li"),lhe=a("strong"),n4o=o("realm"),s4o=o(" \u2014 "),QD=a("a"),l4o=o("RealmTokenizer"),i4o=o(" or "),WD=a("a"),d4o=o("RealmTokenizerFast"),m4o=o(" (REALM model)"),c4o=l(),ol=a("li"),ihe=a("strong"),f4o=o("reformer"),g4o=o(" \u2014 "),UD=a("a"),h4o=o("ReformerTokenizer"),u4o=o(" or "),HD=a("a"),p4o=o("ReformerTokenizerFast"),_4o=o(" (Reformer model)"),b4o=l(),rl=a("li"),dhe=a("strong"),v4o=o("rembert"),F4o=o(" \u2014 "),JD=a("a"),T4o=o("RemBertTokenizer"),M4o=o(" or "),YD=a("a"),E4o=o("RemBertTokenizerFast"),C4o=o(" (RemBERT model)"),w4o=l(),tl=a("li"),mhe=a("strong"),A4o=o("retribert"),L4o=o(" \u2014 "),KD=a("a"),y4o=o("RetriBertTokenizer"),x4o=o(" or "),ZD=a("a"),$4o=o("RetriBertTokenizerFast"),k4o=o(" (RetriBERT model)"),S4o=l(),al=a("li"),che=a("strong"),R4o=o("roberta"),P4o=o(" \u2014 "),eG=a("a"),B4o=o("RobertaTokenizer"),I4o=o(" or "),oG=a("a"),N4o=o("RobertaTokenizerFast"),q4o=o(" (RoBERTa model)"),j4o=l(),nl=a("li"),fhe=a("strong"),D4o=o("roformer"),G4o=o(" \u2014 "),rG=a("a"),O4o=o("RoFormerTokenizer"),V4o=o(" or "),tG=a("a"),X4o=o("RoFormerTokenizerFast"),z4o=o(" (RoFormer model)"),Q4o=l(),Lu=a("li"),ghe=a("strong"),W4o=o("speech_to_text"),U4o=o(" \u2014 "),aG=a("a"),H4o=o("Speech2TextTokenizer"),J4o=o(" (Speech2Text model)"),Y4o=l(),yu=a("li"),hhe=a("strong"),K4o=o("speech_to_text_2"),Z4o=o(" \u2014 "),nG=a("a"),eCo=o("Speech2Text2Tokenizer"),oCo=o(" (Speech2Text2 model)"),rCo=l(),sl=a("li"),uhe=a("strong"),tCo=o("splinter"),aCo=o(" \u2014 "),sG=a("a"),nCo=o("SplinterTokenizer"),sCo=o(" or "),lG=a("a"),lCo=o("SplinterTokenizerFast"),iCo=o(" (Splinter model)"),dCo=l(),ll=a("li"),phe=a("strong"),mCo=o("squeezebert"),cCo=o(" \u2014 "),iG=a("a"),fCo=o("SqueezeBertTokenizer"),gCo=o(" or "),dG=a("a"),hCo=o("SqueezeBertTokenizerFast"),uCo=o(" (SqueezeBERT model)"),pCo=l(),il=a("li"),_he=a("strong"),_Co=o("t5"),bCo=o(" \u2014 "),mG=a("a"),vCo=o("T5Tokenizer"),FCo=o(" or "),cG=a("a"),TCo=o("T5TokenizerFast"),MCo=o(" (T5 model)"),ECo=l(),xu=a("li"),bhe=a("strong"),CCo=o("tapas"),wCo=o(" \u2014 "),fG=a("a"),ACo=o("TapasTokenizer"),LCo=o(" (TAPAS model)"),yCo=l(),$u=a("li"),vhe=a("strong"),xCo=o("tapex"),$Co=o(" \u2014 "),gG=a("a"),kCo=o("TapexTokenizer"),SCo=o(" (TAPEX model)"),RCo=l(),ku=a("li"),Fhe=a("strong"),PCo=o("transfo-xl"),BCo=o(" \u2014 "),hG=a("a"),ICo=o("TransfoXLTokenizer"),NCo=o(" (Transformer-XL model)"),qCo=l(),dl=a("li"),The=a("strong"),jCo=o("vilt"),DCo=o(" \u2014 "),uG=a("a"),GCo=o("BertTokenizer"),OCo=o(" or "),pG=a("a"),VCo=o("BertTokenizerFast"),XCo=o(" (ViLT model)"),zCo=l(),ml=a("li"),Mhe=a("strong"),QCo=o("visual_bert"),WCo=o(" \u2014 "),_G=a("a"),UCo=o("BertTokenizer"),HCo=o(" or "),bG=a("a"),JCo=o("BertTokenizerFast"),YCo=o(" (VisualBERT model)"),KCo=l(),Su=a("li"),Ehe=a("strong"),ZCo=o("wav2vec2"),e3o=o(" \u2014 "),vG=a("a"),o3o=o("Wav2Vec2CTCTokenizer"),r3o=o(" (Wav2Vec2 model)"),t3o=l(),Ru=a("li"),Che=a("strong"),a3o=o("wav2vec2-conformer"),n3o=o(" \u2014 "),FG=a("a"),s3o=o("Wav2Vec2CTCTokenizer"),l3o=o(" (Wav2Vec2-Conformer model)"),i3o=l(),Pu=a("li"),whe=a("strong"),d3o=o("wav2vec2_phoneme"),m3o=o(" \u2014 "),TG=a("a"),c3o=o("Wav2Vec2PhonemeCTCTokenizer"),f3o=o(" (Wav2Vec2Phoneme model)"),g3o=l(),cl=a("li"),Ahe=a("strong"),h3o=o("xclip"),u3o=o(" \u2014 "),MG=a("a"),p3o=o("CLIPTokenizer"),_3o=o(" or "),EG=a("a"),b3o=o("CLIPTokenizerFast"),v3o=o(" (X-CLIP model)"),F3o=l(),fl=a("li"),Lhe=a("strong"),T3o=o("xglm"),M3o=o(" \u2014 "),CG=a("a"),E3o=o("XGLMTokenizer"),C3o=o(" or "),wG=a("a"),w3o=o("XGLMTokenizerFast"),A3o=o(" (XGLM model)"),L3o=l(),Bu=a("li"),yhe=a("strong"),y3o=o("xlm"),x3o=o(" \u2014 "),AG=a("a"),$3o=o("XLMTokenizer"),k3o=o(" (XLM model)"),S3o=l(),Iu=a("li"),xhe=a("strong"),R3o=o("xlm-prophetnet"),P3o=o(" \u2014 "),LG=a("a"),B3o=o("XLMProphetNetTokenizer"),I3o=o(" (XLM-ProphetNet model)"),N3o=l(),gl=a("li"),$he=a("strong"),q3o=o("xlm-roberta"),j3o=o(" \u2014 "),yG=a("a"),D3o=o("XLMRobertaTokenizer"),G3o=o(" or "),xG=a("a"),O3o=o("XLMRobertaTokenizerFast"),V3o=o(" (XLM-RoBERTa model)"),X3o=l(),hl=a("li"),khe=a("strong"),z3o=o("xlm-roberta-xl"),Q3o=o(" \u2014 "),$G=a("a"),W3o=o("XLMRobertaTokenizer"),U3o=o(" or "),kG=a("a"),H3o=o("XLMRobertaTokenizerFast"),J3o=o(" (XLM-RoBERTa-XL model)"),Y3o=l(),ul=a("li"),She=a("strong"),K3o=o("xlnet"),Z3o=o(" \u2014 "),SG=a("a"),e5o=o("XLNetTokenizer"),o5o=o(" or "),RG=a("a"),r5o=o("XLNetTokenizerFast"),t5o=o(" (XLNet model)"),a5o=l(),pl=a("li"),Rhe=a("strong"),n5o=o("yoso"),s5o=o(" \u2014 "),PG=a("a"),l5o=o("AlbertTokenizer"),i5o=o(" or "),BG=a("a"),d5o=o("AlbertTokenizerFast"),m5o=o(" (YOSO model)"),c5o=l(),F(Nu.$$.fragment),f5o=l(),qu=a("div"),F(gx.$$.fragment),g5o=l(),Phe=a("p"),h5o=o("Register a new tokenizer in this mapping."),HZe=l(),hd=a("h2"),ju=a("a"),Bhe=a("span"),F(hx.$$.fragment),u5o=l(),Ihe=a("span"),p5o=o("AutoFeatureExtractor"),JZe=l(),So=a("div"),F(ux.$$.fragment),_5o=l(),px=a("p"),b5o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),IG=a("a"),v5o=o("AutoFeatureExtractor.from_pretrained()"),F5o=o(" class method."),T5o=l(),_x=a("p"),M5o=o("This class cannot be instantiated directly using "),Nhe=a("code"),E5o=o("__init__()"),C5o=o(" (throws an error)."),w5o=l(),Ye=a("div"),F(bx.$$.fragment),A5o=l(),qhe=a("p"),L5o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),y5o=l(),Ha=a("p"),x5o=o("The feature extractor class to instantiate is selected based on the "),jhe=a("code"),$5o=o("model_type"),k5o=o(` property of the config object
(either passed as an argument or loaded from `),Dhe=a("code"),S5o=o("pretrained_model_name_or_path"),R5o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ghe=a("code"),P5o=o("pretrained_model_name_or_path"),B5o=o(":"),I5o=l(),z=a("ul"),Du=a("li"),Ohe=a("strong"),N5o=o("beit"),q5o=o(" \u2014 "),NG=a("a"),j5o=o("BeitFeatureExtractor"),D5o=o(" (BEiT model)"),G5o=l(),Gu=a("li"),Vhe=a("strong"),O5o=o("clip"),V5o=o(" \u2014 "),qG=a("a"),X5o=o("CLIPFeatureExtractor"),z5o=o(" (CLIP model)"),Q5o=l(),Ou=a("li"),Xhe=a("strong"),W5o=o("conditional_detr"),U5o=o(" \u2014 "),jG=a("a"),H5o=o("ConditionalDetrFeatureExtractor"),J5o=o(" (Conditional DETR model)"),Y5o=l(),Vu=a("li"),zhe=a("strong"),K5o=o("convnext"),Z5o=o(" \u2014 "),DG=a("a"),e0o=o("ConvNextFeatureExtractor"),o0o=o(" (ConvNeXT model)"),r0o=l(),Xu=a("li"),Qhe=a("strong"),t0o=o("cvt"),a0o=o(" \u2014 "),GG=a("a"),n0o=o("ConvNextFeatureExtractor"),s0o=o(" (CvT model)"),l0o=l(),zu=a("li"),Whe=a("strong"),i0o=o("data2vec-audio"),d0o=o(" \u2014 "),OG=a("a"),m0o=o("Wav2Vec2FeatureExtractor"),c0o=o(" (Data2VecAudio model)"),f0o=l(),Qu=a("li"),Uhe=a("strong"),g0o=o("data2vec-vision"),h0o=o(" \u2014 "),VG=a("a"),u0o=o("BeitFeatureExtractor"),p0o=o(" (Data2VecVision model)"),_0o=l(),Wu=a("li"),Hhe=a("strong"),b0o=o("deformable_detr"),v0o=o(" \u2014 "),XG=a("a"),F0o=o("DeformableDetrFeatureExtractor"),T0o=o(" (Deformable DETR model)"),M0o=l(),Uu=a("li"),Jhe=a("strong"),E0o=o("deit"),C0o=o(" \u2014 "),zG=a("a"),w0o=o("DeiTFeatureExtractor"),A0o=o(" (DeiT model)"),L0o=l(),Hu=a("li"),Yhe=a("strong"),y0o=o("detr"),x0o=o(" \u2014 "),QG=a("a"),$0o=o("DetrFeatureExtractor"),k0o=o(" (DETR model)"),S0o=l(),Ju=a("li"),Khe=a("strong"),R0o=o("donut"),P0o=o(" \u2014 "),WG=a("a"),B0o=o("DonutFeatureExtractor"),I0o=o(" (Donut model)"),N0o=l(),Yu=a("li"),Zhe=a("strong"),q0o=o("dpt"),j0o=o(" \u2014 "),UG=a("a"),D0o=o("DPTFeatureExtractor"),G0o=o(" (DPT model)"),O0o=l(),Ku=a("li"),eue=a("strong"),V0o=o("flava"),X0o=o(" \u2014 "),HG=a("a"),z0o=o("FlavaFeatureExtractor"),Q0o=o(" (FLAVA model)"),W0o=l(),Zu=a("li"),oue=a("strong"),U0o=o("glpn"),H0o=o(" \u2014 "),JG=a("a"),J0o=o("GLPNFeatureExtractor"),Y0o=o(" (GLPN model)"),K0o=l(),ep=a("li"),rue=a("strong"),Z0o=o("groupvit"),ewo=o(" \u2014 "),YG=a("a"),owo=o("CLIPFeatureExtractor"),rwo=o(" (GroupViT model)"),two=l(),op=a("li"),tue=a("strong"),awo=o("hubert"),nwo=o(" \u2014 "),KG=a("a"),swo=o("Wav2Vec2FeatureExtractor"),lwo=o(" (Hubert model)"),iwo=l(),rp=a("li"),aue=a("strong"),dwo=o("imagegpt"),mwo=o(" \u2014 "),ZG=a("a"),cwo=o("ImageGPTFeatureExtractor"),fwo=o(" (ImageGPT model)"),gwo=l(),tp=a("li"),nue=a("strong"),hwo=o("layoutlmv2"),uwo=o(" \u2014 "),eO=a("a"),pwo=o("LayoutLMv2FeatureExtractor"),_wo=o(" (LayoutLMv2 model)"),bwo=l(),ap=a("li"),sue=a("strong"),vwo=o("layoutlmv3"),Fwo=o(" \u2014 "),oO=a("a"),Two=o("LayoutLMv3FeatureExtractor"),Mwo=o(" (LayoutLMv3 model)"),Ewo=l(),np=a("li"),lue=a("strong"),Cwo=o("levit"),wwo=o(" \u2014 "),rO=a("a"),Awo=o("LevitFeatureExtractor"),Lwo=o(" (LeViT model)"),ywo=l(),sp=a("li"),iue=a("strong"),xwo=o("maskformer"),$wo=o(" \u2014 "),tO=a("a"),kwo=o("MaskFormerFeatureExtractor"),Swo=o(" (MaskFormer model)"),Rwo=l(),lp=a("li"),due=a("strong"),Pwo=o("mctct"),Bwo=o(" \u2014 "),aO=a("a"),Iwo=o("MCTCTFeatureExtractor"),Nwo=o(" (M-CTC-T model)"),qwo=l(),ip=a("li"),mue=a("strong"),jwo=o("mobilevit"),Dwo=o(" \u2014 "),nO=a("a"),Gwo=o("MobileViTFeatureExtractor"),Owo=o(" (MobileViT model)"),Vwo=l(),dp=a("li"),cue=a("strong"),Xwo=o("owlvit"),zwo=o(" \u2014 "),sO=a("a"),Qwo=o("OwlViTFeatureExtractor"),Wwo=o(" (OWL-ViT model)"),Uwo=l(),mp=a("li"),fue=a("strong"),Hwo=o("perceiver"),Jwo=o(" \u2014 "),lO=a("a"),Ywo=o("PerceiverFeatureExtractor"),Kwo=o(" (Perceiver model)"),Zwo=l(),cp=a("li"),gue=a("strong"),eAo=o("poolformer"),oAo=o(" \u2014 "),iO=a("a"),rAo=o("PoolFormerFeatureExtractor"),tAo=o(" (PoolFormer model)"),aAo=l(),fp=a("li"),hue=a("strong"),nAo=o("regnet"),sAo=o(" \u2014 "),dO=a("a"),lAo=o("ConvNextFeatureExtractor"),iAo=o(" (RegNet model)"),dAo=l(),gp=a("li"),uue=a("strong"),mAo=o("resnet"),cAo=o(" \u2014 "),mO=a("a"),fAo=o("ConvNextFeatureExtractor"),gAo=o(" (ResNet model)"),hAo=l(),hp=a("li"),pue=a("strong"),uAo=o("segformer"),pAo=o(" \u2014 "),cO=a("a"),_Ao=o("SegformerFeatureExtractor"),bAo=o(" (SegFormer model)"),vAo=l(),up=a("li"),_ue=a("strong"),FAo=o("speech_to_text"),TAo=o(" \u2014 "),fO=a("a"),MAo=o("Speech2TextFeatureExtractor"),EAo=o(" (Speech2Text model)"),CAo=l(),pp=a("li"),bue=a("strong"),wAo=o("swin"),AAo=o(" \u2014 "),gO=a("a"),LAo=o("ViTFeatureExtractor"),yAo=o(" (Swin Transformer model)"),xAo=l(),_p=a("li"),vue=a("strong"),$Ao=o("swinv2"),kAo=o(" \u2014 "),hO=a("a"),SAo=o("ViTFeatureExtractor"),RAo=o(" (Swin Transformer V2 model)"),PAo=l(),bp=a("li"),Fue=a("strong"),BAo=o("van"),IAo=o(" \u2014 "),uO=a("a"),NAo=o("ConvNextFeatureExtractor"),qAo=o(" (VAN model)"),jAo=l(),vp=a("li"),Tue=a("strong"),DAo=o("videomae"),GAo=o(" \u2014 "),pO=a("a"),OAo=o("VideoMAEFeatureExtractor"),VAo=o(" (VideoMAE model)"),XAo=l(),Fp=a("li"),Mue=a("strong"),zAo=o("vilt"),QAo=o(" \u2014 "),_O=a("a"),WAo=o("ViltFeatureExtractor"),UAo=o(" (ViLT model)"),HAo=l(),Tp=a("li"),Eue=a("strong"),JAo=o("vit"),YAo=o(" \u2014 "),bO=a("a"),KAo=o("ViTFeatureExtractor"),ZAo=o(" (ViT model)"),e6o=l(),Mp=a("li"),Cue=a("strong"),o6o=o("vit_mae"),r6o=o(" \u2014 "),vO=a("a"),t6o=o("ViTFeatureExtractor"),a6o=o(" (ViTMAE model)"),n6o=l(),Ep=a("li"),wue=a("strong"),s6o=o("vit_msn"),l6o=o(" \u2014 "),FO=a("a"),i6o=o("ViTFeatureExtractor"),d6o=o(" (ViTMSN model)"),m6o=l(),Cp=a("li"),Aue=a("strong"),c6o=o("wav2vec2"),f6o=o(" \u2014 "),TO=a("a"),g6o=o("Wav2Vec2FeatureExtractor"),h6o=o(" (Wav2Vec2 model)"),u6o=l(),wp=a("li"),Lue=a("strong"),p6o=o("wav2vec2-conformer"),_6o=o(" \u2014 "),MO=a("a"),b6o=o("Wav2Vec2FeatureExtractor"),v6o=o(" (Wav2Vec2-Conformer model)"),F6o=l(),Ap=a("li"),yue=a("strong"),T6o=o("xclip"),M6o=o(" \u2014 "),EO=a("a"),E6o=o("CLIPFeatureExtractor"),C6o=o(" (X-CLIP model)"),w6o=l(),Lp=a("li"),xue=a("strong"),A6o=o("yolos"),L6o=o(" \u2014 "),CO=a("a"),y6o=o("YolosFeatureExtractor"),x6o=o(" (YOLOS model)"),$6o=l(),F(yp.$$.fragment),k6o=l(),F(xp.$$.fragment),S6o=l(),$p=a("div"),F(vx.$$.fragment),R6o=l(),$ue=a("p"),P6o=o("Register a new feature extractor for this class."),YZe=l(),ud=a("h2"),kp=a("a"),kue=a("span"),F(Fx.$$.fragment),B6o=l(),Sue=a("span"),I6o=o("AutoProcessor"),KZe=l(),Ro=a("div"),F(Tx.$$.fragment),N6o=l(),Mx=a("p"),q6o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),wO=a("a"),j6o=o("AutoProcessor.from_pretrained()"),D6o=o(" class method."),G6o=l(),Ex=a("p"),O6o=o("This class cannot be instantiated directly using "),Rue=a("code"),V6o=o("__init__()"),X6o=o(" (throws an error)."),z6o=l(),Ke=a("div"),F(Cx.$$.fragment),Q6o=l(),Pue=a("p"),W6o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),U6o=l(),pd=a("p"),H6o=o("The processor class to instantiate is selected based on the "),Bue=a("code"),J6o=o("model_type"),Y6o=o(` property of the config object (either
passed as an argument or loaded from `),Iue=a("code"),K6o=o("pretrained_model_name_or_path"),Z6o=o(" if possible):"),e7o=l(),le=a("ul"),Sp=a("li"),Nue=a("strong"),o7o=o("clip"),r7o=o(" \u2014 "),AO=a("a"),t7o=o("CLIPProcessor"),a7o=o(" (CLIP model)"),n7o=l(),Rp=a("li"),que=a("strong"),s7o=o("donut"),l7o=o(" \u2014 "),LO=a("a"),i7o=o("DonutProcessor"),d7o=o(" (Donut model)"),m7o=l(),Pp=a("li"),jue=a("strong"),c7o=o("flava"),f7o=o(" \u2014 "),yO=a("a"),g7o=o("FlavaProcessor"),h7o=o(" (FLAVA model)"),u7o=l(),Bp=a("li"),Due=a("strong"),p7o=o("groupvit"),_7o=o(" \u2014 "),xO=a("a"),b7o=o("CLIPProcessor"),v7o=o(" (GroupViT model)"),F7o=l(),Ip=a("li"),Gue=a("strong"),T7o=o("layoutlmv2"),M7o=o(" \u2014 "),$O=a("a"),E7o=o("LayoutLMv2Processor"),C7o=o(" (LayoutLMv2 model)"),w7o=l(),Np=a("li"),Oue=a("strong"),A7o=o("layoutlmv3"),L7o=o(" \u2014 "),kO=a("a"),y7o=o("LayoutLMv3Processor"),x7o=o(" (LayoutLMv3 model)"),$7o=l(),qp=a("li"),Vue=a("strong"),k7o=o("layoutxlm"),S7o=o(" \u2014 "),SO=a("a"),R7o=o("LayoutXLMProcessor"),P7o=o(" (LayoutXLM model)"),B7o=l(),jp=a("li"),Xue=a("strong"),I7o=o("markuplm"),N7o=o(" \u2014 "),RO=a("a"),q7o=o("MarkupLMProcessor"),j7o=o(" (MarkupLM model)"),D7o=l(),Dp=a("li"),zue=a("strong"),G7o=o("owlvit"),O7o=o(" \u2014 "),PO=a("a"),V7o=o("OwlViTProcessor"),X7o=o(" (OWL-ViT model)"),z7o=l(),Gp=a("li"),Que=a("strong"),Q7o=o("sew"),W7o=o(" \u2014 "),BO=a("a"),U7o=o("Wav2Vec2Processor"),H7o=o(" (SEW model)"),J7o=l(),Op=a("li"),Wue=a("strong"),Y7o=o("sew-d"),K7o=o(" \u2014 "),IO=a("a"),Z7o=o("Wav2Vec2Processor"),eLo=o(" (SEW-D model)"),oLo=l(),Vp=a("li"),Uue=a("strong"),rLo=o("speech_to_text"),tLo=o(" \u2014 "),NO=a("a"),aLo=o("Speech2TextProcessor"),nLo=o(" (Speech2Text model)"),sLo=l(),Xp=a("li"),Hue=a("strong"),lLo=o("speech_to_text_2"),iLo=o(" \u2014 "),qO=a("a"),dLo=o("Speech2Text2Processor"),mLo=o(" (Speech2Text2 model)"),cLo=l(),zp=a("li"),Jue=a("strong"),fLo=o("trocr"),gLo=o(" \u2014 "),jO=a("a"),hLo=o("TrOCRProcessor"),uLo=o(" (TrOCR model)"),pLo=l(),Qp=a("li"),Yue=a("strong"),_Lo=o("unispeech"),bLo=o(" \u2014 "),DO=a("a"),vLo=o("Wav2Vec2Processor"),FLo=o(" (UniSpeech model)"),TLo=l(),Wp=a("li"),Kue=a("strong"),MLo=o("unispeech-sat"),ELo=o(" \u2014 "),GO=a("a"),CLo=o("Wav2Vec2Processor"),wLo=o(" (UniSpeechSat model)"),ALo=l(),Up=a("li"),Zue=a("strong"),LLo=o("vilt"),yLo=o(" \u2014 "),OO=a("a"),xLo=o("ViltProcessor"),$Lo=o(" (ViLT model)"),kLo=l(),Hp=a("li"),epe=a("strong"),SLo=o("vision-text-dual-encoder"),RLo=o(" \u2014 "),VO=a("a"),PLo=o("VisionTextDualEncoderProcessor"),BLo=o(" (VisionTextDualEncoder model)"),ILo=l(),Jp=a("li"),ope=a("strong"),NLo=o("wav2vec2"),qLo=o(" \u2014 "),XO=a("a"),jLo=o("Wav2Vec2Processor"),DLo=o(" (Wav2Vec2 model)"),GLo=l(),Yp=a("li"),rpe=a("strong"),OLo=o("wav2vec2-conformer"),VLo=o(" \u2014 "),zO=a("a"),XLo=o("Wav2Vec2Processor"),zLo=o(" (Wav2Vec2-Conformer model)"),QLo=l(),Kp=a("li"),tpe=a("strong"),WLo=o("wavlm"),ULo=o(" \u2014 "),QO=a("a"),HLo=o("Wav2Vec2Processor"),JLo=o(" (WavLM model)"),YLo=l(),Zp=a("li"),ape=a("strong"),KLo=o("xclip"),ZLo=o(" \u2014 "),WO=a("a"),eyo=o("CLIPProcessor"),oyo=o(" (X-CLIP model)"),ryo=l(),F(e_.$$.fragment),tyo=l(),F(o_.$$.fragment),ayo=l(),r_=a("div"),F(wx.$$.fragment),nyo=l(),npe=a("p"),syo=o("Register a new processor for this class."),ZZe=l(),_d=a("h2"),t_=a("a"),spe=a("span"),F(Ax.$$.fragment),lyo=l(),lpe=a("span"),iyo=o("AutoModel"),eeo=l(),Po=a("div"),F(Lx.$$.fragment),dyo=l(),bd=a("p"),myo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),UO=a("a"),cyo=o("from_pretrained()"),fyo=o(" class method or the "),HO=a("a"),gyo=o("from_config()"),hyo=o(` class
method.`),uyo=l(),yx=a("p"),pyo=o("This class cannot be instantiated directly using "),ipe=a("code"),_yo=o("__init__()"),byo=o(" (throws an error)."),vyo=l(),_t=a("div"),F(xx.$$.fragment),Fyo=l(),dpe=a("p"),Tyo=o("Instantiates one of the base model classes of the library from a configuration."),Myo=l(),vd=a("p"),Eyo=o(`Note:
Loading a model from its configuration file does `),mpe=a("strong"),Cyo=o("not"),wyo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JO=a("a"),Ayo=o("from_pretrained()"),Lyo=o(" to load the model weights."),yyo=l(),F(a_.$$.fragment),xyo=l(),Ze=a("div"),F($x.$$.fragment),$yo=l(),cpe=a("p"),kyo=o("Instantiate one of the base model classes of the library from a pretrained model."),Syo=l(),Ja=a("p"),Ryo=o("The model class to instantiate is selected based on the "),fpe=a("code"),Pyo=o("model_type"),Byo=o(` property of the config object (either
passed as an argument or loaded from `),gpe=a("code"),Iyo=o("pretrained_model_name_or_path"),Nyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hpe=a("code"),qyo=o("pretrained_model_name_or_path"),jyo=o(":"),Dyo=l(),y=a("ul"),n_=a("li"),upe=a("strong"),Gyo=o("albert"),Oyo=o(" \u2014 "),YO=a("a"),Vyo=o("AlbertModel"),Xyo=o(" (ALBERT model)"),zyo=l(),s_=a("li"),ppe=a("strong"),Qyo=o("bart"),Wyo=o(" \u2014 "),KO=a("a"),Uyo=o("BartModel"),Hyo=o(" (BART model)"),Jyo=l(),l_=a("li"),_pe=a("strong"),Yyo=o("beit"),Kyo=o(" \u2014 "),ZO=a("a"),Zyo=o("BeitModel"),e8o=o(" (BEiT model)"),o8o=l(),i_=a("li"),bpe=a("strong"),r8o=o("bert"),t8o=o(" \u2014 "),eV=a("a"),a8o=o("BertModel"),n8o=o(" (BERT model)"),s8o=l(),d_=a("li"),vpe=a("strong"),l8o=o("bert-generation"),i8o=o(" \u2014 "),oV=a("a"),d8o=o("BertGenerationEncoder"),m8o=o(" (Bert Generation model)"),c8o=l(),m_=a("li"),Fpe=a("strong"),f8o=o("big_bird"),g8o=o(" \u2014 "),rV=a("a"),h8o=o("BigBirdModel"),u8o=o(" (BigBird model)"),p8o=l(),c_=a("li"),Tpe=a("strong"),_8o=o("bigbird_pegasus"),b8o=o(" \u2014 "),tV=a("a"),v8o=o("BigBirdPegasusModel"),F8o=o(" (BigBird-Pegasus model)"),T8o=l(),f_=a("li"),Mpe=a("strong"),M8o=o("blenderbot"),E8o=o(" \u2014 "),aV=a("a"),C8o=o("BlenderbotModel"),w8o=o(" (Blenderbot model)"),A8o=l(),g_=a("li"),Epe=a("strong"),L8o=o("blenderbot-small"),y8o=o(" \u2014 "),nV=a("a"),x8o=o("BlenderbotSmallModel"),$8o=o(" (BlenderbotSmall model)"),k8o=l(),h_=a("li"),Cpe=a("strong"),S8o=o("bloom"),R8o=o(" \u2014 "),sV=a("a"),P8o=o("BloomModel"),B8o=o(" (BLOOM model)"),I8o=l(),u_=a("li"),wpe=a("strong"),N8o=o("camembert"),q8o=o(" \u2014 "),lV=a("a"),j8o=o("CamembertModel"),D8o=o(" (CamemBERT model)"),G8o=l(),p_=a("li"),Ape=a("strong"),O8o=o("canine"),V8o=o(" \u2014 "),iV=a("a"),X8o=o("CanineModel"),z8o=o(" (CANINE model)"),Q8o=l(),__=a("li"),Lpe=a("strong"),W8o=o("clip"),U8o=o(" \u2014 "),dV=a("a"),H8o=o("CLIPModel"),J8o=o(" (CLIP model)"),Y8o=l(),b_=a("li"),ype=a("strong"),K8o=o("codegen"),Z8o=o(" \u2014 "),mV=a("a"),e9o=o("CodeGenModel"),o9o=o(" (CodeGen model)"),r9o=l(),v_=a("li"),xpe=a("strong"),t9o=o("conditional_detr"),a9o=o(" \u2014 "),cV=a("a"),n9o=o("ConditionalDetrModel"),s9o=o(" (Conditional DETR model)"),l9o=l(),F_=a("li"),$pe=a("strong"),i9o=o("convbert"),d9o=o(" \u2014 "),fV=a("a"),m9o=o("ConvBertModel"),c9o=o(" (ConvBERT model)"),f9o=l(),T_=a("li"),kpe=a("strong"),g9o=o("convnext"),h9o=o(" \u2014 "),gV=a("a"),u9o=o("ConvNextModel"),p9o=o(" (ConvNeXT model)"),_9o=l(),M_=a("li"),Spe=a("strong"),b9o=o("ctrl"),v9o=o(" \u2014 "),hV=a("a"),F9o=o("CTRLModel"),T9o=o(" (CTRL model)"),M9o=l(),E_=a("li"),Rpe=a("strong"),E9o=o("cvt"),C9o=o(" \u2014 "),uV=a("a"),w9o=o("CvtModel"),A9o=o(" (CvT model)"),L9o=l(),C_=a("li"),Ppe=a("strong"),y9o=o("data2vec-audio"),x9o=o(" \u2014 "),pV=a("a"),$9o=o("Data2VecAudioModel"),k9o=o(" (Data2VecAudio model)"),S9o=l(),w_=a("li"),Bpe=a("strong"),R9o=o("data2vec-text"),P9o=o(" \u2014 "),_V=a("a"),B9o=o("Data2VecTextModel"),I9o=o(" (Data2VecText model)"),N9o=l(),A_=a("li"),Ipe=a("strong"),q9o=o("data2vec-vision"),j9o=o(" \u2014 "),bV=a("a"),D9o=o("Data2VecVisionModel"),G9o=o(" (Data2VecVision model)"),O9o=l(),L_=a("li"),Npe=a("strong"),V9o=o("deberta"),X9o=o(" \u2014 "),vV=a("a"),z9o=o("DebertaModel"),Q9o=o(" (DeBERTa model)"),W9o=l(),y_=a("li"),qpe=a("strong"),U9o=o("deberta-v2"),H9o=o(" \u2014 "),FV=a("a"),J9o=o("DebertaV2Model"),Y9o=o(" (DeBERTa-v2 model)"),K9o=l(),x_=a("li"),jpe=a("strong"),Z9o=o("decision_transformer"),exo=o(" \u2014 "),TV=a("a"),oxo=o("DecisionTransformerModel"),rxo=o(" (Decision Transformer model)"),txo=l(),$_=a("li"),Dpe=a("strong"),axo=o("deformable_detr"),nxo=o(" \u2014 "),MV=a("a"),sxo=o("DeformableDetrModel"),lxo=o(" (Deformable DETR model)"),ixo=l(),k_=a("li"),Gpe=a("strong"),dxo=o("deit"),mxo=o(" \u2014 "),EV=a("a"),cxo=o("DeiTModel"),fxo=o(" (DeiT model)"),gxo=l(),S_=a("li"),Ope=a("strong"),hxo=o("detr"),uxo=o(" \u2014 "),CV=a("a"),pxo=o("DetrModel"),_xo=o(" (DETR model)"),bxo=l(),R_=a("li"),Vpe=a("strong"),vxo=o("distilbert"),Fxo=o(" \u2014 "),wV=a("a"),Txo=o("DistilBertModel"),Mxo=o(" (DistilBERT model)"),Exo=l(),P_=a("li"),Xpe=a("strong"),Cxo=o("donut-swin"),wxo=o(" \u2014 "),AV=a("a"),Axo=o("DonutSwinModel"),Lxo=o(" (DonutSwin model)"),yxo=l(),B_=a("li"),zpe=a("strong"),xxo=o("dpr"),$xo=o(" \u2014 "),LV=a("a"),kxo=o("DPRQuestionEncoder"),Sxo=o(" (DPR model)"),Rxo=l(),I_=a("li"),Qpe=a("strong"),Pxo=o("dpt"),Bxo=o(" \u2014 "),yV=a("a"),Ixo=o("DPTModel"),Nxo=o(" (DPT model)"),qxo=l(),N_=a("li"),Wpe=a("strong"),jxo=o("electra"),Dxo=o(" \u2014 "),xV=a("a"),Gxo=o("ElectraModel"),Oxo=o(" (ELECTRA model)"),Vxo=l(),q_=a("li"),Upe=a("strong"),Xxo=o("ernie"),zxo=o(" \u2014 "),$V=a("a"),Qxo=o("ErnieModel"),Wxo=o(" (ERNIE model)"),Uxo=l(),j_=a("li"),Hpe=a("strong"),Hxo=o("esm"),Jxo=o(" \u2014 "),kV=a("a"),Yxo=o("EsmModel"),Kxo=o(" (ESM model)"),Zxo=l(),D_=a("li"),Jpe=a("strong"),e$o=o("flaubert"),o$o=o(" \u2014 "),SV=a("a"),r$o=o("FlaubertModel"),t$o=o(" (FlauBERT model)"),a$o=l(),G_=a("li"),Ype=a("strong"),n$o=o("flava"),s$o=o(" \u2014 "),RV=a("a"),l$o=o("FlavaModel"),i$o=o(" (FLAVA model)"),d$o=l(),O_=a("li"),Kpe=a("strong"),m$o=o("fnet"),c$o=o(" \u2014 "),PV=a("a"),f$o=o("FNetModel"),g$o=o(" (FNet model)"),h$o=l(),V_=a("li"),Zpe=a("strong"),u$o=o("fsmt"),p$o=o(" \u2014 "),BV=a("a"),_$o=o("FSMTModel"),b$o=o(" (FairSeq Machine-Translation model)"),v$o=l(),_l=a("li"),e_e=a("strong"),F$o=o("funnel"),T$o=o(" \u2014 "),IV=a("a"),M$o=o("FunnelModel"),E$o=o(" or "),NV=a("a"),C$o=o("FunnelBaseModel"),w$o=o(" (Funnel Transformer model)"),A$o=l(),X_=a("li"),o_e=a("strong"),L$o=o("glpn"),y$o=o(" \u2014 "),qV=a("a"),x$o=o("GLPNModel"),$$o=o(" (GLPN model)"),k$o=l(),z_=a("li"),r_e=a("strong"),S$o=o("gpt2"),R$o=o(" \u2014 "),jV=a("a"),P$o=o("GPT2Model"),B$o=o(" (OpenAI GPT-2 model)"),I$o=l(),Q_=a("li"),t_e=a("strong"),N$o=o("gpt_neo"),q$o=o(" \u2014 "),DV=a("a"),j$o=o("GPTNeoModel"),D$o=o(" (GPT Neo model)"),G$o=l(),W_=a("li"),a_e=a("strong"),O$o=o("gpt_neox"),V$o=o(" \u2014 "),GV=a("a"),X$o=o("GPTNeoXModel"),z$o=o(" (GPT NeoX model)"),Q$o=l(),U_=a("li"),n_e=a("strong"),W$o=o("gpt_neox_japanese"),U$o=o(" \u2014 "),OV=a("a"),H$o=o("GPTNeoXJapaneseModel"),J$o=o(" (GPT NeoX Japanese model)"),Y$o=l(),H_=a("li"),s_e=a("strong"),K$o=o("gptj"),Z$o=o(" \u2014 "),VV=a("a"),eko=o("GPTJModel"),oko=o(" (GPT-J model)"),rko=l(),J_=a("li"),l_e=a("strong"),tko=o("groupvit"),ako=o(" \u2014 "),XV=a("a"),nko=o("GroupViTModel"),sko=o(" (GroupViT model)"),lko=l(),Y_=a("li"),i_e=a("strong"),iko=o("hubert"),dko=o(" \u2014 "),zV=a("a"),mko=o("HubertModel"),cko=o(" (Hubert model)"),fko=l(),K_=a("li"),d_e=a("strong"),gko=o("ibert"),hko=o(" \u2014 "),QV=a("a"),uko=o("IBertModel"),pko=o(" (I-BERT model)"),_ko=l(),Z_=a("li"),m_e=a("strong"),bko=o("imagegpt"),vko=o(" \u2014 "),WV=a("a"),Fko=o("ImageGPTModel"),Tko=o(" (ImageGPT model)"),Mko=l(),e2=a("li"),c_e=a("strong"),Eko=o("layoutlm"),Cko=o(" \u2014 "),UV=a("a"),wko=o("LayoutLMModel"),Ako=o(" (LayoutLM model)"),Lko=l(),o2=a("li"),f_e=a("strong"),yko=o("layoutlmv2"),xko=o(" \u2014 "),HV=a("a"),$ko=o("LayoutLMv2Model"),kko=o(" (LayoutLMv2 model)"),Sko=l(),r2=a("li"),g_e=a("strong"),Rko=o("layoutlmv3"),Pko=o(" \u2014 "),JV=a("a"),Bko=o("LayoutLMv3Model"),Iko=o(" (LayoutLMv3 model)"),Nko=l(),t2=a("li"),h_e=a("strong"),qko=o("led"),jko=o(" \u2014 "),YV=a("a"),Dko=o("LEDModel"),Gko=o(" (LED model)"),Oko=l(),a2=a("li"),u_e=a("strong"),Vko=o("levit"),Xko=o(" \u2014 "),KV=a("a"),zko=o("LevitModel"),Qko=o(" (LeViT model)"),Wko=l(),n2=a("li"),p_e=a("strong"),Uko=o("longformer"),Hko=o(" \u2014 "),ZV=a("a"),Jko=o("LongformerModel"),Yko=o(" (Longformer model)"),Kko=l(),s2=a("li"),__e=a("strong"),Zko=o("longt5"),eSo=o(" \u2014 "),eX=a("a"),oSo=o("LongT5Model"),rSo=o(" (LongT5 model)"),tSo=l(),l2=a("li"),b_e=a("strong"),aSo=o("luke"),nSo=o(" \u2014 "),oX=a("a"),sSo=o("LukeModel"),lSo=o(" (LUKE model)"),iSo=l(),i2=a("li"),v_e=a("strong"),dSo=o("lxmert"),mSo=o(" \u2014 "),rX=a("a"),cSo=o("LxmertModel"),fSo=o(" (LXMERT model)"),gSo=l(),d2=a("li"),F_e=a("strong"),hSo=o("m2m_100"),uSo=o(" \u2014 "),tX=a("a"),pSo=o("M2M100Model"),_So=o(" (M2M100 model)"),bSo=l(),m2=a("li"),T_e=a("strong"),vSo=o("marian"),FSo=o(" \u2014 "),aX=a("a"),TSo=o("MarianModel"),MSo=o(" (Marian model)"),ESo=l(),c2=a("li"),M_e=a("strong"),CSo=o("markuplm"),wSo=o(" \u2014 "),nX=a("a"),ASo=o("MarkupLMModel"),LSo=o(" (MarkupLM model)"),ySo=l(),f2=a("li"),E_e=a("strong"),xSo=o("maskformer"),$So=o(" \u2014 "),sX=a("a"),kSo=o("MaskFormerModel"),SSo=o(" (MaskFormer model)"),RSo=l(),g2=a("li"),C_e=a("strong"),PSo=o("mbart"),BSo=o(" \u2014 "),lX=a("a"),ISo=o("MBartModel"),NSo=o(" (mBART model)"),qSo=l(),h2=a("li"),w_e=a("strong"),jSo=o("mctct"),DSo=o(" \u2014 "),iX=a("a"),GSo=o("MCTCTModel"),OSo=o(" (M-CTC-T model)"),VSo=l(),u2=a("li"),A_e=a("strong"),XSo=o("megatron-bert"),zSo=o(" \u2014 "),dX=a("a"),QSo=o("MegatronBertModel"),WSo=o(" (Megatron-BERT model)"),USo=l(),p2=a("li"),L_e=a("strong"),HSo=o("mobilebert"),JSo=o(" \u2014 "),mX=a("a"),YSo=o("MobileBertModel"),KSo=o(" (MobileBERT model)"),ZSo=l(),_2=a("li"),y_e=a("strong"),eRo=o("mobilevit"),oRo=o(" \u2014 "),cX=a("a"),rRo=o("MobileViTModel"),tRo=o(" (MobileViT model)"),aRo=l(),b2=a("li"),x_e=a("strong"),nRo=o("mpnet"),sRo=o(" \u2014 "),fX=a("a"),lRo=o("MPNetModel"),iRo=o(" (MPNet model)"),dRo=l(),v2=a("li"),$_e=a("strong"),mRo=o("mt5"),cRo=o(" \u2014 "),gX=a("a"),fRo=o("MT5Model"),gRo=o(" (MT5 model)"),hRo=l(),F2=a("li"),k_e=a("strong"),uRo=o("mvp"),pRo=o(" \u2014 "),hX=a("a"),_Ro=o("MvpModel"),bRo=o(" (MVP model)"),vRo=l(),T2=a("li"),S_e=a("strong"),FRo=o("nezha"),TRo=o(" \u2014 "),uX=a("a"),MRo=o("NezhaModel"),ERo=o(" (Nezha model)"),CRo=l(),M2=a("li"),R_e=a("strong"),wRo=o("nllb"),ARo=o(" \u2014 "),pX=a("a"),LRo=o("M2M100Model"),yRo=o(" (NLLB model)"),xRo=l(),E2=a("li"),P_e=a("strong"),$Ro=o("nystromformer"),kRo=o(" \u2014 "),_X=a("a"),SRo=o("NystromformerModel"),RRo=o(" (Nystr\xF6mformer model)"),PRo=l(),C2=a("li"),B_e=a("strong"),BRo=o("openai-gpt"),IRo=o(" \u2014 "),bX=a("a"),NRo=o("OpenAIGPTModel"),qRo=o(" (OpenAI GPT model)"),jRo=l(),w2=a("li"),I_e=a("strong"),DRo=o("opt"),GRo=o(" \u2014 "),vX=a("a"),ORo=o("OPTModel"),VRo=o(" (OPT model)"),XRo=l(),A2=a("li"),N_e=a("strong"),zRo=o("owlvit"),QRo=o(" \u2014 "),FX=a("a"),WRo=o("OwlViTModel"),URo=o(" (OWL-ViT model)"),HRo=l(),L2=a("li"),q_e=a("strong"),JRo=o("pegasus"),YRo=o(" \u2014 "),TX=a("a"),KRo=o("PegasusModel"),ZRo=o(" (Pegasus model)"),ePo=l(),y2=a("li"),j_e=a("strong"),oPo=o("pegasus_x"),rPo=o(" \u2014 "),MX=a("a"),tPo=o("PegasusXModel"),aPo=o(" (PEGASUS-X model)"),nPo=l(),x2=a("li"),D_e=a("strong"),sPo=o("perceiver"),lPo=o(" \u2014 "),EX=a("a"),iPo=o("PerceiverModel"),dPo=o(" (Perceiver model)"),mPo=l(),$2=a("li"),G_e=a("strong"),cPo=o("plbart"),fPo=o(" \u2014 "),CX=a("a"),gPo=o("PLBartModel"),hPo=o(" (PLBart model)"),uPo=l(),k2=a("li"),O_e=a("strong"),pPo=o("poolformer"),_Po=o(" \u2014 "),wX=a("a"),bPo=o("PoolFormerModel"),vPo=o(" (PoolFormer model)"),FPo=l(),S2=a("li"),V_e=a("strong"),TPo=o("prophetnet"),MPo=o(" \u2014 "),AX=a("a"),EPo=o("ProphetNetModel"),CPo=o(" (ProphetNet model)"),wPo=l(),R2=a("li"),X_e=a("strong"),APo=o("qdqbert"),LPo=o(" \u2014 "),LX=a("a"),yPo=o("QDQBertModel"),xPo=o(" (QDQBert model)"),$Po=l(),P2=a("li"),z_e=a("strong"),kPo=o("reformer"),SPo=o(" \u2014 "),yX=a("a"),RPo=o("ReformerModel"),PPo=o(" (Reformer model)"),BPo=l(),B2=a("li"),Q_e=a("strong"),IPo=o("regnet"),NPo=o(" \u2014 "),xX=a("a"),qPo=o("RegNetModel"),jPo=o(" (RegNet model)"),DPo=l(),I2=a("li"),W_e=a("strong"),GPo=o("rembert"),OPo=o(" \u2014 "),$X=a("a"),VPo=o("RemBertModel"),XPo=o(" (RemBERT model)"),zPo=l(),N2=a("li"),U_e=a("strong"),QPo=o("resnet"),WPo=o(" \u2014 "),kX=a("a"),UPo=o("ResNetModel"),HPo=o(" (ResNet model)"),JPo=l(),q2=a("li"),H_e=a("strong"),YPo=o("retribert"),KPo=o(" \u2014 "),SX=a("a"),ZPo=o("RetriBertModel"),eBo=o(" (RetriBERT model)"),oBo=l(),j2=a("li"),J_e=a("strong"),rBo=o("roberta"),tBo=o(" \u2014 "),RX=a("a"),aBo=o("RobertaModel"),nBo=o(" (RoBERTa model)"),sBo=l(),D2=a("li"),Y_e=a("strong"),lBo=o("roformer"),iBo=o(" \u2014 "),PX=a("a"),dBo=o("RoFormerModel"),mBo=o(" (RoFormer model)"),cBo=l(),G2=a("li"),K_e=a("strong"),fBo=o("segformer"),gBo=o(" \u2014 "),BX=a("a"),hBo=o("SegformerModel"),uBo=o(" (SegFormer model)"),pBo=l(),O2=a("li"),Z_e=a("strong"),_Bo=o("sew"),bBo=o(" \u2014 "),IX=a("a"),vBo=o("SEWModel"),FBo=o(" (SEW model)"),TBo=l(),V2=a("li"),e2e=a("strong"),MBo=o("sew-d"),EBo=o(" \u2014 "),NX=a("a"),CBo=o("SEWDModel"),wBo=o(" (SEW-D model)"),ABo=l(),X2=a("li"),o2e=a("strong"),LBo=o("speech_to_text"),yBo=o(" \u2014 "),qX=a("a"),xBo=o("Speech2TextModel"),$Bo=o(" (Speech2Text model)"),kBo=l(),z2=a("li"),r2e=a("strong"),SBo=o("splinter"),RBo=o(" \u2014 "),jX=a("a"),PBo=o("SplinterModel"),BBo=o(" (Splinter model)"),IBo=l(),Q2=a("li"),t2e=a("strong"),NBo=o("squeezebert"),qBo=o(" \u2014 "),DX=a("a"),jBo=o("SqueezeBertModel"),DBo=o(" (SqueezeBERT model)"),GBo=l(),W2=a("li"),a2e=a("strong"),OBo=o("swin"),VBo=o(" \u2014 "),GX=a("a"),XBo=o("SwinModel"),zBo=o(" (Swin Transformer model)"),QBo=l(),U2=a("li"),n2e=a("strong"),WBo=o("swinv2"),UBo=o(" \u2014 "),OX=a("a"),HBo=o("Swinv2Model"),JBo=o(" (Swin Transformer V2 model)"),YBo=l(),H2=a("li"),s2e=a("strong"),KBo=o("t5"),ZBo=o(" \u2014 "),VX=a("a"),eIo=o("T5Model"),oIo=o(" (T5 model)"),rIo=l(),J2=a("li"),l2e=a("strong"),tIo=o("tapas"),aIo=o(" \u2014 "),XX=a("a"),nIo=o("TapasModel"),sIo=o(" (TAPAS model)"),lIo=l(),Y2=a("li"),i2e=a("strong"),iIo=o("time_series_transformer"),dIo=o(" \u2014 "),zX=a("a"),mIo=o("TimeSeriesTransformerModel"),cIo=o(" (Time Series Transformer model)"),fIo=l(),K2=a("li"),d2e=a("strong"),gIo=o("trajectory_transformer"),hIo=o(" \u2014 "),QX=a("a"),uIo=o("TrajectoryTransformerModel"),pIo=o(" (Trajectory Transformer model)"),_Io=l(),Z2=a("li"),m2e=a("strong"),bIo=o("transfo-xl"),vIo=o(" \u2014 "),WX=a("a"),FIo=o("TransfoXLModel"),TIo=o(" (Transformer-XL model)"),MIo=l(),e1=a("li"),c2e=a("strong"),EIo=o("unispeech"),CIo=o(" \u2014 "),UX=a("a"),wIo=o("UniSpeechModel"),AIo=o(" (UniSpeech model)"),LIo=l(),o1=a("li"),f2e=a("strong"),yIo=o("unispeech-sat"),xIo=o(" \u2014 "),HX=a("a"),$Io=o("UniSpeechSatModel"),kIo=o(" (UniSpeechSat model)"),SIo=l(),r1=a("li"),g2e=a("strong"),RIo=o("van"),PIo=o(" \u2014 "),JX=a("a"),BIo=o("VanModel"),IIo=o(" (VAN model)"),NIo=l(),t1=a("li"),h2e=a("strong"),qIo=o("videomae"),jIo=o(" \u2014 "),YX=a("a"),DIo=o("VideoMAEModel"),GIo=o(" (VideoMAE model)"),OIo=l(),a1=a("li"),u2e=a("strong"),VIo=o("vilt"),XIo=o(" \u2014 "),KX=a("a"),zIo=o("ViltModel"),QIo=o(" (ViLT model)"),WIo=l(),n1=a("li"),p2e=a("strong"),UIo=o("vision-text-dual-encoder"),HIo=o(" \u2014 "),ZX=a("a"),JIo=o("VisionTextDualEncoderModel"),YIo=o(" (VisionTextDualEncoder model)"),KIo=l(),s1=a("li"),_2e=a("strong"),ZIo=o("visual_bert"),eNo=o(" \u2014 "),ez=a("a"),oNo=o("VisualBertModel"),rNo=o(" (VisualBERT model)"),tNo=l(),l1=a("li"),b2e=a("strong"),aNo=o("vit"),nNo=o(" \u2014 "),oz=a("a"),sNo=o("ViTModel"),lNo=o(" (ViT model)"),iNo=l(),i1=a("li"),v2e=a("strong"),dNo=o("vit_mae"),mNo=o(" \u2014 "),rz=a("a"),cNo=o("ViTMAEModel"),fNo=o(" (ViTMAE model)"),gNo=l(),d1=a("li"),F2e=a("strong"),hNo=o("vit_msn"),uNo=o(" \u2014 "),tz=a("a"),pNo=o("ViTMSNModel"),_No=o(" (ViTMSN model)"),bNo=l(),m1=a("li"),T2e=a("strong"),vNo=o("wav2vec2"),FNo=o(" \u2014 "),az=a("a"),TNo=o("Wav2Vec2Model"),MNo=o(" (Wav2Vec2 model)"),ENo=l(),c1=a("li"),M2e=a("strong"),CNo=o("wav2vec2-conformer"),wNo=o(" \u2014 "),nz=a("a"),ANo=o("Wav2Vec2ConformerModel"),LNo=o(" (Wav2Vec2-Conformer model)"),yNo=l(),f1=a("li"),E2e=a("strong"),xNo=o("wavlm"),$No=o(" \u2014 "),sz=a("a"),kNo=o("WavLMModel"),SNo=o(" (WavLM model)"),RNo=l(),g1=a("li"),C2e=a("strong"),PNo=o("xclip"),BNo=o(" \u2014 "),lz=a("a"),INo=o("XCLIPModel"),NNo=o(" (X-CLIP model)"),qNo=l(),h1=a("li"),w2e=a("strong"),jNo=o("xglm"),DNo=o(" \u2014 "),iz=a("a"),GNo=o("XGLMModel"),ONo=o(" (XGLM model)"),VNo=l(),u1=a("li"),A2e=a("strong"),XNo=o("xlm"),zNo=o(" \u2014 "),dz=a("a"),QNo=o("XLMModel"),WNo=o(" (XLM model)"),UNo=l(),p1=a("li"),L2e=a("strong"),HNo=o("xlm-prophetnet"),JNo=o(" \u2014 "),mz=a("a"),YNo=o("XLMProphetNetModel"),KNo=o(" (XLM-ProphetNet model)"),ZNo=l(),_1=a("li"),y2e=a("strong"),eqo=o("xlm-roberta"),oqo=o(" \u2014 "),cz=a("a"),rqo=o("XLMRobertaModel"),tqo=o(" (XLM-RoBERTa model)"),aqo=l(),b1=a("li"),x2e=a("strong"),nqo=o("xlm-roberta-xl"),sqo=o(" \u2014 "),fz=a("a"),lqo=o("XLMRobertaXLModel"),iqo=o(" (XLM-RoBERTa-XL model)"),dqo=l(),v1=a("li"),$2e=a("strong"),mqo=o("xlnet"),cqo=o(" \u2014 "),gz=a("a"),fqo=o("XLNetModel"),gqo=o(" (XLNet model)"),hqo=l(),F1=a("li"),k2e=a("strong"),uqo=o("yolos"),pqo=o(" \u2014 "),hz=a("a"),_qo=o("YolosModel"),bqo=o(" (YOLOS model)"),vqo=l(),T1=a("li"),S2e=a("strong"),Fqo=o("yoso"),Tqo=o(" \u2014 "),uz=a("a"),Mqo=o("YosoModel"),Eqo=o(" (YOSO model)"),Cqo=l(),M1=a("p"),wqo=o("The model is set in evaluation mode by default using "),R2e=a("code"),Aqo=o("model.eval()"),Lqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=a("code"),yqo=o("model.train()"),xqo=l(),F(E1.$$.fragment),oeo=l(),Fd=a("h2"),C1=a("a"),B2e=a("span"),F(kx.$$.fragment),$qo=l(),I2e=a("span"),kqo=o("AutoModelForPreTraining"),reo=l(),Bo=a("div"),F(Sx.$$.fragment),Sqo=l(),Td=a("p"),Rqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pz=a("a"),Pqo=o("from_pretrained()"),Bqo=o(" class method or the "),_z=a("a"),Iqo=o("from_config()"),Nqo=o(` class
method.`),qqo=l(),Rx=a("p"),jqo=o("This class cannot be instantiated directly using "),N2e=a("code"),Dqo=o("__init__()"),Gqo=o(" (throws an error)."),Oqo=l(),bt=a("div"),F(Px.$$.fragment),Vqo=l(),q2e=a("p"),Xqo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),zqo=l(),Md=a("p"),Qqo=o(`Note:
Loading a model from its configuration file does `),j2e=a("strong"),Wqo=o("not"),Uqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bz=a("a"),Hqo=o("from_pretrained()"),Jqo=o(" to load the model weights."),Yqo=l(),F(w1.$$.fragment),Kqo=l(),eo=a("div"),F(Bx.$$.fragment),Zqo=l(),D2e=a("p"),ejo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ojo=l(),Ya=a("p"),rjo=o("The model class to instantiate is selected based on the "),G2e=a("code"),tjo=o("model_type"),ajo=o(` property of the config object (either
passed as an argument or loaded from `),O2e=a("code"),njo=o("pretrained_model_name_or_path"),sjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=a("code"),ljo=o("pretrained_model_name_or_path"),ijo=o(":"),djo=l(),G=a("ul"),A1=a("li"),X2e=a("strong"),mjo=o("albert"),cjo=o(" \u2014 "),vz=a("a"),fjo=o("AlbertForPreTraining"),gjo=o(" (ALBERT model)"),hjo=l(),L1=a("li"),z2e=a("strong"),ujo=o("bart"),pjo=o(" \u2014 "),Fz=a("a"),_jo=o("BartForConditionalGeneration"),bjo=o(" (BART model)"),vjo=l(),y1=a("li"),Q2e=a("strong"),Fjo=o("bert"),Tjo=o(" \u2014 "),Tz=a("a"),Mjo=o("BertForPreTraining"),Ejo=o(" (BERT model)"),Cjo=l(),x1=a("li"),W2e=a("strong"),wjo=o("big_bird"),Ajo=o(" \u2014 "),Mz=a("a"),Ljo=o("BigBirdForPreTraining"),yjo=o(" (BigBird model)"),xjo=l(),$1=a("li"),U2e=a("strong"),$jo=o("bloom"),kjo=o(" \u2014 "),Ez=a("a"),Sjo=o("BloomForCausalLM"),Rjo=o(" (BLOOM model)"),Pjo=l(),k1=a("li"),H2e=a("strong"),Bjo=o("camembert"),Ijo=o(" \u2014 "),Cz=a("a"),Njo=o("CamembertForMaskedLM"),qjo=o(" (CamemBERT model)"),jjo=l(),S1=a("li"),J2e=a("strong"),Djo=o("ctrl"),Gjo=o(" \u2014 "),wz=a("a"),Ojo=o("CTRLLMHeadModel"),Vjo=o(" (CTRL model)"),Xjo=l(),R1=a("li"),Y2e=a("strong"),zjo=o("data2vec-text"),Qjo=o(" \u2014 "),Az=a("a"),Wjo=o("Data2VecTextForMaskedLM"),Ujo=o(" (Data2VecText model)"),Hjo=l(),P1=a("li"),K2e=a("strong"),Jjo=o("deberta"),Yjo=o(" \u2014 "),Lz=a("a"),Kjo=o("DebertaForMaskedLM"),Zjo=o(" (DeBERTa model)"),eDo=l(),B1=a("li"),Z2e=a("strong"),oDo=o("deberta-v2"),rDo=o(" \u2014 "),yz=a("a"),tDo=o("DebertaV2ForMaskedLM"),aDo=o(" (DeBERTa-v2 model)"),nDo=l(),I1=a("li"),e1e=a("strong"),sDo=o("distilbert"),lDo=o(" \u2014 "),xz=a("a"),iDo=o("DistilBertForMaskedLM"),dDo=o(" (DistilBERT model)"),mDo=l(),N1=a("li"),o1e=a("strong"),cDo=o("electra"),fDo=o(" \u2014 "),$z=a("a"),gDo=o("ElectraForPreTraining"),hDo=o(" (ELECTRA model)"),uDo=l(),q1=a("li"),r1e=a("strong"),pDo=o("ernie"),_Do=o(" \u2014 "),kz=a("a"),bDo=o("ErnieForPreTraining"),vDo=o(" (ERNIE model)"),FDo=l(),j1=a("li"),t1e=a("strong"),TDo=o("flaubert"),MDo=o(" \u2014 "),Sz=a("a"),EDo=o("FlaubertWithLMHeadModel"),CDo=o(" (FlauBERT model)"),wDo=l(),D1=a("li"),a1e=a("strong"),ADo=o("flava"),LDo=o(" \u2014 "),Rz=a("a"),yDo=o("FlavaForPreTraining"),xDo=o(" (FLAVA model)"),$Do=l(),G1=a("li"),n1e=a("strong"),kDo=o("fnet"),SDo=o(" \u2014 "),Pz=a("a"),RDo=o("FNetForPreTraining"),PDo=o(" (FNet model)"),BDo=l(),O1=a("li"),s1e=a("strong"),IDo=o("fsmt"),NDo=o(" \u2014 "),Bz=a("a"),qDo=o("FSMTForConditionalGeneration"),jDo=o(" (FairSeq Machine-Translation model)"),DDo=l(),V1=a("li"),l1e=a("strong"),GDo=o("funnel"),ODo=o(" \u2014 "),Iz=a("a"),VDo=o("FunnelForPreTraining"),XDo=o(" (Funnel Transformer model)"),zDo=l(),X1=a("li"),i1e=a("strong"),QDo=o("gpt2"),WDo=o(" \u2014 "),Nz=a("a"),UDo=o("GPT2LMHeadModel"),HDo=o(" (OpenAI GPT-2 model)"),JDo=l(),z1=a("li"),d1e=a("strong"),YDo=o("ibert"),KDo=o(" \u2014 "),qz=a("a"),ZDo=o("IBertForMaskedLM"),eGo=o(" (I-BERT model)"),oGo=l(),Q1=a("li"),m1e=a("strong"),rGo=o("layoutlm"),tGo=o(" \u2014 "),jz=a("a"),aGo=o("LayoutLMForMaskedLM"),nGo=o(" (LayoutLM model)"),sGo=l(),W1=a("li"),c1e=a("strong"),lGo=o("longformer"),iGo=o(" \u2014 "),Dz=a("a"),dGo=o("LongformerForMaskedLM"),mGo=o(" (Longformer model)"),cGo=l(),U1=a("li"),f1e=a("strong"),fGo=o("luke"),gGo=o(" \u2014 "),Gz=a("a"),hGo=o("LukeForMaskedLM"),uGo=o(" (LUKE model)"),pGo=l(),H1=a("li"),g1e=a("strong"),_Go=o("lxmert"),bGo=o(" \u2014 "),Oz=a("a"),vGo=o("LxmertForPreTraining"),FGo=o(" (LXMERT model)"),TGo=l(),J1=a("li"),h1e=a("strong"),MGo=o("megatron-bert"),EGo=o(" \u2014 "),Vz=a("a"),CGo=o("MegatronBertForPreTraining"),wGo=o(" (Megatron-BERT model)"),AGo=l(),Y1=a("li"),u1e=a("strong"),LGo=o("mobilebert"),yGo=o(" \u2014 "),Xz=a("a"),xGo=o("MobileBertForPreTraining"),$Go=o(" (MobileBERT model)"),kGo=l(),K1=a("li"),p1e=a("strong"),SGo=o("mpnet"),RGo=o(" \u2014 "),zz=a("a"),PGo=o("MPNetForMaskedLM"),BGo=o(" (MPNet model)"),IGo=l(),Z1=a("li"),_1e=a("strong"),NGo=o("mvp"),qGo=o(" \u2014 "),Qz=a("a"),jGo=o("MvpForConditionalGeneration"),DGo=o(" (MVP model)"),GGo=l(),eb=a("li"),b1e=a("strong"),OGo=o("nezha"),VGo=o(" \u2014 "),Wz=a("a"),XGo=o("NezhaForPreTraining"),zGo=o(" (Nezha model)"),QGo=l(),ob=a("li"),v1e=a("strong"),WGo=o("openai-gpt"),UGo=o(" \u2014 "),Uz=a("a"),HGo=o("OpenAIGPTLMHeadModel"),JGo=o(" (OpenAI GPT model)"),YGo=l(),rb=a("li"),F1e=a("strong"),KGo=o("retribert"),ZGo=o(" \u2014 "),Hz=a("a"),eOo=o("RetriBertModel"),oOo=o(" (RetriBERT model)"),rOo=l(),tb=a("li"),T1e=a("strong"),tOo=o("roberta"),aOo=o(" \u2014 "),Jz=a("a"),nOo=o("RobertaForMaskedLM"),sOo=o(" (RoBERTa model)"),lOo=l(),ab=a("li"),M1e=a("strong"),iOo=o("splinter"),dOo=o(" \u2014 "),Yz=a("a"),mOo=o("SplinterForPreTraining"),cOo=o(" (Splinter model)"),fOo=l(),nb=a("li"),E1e=a("strong"),gOo=o("squeezebert"),hOo=o(" \u2014 "),Kz=a("a"),uOo=o("SqueezeBertForMaskedLM"),pOo=o(" (SqueezeBERT model)"),_Oo=l(),sb=a("li"),C1e=a("strong"),bOo=o("t5"),vOo=o(" \u2014 "),Zz=a("a"),FOo=o("T5ForConditionalGeneration"),TOo=o(" (T5 model)"),MOo=l(),lb=a("li"),w1e=a("strong"),EOo=o("tapas"),COo=o(" \u2014 "),eQ=a("a"),wOo=o("TapasForMaskedLM"),AOo=o(" (TAPAS model)"),LOo=l(),ib=a("li"),A1e=a("strong"),yOo=o("transfo-xl"),xOo=o(" \u2014 "),oQ=a("a"),$Oo=o("TransfoXLLMHeadModel"),kOo=o(" (Transformer-XL model)"),SOo=l(),db=a("li"),L1e=a("strong"),ROo=o("unispeech"),POo=o(" \u2014 "),rQ=a("a"),BOo=o("UniSpeechForPreTraining"),IOo=o(" (UniSpeech model)"),NOo=l(),mb=a("li"),y1e=a("strong"),qOo=o("unispeech-sat"),jOo=o(" \u2014 "),tQ=a("a"),DOo=o("UniSpeechSatForPreTraining"),GOo=o(" (UniSpeechSat model)"),OOo=l(),cb=a("li"),x1e=a("strong"),VOo=o("videomae"),XOo=o(" \u2014 "),aQ=a("a"),zOo=o("VideoMAEForPreTraining"),QOo=o(" (VideoMAE model)"),WOo=l(),fb=a("li"),$1e=a("strong"),UOo=o("visual_bert"),HOo=o(" \u2014 "),nQ=a("a"),JOo=o("VisualBertForPreTraining"),YOo=o(" (VisualBERT model)"),KOo=l(),gb=a("li"),k1e=a("strong"),ZOo=o("vit_mae"),eVo=o(" \u2014 "),sQ=a("a"),oVo=o("ViTMAEForPreTraining"),rVo=o(" (ViTMAE model)"),tVo=l(),hb=a("li"),S1e=a("strong"),aVo=o("wav2vec2"),nVo=o(" \u2014 "),lQ=a("a"),sVo=o("Wav2Vec2ForPreTraining"),lVo=o(" (Wav2Vec2 model)"),iVo=l(),ub=a("li"),R1e=a("strong"),dVo=o("wav2vec2-conformer"),mVo=o(" \u2014 "),iQ=a("a"),cVo=o("Wav2Vec2ConformerForPreTraining"),fVo=o(" (Wav2Vec2-Conformer model)"),gVo=l(),pb=a("li"),P1e=a("strong"),hVo=o("xlm"),uVo=o(" \u2014 "),dQ=a("a"),pVo=o("XLMWithLMHeadModel"),_Vo=o(" (XLM model)"),bVo=l(),_b=a("li"),B1e=a("strong"),vVo=o("xlm-roberta"),FVo=o(" \u2014 "),mQ=a("a"),TVo=o("XLMRobertaForMaskedLM"),MVo=o(" (XLM-RoBERTa model)"),EVo=l(),bb=a("li"),I1e=a("strong"),CVo=o("xlm-roberta-xl"),wVo=o(" \u2014 "),cQ=a("a"),AVo=o("XLMRobertaXLForMaskedLM"),LVo=o(" (XLM-RoBERTa-XL model)"),yVo=l(),vb=a("li"),N1e=a("strong"),xVo=o("xlnet"),$Vo=o(" \u2014 "),fQ=a("a"),kVo=o("XLNetLMHeadModel"),SVo=o(" (XLNet model)"),RVo=l(),Fb=a("p"),PVo=o("The model is set in evaluation mode by default using "),q1e=a("code"),BVo=o("model.eval()"),IVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j1e=a("code"),NVo=o("model.train()"),qVo=l(),F(Tb.$$.fragment),teo=l(),Ed=a("h2"),Mb=a("a"),D1e=a("span"),F(Ix.$$.fragment),jVo=l(),G1e=a("span"),DVo=o("AutoModelForCausalLM"),aeo=l(),Io=a("div"),F(Nx.$$.fragment),GVo=l(),Cd=a("p"),OVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),gQ=a("a"),VVo=o("from_pretrained()"),XVo=o(" class method or the "),hQ=a("a"),zVo=o("from_config()"),QVo=o(` class
method.`),WVo=l(),qx=a("p"),UVo=o("This class cannot be instantiated directly using "),O1e=a("code"),HVo=o("__init__()"),JVo=o(" (throws an error)."),YVo=l(),vt=a("div"),F(jx.$$.fragment),KVo=l(),V1e=a("p"),ZVo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),eXo=l(),wd=a("p"),oXo=o(`Note:
Loading a model from its configuration file does `),X1e=a("strong"),rXo=o("not"),tXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uQ=a("a"),aXo=o("from_pretrained()"),nXo=o(" to load the model weights."),sXo=l(),F(Eb.$$.fragment),lXo=l(),oo=a("div"),F(Dx.$$.fragment),iXo=l(),z1e=a("p"),dXo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),mXo=l(),Ka=a("p"),cXo=o("The model class to instantiate is selected based on the "),Q1e=a("code"),fXo=o("model_type"),gXo=o(` property of the config object (either
passed as an argument or loaded from `),W1e=a("code"),hXo=o("pretrained_model_name_or_path"),uXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=a("code"),pXo=o("pretrained_model_name_or_path"),_Xo=o(":"),bXo=l(),Q=a("ul"),Cb=a("li"),H1e=a("strong"),vXo=o("bart"),FXo=o(" \u2014 "),pQ=a("a"),TXo=o("BartForCausalLM"),MXo=o(" (BART model)"),EXo=l(),wb=a("li"),J1e=a("strong"),CXo=o("bert"),wXo=o(" \u2014 "),_Q=a("a"),AXo=o("BertLMHeadModel"),LXo=o(" (BERT model)"),yXo=l(),Ab=a("li"),Y1e=a("strong"),xXo=o("bert-generation"),$Xo=o(" \u2014 "),bQ=a("a"),kXo=o("BertGenerationDecoder"),SXo=o(" (Bert Generation model)"),RXo=l(),Lb=a("li"),K1e=a("strong"),PXo=o("big_bird"),BXo=o(" \u2014 "),vQ=a("a"),IXo=o("BigBirdForCausalLM"),NXo=o(" (BigBird model)"),qXo=l(),yb=a("li"),Z1e=a("strong"),jXo=o("bigbird_pegasus"),DXo=o(" \u2014 "),FQ=a("a"),GXo=o("BigBirdPegasusForCausalLM"),OXo=o(" (BigBird-Pegasus model)"),VXo=l(),xb=a("li"),ebe=a("strong"),XXo=o("blenderbot"),zXo=o(" \u2014 "),TQ=a("a"),QXo=o("BlenderbotForCausalLM"),WXo=o(" (Blenderbot model)"),UXo=l(),$b=a("li"),obe=a("strong"),HXo=o("blenderbot-small"),JXo=o(" \u2014 "),MQ=a("a"),YXo=o("BlenderbotSmallForCausalLM"),KXo=o(" (BlenderbotSmall model)"),ZXo=l(),kb=a("li"),rbe=a("strong"),ezo=o("bloom"),ozo=o(" \u2014 "),EQ=a("a"),rzo=o("BloomForCausalLM"),tzo=o(" (BLOOM model)"),azo=l(),Sb=a("li"),tbe=a("strong"),nzo=o("camembert"),szo=o(" \u2014 "),CQ=a("a"),lzo=o("CamembertForCausalLM"),izo=o(" (CamemBERT model)"),dzo=l(),Rb=a("li"),abe=a("strong"),mzo=o("codegen"),czo=o(" \u2014 "),wQ=a("a"),fzo=o("CodeGenForCausalLM"),gzo=o(" (CodeGen model)"),hzo=l(),Pb=a("li"),nbe=a("strong"),uzo=o("ctrl"),pzo=o(" \u2014 "),AQ=a("a"),_zo=o("CTRLLMHeadModel"),bzo=o(" (CTRL model)"),vzo=l(),Bb=a("li"),sbe=a("strong"),Fzo=o("data2vec-text"),Tzo=o(" \u2014 "),LQ=a("a"),Mzo=o("Data2VecTextForCausalLM"),Ezo=o(" (Data2VecText model)"),Czo=l(),Ib=a("li"),lbe=a("strong"),wzo=o("electra"),Azo=o(" \u2014 "),yQ=a("a"),Lzo=o("ElectraForCausalLM"),yzo=o(" (ELECTRA model)"),xzo=l(),Nb=a("li"),ibe=a("strong"),$zo=o("ernie"),kzo=o(" \u2014 "),xQ=a("a"),Szo=o("ErnieForCausalLM"),Rzo=o(" (ERNIE model)"),Pzo=l(),qb=a("li"),dbe=a("strong"),Bzo=o("gpt2"),Izo=o(" \u2014 "),$Q=a("a"),Nzo=o("GPT2LMHeadModel"),qzo=o(" (OpenAI GPT-2 model)"),jzo=l(),jb=a("li"),mbe=a("strong"),Dzo=o("gpt_neo"),Gzo=o(" \u2014 "),kQ=a("a"),Ozo=o("GPTNeoForCausalLM"),Vzo=o(" (GPT Neo model)"),Xzo=l(),Db=a("li"),cbe=a("strong"),zzo=o("gpt_neox"),Qzo=o(" \u2014 "),SQ=a("a"),Wzo=o("GPTNeoXForCausalLM"),Uzo=o(" (GPT NeoX model)"),Hzo=l(),Gb=a("li"),fbe=a("strong"),Jzo=o("gpt_neox_japanese"),Yzo=o(" \u2014 "),RQ=a("a"),Kzo=o("GPTNeoXJapaneseForCausalLM"),Zzo=o(" (GPT NeoX Japanese model)"),eQo=l(),Ob=a("li"),gbe=a("strong"),oQo=o("gptj"),rQo=o(" \u2014 "),PQ=a("a"),tQo=o("GPTJForCausalLM"),aQo=o(" (GPT-J model)"),nQo=l(),Vb=a("li"),hbe=a("strong"),sQo=o("marian"),lQo=o(" \u2014 "),BQ=a("a"),iQo=o("MarianForCausalLM"),dQo=o(" (Marian model)"),mQo=l(),Xb=a("li"),ube=a("strong"),cQo=o("mbart"),fQo=o(" \u2014 "),IQ=a("a"),gQo=o("MBartForCausalLM"),hQo=o(" (mBART model)"),uQo=l(),zb=a("li"),pbe=a("strong"),pQo=o("megatron-bert"),_Qo=o(" \u2014 "),NQ=a("a"),bQo=o("MegatronBertForCausalLM"),vQo=o(" (Megatron-BERT model)"),FQo=l(),Qb=a("li"),_be=a("strong"),TQo=o("mvp"),MQo=o(" \u2014 "),qQ=a("a"),EQo=o("MvpForCausalLM"),CQo=o(" (MVP model)"),wQo=l(),Wb=a("li"),bbe=a("strong"),AQo=o("openai-gpt"),LQo=o(" \u2014 "),jQ=a("a"),yQo=o("OpenAIGPTLMHeadModel"),xQo=o(" (OpenAI GPT model)"),$Qo=l(),Ub=a("li"),vbe=a("strong"),kQo=o("opt"),SQo=o(" \u2014 "),DQ=a("a"),RQo=o("OPTForCausalLM"),PQo=o(" (OPT model)"),BQo=l(),Hb=a("li"),Fbe=a("strong"),IQo=o("pegasus"),NQo=o(" \u2014 "),GQ=a("a"),qQo=o("PegasusForCausalLM"),jQo=o(" (Pegasus model)"),DQo=l(),Jb=a("li"),Tbe=a("strong"),GQo=o("plbart"),OQo=o(" \u2014 "),OQ=a("a"),VQo=o("PLBartForCausalLM"),XQo=o(" (PLBart model)"),zQo=l(),Yb=a("li"),Mbe=a("strong"),QQo=o("prophetnet"),WQo=o(" \u2014 "),VQ=a("a"),UQo=o("ProphetNetForCausalLM"),HQo=o(" (ProphetNet model)"),JQo=l(),Kb=a("li"),Ebe=a("strong"),YQo=o("qdqbert"),KQo=o(" \u2014 "),XQ=a("a"),ZQo=o("QDQBertLMHeadModel"),eWo=o(" (QDQBert model)"),oWo=l(),Zb=a("li"),Cbe=a("strong"),rWo=o("reformer"),tWo=o(" \u2014 "),zQ=a("a"),aWo=o("ReformerModelWithLMHead"),nWo=o(" (Reformer model)"),sWo=l(),ev=a("li"),wbe=a("strong"),lWo=o("rembert"),iWo=o(" \u2014 "),QQ=a("a"),dWo=o("RemBertForCausalLM"),mWo=o(" (RemBERT model)"),cWo=l(),ov=a("li"),Abe=a("strong"),fWo=o("roberta"),gWo=o(" \u2014 "),WQ=a("a"),hWo=o("RobertaForCausalLM"),uWo=o(" (RoBERTa model)"),pWo=l(),rv=a("li"),Lbe=a("strong"),_Wo=o("roformer"),bWo=o(" \u2014 "),UQ=a("a"),vWo=o("RoFormerForCausalLM"),FWo=o(" (RoFormer model)"),TWo=l(),tv=a("li"),ybe=a("strong"),MWo=o("speech_to_text_2"),EWo=o(" \u2014 "),HQ=a("a"),CWo=o("Speech2Text2ForCausalLM"),wWo=o(" (Speech2Text2 model)"),AWo=l(),av=a("li"),xbe=a("strong"),LWo=o("transfo-xl"),yWo=o(" \u2014 "),JQ=a("a"),xWo=o("TransfoXLLMHeadModel"),$Wo=o(" (Transformer-XL model)"),kWo=l(),nv=a("li"),$be=a("strong"),SWo=o("trocr"),RWo=o(" \u2014 "),YQ=a("a"),PWo=o("TrOCRForCausalLM"),BWo=o(" (TrOCR model)"),IWo=l(),sv=a("li"),kbe=a("strong"),NWo=o("xglm"),qWo=o(" \u2014 "),KQ=a("a"),jWo=o("XGLMForCausalLM"),DWo=o(" (XGLM model)"),GWo=l(),lv=a("li"),Sbe=a("strong"),OWo=o("xlm"),VWo=o(" \u2014 "),ZQ=a("a"),XWo=o("XLMWithLMHeadModel"),zWo=o(" (XLM model)"),QWo=l(),iv=a("li"),Rbe=a("strong"),WWo=o("xlm-prophetnet"),UWo=o(" \u2014 "),eW=a("a"),HWo=o("XLMProphetNetForCausalLM"),JWo=o(" (XLM-ProphetNet model)"),YWo=l(),dv=a("li"),Pbe=a("strong"),KWo=o("xlm-roberta"),ZWo=o(" \u2014 "),oW=a("a"),eUo=o("XLMRobertaForCausalLM"),oUo=o(" (XLM-RoBERTa model)"),rUo=l(),mv=a("li"),Bbe=a("strong"),tUo=o("xlm-roberta-xl"),aUo=o(" \u2014 "),rW=a("a"),nUo=o("XLMRobertaXLForCausalLM"),sUo=o(" (XLM-RoBERTa-XL model)"),lUo=l(),cv=a("li"),Ibe=a("strong"),iUo=o("xlnet"),dUo=o(" \u2014 "),tW=a("a"),mUo=o("XLNetLMHeadModel"),cUo=o(" (XLNet model)"),fUo=l(),fv=a("p"),gUo=o("The model is set in evaluation mode by default using "),Nbe=a("code"),hUo=o("model.eval()"),uUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qbe=a("code"),pUo=o("model.train()"),_Uo=l(),F(gv.$$.fragment),neo=l(),Ad=a("h2"),hv=a("a"),jbe=a("span"),F(Gx.$$.fragment),bUo=l(),Dbe=a("span"),vUo=o("AutoModelForMaskedLM"),seo=l(),No=a("div"),F(Ox.$$.fragment),FUo=l(),Ld=a("p"),TUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aW=a("a"),MUo=o("from_pretrained()"),EUo=o(" class method or the "),nW=a("a"),CUo=o("from_config()"),wUo=o(` class
method.`),AUo=l(),Vx=a("p"),LUo=o("This class cannot be instantiated directly using "),Gbe=a("code"),yUo=o("__init__()"),xUo=o(" (throws an error)."),$Uo=l(),Ft=a("div"),F(Xx.$$.fragment),kUo=l(),Obe=a("p"),SUo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),RUo=l(),yd=a("p"),PUo=o(`Note:
Loading a model from its configuration file does `),Vbe=a("strong"),BUo=o("not"),IUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),NUo=o("from_pretrained()"),qUo=o(" to load the model weights."),jUo=l(),F(uv.$$.fragment),DUo=l(),ro=a("div"),F(zx.$$.fragment),GUo=l(),Xbe=a("p"),OUo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),VUo=l(),Za=a("p"),XUo=o("The model class to instantiate is selected based on the "),zbe=a("code"),zUo=o("model_type"),QUo=o(` property of the config object (either
passed as an argument or loaded from `),Qbe=a("code"),WUo=o("pretrained_model_name_or_path"),UUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wbe=a("code"),HUo=o("pretrained_model_name_or_path"),JUo=o(":"),YUo=l(),J=a("ul"),pv=a("li"),Ube=a("strong"),KUo=o("albert"),ZUo=o(" \u2014 "),lW=a("a"),eHo=o("AlbertForMaskedLM"),oHo=o(" (ALBERT model)"),rHo=l(),_v=a("li"),Hbe=a("strong"),tHo=o("bart"),aHo=o(" \u2014 "),iW=a("a"),nHo=o("BartForConditionalGeneration"),sHo=o(" (BART model)"),lHo=l(),bv=a("li"),Jbe=a("strong"),iHo=o("bert"),dHo=o(" \u2014 "),dW=a("a"),mHo=o("BertForMaskedLM"),cHo=o(" (BERT model)"),fHo=l(),vv=a("li"),Ybe=a("strong"),gHo=o("big_bird"),hHo=o(" \u2014 "),mW=a("a"),uHo=o("BigBirdForMaskedLM"),pHo=o(" (BigBird model)"),_Ho=l(),Fv=a("li"),Kbe=a("strong"),bHo=o("camembert"),vHo=o(" \u2014 "),cW=a("a"),FHo=o("CamembertForMaskedLM"),THo=o(" (CamemBERT model)"),MHo=l(),Tv=a("li"),Zbe=a("strong"),EHo=o("convbert"),CHo=o(" \u2014 "),fW=a("a"),wHo=o("ConvBertForMaskedLM"),AHo=o(" (ConvBERT model)"),LHo=l(),Mv=a("li"),eve=a("strong"),yHo=o("data2vec-text"),xHo=o(" \u2014 "),gW=a("a"),$Ho=o("Data2VecTextForMaskedLM"),kHo=o(" (Data2VecText model)"),SHo=l(),Ev=a("li"),ove=a("strong"),RHo=o("deberta"),PHo=o(" \u2014 "),hW=a("a"),BHo=o("DebertaForMaskedLM"),IHo=o(" (DeBERTa model)"),NHo=l(),Cv=a("li"),rve=a("strong"),qHo=o("deberta-v2"),jHo=o(" \u2014 "),uW=a("a"),DHo=o("DebertaV2ForMaskedLM"),GHo=o(" (DeBERTa-v2 model)"),OHo=l(),wv=a("li"),tve=a("strong"),VHo=o("distilbert"),XHo=o(" \u2014 "),pW=a("a"),zHo=o("DistilBertForMaskedLM"),QHo=o(" (DistilBERT model)"),WHo=l(),Av=a("li"),ave=a("strong"),UHo=o("electra"),HHo=o(" \u2014 "),_W=a("a"),JHo=o("ElectraForMaskedLM"),YHo=o(" (ELECTRA model)"),KHo=l(),Lv=a("li"),nve=a("strong"),ZHo=o("ernie"),eJo=o(" \u2014 "),bW=a("a"),oJo=o("ErnieForMaskedLM"),rJo=o(" (ERNIE model)"),tJo=l(),yv=a("li"),sve=a("strong"),aJo=o("flaubert"),nJo=o(" \u2014 "),vW=a("a"),sJo=o("FlaubertWithLMHeadModel"),lJo=o(" (FlauBERT model)"),iJo=l(),xv=a("li"),lve=a("strong"),dJo=o("fnet"),mJo=o(" \u2014 "),FW=a("a"),cJo=o("FNetForMaskedLM"),fJo=o(" (FNet model)"),gJo=l(),$v=a("li"),ive=a("strong"),hJo=o("funnel"),uJo=o(" \u2014 "),TW=a("a"),pJo=o("FunnelForMaskedLM"),_Jo=o(" (Funnel Transformer model)"),bJo=l(),kv=a("li"),dve=a("strong"),vJo=o("ibert"),FJo=o(" \u2014 "),MW=a("a"),TJo=o("IBertForMaskedLM"),MJo=o(" (I-BERT model)"),EJo=l(),Sv=a("li"),mve=a("strong"),CJo=o("layoutlm"),wJo=o(" \u2014 "),EW=a("a"),AJo=o("LayoutLMForMaskedLM"),LJo=o(" (LayoutLM model)"),yJo=l(),Rv=a("li"),cve=a("strong"),xJo=o("longformer"),$Jo=o(" \u2014 "),CW=a("a"),kJo=o("LongformerForMaskedLM"),SJo=o(" (Longformer model)"),RJo=l(),Pv=a("li"),fve=a("strong"),PJo=o("luke"),BJo=o(" \u2014 "),wW=a("a"),IJo=o("LukeForMaskedLM"),NJo=o(" (LUKE model)"),qJo=l(),Bv=a("li"),gve=a("strong"),jJo=o("mbart"),DJo=o(" \u2014 "),AW=a("a"),GJo=o("MBartForConditionalGeneration"),OJo=o(" (mBART model)"),VJo=l(),Iv=a("li"),hve=a("strong"),XJo=o("megatron-bert"),zJo=o(" \u2014 "),LW=a("a"),QJo=o("MegatronBertForMaskedLM"),WJo=o(" (Megatron-BERT model)"),UJo=l(),Nv=a("li"),uve=a("strong"),HJo=o("mobilebert"),JJo=o(" \u2014 "),yW=a("a"),YJo=o("MobileBertForMaskedLM"),KJo=o(" (MobileBERT model)"),ZJo=l(),qv=a("li"),pve=a("strong"),eYo=o("mpnet"),oYo=o(" \u2014 "),xW=a("a"),rYo=o("MPNetForMaskedLM"),tYo=o(" (MPNet model)"),aYo=l(),jv=a("li"),_ve=a("strong"),nYo=o("mvp"),sYo=o(" \u2014 "),$W=a("a"),lYo=o("MvpForConditionalGeneration"),iYo=o(" (MVP model)"),dYo=l(),Dv=a("li"),bve=a("strong"),mYo=o("nezha"),cYo=o(" \u2014 "),kW=a("a"),fYo=o("NezhaForMaskedLM"),gYo=o(" (Nezha model)"),hYo=l(),Gv=a("li"),vve=a("strong"),uYo=o("nystromformer"),pYo=o(" \u2014 "),SW=a("a"),_Yo=o("NystromformerForMaskedLM"),bYo=o(" (Nystr\xF6mformer model)"),vYo=l(),Ov=a("li"),Fve=a("strong"),FYo=o("perceiver"),TYo=o(" \u2014 "),RW=a("a"),MYo=o("PerceiverForMaskedLM"),EYo=o(" (Perceiver model)"),CYo=l(),Vv=a("li"),Tve=a("strong"),wYo=o("qdqbert"),AYo=o(" \u2014 "),PW=a("a"),LYo=o("QDQBertForMaskedLM"),yYo=o(" (QDQBert model)"),xYo=l(),Xv=a("li"),Mve=a("strong"),$Yo=o("reformer"),kYo=o(" \u2014 "),BW=a("a"),SYo=o("ReformerForMaskedLM"),RYo=o(" (Reformer model)"),PYo=l(),zv=a("li"),Eve=a("strong"),BYo=o("rembert"),IYo=o(" \u2014 "),IW=a("a"),NYo=o("RemBertForMaskedLM"),qYo=o(" (RemBERT model)"),jYo=l(),Qv=a("li"),Cve=a("strong"),DYo=o("roberta"),GYo=o(" \u2014 "),NW=a("a"),OYo=o("RobertaForMaskedLM"),VYo=o(" (RoBERTa model)"),XYo=l(),Wv=a("li"),wve=a("strong"),zYo=o("roformer"),QYo=o(" \u2014 "),qW=a("a"),WYo=o("RoFormerForMaskedLM"),UYo=o(" (RoFormer model)"),HYo=l(),Uv=a("li"),Ave=a("strong"),JYo=o("squeezebert"),YYo=o(" \u2014 "),jW=a("a"),KYo=o("SqueezeBertForMaskedLM"),ZYo=o(" (SqueezeBERT model)"),eKo=l(),Hv=a("li"),Lve=a("strong"),oKo=o("tapas"),rKo=o(" \u2014 "),DW=a("a"),tKo=o("TapasForMaskedLM"),aKo=o(" (TAPAS model)"),nKo=l(),Jv=a("li"),yve=a("strong"),sKo=o("wav2vec2"),lKo=o(" \u2014 "),xve=a("code"),iKo=o("Wav2Vec2ForMaskedLM"),dKo=o(" (Wav2Vec2 model)"),mKo=l(),Yv=a("li"),$ve=a("strong"),cKo=o("xlm"),fKo=o(" \u2014 "),GW=a("a"),gKo=o("XLMWithLMHeadModel"),hKo=o(" (XLM model)"),uKo=l(),Kv=a("li"),kve=a("strong"),pKo=o("xlm-roberta"),_Ko=o(" \u2014 "),OW=a("a"),bKo=o("XLMRobertaForMaskedLM"),vKo=o(" (XLM-RoBERTa model)"),FKo=l(),Zv=a("li"),Sve=a("strong"),TKo=o("xlm-roberta-xl"),MKo=o(" \u2014 "),VW=a("a"),EKo=o("XLMRobertaXLForMaskedLM"),CKo=o(" (XLM-RoBERTa-XL model)"),wKo=l(),eF=a("li"),Rve=a("strong"),AKo=o("yoso"),LKo=o(" \u2014 "),XW=a("a"),yKo=o("YosoForMaskedLM"),xKo=o(" (YOSO model)"),$Ko=l(),oF=a("p"),kKo=o("The model is set in evaluation mode by default using "),Pve=a("code"),SKo=o("model.eval()"),RKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bve=a("code"),PKo=o("model.train()"),BKo=l(),F(rF.$$.fragment),leo=l(),xd=a("h2"),tF=a("a"),Ive=a("span"),F(Qx.$$.fragment),IKo=l(),Nve=a("span"),NKo=o("AutoModelForSeq2SeqLM"),ieo=l(),qo=a("div"),F(Wx.$$.fragment),qKo=l(),$d=a("p"),jKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zW=a("a"),DKo=o("from_pretrained()"),GKo=o(" class method or the "),QW=a("a"),OKo=o("from_config()"),VKo=o(` class
method.`),XKo=l(),Ux=a("p"),zKo=o("This class cannot be instantiated directly using "),qve=a("code"),QKo=o("__init__()"),WKo=o(" (throws an error)."),UKo=l(),Tt=a("div"),F(Hx.$$.fragment),HKo=l(),jve=a("p"),JKo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YKo=l(),kd=a("p"),KKo=o(`Note:
Loading a model from its configuration file does `),Dve=a("strong"),ZKo=o("not"),eZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),oZo=o("from_pretrained()"),rZo=o(" to load the model weights."),tZo=l(),F(aF.$$.fragment),aZo=l(),to=a("div"),F(Jx.$$.fragment),nZo=l(),Gve=a("p"),sZo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),lZo=l(),en=a("p"),iZo=o("The model class to instantiate is selected based on the "),Ove=a("code"),dZo=o("model_type"),mZo=o(` property of the config object (either
passed as an argument or loaded from `),Vve=a("code"),cZo=o("pretrained_model_name_or_path"),fZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xve=a("code"),gZo=o("pretrained_model_name_or_path"),hZo=o(":"),uZo=l(),fe=a("ul"),nF=a("li"),zve=a("strong"),pZo=o("bart"),_Zo=o(" \u2014 "),UW=a("a"),bZo=o("BartForConditionalGeneration"),vZo=o(" (BART model)"),FZo=l(),sF=a("li"),Qve=a("strong"),TZo=o("bigbird_pegasus"),MZo=o(" \u2014 "),HW=a("a"),EZo=o("BigBirdPegasusForConditionalGeneration"),CZo=o(" (BigBird-Pegasus model)"),wZo=l(),lF=a("li"),Wve=a("strong"),AZo=o("blenderbot"),LZo=o(" \u2014 "),JW=a("a"),yZo=o("BlenderbotForConditionalGeneration"),xZo=o(" (Blenderbot model)"),$Zo=l(),iF=a("li"),Uve=a("strong"),kZo=o("blenderbot-small"),SZo=o(" \u2014 "),YW=a("a"),RZo=o("BlenderbotSmallForConditionalGeneration"),PZo=o(" (BlenderbotSmall model)"),BZo=l(),dF=a("li"),Hve=a("strong"),IZo=o("encoder-decoder"),NZo=o(" \u2014 "),KW=a("a"),qZo=o("EncoderDecoderModel"),jZo=o(" (Encoder decoder model)"),DZo=l(),mF=a("li"),Jve=a("strong"),GZo=o("fsmt"),OZo=o(" \u2014 "),ZW=a("a"),VZo=o("FSMTForConditionalGeneration"),XZo=o(" (FairSeq Machine-Translation model)"),zZo=l(),cF=a("li"),Yve=a("strong"),QZo=o("led"),WZo=o(" \u2014 "),eU=a("a"),UZo=o("LEDForConditionalGeneration"),HZo=o(" (LED model)"),JZo=l(),fF=a("li"),Kve=a("strong"),YZo=o("longt5"),KZo=o(" \u2014 "),oU=a("a"),ZZo=o("LongT5ForConditionalGeneration"),eer=o(" (LongT5 model)"),oer=l(),gF=a("li"),Zve=a("strong"),rer=o("m2m_100"),ter=o(" \u2014 "),rU=a("a"),aer=o("M2M100ForConditionalGeneration"),ner=o(" (M2M100 model)"),ser=l(),hF=a("li"),eFe=a("strong"),ler=o("marian"),ier=o(" \u2014 "),tU=a("a"),der=o("MarianMTModel"),mer=o(" (Marian model)"),cer=l(),uF=a("li"),oFe=a("strong"),fer=o("mbart"),ger=o(" \u2014 "),aU=a("a"),her=o("MBartForConditionalGeneration"),uer=o(" (mBART model)"),per=l(),pF=a("li"),rFe=a("strong"),_er=o("mt5"),ber=o(" \u2014 "),nU=a("a"),ver=o("MT5ForConditionalGeneration"),Fer=o(" (MT5 model)"),Ter=l(),_F=a("li"),tFe=a("strong"),Mer=o("mvp"),Eer=o(" \u2014 "),sU=a("a"),Cer=o("MvpForConditionalGeneration"),wer=o(" (MVP model)"),Aer=l(),bF=a("li"),aFe=a("strong"),Ler=o("nllb"),yer=o(" \u2014 "),lU=a("a"),xer=o("M2M100ForConditionalGeneration"),$er=o(" (NLLB model)"),ker=l(),vF=a("li"),nFe=a("strong"),Ser=o("pegasus"),Rer=o(" \u2014 "),iU=a("a"),Per=o("PegasusForConditionalGeneration"),Ber=o(" (Pegasus model)"),Ier=l(),FF=a("li"),sFe=a("strong"),Ner=o("pegasus_x"),qer=o(" \u2014 "),dU=a("a"),jer=o("PegasusXForConditionalGeneration"),Der=o(" (PEGASUS-X model)"),Ger=l(),TF=a("li"),lFe=a("strong"),Oer=o("plbart"),Ver=o(" \u2014 "),mU=a("a"),Xer=o("PLBartForConditionalGeneration"),zer=o(" (PLBart model)"),Qer=l(),MF=a("li"),iFe=a("strong"),Wer=o("prophetnet"),Uer=o(" \u2014 "),cU=a("a"),Her=o("ProphetNetForConditionalGeneration"),Jer=o(" (ProphetNet model)"),Yer=l(),EF=a("li"),dFe=a("strong"),Ker=o("t5"),Zer=o(" \u2014 "),fU=a("a"),eor=o("T5ForConditionalGeneration"),oor=o(" (T5 model)"),ror=l(),CF=a("li"),mFe=a("strong"),tor=o("xlm-prophetnet"),aor=o(" \u2014 "),gU=a("a"),nor=o("XLMProphetNetForConditionalGeneration"),sor=o(" (XLM-ProphetNet model)"),lor=l(),wF=a("p"),ior=o("The model is set in evaluation mode by default using "),cFe=a("code"),dor=o("model.eval()"),mor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fFe=a("code"),cor=o("model.train()"),gor=l(),F(AF.$$.fragment),deo=l(),Sd=a("h2"),LF=a("a"),gFe=a("span"),F(Yx.$$.fragment),hor=l(),hFe=a("span"),uor=o("AutoModelForSequenceClassification"),meo=l(),jo=a("div"),F(Kx.$$.fragment),por=l(),Rd=a("p"),_or=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hU=a("a"),bor=o("from_pretrained()"),vor=o(" class method or the "),uU=a("a"),For=o("from_config()"),Tor=o(` class
method.`),Mor=l(),Zx=a("p"),Eor=o("This class cannot be instantiated directly using "),uFe=a("code"),Cor=o("__init__()"),wor=o(" (throws an error)."),Aor=l(),Mt=a("div"),F(e$.$$.fragment),Lor=l(),pFe=a("p"),yor=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),xor=l(),Pd=a("p"),$or=o(`Note:
Loading a model from its configuration file does `),_Fe=a("strong"),kor=o("not"),Sor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pU=a("a"),Ror=o("from_pretrained()"),Por=o(" to load the model weights."),Bor=l(),F(yF.$$.fragment),Ior=l(),ao=a("div"),F(o$.$$.fragment),Nor=l(),bFe=a("p"),qor=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),jor=l(),on=a("p"),Dor=o("The model class to instantiate is selected based on the "),vFe=a("code"),Gor=o("model_type"),Oor=o(` property of the config object (either
passed as an argument or loaded from `),FFe=a("code"),Vor=o("pretrained_model_name_or_path"),Xor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=a("code"),zor=o("pretrained_model_name_or_path"),Qor=o(":"),Wor=l(),B=a("ul"),xF=a("li"),MFe=a("strong"),Uor=o("albert"),Hor=o(" \u2014 "),_U=a("a"),Jor=o("AlbertForSequenceClassification"),Yor=o(" (ALBERT model)"),Kor=l(),$F=a("li"),EFe=a("strong"),Zor=o("bart"),err=o(" \u2014 "),bU=a("a"),orr=o("BartForSequenceClassification"),rrr=o(" (BART model)"),trr=l(),kF=a("li"),CFe=a("strong"),arr=o("bert"),nrr=o(" \u2014 "),vU=a("a"),srr=o("BertForSequenceClassification"),lrr=o(" (BERT model)"),irr=l(),SF=a("li"),wFe=a("strong"),drr=o("big_bird"),mrr=o(" \u2014 "),FU=a("a"),crr=o("BigBirdForSequenceClassification"),frr=o(" (BigBird model)"),grr=l(),RF=a("li"),AFe=a("strong"),hrr=o("bigbird_pegasus"),urr=o(" \u2014 "),TU=a("a"),prr=o("BigBirdPegasusForSequenceClassification"),_rr=o(" (BigBird-Pegasus model)"),brr=l(),PF=a("li"),LFe=a("strong"),vrr=o("bloom"),Frr=o(" \u2014 "),MU=a("a"),Trr=o("BloomForSequenceClassification"),Mrr=o(" (BLOOM model)"),Err=l(),BF=a("li"),yFe=a("strong"),Crr=o("camembert"),wrr=o(" \u2014 "),EU=a("a"),Arr=o("CamembertForSequenceClassification"),Lrr=o(" (CamemBERT model)"),yrr=l(),IF=a("li"),xFe=a("strong"),xrr=o("canine"),$rr=o(" \u2014 "),CU=a("a"),krr=o("CanineForSequenceClassification"),Srr=o(" (CANINE model)"),Rrr=l(),NF=a("li"),$Fe=a("strong"),Prr=o("convbert"),Brr=o(" \u2014 "),wU=a("a"),Irr=o("ConvBertForSequenceClassification"),Nrr=o(" (ConvBERT model)"),qrr=l(),qF=a("li"),kFe=a("strong"),jrr=o("ctrl"),Drr=o(" \u2014 "),AU=a("a"),Grr=o("CTRLForSequenceClassification"),Orr=o(" (CTRL model)"),Vrr=l(),jF=a("li"),SFe=a("strong"),Xrr=o("data2vec-text"),zrr=o(" \u2014 "),LU=a("a"),Qrr=o("Data2VecTextForSequenceClassification"),Wrr=o(" (Data2VecText model)"),Urr=l(),DF=a("li"),RFe=a("strong"),Hrr=o("deberta"),Jrr=o(" \u2014 "),yU=a("a"),Yrr=o("DebertaForSequenceClassification"),Krr=o(" (DeBERTa model)"),Zrr=l(),GF=a("li"),PFe=a("strong"),etr=o("deberta-v2"),otr=o(" \u2014 "),xU=a("a"),rtr=o("DebertaV2ForSequenceClassification"),ttr=o(" (DeBERTa-v2 model)"),atr=l(),OF=a("li"),BFe=a("strong"),ntr=o("distilbert"),str=o(" \u2014 "),$U=a("a"),ltr=o("DistilBertForSequenceClassification"),itr=o(" (DistilBERT model)"),dtr=l(),VF=a("li"),IFe=a("strong"),mtr=o("electra"),ctr=o(" \u2014 "),kU=a("a"),ftr=o("ElectraForSequenceClassification"),gtr=o(" (ELECTRA model)"),htr=l(),XF=a("li"),NFe=a("strong"),utr=o("ernie"),ptr=o(" \u2014 "),SU=a("a"),_tr=o("ErnieForSequenceClassification"),btr=o(" (ERNIE model)"),vtr=l(),zF=a("li"),qFe=a("strong"),Ftr=o("esm"),Ttr=o(" \u2014 "),RU=a("a"),Mtr=o("EsmForSequenceClassification"),Etr=o(" (ESM model)"),Ctr=l(),QF=a("li"),jFe=a("strong"),wtr=o("flaubert"),Atr=o(" \u2014 "),PU=a("a"),Ltr=o("FlaubertForSequenceClassification"),ytr=o(" (FlauBERT model)"),xtr=l(),WF=a("li"),DFe=a("strong"),$tr=o("fnet"),ktr=o(" \u2014 "),BU=a("a"),Str=o("FNetForSequenceClassification"),Rtr=o(" (FNet model)"),Ptr=l(),UF=a("li"),GFe=a("strong"),Btr=o("funnel"),Itr=o(" \u2014 "),IU=a("a"),Ntr=o("FunnelForSequenceClassification"),qtr=o(" (Funnel Transformer model)"),jtr=l(),HF=a("li"),OFe=a("strong"),Dtr=o("gpt2"),Gtr=o(" \u2014 "),NU=a("a"),Otr=o("GPT2ForSequenceClassification"),Vtr=o(" (OpenAI GPT-2 model)"),Xtr=l(),JF=a("li"),VFe=a("strong"),ztr=o("gpt_neo"),Qtr=o(" \u2014 "),qU=a("a"),Wtr=o("GPTNeoForSequenceClassification"),Utr=o(" (GPT Neo model)"),Htr=l(),YF=a("li"),XFe=a("strong"),Jtr=o("gptj"),Ytr=o(" \u2014 "),jU=a("a"),Ktr=o("GPTJForSequenceClassification"),Ztr=o(" (GPT-J model)"),ear=l(),KF=a("li"),zFe=a("strong"),oar=o("ibert"),rar=o(" \u2014 "),DU=a("a"),tar=o("IBertForSequenceClassification"),aar=o(" (I-BERT model)"),nar=l(),ZF=a("li"),QFe=a("strong"),sar=o("layoutlm"),lar=o(" \u2014 "),GU=a("a"),iar=o("LayoutLMForSequenceClassification"),dar=o(" (LayoutLM model)"),mar=l(),eT=a("li"),WFe=a("strong"),car=o("layoutlmv2"),far=o(" \u2014 "),OU=a("a"),gar=o("LayoutLMv2ForSequenceClassification"),har=o(" (LayoutLMv2 model)"),uar=l(),oT=a("li"),UFe=a("strong"),par=o("layoutlmv3"),_ar=o(" \u2014 "),VU=a("a"),bar=o("LayoutLMv3ForSequenceClassification"),Far=o(" (LayoutLMv3 model)"),Tar=l(),rT=a("li"),HFe=a("strong"),Mar=o("led"),Ear=o(" \u2014 "),XU=a("a"),Car=o("LEDForSequenceClassification"),war=o(" (LED model)"),Aar=l(),tT=a("li"),JFe=a("strong"),Lar=o("longformer"),yar=o(" \u2014 "),zU=a("a"),xar=o("LongformerForSequenceClassification"),$ar=o(" (Longformer model)"),kar=l(),aT=a("li"),YFe=a("strong"),Sar=o("luke"),Rar=o(" \u2014 "),QU=a("a"),Par=o("LukeForSequenceClassification"),Bar=o(" (LUKE model)"),Iar=l(),nT=a("li"),KFe=a("strong"),Nar=o("markuplm"),qar=o(" \u2014 "),WU=a("a"),jar=o("MarkupLMForSequenceClassification"),Dar=o(" (MarkupLM model)"),Gar=l(),sT=a("li"),ZFe=a("strong"),Oar=o("mbart"),Var=o(" \u2014 "),UU=a("a"),Xar=o("MBartForSequenceClassification"),zar=o(" (mBART model)"),Qar=l(),lT=a("li"),eTe=a("strong"),War=o("megatron-bert"),Uar=o(" \u2014 "),HU=a("a"),Har=o("MegatronBertForSequenceClassification"),Jar=o(" (Megatron-BERT model)"),Yar=l(),iT=a("li"),oTe=a("strong"),Kar=o("mobilebert"),Zar=o(" \u2014 "),JU=a("a"),enr=o("MobileBertForSequenceClassification"),onr=o(" (MobileBERT model)"),rnr=l(),dT=a("li"),rTe=a("strong"),tnr=o("mpnet"),anr=o(" \u2014 "),YU=a("a"),nnr=o("MPNetForSequenceClassification"),snr=o(" (MPNet model)"),lnr=l(),mT=a("li"),tTe=a("strong"),inr=o("mvp"),dnr=o(" \u2014 "),KU=a("a"),mnr=o("MvpForSequenceClassification"),cnr=o(" (MVP model)"),fnr=l(),cT=a("li"),aTe=a("strong"),gnr=o("nezha"),hnr=o(" \u2014 "),ZU=a("a"),unr=o("NezhaForSequenceClassification"),pnr=o(" (Nezha model)"),_nr=l(),fT=a("li"),nTe=a("strong"),bnr=o("nystromformer"),vnr=o(" \u2014 "),eH=a("a"),Fnr=o("NystromformerForSequenceClassification"),Tnr=o(" (Nystr\xF6mformer model)"),Mnr=l(),gT=a("li"),sTe=a("strong"),Enr=o("openai-gpt"),Cnr=o(" \u2014 "),oH=a("a"),wnr=o("OpenAIGPTForSequenceClassification"),Anr=o(" (OpenAI GPT model)"),Lnr=l(),hT=a("li"),lTe=a("strong"),ynr=o("opt"),xnr=o(" \u2014 "),rH=a("a"),$nr=o("OPTForSequenceClassification"),knr=o(" (OPT model)"),Snr=l(),uT=a("li"),iTe=a("strong"),Rnr=o("perceiver"),Pnr=o(" \u2014 "),tH=a("a"),Bnr=o("PerceiverForSequenceClassification"),Inr=o(" (Perceiver model)"),Nnr=l(),pT=a("li"),dTe=a("strong"),qnr=o("plbart"),jnr=o(" \u2014 "),aH=a("a"),Dnr=o("PLBartForSequenceClassification"),Gnr=o(" (PLBart model)"),Onr=l(),_T=a("li"),mTe=a("strong"),Vnr=o("qdqbert"),Xnr=o(" \u2014 "),nH=a("a"),znr=o("QDQBertForSequenceClassification"),Qnr=o(" (QDQBert model)"),Wnr=l(),bT=a("li"),cTe=a("strong"),Unr=o("reformer"),Hnr=o(" \u2014 "),sH=a("a"),Jnr=o("ReformerForSequenceClassification"),Ynr=o(" (Reformer model)"),Knr=l(),vT=a("li"),fTe=a("strong"),Znr=o("rembert"),esr=o(" \u2014 "),lH=a("a"),osr=o("RemBertForSequenceClassification"),rsr=o(" (RemBERT model)"),tsr=l(),FT=a("li"),gTe=a("strong"),asr=o("roberta"),nsr=o(" \u2014 "),iH=a("a"),ssr=o("RobertaForSequenceClassification"),lsr=o(" (RoBERTa model)"),isr=l(),TT=a("li"),hTe=a("strong"),dsr=o("roformer"),msr=o(" \u2014 "),dH=a("a"),csr=o("RoFormerForSequenceClassification"),fsr=o(" (RoFormer model)"),gsr=l(),MT=a("li"),uTe=a("strong"),hsr=o("squeezebert"),usr=o(" \u2014 "),mH=a("a"),psr=o("SqueezeBertForSequenceClassification"),_sr=o(" (SqueezeBERT model)"),bsr=l(),ET=a("li"),pTe=a("strong"),vsr=o("tapas"),Fsr=o(" \u2014 "),cH=a("a"),Tsr=o("TapasForSequenceClassification"),Msr=o(" (TAPAS model)"),Esr=l(),CT=a("li"),_Te=a("strong"),Csr=o("transfo-xl"),wsr=o(" \u2014 "),fH=a("a"),Asr=o("TransfoXLForSequenceClassification"),Lsr=o(" (Transformer-XL model)"),ysr=l(),wT=a("li"),bTe=a("strong"),xsr=o("xlm"),$sr=o(" \u2014 "),gH=a("a"),ksr=o("XLMForSequenceClassification"),Ssr=o(" (XLM model)"),Rsr=l(),AT=a("li"),vTe=a("strong"),Psr=o("xlm-roberta"),Bsr=o(" \u2014 "),hH=a("a"),Isr=o("XLMRobertaForSequenceClassification"),Nsr=o(" (XLM-RoBERTa model)"),qsr=l(),LT=a("li"),FTe=a("strong"),jsr=o("xlm-roberta-xl"),Dsr=o(" \u2014 "),uH=a("a"),Gsr=o("XLMRobertaXLForSequenceClassification"),Osr=o(" (XLM-RoBERTa-XL model)"),Vsr=l(),yT=a("li"),TTe=a("strong"),Xsr=o("xlnet"),zsr=o(" \u2014 "),pH=a("a"),Qsr=o("XLNetForSequenceClassification"),Wsr=o(" (XLNet model)"),Usr=l(),xT=a("li"),MTe=a("strong"),Hsr=o("yoso"),Jsr=o(" \u2014 "),_H=a("a"),Ysr=o("YosoForSequenceClassification"),Ksr=o(" (YOSO model)"),Zsr=l(),$T=a("p"),elr=o("The model is set in evaluation mode by default using "),ETe=a("code"),olr=o("model.eval()"),rlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CTe=a("code"),tlr=o("model.train()"),alr=l(),F(kT.$$.fragment),ceo=l(),Bd=a("h2"),ST=a("a"),wTe=a("span"),F(r$.$$.fragment),nlr=l(),ATe=a("span"),slr=o("AutoModelForMultipleChoice"),feo=l(),Do=a("div"),F(t$.$$.fragment),llr=l(),Id=a("p"),ilr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),bH=a("a"),dlr=o("from_pretrained()"),mlr=o(" class method or the "),vH=a("a"),clr=o("from_config()"),flr=o(` class
method.`),glr=l(),a$=a("p"),hlr=o("This class cannot be instantiated directly using "),LTe=a("code"),ulr=o("__init__()"),plr=o(" (throws an error)."),_lr=l(),Et=a("div"),F(n$.$$.fragment),blr=l(),yTe=a("p"),vlr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Flr=l(),Nd=a("p"),Tlr=o(`Note:
Loading a model from its configuration file does `),xTe=a("strong"),Mlr=o("not"),Elr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=a("a"),Clr=o("from_pretrained()"),wlr=o(" to load the model weights."),Alr=l(),F(RT.$$.fragment),Llr=l(),no=a("div"),F(s$.$$.fragment),ylr=l(),$Te=a("p"),xlr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$lr=l(),rn=a("p"),klr=o("The model class to instantiate is selected based on the "),kTe=a("code"),Slr=o("model_type"),Rlr=o(` property of the config object (either
passed as an argument or loaded from `),STe=a("code"),Plr=o("pretrained_model_name_or_path"),Blr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=a("code"),Ilr=o("pretrained_model_name_or_path"),Nlr=o(":"),qlr=l(),Z=a("ul"),PT=a("li"),PTe=a("strong"),jlr=o("albert"),Dlr=o(" \u2014 "),TH=a("a"),Glr=o("AlbertForMultipleChoice"),Olr=o(" (ALBERT model)"),Vlr=l(),BT=a("li"),BTe=a("strong"),Xlr=o("bert"),zlr=o(" \u2014 "),MH=a("a"),Qlr=o("BertForMultipleChoice"),Wlr=o(" (BERT model)"),Ulr=l(),IT=a("li"),ITe=a("strong"),Hlr=o("big_bird"),Jlr=o(" \u2014 "),EH=a("a"),Ylr=o("BigBirdForMultipleChoice"),Klr=o(" (BigBird model)"),Zlr=l(),NT=a("li"),NTe=a("strong"),eir=o("camembert"),oir=o(" \u2014 "),CH=a("a"),rir=o("CamembertForMultipleChoice"),tir=o(" (CamemBERT model)"),air=l(),qT=a("li"),qTe=a("strong"),nir=o("canine"),sir=o(" \u2014 "),wH=a("a"),lir=o("CanineForMultipleChoice"),iir=o(" (CANINE model)"),dir=l(),jT=a("li"),jTe=a("strong"),mir=o("convbert"),cir=o(" \u2014 "),AH=a("a"),fir=o("ConvBertForMultipleChoice"),gir=o(" (ConvBERT model)"),hir=l(),DT=a("li"),DTe=a("strong"),uir=o("data2vec-text"),pir=o(" \u2014 "),LH=a("a"),_ir=o("Data2VecTextForMultipleChoice"),bir=o(" (Data2VecText model)"),vir=l(),GT=a("li"),GTe=a("strong"),Fir=o("deberta-v2"),Tir=o(" \u2014 "),yH=a("a"),Mir=o("DebertaV2ForMultipleChoice"),Eir=o(" (DeBERTa-v2 model)"),Cir=l(),OT=a("li"),OTe=a("strong"),wir=o("distilbert"),Air=o(" \u2014 "),xH=a("a"),Lir=o("DistilBertForMultipleChoice"),yir=o(" (DistilBERT model)"),xir=l(),VT=a("li"),VTe=a("strong"),$ir=o("electra"),kir=o(" \u2014 "),$H=a("a"),Sir=o("ElectraForMultipleChoice"),Rir=o(" (ELECTRA model)"),Pir=l(),XT=a("li"),XTe=a("strong"),Bir=o("ernie"),Iir=o(" \u2014 "),kH=a("a"),Nir=o("ErnieForMultipleChoice"),qir=o(" (ERNIE model)"),jir=l(),zT=a("li"),zTe=a("strong"),Dir=o("flaubert"),Gir=o(" \u2014 "),SH=a("a"),Oir=o("FlaubertForMultipleChoice"),Vir=o(" (FlauBERT model)"),Xir=l(),QT=a("li"),QTe=a("strong"),zir=o("fnet"),Qir=o(" \u2014 "),RH=a("a"),Wir=o("FNetForMultipleChoice"),Uir=o(" (FNet model)"),Hir=l(),WT=a("li"),WTe=a("strong"),Jir=o("funnel"),Yir=o(" \u2014 "),PH=a("a"),Kir=o("FunnelForMultipleChoice"),Zir=o(" (Funnel Transformer model)"),edr=l(),UT=a("li"),UTe=a("strong"),odr=o("ibert"),rdr=o(" \u2014 "),BH=a("a"),tdr=o("IBertForMultipleChoice"),adr=o(" (I-BERT model)"),ndr=l(),HT=a("li"),HTe=a("strong"),sdr=o("longformer"),ldr=o(" \u2014 "),IH=a("a"),idr=o("LongformerForMultipleChoice"),ddr=o(" (Longformer model)"),mdr=l(),JT=a("li"),JTe=a("strong"),cdr=o("luke"),fdr=o(" \u2014 "),NH=a("a"),gdr=o("LukeForMultipleChoice"),hdr=o(" (LUKE model)"),udr=l(),YT=a("li"),YTe=a("strong"),pdr=o("megatron-bert"),_dr=o(" \u2014 "),qH=a("a"),bdr=o("MegatronBertForMultipleChoice"),vdr=o(" (Megatron-BERT model)"),Fdr=l(),KT=a("li"),KTe=a("strong"),Tdr=o("mobilebert"),Mdr=o(" \u2014 "),jH=a("a"),Edr=o("MobileBertForMultipleChoice"),Cdr=o(" (MobileBERT model)"),wdr=l(),ZT=a("li"),ZTe=a("strong"),Adr=o("mpnet"),Ldr=o(" \u2014 "),DH=a("a"),ydr=o("MPNetForMultipleChoice"),xdr=o(" (MPNet model)"),$dr=l(),eM=a("li"),eMe=a("strong"),kdr=o("nezha"),Sdr=o(" \u2014 "),GH=a("a"),Rdr=o("NezhaForMultipleChoice"),Pdr=o(" (Nezha model)"),Bdr=l(),oM=a("li"),oMe=a("strong"),Idr=o("nystromformer"),Ndr=o(" \u2014 "),OH=a("a"),qdr=o("NystromformerForMultipleChoice"),jdr=o(" (Nystr\xF6mformer model)"),Ddr=l(),rM=a("li"),rMe=a("strong"),Gdr=o("qdqbert"),Odr=o(" \u2014 "),VH=a("a"),Vdr=o("QDQBertForMultipleChoice"),Xdr=o(" (QDQBert model)"),zdr=l(),tM=a("li"),tMe=a("strong"),Qdr=o("rembert"),Wdr=o(" \u2014 "),XH=a("a"),Udr=o("RemBertForMultipleChoice"),Hdr=o(" (RemBERT model)"),Jdr=l(),aM=a("li"),aMe=a("strong"),Ydr=o("roberta"),Kdr=o(" \u2014 "),zH=a("a"),Zdr=o("RobertaForMultipleChoice"),emr=o(" (RoBERTa model)"),omr=l(),nM=a("li"),nMe=a("strong"),rmr=o("roformer"),tmr=o(" \u2014 "),QH=a("a"),amr=o("RoFormerForMultipleChoice"),nmr=o(" (RoFormer model)"),smr=l(),sM=a("li"),sMe=a("strong"),lmr=o("squeezebert"),imr=o(" \u2014 "),WH=a("a"),dmr=o("SqueezeBertForMultipleChoice"),mmr=o(" (SqueezeBERT model)"),cmr=l(),lM=a("li"),lMe=a("strong"),fmr=o("xlm"),gmr=o(" \u2014 "),UH=a("a"),hmr=o("XLMForMultipleChoice"),umr=o(" (XLM model)"),pmr=l(),iM=a("li"),iMe=a("strong"),_mr=o("xlm-roberta"),bmr=o(" \u2014 "),HH=a("a"),vmr=o("XLMRobertaForMultipleChoice"),Fmr=o(" (XLM-RoBERTa model)"),Tmr=l(),dM=a("li"),dMe=a("strong"),Mmr=o("xlm-roberta-xl"),Emr=o(" \u2014 "),JH=a("a"),Cmr=o("XLMRobertaXLForMultipleChoice"),wmr=o(" (XLM-RoBERTa-XL model)"),Amr=l(),mM=a("li"),mMe=a("strong"),Lmr=o("xlnet"),ymr=o(" \u2014 "),YH=a("a"),xmr=o("XLNetForMultipleChoice"),$mr=o(" (XLNet model)"),kmr=l(),cM=a("li"),cMe=a("strong"),Smr=o("yoso"),Rmr=o(" \u2014 "),KH=a("a"),Pmr=o("YosoForMultipleChoice"),Bmr=o(" (YOSO model)"),Imr=l(),fM=a("p"),Nmr=o("The model is set in evaluation mode by default using "),fMe=a("code"),qmr=o("model.eval()"),jmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gMe=a("code"),Dmr=o("model.train()"),Gmr=l(),F(gM.$$.fragment),geo=l(),qd=a("h2"),hM=a("a"),hMe=a("span"),F(l$.$$.fragment),Omr=l(),uMe=a("span"),Vmr=o("AutoModelForNextSentencePrediction"),heo=l(),Go=a("div"),F(i$.$$.fragment),Xmr=l(),jd=a("p"),zmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ZH=a("a"),Qmr=o("from_pretrained()"),Wmr=o(" class method or the "),eJ=a("a"),Umr=o("from_config()"),Hmr=o(` class
method.`),Jmr=l(),d$=a("p"),Ymr=o("This class cannot be instantiated directly using "),pMe=a("code"),Kmr=o("__init__()"),Zmr=o(" (throws an error)."),ecr=l(),Ct=a("div"),F(m$.$$.fragment),ocr=l(),_Me=a("p"),rcr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),tcr=l(),Dd=a("p"),acr=o(`Note:
Loading a model from its configuration file does `),bMe=a("strong"),ncr=o("not"),scr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=a("a"),lcr=o("from_pretrained()"),icr=o(" to load the model weights."),dcr=l(),F(uM.$$.fragment),mcr=l(),so=a("div"),F(c$.$$.fragment),ccr=l(),vMe=a("p"),fcr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),gcr=l(),tn=a("p"),hcr=o("The model class to instantiate is selected based on the "),FMe=a("code"),ucr=o("model_type"),pcr=o(` property of the config object (either
passed as an argument or loaded from `),TMe=a("code"),_cr=o("pretrained_model_name_or_path"),bcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MMe=a("code"),vcr=o("pretrained_model_name_or_path"),Fcr=o(":"),Tcr=l(),Ue=a("ul"),pM=a("li"),EMe=a("strong"),Mcr=o("bert"),Ecr=o(" \u2014 "),rJ=a("a"),Ccr=o("BertForNextSentencePrediction"),wcr=o(" (BERT model)"),Acr=l(),_M=a("li"),CMe=a("strong"),Lcr=o("ernie"),ycr=o(" \u2014 "),tJ=a("a"),xcr=o("ErnieForNextSentencePrediction"),$cr=o(" (ERNIE model)"),kcr=l(),bM=a("li"),wMe=a("strong"),Scr=o("fnet"),Rcr=o(" \u2014 "),aJ=a("a"),Pcr=o("FNetForNextSentencePrediction"),Bcr=o(" (FNet model)"),Icr=l(),vM=a("li"),AMe=a("strong"),Ncr=o("megatron-bert"),qcr=o(" \u2014 "),nJ=a("a"),jcr=o("MegatronBertForNextSentencePrediction"),Dcr=o(" (Megatron-BERT model)"),Gcr=l(),FM=a("li"),LMe=a("strong"),Ocr=o("mobilebert"),Vcr=o(" \u2014 "),sJ=a("a"),Xcr=o("MobileBertForNextSentencePrediction"),zcr=o(" (MobileBERT model)"),Qcr=l(),TM=a("li"),yMe=a("strong"),Wcr=o("nezha"),Ucr=o(" \u2014 "),lJ=a("a"),Hcr=o("NezhaForNextSentencePrediction"),Jcr=o(" (Nezha model)"),Ycr=l(),MM=a("li"),xMe=a("strong"),Kcr=o("qdqbert"),Zcr=o(" \u2014 "),iJ=a("a"),efr=o("QDQBertForNextSentencePrediction"),ofr=o(" (QDQBert model)"),rfr=l(),EM=a("p"),tfr=o("The model is set in evaluation mode by default using "),$Me=a("code"),afr=o("model.eval()"),nfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kMe=a("code"),sfr=o("model.train()"),lfr=l(),F(CM.$$.fragment),ueo=l(),Gd=a("h2"),wM=a("a"),SMe=a("span"),F(f$.$$.fragment),ifr=l(),RMe=a("span"),dfr=o("AutoModelForTokenClassification"),peo=l(),Oo=a("div"),F(g$.$$.fragment),mfr=l(),Od=a("p"),cfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),dJ=a("a"),ffr=o("from_pretrained()"),gfr=o(" class method or the "),mJ=a("a"),hfr=o("from_config()"),ufr=o(` class
method.`),pfr=l(),h$=a("p"),_fr=o("This class cannot be instantiated directly using "),PMe=a("code"),bfr=o("__init__()"),vfr=o(" (throws an error)."),Ffr=l(),wt=a("div"),F(u$.$$.fragment),Tfr=l(),BMe=a("p"),Mfr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Efr=l(),Vd=a("p"),Cfr=o(`Note:
Loading a model from its configuration file does `),IMe=a("strong"),wfr=o("not"),Afr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cJ=a("a"),Lfr=o("from_pretrained()"),yfr=o(" to load the model weights."),xfr=l(),F(AM.$$.fragment),$fr=l(),lo=a("div"),F(p$.$$.fragment),kfr=l(),NMe=a("p"),Sfr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Rfr=l(),an=a("p"),Pfr=o("The model class to instantiate is selected based on the "),qMe=a("code"),Bfr=o("model_type"),Ifr=o(` property of the config object (either
passed as an argument or loaded from `),jMe=a("code"),Nfr=o("pretrained_model_name_or_path"),qfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DMe=a("code"),jfr=o("pretrained_model_name_or_path"),Dfr=o(":"),Gfr=l(),H=a("ul"),LM=a("li"),GMe=a("strong"),Ofr=o("albert"),Vfr=o(" \u2014 "),fJ=a("a"),Xfr=o("AlbertForTokenClassification"),zfr=o(" (ALBERT model)"),Qfr=l(),yM=a("li"),OMe=a("strong"),Wfr=o("bert"),Ufr=o(" \u2014 "),gJ=a("a"),Hfr=o("BertForTokenClassification"),Jfr=o(" (BERT model)"),Yfr=l(),xM=a("li"),VMe=a("strong"),Kfr=o("big_bird"),Zfr=o(" \u2014 "),hJ=a("a"),egr=o("BigBirdForTokenClassification"),ogr=o(" (BigBird model)"),rgr=l(),$M=a("li"),XMe=a("strong"),tgr=o("bloom"),agr=o(" \u2014 "),uJ=a("a"),ngr=o("BloomForTokenClassification"),sgr=o(" (BLOOM model)"),lgr=l(),kM=a("li"),zMe=a("strong"),igr=o("camembert"),dgr=o(" \u2014 "),pJ=a("a"),mgr=o("CamembertForTokenClassification"),cgr=o(" (CamemBERT model)"),fgr=l(),SM=a("li"),QMe=a("strong"),ggr=o("canine"),hgr=o(" \u2014 "),_J=a("a"),ugr=o("CanineForTokenClassification"),pgr=o(" (CANINE model)"),_gr=l(),RM=a("li"),WMe=a("strong"),bgr=o("convbert"),vgr=o(" \u2014 "),bJ=a("a"),Fgr=o("ConvBertForTokenClassification"),Tgr=o(" (ConvBERT model)"),Mgr=l(),PM=a("li"),UMe=a("strong"),Egr=o("data2vec-text"),Cgr=o(" \u2014 "),vJ=a("a"),wgr=o("Data2VecTextForTokenClassification"),Agr=o(" (Data2VecText model)"),Lgr=l(),BM=a("li"),HMe=a("strong"),ygr=o("deberta"),xgr=o(" \u2014 "),FJ=a("a"),$gr=o("DebertaForTokenClassification"),kgr=o(" (DeBERTa model)"),Sgr=l(),IM=a("li"),JMe=a("strong"),Rgr=o("deberta-v2"),Pgr=o(" \u2014 "),TJ=a("a"),Bgr=o("DebertaV2ForTokenClassification"),Igr=o(" (DeBERTa-v2 model)"),Ngr=l(),NM=a("li"),YMe=a("strong"),qgr=o("distilbert"),jgr=o(" \u2014 "),MJ=a("a"),Dgr=o("DistilBertForTokenClassification"),Ggr=o(" (DistilBERT model)"),Ogr=l(),qM=a("li"),KMe=a("strong"),Vgr=o("electra"),Xgr=o(" \u2014 "),EJ=a("a"),zgr=o("ElectraForTokenClassification"),Qgr=o(" (ELECTRA model)"),Wgr=l(),jM=a("li"),ZMe=a("strong"),Ugr=o("ernie"),Hgr=o(" \u2014 "),CJ=a("a"),Jgr=o("ErnieForTokenClassification"),Ygr=o(" (ERNIE model)"),Kgr=l(),DM=a("li"),eEe=a("strong"),Zgr=o("esm"),ehr=o(" \u2014 "),wJ=a("a"),ohr=o("EsmForTokenClassification"),rhr=o(" (ESM model)"),thr=l(),GM=a("li"),oEe=a("strong"),ahr=o("flaubert"),nhr=o(" \u2014 "),AJ=a("a"),shr=o("FlaubertForTokenClassification"),lhr=o(" (FlauBERT model)"),ihr=l(),OM=a("li"),rEe=a("strong"),dhr=o("fnet"),mhr=o(" \u2014 "),LJ=a("a"),chr=o("FNetForTokenClassification"),fhr=o(" (FNet model)"),ghr=l(),VM=a("li"),tEe=a("strong"),hhr=o("funnel"),uhr=o(" \u2014 "),yJ=a("a"),phr=o("FunnelForTokenClassification"),_hr=o(" (Funnel Transformer model)"),bhr=l(),XM=a("li"),aEe=a("strong"),vhr=o("gpt2"),Fhr=o(" \u2014 "),xJ=a("a"),Thr=o("GPT2ForTokenClassification"),Mhr=o(" (OpenAI GPT-2 model)"),Ehr=l(),zM=a("li"),nEe=a("strong"),Chr=o("ibert"),whr=o(" \u2014 "),$J=a("a"),Ahr=o("IBertForTokenClassification"),Lhr=o(" (I-BERT model)"),yhr=l(),QM=a("li"),sEe=a("strong"),xhr=o("layoutlm"),$hr=o(" \u2014 "),kJ=a("a"),khr=o("LayoutLMForTokenClassification"),Shr=o(" (LayoutLM model)"),Rhr=l(),WM=a("li"),lEe=a("strong"),Phr=o("layoutlmv2"),Bhr=o(" \u2014 "),SJ=a("a"),Ihr=o("LayoutLMv2ForTokenClassification"),Nhr=o(" (LayoutLMv2 model)"),qhr=l(),UM=a("li"),iEe=a("strong"),jhr=o("layoutlmv3"),Dhr=o(" \u2014 "),RJ=a("a"),Ghr=o("LayoutLMv3ForTokenClassification"),Ohr=o(" (LayoutLMv3 model)"),Vhr=l(),HM=a("li"),dEe=a("strong"),Xhr=o("longformer"),zhr=o(" \u2014 "),PJ=a("a"),Qhr=o("LongformerForTokenClassification"),Whr=o(" (Longformer model)"),Uhr=l(),JM=a("li"),mEe=a("strong"),Hhr=o("luke"),Jhr=o(" \u2014 "),BJ=a("a"),Yhr=o("LukeForTokenClassification"),Khr=o(" (LUKE model)"),Zhr=l(),YM=a("li"),cEe=a("strong"),eur=o("markuplm"),our=o(" \u2014 "),IJ=a("a"),rur=o("MarkupLMForTokenClassification"),tur=o(" (MarkupLM model)"),aur=l(),KM=a("li"),fEe=a("strong"),nur=o("megatron-bert"),sur=o(" \u2014 "),NJ=a("a"),lur=o("MegatronBertForTokenClassification"),iur=o(" (Megatron-BERT model)"),dur=l(),ZM=a("li"),gEe=a("strong"),mur=o("mobilebert"),cur=o(" \u2014 "),qJ=a("a"),fur=o("MobileBertForTokenClassification"),gur=o(" (MobileBERT model)"),hur=l(),eE=a("li"),hEe=a("strong"),uur=o("mpnet"),pur=o(" \u2014 "),jJ=a("a"),_ur=o("MPNetForTokenClassification"),bur=o(" (MPNet model)"),vur=l(),oE=a("li"),uEe=a("strong"),Fur=o("nezha"),Tur=o(" \u2014 "),DJ=a("a"),Mur=o("NezhaForTokenClassification"),Eur=o(" (Nezha model)"),Cur=l(),rE=a("li"),pEe=a("strong"),wur=o("nystromformer"),Aur=o(" \u2014 "),GJ=a("a"),Lur=o("NystromformerForTokenClassification"),yur=o(" (Nystr\xF6mformer model)"),xur=l(),tE=a("li"),_Ee=a("strong"),$ur=o("qdqbert"),kur=o(" \u2014 "),OJ=a("a"),Sur=o("QDQBertForTokenClassification"),Rur=o(" (QDQBert model)"),Pur=l(),aE=a("li"),bEe=a("strong"),Bur=o("rembert"),Iur=o(" \u2014 "),VJ=a("a"),Nur=o("RemBertForTokenClassification"),qur=o(" (RemBERT model)"),jur=l(),nE=a("li"),vEe=a("strong"),Dur=o("roberta"),Gur=o(" \u2014 "),XJ=a("a"),Our=o("RobertaForTokenClassification"),Vur=o(" (RoBERTa model)"),Xur=l(),sE=a("li"),FEe=a("strong"),zur=o("roformer"),Qur=o(" \u2014 "),zJ=a("a"),Wur=o("RoFormerForTokenClassification"),Uur=o(" (RoFormer model)"),Hur=l(),lE=a("li"),TEe=a("strong"),Jur=o("squeezebert"),Yur=o(" \u2014 "),QJ=a("a"),Kur=o("SqueezeBertForTokenClassification"),Zur=o(" (SqueezeBERT model)"),epr=l(),iE=a("li"),MEe=a("strong"),opr=o("xlm"),rpr=o(" \u2014 "),WJ=a("a"),tpr=o("XLMForTokenClassification"),apr=o(" (XLM model)"),npr=l(),dE=a("li"),EEe=a("strong"),spr=o("xlm-roberta"),lpr=o(" \u2014 "),UJ=a("a"),ipr=o("XLMRobertaForTokenClassification"),dpr=o(" (XLM-RoBERTa model)"),mpr=l(),mE=a("li"),CEe=a("strong"),cpr=o("xlm-roberta-xl"),fpr=o(" \u2014 "),HJ=a("a"),gpr=o("XLMRobertaXLForTokenClassification"),hpr=o(" (XLM-RoBERTa-XL model)"),upr=l(),cE=a("li"),wEe=a("strong"),ppr=o("xlnet"),_pr=o(" \u2014 "),JJ=a("a"),bpr=o("XLNetForTokenClassification"),vpr=o(" (XLNet model)"),Fpr=l(),fE=a("li"),AEe=a("strong"),Tpr=o("yoso"),Mpr=o(" \u2014 "),YJ=a("a"),Epr=o("YosoForTokenClassification"),Cpr=o(" (YOSO model)"),wpr=l(),gE=a("p"),Apr=o("The model is set in evaluation mode by default using "),LEe=a("code"),Lpr=o("model.eval()"),ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yEe=a("code"),xpr=o("model.train()"),$pr=l(),F(hE.$$.fragment),_eo=l(),Xd=a("h2"),uE=a("a"),xEe=a("span"),F(_$.$$.fragment),kpr=l(),$Ee=a("span"),Spr=o("AutoModelForQuestionAnswering"),beo=l(),Vo=a("div"),F(b$.$$.fragment),Rpr=l(),zd=a("p"),Ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KJ=a("a"),Bpr=o("from_pretrained()"),Ipr=o(" class method or the "),ZJ=a("a"),Npr=o("from_config()"),qpr=o(` class
method.`),jpr=l(),v$=a("p"),Dpr=o("This class cannot be instantiated directly using "),kEe=a("code"),Gpr=o("__init__()"),Opr=o(" (throws an error)."),Vpr=l(),At=a("div"),F(F$.$$.fragment),Xpr=l(),SEe=a("p"),zpr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Qpr=l(),Qd=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),REe=a("strong"),Upr=o("not"),Hpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eY=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" to load the model weights."),Kpr=l(),F(pE.$$.fragment),Zpr=l(),io=a("div"),F(T$.$$.fragment),e_r=l(),PEe=a("p"),o_r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),r_r=l(),nn=a("p"),t_r=o("The model class to instantiate is selected based on the "),BEe=a("code"),a_r=o("model_type"),n_r=o(` property of the config object (either
passed as an argument or loaded from `),IEe=a("code"),s_r=o("pretrained_model_name_or_path"),l_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NEe=a("code"),i_r=o("pretrained_model_name_or_path"),d_r=o(":"),m_r=l(),V=a("ul"),_E=a("li"),qEe=a("strong"),c_r=o("albert"),f_r=o(" \u2014 "),oY=a("a"),g_r=o("AlbertForQuestionAnswering"),h_r=o(" (ALBERT model)"),u_r=l(),bE=a("li"),jEe=a("strong"),p_r=o("bart"),__r=o(" \u2014 "),rY=a("a"),b_r=o("BartForQuestionAnswering"),v_r=o(" (BART model)"),F_r=l(),vE=a("li"),DEe=a("strong"),T_r=o("bert"),M_r=o(" \u2014 "),tY=a("a"),E_r=o("BertForQuestionAnswering"),C_r=o(" (BERT model)"),w_r=l(),FE=a("li"),GEe=a("strong"),A_r=o("big_bird"),L_r=o(" \u2014 "),aY=a("a"),y_r=o("BigBirdForQuestionAnswering"),x_r=o(" (BigBird model)"),$_r=l(),TE=a("li"),OEe=a("strong"),k_r=o("bigbird_pegasus"),S_r=o(" \u2014 "),nY=a("a"),R_r=o("BigBirdPegasusForQuestionAnswering"),P_r=o(" (BigBird-Pegasus model)"),B_r=l(),ME=a("li"),VEe=a("strong"),I_r=o("camembert"),N_r=o(" \u2014 "),sY=a("a"),q_r=o("CamembertForQuestionAnswering"),j_r=o(" (CamemBERT model)"),D_r=l(),EE=a("li"),XEe=a("strong"),G_r=o("canine"),O_r=o(" \u2014 "),lY=a("a"),V_r=o("CanineForQuestionAnswering"),X_r=o(" (CANINE model)"),z_r=l(),CE=a("li"),zEe=a("strong"),Q_r=o("convbert"),W_r=o(" \u2014 "),iY=a("a"),U_r=o("ConvBertForQuestionAnswering"),H_r=o(" (ConvBERT model)"),J_r=l(),wE=a("li"),QEe=a("strong"),Y_r=o("data2vec-text"),K_r=o(" \u2014 "),dY=a("a"),Z_r=o("Data2VecTextForQuestionAnswering"),e2r=o(" (Data2VecText model)"),o2r=l(),AE=a("li"),WEe=a("strong"),r2r=o("deberta"),t2r=o(" \u2014 "),mY=a("a"),a2r=o("DebertaForQuestionAnswering"),n2r=o(" (DeBERTa model)"),s2r=l(),LE=a("li"),UEe=a("strong"),l2r=o("deberta-v2"),i2r=o(" \u2014 "),cY=a("a"),d2r=o("DebertaV2ForQuestionAnswering"),m2r=o(" (DeBERTa-v2 model)"),c2r=l(),yE=a("li"),HEe=a("strong"),f2r=o("distilbert"),g2r=o(" \u2014 "),fY=a("a"),h2r=o("DistilBertForQuestionAnswering"),u2r=o(" (DistilBERT model)"),p2r=l(),xE=a("li"),JEe=a("strong"),_2r=o("electra"),b2r=o(" \u2014 "),gY=a("a"),v2r=o("ElectraForQuestionAnswering"),F2r=o(" (ELECTRA model)"),T2r=l(),$E=a("li"),YEe=a("strong"),M2r=o("ernie"),E2r=o(" \u2014 "),hY=a("a"),C2r=o("ErnieForQuestionAnswering"),w2r=o(" (ERNIE model)"),A2r=l(),kE=a("li"),KEe=a("strong"),L2r=o("flaubert"),y2r=o(" \u2014 "),uY=a("a"),x2r=o("FlaubertForQuestionAnsweringSimple"),$2r=o(" (FlauBERT model)"),k2r=l(),SE=a("li"),ZEe=a("strong"),S2r=o("fnet"),R2r=o(" \u2014 "),pY=a("a"),P2r=o("FNetForQuestionAnswering"),B2r=o(" (FNet model)"),I2r=l(),RE=a("li"),e4e=a("strong"),N2r=o("funnel"),q2r=o(" \u2014 "),_Y=a("a"),j2r=o("FunnelForQuestionAnswering"),D2r=o(" (Funnel Transformer model)"),G2r=l(),PE=a("li"),o4e=a("strong"),O2r=o("gptj"),V2r=o(" \u2014 "),bY=a("a"),X2r=o("GPTJForQuestionAnswering"),z2r=o(" (GPT-J model)"),Q2r=l(),BE=a("li"),r4e=a("strong"),W2r=o("ibert"),U2r=o(" \u2014 "),vY=a("a"),H2r=o("IBertForQuestionAnswering"),J2r=o(" (I-BERT model)"),Y2r=l(),IE=a("li"),t4e=a("strong"),K2r=o("layoutlmv2"),Z2r=o(" \u2014 "),FY=a("a"),e1r=o("LayoutLMv2ForQuestionAnswering"),o1r=o(" (LayoutLMv2 model)"),r1r=l(),NE=a("li"),a4e=a("strong"),t1r=o("layoutlmv3"),a1r=o(" \u2014 "),TY=a("a"),n1r=o("LayoutLMv3ForQuestionAnswering"),s1r=o(" (LayoutLMv3 model)"),l1r=l(),qE=a("li"),n4e=a("strong"),i1r=o("led"),d1r=o(" \u2014 "),MY=a("a"),m1r=o("LEDForQuestionAnswering"),c1r=o(" (LED model)"),f1r=l(),jE=a("li"),s4e=a("strong"),g1r=o("longformer"),h1r=o(" \u2014 "),EY=a("a"),u1r=o("LongformerForQuestionAnswering"),p1r=o(" (Longformer model)"),_1r=l(),DE=a("li"),l4e=a("strong"),b1r=o("luke"),v1r=o(" \u2014 "),CY=a("a"),F1r=o("LukeForQuestionAnswering"),T1r=o(" (LUKE model)"),M1r=l(),GE=a("li"),i4e=a("strong"),E1r=o("lxmert"),C1r=o(" \u2014 "),wY=a("a"),w1r=o("LxmertForQuestionAnswering"),A1r=o(" (LXMERT model)"),L1r=l(),OE=a("li"),d4e=a("strong"),y1r=o("markuplm"),x1r=o(" \u2014 "),AY=a("a"),$1r=o("MarkupLMForQuestionAnswering"),k1r=o(" (MarkupLM model)"),S1r=l(),VE=a("li"),m4e=a("strong"),R1r=o("mbart"),P1r=o(" \u2014 "),LY=a("a"),B1r=o("MBartForQuestionAnswering"),I1r=o(" (mBART model)"),N1r=l(),XE=a("li"),c4e=a("strong"),q1r=o("megatron-bert"),j1r=o(" \u2014 "),yY=a("a"),D1r=o("MegatronBertForQuestionAnswering"),G1r=o(" (Megatron-BERT model)"),O1r=l(),zE=a("li"),f4e=a("strong"),V1r=o("mobilebert"),X1r=o(" \u2014 "),xY=a("a"),z1r=o("MobileBertForQuestionAnswering"),Q1r=o(" (MobileBERT model)"),W1r=l(),QE=a("li"),g4e=a("strong"),U1r=o("mpnet"),H1r=o(" \u2014 "),$Y=a("a"),J1r=o("MPNetForQuestionAnswering"),Y1r=o(" (MPNet model)"),K1r=l(),WE=a("li"),h4e=a("strong"),Z1r=o("mvp"),ebr=o(" \u2014 "),kY=a("a"),obr=o("MvpForQuestionAnswering"),rbr=o(" (MVP model)"),tbr=l(),UE=a("li"),u4e=a("strong"),abr=o("nezha"),nbr=o(" \u2014 "),SY=a("a"),sbr=o("NezhaForQuestionAnswering"),lbr=o(" (Nezha model)"),ibr=l(),HE=a("li"),p4e=a("strong"),dbr=o("nystromformer"),mbr=o(" \u2014 "),RY=a("a"),cbr=o("NystromformerForQuestionAnswering"),fbr=o(" (Nystr\xF6mformer model)"),gbr=l(),JE=a("li"),_4e=a("strong"),hbr=o("qdqbert"),ubr=o(" \u2014 "),PY=a("a"),pbr=o("QDQBertForQuestionAnswering"),_br=o(" (QDQBert model)"),bbr=l(),YE=a("li"),b4e=a("strong"),vbr=o("reformer"),Fbr=o(" \u2014 "),BY=a("a"),Tbr=o("ReformerForQuestionAnswering"),Mbr=o(" (Reformer model)"),Ebr=l(),KE=a("li"),v4e=a("strong"),Cbr=o("rembert"),wbr=o(" \u2014 "),IY=a("a"),Abr=o("RemBertForQuestionAnswering"),Lbr=o(" (RemBERT model)"),ybr=l(),ZE=a("li"),F4e=a("strong"),xbr=o("roberta"),$br=o(" \u2014 "),NY=a("a"),kbr=o("RobertaForQuestionAnswering"),Sbr=o(" (RoBERTa model)"),Rbr=l(),e4=a("li"),T4e=a("strong"),Pbr=o("roformer"),Bbr=o(" \u2014 "),qY=a("a"),Ibr=o("RoFormerForQuestionAnswering"),Nbr=o(" (RoFormer model)"),qbr=l(),o4=a("li"),M4e=a("strong"),jbr=o("splinter"),Dbr=o(" \u2014 "),jY=a("a"),Gbr=o("SplinterForQuestionAnswering"),Obr=o(" (Splinter model)"),Vbr=l(),r4=a("li"),E4e=a("strong"),Xbr=o("squeezebert"),zbr=o(" \u2014 "),DY=a("a"),Qbr=o("SqueezeBertForQuestionAnswering"),Wbr=o(" (SqueezeBERT model)"),Ubr=l(),t4=a("li"),C4e=a("strong"),Hbr=o("xlm"),Jbr=o(" \u2014 "),GY=a("a"),Ybr=o("XLMForQuestionAnsweringSimple"),Kbr=o(" (XLM model)"),Zbr=l(),a4=a("li"),w4e=a("strong"),evr=o("xlm-roberta"),ovr=o(" \u2014 "),OY=a("a"),rvr=o("XLMRobertaForQuestionAnswering"),tvr=o(" (XLM-RoBERTa model)"),avr=l(),n4=a("li"),A4e=a("strong"),nvr=o("xlm-roberta-xl"),svr=o(" \u2014 "),VY=a("a"),lvr=o("XLMRobertaXLForQuestionAnswering"),ivr=o(" (XLM-RoBERTa-XL model)"),dvr=l(),s4=a("li"),L4e=a("strong"),mvr=o("xlnet"),cvr=o(" \u2014 "),XY=a("a"),fvr=o("XLNetForQuestionAnsweringSimple"),gvr=o(" (XLNet model)"),hvr=l(),l4=a("li"),y4e=a("strong"),uvr=o("yoso"),pvr=o(" \u2014 "),zY=a("a"),_vr=o("YosoForQuestionAnswering"),bvr=o(" (YOSO model)"),vvr=l(),i4=a("p"),Fvr=o("The model is set in evaluation mode by default using "),x4e=a("code"),Tvr=o("model.eval()"),Mvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$4e=a("code"),Evr=o("model.train()"),Cvr=l(),F(d4.$$.fragment),veo=l(),Wd=a("h2"),m4=a("a"),k4e=a("span"),F(M$.$$.fragment),wvr=l(),S4e=a("span"),Avr=o("AutoModelForTableQuestionAnswering"),Feo=l(),Xo=a("div"),F(E$.$$.fragment),Lvr=l(),Ud=a("p"),yvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),QY=a("a"),xvr=o("from_pretrained()"),$vr=o(" class method or the "),WY=a("a"),kvr=o("from_config()"),Svr=o(` class
method.`),Rvr=l(),C$=a("p"),Pvr=o("This class cannot be instantiated directly using "),R4e=a("code"),Bvr=o("__init__()"),Ivr=o(" (throws an error)."),Nvr=l(),Lt=a("div"),F(w$.$$.fragment),qvr=l(),P4e=a("p"),jvr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Dvr=l(),Hd=a("p"),Gvr=o(`Note:
Loading a model from its configuration file does `),B4e=a("strong"),Ovr=o("not"),Vvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UY=a("a"),Xvr=o("from_pretrained()"),zvr=o(" to load the model weights."),Qvr=l(),F(c4.$$.fragment),Wvr=l(),mo=a("div"),F(A$.$$.fragment),Uvr=l(),I4e=a("p"),Hvr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Jvr=l(),sn=a("p"),Yvr=o("The model class to instantiate is selected based on the "),N4e=a("code"),Kvr=o("model_type"),Zvr=o(` property of the config object (either
passed as an argument or loaded from `),q4e=a("code"),eFr=o("pretrained_model_name_or_path"),oFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j4e=a("code"),rFr=o("pretrained_model_name_or_path"),tFr=o(":"),aFr=l(),D4e=a("ul"),f4=a("li"),G4e=a("strong"),nFr=o("tapas"),sFr=o(" \u2014 "),HY=a("a"),lFr=o("TapasForQuestionAnswering"),iFr=o(" (TAPAS model)"),dFr=l(),g4=a("p"),mFr=o("The model is set in evaluation mode by default using "),O4e=a("code"),cFr=o("model.eval()"),fFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V4e=a("code"),gFr=o("model.train()"),hFr=l(),F(h4.$$.fragment),Teo=l(),Jd=a("h2"),u4=a("a"),X4e=a("span"),F(L$.$$.fragment),uFr=l(),z4e=a("span"),pFr=o("AutoModelForDocumentQuestionAnswering"),Meo=l(),zo=a("div"),F(y$.$$.fragment),_Fr=l(),Yd=a("p"),bFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),JY=a("a"),vFr=o("from_pretrained()"),FFr=o(" class method or the "),YY=a("a"),TFr=o("from_config()"),MFr=o(` class
method.`),EFr=l(),x$=a("p"),CFr=o("This class cannot be instantiated directly using "),Q4e=a("code"),wFr=o("__init__()"),AFr=o(" (throws an error)."),LFr=l(),yt=a("div"),F($$.$$.fragment),yFr=l(),W4e=a("p"),xFr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),$Fr=l(),Kd=a("p"),kFr=o(`Note:
Loading a model from its configuration file does `),U4e=a("strong"),SFr=o("not"),RFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=a("a"),PFr=o("from_pretrained()"),BFr=o(" to load the model weights."),IFr=l(),F(p4.$$.fragment),NFr=l(),co=a("div"),F(k$.$$.fragment),qFr=l(),H4e=a("p"),jFr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),DFr=l(),ln=a("p"),GFr=o("The model class to instantiate is selected based on the "),J4e=a("code"),OFr=o("model_type"),VFr=o(` property of the config object (either
passed as an argument or loaded from `),Y4e=a("code"),XFr=o("pretrained_model_name_or_path"),zFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=a("code"),QFr=o("pretrained_model_name_or_path"),WFr=o(":"),UFr=l(),Zd=a("ul"),_4=a("li"),Z4e=a("strong"),HFr=o("layoutlm"),JFr=o(" \u2014 "),ZY=a("a"),YFr=o("LayoutLMForQuestionAnswering"),KFr=o(" (LayoutLM model)"),ZFr=l(),b4=a("li"),eCe=a("strong"),eTr=o("layoutlmv2"),oTr=o(" \u2014 "),eK=a("a"),rTr=o("LayoutLMv2ForQuestionAnswering"),tTr=o(" (LayoutLMv2 model)"),aTr=l(),v4=a("li"),oCe=a("strong"),nTr=o("layoutlmv3"),sTr=o(" \u2014 "),oK=a("a"),lTr=o("LayoutLMv3ForQuestionAnswering"),iTr=o(" (LayoutLMv3 model)"),dTr=l(),F4=a("p"),mTr=o("The model is set in evaluation mode by default using "),rCe=a("code"),cTr=o("model.eval()"),fTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tCe=a("code"),gTr=o("model.train()"),hTr=l(),F(T4.$$.fragment),Eeo=l(),em=a("h2"),M4=a("a"),aCe=a("span"),F(S$.$$.fragment),uTr=l(),nCe=a("span"),pTr=o("AutoModelForImageClassification"),Ceo=l(),Qo=a("div"),F(R$.$$.fragment),_Tr=l(),om=a("p"),bTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rK=a("a"),vTr=o("from_pretrained()"),FTr=o(" class method or the "),tK=a("a"),TTr=o("from_config()"),MTr=o(` class
method.`),ETr=l(),P$=a("p"),CTr=o("This class cannot be instantiated directly using "),sCe=a("code"),wTr=o("__init__()"),ATr=o(" (throws an error)."),LTr=l(),xt=a("div"),F(B$.$$.fragment),yTr=l(),lCe=a("p"),xTr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$Tr=l(),rm=a("p"),kTr=o(`Note:
Loading a model from its configuration file does `),iCe=a("strong"),STr=o("not"),RTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aK=a("a"),PTr=o("from_pretrained()"),BTr=o(" to load the model weights."),ITr=l(),F(E4.$$.fragment),NTr=l(),fo=a("div"),F(I$.$$.fragment),qTr=l(),dCe=a("p"),jTr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),DTr=l(),dn=a("p"),GTr=o("The model class to instantiate is selected based on the "),mCe=a("code"),OTr=o("model_type"),VTr=o(` property of the config object (either
passed as an argument or loaded from `),cCe=a("code"),XTr=o("pretrained_model_name_or_path"),zTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=a("code"),QTr=o("pretrained_model_name_or_path"),WTr=o(":"),UTr=l(),be=a("ul"),C4=a("li"),gCe=a("strong"),HTr=o("beit"),JTr=o(" \u2014 "),nK=a("a"),YTr=o("BeitForImageClassification"),KTr=o(" (BEiT model)"),ZTr=l(),w4=a("li"),hCe=a("strong"),eMr=o("convnext"),oMr=o(" \u2014 "),sK=a("a"),rMr=o("ConvNextForImageClassification"),tMr=o(" (ConvNeXT model)"),aMr=l(),A4=a("li"),uCe=a("strong"),nMr=o("cvt"),sMr=o(" \u2014 "),lK=a("a"),lMr=o("CvtForImageClassification"),iMr=o(" (CvT model)"),dMr=l(),L4=a("li"),pCe=a("strong"),mMr=o("data2vec-vision"),cMr=o(" \u2014 "),iK=a("a"),fMr=o("Data2VecVisionForImageClassification"),gMr=o(" (Data2VecVision model)"),hMr=l(),bl=a("li"),_Ce=a("strong"),uMr=o("deit"),pMr=o(" \u2014 "),dK=a("a"),_Mr=o("DeiTForImageClassification"),bMr=o(" or "),mK=a("a"),vMr=o("DeiTForImageClassificationWithTeacher"),FMr=o(" (DeiT model)"),TMr=l(),y4=a("li"),bCe=a("strong"),MMr=o("imagegpt"),EMr=o(" \u2014 "),cK=a("a"),CMr=o("ImageGPTForImageClassification"),wMr=o(" (ImageGPT model)"),AMr=l(),vl=a("li"),vCe=a("strong"),LMr=o("levit"),yMr=o(" \u2014 "),fK=a("a"),xMr=o("LevitForImageClassification"),$Mr=o(" or "),gK=a("a"),kMr=o("LevitForImageClassificationWithTeacher"),SMr=o(" (LeViT model)"),RMr=l(),x4=a("li"),FCe=a("strong"),PMr=o("mobilevit"),BMr=o(" \u2014 "),hK=a("a"),IMr=o("MobileViTForImageClassification"),NMr=o(" (MobileViT model)"),qMr=l(),$t=a("li"),TCe=a("strong"),jMr=o("perceiver"),DMr=o(" \u2014 "),uK=a("a"),GMr=o("PerceiverForImageClassificationLearned"),OMr=o(" or "),pK=a("a"),VMr=o("PerceiverForImageClassificationFourier"),XMr=o(" or "),_K=a("a"),zMr=o("PerceiverForImageClassificationConvProcessing"),QMr=o(" (Perceiver model)"),WMr=l(),$4=a("li"),MCe=a("strong"),UMr=o("poolformer"),HMr=o(" \u2014 "),bK=a("a"),JMr=o("PoolFormerForImageClassification"),YMr=o(" (PoolFormer model)"),KMr=l(),k4=a("li"),ECe=a("strong"),ZMr=o("regnet"),eEr=o(" \u2014 "),vK=a("a"),oEr=o("RegNetForImageClassification"),rEr=o(" (RegNet model)"),tEr=l(),S4=a("li"),CCe=a("strong"),aEr=o("resnet"),nEr=o(" \u2014 "),FK=a("a"),sEr=o("ResNetForImageClassification"),lEr=o(" (ResNet model)"),iEr=l(),R4=a("li"),wCe=a("strong"),dEr=o("segformer"),mEr=o(" \u2014 "),TK=a("a"),cEr=o("SegformerForImageClassification"),fEr=o(" (SegFormer model)"),gEr=l(),P4=a("li"),ACe=a("strong"),hEr=o("swin"),uEr=o(" \u2014 "),MK=a("a"),pEr=o("SwinForImageClassification"),_Er=o(" (Swin Transformer model)"),bEr=l(),B4=a("li"),LCe=a("strong"),vEr=o("swinv2"),FEr=o(" \u2014 "),EK=a("a"),TEr=o("Swinv2ForImageClassification"),MEr=o(" (Swin Transformer V2 model)"),EEr=l(),I4=a("li"),yCe=a("strong"),CEr=o("van"),wEr=o(" \u2014 "),CK=a("a"),AEr=o("VanForImageClassification"),LEr=o(" (VAN model)"),yEr=l(),N4=a("li"),xCe=a("strong"),xEr=o("vit"),$Er=o(" \u2014 "),wK=a("a"),kEr=o("ViTForImageClassification"),SEr=o(" (ViT model)"),REr=l(),q4=a("li"),$Ce=a("strong"),PEr=o("vit_msn"),BEr=o(" \u2014 "),AK=a("a"),IEr=o("ViTMSNForImageClassification"),NEr=o(" (ViTMSN model)"),qEr=l(),j4=a("p"),jEr=o("The model is set in evaluation mode by default using "),kCe=a("code"),DEr=o("model.eval()"),GEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),SCe=a("code"),OEr=o("model.train()"),VEr=l(),F(D4.$$.fragment),weo=l(),tm=a("h2"),G4=a("a"),RCe=a("span"),F(N$.$$.fragment),XEr=l(),PCe=a("span"),zEr=o("AutoModelForVideoClassification"),Aeo=l(),Wo=a("div"),F(q$.$$.fragment),QEr=l(),am=a("p"),WEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),LK=a("a"),UEr=o("from_pretrained()"),HEr=o(" class method or the "),yK=a("a"),JEr=o("from_config()"),YEr=o(` class
method.`),KEr=l(),j$=a("p"),ZEr=o("This class cannot be instantiated directly using "),BCe=a("code"),e4r=o("__init__()"),o4r=o(" (throws an error)."),r4r=l(),kt=a("div"),F(D$.$$.fragment),t4r=l(),ICe=a("p"),a4r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),n4r=l(),nm=a("p"),s4r=o(`Note:
Loading a model from its configuration file does `),NCe=a("strong"),l4r=o("not"),i4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=a("a"),d4r=o("from_pretrained()"),m4r=o(" to load the model weights."),c4r=l(),F(O4.$$.fragment),f4r=l(),go=a("div"),F(G$.$$.fragment),g4r=l(),qCe=a("p"),h4r=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),u4r=l(),mn=a("p"),p4r=o("The model class to instantiate is selected based on the "),jCe=a("code"),_4r=o("model_type"),b4r=o(` property of the config object (either
passed as an argument or loaded from `),DCe=a("code"),v4r=o("pretrained_model_name_or_path"),F4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GCe=a("code"),T4r=o("pretrained_model_name_or_path"),M4r=o(":"),E4r=l(),OCe=a("ul"),V4=a("li"),VCe=a("strong"),C4r=o("videomae"),w4r=o(" \u2014 "),$K=a("a"),A4r=o("VideoMAEForVideoClassification"),L4r=o(" (VideoMAE model)"),y4r=l(),X4=a("p"),x4r=o("The model is set in evaluation mode by default using "),XCe=a("code"),$4r=o("model.eval()"),k4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zCe=a("code"),S4r=o("model.train()"),R4r=l(),F(z4.$$.fragment),Leo=l(),sm=a("h2"),Q4=a("a"),QCe=a("span"),F(O$.$$.fragment),P4r=l(),WCe=a("span"),B4r=o("AutoModelForVision2Seq"),yeo=l(),Uo=a("div"),F(V$.$$.fragment),I4r=l(),lm=a("p"),N4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),kK=a("a"),q4r=o("from_pretrained()"),j4r=o(" class method or the "),SK=a("a"),D4r=o("from_config()"),G4r=o(` class
method.`),O4r=l(),X$=a("p"),V4r=o("This class cannot be instantiated directly using "),UCe=a("code"),X4r=o("__init__()"),z4r=o(" (throws an error)."),Q4r=l(),St=a("div"),F(z$.$$.fragment),W4r=l(),HCe=a("p"),U4r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),H4r=l(),im=a("p"),J4r=o(`Note:
Loading a model from its configuration file does `),JCe=a("strong"),Y4r=o("not"),K4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RK=a("a"),Z4r=o("from_pretrained()"),eCr=o(" to load the model weights."),oCr=l(),F(W4.$$.fragment),rCr=l(),ho=a("div"),F(Q$.$$.fragment),tCr=l(),YCe=a("p"),aCr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nCr=l(),cn=a("p"),sCr=o("The model class to instantiate is selected based on the "),KCe=a("code"),lCr=o("model_type"),iCr=o(` property of the config object (either
passed as an argument or loaded from `),ZCe=a("code"),dCr=o("pretrained_model_name_or_path"),mCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e3e=a("code"),cCr=o("pretrained_model_name_or_path"),fCr=o(":"),gCr=l(),o3e=a("ul"),U4=a("li"),r3e=a("strong"),hCr=o("vision-encoder-decoder"),uCr=o(" \u2014 "),PK=a("a"),pCr=o("VisionEncoderDecoderModel"),_Cr=o(" (Vision Encoder decoder model)"),bCr=l(),H4=a("p"),vCr=o("The model is set in evaluation mode by default using "),t3e=a("code"),FCr=o("model.eval()"),TCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a3e=a("code"),MCr=o("model.train()"),ECr=l(),F(J4.$$.fragment),xeo=l(),dm=a("h2"),Y4=a("a"),n3e=a("span"),F(W$.$$.fragment),CCr=l(),s3e=a("span"),wCr=o("AutoModelForVisualQuestionAnswering"),$eo=l(),Ho=a("div"),F(U$.$$.fragment),ACr=l(),mm=a("p"),LCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),BK=a("a"),yCr=o("from_pretrained()"),xCr=o(" class method or the "),IK=a("a"),$Cr=o("from_config()"),kCr=o(` class
method.`),SCr=l(),H$=a("p"),RCr=o("This class cannot be instantiated directly using "),l3e=a("code"),PCr=o("__init__()"),BCr=o(" (throws an error)."),ICr=l(),Rt=a("div"),F(J$.$$.fragment),NCr=l(),i3e=a("p"),qCr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),jCr=l(),cm=a("p"),DCr=o(`Note:
Loading a model from its configuration file does `),d3e=a("strong"),GCr=o("not"),OCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NK=a("a"),VCr=o("from_pretrained()"),XCr=o(" to load the model weights."),zCr=l(),F(K4.$$.fragment),QCr=l(),uo=a("div"),F(Y$.$$.fragment),WCr=l(),m3e=a("p"),UCr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),HCr=l(),fn=a("p"),JCr=o("The model class to instantiate is selected based on the "),c3e=a("code"),YCr=o("model_type"),KCr=o(` property of the config object (either
passed as an argument or loaded from `),f3e=a("code"),ZCr=o("pretrained_model_name_or_path"),e3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g3e=a("code"),o3r=o("pretrained_model_name_or_path"),r3r=o(":"),t3r=l(),h3e=a("ul"),Z4=a("li"),u3e=a("strong"),a3r=o("vilt"),n3r=o(" \u2014 "),qK=a("a"),s3r=o("ViltForQuestionAnswering"),l3r=o(" (ViLT model)"),i3r=l(),eC=a("p"),d3r=o("The model is set in evaluation mode by default using "),p3e=a("code"),m3r=o("model.eval()"),c3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_3e=a("code"),f3r=o("model.train()"),g3r=l(),F(oC.$$.fragment),keo=l(),fm=a("h2"),rC=a("a"),b3e=a("span"),F(K$.$$.fragment),h3r=l(),v3e=a("span"),u3r=o("AutoModelForAudioClassification"),Seo=l(),Jo=a("div"),F(Z$.$$.fragment),p3r=l(),gm=a("p"),_3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),jK=a("a"),b3r=o("from_pretrained()"),v3r=o(" class method or the "),DK=a("a"),F3r=o("from_config()"),T3r=o(` class
method.`),M3r=l(),ek=a("p"),E3r=o("This class cannot be instantiated directly using "),F3e=a("code"),C3r=o("__init__()"),w3r=o(" (throws an error)."),A3r=l(),Pt=a("div"),F(ok.$$.fragment),L3r=l(),T3e=a("p"),y3r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),x3r=l(),hm=a("p"),$3r=o(`Note:
Loading a model from its configuration file does `),M3e=a("strong"),k3r=o("not"),S3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=a("a"),R3r=o("from_pretrained()"),P3r=o(" to load the model weights."),B3r=l(),F(tC.$$.fragment),I3r=l(),po=a("div"),F(rk.$$.fragment),N3r=l(),E3e=a("p"),q3r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),j3r=l(),gn=a("p"),D3r=o("The model class to instantiate is selected based on the "),C3e=a("code"),G3r=o("model_type"),O3r=o(` property of the config object (either
passed as an argument or loaded from `),w3e=a("code"),V3r=o("pretrained_model_name_or_path"),X3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A3e=a("code"),z3r=o("pretrained_model_name_or_path"),Q3r=o(":"),W3r=l(),Pe=a("ul"),aC=a("li"),L3e=a("strong"),U3r=o("data2vec-audio"),H3r=o(" \u2014 "),OK=a("a"),J3r=o("Data2VecAudioForSequenceClassification"),Y3r=o(" (Data2VecAudio model)"),K3r=l(),nC=a("li"),y3e=a("strong"),Z3r=o("hubert"),e5r=o(" \u2014 "),VK=a("a"),o5r=o("HubertForSequenceClassification"),r5r=o(" (Hubert model)"),t5r=l(),sC=a("li"),x3e=a("strong"),a5r=o("sew"),n5r=o(" \u2014 "),XK=a("a"),s5r=o("SEWForSequenceClassification"),l5r=o(" (SEW model)"),i5r=l(),lC=a("li"),$3e=a("strong"),d5r=o("sew-d"),m5r=o(" \u2014 "),zK=a("a"),c5r=o("SEWDForSequenceClassification"),f5r=o(" (SEW-D model)"),g5r=l(),iC=a("li"),k3e=a("strong"),h5r=o("unispeech"),u5r=o(" \u2014 "),QK=a("a"),p5r=o("UniSpeechForSequenceClassification"),_5r=o(" (UniSpeech model)"),b5r=l(),dC=a("li"),S3e=a("strong"),v5r=o("unispeech-sat"),F5r=o(" \u2014 "),WK=a("a"),T5r=o("UniSpeechSatForSequenceClassification"),M5r=o(" (UniSpeechSat model)"),E5r=l(),mC=a("li"),R3e=a("strong"),C5r=o("wav2vec2"),w5r=o(" \u2014 "),UK=a("a"),A5r=o("Wav2Vec2ForSequenceClassification"),L5r=o(" (Wav2Vec2 model)"),y5r=l(),cC=a("li"),P3e=a("strong"),x5r=o("wav2vec2-conformer"),$5r=o(" \u2014 "),HK=a("a"),k5r=o("Wav2Vec2ConformerForSequenceClassification"),S5r=o(" (Wav2Vec2-Conformer model)"),R5r=l(),fC=a("li"),B3e=a("strong"),P5r=o("wavlm"),B5r=o(" \u2014 "),JK=a("a"),I5r=o("WavLMForSequenceClassification"),N5r=o(" (WavLM model)"),q5r=l(),gC=a("p"),j5r=o("The model is set in evaluation mode by default using "),I3e=a("code"),D5r=o("model.eval()"),G5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N3e=a("code"),O5r=o("model.train()"),V5r=l(),F(hC.$$.fragment),Reo=l(),um=a("h2"),uC=a("a"),q3e=a("span"),F(tk.$$.fragment),X5r=l(),j3e=a("span"),z5r=o("AutoModelForAudioFrameClassification"),Peo=l(),Yo=a("div"),F(ak.$$.fragment),Q5r=l(),pm=a("p"),W5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),YK=a("a"),U5r=o("from_pretrained()"),H5r=o(" class method or the "),KK=a("a"),J5r=o("from_config()"),Y5r=o(` class
method.`),K5r=l(),nk=a("p"),Z5r=o("This class cannot be instantiated directly using "),D3e=a("code"),e0r=o("__init__()"),o0r=o(" (throws an error)."),r0r=l(),Bt=a("div"),F(sk.$$.fragment),t0r=l(),G3e=a("p"),a0r=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),n0r=l(),_m=a("p"),s0r=o(`Note:
Loading a model from its configuration file does `),O3e=a("strong"),l0r=o("not"),i0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZK=a("a"),d0r=o("from_pretrained()"),m0r=o(" to load the model weights."),c0r=l(),F(pC.$$.fragment),f0r=l(),_o=a("div"),F(lk.$$.fragment),g0r=l(),V3e=a("p"),h0r=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),u0r=l(),hn=a("p"),p0r=o("The model class to instantiate is selected based on the "),X3e=a("code"),_0r=o("model_type"),b0r=o(` property of the config object (either
passed as an argument or loaded from `),z3e=a("code"),v0r=o("pretrained_model_name_or_path"),F0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q3e=a("code"),T0r=o("pretrained_model_name_or_path"),M0r=o(":"),E0r=l(),ct=a("ul"),_C=a("li"),W3e=a("strong"),C0r=o("data2vec-audio"),w0r=o(" \u2014 "),eZ=a("a"),A0r=o("Data2VecAudioForAudioFrameClassification"),L0r=o(" (Data2VecAudio model)"),y0r=l(),bC=a("li"),U3e=a("strong"),x0r=o("unispeech-sat"),$0r=o(" \u2014 "),oZ=a("a"),k0r=o("UniSpeechSatForAudioFrameClassification"),S0r=o(" (UniSpeechSat model)"),R0r=l(),vC=a("li"),H3e=a("strong"),P0r=o("wav2vec2"),B0r=o(" \u2014 "),rZ=a("a"),I0r=o("Wav2Vec2ForAudioFrameClassification"),N0r=o(" (Wav2Vec2 model)"),q0r=l(),FC=a("li"),J3e=a("strong"),j0r=o("wav2vec2-conformer"),D0r=o(" \u2014 "),tZ=a("a"),G0r=o("Wav2Vec2ConformerForAudioFrameClassification"),O0r=o(" (Wav2Vec2-Conformer model)"),V0r=l(),TC=a("li"),Y3e=a("strong"),X0r=o("wavlm"),z0r=o(" \u2014 "),aZ=a("a"),Q0r=o("WavLMForAudioFrameClassification"),W0r=o(" (WavLM model)"),U0r=l(),MC=a("p"),H0r=o("The model is set in evaluation mode by default using "),K3e=a("code"),J0r=o("model.eval()"),Y0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z3e=a("code"),K0r=o("model.train()"),Z0r=l(),F(EC.$$.fragment),Beo=l(),bm=a("h2"),CC=a("a"),e5e=a("span"),F(ik.$$.fragment),ewr=l(),o5e=a("span"),owr=o("AutoModelForCTC"),Ieo=l(),Ko=a("div"),F(dk.$$.fragment),rwr=l(),vm=a("p"),twr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),nZ=a("a"),awr=o("from_pretrained()"),nwr=o(" class method or the "),sZ=a("a"),swr=o("from_config()"),lwr=o(` class
method.`),iwr=l(),mk=a("p"),dwr=o("This class cannot be instantiated directly using "),r5e=a("code"),mwr=o("__init__()"),cwr=o(" (throws an error)."),fwr=l(),It=a("div"),F(ck.$$.fragment),gwr=l(),t5e=a("p"),hwr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),uwr=l(),Fm=a("p"),pwr=o(`Note:
Loading a model from its configuration file does `),a5e=a("strong"),_wr=o("not"),bwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lZ=a("a"),vwr=o("from_pretrained()"),Fwr=o(" to load the model weights."),Twr=l(),F(wC.$$.fragment),Mwr=l(),bo=a("div"),F(fk.$$.fragment),Ewr=l(),n5e=a("p"),Cwr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),wwr=l(),un=a("p"),Awr=o("The model class to instantiate is selected based on the "),s5e=a("code"),Lwr=o("model_type"),ywr=o(` property of the config object (either
passed as an argument or loaded from `),l5e=a("code"),xwr=o("pretrained_model_name_or_path"),$wr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i5e=a("code"),kwr=o("pretrained_model_name_or_path"),Swr=o(":"),Rwr=l(),Le=a("ul"),AC=a("li"),d5e=a("strong"),Pwr=o("data2vec-audio"),Bwr=o(" \u2014 "),iZ=a("a"),Iwr=o("Data2VecAudioForCTC"),Nwr=o(" (Data2VecAudio model)"),qwr=l(),LC=a("li"),m5e=a("strong"),jwr=o("hubert"),Dwr=o(" \u2014 "),dZ=a("a"),Gwr=o("HubertForCTC"),Owr=o(" (Hubert model)"),Vwr=l(),yC=a("li"),c5e=a("strong"),Xwr=o("mctct"),zwr=o(" \u2014 "),mZ=a("a"),Qwr=o("MCTCTForCTC"),Wwr=o(" (M-CTC-T model)"),Uwr=l(),xC=a("li"),f5e=a("strong"),Hwr=o("sew"),Jwr=o(" \u2014 "),cZ=a("a"),Ywr=o("SEWForCTC"),Kwr=o(" (SEW model)"),Zwr=l(),$C=a("li"),g5e=a("strong"),eAr=o("sew-d"),oAr=o(" \u2014 "),fZ=a("a"),rAr=o("SEWDForCTC"),tAr=o(" (SEW-D model)"),aAr=l(),kC=a("li"),h5e=a("strong"),nAr=o("unispeech"),sAr=o(" \u2014 "),gZ=a("a"),lAr=o("UniSpeechForCTC"),iAr=o(" (UniSpeech model)"),dAr=l(),SC=a("li"),u5e=a("strong"),mAr=o("unispeech-sat"),cAr=o(" \u2014 "),hZ=a("a"),fAr=o("UniSpeechSatForCTC"),gAr=o(" (UniSpeechSat model)"),hAr=l(),RC=a("li"),p5e=a("strong"),uAr=o("wav2vec2"),pAr=o(" \u2014 "),uZ=a("a"),_Ar=o("Wav2Vec2ForCTC"),bAr=o(" (Wav2Vec2 model)"),vAr=l(),PC=a("li"),_5e=a("strong"),FAr=o("wav2vec2-conformer"),TAr=o(" \u2014 "),pZ=a("a"),MAr=o("Wav2Vec2ConformerForCTC"),EAr=o(" (Wav2Vec2-Conformer model)"),CAr=l(),BC=a("li"),b5e=a("strong"),wAr=o("wavlm"),AAr=o(" \u2014 "),_Z=a("a"),LAr=o("WavLMForCTC"),yAr=o(" (WavLM model)"),xAr=l(),IC=a("p"),$Ar=o("The model is set in evaluation mode by default using "),v5e=a("code"),kAr=o("model.eval()"),SAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=a("code"),RAr=o("model.train()"),PAr=l(),F(NC.$$.fragment),Neo=l(),Tm=a("h2"),qC=a("a"),T5e=a("span"),F(gk.$$.fragment),BAr=l(),M5e=a("span"),IAr=o("AutoModelForSpeechSeq2Seq"),qeo=l(),Zo=a("div"),F(hk.$$.fragment),NAr=l(),Mm=a("p"),qAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),bZ=a("a"),jAr=o("from_pretrained()"),DAr=o(" class method or the "),vZ=a("a"),GAr=o("from_config()"),OAr=o(` class
method.`),VAr=l(),uk=a("p"),XAr=o("This class cannot be instantiated directly using "),E5e=a("code"),zAr=o("__init__()"),QAr=o(" (throws an error)."),WAr=l(),Nt=a("div"),F(pk.$$.fragment),UAr=l(),C5e=a("p"),HAr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),JAr=l(),Em=a("p"),YAr=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),KAr=o("not"),ZAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FZ=a("a"),e6r=o("from_pretrained()"),o6r=o(" to load the model weights."),r6r=l(),F(jC.$$.fragment),t6r=l(),vo=a("div"),F(_k.$$.fragment),a6r=l(),A5e=a("p"),n6r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),s6r=l(),pn=a("p"),l6r=o("The model class to instantiate is selected based on the "),L5e=a("code"),i6r=o("model_type"),d6r=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),m6r=o("pretrained_model_name_or_path"),c6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),f6r=o("pretrained_model_name_or_path"),g6r=o(":"),h6r=l(),bk=a("ul"),DC=a("li"),$5e=a("strong"),u6r=o("speech-encoder-decoder"),p6r=o(" \u2014 "),TZ=a("a"),_6r=o("SpeechEncoderDecoderModel"),b6r=o(" (Speech Encoder decoder model)"),v6r=l(),GC=a("li"),k5e=a("strong"),F6r=o("speech_to_text"),T6r=o(" \u2014 "),MZ=a("a"),M6r=o("Speech2TextForConditionalGeneration"),E6r=o(" (Speech2Text model)"),C6r=l(),OC=a("p"),w6r=o("The model is set in evaluation mode by default using "),S5e=a("code"),A6r=o("model.eval()"),L6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R5e=a("code"),y6r=o("model.train()"),x6r=l(),F(VC.$$.fragment),jeo=l(),Cm=a("h2"),XC=a("a"),P5e=a("span"),F(vk.$$.fragment),$6r=l(),B5e=a("span"),k6r=o("AutoModelForAudioXVector"),Deo=l(),er=a("div"),F(Fk.$$.fragment),S6r=l(),wm=a("p"),R6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),EZ=a("a"),P6r=o("from_pretrained()"),B6r=o(" class method or the "),CZ=a("a"),I6r=o("from_config()"),N6r=o(` class
method.`),q6r=l(),Tk=a("p"),j6r=o("This class cannot be instantiated directly using "),I5e=a("code"),D6r=o("__init__()"),G6r=o(" (throws an error)."),O6r=l(),qt=a("div"),F(Mk.$$.fragment),V6r=l(),N5e=a("p"),X6r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),z6r=l(),Am=a("p"),Q6r=o(`Note:
Loading a model from its configuration file does `),q5e=a("strong"),W6r=o("not"),U6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),H6r=o("from_pretrained()"),J6r=o(" to load the model weights."),Y6r=l(),F(zC.$$.fragment),K6r=l(),Fo=a("div"),F(Ek.$$.fragment),Z6r=l(),j5e=a("p"),e7r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),o7r=l(),_n=a("p"),r7r=o("The model class to instantiate is selected based on the "),D5e=a("code"),t7r=o("model_type"),a7r=o(` property of the config object (either
passed as an argument or loaded from `),G5e=a("code"),n7r=o("pretrained_model_name_or_path"),s7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O5e=a("code"),l7r=o("pretrained_model_name_or_path"),i7r=o(":"),d7r=l(),ft=a("ul"),QC=a("li"),V5e=a("strong"),m7r=o("data2vec-audio"),c7r=o(" \u2014 "),AZ=a("a"),f7r=o("Data2VecAudioForXVector"),g7r=o(" (Data2VecAudio model)"),h7r=l(),WC=a("li"),X5e=a("strong"),u7r=o("unispeech-sat"),p7r=o(" \u2014 "),LZ=a("a"),_7r=o("UniSpeechSatForXVector"),b7r=o(" (UniSpeechSat model)"),v7r=l(),UC=a("li"),z5e=a("strong"),F7r=o("wav2vec2"),T7r=o(" \u2014 "),yZ=a("a"),M7r=o("Wav2Vec2ForXVector"),E7r=o(" (Wav2Vec2 model)"),C7r=l(),HC=a("li"),Q5e=a("strong"),w7r=o("wav2vec2-conformer"),A7r=o(" \u2014 "),xZ=a("a"),L7r=o("Wav2Vec2ConformerForXVector"),y7r=o(" (Wav2Vec2-Conformer model)"),x7r=l(),JC=a("li"),W5e=a("strong"),$7r=o("wavlm"),k7r=o(" \u2014 "),$Z=a("a"),S7r=o("WavLMForXVector"),R7r=o(" (WavLM model)"),P7r=l(),YC=a("p"),B7r=o("The model is set in evaluation mode by default using "),U5e=a("code"),I7r=o("model.eval()"),N7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H5e=a("code"),q7r=o("model.train()"),j7r=l(),F(KC.$$.fragment),Geo=l(),Lm=a("h2"),ZC=a("a"),J5e=a("span"),F(Ck.$$.fragment),D7r=l(),Y5e=a("span"),G7r=o("AutoModelForMaskedImageModeling"),Oeo=l(),or=a("div"),F(wk.$$.fragment),O7r=l(),ym=a("p"),V7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),kZ=a("a"),X7r=o("from_pretrained()"),z7r=o(" class method or the "),SZ=a("a"),Q7r=o("from_config()"),W7r=o(` class
method.`),U7r=l(),Ak=a("p"),H7r=o("This class cannot be instantiated directly using "),K5e=a("code"),J7r=o("__init__()"),Y7r=o(" (throws an error)."),K7r=l(),jt=a("div"),F(Lk.$$.fragment),Z7r=l(),Z5e=a("p"),eLr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),oLr=l(),xm=a("p"),rLr=o(`Note:
Loading a model from its configuration file does `),e0e=a("strong"),tLr=o("not"),aLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RZ=a("a"),nLr=o("from_pretrained()"),sLr=o(" to load the model weights."),lLr=l(),F(e3.$$.fragment),iLr=l(),To=a("div"),F(yk.$$.fragment),dLr=l(),o0e=a("p"),mLr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),cLr=l(),bn=a("p"),fLr=o("The model class to instantiate is selected based on the "),r0e=a("code"),gLr=o("model_type"),hLr=o(` property of the config object (either
passed as an argument or loaded from `),t0e=a("code"),uLr=o("pretrained_model_name_or_path"),pLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=a("code"),_Lr=o("pretrained_model_name_or_path"),bLr=o(":"),vLr=l(),vn=a("ul"),o3=a("li"),n0e=a("strong"),FLr=o("deit"),TLr=o(" \u2014 "),PZ=a("a"),MLr=o("DeiTForMaskedImageModeling"),ELr=o(" (DeiT model)"),CLr=l(),r3=a("li"),s0e=a("strong"),wLr=o("swin"),ALr=o(" \u2014 "),BZ=a("a"),LLr=o("SwinForMaskedImageModeling"),yLr=o(" (Swin Transformer model)"),xLr=l(),t3=a("li"),l0e=a("strong"),$Lr=o("swinv2"),kLr=o(" \u2014 "),IZ=a("a"),SLr=o("Swinv2ForMaskedImageModeling"),RLr=o(" (Swin Transformer V2 model)"),PLr=l(),a3=a("li"),i0e=a("strong"),BLr=o("vit"),ILr=o(" \u2014 "),NZ=a("a"),NLr=o("ViTForMaskedImageModeling"),qLr=o(" (ViT model)"),jLr=l(),n3=a("p"),DLr=o("The model is set in evaluation mode by default using "),d0e=a("code"),GLr=o("model.eval()"),OLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m0e=a("code"),VLr=o("model.train()"),XLr=l(),F(s3.$$.fragment),Veo=l(),$m=a("h2"),l3=a("a"),c0e=a("span"),F(xk.$$.fragment),zLr=l(),f0e=a("span"),QLr=o("AutoModelForObjectDetection"),Xeo=l(),rr=a("div"),F($k.$$.fragment),WLr=l(),km=a("p"),ULr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),qZ=a("a"),HLr=o("from_pretrained()"),JLr=o(" class method or the "),jZ=a("a"),YLr=o("from_config()"),KLr=o(` class
method.`),ZLr=l(),kk=a("p"),eyr=o("This class cannot be instantiated directly using "),g0e=a("code"),oyr=o("__init__()"),ryr=o(" (throws an error)."),tyr=l(),Dt=a("div"),F(Sk.$$.fragment),ayr=l(),h0e=a("p"),nyr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),syr=l(),Sm=a("p"),lyr=o(`Note:
Loading a model from its configuration file does `),u0e=a("strong"),iyr=o("not"),dyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=a("a"),myr=o("from_pretrained()"),cyr=o(" to load the model weights."),fyr=l(),F(i3.$$.fragment),gyr=l(),Mo=a("div"),F(Rk.$$.fragment),hyr=l(),p0e=a("p"),uyr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),pyr=l(),Fn=a("p"),_yr=o("The model class to instantiate is selected based on the "),_0e=a("code"),byr=o("model_type"),vyr=o(` property of the config object (either
passed as an argument or loaded from `),b0e=a("code"),Fyr=o("pretrained_model_name_or_path"),Tyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v0e=a("code"),Myr=o("pretrained_model_name_or_path"),Eyr=o(":"),Cyr=l(),Tn=a("ul"),d3=a("li"),F0e=a("strong"),wyr=o("conditional_detr"),Ayr=o(" \u2014 "),GZ=a("a"),Lyr=o("ConditionalDetrForObjectDetection"),yyr=o(" (Conditional DETR model)"),xyr=l(),m3=a("li"),T0e=a("strong"),$yr=o("deformable_detr"),kyr=o(" \u2014 "),OZ=a("a"),Syr=o("DeformableDetrForObjectDetection"),Ryr=o(" (Deformable DETR model)"),Pyr=l(),c3=a("li"),M0e=a("strong"),Byr=o("detr"),Iyr=o(" \u2014 "),VZ=a("a"),Nyr=o("DetrForObjectDetection"),qyr=o(" (DETR model)"),jyr=l(),f3=a("li"),E0e=a("strong"),Dyr=o("yolos"),Gyr=o(" \u2014 "),XZ=a("a"),Oyr=o("YolosForObjectDetection"),Vyr=o(" (YOLOS model)"),Xyr=l(),g3=a("p"),zyr=o("The model is set in evaluation mode by default using "),C0e=a("code"),Qyr=o("model.eval()"),Wyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w0e=a("code"),Uyr=o("model.train()"),Hyr=l(),F(h3.$$.fragment),zeo=l(),Rm=a("h2"),u3=a("a"),A0e=a("span"),F(Pk.$$.fragment),Jyr=l(),L0e=a("span"),Yyr=o("AutoModelForImageSegmentation"),Qeo=l(),tr=a("div"),F(Bk.$$.fragment),Kyr=l(),Pm=a("p"),Zyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),zZ=a("a"),e8r=o("from_pretrained()"),o8r=o(" class method or the "),QZ=a("a"),r8r=o("from_config()"),t8r=o(` class
method.`),a8r=l(),Ik=a("p"),n8r=o("This class cannot be instantiated directly using "),y0e=a("code"),s8r=o("__init__()"),l8r=o(" (throws an error)."),i8r=l(),Gt=a("div"),F(Nk.$$.fragment),d8r=l(),x0e=a("p"),m8r=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),c8r=l(),Bm=a("p"),f8r=o(`Note:
Loading a model from its configuration file does `),$0e=a("strong"),g8r=o("not"),h8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WZ=a("a"),u8r=o("from_pretrained()"),p8r=o(" to load the model weights."),_8r=l(),F(p3.$$.fragment),b8r=l(),Eo=a("div"),F(qk.$$.fragment),v8r=l(),k0e=a("p"),F8r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),T8r=l(),Mn=a("p"),M8r=o("The model class to instantiate is selected based on the "),S0e=a("code"),E8r=o("model_type"),C8r=o(` property of the config object (either
passed as an argument or loaded from `),R0e=a("code"),w8r=o("pretrained_model_name_or_path"),A8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P0e=a("code"),L8r=o("pretrained_model_name_or_path"),y8r=o(":"),x8r=l(),B0e=a("ul"),_3=a("li"),I0e=a("strong"),$8r=o("detr"),k8r=o(" \u2014 "),UZ=a("a"),S8r=o("DetrForSegmentation"),R8r=o(" (DETR model)"),P8r=l(),b3=a("p"),B8r=o("The model is set in evaluation mode by default using "),N0e=a("code"),I8r=o("model.eval()"),N8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q0e=a("code"),q8r=o("model.train()"),j8r=l(),F(v3.$$.fragment),Weo=l(),Im=a("h2"),F3=a("a"),j0e=a("span"),F(jk.$$.fragment),D8r=l(),D0e=a("span"),G8r=o("AutoModelForSemanticSegmentation"),Ueo=l(),ar=a("div"),F(Dk.$$.fragment),O8r=l(),Nm=a("p"),V8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),HZ=a("a"),X8r=o("from_pretrained()"),z8r=o(" class method or the "),JZ=a("a"),Q8r=o("from_config()"),W8r=o(` class
method.`),U8r=l(),Gk=a("p"),H8r=o("This class cannot be instantiated directly using "),G0e=a("code"),J8r=o("__init__()"),Y8r=o(" (throws an error)."),K8r=l(),Ot=a("div"),F(Ok.$$.fragment),Z8r=l(),O0e=a("p"),e9r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),o9r=l(),qm=a("p"),r9r=o(`Note:
Loading a model from its configuration file does `),V0e=a("strong"),t9r=o("not"),a9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YZ=a("a"),n9r=o("from_pretrained()"),s9r=o(" to load the model weights."),l9r=l(),F(T3.$$.fragment),i9r=l(),Co=a("div"),F(Vk.$$.fragment),d9r=l(),X0e=a("p"),m9r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),c9r=l(),En=a("p"),f9r=o("The model class to instantiate is selected based on the "),z0e=a("code"),g9r=o("model_type"),h9r=o(` property of the config object (either
passed as an argument or loaded from `),Q0e=a("code"),u9r=o("pretrained_model_name_or_path"),p9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W0e=a("code"),_9r=o("pretrained_model_name_or_path"),b9r=o(":"),v9r=l(),gt=a("ul"),M3=a("li"),U0e=a("strong"),F9r=o("beit"),T9r=o(" \u2014 "),KZ=a("a"),M9r=o("BeitForSemanticSegmentation"),E9r=o(" (BEiT model)"),C9r=l(),E3=a("li"),H0e=a("strong"),w9r=o("data2vec-vision"),A9r=o(" \u2014 "),ZZ=a("a"),L9r=o("Data2VecVisionForSemanticSegmentation"),y9r=o(" (Data2VecVision model)"),x9r=l(),C3=a("li"),J0e=a("strong"),$9r=o("dpt"),k9r=o(" \u2014 "),eee=a("a"),S9r=o("DPTForSemanticSegmentation"),R9r=o(" (DPT model)"),P9r=l(),w3=a("li"),Y0e=a("strong"),B9r=o("mobilevit"),I9r=o(" \u2014 "),oee=a("a"),N9r=o("MobileViTForSemanticSegmentation"),q9r=o(" (MobileViT model)"),j9r=l(),A3=a("li"),K0e=a("strong"),D9r=o("segformer"),G9r=o(" \u2014 "),ree=a("a"),O9r=o("SegformerForSemanticSegmentation"),V9r=o(" (SegFormer model)"),X9r=l(),L3=a("p"),z9r=o("The model is set in evaluation mode by default using "),Z0e=a("code"),Q9r=o("model.eval()"),W9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ewe=a("code"),U9r=o("model.train()"),H9r=l(),F(y3.$$.fragment),Heo=l(),jm=a("h2"),x3=a("a"),owe=a("span"),F(Xk.$$.fragment),J9r=l(),rwe=a("span"),Y9r=o("AutoModelForInstanceSegmentation"),Jeo=l(),nr=a("div"),F(zk.$$.fragment),K9r=l(),Dm=a("p"),Z9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),tee=a("a"),exr=o("from_pretrained()"),oxr=o(" class method or the "),aee=a("a"),rxr=o("from_config()"),txr=o(` class
method.`),axr=l(),Qk=a("p"),nxr=o("This class cannot be instantiated directly using "),twe=a("code"),sxr=o("__init__()"),lxr=o(" (throws an error)."),ixr=l(),Vt=a("div"),F(Wk.$$.fragment),dxr=l(),awe=a("p"),mxr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),cxr=l(),Gm=a("p"),fxr=o(`Note:
Loading a model from its configuration file does `),nwe=a("strong"),gxr=o("not"),hxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nee=a("a"),uxr=o("from_pretrained()"),pxr=o(" to load the model weights."),_xr=l(),F($3.$$.fragment),bxr=l(),wo=a("div"),F(Uk.$$.fragment),vxr=l(),swe=a("p"),Fxr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Txr=l(),Cn=a("p"),Mxr=o("The model class to instantiate is selected based on the "),lwe=a("code"),Exr=o("model_type"),Cxr=o(` property of the config object (either
passed as an argument or loaded from `),iwe=a("code"),wxr=o("pretrained_model_name_or_path"),Axr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=a("code"),Lxr=o("pretrained_model_name_or_path"),yxr=o(":"),xxr=l(),mwe=a("ul"),k3=a("li"),cwe=a("strong"),$xr=o("maskformer"),kxr=o(" \u2014 "),see=a("a"),Sxr=o("MaskFormerForInstanceSegmentation"),Rxr=o(" (MaskFormer model)"),Pxr=l(),S3=a("p"),Bxr=o("The model is set in evaluation mode by default using "),fwe=a("code"),Ixr=o("model.eval()"),Nxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gwe=a("code"),qxr=o("model.train()"),jxr=l(),F(R3.$$.fragment),Yeo=l(),Om=a("h2"),P3=a("a"),hwe=a("span"),F(Hk.$$.fragment),Dxr=l(),uwe=a("span"),Gxr=o("TFAutoModel"),Keo=l(),sr=a("div"),F(Jk.$$.fragment),Oxr=l(),Vm=a("p"),Vxr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),lee=a("a"),Xxr=o("from_pretrained()"),zxr=o(" class method or the "),iee=a("a"),Qxr=o("from_config()"),Wxr=o(` class
method.`),Uxr=l(),Yk=a("p"),Hxr=o("This class cannot be instantiated directly using "),pwe=a("code"),Jxr=o("__init__()"),Yxr=o(" (throws an error)."),Kxr=l(),Xt=a("div"),F(Kk.$$.fragment),Zxr=l(),_we=a("p"),e$r=o("Instantiates one of the base model classes of the library from a configuration."),o$r=l(),Xm=a("p"),r$r=o(`Note:
Loading a model from its configuration file does `),bwe=a("strong"),t$r=o("not"),a$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=a("a"),n$r=o("from_pretrained()"),s$r=o(" to load the model weights."),l$r=l(),F(B3.$$.fragment),i$r=l(),Ir=a("div"),F(Zk.$$.fragment),d$r=l(),vwe=a("p"),m$r=o("Instantiate one of the base model classes of the library from a pretrained model."),c$r=l(),wn=a("p"),f$r=o("The model class to instantiate is selected based on the "),Fwe=a("code"),g$r=o("model_type"),h$r=o(` property of the config object (either
passed as an argument or loaded from `),Twe=a("code"),u$r=o("pretrained_model_name_or_path"),p$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mwe=a("code"),_$r=o("pretrained_model_name_or_path"),b$r=o(":"),v$r=l(),I=a("ul"),I3=a("li"),Ewe=a("strong"),F$r=o("albert"),T$r=o(" \u2014 "),mee=a("a"),M$r=o("TFAlbertModel"),E$r=o(" (ALBERT model)"),C$r=l(),N3=a("li"),Cwe=a("strong"),w$r=o("bart"),A$r=o(" \u2014 "),cee=a("a"),L$r=o("TFBartModel"),y$r=o(" (BART model)"),x$r=l(),q3=a("li"),wwe=a("strong"),$$r=o("bert"),k$r=o(" \u2014 "),fee=a("a"),S$r=o("TFBertModel"),R$r=o(" (BERT model)"),P$r=l(),j3=a("li"),Awe=a("strong"),B$r=o("blenderbot"),I$r=o(" \u2014 "),gee=a("a"),N$r=o("TFBlenderbotModel"),q$r=o(" (Blenderbot model)"),j$r=l(),D3=a("li"),Lwe=a("strong"),D$r=o("blenderbot-small"),G$r=o(" \u2014 "),hee=a("a"),O$r=o("TFBlenderbotSmallModel"),V$r=o(" (BlenderbotSmall model)"),X$r=l(),G3=a("li"),ywe=a("strong"),z$r=o("camembert"),Q$r=o(" \u2014 "),uee=a("a"),W$r=o("TFCamembertModel"),U$r=o(" (CamemBERT model)"),H$r=l(),O3=a("li"),xwe=a("strong"),J$r=o("clip"),Y$r=o(" \u2014 "),pee=a("a"),K$r=o("TFCLIPModel"),Z$r=o(" (CLIP model)"),ekr=l(),V3=a("li"),$we=a("strong"),okr=o("convbert"),rkr=o(" \u2014 "),_ee=a("a"),tkr=o("TFConvBertModel"),akr=o(" (ConvBERT model)"),nkr=l(),X3=a("li"),kwe=a("strong"),skr=o("convnext"),lkr=o(" \u2014 "),bee=a("a"),ikr=o("TFConvNextModel"),dkr=o(" (ConvNeXT model)"),mkr=l(),z3=a("li"),Swe=a("strong"),ckr=o("ctrl"),fkr=o(" \u2014 "),vee=a("a"),gkr=o("TFCTRLModel"),hkr=o(" (CTRL model)"),ukr=l(),Q3=a("li"),Rwe=a("strong"),pkr=o("data2vec-vision"),_kr=o(" \u2014 "),Fee=a("a"),bkr=o("TFData2VecVisionModel"),vkr=o(" (Data2VecVision model)"),Fkr=l(),W3=a("li"),Pwe=a("strong"),Tkr=o("deberta"),Mkr=o(" \u2014 "),Tee=a("a"),Ekr=o("TFDebertaModel"),Ckr=o(" (DeBERTa model)"),wkr=l(),U3=a("li"),Bwe=a("strong"),Akr=o("deberta-v2"),Lkr=o(" \u2014 "),Mee=a("a"),ykr=o("TFDebertaV2Model"),xkr=o(" (DeBERTa-v2 model)"),$kr=l(),H3=a("li"),Iwe=a("strong"),kkr=o("deit"),Skr=o(" \u2014 "),Eee=a("a"),Rkr=o("TFDeiTModel"),Pkr=o(" (DeiT model)"),Bkr=l(),J3=a("li"),Nwe=a("strong"),Ikr=o("distilbert"),Nkr=o(" \u2014 "),Cee=a("a"),qkr=o("TFDistilBertModel"),jkr=o(" (DistilBERT model)"),Dkr=l(),Y3=a("li"),qwe=a("strong"),Gkr=o("dpr"),Okr=o(" \u2014 "),wee=a("a"),Vkr=o("TFDPRQuestionEncoder"),Xkr=o(" (DPR model)"),zkr=l(),K3=a("li"),jwe=a("strong"),Qkr=o("electra"),Wkr=o(" \u2014 "),Aee=a("a"),Ukr=o("TFElectraModel"),Hkr=o(" (ELECTRA model)"),Jkr=l(),Z3=a("li"),Dwe=a("strong"),Ykr=o("flaubert"),Kkr=o(" \u2014 "),Lee=a("a"),Zkr=o("TFFlaubertModel"),eSr=o(" (FlauBERT model)"),oSr=l(),Fl=a("li"),Gwe=a("strong"),rSr=o("funnel"),tSr=o(" \u2014 "),yee=a("a"),aSr=o("TFFunnelModel"),nSr=o(" or "),xee=a("a"),sSr=o("TFFunnelBaseModel"),lSr=o(" (Funnel Transformer model)"),iSr=l(),e5=a("li"),Owe=a("strong"),dSr=o("gpt2"),mSr=o(" \u2014 "),$ee=a("a"),cSr=o("TFGPT2Model"),fSr=o(" (OpenAI GPT-2 model)"),gSr=l(),o5=a("li"),Vwe=a("strong"),hSr=o("gptj"),uSr=o(" \u2014 "),kee=a("a"),pSr=o("TFGPTJModel"),_Sr=o(" (GPT-J model)"),bSr=l(),r5=a("li"),Xwe=a("strong"),vSr=o("groupvit"),FSr=o(" \u2014 "),See=a("a"),TSr=o("TFGroupViTModel"),MSr=o(" (GroupViT model)"),ESr=l(),t5=a("li"),zwe=a("strong"),CSr=o("hubert"),wSr=o(" \u2014 "),Ree=a("a"),ASr=o("TFHubertModel"),LSr=o(" (Hubert model)"),ySr=l(),a5=a("li"),Qwe=a("strong"),xSr=o("layoutlm"),$Sr=o(" \u2014 "),Pee=a("a"),kSr=o("TFLayoutLMModel"),SSr=o(" (LayoutLM model)"),RSr=l(),n5=a("li"),Wwe=a("strong"),PSr=o("layoutlmv3"),BSr=o(" \u2014 "),Bee=a("a"),ISr=o("TFLayoutLMv3Model"),NSr=o(" (LayoutLMv3 model)"),qSr=l(),s5=a("li"),Uwe=a("strong"),jSr=o("led"),DSr=o(" \u2014 "),Iee=a("a"),GSr=o("TFLEDModel"),OSr=o(" (LED model)"),VSr=l(),l5=a("li"),Hwe=a("strong"),XSr=o("longformer"),zSr=o(" \u2014 "),Nee=a("a"),QSr=o("TFLongformerModel"),WSr=o(" (Longformer model)"),USr=l(),i5=a("li"),Jwe=a("strong"),HSr=o("lxmert"),JSr=o(" \u2014 "),qee=a("a"),YSr=o("TFLxmertModel"),KSr=o(" (LXMERT model)"),ZSr=l(),d5=a("li"),Ywe=a("strong"),eRr=o("marian"),oRr=o(" \u2014 "),jee=a("a"),rRr=o("TFMarianModel"),tRr=o(" (Marian model)"),aRr=l(),m5=a("li"),Kwe=a("strong"),nRr=o("mbart"),sRr=o(" \u2014 "),Dee=a("a"),lRr=o("TFMBartModel"),iRr=o(" (mBART model)"),dRr=l(),c5=a("li"),Zwe=a("strong"),mRr=o("mobilebert"),cRr=o(" \u2014 "),Gee=a("a"),fRr=o("TFMobileBertModel"),gRr=o(" (MobileBERT model)"),hRr=l(),f5=a("li"),eAe=a("strong"),uRr=o("mobilevit"),pRr=o(" \u2014 "),Oee=a("a"),_Rr=o("TFMobileViTModel"),bRr=o(" (MobileViT model)"),vRr=l(),g5=a("li"),oAe=a("strong"),FRr=o("mpnet"),TRr=o(" \u2014 "),Vee=a("a"),MRr=o("TFMPNetModel"),ERr=o(" (MPNet model)"),CRr=l(),h5=a("li"),rAe=a("strong"),wRr=o("mt5"),ARr=o(" \u2014 "),Xee=a("a"),LRr=o("TFMT5Model"),yRr=o(" (MT5 model)"),xRr=l(),u5=a("li"),tAe=a("strong"),$Rr=o("openai-gpt"),kRr=o(" \u2014 "),zee=a("a"),SRr=o("TFOpenAIGPTModel"),RRr=o(" (OpenAI GPT model)"),PRr=l(),p5=a("li"),aAe=a("strong"),BRr=o("opt"),IRr=o(" \u2014 "),Qee=a("a"),NRr=o("TFOPTModel"),qRr=o(" (OPT model)"),jRr=l(),_5=a("li"),nAe=a("strong"),DRr=o("pegasus"),GRr=o(" \u2014 "),Wee=a("a"),ORr=o("TFPegasusModel"),VRr=o(" (Pegasus model)"),XRr=l(),b5=a("li"),sAe=a("strong"),zRr=o("regnet"),QRr=o(" \u2014 "),Uee=a("a"),WRr=o("TFRegNetModel"),URr=o(" (RegNet model)"),HRr=l(),v5=a("li"),lAe=a("strong"),JRr=o("rembert"),YRr=o(" \u2014 "),Hee=a("a"),KRr=o("TFRemBertModel"),ZRr=o(" (RemBERT model)"),ePr=l(),F5=a("li"),iAe=a("strong"),oPr=o("resnet"),rPr=o(" \u2014 "),Jee=a("a"),tPr=o("TFResNetModel"),aPr=o(" (ResNet model)"),nPr=l(),T5=a("li"),dAe=a("strong"),sPr=o("roberta"),lPr=o(" \u2014 "),Yee=a("a"),iPr=o("TFRobertaModel"),dPr=o(" (RoBERTa model)"),mPr=l(),M5=a("li"),mAe=a("strong"),cPr=o("roformer"),fPr=o(" \u2014 "),Kee=a("a"),gPr=o("TFRoFormerModel"),hPr=o(" (RoFormer model)"),uPr=l(),E5=a("li"),cAe=a("strong"),pPr=o("segformer"),_Pr=o(" \u2014 "),Zee=a("a"),bPr=o("TFSegformerModel"),vPr=o(" (SegFormer model)"),FPr=l(),C5=a("li"),fAe=a("strong"),TPr=o("speech_to_text"),MPr=o(" \u2014 "),eoe=a("a"),EPr=o("TFSpeech2TextModel"),CPr=o(" (Speech2Text model)"),wPr=l(),w5=a("li"),gAe=a("strong"),APr=o("swin"),LPr=o(" \u2014 "),ooe=a("a"),yPr=o("TFSwinModel"),xPr=o(" (Swin Transformer model)"),$Pr=l(),A5=a("li"),hAe=a("strong"),kPr=o("t5"),SPr=o(" \u2014 "),roe=a("a"),RPr=o("TFT5Model"),PPr=o(" (T5 model)"),BPr=l(),L5=a("li"),uAe=a("strong"),IPr=o("tapas"),NPr=o(" \u2014 "),toe=a("a"),qPr=o("TFTapasModel"),jPr=o(" (TAPAS model)"),DPr=l(),y5=a("li"),pAe=a("strong"),GPr=o("transfo-xl"),OPr=o(" \u2014 "),aoe=a("a"),VPr=o("TFTransfoXLModel"),XPr=o(" (Transformer-XL model)"),zPr=l(),x5=a("li"),_Ae=a("strong"),QPr=o("vit"),WPr=o(" \u2014 "),noe=a("a"),UPr=o("TFViTModel"),HPr=o(" (ViT model)"),JPr=l(),$5=a("li"),bAe=a("strong"),YPr=o("vit_mae"),KPr=o(" \u2014 "),soe=a("a"),ZPr=o("TFViTMAEModel"),eBr=o(" (ViTMAE model)"),oBr=l(),k5=a("li"),vAe=a("strong"),rBr=o("wav2vec2"),tBr=o(" \u2014 "),loe=a("a"),aBr=o("TFWav2Vec2Model"),nBr=o(" (Wav2Vec2 model)"),sBr=l(),S5=a("li"),FAe=a("strong"),lBr=o("xglm"),iBr=o(" \u2014 "),ioe=a("a"),dBr=o("TFXGLMModel"),mBr=o(" (XGLM model)"),cBr=l(),R5=a("li"),TAe=a("strong"),fBr=o("xlm"),gBr=o(" \u2014 "),doe=a("a"),hBr=o("TFXLMModel"),uBr=o(" (XLM model)"),pBr=l(),P5=a("li"),MAe=a("strong"),_Br=o("xlm-roberta"),bBr=o(" \u2014 "),moe=a("a"),vBr=o("TFXLMRobertaModel"),FBr=o(" (XLM-RoBERTa model)"),TBr=l(),B5=a("li"),EAe=a("strong"),MBr=o("xlnet"),EBr=o(" \u2014 "),coe=a("a"),CBr=o("TFXLNetModel"),wBr=o(" (XLNet model)"),ABr=l(),F(I5.$$.fragment),Zeo=l(),zm=a("h2"),N5=a("a"),CAe=a("span"),F(eS.$$.fragment),LBr=l(),wAe=a("span"),yBr=o("TFAutoModelForPreTraining"),eoo=l(),lr=a("div"),F(oS.$$.fragment),xBr=l(),Qm=a("p"),$Br=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),foe=a("a"),kBr=o("from_pretrained()"),SBr=o(" class method or the "),goe=a("a"),RBr=o("from_config()"),PBr=o(` class
method.`),BBr=l(),rS=a("p"),IBr=o("This class cannot be instantiated directly using "),AAe=a("code"),NBr=o("__init__()"),qBr=o(" (throws an error)."),jBr=l(),zt=a("div"),F(tS.$$.fragment),DBr=l(),LAe=a("p"),GBr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),OBr=l(),Wm=a("p"),VBr=o(`Note:
Loading a model from its configuration file does `),yAe=a("strong"),XBr=o("not"),zBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=a("a"),QBr=o("from_pretrained()"),WBr=o(" to load the model weights."),UBr=l(),F(q5.$$.fragment),HBr=l(),Nr=a("div"),F(aS.$$.fragment),JBr=l(),xAe=a("p"),YBr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KBr=l(),An=a("p"),ZBr=o("The model class to instantiate is selected based on the "),$Ae=a("code"),eIr=o("model_type"),oIr=o(` property of the config object (either
passed as an argument or loaded from `),kAe=a("code"),rIr=o("pretrained_model_name_or_path"),tIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SAe=a("code"),aIr=o("pretrained_model_name_or_path"),nIr=o(":"),sIr=l(),se=a("ul"),j5=a("li"),RAe=a("strong"),lIr=o("albert"),iIr=o(" \u2014 "),uoe=a("a"),dIr=o("TFAlbertForPreTraining"),mIr=o(" (ALBERT model)"),cIr=l(),D5=a("li"),PAe=a("strong"),fIr=o("bart"),gIr=o(" \u2014 "),poe=a("a"),hIr=o("TFBartForConditionalGeneration"),uIr=o(" (BART model)"),pIr=l(),G5=a("li"),BAe=a("strong"),_Ir=o("bert"),bIr=o(" \u2014 "),_oe=a("a"),vIr=o("TFBertForPreTraining"),FIr=o(" (BERT model)"),TIr=l(),O5=a("li"),IAe=a("strong"),MIr=o("camembert"),EIr=o(" \u2014 "),boe=a("a"),CIr=o("TFCamembertForMaskedLM"),wIr=o(" (CamemBERT model)"),AIr=l(),V5=a("li"),NAe=a("strong"),LIr=o("ctrl"),yIr=o(" \u2014 "),voe=a("a"),xIr=o("TFCTRLLMHeadModel"),$Ir=o(" (CTRL model)"),kIr=l(),X5=a("li"),qAe=a("strong"),SIr=o("distilbert"),RIr=o(" \u2014 "),Foe=a("a"),PIr=o("TFDistilBertForMaskedLM"),BIr=o(" (DistilBERT model)"),IIr=l(),z5=a("li"),jAe=a("strong"),NIr=o("electra"),qIr=o(" \u2014 "),Toe=a("a"),jIr=o("TFElectraForPreTraining"),DIr=o(" (ELECTRA model)"),GIr=l(),Q5=a("li"),DAe=a("strong"),OIr=o("flaubert"),VIr=o(" \u2014 "),Moe=a("a"),XIr=o("TFFlaubertWithLMHeadModel"),zIr=o(" (FlauBERT model)"),QIr=l(),W5=a("li"),GAe=a("strong"),WIr=o("funnel"),UIr=o(" \u2014 "),Eoe=a("a"),HIr=o("TFFunnelForPreTraining"),JIr=o(" (Funnel Transformer model)"),YIr=l(),U5=a("li"),OAe=a("strong"),KIr=o("gpt2"),ZIr=o(" \u2014 "),Coe=a("a"),eNr=o("TFGPT2LMHeadModel"),oNr=o(" (OpenAI GPT-2 model)"),rNr=l(),H5=a("li"),VAe=a("strong"),tNr=o("layoutlm"),aNr=o(" \u2014 "),woe=a("a"),nNr=o("TFLayoutLMForMaskedLM"),sNr=o(" (LayoutLM model)"),lNr=l(),J5=a("li"),XAe=a("strong"),iNr=o("lxmert"),dNr=o(" \u2014 "),Aoe=a("a"),mNr=o("TFLxmertForPreTraining"),cNr=o(" (LXMERT model)"),fNr=l(),Y5=a("li"),zAe=a("strong"),gNr=o("mobilebert"),hNr=o(" \u2014 "),Loe=a("a"),uNr=o("TFMobileBertForPreTraining"),pNr=o(" (MobileBERT model)"),_Nr=l(),K5=a("li"),QAe=a("strong"),bNr=o("mpnet"),vNr=o(" \u2014 "),yoe=a("a"),FNr=o("TFMPNetForMaskedLM"),TNr=o(" (MPNet model)"),MNr=l(),Z5=a("li"),WAe=a("strong"),ENr=o("openai-gpt"),CNr=o(" \u2014 "),xoe=a("a"),wNr=o("TFOpenAIGPTLMHeadModel"),ANr=o(" (OpenAI GPT model)"),LNr=l(),e0=a("li"),UAe=a("strong"),yNr=o("roberta"),xNr=o(" \u2014 "),$oe=a("a"),$Nr=o("TFRobertaForMaskedLM"),kNr=o(" (RoBERTa model)"),SNr=l(),o0=a("li"),HAe=a("strong"),RNr=o("t5"),PNr=o(" \u2014 "),koe=a("a"),BNr=o("TFT5ForConditionalGeneration"),INr=o(" (T5 model)"),NNr=l(),r0=a("li"),JAe=a("strong"),qNr=o("tapas"),jNr=o(" \u2014 "),Soe=a("a"),DNr=o("TFTapasForMaskedLM"),GNr=o(" (TAPAS model)"),ONr=l(),t0=a("li"),YAe=a("strong"),VNr=o("transfo-xl"),XNr=o(" \u2014 "),Roe=a("a"),zNr=o("TFTransfoXLLMHeadModel"),QNr=o(" (Transformer-XL model)"),WNr=l(),a0=a("li"),KAe=a("strong"),UNr=o("vit_mae"),HNr=o(" \u2014 "),Poe=a("a"),JNr=o("TFViTMAEForPreTraining"),YNr=o(" (ViTMAE model)"),KNr=l(),n0=a("li"),ZAe=a("strong"),ZNr=o("xlm"),eqr=o(" \u2014 "),Boe=a("a"),oqr=o("TFXLMWithLMHeadModel"),rqr=o(" (XLM model)"),tqr=l(),s0=a("li"),e6e=a("strong"),aqr=o("xlm-roberta"),nqr=o(" \u2014 "),Ioe=a("a"),sqr=o("TFXLMRobertaForMaskedLM"),lqr=o(" (XLM-RoBERTa model)"),iqr=l(),l0=a("li"),o6e=a("strong"),dqr=o("xlnet"),mqr=o(" \u2014 "),Noe=a("a"),cqr=o("TFXLNetLMHeadModel"),fqr=o(" (XLNet model)"),gqr=l(),F(i0.$$.fragment),ooo=l(),Um=a("h2"),d0=a("a"),r6e=a("span"),F(nS.$$.fragment),hqr=l(),t6e=a("span"),uqr=o("TFAutoModelForCausalLM"),roo=l(),ir=a("div"),F(sS.$$.fragment),pqr=l(),Hm=a("p"),_qr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qoe=a("a"),bqr=o("from_pretrained()"),vqr=o(" class method or the "),joe=a("a"),Fqr=o("from_config()"),Tqr=o(` class
method.`),Mqr=l(),lS=a("p"),Eqr=o("This class cannot be instantiated directly using "),a6e=a("code"),Cqr=o("__init__()"),wqr=o(" (throws an error)."),Aqr=l(),Qt=a("div"),F(iS.$$.fragment),Lqr=l(),n6e=a("p"),yqr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),xqr=l(),Jm=a("p"),$qr=o(`Note:
Loading a model from its configuration file does `),s6e=a("strong"),kqr=o("not"),Sqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=a("a"),Rqr=o("from_pretrained()"),Pqr=o(" to load the model weights."),Bqr=l(),F(m0.$$.fragment),Iqr=l(),qr=a("div"),F(dS.$$.fragment),Nqr=l(),l6e=a("p"),qqr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),jqr=l(),Ln=a("p"),Dqr=o("The model class to instantiate is selected based on the "),i6e=a("code"),Gqr=o("model_type"),Oqr=o(` property of the config object (either
passed as an argument or loaded from `),d6e=a("code"),Vqr=o("pretrained_model_name_or_path"),Xqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=a("code"),zqr=o("pretrained_model_name_or_path"),Qqr=o(":"),Wqr=l(),Me=a("ul"),c0=a("li"),c6e=a("strong"),Uqr=o("bert"),Hqr=o(" \u2014 "),Goe=a("a"),Jqr=o("TFBertLMHeadModel"),Yqr=o(" (BERT model)"),Kqr=l(),f0=a("li"),f6e=a("strong"),Zqr=o("camembert"),ejr=o(" \u2014 "),Ooe=a("a"),ojr=o("TFCamembertForCausalLM"),rjr=o(" (CamemBERT model)"),tjr=l(),g0=a("li"),g6e=a("strong"),ajr=o("ctrl"),njr=o(" \u2014 "),Voe=a("a"),sjr=o("TFCTRLLMHeadModel"),ljr=o(" (CTRL model)"),ijr=l(),h0=a("li"),h6e=a("strong"),djr=o("gpt2"),mjr=o(" \u2014 "),Xoe=a("a"),cjr=o("TFGPT2LMHeadModel"),fjr=o(" (OpenAI GPT-2 model)"),gjr=l(),u0=a("li"),u6e=a("strong"),hjr=o("gptj"),ujr=o(" \u2014 "),zoe=a("a"),pjr=o("TFGPTJForCausalLM"),_jr=o(" (GPT-J model)"),bjr=l(),p0=a("li"),p6e=a("strong"),vjr=o("openai-gpt"),Fjr=o(" \u2014 "),Qoe=a("a"),Tjr=o("TFOpenAIGPTLMHeadModel"),Mjr=o(" (OpenAI GPT model)"),Ejr=l(),_0=a("li"),_6e=a("strong"),Cjr=o("opt"),wjr=o(" \u2014 "),Woe=a("a"),Ajr=o("TFOPTForCausalLM"),Ljr=o(" (OPT model)"),yjr=l(),b0=a("li"),b6e=a("strong"),xjr=o("rembert"),$jr=o(" \u2014 "),Uoe=a("a"),kjr=o("TFRemBertForCausalLM"),Sjr=o(" (RemBERT model)"),Rjr=l(),v0=a("li"),v6e=a("strong"),Pjr=o("roberta"),Bjr=o(" \u2014 "),Hoe=a("a"),Ijr=o("TFRobertaForCausalLM"),Njr=o(" (RoBERTa model)"),qjr=l(),F0=a("li"),F6e=a("strong"),jjr=o("roformer"),Djr=o(" \u2014 "),Joe=a("a"),Gjr=o("TFRoFormerForCausalLM"),Ojr=o(" (RoFormer model)"),Vjr=l(),T0=a("li"),T6e=a("strong"),Xjr=o("transfo-xl"),zjr=o(" \u2014 "),Yoe=a("a"),Qjr=o("TFTransfoXLLMHeadModel"),Wjr=o(" (Transformer-XL model)"),Ujr=l(),M0=a("li"),M6e=a("strong"),Hjr=o("xglm"),Jjr=o(" \u2014 "),Koe=a("a"),Yjr=o("TFXGLMForCausalLM"),Kjr=o(" (XGLM model)"),Zjr=l(),E0=a("li"),E6e=a("strong"),eDr=o("xlm"),oDr=o(" \u2014 "),Zoe=a("a"),rDr=o("TFXLMWithLMHeadModel"),tDr=o(" (XLM model)"),aDr=l(),C0=a("li"),C6e=a("strong"),nDr=o("xlnet"),sDr=o(" \u2014 "),ere=a("a"),lDr=o("TFXLNetLMHeadModel"),iDr=o(" (XLNet model)"),dDr=l(),F(w0.$$.fragment),too=l(),Ym=a("h2"),A0=a("a"),w6e=a("span"),F(mS.$$.fragment),mDr=l(),A6e=a("span"),cDr=o("TFAutoModelForImageClassification"),aoo=l(),dr=a("div"),F(cS.$$.fragment),fDr=l(),Km=a("p"),gDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),ore=a("a"),hDr=o("from_pretrained()"),uDr=o(" class method or the "),rre=a("a"),pDr=o("from_config()"),_Dr=o(` class
method.`),bDr=l(),fS=a("p"),vDr=o("This class cannot be instantiated directly using "),L6e=a("code"),FDr=o("__init__()"),TDr=o(" (throws an error)."),MDr=l(),Wt=a("div"),F(gS.$$.fragment),EDr=l(),y6e=a("p"),CDr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wDr=l(),Zm=a("p"),ADr=o(`Note:
Loading a model from its configuration file does `),x6e=a("strong"),LDr=o("not"),yDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=a("a"),xDr=o("from_pretrained()"),$Dr=o(" to load the model weights."),kDr=l(),F(L0.$$.fragment),SDr=l(),jr=a("div"),F(hS.$$.fragment),RDr=l(),$6e=a("p"),PDr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),BDr=l(),yn=a("p"),IDr=o("The model class to instantiate is selected based on the "),k6e=a("code"),NDr=o("model_type"),qDr=o(` property of the config object (either
passed as an argument or loaded from `),S6e=a("code"),jDr=o("pretrained_model_name_or_path"),DDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R6e=a("code"),GDr=o("pretrained_model_name_or_path"),ODr=o(":"),VDr=l(),Be=a("ul"),y0=a("li"),P6e=a("strong"),XDr=o("convnext"),zDr=o(" \u2014 "),are=a("a"),QDr=o("TFConvNextForImageClassification"),WDr=o(" (ConvNeXT model)"),UDr=l(),x0=a("li"),B6e=a("strong"),HDr=o("data2vec-vision"),JDr=o(" \u2014 "),nre=a("a"),YDr=o("TFData2VecVisionForImageClassification"),KDr=o(" (Data2VecVision model)"),ZDr=l(),Tl=a("li"),I6e=a("strong"),eGr=o("deit"),oGr=o(" \u2014 "),sre=a("a"),rGr=o("TFDeiTForImageClassification"),tGr=o(" or "),lre=a("a"),aGr=o("TFDeiTForImageClassificationWithTeacher"),nGr=o(" (DeiT model)"),sGr=l(),$0=a("li"),N6e=a("strong"),lGr=o("mobilevit"),iGr=o(" \u2014 "),ire=a("a"),dGr=o("TFMobileViTForImageClassification"),mGr=o(" (MobileViT model)"),cGr=l(),k0=a("li"),q6e=a("strong"),fGr=o("regnet"),gGr=o(" \u2014 "),dre=a("a"),hGr=o("TFRegNetForImageClassification"),uGr=o(" (RegNet model)"),pGr=l(),S0=a("li"),j6e=a("strong"),_Gr=o("resnet"),bGr=o(" \u2014 "),mre=a("a"),vGr=o("TFResNetForImageClassification"),FGr=o(" (ResNet model)"),TGr=l(),R0=a("li"),D6e=a("strong"),MGr=o("segformer"),EGr=o(" \u2014 "),cre=a("a"),CGr=o("TFSegformerForImageClassification"),wGr=o(" (SegFormer model)"),AGr=l(),P0=a("li"),G6e=a("strong"),LGr=o("swin"),yGr=o(" \u2014 "),fre=a("a"),xGr=o("TFSwinForImageClassification"),$Gr=o(" (Swin Transformer model)"),kGr=l(),B0=a("li"),O6e=a("strong"),SGr=o("vit"),RGr=o(" \u2014 "),gre=a("a"),PGr=o("TFViTForImageClassification"),BGr=o(" (ViT model)"),IGr=l(),F(I0.$$.fragment),noo=l(),ec=a("h2"),N0=a("a"),V6e=a("span"),F(uS.$$.fragment),NGr=l(),X6e=a("span"),qGr=o("TFAutoModelForSemanticSegmentation"),soo=l(),mr=a("div"),F(pS.$$.fragment),jGr=l(),oc=a("p"),DGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),hre=a("a"),GGr=o("from_pretrained()"),OGr=o(" class method or the "),ure=a("a"),VGr=o("from_config()"),XGr=o(` class
method.`),zGr=l(),_S=a("p"),QGr=o("This class cannot be instantiated directly using "),z6e=a("code"),WGr=o("__init__()"),UGr=o(" (throws an error)."),HGr=l(),Ut=a("div"),F(bS.$$.fragment),JGr=l(),Q6e=a("p"),YGr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),KGr=l(),rc=a("p"),ZGr=o(`Note:
Loading a model from its configuration file does `),W6e=a("strong"),eOr=o("not"),oOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pre=a("a"),rOr=o("from_pretrained()"),tOr=o(" to load the model weights."),aOr=l(),F(q0.$$.fragment),nOr=l(),Dr=a("div"),F(vS.$$.fragment),sOr=l(),U6e=a("p"),lOr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),iOr=l(),xn=a("p"),dOr=o("The model class to instantiate is selected based on the "),H6e=a("code"),mOr=o("model_type"),cOr=o(` property of the config object (either
passed as an argument or loaded from `),J6e=a("code"),fOr=o("pretrained_model_name_or_path"),gOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=a("code"),hOr=o("pretrained_model_name_or_path"),uOr=o(":"),pOr=l(),tc=a("ul"),j0=a("li"),K6e=a("strong"),_Or=o("data2vec-vision"),bOr=o(" \u2014 "),_re=a("a"),vOr=o("TFData2VecVisionForSemanticSegmentation"),FOr=o(" (Data2VecVision model)"),TOr=l(),D0=a("li"),Z6e=a("strong"),MOr=o("mobilevit"),EOr=o(" \u2014 "),bre=a("a"),COr=o("TFMobileViTForSemanticSegmentation"),wOr=o(" (MobileViT model)"),AOr=l(),G0=a("li"),e7e=a("strong"),LOr=o("segformer"),yOr=o(" \u2014 "),vre=a("a"),xOr=o("TFSegformerForSemanticSegmentation"),$Or=o(" (SegFormer model)"),kOr=l(),F(O0.$$.fragment),loo=l(),ac=a("h2"),V0=a("a"),o7e=a("span"),F(FS.$$.fragment),SOr=l(),r7e=a("span"),ROr=o("TFAutoModelForMaskedLM"),ioo=l(),cr=a("div"),F(TS.$$.fragment),POr=l(),nc=a("p"),BOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fre=a("a"),IOr=o("from_pretrained()"),NOr=o(" class method or the "),Tre=a("a"),qOr=o("from_config()"),jOr=o(` class
method.`),DOr=l(),MS=a("p"),GOr=o("This class cannot be instantiated directly using "),t7e=a("code"),OOr=o("__init__()"),VOr=o(" (throws an error)."),XOr=l(),Ht=a("div"),F(ES.$$.fragment),zOr=l(),a7e=a("p"),QOr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),WOr=l(),sc=a("p"),UOr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),HOr=o("not"),JOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mre=a("a"),YOr=o("from_pretrained()"),KOr=o(" to load the model weights."),ZOr=l(),F(X0.$$.fragment),eVr=l(),Gr=a("div"),F(CS.$$.fragment),oVr=l(),s7e=a("p"),rVr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),tVr=l(),$n=a("p"),aVr=o("The model class to instantiate is selected based on the "),l7e=a("code"),nVr=o("model_type"),sVr=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),lVr=o("pretrained_model_name_or_path"),iVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),dVr=o("pretrained_model_name_or_path"),mVr=o(":"),cVr=l(),ge=a("ul"),z0=a("li"),m7e=a("strong"),fVr=o("albert"),gVr=o(" \u2014 "),Ere=a("a"),hVr=o("TFAlbertForMaskedLM"),uVr=o(" (ALBERT model)"),pVr=l(),Q0=a("li"),c7e=a("strong"),_Vr=o("bert"),bVr=o(" \u2014 "),Cre=a("a"),vVr=o("TFBertForMaskedLM"),FVr=o(" (BERT model)"),TVr=l(),W0=a("li"),f7e=a("strong"),MVr=o("camembert"),EVr=o(" \u2014 "),wre=a("a"),CVr=o("TFCamembertForMaskedLM"),wVr=o(" (CamemBERT model)"),AVr=l(),U0=a("li"),g7e=a("strong"),LVr=o("convbert"),yVr=o(" \u2014 "),Are=a("a"),xVr=o("TFConvBertForMaskedLM"),$Vr=o(" (ConvBERT model)"),kVr=l(),H0=a("li"),h7e=a("strong"),SVr=o("deberta"),RVr=o(" \u2014 "),Lre=a("a"),PVr=o("TFDebertaForMaskedLM"),BVr=o(" (DeBERTa model)"),IVr=l(),J0=a("li"),u7e=a("strong"),NVr=o("deberta-v2"),qVr=o(" \u2014 "),yre=a("a"),jVr=o("TFDebertaV2ForMaskedLM"),DVr=o(" (DeBERTa-v2 model)"),GVr=l(),Y0=a("li"),p7e=a("strong"),OVr=o("distilbert"),VVr=o(" \u2014 "),xre=a("a"),XVr=o("TFDistilBertForMaskedLM"),zVr=o(" (DistilBERT model)"),QVr=l(),K0=a("li"),_7e=a("strong"),WVr=o("electra"),UVr=o(" \u2014 "),$re=a("a"),HVr=o("TFElectraForMaskedLM"),JVr=o(" (ELECTRA model)"),YVr=l(),Z0=a("li"),b7e=a("strong"),KVr=o("flaubert"),ZVr=o(" \u2014 "),kre=a("a"),eXr=o("TFFlaubertWithLMHeadModel"),oXr=o(" (FlauBERT model)"),rXr=l(),ew=a("li"),v7e=a("strong"),tXr=o("funnel"),aXr=o(" \u2014 "),Sre=a("a"),nXr=o("TFFunnelForMaskedLM"),sXr=o(" (Funnel Transformer model)"),lXr=l(),ow=a("li"),F7e=a("strong"),iXr=o("layoutlm"),dXr=o(" \u2014 "),Rre=a("a"),mXr=o("TFLayoutLMForMaskedLM"),cXr=o(" (LayoutLM model)"),fXr=l(),rw=a("li"),T7e=a("strong"),gXr=o("longformer"),hXr=o(" \u2014 "),Pre=a("a"),uXr=o("TFLongformerForMaskedLM"),pXr=o(" (Longformer model)"),_Xr=l(),tw=a("li"),M7e=a("strong"),bXr=o("mobilebert"),vXr=o(" \u2014 "),Bre=a("a"),FXr=o("TFMobileBertForMaskedLM"),TXr=o(" (MobileBERT model)"),MXr=l(),aw=a("li"),E7e=a("strong"),EXr=o("mpnet"),CXr=o(" \u2014 "),Ire=a("a"),wXr=o("TFMPNetForMaskedLM"),AXr=o(" (MPNet model)"),LXr=l(),nw=a("li"),C7e=a("strong"),yXr=o("rembert"),xXr=o(" \u2014 "),Nre=a("a"),$Xr=o("TFRemBertForMaskedLM"),kXr=o(" (RemBERT model)"),SXr=l(),sw=a("li"),w7e=a("strong"),RXr=o("roberta"),PXr=o(" \u2014 "),qre=a("a"),BXr=o("TFRobertaForMaskedLM"),IXr=o(" (RoBERTa model)"),NXr=l(),lw=a("li"),A7e=a("strong"),qXr=o("roformer"),jXr=o(" \u2014 "),jre=a("a"),DXr=o("TFRoFormerForMaskedLM"),GXr=o(" (RoFormer model)"),OXr=l(),iw=a("li"),L7e=a("strong"),VXr=o("tapas"),XXr=o(" \u2014 "),Dre=a("a"),zXr=o("TFTapasForMaskedLM"),QXr=o(" (TAPAS model)"),WXr=l(),dw=a("li"),y7e=a("strong"),UXr=o("xlm"),HXr=o(" \u2014 "),Gre=a("a"),JXr=o("TFXLMWithLMHeadModel"),YXr=o(" (XLM model)"),KXr=l(),mw=a("li"),x7e=a("strong"),ZXr=o("xlm-roberta"),ezr=o(" \u2014 "),Ore=a("a"),ozr=o("TFXLMRobertaForMaskedLM"),rzr=o(" (XLM-RoBERTa model)"),tzr=l(),F(cw.$$.fragment),doo=l(),lc=a("h2"),fw=a("a"),$7e=a("span"),F(wS.$$.fragment),azr=l(),k7e=a("span"),nzr=o("TFAutoModelForSeq2SeqLM"),moo=l(),fr=a("div"),F(AS.$$.fragment),szr=l(),ic=a("p"),lzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Vre=a("a"),izr=o("from_pretrained()"),dzr=o(" class method or the "),Xre=a("a"),mzr=o("from_config()"),czr=o(` class
method.`),fzr=l(),LS=a("p"),gzr=o("This class cannot be instantiated directly using "),S7e=a("code"),hzr=o("__init__()"),uzr=o(" (throws an error)."),pzr=l(),Jt=a("div"),F(yS.$$.fragment),_zr=l(),R7e=a("p"),bzr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vzr=l(),dc=a("p"),Fzr=o(`Note:
Loading a model from its configuration file does `),P7e=a("strong"),Tzr=o("not"),Mzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=a("a"),Ezr=o("from_pretrained()"),Czr=o(" to load the model weights."),wzr=l(),F(gw.$$.fragment),Azr=l(),Or=a("div"),F(xS.$$.fragment),Lzr=l(),B7e=a("p"),yzr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),xzr=l(),kn=a("p"),$zr=o("The model class to instantiate is selected based on the "),I7e=a("code"),kzr=o("model_type"),Szr=o(` property of the config object (either
passed as an argument or loaded from `),N7e=a("code"),Rzr=o("pretrained_model_name_or_path"),Pzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q7e=a("code"),Bzr=o("pretrained_model_name_or_path"),Izr=o(":"),Nzr=l(),ye=a("ul"),hw=a("li"),j7e=a("strong"),qzr=o("bart"),jzr=o(" \u2014 "),Qre=a("a"),Dzr=o("TFBartForConditionalGeneration"),Gzr=o(" (BART model)"),Ozr=l(),uw=a("li"),D7e=a("strong"),Vzr=o("blenderbot"),Xzr=o(" \u2014 "),Wre=a("a"),zzr=o("TFBlenderbotForConditionalGeneration"),Qzr=o(" (Blenderbot model)"),Wzr=l(),pw=a("li"),G7e=a("strong"),Uzr=o("blenderbot-small"),Hzr=o(" \u2014 "),Ure=a("a"),Jzr=o("TFBlenderbotSmallForConditionalGeneration"),Yzr=o(" (BlenderbotSmall model)"),Kzr=l(),_w=a("li"),O7e=a("strong"),Zzr=o("encoder-decoder"),eQr=o(" \u2014 "),Hre=a("a"),oQr=o("TFEncoderDecoderModel"),rQr=o(" (Encoder decoder model)"),tQr=l(),bw=a("li"),V7e=a("strong"),aQr=o("led"),nQr=o(" \u2014 "),Jre=a("a"),sQr=o("TFLEDForConditionalGeneration"),lQr=o(" (LED model)"),iQr=l(),vw=a("li"),X7e=a("strong"),dQr=o("marian"),mQr=o(" \u2014 "),Yre=a("a"),cQr=o("TFMarianMTModel"),fQr=o(" (Marian model)"),gQr=l(),Fw=a("li"),z7e=a("strong"),hQr=o("mbart"),uQr=o(" \u2014 "),Kre=a("a"),pQr=o("TFMBartForConditionalGeneration"),_Qr=o(" (mBART model)"),bQr=l(),Tw=a("li"),Q7e=a("strong"),vQr=o("mt5"),FQr=o(" \u2014 "),Zre=a("a"),TQr=o("TFMT5ForConditionalGeneration"),MQr=o(" (MT5 model)"),EQr=l(),Mw=a("li"),W7e=a("strong"),CQr=o("pegasus"),wQr=o(" \u2014 "),ete=a("a"),AQr=o("TFPegasusForConditionalGeneration"),LQr=o(" (Pegasus model)"),yQr=l(),Ew=a("li"),U7e=a("strong"),xQr=o("t5"),$Qr=o(" \u2014 "),ote=a("a"),kQr=o("TFT5ForConditionalGeneration"),SQr=o(" (T5 model)"),RQr=l(),F(Cw.$$.fragment),coo=l(),mc=a("h2"),ww=a("a"),H7e=a("span"),F($S.$$.fragment),PQr=l(),J7e=a("span"),BQr=o("TFAutoModelForSequenceClassification"),foo=l(),gr=a("div"),F(kS.$$.fragment),IQr=l(),cc=a("p"),NQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),rte=a("a"),qQr=o("from_pretrained()"),jQr=o(" class method or the "),tte=a("a"),DQr=o("from_config()"),GQr=o(` class
method.`),OQr=l(),SS=a("p"),VQr=o("This class cannot be instantiated directly using "),Y7e=a("code"),XQr=o("__init__()"),zQr=o(" (throws an error)."),QQr=l(),Yt=a("div"),F(RS.$$.fragment),WQr=l(),K7e=a("p"),UQr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),HQr=l(),fc=a("p"),JQr=o(`Note:
Loading a model from its configuration file does `),Z7e=a("strong"),YQr=o("not"),KQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=a("a"),ZQr=o("from_pretrained()"),eWr=o(" to load the model weights."),oWr=l(),F(Aw.$$.fragment),rWr=l(),Vr=a("div"),F(PS.$$.fragment),tWr=l(),eLe=a("p"),aWr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nWr=l(),Sn=a("p"),sWr=o("The model class to instantiate is selected based on the "),oLe=a("code"),lWr=o("model_type"),iWr=o(` property of the config object (either
passed as an argument or loaded from `),rLe=a("code"),dWr=o("pretrained_model_name_or_path"),mWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tLe=a("code"),cWr=o("pretrained_model_name_or_path"),fWr=o(":"),gWr=l(),re=a("ul"),Lw=a("li"),aLe=a("strong"),hWr=o("albert"),uWr=o(" \u2014 "),nte=a("a"),pWr=o("TFAlbertForSequenceClassification"),_Wr=o(" (ALBERT model)"),bWr=l(),yw=a("li"),nLe=a("strong"),vWr=o("bert"),FWr=o(" \u2014 "),ste=a("a"),TWr=o("TFBertForSequenceClassification"),MWr=o(" (BERT model)"),EWr=l(),xw=a("li"),sLe=a("strong"),CWr=o("camembert"),wWr=o(" \u2014 "),lte=a("a"),AWr=o("TFCamembertForSequenceClassification"),LWr=o(" (CamemBERT model)"),yWr=l(),$w=a("li"),lLe=a("strong"),xWr=o("convbert"),$Wr=o(" \u2014 "),ite=a("a"),kWr=o("TFConvBertForSequenceClassification"),SWr=o(" (ConvBERT model)"),RWr=l(),kw=a("li"),iLe=a("strong"),PWr=o("ctrl"),BWr=o(" \u2014 "),dte=a("a"),IWr=o("TFCTRLForSequenceClassification"),NWr=o(" (CTRL model)"),qWr=l(),Sw=a("li"),dLe=a("strong"),jWr=o("deberta"),DWr=o(" \u2014 "),mte=a("a"),GWr=o("TFDebertaForSequenceClassification"),OWr=o(" (DeBERTa model)"),VWr=l(),Rw=a("li"),mLe=a("strong"),XWr=o("deberta-v2"),zWr=o(" \u2014 "),cte=a("a"),QWr=o("TFDebertaV2ForSequenceClassification"),WWr=o(" (DeBERTa-v2 model)"),UWr=l(),Pw=a("li"),cLe=a("strong"),HWr=o("distilbert"),JWr=o(" \u2014 "),fte=a("a"),YWr=o("TFDistilBertForSequenceClassification"),KWr=o(" (DistilBERT model)"),ZWr=l(),Bw=a("li"),fLe=a("strong"),eUr=o("electra"),oUr=o(" \u2014 "),gte=a("a"),rUr=o("TFElectraForSequenceClassification"),tUr=o(" (ELECTRA model)"),aUr=l(),Iw=a("li"),gLe=a("strong"),nUr=o("flaubert"),sUr=o(" \u2014 "),hte=a("a"),lUr=o("TFFlaubertForSequenceClassification"),iUr=o(" (FlauBERT model)"),dUr=l(),Nw=a("li"),hLe=a("strong"),mUr=o("funnel"),cUr=o(" \u2014 "),ute=a("a"),fUr=o("TFFunnelForSequenceClassification"),gUr=o(" (Funnel Transformer model)"),hUr=l(),qw=a("li"),uLe=a("strong"),uUr=o("gpt2"),pUr=o(" \u2014 "),pte=a("a"),_Ur=o("TFGPT2ForSequenceClassification"),bUr=o(" (OpenAI GPT-2 model)"),vUr=l(),jw=a("li"),pLe=a("strong"),FUr=o("gptj"),TUr=o(" \u2014 "),_te=a("a"),MUr=o("TFGPTJForSequenceClassification"),EUr=o(" (GPT-J model)"),CUr=l(),Dw=a("li"),_Le=a("strong"),wUr=o("layoutlm"),AUr=o(" \u2014 "),bte=a("a"),LUr=o("TFLayoutLMForSequenceClassification"),yUr=o(" (LayoutLM model)"),xUr=l(),Gw=a("li"),bLe=a("strong"),$Ur=o("layoutlmv3"),kUr=o(" \u2014 "),vte=a("a"),SUr=o("TFLayoutLMv3ForSequenceClassification"),RUr=o(" (LayoutLMv3 model)"),PUr=l(),Ow=a("li"),vLe=a("strong"),BUr=o("longformer"),IUr=o(" \u2014 "),Fte=a("a"),NUr=o("TFLongformerForSequenceClassification"),qUr=o(" (Longformer model)"),jUr=l(),Vw=a("li"),FLe=a("strong"),DUr=o("mobilebert"),GUr=o(" \u2014 "),Tte=a("a"),OUr=o("TFMobileBertForSequenceClassification"),VUr=o(" (MobileBERT model)"),XUr=l(),Xw=a("li"),TLe=a("strong"),zUr=o("mpnet"),QUr=o(" \u2014 "),Mte=a("a"),WUr=o("TFMPNetForSequenceClassification"),UUr=o(" (MPNet model)"),HUr=l(),zw=a("li"),MLe=a("strong"),JUr=o("openai-gpt"),YUr=o(" \u2014 "),Ete=a("a"),KUr=o("TFOpenAIGPTForSequenceClassification"),ZUr=o(" (OpenAI GPT model)"),eHr=l(),Qw=a("li"),ELe=a("strong"),oHr=o("rembert"),rHr=o(" \u2014 "),Cte=a("a"),tHr=o("TFRemBertForSequenceClassification"),aHr=o(" (RemBERT model)"),nHr=l(),Ww=a("li"),CLe=a("strong"),sHr=o("roberta"),lHr=o(" \u2014 "),wte=a("a"),iHr=o("TFRobertaForSequenceClassification"),dHr=o(" (RoBERTa model)"),mHr=l(),Uw=a("li"),wLe=a("strong"),cHr=o("roformer"),fHr=o(" \u2014 "),Ate=a("a"),gHr=o("TFRoFormerForSequenceClassification"),hHr=o(" (RoFormer model)"),uHr=l(),Hw=a("li"),ALe=a("strong"),pHr=o("tapas"),_Hr=o(" \u2014 "),Lte=a("a"),bHr=o("TFTapasForSequenceClassification"),vHr=o(" (TAPAS model)"),FHr=l(),Jw=a("li"),LLe=a("strong"),THr=o("transfo-xl"),MHr=o(" \u2014 "),yte=a("a"),EHr=o("TFTransfoXLForSequenceClassification"),CHr=o(" (Transformer-XL model)"),wHr=l(),Yw=a("li"),yLe=a("strong"),AHr=o("xlm"),LHr=o(" \u2014 "),xte=a("a"),yHr=o("TFXLMForSequenceClassification"),xHr=o(" (XLM model)"),$Hr=l(),Kw=a("li"),xLe=a("strong"),kHr=o("xlm-roberta"),SHr=o(" \u2014 "),$te=a("a"),RHr=o("TFXLMRobertaForSequenceClassification"),PHr=o(" (XLM-RoBERTa model)"),BHr=l(),Zw=a("li"),$Le=a("strong"),IHr=o("xlnet"),NHr=o(" \u2014 "),kte=a("a"),qHr=o("TFXLNetForSequenceClassification"),jHr=o(" (XLNet model)"),DHr=l(),F(eA.$$.fragment),goo=l(),gc=a("h2"),oA=a("a"),kLe=a("span"),F(BS.$$.fragment),GHr=l(),SLe=a("span"),OHr=o("TFAutoModelForMultipleChoice"),hoo=l(),hr=a("div"),F(IS.$$.fragment),VHr=l(),hc=a("p"),XHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ste=a("a"),zHr=o("from_pretrained()"),QHr=o(" class method or the "),Rte=a("a"),WHr=o("from_config()"),UHr=o(` class
method.`),HHr=l(),NS=a("p"),JHr=o("This class cannot be instantiated directly using "),RLe=a("code"),YHr=o("__init__()"),KHr=o(" (throws an error)."),ZHr=l(),Kt=a("div"),F(qS.$$.fragment),eJr=l(),PLe=a("p"),oJr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),rJr=l(),uc=a("p"),tJr=o(`Note:
Loading a model from its configuration file does `),BLe=a("strong"),aJr=o("not"),nJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pte=a("a"),sJr=o("from_pretrained()"),lJr=o(" to load the model weights."),iJr=l(),F(rA.$$.fragment),dJr=l(),Xr=a("div"),F(jS.$$.fragment),mJr=l(),ILe=a("p"),cJr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),fJr=l(),Rn=a("p"),gJr=o("The model class to instantiate is selected based on the "),NLe=a("code"),hJr=o("model_type"),uJr=o(` property of the config object (either
passed as an argument or loaded from `),qLe=a("code"),pJr=o("pretrained_model_name_or_path"),_Jr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jLe=a("code"),bJr=o("pretrained_model_name_or_path"),vJr=o(":"),FJr=l(),ve=a("ul"),tA=a("li"),DLe=a("strong"),TJr=o("albert"),MJr=o(" \u2014 "),Bte=a("a"),EJr=o("TFAlbertForMultipleChoice"),CJr=o(" (ALBERT model)"),wJr=l(),aA=a("li"),GLe=a("strong"),AJr=o("bert"),LJr=o(" \u2014 "),Ite=a("a"),yJr=o("TFBertForMultipleChoice"),xJr=o(" (BERT model)"),$Jr=l(),nA=a("li"),OLe=a("strong"),kJr=o("camembert"),SJr=o(" \u2014 "),Nte=a("a"),RJr=o("TFCamembertForMultipleChoice"),PJr=o(" (CamemBERT model)"),BJr=l(),sA=a("li"),VLe=a("strong"),IJr=o("convbert"),NJr=o(" \u2014 "),qte=a("a"),qJr=o("TFConvBertForMultipleChoice"),jJr=o(" (ConvBERT model)"),DJr=l(),lA=a("li"),XLe=a("strong"),GJr=o("distilbert"),OJr=o(" \u2014 "),jte=a("a"),VJr=o("TFDistilBertForMultipleChoice"),XJr=o(" (DistilBERT model)"),zJr=l(),iA=a("li"),zLe=a("strong"),QJr=o("electra"),WJr=o(" \u2014 "),Dte=a("a"),UJr=o("TFElectraForMultipleChoice"),HJr=o(" (ELECTRA model)"),JJr=l(),dA=a("li"),QLe=a("strong"),YJr=o("flaubert"),KJr=o(" \u2014 "),Gte=a("a"),ZJr=o("TFFlaubertForMultipleChoice"),eYr=o(" (FlauBERT model)"),oYr=l(),mA=a("li"),WLe=a("strong"),rYr=o("funnel"),tYr=o(" \u2014 "),Ote=a("a"),aYr=o("TFFunnelForMultipleChoice"),nYr=o(" (Funnel Transformer model)"),sYr=l(),cA=a("li"),ULe=a("strong"),lYr=o("longformer"),iYr=o(" \u2014 "),Vte=a("a"),dYr=o("TFLongformerForMultipleChoice"),mYr=o(" (Longformer model)"),cYr=l(),fA=a("li"),HLe=a("strong"),fYr=o("mobilebert"),gYr=o(" \u2014 "),Xte=a("a"),hYr=o("TFMobileBertForMultipleChoice"),uYr=o(" (MobileBERT model)"),pYr=l(),gA=a("li"),JLe=a("strong"),_Yr=o("mpnet"),bYr=o(" \u2014 "),zte=a("a"),vYr=o("TFMPNetForMultipleChoice"),FYr=o(" (MPNet model)"),TYr=l(),hA=a("li"),YLe=a("strong"),MYr=o("rembert"),EYr=o(" \u2014 "),Qte=a("a"),CYr=o("TFRemBertForMultipleChoice"),wYr=o(" (RemBERT model)"),AYr=l(),uA=a("li"),KLe=a("strong"),LYr=o("roberta"),yYr=o(" \u2014 "),Wte=a("a"),xYr=o("TFRobertaForMultipleChoice"),$Yr=o(" (RoBERTa model)"),kYr=l(),pA=a("li"),ZLe=a("strong"),SYr=o("roformer"),RYr=o(" \u2014 "),Ute=a("a"),PYr=o("TFRoFormerForMultipleChoice"),BYr=o(" (RoFormer model)"),IYr=l(),_A=a("li"),eye=a("strong"),NYr=o("xlm"),qYr=o(" \u2014 "),Hte=a("a"),jYr=o("TFXLMForMultipleChoice"),DYr=o(" (XLM model)"),GYr=l(),bA=a("li"),oye=a("strong"),OYr=o("xlm-roberta"),VYr=o(" \u2014 "),Jte=a("a"),XYr=o("TFXLMRobertaForMultipleChoice"),zYr=o(" (XLM-RoBERTa model)"),QYr=l(),vA=a("li"),rye=a("strong"),WYr=o("xlnet"),UYr=o(" \u2014 "),Yte=a("a"),HYr=o("TFXLNetForMultipleChoice"),JYr=o(" (XLNet model)"),YYr=l(),F(FA.$$.fragment),uoo=l(),pc=a("h2"),TA=a("a"),tye=a("span"),F(DS.$$.fragment),KYr=l(),aye=a("span"),ZYr=o("TFAutoModelForNextSentencePrediction"),poo=l(),ur=a("div"),F(GS.$$.fragment),eKr=l(),_c=a("p"),oKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Kte=a("a"),rKr=o("from_pretrained()"),tKr=o(" class method or the "),Zte=a("a"),aKr=o("from_config()"),nKr=o(` class
method.`),sKr=l(),OS=a("p"),lKr=o("This class cannot be instantiated directly using "),nye=a("code"),iKr=o("__init__()"),dKr=o(" (throws an error)."),mKr=l(),Zt=a("div"),F(VS.$$.fragment),cKr=l(),sye=a("p"),fKr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gKr=l(),bc=a("p"),hKr=o(`Note:
Loading a model from its configuration file does `),lye=a("strong"),uKr=o("not"),pKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eae=a("a"),_Kr=o("from_pretrained()"),bKr=o(" to load the model weights."),vKr=l(),F(MA.$$.fragment),FKr=l(),zr=a("div"),F(XS.$$.fragment),TKr=l(),iye=a("p"),MKr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),EKr=l(),Pn=a("p"),CKr=o("The model class to instantiate is selected based on the "),dye=a("code"),wKr=o("model_type"),AKr=o(` property of the config object (either
passed as an argument or loaded from `),mye=a("code"),LKr=o("pretrained_model_name_or_path"),yKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cye=a("code"),xKr=o("pretrained_model_name_or_path"),$Kr=o(":"),kKr=l(),zS=a("ul"),EA=a("li"),fye=a("strong"),SKr=o("bert"),RKr=o(" \u2014 "),oae=a("a"),PKr=o("TFBertForNextSentencePrediction"),BKr=o(" (BERT model)"),IKr=l(),CA=a("li"),gye=a("strong"),NKr=o("mobilebert"),qKr=o(" \u2014 "),rae=a("a"),jKr=o("TFMobileBertForNextSentencePrediction"),DKr=o(" (MobileBERT model)"),GKr=l(),F(wA.$$.fragment),_oo=l(),vc=a("h2"),AA=a("a"),hye=a("span"),F(QS.$$.fragment),OKr=l(),uye=a("span"),VKr=o("TFAutoModelForTableQuestionAnswering"),boo=l(),pr=a("div"),F(WS.$$.fragment),XKr=l(),Fc=a("p"),zKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),tae=a("a"),QKr=o("from_pretrained()"),WKr=o(" class method or the "),aae=a("a"),UKr=o("from_config()"),HKr=o(` class
method.`),JKr=l(),US=a("p"),YKr=o("This class cannot be instantiated directly using "),pye=a("code"),KKr=o("__init__()"),ZKr=o(" (throws an error)."),eZr=l(),ea=a("div"),F(HS.$$.fragment),oZr=l(),_ye=a("p"),rZr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),tZr=l(),Tc=a("p"),aZr=o(`Note:
Loading a model from its configuration file does `),bye=a("strong"),nZr=o("not"),sZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nae=a("a"),lZr=o("from_pretrained()"),iZr=o(" to load the model weights."),dZr=l(),F(LA.$$.fragment),mZr=l(),Qr=a("div"),F(JS.$$.fragment),cZr=l(),vye=a("p"),fZr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),gZr=l(),Bn=a("p"),hZr=o("The model class to instantiate is selected based on the "),Fye=a("code"),uZr=o("model_type"),pZr=o(` property of the config object (either
passed as an argument or loaded from `),Tye=a("code"),_Zr=o("pretrained_model_name_or_path"),bZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mye=a("code"),vZr=o("pretrained_model_name_or_path"),FZr=o(":"),TZr=l(),Eye=a("ul"),yA=a("li"),Cye=a("strong"),MZr=o("tapas"),EZr=o(" \u2014 "),sae=a("a"),CZr=o("TFTapasForQuestionAnswering"),wZr=o(" (TAPAS model)"),AZr=l(),F(xA.$$.fragment),voo=l(),Mc=a("h2"),$A=a("a"),wye=a("span"),F(YS.$$.fragment),LZr=l(),Aye=a("span"),yZr=o("TFAutoModelForDocumentQuestionAnswering"),Foo=l(),_r=a("div"),F(KS.$$.fragment),xZr=l(),Ec=a("p"),$Zr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),lae=a("a"),kZr=o("from_pretrained()"),SZr=o(" class method or the "),iae=a("a"),RZr=o("from_config()"),PZr=o(` class
method.`),BZr=l(),ZS=a("p"),IZr=o("This class cannot be instantiated directly using "),Lye=a("code"),NZr=o("__init__()"),qZr=o(" (throws an error)."),jZr=l(),oa=a("div"),F(eR.$$.fragment),DZr=l(),yye=a("p"),GZr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),OZr=l(),Cc=a("p"),VZr=o(`Note:
Loading a model from its configuration file does `),xye=a("strong"),XZr=o("not"),zZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dae=a("a"),QZr=o("from_pretrained()"),WZr=o(" to load the model weights."),UZr=l(),F(kA.$$.fragment),HZr=l(),Wr=a("div"),F(oR.$$.fragment),JZr=l(),$ye=a("p"),YZr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),KZr=l(),In=a("p"),ZZr=o("The model class to instantiate is selected based on the "),kye=a("code"),eet=o("model_type"),oet=o(` property of the config object (either
passed as an argument or loaded from `),Sye=a("code"),ret=o("pretrained_model_name_or_path"),tet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rye=a("code"),aet=o("pretrained_model_name_or_path"),net=o(":"),set=l(),Pye=a("ul"),SA=a("li"),Bye=a("strong"),iet=o("layoutlm"),det=o(" \u2014 "),mae=a("a"),met=o("TFLayoutLMForQuestionAnswering"),cet=o(" (LayoutLM model)"),fet=l(),F(RA.$$.fragment),Too=l(),wc=a("h2"),PA=a("a"),Iye=a("span"),F(rR.$$.fragment),get=l(),Nye=a("span"),het=o("TFAutoModelForTokenClassification"),Moo=l(),br=a("div"),F(tR.$$.fragment),uet=l(),Ac=a("p"),pet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),cae=a("a"),_et=o("from_pretrained()"),bet=o(" class method or the "),fae=a("a"),vet=o("from_config()"),Fet=o(` class
method.`),Tet=l(),aR=a("p"),Met=o("This class cannot be instantiated directly using "),qye=a("code"),Eet=o("__init__()"),Cet=o(" (throws an error)."),wet=l(),ra=a("div"),F(nR.$$.fragment),Aet=l(),jye=a("p"),Let=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),yet=l(),Lc=a("p"),xet=o(`Note:
Loading a model from its configuration file does `),Dye=a("strong"),$et=o("not"),ket=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gae=a("a"),Set=o("from_pretrained()"),Ret=o(" to load the model weights."),Pet=l(),F(BA.$$.fragment),Bet=l(),Ur=a("div"),F(sR.$$.fragment),Iet=l(),Gye=a("p"),Net=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qet=l(),Nn=a("p"),jet=o("The model class to instantiate is selected based on the "),Oye=a("code"),Det=o("model_type"),Get=o(` property of the config object (either
passed as an argument or loaded from `),Vye=a("code"),Oet=o("pretrained_model_name_or_path"),Vet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xye=a("code"),Xet=o("pretrained_model_name_or_path"),zet=o(":"),Qet=l(),de=a("ul"),IA=a("li"),zye=a("strong"),Wet=o("albert"),Uet=o(" \u2014 "),hae=a("a"),Het=o("TFAlbertForTokenClassification"),Jet=o(" (ALBERT model)"),Yet=l(),NA=a("li"),Qye=a("strong"),Ket=o("bert"),Zet=o(" \u2014 "),uae=a("a"),eot=o("TFBertForTokenClassification"),oot=o(" (BERT model)"),rot=l(),qA=a("li"),Wye=a("strong"),tot=o("camembert"),aot=o(" \u2014 "),pae=a("a"),not=o("TFCamembertForTokenClassification"),sot=o(" (CamemBERT model)"),lot=l(),jA=a("li"),Uye=a("strong"),iot=o("convbert"),dot=o(" \u2014 "),_ae=a("a"),mot=o("TFConvBertForTokenClassification"),cot=o(" (ConvBERT model)"),fot=l(),DA=a("li"),Hye=a("strong"),got=o("deberta"),hot=o(" \u2014 "),bae=a("a"),uot=o("TFDebertaForTokenClassification"),pot=o(" (DeBERTa model)"),_ot=l(),GA=a("li"),Jye=a("strong"),bot=o("deberta-v2"),vot=o(" \u2014 "),vae=a("a"),Fot=o("TFDebertaV2ForTokenClassification"),Tot=o(" (DeBERTa-v2 model)"),Mot=l(),OA=a("li"),Yye=a("strong"),Eot=o("distilbert"),Cot=o(" \u2014 "),Fae=a("a"),wot=o("TFDistilBertForTokenClassification"),Aot=o(" (DistilBERT model)"),Lot=l(),VA=a("li"),Kye=a("strong"),yot=o("electra"),xot=o(" \u2014 "),Tae=a("a"),$ot=o("TFElectraForTokenClassification"),kot=o(" (ELECTRA model)"),Sot=l(),XA=a("li"),Zye=a("strong"),Rot=o("flaubert"),Pot=o(" \u2014 "),Mae=a("a"),Bot=o("TFFlaubertForTokenClassification"),Iot=o(" (FlauBERT model)"),Not=l(),zA=a("li"),e8e=a("strong"),qot=o("funnel"),jot=o(" \u2014 "),Eae=a("a"),Dot=o("TFFunnelForTokenClassification"),Got=o(" (Funnel Transformer model)"),Oot=l(),QA=a("li"),o8e=a("strong"),Vot=o("layoutlm"),Xot=o(" \u2014 "),Cae=a("a"),zot=o("TFLayoutLMForTokenClassification"),Qot=o(" (LayoutLM model)"),Wot=l(),WA=a("li"),r8e=a("strong"),Uot=o("layoutlmv3"),Hot=o(" \u2014 "),wae=a("a"),Jot=o("TFLayoutLMv3ForTokenClassification"),Yot=o(" (LayoutLMv3 model)"),Kot=l(),UA=a("li"),t8e=a("strong"),Zot=o("longformer"),ert=o(" \u2014 "),Aae=a("a"),ort=o("TFLongformerForTokenClassification"),rrt=o(" (Longformer model)"),trt=l(),HA=a("li"),a8e=a("strong"),art=o("mobilebert"),nrt=o(" \u2014 "),Lae=a("a"),srt=o("TFMobileBertForTokenClassification"),lrt=o(" (MobileBERT model)"),irt=l(),JA=a("li"),n8e=a("strong"),drt=o("mpnet"),mrt=o(" \u2014 "),yae=a("a"),crt=o("TFMPNetForTokenClassification"),frt=o(" (MPNet model)"),grt=l(),YA=a("li"),s8e=a("strong"),hrt=o("rembert"),urt=o(" \u2014 "),xae=a("a"),prt=o("TFRemBertForTokenClassification"),_rt=o(" (RemBERT model)"),brt=l(),KA=a("li"),l8e=a("strong"),vrt=o("roberta"),Frt=o(" \u2014 "),$ae=a("a"),Trt=o("TFRobertaForTokenClassification"),Mrt=o(" (RoBERTa model)"),Ert=l(),ZA=a("li"),i8e=a("strong"),Crt=o("roformer"),wrt=o(" \u2014 "),kae=a("a"),Art=o("TFRoFormerForTokenClassification"),Lrt=o(" (RoFormer model)"),yrt=l(),e6=a("li"),d8e=a("strong"),xrt=o("xlm"),$rt=o(" \u2014 "),Sae=a("a"),krt=o("TFXLMForTokenClassification"),Srt=o(" (XLM model)"),Rrt=l(),o6=a("li"),m8e=a("strong"),Prt=o("xlm-roberta"),Brt=o(" \u2014 "),Rae=a("a"),Irt=o("TFXLMRobertaForTokenClassification"),Nrt=o(" (XLM-RoBERTa model)"),qrt=l(),r6=a("li"),c8e=a("strong"),jrt=o("xlnet"),Drt=o(" \u2014 "),Pae=a("a"),Grt=o("TFXLNetForTokenClassification"),Ort=o(" (XLNet model)"),Vrt=l(),F(t6.$$.fragment),Eoo=l(),yc=a("h2"),a6=a("a"),f8e=a("span"),F(lR.$$.fragment),Xrt=l(),g8e=a("span"),zrt=o("TFAutoModelForQuestionAnswering"),Coo=l(),vr=a("div"),F(iR.$$.fragment),Qrt=l(),xc=a("p"),Wrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Bae=a("a"),Urt=o("from_pretrained()"),Hrt=o(" class method or the "),Iae=a("a"),Jrt=o("from_config()"),Yrt=o(` class
method.`),Krt=l(),dR=a("p"),Zrt=o("This class cannot be instantiated directly using "),h8e=a("code"),ett=o("__init__()"),ott=o(" (throws an error)."),rtt=l(),ta=a("div"),F(mR.$$.fragment),ttt=l(),u8e=a("p"),att=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ntt=l(),$c=a("p"),stt=o(`Note:
Loading a model from its configuration file does `),p8e=a("strong"),ltt=o("not"),itt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nae=a("a"),dtt=o("from_pretrained()"),mtt=o(" to load the model weights."),ctt=l(),F(n6.$$.fragment),ftt=l(),Hr=a("div"),F(cR.$$.fragment),gtt=l(),_8e=a("p"),htt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),utt=l(),qn=a("p"),ptt=o("The model class to instantiate is selected based on the "),b8e=a("code"),_tt=o("model_type"),btt=o(` property of the config object (either
passed as an argument or loaded from `),v8e=a("code"),vtt=o("pretrained_model_name_or_path"),Ftt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=a("code"),Ttt=o("pretrained_model_name_or_path"),Mtt=o(":"),Ett=l(),me=a("ul"),s6=a("li"),T8e=a("strong"),Ctt=o("albert"),wtt=o(" \u2014 "),qae=a("a"),Att=o("TFAlbertForQuestionAnswering"),Ltt=o(" (ALBERT model)"),ytt=l(),l6=a("li"),M8e=a("strong"),xtt=o("bert"),$tt=o(" \u2014 "),jae=a("a"),ktt=o("TFBertForQuestionAnswering"),Stt=o(" (BERT model)"),Rtt=l(),i6=a("li"),E8e=a("strong"),Ptt=o("camembert"),Btt=o(" \u2014 "),Dae=a("a"),Itt=o("TFCamembertForQuestionAnswering"),Ntt=o(" (CamemBERT model)"),qtt=l(),d6=a("li"),C8e=a("strong"),jtt=o("convbert"),Dtt=o(" \u2014 "),Gae=a("a"),Gtt=o("TFConvBertForQuestionAnswering"),Ott=o(" (ConvBERT model)"),Vtt=l(),m6=a("li"),w8e=a("strong"),Xtt=o("deberta"),ztt=o(" \u2014 "),Oae=a("a"),Qtt=o("TFDebertaForQuestionAnswering"),Wtt=o(" (DeBERTa model)"),Utt=l(),c6=a("li"),A8e=a("strong"),Htt=o("deberta-v2"),Jtt=o(" \u2014 "),Vae=a("a"),Ytt=o("TFDebertaV2ForQuestionAnswering"),Ktt=o(" (DeBERTa-v2 model)"),Ztt=l(),f6=a("li"),L8e=a("strong"),eat=o("distilbert"),oat=o(" \u2014 "),Xae=a("a"),rat=o("TFDistilBertForQuestionAnswering"),tat=o(" (DistilBERT model)"),aat=l(),g6=a("li"),y8e=a("strong"),nat=o("electra"),sat=o(" \u2014 "),zae=a("a"),lat=o("TFElectraForQuestionAnswering"),iat=o(" (ELECTRA model)"),dat=l(),h6=a("li"),x8e=a("strong"),mat=o("flaubert"),cat=o(" \u2014 "),Qae=a("a"),fat=o("TFFlaubertForQuestionAnsweringSimple"),gat=o(" (FlauBERT model)"),hat=l(),u6=a("li"),$8e=a("strong"),uat=o("funnel"),pat=o(" \u2014 "),Wae=a("a"),_at=o("TFFunnelForQuestionAnswering"),bat=o(" (Funnel Transformer model)"),vat=l(),p6=a("li"),k8e=a("strong"),Fat=o("gptj"),Tat=o(" \u2014 "),Uae=a("a"),Mat=o("TFGPTJForQuestionAnswering"),Eat=o(" (GPT-J model)"),Cat=l(),_6=a("li"),S8e=a("strong"),wat=o("layoutlmv3"),Aat=o(" \u2014 "),Hae=a("a"),Lat=o("TFLayoutLMv3ForQuestionAnswering"),yat=o(" (LayoutLMv3 model)"),xat=l(),b6=a("li"),R8e=a("strong"),$at=o("longformer"),kat=o(" \u2014 "),Jae=a("a"),Sat=o("TFLongformerForQuestionAnswering"),Rat=o(" (Longformer model)"),Pat=l(),v6=a("li"),P8e=a("strong"),Bat=o("mobilebert"),Iat=o(" \u2014 "),Yae=a("a"),Nat=o("TFMobileBertForQuestionAnswering"),qat=o(" (MobileBERT model)"),jat=l(),F6=a("li"),B8e=a("strong"),Dat=o("mpnet"),Gat=o(" \u2014 "),Kae=a("a"),Oat=o("TFMPNetForQuestionAnswering"),Vat=o(" (MPNet model)"),Xat=l(),T6=a("li"),I8e=a("strong"),zat=o("rembert"),Qat=o(" \u2014 "),Zae=a("a"),Wat=o("TFRemBertForQuestionAnswering"),Uat=o(" (RemBERT model)"),Hat=l(),M6=a("li"),N8e=a("strong"),Jat=o("roberta"),Yat=o(" \u2014 "),ene=a("a"),Kat=o("TFRobertaForQuestionAnswering"),Zat=o(" (RoBERTa model)"),ent=l(),E6=a("li"),q8e=a("strong"),ont=o("roformer"),rnt=o(" \u2014 "),one=a("a"),tnt=o("TFRoFormerForQuestionAnswering"),ant=o(" (RoFormer model)"),nnt=l(),C6=a("li"),j8e=a("strong"),snt=o("xlm"),lnt=o(" \u2014 "),rne=a("a"),int=o("TFXLMForQuestionAnsweringSimple"),dnt=o(" (XLM model)"),mnt=l(),w6=a("li"),D8e=a("strong"),cnt=o("xlm-roberta"),fnt=o(" \u2014 "),tne=a("a"),gnt=o("TFXLMRobertaForQuestionAnswering"),hnt=o(" (XLM-RoBERTa model)"),unt=l(),A6=a("li"),G8e=a("strong"),pnt=o("xlnet"),_nt=o(" \u2014 "),ane=a("a"),bnt=o("TFXLNetForQuestionAnsweringSimple"),vnt=o(" (XLNet model)"),Fnt=l(),F(L6.$$.fragment),woo=l(),kc=a("h2"),y6=a("a"),O8e=a("span"),F(fR.$$.fragment),Tnt=l(),V8e=a("span"),Mnt=o("TFAutoModelForVision2Seq"),Aoo=l(),Fr=a("div"),F(gR.$$.fragment),Ent=l(),Sc=a("p"),Cnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nne=a("a"),wnt=o("from_pretrained()"),Ant=o(" class method or the "),sne=a("a"),Lnt=o("from_config()"),ynt=o(` class
method.`),xnt=l(),hR=a("p"),$nt=o("This class cannot be instantiated directly using "),X8e=a("code"),knt=o("__init__()"),Snt=o(" (throws an error)."),Rnt=l(),aa=a("div"),F(uR.$$.fragment),Pnt=l(),z8e=a("p"),Bnt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Int=l(),Rc=a("p"),Nnt=o(`Note:
Loading a model from its configuration file does `),Q8e=a("strong"),qnt=o("not"),jnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=a("a"),Dnt=o("from_pretrained()"),Gnt=o(" to load the model weights."),Ont=l(),F(x6.$$.fragment),Vnt=l(),Jr=a("div"),F(pR.$$.fragment),Xnt=l(),W8e=a("p"),znt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Qnt=l(),jn=a("p"),Wnt=o("The model class to instantiate is selected based on the "),U8e=a("code"),Unt=o("model_type"),Hnt=o(` property of the config object (either
passed as an argument or loaded from `),H8e=a("code"),Jnt=o("pretrained_model_name_or_path"),Ynt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J8e=a("code"),Knt=o("pretrained_model_name_or_path"),Znt=o(":"),est=l(),Y8e=a("ul"),$6=a("li"),K8e=a("strong"),ost=o("vision-encoder-decoder"),rst=o(" \u2014 "),ine=a("a"),tst=o("TFVisionEncoderDecoderModel"),ast=o(" (Vision Encoder decoder model)"),nst=l(),F(k6.$$.fragment),Loo=l(),Pc=a("h2"),S6=a("a"),Z8e=a("span"),F(_R.$$.fragment),sst=l(),e9e=a("span"),lst=o("TFAutoModelForSpeechSeq2Seq"),yoo=l(),Tr=a("div"),F(bR.$$.fragment),ist=l(),Bc=a("p"),dst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),dne=a("a"),mst=o("from_pretrained()"),cst=o(" class method or the "),mne=a("a"),fst=o("from_config()"),gst=o(` class
method.`),hst=l(),vR=a("p"),ust=o("This class cannot be instantiated directly using "),o9e=a("code"),pst=o("__init__()"),_st=o(" (throws an error)."),bst=l(),na=a("div"),F(FR.$$.fragment),vst=l(),r9e=a("p"),Fst=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Tst=l(),Ic=a("p"),Mst=o(`Note:
Loading a model from its configuration file does `),t9e=a("strong"),Est=o("not"),Cst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cne=a("a"),wst=o("from_pretrained()"),Ast=o(" to load the model weights."),Lst=l(),F(R6.$$.fragment),yst=l(),Yr=a("div"),F(TR.$$.fragment),xst=l(),a9e=a("p"),$st=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),kst=l(),Dn=a("p"),Sst=o("The model class to instantiate is selected based on the "),n9e=a("code"),Rst=o("model_type"),Pst=o(` property of the config object (either
passed as an argument or loaded from `),s9e=a("code"),Bst=o("pretrained_model_name_or_path"),Ist=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=a("code"),Nst=o("pretrained_model_name_or_path"),qst=o(":"),jst=l(),i9e=a("ul"),P6=a("li"),d9e=a("strong"),Dst=o("speech_to_text"),Gst=o(" \u2014 "),fne=a("a"),Ost=o("TFSpeech2TextForConditionalGeneration"),Vst=o(" (Speech2Text model)"),Xst=l(),F(B6.$$.fragment),xoo=l(),Nc=a("h2"),I6=a("a"),m9e=a("span"),F(MR.$$.fragment),zst=l(),c9e=a("span"),Qst=o("FlaxAutoModel"),$oo=l(),Mr=a("div"),F(ER.$$.fragment),Wst=l(),qc=a("p"),Ust=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gne=a("a"),Hst=o("from_pretrained()"),Jst=o(" class method or the "),hne=a("a"),Yst=o("from_config()"),Kst=o(` class
method.`),Zst=l(),CR=a("p"),elt=o("This class cannot be instantiated directly using "),f9e=a("code"),olt=o("__init__()"),rlt=o(" (throws an error)."),tlt=l(),sa=a("div"),F(wR.$$.fragment),alt=l(),g9e=a("p"),nlt=o("Instantiates one of the base model classes of the library from a configuration."),slt=l(),jc=a("p"),llt=o(`Note:
Loading a model from its configuration file does `),h9e=a("strong"),ilt=o("not"),dlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),une=a("a"),mlt=o("from_pretrained()"),clt=o(" to load the model weights."),flt=l(),F(N6.$$.fragment),glt=l(),Kr=a("div"),F(AR.$$.fragment),hlt=l(),u9e=a("p"),ult=o("Instantiate one of the base model classes of the library from a pretrained model."),plt=l(),Gn=a("p"),_lt=o("The model class to instantiate is selected based on the "),p9e=a("code"),blt=o("model_type"),vlt=o(` property of the config object (either
passed as an argument or loaded from `),_9e=a("code"),Flt=o("pretrained_model_name_or_path"),Tlt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b9e=a("code"),Mlt=o("pretrained_model_name_or_path"),Elt=o(":"),Clt=l(),te=a("ul"),q6=a("li"),v9e=a("strong"),wlt=o("albert"),Alt=o(" \u2014 "),pne=a("a"),Llt=o("FlaxAlbertModel"),ylt=o(" (ALBERT model)"),xlt=l(),j6=a("li"),F9e=a("strong"),$lt=o("bart"),klt=o(" \u2014 "),_ne=a("a"),Slt=o("FlaxBartModel"),Rlt=o(" (BART model)"),Plt=l(),D6=a("li"),T9e=a("strong"),Blt=o("beit"),Ilt=o(" \u2014 "),bne=a("a"),Nlt=o("FlaxBeitModel"),qlt=o(" (BEiT model)"),jlt=l(),G6=a("li"),M9e=a("strong"),Dlt=o("bert"),Glt=o(" \u2014 "),vne=a("a"),Olt=o("FlaxBertModel"),Vlt=o(" (BERT model)"),Xlt=l(),O6=a("li"),E9e=a("strong"),zlt=o("big_bird"),Qlt=o(" \u2014 "),Fne=a("a"),Wlt=o("FlaxBigBirdModel"),Ult=o(" (BigBird model)"),Hlt=l(),V6=a("li"),C9e=a("strong"),Jlt=o("blenderbot"),Ylt=o(" \u2014 "),Tne=a("a"),Klt=o("FlaxBlenderbotModel"),Zlt=o(" (Blenderbot model)"),eit=l(),X6=a("li"),w9e=a("strong"),oit=o("blenderbot-small"),rit=o(" \u2014 "),Mne=a("a"),tit=o("FlaxBlenderbotSmallModel"),ait=o(" (BlenderbotSmall model)"),nit=l(),z6=a("li"),A9e=a("strong"),sit=o("clip"),lit=o(" \u2014 "),Ene=a("a"),iit=o("FlaxCLIPModel"),dit=o(" (CLIP model)"),mit=l(),Q6=a("li"),L9e=a("strong"),cit=o("distilbert"),fit=o(" \u2014 "),Cne=a("a"),git=o("FlaxDistilBertModel"),hit=o(" (DistilBERT model)"),uit=l(),W6=a("li"),y9e=a("strong"),pit=o("electra"),_it=o(" \u2014 "),wne=a("a"),bit=o("FlaxElectraModel"),vit=o(" (ELECTRA model)"),Fit=l(),U6=a("li"),x9e=a("strong"),Tit=o("gpt2"),Mit=o(" \u2014 "),Ane=a("a"),Eit=o("FlaxGPT2Model"),Cit=o(" (OpenAI GPT-2 model)"),wit=l(),H6=a("li"),$9e=a("strong"),Ait=o("gpt_neo"),Lit=o(" \u2014 "),Lne=a("a"),yit=o("FlaxGPTNeoModel"),xit=o(" (GPT Neo model)"),$it=l(),J6=a("li"),k9e=a("strong"),kit=o("gptj"),Sit=o(" \u2014 "),yne=a("a"),Rit=o("FlaxGPTJModel"),Pit=o(" (GPT-J model)"),Bit=l(),Y6=a("li"),S9e=a("strong"),Iit=o("longt5"),Nit=o(" \u2014 "),xne=a("a"),qit=o("FlaxLongT5Model"),jit=o(" (LongT5 model)"),Dit=l(),K6=a("li"),R9e=a("strong"),Git=o("marian"),Oit=o(" \u2014 "),$ne=a("a"),Vit=o("FlaxMarianModel"),Xit=o(" (Marian model)"),zit=l(),Z6=a("li"),P9e=a("strong"),Qit=o("mbart"),Wit=o(" \u2014 "),kne=a("a"),Uit=o("FlaxMBartModel"),Hit=o(" (mBART model)"),Jit=l(),e7=a("li"),B9e=a("strong"),Yit=o("mt5"),Kit=o(" \u2014 "),Sne=a("a"),Zit=o("FlaxMT5Model"),edt=o(" (MT5 model)"),odt=l(),o7=a("li"),I9e=a("strong"),rdt=o("opt"),tdt=o(" \u2014 "),Rne=a("a"),adt=o("FlaxOPTModel"),ndt=o(" (OPT model)"),sdt=l(),r7=a("li"),N9e=a("strong"),ldt=o("pegasus"),idt=o(" \u2014 "),Pne=a("a"),ddt=o("FlaxPegasusModel"),mdt=o(" (Pegasus model)"),cdt=l(),t7=a("li"),q9e=a("strong"),fdt=o("roberta"),gdt=o(" \u2014 "),Bne=a("a"),hdt=o("FlaxRobertaModel"),udt=o(" (RoBERTa model)"),pdt=l(),a7=a("li"),j9e=a("strong"),_dt=o("roformer"),bdt=o(" \u2014 "),Ine=a("a"),vdt=o("FlaxRoFormerModel"),Fdt=o(" (RoFormer model)"),Tdt=l(),n7=a("li"),D9e=a("strong"),Mdt=o("t5"),Edt=o(" \u2014 "),Nne=a("a"),Cdt=o("FlaxT5Model"),wdt=o(" (T5 model)"),Adt=l(),s7=a("li"),G9e=a("strong"),Ldt=o("vision-text-dual-encoder"),ydt=o(" \u2014 "),qne=a("a"),xdt=o("FlaxVisionTextDualEncoderModel"),$dt=o(" (VisionTextDualEncoder model)"),kdt=l(),l7=a("li"),O9e=a("strong"),Sdt=o("vit"),Rdt=o(" \u2014 "),jne=a("a"),Pdt=o("FlaxViTModel"),Bdt=o(" (ViT model)"),Idt=l(),i7=a("li"),V9e=a("strong"),Ndt=o("wav2vec2"),qdt=o(" \u2014 "),Dne=a("a"),jdt=o("FlaxWav2Vec2Model"),Ddt=o(" (Wav2Vec2 model)"),Gdt=l(),d7=a("li"),X9e=a("strong"),Odt=o("xglm"),Vdt=o(" \u2014 "),Gne=a("a"),Xdt=o("FlaxXGLMModel"),zdt=o(" (XGLM model)"),Qdt=l(),m7=a("li"),z9e=a("strong"),Wdt=o("xlm-roberta"),Udt=o(" \u2014 "),One=a("a"),Hdt=o("FlaxXLMRobertaModel"),Jdt=o(" (XLM-RoBERTa model)"),Ydt=l(),F(c7.$$.fragment),koo=l(),Dc=a("h2"),f7=a("a"),Q9e=a("span"),F(LR.$$.fragment),Kdt=l(),W9e=a("span"),Zdt=o("FlaxAutoModelForCausalLM"),Soo=l(),Er=a("div"),F(yR.$$.fragment),emt=l(),Gc=a("p"),omt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Vne=a("a"),rmt=o("from_pretrained()"),tmt=o(" class method or the "),Xne=a("a"),amt=o("from_config()"),nmt=o(` class
method.`),smt=l(),xR=a("p"),lmt=o("This class cannot be instantiated directly using "),U9e=a("code"),imt=o("__init__()"),dmt=o(" (throws an error)."),mmt=l(),la=a("div"),F($R.$$.fragment),cmt=l(),H9e=a("p"),fmt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gmt=l(),Oc=a("p"),hmt=o(`Note:
Loading a model from its configuration file does `),J9e=a("strong"),umt=o("not"),pmt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zne=a("a"),_mt=o("from_pretrained()"),bmt=o(" to load the model weights."),vmt=l(),F(g7.$$.fragment),Fmt=l(),Zr=a("div"),F(kR.$$.fragment),Tmt=l(),Y9e=a("p"),Mmt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Emt=l(),On=a("p"),Cmt=o("The model class to instantiate is selected based on the "),K9e=a("code"),wmt=o("model_type"),Amt=o(` property of the config object (either
passed as an argument or loaded from `),Z9e=a("code"),Lmt=o("pretrained_model_name_or_path"),ymt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),exe=a("code"),xmt=o("pretrained_model_name_or_path"),$mt=o(":"),kmt=l(),xe=a("ul"),h7=a("li"),oxe=a("strong"),Smt=o("bart"),Rmt=o(" \u2014 "),Qne=a("a"),Pmt=o("FlaxBartForCausalLM"),Bmt=o(" (BART model)"),Imt=l(),u7=a("li"),rxe=a("strong"),Nmt=o("bert"),qmt=o(" \u2014 "),Wne=a("a"),jmt=o("FlaxBertForCausalLM"),Dmt=o(" (BERT model)"),Gmt=l(),p7=a("li"),txe=a("strong"),Omt=o("big_bird"),Vmt=o(" \u2014 "),Une=a("a"),Xmt=o("FlaxBigBirdForCausalLM"),zmt=o(" (BigBird model)"),Qmt=l(),_7=a("li"),axe=a("strong"),Wmt=o("electra"),Umt=o(" \u2014 "),Hne=a("a"),Hmt=o("FlaxElectraForCausalLM"),Jmt=o(" (ELECTRA model)"),Ymt=l(),b7=a("li"),nxe=a("strong"),Kmt=o("gpt2"),Zmt=o(" \u2014 "),Jne=a("a"),ect=o("FlaxGPT2LMHeadModel"),oct=o(" (OpenAI GPT-2 model)"),rct=l(),v7=a("li"),sxe=a("strong"),tct=o("gpt_neo"),act=o(" \u2014 "),Yne=a("a"),nct=o("FlaxGPTNeoForCausalLM"),sct=o(" (GPT Neo model)"),lct=l(),F7=a("li"),lxe=a("strong"),ict=o("gptj"),dct=o(" \u2014 "),Kne=a("a"),mct=o("FlaxGPTJForCausalLM"),cct=o(" (GPT-J model)"),fct=l(),T7=a("li"),ixe=a("strong"),gct=o("opt"),hct=o(" \u2014 "),Zne=a("a"),uct=o("FlaxOPTForCausalLM"),pct=o(" (OPT model)"),_ct=l(),M7=a("li"),dxe=a("strong"),bct=o("roberta"),vct=o(" \u2014 "),ese=a("a"),Fct=o("FlaxRobertaForCausalLM"),Tct=o(" (RoBERTa model)"),Mct=l(),E7=a("li"),mxe=a("strong"),Ect=o("xglm"),Cct=o(" \u2014 "),ose=a("a"),wct=o("FlaxXGLMForCausalLM"),Act=o(" (XGLM model)"),Lct=l(),F(C7.$$.fragment),Roo=l(),Vc=a("h2"),w7=a("a"),cxe=a("span"),F(SR.$$.fragment),yct=l(),fxe=a("span"),xct=o("FlaxAutoModelForPreTraining"),Poo=l(),Cr=a("div"),F(RR.$$.fragment),$ct=l(),Xc=a("p"),kct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rse=a("a"),Sct=o("from_pretrained()"),Rct=o(" class method or the "),tse=a("a"),Pct=o("from_config()"),Bct=o(` class
method.`),Ict=l(),PR=a("p"),Nct=o("This class cannot be instantiated directly using "),gxe=a("code"),qct=o("__init__()"),jct=o(" (throws an error)."),Dct=l(),ia=a("div"),F(BR.$$.fragment),Gct=l(),hxe=a("p"),Oct=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Vct=l(),zc=a("p"),Xct=o(`Note:
Loading a model from its configuration file does `),uxe=a("strong"),zct=o("not"),Qct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=a("a"),Wct=o("from_pretrained()"),Uct=o(" to load the model weights."),Hct=l(),F(A7.$$.fragment),Jct=l(),et=a("div"),F(IR.$$.fragment),Yct=l(),pxe=a("p"),Kct=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Zct=l(),Vn=a("p"),eft=o("The model class to instantiate is selected based on the "),_xe=a("code"),oft=o("model_type"),rft=o(` property of the config object (either
passed as an argument or loaded from `),bxe=a("code"),tft=o("pretrained_model_name_or_path"),aft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vxe=a("code"),nft=o("pretrained_model_name_or_path"),sft=o(":"),lft=l(),Ee=a("ul"),L7=a("li"),Fxe=a("strong"),ift=o("albert"),dft=o(" \u2014 "),nse=a("a"),mft=o("FlaxAlbertForPreTraining"),cft=o(" (ALBERT model)"),fft=l(),y7=a("li"),Txe=a("strong"),gft=o("bart"),hft=o(" \u2014 "),sse=a("a"),uft=o("FlaxBartForConditionalGeneration"),pft=o(" (BART model)"),_ft=l(),x7=a("li"),Mxe=a("strong"),bft=o("bert"),vft=o(" \u2014 "),lse=a("a"),Fft=o("FlaxBertForPreTraining"),Tft=o(" (BERT model)"),Mft=l(),$7=a("li"),Exe=a("strong"),Eft=o("big_bird"),Cft=o(" \u2014 "),ise=a("a"),wft=o("FlaxBigBirdForPreTraining"),Aft=o(" (BigBird model)"),Lft=l(),k7=a("li"),Cxe=a("strong"),yft=o("electra"),xft=o(" \u2014 "),dse=a("a"),$ft=o("FlaxElectraForPreTraining"),kft=o(" (ELECTRA model)"),Sft=l(),S7=a("li"),wxe=a("strong"),Rft=o("longt5"),Pft=o(" \u2014 "),mse=a("a"),Bft=o("FlaxLongT5ForConditionalGeneration"),Ift=o(" (LongT5 model)"),Nft=l(),R7=a("li"),Axe=a("strong"),qft=o("mbart"),jft=o(" \u2014 "),cse=a("a"),Dft=o("FlaxMBartForConditionalGeneration"),Gft=o(" (mBART model)"),Oft=l(),P7=a("li"),Lxe=a("strong"),Vft=o("mt5"),Xft=o(" \u2014 "),fse=a("a"),zft=o("FlaxMT5ForConditionalGeneration"),Qft=o(" (MT5 model)"),Wft=l(),B7=a("li"),yxe=a("strong"),Uft=o("roberta"),Hft=o(" \u2014 "),gse=a("a"),Jft=o("FlaxRobertaForMaskedLM"),Yft=o(" (RoBERTa model)"),Kft=l(),I7=a("li"),xxe=a("strong"),Zft=o("roformer"),egt=o(" \u2014 "),hse=a("a"),ogt=o("FlaxRoFormerForMaskedLM"),rgt=o(" (RoFormer model)"),tgt=l(),N7=a("li"),$xe=a("strong"),agt=o("t5"),ngt=o(" \u2014 "),use=a("a"),sgt=o("FlaxT5ForConditionalGeneration"),lgt=o(" (T5 model)"),igt=l(),q7=a("li"),kxe=a("strong"),dgt=o("wav2vec2"),mgt=o(" \u2014 "),pse=a("a"),cgt=o("FlaxWav2Vec2ForPreTraining"),fgt=o(" (Wav2Vec2 model)"),ggt=l(),j7=a("li"),Sxe=a("strong"),hgt=o("xlm-roberta"),ugt=o(" \u2014 "),_se=a("a"),pgt=o("FlaxXLMRobertaForMaskedLM"),_gt=o(" (XLM-RoBERTa model)"),bgt=l(),F(D7.$$.fragment),Boo=l(),Qc=a("h2"),G7=a("a"),Rxe=a("span"),F(NR.$$.fragment),vgt=l(),Pxe=a("span"),Fgt=o("FlaxAutoModelForMaskedLM"),Ioo=l(),wr=a("div"),F(qR.$$.fragment),Tgt=l(),Wc=a("p"),Mgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),bse=a("a"),Egt=o("from_pretrained()"),Cgt=o(" class method or the "),vse=a("a"),wgt=o("from_config()"),Agt=o(` class
method.`),Lgt=l(),jR=a("p"),ygt=o("This class cannot be instantiated directly using "),Bxe=a("code"),xgt=o("__init__()"),$gt=o(" (throws an error)."),kgt=l(),da=a("div"),F(DR.$$.fragment),Sgt=l(),Ixe=a("p"),Rgt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Pgt=l(),Uc=a("p"),Bgt=o(`Note:
Loading a model from its configuration file does `),Nxe=a("strong"),Igt=o("not"),Ngt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fse=a("a"),qgt=o("from_pretrained()"),jgt=o(" to load the model weights."),Dgt=l(),F(O7.$$.fragment),Ggt=l(),ot=a("div"),F(GR.$$.fragment),Ogt=l(),qxe=a("p"),Vgt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Xgt=l(),Xn=a("p"),zgt=o("The model class to instantiate is selected based on the "),jxe=a("code"),Qgt=o("model_type"),Wgt=o(` property of the config object (either
passed as an argument or loaded from `),Dxe=a("code"),Ugt=o("pretrained_model_name_or_path"),Hgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=a("code"),Jgt=o("pretrained_model_name_or_path"),Ygt=o(":"),Kgt=l(),$e=a("ul"),V7=a("li"),Oxe=a("strong"),Zgt=o("albert"),eht=o(" \u2014 "),Tse=a("a"),oht=o("FlaxAlbertForMaskedLM"),rht=o(" (ALBERT model)"),tht=l(),X7=a("li"),Vxe=a("strong"),aht=o("bart"),nht=o(" \u2014 "),Mse=a("a"),sht=o("FlaxBartForConditionalGeneration"),lht=o(" (BART model)"),iht=l(),z7=a("li"),Xxe=a("strong"),dht=o("bert"),mht=o(" \u2014 "),Ese=a("a"),cht=o("FlaxBertForMaskedLM"),fht=o(" (BERT model)"),ght=l(),Q7=a("li"),zxe=a("strong"),hht=o("big_bird"),uht=o(" \u2014 "),Cse=a("a"),pht=o("FlaxBigBirdForMaskedLM"),_ht=o(" (BigBird model)"),bht=l(),W7=a("li"),Qxe=a("strong"),vht=o("distilbert"),Fht=o(" \u2014 "),wse=a("a"),Tht=o("FlaxDistilBertForMaskedLM"),Mht=o(" (DistilBERT model)"),Eht=l(),U7=a("li"),Wxe=a("strong"),Cht=o("electra"),wht=o(" \u2014 "),Ase=a("a"),Aht=o("FlaxElectraForMaskedLM"),Lht=o(" (ELECTRA model)"),yht=l(),H7=a("li"),Uxe=a("strong"),xht=o("mbart"),$ht=o(" \u2014 "),Lse=a("a"),kht=o("FlaxMBartForConditionalGeneration"),Sht=o(" (mBART model)"),Rht=l(),J7=a("li"),Hxe=a("strong"),Pht=o("roberta"),Bht=o(" \u2014 "),yse=a("a"),Iht=o("FlaxRobertaForMaskedLM"),Nht=o(" (RoBERTa model)"),qht=l(),Y7=a("li"),Jxe=a("strong"),jht=o("roformer"),Dht=o(" \u2014 "),xse=a("a"),Ght=o("FlaxRoFormerForMaskedLM"),Oht=o(" (RoFormer model)"),Vht=l(),K7=a("li"),Yxe=a("strong"),Xht=o("xlm-roberta"),zht=o(" \u2014 "),$se=a("a"),Qht=o("FlaxXLMRobertaForMaskedLM"),Wht=o(" (XLM-RoBERTa model)"),Uht=l(),F(Z7.$$.fragment),Noo=l(),Hc=a("h2"),eL=a("a"),Kxe=a("span"),F(OR.$$.fragment),Hht=l(),Zxe=a("span"),Jht=o("FlaxAutoModelForSeq2SeqLM"),qoo=l(),Ar=a("div"),F(VR.$$.fragment),Yht=l(),Jc=a("p"),Kht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kse=a("a"),Zht=o("from_pretrained()"),eut=o(" class method or the "),Sse=a("a"),out=o("from_config()"),rut=o(` class
method.`),tut=l(),XR=a("p"),aut=o("This class cannot be instantiated directly using "),e$e=a("code"),nut=o("__init__()"),sut=o(" (throws an error)."),lut=l(),ma=a("div"),F(zR.$$.fragment),iut=l(),o$e=a("p"),dut=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),mut=l(),Yc=a("p"),cut=o(`Note:
Loading a model from its configuration file does `),r$e=a("strong"),fut=o("not"),gut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rse=a("a"),hut=o("from_pretrained()"),uut=o(" to load the model weights."),put=l(),F(oL.$$.fragment),_ut=l(),rt=a("div"),F(QR.$$.fragment),but=l(),t$e=a("p"),vut=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Fut=l(),zn=a("p"),Tut=o("The model class to instantiate is selected based on the "),a$e=a("code"),Mut=o("model_type"),Eut=o(` property of the config object (either
passed as an argument or loaded from `),n$e=a("code"),Cut=o("pretrained_model_name_or_path"),wut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s$e=a("code"),Aut=o("pretrained_model_name_or_path"),Lut=o(":"),yut=l(),ke=a("ul"),rL=a("li"),l$e=a("strong"),xut=o("bart"),$ut=o(" \u2014 "),Pse=a("a"),kut=o("FlaxBartForConditionalGeneration"),Sut=o(" (BART model)"),Rut=l(),tL=a("li"),i$e=a("strong"),Put=o("blenderbot"),But=o(" \u2014 "),Bse=a("a"),Iut=o("FlaxBlenderbotForConditionalGeneration"),Nut=o(" (Blenderbot model)"),qut=l(),aL=a("li"),d$e=a("strong"),jut=o("blenderbot-small"),Dut=o(" \u2014 "),Ise=a("a"),Gut=o("FlaxBlenderbotSmallForConditionalGeneration"),Out=o(" (BlenderbotSmall model)"),Vut=l(),nL=a("li"),m$e=a("strong"),Xut=o("encoder-decoder"),zut=o(" \u2014 "),Nse=a("a"),Qut=o("FlaxEncoderDecoderModel"),Wut=o(" (Encoder decoder model)"),Uut=l(),sL=a("li"),c$e=a("strong"),Hut=o("longt5"),Jut=o(" \u2014 "),qse=a("a"),Yut=o("FlaxLongT5ForConditionalGeneration"),Kut=o(" (LongT5 model)"),Zut=l(),lL=a("li"),f$e=a("strong"),ept=o("marian"),opt=o(" \u2014 "),jse=a("a"),rpt=o("FlaxMarianMTModel"),tpt=o(" (Marian model)"),apt=l(),iL=a("li"),g$e=a("strong"),npt=o("mbart"),spt=o(" \u2014 "),Dse=a("a"),lpt=o("FlaxMBartForConditionalGeneration"),ipt=o(" (mBART model)"),dpt=l(),dL=a("li"),h$e=a("strong"),mpt=o("mt5"),cpt=o(" \u2014 "),Gse=a("a"),fpt=o("FlaxMT5ForConditionalGeneration"),gpt=o(" (MT5 model)"),hpt=l(),mL=a("li"),u$e=a("strong"),upt=o("pegasus"),ppt=o(" \u2014 "),Ose=a("a"),_pt=o("FlaxPegasusForConditionalGeneration"),bpt=o(" (Pegasus model)"),vpt=l(),cL=a("li"),p$e=a("strong"),Fpt=o("t5"),Tpt=o(" \u2014 "),Vse=a("a"),Mpt=o("FlaxT5ForConditionalGeneration"),Ept=o(" (T5 model)"),Cpt=l(),F(fL.$$.fragment),joo=l(),Kc=a("h2"),gL=a("a"),_$e=a("span"),F(WR.$$.fragment),wpt=l(),b$e=a("span"),Apt=o("FlaxAutoModelForSequenceClassification"),Doo=l(),Lr=a("div"),F(UR.$$.fragment),Lpt=l(),Zc=a("p"),ypt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Xse=a("a"),xpt=o("from_pretrained()"),$pt=o(" class method or the "),zse=a("a"),kpt=o("from_config()"),Spt=o(` class
method.`),Rpt=l(),HR=a("p"),Ppt=o("This class cannot be instantiated directly using "),v$e=a("code"),Bpt=o("__init__()"),Ipt=o(" (throws an error)."),Npt=l(),ca=a("div"),F(JR.$$.fragment),qpt=l(),F$e=a("p"),jpt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Dpt=l(),ef=a("p"),Gpt=o(`Note:
Loading a model from its configuration file does `),T$e=a("strong"),Opt=o("not"),Vpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qse=a("a"),Xpt=o("from_pretrained()"),zpt=o(" to load the model weights."),Qpt=l(),F(hL.$$.fragment),Wpt=l(),tt=a("div"),F(YR.$$.fragment),Upt=l(),M$e=a("p"),Hpt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Jpt=l(),Qn=a("p"),Ypt=o("The model class to instantiate is selected based on the "),E$e=a("code"),Kpt=o("model_type"),Zpt=o(` property of the config object (either
passed as an argument or loaded from `),C$e=a("code"),e_t=o("pretrained_model_name_or_path"),o_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w$e=a("code"),r_t=o("pretrained_model_name_or_path"),t_t=o(":"),a_t=l(),Se=a("ul"),uL=a("li"),A$e=a("strong"),n_t=o("albert"),s_t=o(" \u2014 "),Wse=a("a"),l_t=o("FlaxAlbertForSequenceClassification"),i_t=o(" (ALBERT model)"),d_t=l(),pL=a("li"),L$e=a("strong"),m_t=o("bart"),c_t=o(" \u2014 "),Use=a("a"),f_t=o("FlaxBartForSequenceClassification"),g_t=o(" (BART model)"),h_t=l(),_L=a("li"),y$e=a("strong"),u_t=o("bert"),p_t=o(" \u2014 "),Hse=a("a"),__t=o("FlaxBertForSequenceClassification"),b_t=o(" (BERT model)"),v_t=l(),bL=a("li"),x$e=a("strong"),F_t=o("big_bird"),T_t=o(" \u2014 "),Jse=a("a"),M_t=o("FlaxBigBirdForSequenceClassification"),E_t=o(" (BigBird model)"),C_t=l(),vL=a("li"),$$e=a("strong"),w_t=o("distilbert"),A_t=o(" \u2014 "),Yse=a("a"),L_t=o("FlaxDistilBertForSequenceClassification"),y_t=o(" (DistilBERT model)"),x_t=l(),FL=a("li"),k$e=a("strong"),$_t=o("electra"),k_t=o(" \u2014 "),Kse=a("a"),S_t=o("FlaxElectraForSequenceClassification"),R_t=o(" (ELECTRA model)"),P_t=l(),TL=a("li"),S$e=a("strong"),B_t=o("mbart"),I_t=o(" \u2014 "),Zse=a("a"),N_t=o("FlaxMBartForSequenceClassification"),q_t=o(" (mBART model)"),j_t=l(),ML=a("li"),R$e=a("strong"),D_t=o("roberta"),G_t=o(" \u2014 "),ele=a("a"),O_t=o("FlaxRobertaForSequenceClassification"),V_t=o(" (RoBERTa model)"),X_t=l(),EL=a("li"),P$e=a("strong"),z_t=o("roformer"),Q_t=o(" \u2014 "),ole=a("a"),W_t=o("FlaxRoFormerForSequenceClassification"),U_t=o(" (RoFormer model)"),H_t=l(),CL=a("li"),B$e=a("strong"),J_t=o("xlm-roberta"),Y_t=o(" \u2014 "),rle=a("a"),K_t=o("FlaxXLMRobertaForSequenceClassification"),Z_t=o(" (XLM-RoBERTa model)"),e2t=l(),F(wL.$$.fragment),Goo=l(),of=a("h2"),AL=a("a"),I$e=a("span"),F(KR.$$.fragment),o2t=l(),N$e=a("span"),r2t=o("FlaxAutoModelForQuestionAnswering"),Ooo=l(),yr=a("div"),F(ZR.$$.fragment),t2t=l(),rf=a("p"),a2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tle=a("a"),n2t=o("from_pretrained()"),s2t=o(" class method or the "),ale=a("a"),l2t=o("from_config()"),i2t=o(` class
method.`),d2t=l(),eP=a("p"),m2t=o("This class cannot be instantiated directly using "),q$e=a("code"),c2t=o("__init__()"),f2t=o(" (throws an error)."),g2t=l(),fa=a("div"),F(oP.$$.fragment),h2t=l(),j$e=a("p"),u2t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),p2t=l(),tf=a("p"),_2t=o(`Note:
Loading a model from its configuration file does `),D$e=a("strong"),b2t=o("not"),v2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nle=a("a"),F2t=o("from_pretrained()"),T2t=o(" to load the model weights."),M2t=l(),F(LL.$$.fragment),E2t=l(),at=a("div"),F(rP.$$.fragment),C2t=l(),G$e=a("p"),w2t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),A2t=l(),Wn=a("p"),L2t=o("The model class to instantiate is selected based on the "),O$e=a("code"),y2t=o("model_type"),x2t=o(` property of the config object (either
passed as an argument or loaded from `),V$e=a("code"),$2t=o("pretrained_model_name_or_path"),k2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X$e=a("code"),S2t=o("pretrained_model_name_or_path"),R2t=o(":"),P2t=l(),Re=a("ul"),yL=a("li"),z$e=a("strong"),B2t=o("albert"),I2t=o(" \u2014 "),sle=a("a"),N2t=o("FlaxAlbertForQuestionAnswering"),q2t=o(" (ALBERT model)"),j2t=l(),xL=a("li"),Q$e=a("strong"),D2t=o("bart"),G2t=o(" \u2014 "),lle=a("a"),O2t=o("FlaxBartForQuestionAnswering"),V2t=o(" (BART model)"),X2t=l(),$L=a("li"),W$e=a("strong"),z2t=o("bert"),Q2t=o(" \u2014 "),ile=a("a"),W2t=o("FlaxBertForQuestionAnswering"),U2t=o(" (BERT model)"),H2t=l(),kL=a("li"),U$e=a("strong"),J2t=o("big_bird"),Y2t=o(" \u2014 "),dle=a("a"),K2t=o("FlaxBigBirdForQuestionAnswering"),Z2t=o(" (BigBird model)"),e1t=l(),SL=a("li"),H$e=a("strong"),o1t=o("distilbert"),r1t=o(" \u2014 "),mle=a("a"),t1t=o("FlaxDistilBertForQuestionAnswering"),a1t=o(" (DistilBERT model)"),n1t=l(),RL=a("li"),J$e=a("strong"),s1t=o("electra"),l1t=o(" \u2014 "),cle=a("a"),i1t=o("FlaxElectraForQuestionAnswering"),d1t=o(" (ELECTRA model)"),m1t=l(),PL=a("li"),Y$e=a("strong"),c1t=o("mbart"),f1t=o(" \u2014 "),fle=a("a"),g1t=o("FlaxMBartForQuestionAnswering"),h1t=o(" (mBART model)"),u1t=l(),BL=a("li"),K$e=a("strong"),p1t=o("roberta"),_1t=o(" \u2014 "),gle=a("a"),b1t=o("FlaxRobertaForQuestionAnswering"),v1t=o(" (RoBERTa model)"),F1t=l(),IL=a("li"),Z$e=a("strong"),T1t=o("roformer"),M1t=o(" \u2014 "),hle=a("a"),E1t=o("FlaxRoFormerForQuestionAnswering"),C1t=o(" (RoFormer model)"),w1t=l(),NL=a("li"),eke=a("strong"),A1t=o("xlm-roberta"),L1t=o(" \u2014 "),ule=a("a"),y1t=o("FlaxXLMRobertaForQuestionAnswering"),x1t=o(" (XLM-RoBERTa model)"),$1t=l(),F(qL.$$.fragment),Voo=l(),af=a("h2"),jL=a("a"),oke=a("span"),F(tP.$$.fragment),k1t=l(),rke=a("span"),S1t=o("FlaxAutoModelForTokenClassification"),Xoo=l(),xr=a("div"),F(aP.$$.fragment),R1t=l(),nf=a("p"),P1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ple=a("a"),B1t=o("from_pretrained()"),I1t=o(" class method or the "),_le=a("a"),N1t=o("from_config()"),q1t=o(` class
method.`),j1t=l(),nP=a("p"),D1t=o("This class cannot be instantiated directly using "),tke=a("code"),G1t=o("__init__()"),O1t=o(" (throws an error)."),V1t=l(),ga=a("div"),F(sP.$$.fragment),X1t=l(),ake=a("p"),z1t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Q1t=l(),sf=a("p"),W1t=o(`Note:
Loading a model from its configuration file does `),nke=a("strong"),U1t=o("not"),H1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ble=a("a"),J1t=o("from_pretrained()"),Y1t=o(" to load the model weights."),K1t=l(),F(DL.$$.fragment),Z1t=l(),nt=a("div"),F(lP.$$.fragment),ebt=l(),ske=a("p"),obt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),rbt=l(),Un=a("p"),tbt=o("The model class to instantiate is selected based on the "),lke=a("code"),abt=o("model_type"),nbt=o(` property of the config object (either
passed as an argument or loaded from `),ike=a("code"),sbt=o("pretrained_model_name_or_path"),lbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dke=a("code"),ibt=o("pretrained_model_name_or_path"),dbt=o(":"),mbt=l(),Xe=a("ul"),GL=a("li"),mke=a("strong"),cbt=o("albert"),fbt=o(" \u2014 "),vle=a("a"),gbt=o("FlaxAlbertForTokenClassification"),hbt=o(" (ALBERT model)"),ubt=l(),OL=a("li"),cke=a("strong"),pbt=o("bert"),_bt=o(" \u2014 "),Fle=a("a"),bbt=o("FlaxBertForTokenClassification"),vbt=o(" (BERT model)"),Fbt=l(),VL=a("li"),fke=a("strong"),Tbt=o("big_bird"),Mbt=o(" \u2014 "),Tle=a("a"),Ebt=o("FlaxBigBirdForTokenClassification"),Cbt=o(" (BigBird model)"),wbt=l(),XL=a("li"),gke=a("strong"),Abt=o("distilbert"),Lbt=o(" \u2014 "),Mle=a("a"),ybt=o("FlaxDistilBertForTokenClassification"),xbt=o(" (DistilBERT model)"),$bt=l(),zL=a("li"),hke=a("strong"),kbt=o("electra"),Sbt=o(" \u2014 "),Ele=a("a"),Rbt=o("FlaxElectraForTokenClassification"),Pbt=o(" (ELECTRA model)"),Bbt=l(),QL=a("li"),uke=a("strong"),Ibt=o("roberta"),Nbt=o(" \u2014 "),Cle=a("a"),qbt=o("FlaxRobertaForTokenClassification"),jbt=o(" (RoBERTa model)"),Dbt=l(),WL=a("li"),pke=a("strong"),Gbt=o("roformer"),Obt=o(" \u2014 "),wle=a("a"),Vbt=o("FlaxRoFormerForTokenClassification"),Xbt=o(" (RoFormer model)"),zbt=l(),UL=a("li"),_ke=a("strong"),Qbt=o("xlm-roberta"),Wbt=o(" \u2014 "),Ale=a("a"),Ubt=o("FlaxXLMRobertaForTokenClassification"),Hbt=o(" (XLM-RoBERTa model)"),Jbt=l(),F(HL.$$.fragment),zoo=l(),lf=a("h2"),JL=a("a"),bke=a("span"),F(iP.$$.fragment),Ybt=l(),vke=a("span"),Kbt=o("FlaxAutoModelForMultipleChoice"),Qoo=l(),$r=a("div"),F(dP.$$.fragment),Zbt=l(),df=a("p"),evt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lle=a("a"),ovt=o("from_pretrained()"),rvt=o(" class method or the "),yle=a("a"),tvt=o("from_config()"),avt=o(` class
method.`),nvt=l(),mP=a("p"),svt=o("This class cannot be instantiated directly using "),Fke=a("code"),lvt=o("__init__()"),ivt=o(" (throws an error)."),dvt=l(),ha=a("div"),F(cP.$$.fragment),mvt=l(),Tke=a("p"),cvt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fvt=l(),mf=a("p"),gvt=o(`Note:
Loading a model from its configuration file does `),Mke=a("strong"),hvt=o("not"),uvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xle=a("a"),pvt=o("from_pretrained()"),_vt=o(" to load the model weights."),bvt=l(),F(YL.$$.fragment),vvt=l(),st=a("div"),F(fP.$$.fragment),Fvt=l(),Eke=a("p"),Tvt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Mvt=l(),Hn=a("p"),Evt=o("The model class to instantiate is selected based on the "),Cke=a("code"),Cvt=o("model_type"),wvt=o(` property of the config object (either
passed as an argument or loaded from `),wke=a("code"),Avt=o("pretrained_model_name_or_path"),Lvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ake=a("code"),yvt=o("pretrained_model_name_or_path"),xvt=o(":"),$vt=l(),ze=a("ul"),KL=a("li"),Lke=a("strong"),kvt=o("albert"),Svt=o(" \u2014 "),$le=a("a"),Rvt=o("FlaxAlbertForMultipleChoice"),Pvt=o(" (ALBERT model)"),Bvt=l(),ZL=a("li"),yke=a("strong"),Ivt=o("bert"),Nvt=o(" \u2014 "),kle=a("a"),qvt=o("FlaxBertForMultipleChoice"),jvt=o(" (BERT model)"),Dvt=l(),ey=a("li"),xke=a("strong"),Gvt=o("big_bird"),Ovt=o(" \u2014 "),Sle=a("a"),Vvt=o("FlaxBigBirdForMultipleChoice"),Xvt=o(" (BigBird model)"),zvt=l(),oy=a("li"),$ke=a("strong"),Qvt=o("distilbert"),Wvt=o(" \u2014 "),Rle=a("a"),Uvt=o("FlaxDistilBertForMultipleChoice"),Hvt=o(" (DistilBERT model)"),Jvt=l(),ry=a("li"),kke=a("strong"),Yvt=o("electra"),Kvt=o(" \u2014 "),Ple=a("a"),Zvt=o("FlaxElectraForMultipleChoice"),eFt=o(" (ELECTRA model)"),oFt=l(),ty=a("li"),Ske=a("strong"),rFt=o("roberta"),tFt=o(" \u2014 "),Ble=a("a"),aFt=o("FlaxRobertaForMultipleChoice"),nFt=o(" (RoBERTa model)"),sFt=l(),ay=a("li"),Rke=a("strong"),lFt=o("roformer"),iFt=o(" \u2014 "),Ile=a("a"),dFt=o("FlaxRoFormerForMultipleChoice"),mFt=o(" (RoFormer model)"),cFt=l(),ny=a("li"),Pke=a("strong"),fFt=o("xlm-roberta"),gFt=o(" \u2014 "),Nle=a("a"),hFt=o("FlaxXLMRobertaForMultipleChoice"),uFt=o(" (XLM-RoBERTa model)"),pFt=l(),F(sy.$$.fragment),Woo=l(),cf=a("h2"),ly=a("a"),Bke=a("span"),F(gP.$$.fragment),_Ft=l(),Ike=a("span"),bFt=o("FlaxAutoModelForNextSentencePrediction"),Uoo=l(),kr=a("div"),F(hP.$$.fragment),vFt=l(),ff=a("p"),FFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),qle=a("a"),TFt=o("from_pretrained()"),MFt=o(" class method or the "),jle=a("a"),EFt=o("from_config()"),CFt=o(` class
method.`),wFt=l(),uP=a("p"),AFt=o("This class cannot be instantiated directly using "),Nke=a("code"),LFt=o("__init__()"),yFt=o(" (throws an error)."),xFt=l(),ua=a("div"),F(pP.$$.fragment),$Ft=l(),qke=a("p"),kFt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),SFt=l(),gf=a("p"),RFt=o(`Note:
Loading a model from its configuration file does `),jke=a("strong"),PFt=o("not"),BFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dle=a("a"),IFt=o("from_pretrained()"),NFt=o(" to load the model weights."),qFt=l(),F(iy.$$.fragment),jFt=l(),lt=a("div"),F(_P.$$.fragment),DFt=l(),Dke=a("p"),GFt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),OFt=l(),Jn=a("p"),VFt=o("The model class to instantiate is selected based on the "),Gke=a("code"),XFt=o("model_type"),zFt=o(` property of the config object (either
passed as an argument or loaded from `),Oke=a("code"),QFt=o("pretrained_model_name_or_path"),WFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vke=a("code"),UFt=o("pretrained_model_name_or_path"),HFt=o(":"),JFt=l(),Xke=a("ul"),dy=a("li"),zke=a("strong"),YFt=o("bert"),KFt=o(" \u2014 "),Gle=a("a"),ZFt=o("FlaxBertForNextSentencePrediction"),eTt=o(" (BERT model)"),oTt=l(),F(my.$$.fragment),Hoo=l(),hf=a("h2"),cy=a("a"),Qke=a("span"),F(bP.$$.fragment),rTt=l(),Wke=a("span"),tTt=o("FlaxAutoModelForImageClassification"),Joo=l(),Sr=a("div"),F(vP.$$.fragment),aTt=l(),uf=a("p"),nTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ole=a("a"),sTt=o("from_pretrained()"),lTt=o(" class method or the "),Vle=a("a"),iTt=o("from_config()"),dTt=o(` class
method.`),mTt=l(),FP=a("p"),cTt=o("This class cannot be instantiated directly using "),Uke=a("code"),fTt=o("__init__()"),gTt=o(" (throws an error)."),hTt=l(),pa=a("div"),F(TP.$$.fragment),uTt=l(),Hke=a("p"),pTt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_Tt=l(),pf=a("p"),bTt=o(`Note:
Loading a model from its configuration file does `),Jke=a("strong"),vTt=o("not"),FTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xle=a("a"),TTt=o("from_pretrained()"),MTt=o(" to load the model weights."),ETt=l(),F(fy.$$.fragment),CTt=l(),it=a("div"),F(MP.$$.fragment),wTt=l(),Yke=a("p"),ATt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),LTt=l(),Yn=a("p"),yTt=o("The model class to instantiate is selected based on the "),Kke=a("code"),xTt=o("model_type"),$Tt=o(` property of the config object (either
passed as an argument or loaded from `),Zke=a("code"),kTt=o("pretrained_model_name_or_path"),STt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eSe=a("code"),RTt=o("pretrained_model_name_or_path"),PTt=o(":"),BTt=l(),EP=a("ul"),gy=a("li"),oSe=a("strong"),ITt=o("beit"),NTt=o(" \u2014 "),zle=a("a"),qTt=o("FlaxBeitForImageClassification"),jTt=o(" (BEiT model)"),DTt=l(),hy=a("li"),rSe=a("strong"),GTt=o("vit"),OTt=o(" \u2014 "),Qle=a("a"),VTt=o("FlaxViTForImageClassification"),XTt=o(" (ViT model)"),zTt=l(),F(uy.$$.fragment),Yoo=l(),_f=a("h2"),py=a("a"),tSe=a("span"),F(CP.$$.fragment),QTt=l(),aSe=a("span"),WTt=o("FlaxAutoModelForVision2Seq"),Koo=l(),Rr=a("div"),F(wP.$$.fragment),UTt=l(),bf=a("p"),HTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wle=a("a"),JTt=o("from_pretrained()"),YTt=o(" class method or the "),Ule=a("a"),KTt=o("from_config()"),ZTt=o(` class
method.`),eMt=l(),AP=a("p"),oMt=o("This class cannot be instantiated directly using "),nSe=a("code"),rMt=o("__init__()"),tMt=o(" (throws an error)."),aMt=l(),_a=a("div"),F(LP.$$.fragment),nMt=l(),sSe=a("p"),sMt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),lMt=l(),vf=a("p"),iMt=o(`Note:
Loading a model from its configuration file does `),lSe=a("strong"),dMt=o("not"),mMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hle=a("a"),cMt=o("from_pretrained()"),fMt=o(" to load the model weights."),gMt=l(),F(_y.$$.fragment),hMt=l(),dt=a("div"),F(yP.$$.fragment),uMt=l(),iSe=a("p"),pMt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),_Mt=l(),Kn=a("p"),bMt=o("The model class to instantiate is selected based on the "),dSe=a("code"),vMt=o("model_type"),FMt=o(` property of the config object (either
passed as an argument or loaded from `),mSe=a("code"),TMt=o("pretrained_model_name_or_path"),MMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cSe=a("code"),EMt=o("pretrained_model_name_or_path"),CMt=o(":"),wMt=l(),fSe=a("ul"),by=a("li"),gSe=a("strong"),AMt=o("vision-encoder-decoder"),LMt=o(" \u2014 "),Jle=a("a"),yMt=o("FlaxVisionEncoderDecoderModel"),xMt=o(" (Vision Encoder decoder model)"),$Mt=l(),F(vy.$$.fragment),this.h()},l(c){const _=P2a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var xP=s(u);f=n(xP,"A",{id:!0,class:!0,href:!0});var hSe=s(f);p=n(hSe,"SPAN",{});var uSe=s(p);T(d.$$.fragment,uSe),uSe.forEach(t),hSe.forEach(t),h=i(xP),yo=n(xP,"SPAN",{});var pSe=s(yo);td=r(pSe,"Auto Classes"),pSe.forEach(t),xP.forEach(t),Ef=i(c),pt=n(c,"P",{});var $P=s(pt);ad=r($P,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),nd=n($P,"CODE",{});var _Se=s(nd);J9=r(_Se,"from_pretrained()"),_Se.forEach(t),Cf=r($P,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),$P.forEach(t),Ve=i(c),He=n(c,"P",{});var Zn=s(He);sd=r(Zn,"Instantiating one of "),es=n(Zn,"A",{href:!0});var bSe=s(es);Y9=r(bSe,"AutoConfig"),bSe.forEach(t),os=r(Zn,", "),rs=n(Zn,"A",{href:!0});var vSe=s(rs);K9=r(vSe,"AutoModel"),vSe.forEach(t),ld=r(Zn,`, and
`),ts=n(Zn,"A",{href:!0});var FSe=s(ts);Z9=r(FSe,"AutoTokenizer"),FSe.forEach(t),id=r(Zn," will directly create a class of the relevant architecture. For instance"),Zn.forEach(t),wf=i(c),T(Qa.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var kP=s(Ae);eI=r(kP,"will create a model that is an instance of "),dd=n(kP,"A",{href:!0});var TSe=s(dd);oI=r(TSe,"BertModel"),TSe.forEach(t),rI=r(kP,"."),kP.forEach(t),xo=i(c),Wa=n(c,"P",{});var SP=s(Wa);tI=r(SP,"There is one class of "),Af=n(SP,"CODE",{});var MSe=s(Af);aI=r(MSe,"AutoModel"),MSe.forEach(t),pao=r(SP," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),SP.forEach(t),DZe=i(c),md=n(c,"H2",{class:!0});var RP=s(md);Lf=n(RP,"A",{id:!0,class:!0,href:!0});var ESe=s(Lf);eme=n(ESe,"SPAN",{});var CSe=s(eme);T(ex.$$.fragment,CSe),CSe.forEach(t),ESe.forEach(t),_ao=i(RP),ome=n(RP,"SPAN",{});var wSe=s(ome);bao=r(wSe,"Extending the Auto Classes"),wSe.forEach(t),RP.forEach(t),GZe=i(c),as=n(c,"P",{});var Ff=s(as);vao=r(Ff,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),rme=n(Ff,"CODE",{});var ASe=s(rme);Fao=r(ASe,"NewModel"),ASe.forEach(t),Tao=r(Ff,", make sure you have a "),tme=n(Ff,"CODE",{});var LSe=s(tme);Mao=r(LSe,"NewModelConfig"),LSe.forEach(t),Eao=r(Ff,` then you can add those to the auto
classes like this:`),Ff.forEach(t),OZe=i(c),T(ox.$$.fragment,c),VZe=i(c),nI=n(c,"P",{});var ySe=s(nI);Cao=r(ySe,"You will then be able to use the auto classes like you would usually do!"),ySe.forEach(t),XZe=i(c),T(yf.$$.fragment,c),zZe=i(c),cd=n(c,"H2",{class:!0});var PP=s(cd);xf=n(PP,"A",{id:!0,class:!0,href:!0});var xSe=s(xf);ame=n(xSe,"SPAN",{});var $Se=s(ame);T(rx.$$.fragment,$Se),$Se.forEach(t),xSe.forEach(t),wao=i(PP),nme=n(PP,"SPAN",{});var kSe=s(nme);Aao=r(kSe,"AutoConfig"),kSe.forEach(t),PP.forEach(t),QZe=i(c),$o=n(c,"DIV",{class:!0});var ht=s($o);T(tx.$$.fragment,ht),Lao=i(ht),ax=n(ht,"P",{});var BP=s(ax);yao=r(BP,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),sI=n(BP,"A",{href:!0});var SSe=s(sI);xao=r(SSe,"from_pretrained()"),SSe.forEach(t),$ao=r(BP," class method."),BP.forEach(t),kao=i(ht),nx=n(ht,"P",{});var IP=s(nx);Sao=r(IP,"This class cannot be instantiated directly using "),sme=n(IP,"CODE",{});var RSe=s(sme);Rao=r(RSe,"__init__()"),RSe.forEach(t),Pao=r(IP," (throws an error)."),IP.forEach(t),Bao=i(ht),Pr=n(ht,"DIV",{class:!0});var ut=s(Pr);T(sx.$$.fragment,ut),Iao=i(ut),lme=n(ut,"P",{});var PSe=s(lme);Nao=r(PSe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),PSe.forEach(t),qao=i(ut),fd=n(ut,"P",{});var Tf=s(fd);jao=r(Tf,"The configuration class to instantiate is selected based on the "),ime=n(Tf,"CODE",{});var BSe=s(ime);Dao=r(BSe,"model_type"),BSe.forEach(t),Gao=r(Tf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),dme=n(Tf,"CODE",{});var ISe=s(dme);Oao=r(ISe,"pretrained_model_name_or_path"),ISe.forEach(t),Vao=r(Tf,":"),Tf.forEach(t),Xao=i(ut),A=n(ut,"UL",{});var L=s(A);$f=n(L,"LI",{});var Fy=s($f);mme=n(Fy,"STRONG",{});var NSe=s(mme);zao=r(NSe,"albert"),NSe.forEach(t),Qao=r(Fy," \u2014 "),lI=n(Fy,"A",{href:!0});var qSe=s(lI);Wao=r(qSe,"AlbertConfig"),qSe.forEach(t),Uao=r(Fy," (ALBERT model)"),Fy.forEach(t),Hao=i(L),kf=n(L,"LI",{});var Ty=s(kf);cme=n(Ty,"STRONG",{});var jSe=s(cme);Jao=r(jSe,"bart"),jSe.forEach(t),Yao=r(Ty," \u2014 "),iI=n(Ty,"A",{href:!0});var DSe=s(iI);Kao=r(DSe,"BartConfig"),DSe.forEach(t),Zao=r(Ty," (BART model)"),Ty.forEach(t),eno=i(L),Sf=n(L,"LI",{});var My=s(Sf);fme=n(My,"STRONG",{});var GSe=s(fme);ono=r(GSe,"beit"),GSe.forEach(t),rno=r(My," \u2014 "),dI=n(My,"A",{href:!0});var OSe=s(dI);tno=r(OSe,"BeitConfig"),OSe.forEach(t),ano=r(My," (BEiT model)"),My.forEach(t),nno=i(L),Rf=n(L,"LI",{});var Ey=s(Rf);gme=n(Ey,"STRONG",{});var VSe=s(gme);sno=r(VSe,"bert"),VSe.forEach(t),lno=r(Ey," \u2014 "),mI=n(Ey,"A",{href:!0});var XSe=s(mI);ino=r(XSe,"BertConfig"),XSe.forEach(t),dno=r(Ey," (BERT model)"),Ey.forEach(t),mno=i(L),Pf=n(L,"LI",{});var Cy=s(Pf);hme=n(Cy,"STRONG",{});var zSe=s(hme);cno=r(zSe,"bert-generation"),zSe.forEach(t),fno=r(Cy," \u2014 "),cI=n(Cy,"A",{href:!0});var QSe=s(cI);gno=r(QSe,"BertGenerationConfig"),QSe.forEach(t),hno=r(Cy," (Bert Generation model)"),Cy.forEach(t),uno=i(L),Bf=n(L,"LI",{});var wy=s(Bf);ume=n(wy,"STRONG",{});var WSe=s(ume);pno=r(WSe,"big_bird"),WSe.forEach(t),_no=r(wy," \u2014 "),fI=n(wy,"A",{href:!0});var USe=s(fI);bno=r(USe,"BigBirdConfig"),USe.forEach(t),vno=r(wy," (BigBird model)"),wy.forEach(t),Fno=i(L),If=n(L,"LI",{});var Ay=s(If);pme=n(Ay,"STRONG",{});var HSe=s(pme);Tno=r(HSe,"bigbird_pegasus"),HSe.forEach(t),Mno=r(Ay," \u2014 "),gI=n(Ay,"A",{href:!0});var JSe=s(gI);Eno=r(JSe,"BigBirdPegasusConfig"),JSe.forEach(t),Cno=r(Ay," (BigBird-Pegasus model)"),Ay.forEach(t),wno=i(L),Nf=n(L,"LI",{});var Ly=s(Nf);_me=n(Ly,"STRONG",{});var YSe=s(_me);Ano=r(YSe,"blenderbot"),YSe.forEach(t),Lno=r(Ly," \u2014 "),hI=n(Ly,"A",{href:!0});var KSe=s(hI);yno=r(KSe,"BlenderbotConfig"),KSe.forEach(t),xno=r(Ly," (Blenderbot model)"),Ly.forEach(t),$no=i(L),qf=n(L,"LI",{});var yy=s(qf);bme=n(yy,"STRONG",{});var ZSe=s(bme);kno=r(ZSe,"blenderbot-small"),ZSe.forEach(t),Sno=r(yy," \u2014 "),uI=n(yy,"A",{href:!0});var eRe=s(uI);Rno=r(eRe,"BlenderbotSmallConfig"),eRe.forEach(t),Pno=r(yy," (BlenderbotSmall model)"),yy.forEach(t),Bno=i(L),jf=n(L,"LI",{});var xy=s(jf);vme=n(xy,"STRONG",{});var oRe=s(vme);Ino=r(oRe,"bloom"),oRe.forEach(t),Nno=r(xy," \u2014 "),pI=n(xy,"A",{href:!0});var rRe=s(pI);qno=r(rRe,"BloomConfig"),rRe.forEach(t),jno=r(xy," (BLOOM model)"),xy.forEach(t),Dno=i(L),Df=n(L,"LI",{});var $y=s(Df);Fme=n($y,"STRONG",{});var tRe=s(Fme);Gno=r(tRe,"camembert"),tRe.forEach(t),Ono=r($y," \u2014 "),_I=n($y,"A",{href:!0});var aRe=s(_I);Vno=r(aRe,"CamembertConfig"),aRe.forEach(t),Xno=r($y," (CamemBERT model)"),$y.forEach(t),zno=i(L),Gf=n(L,"LI",{});var ky=s(Gf);Tme=n(ky,"STRONG",{});var nRe=s(Tme);Qno=r(nRe,"canine"),nRe.forEach(t),Wno=r(ky," \u2014 "),bI=n(ky,"A",{href:!0});var sRe=s(bI);Uno=r(sRe,"CanineConfig"),sRe.forEach(t),Hno=r(ky," (CANINE model)"),ky.forEach(t),Jno=i(L),Of=n(L,"LI",{});var Sy=s(Of);Mme=n(Sy,"STRONG",{});var lRe=s(Mme);Yno=r(lRe,"clip"),lRe.forEach(t),Kno=r(Sy," \u2014 "),vI=n(Sy,"A",{href:!0});var iRe=s(vI);Zno=r(iRe,"CLIPConfig"),iRe.forEach(t),eso=r(Sy," (CLIP model)"),Sy.forEach(t),oso=i(L),Vf=n(L,"LI",{});var Ry=s(Vf);Eme=n(Ry,"STRONG",{});var dRe=s(Eme);rso=r(dRe,"codegen"),dRe.forEach(t),tso=r(Ry," \u2014 "),FI=n(Ry,"A",{href:!0});var mRe=s(FI);aso=r(mRe,"CodeGenConfig"),mRe.forEach(t),nso=r(Ry," (CodeGen model)"),Ry.forEach(t),sso=i(L),Xf=n(L,"LI",{});var Py=s(Xf);Cme=n(Py,"STRONG",{});var cRe=s(Cme);lso=r(cRe,"conditional_detr"),cRe.forEach(t),iso=r(Py," \u2014 "),TI=n(Py,"A",{href:!0});var fRe=s(TI);dso=r(fRe,"ConditionalDetrConfig"),fRe.forEach(t),mso=r(Py," (Conditional DETR model)"),Py.forEach(t),cso=i(L),zf=n(L,"LI",{});var By=s(zf);wme=n(By,"STRONG",{});var gRe=s(wme);fso=r(gRe,"convbert"),gRe.forEach(t),gso=r(By," \u2014 "),MI=n(By,"A",{href:!0});var hRe=s(MI);hso=r(hRe,"ConvBertConfig"),hRe.forEach(t),uso=r(By," (ConvBERT model)"),By.forEach(t),pso=i(L),Qf=n(L,"LI",{});var Iy=s(Qf);Ame=n(Iy,"STRONG",{});var uRe=s(Ame);_so=r(uRe,"convnext"),uRe.forEach(t),bso=r(Iy," \u2014 "),EI=n(Iy,"A",{href:!0});var pRe=s(EI);vso=r(pRe,"ConvNextConfig"),pRe.forEach(t),Fso=r(Iy," (ConvNeXT model)"),Iy.forEach(t),Tso=i(L),Wf=n(L,"LI",{});var Ny=s(Wf);Lme=n(Ny,"STRONG",{});var _Re=s(Lme);Mso=r(_Re,"ctrl"),_Re.forEach(t),Eso=r(Ny," \u2014 "),CI=n(Ny,"A",{href:!0});var bRe=s(CI);Cso=r(bRe,"CTRLConfig"),bRe.forEach(t),wso=r(Ny," (CTRL model)"),Ny.forEach(t),Aso=i(L),Uf=n(L,"LI",{});var qy=s(Uf);yme=n(qy,"STRONG",{});var vRe=s(yme);Lso=r(vRe,"cvt"),vRe.forEach(t),yso=r(qy," \u2014 "),wI=n(qy,"A",{href:!0});var FRe=s(wI);xso=r(FRe,"CvtConfig"),FRe.forEach(t),$so=r(qy," (CvT model)"),qy.forEach(t),kso=i(L),Hf=n(L,"LI",{});var jy=s(Hf);xme=n(jy,"STRONG",{});var TRe=s(xme);Sso=r(TRe,"data2vec-audio"),TRe.forEach(t),Rso=r(jy," \u2014 "),AI=n(jy,"A",{href:!0});var MRe=s(AI);Pso=r(MRe,"Data2VecAudioConfig"),MRe.forEach(t),Bso=r(jy," (Data2VecAudio model)"),jy.forEach(t),Iso=i(L),Jf=n(L,"LI",{});var Dy=s(Jf);$me=n(Dy,"STRONG",{});var ERe=s($me);Nso=r(ERe,"data2vec-text"),ERe.forEach(t),qso=r(Dy," \u2014 "),LI=n(Dy,"A",{href:!0});var CRe=s(LI);jso=r(CRe,"Data2VecTextConfig"),CRe.forEach(t),Dso=r(Dy," (Data2VecText model)"),Dy.forEach(t),Gso=i(L),Yf=n(L,"LI",{});var Gy=s(Yf);kme=n(Gy,"STRONG",{});var wRe=s(kme);Oso=r(wRe,"data2vec-vision"),wRe.forEach(t),Vso=r(Gy," \u2014 "),yI=n(Gy,"A",{href:!0});var ARe=s(yI);Xso=r(ARe,"Data2VecVisionConfig"),ARe.forEach(t),zso=r(Gy," (Data2VecVision model)"),Gy.forEach(t),Qso=i(L),Kf=n(L,"LI",{});var Oy=s(Kf);Sme=n(Oy,"STRONG",{});var LRe=s(Sme);Wso=r(LRe,"deberta"),LRe.forEach(t),Uso=r(Oy," \u2014 "),xI=n(Oy,"A",{href:!0});var yRe=s(xI);Hso=r(yRe,"DebertaConfig"),yRe.forEach(t),Jso=r(Oy," (DeBERTa model)"),Oy.forEach(t),Yso=i(L),Zf=n(L,"LI",{});var Vy=s(Zf);Rme=n(Vy,"STRONG",{});var xRe=s(Rme);Kso=r(xRe,"deberta-v2"),xRe.forEach(t),Zso=r(Vy," \u2014 "),$I=n(Vy,"A",{href:!0});var $Re=s($I);elo=r($Re,"DebertaV2Config"),$Re.forEach(t),olo=r(Vy," (DeBERTa-v2 model)"),Vy.forEach(t),rlo=i(L),eg=n(L,"LI",{});var Xy=s(eg);Pme=n(Xy,"STRONG",{});var kRe=s(Pme);tlo=r(kRe,"decision_transformer"),kRe.forEach(t),alo=r(Xy," \u2014 "),kI=n(Xy,"A",{href:!0});var SRe=s(kI);nlo=r(SRe,"DecisionTransformerConfig"),SRe.forEach(t),slo=r(Xy," (Decision Transformer model)"),Xy.forEach(t),llo=i(L),og=n(L,"LI",{});var zy=s(og);Bme=n(zy,"STRONG",{});var RRe=s(Bme);ilo=r(RRe,"deformable_detr"),RRe.forEach(t),dlo=r(zy," \u2014 "),SI=n(zy,"A",{href:!0});var PRe=s(SI);mlo=r(PRe,"DeformableDetrConfig"),PRe.forEach(t),clo=r(zy," (Deformable DETR model)"),zy.forEach(t),flo=i(L),rg=n(L,"LI",{});var BRe=s(rg);Ime=n(BRe,"STRONG",{});var SMt=s(Ime);glo=r(SMt,"deit"),SMt.forEach(t),hlo=r(BRe," \u2014 "),RI=n(BRe,"A",{href:!0});var RMt=s(RI);ulo=r(RMt,"DeiTConfig"),RMt.forEach(t),plo=r(BRe," (DeiT model)"),BRe.forEach(t),_lo=i(L),tg=n(L,"LI",{});var IRe=s(tg);Nme=n(IRe,"STRONG",{});var PMt=s(Nme);blo=r(PMt,"detr"),PMt.forEach(t),vlo=r(IRe," \u2014 "),PI=n(IRe,"A",{href:!0});var BMt=s(PI);Flo=r(BMt,"DetrConfig"),BMt.forEach(t),Tlo=r(IRe," (DETR model)"),IRe.forEach(t),Mlo=i(L),ag=n(L,"LI",{});var NRe=s(ag);qme=n(NRe,"STRONG",{});var IMt=s(qme);Elo=r(IMt,"distilbert"),IMt.forEach(t),Clo=r(NRe," \u2014 "),BI=n(NRe,"A",{href:!0});var NMt=s(BI);wlo=r(NMt,"DistilBertConfig"),NMt.forEach(t),Alo=r(NRe," (DistilBERT model)"),NRe.forEach(t),Llo=i(L),ng=n(L,"LI",{});var qRe=s(ng);jme=n(qRe,"STRONG",{});var qMt=s(jme);ylo=r(qMt,"donut-swin"),qMt.forEach(t),xlo=r(qRe," \u2014 "),II=n(qRe,"A",{href:!0});var jMt=s(II);$lo=r(jMt,"DonutSwinConfig"),jMt.forEach(t),klo=r(qRe," (DonutSwin model)"),qRe.forEach(t),Slo=i(L),sg=n(L,"LI",{});var jRe=s(sg);Dme=n(jRe,"STRONG",{});var DMt=s(Dme);Rlo=r(DMt,"dpr"),DMt.forEach(t),Plo=r(jRe," \u2014 "),NI=n(jRe,"A",{href:!0});var GMt=s(NI);Blo=r(GMt,"DPRConfig"),GMt.forEach(t),Ilo=r(jRe," (DPR model)"),jRe.forEach(t),Nlo=i(L),lg=n(L,"LI",{});var DRe=s(lg);Gme=n(DRe,"STRONG",{});var OMt=s(Gme);qlo=r(OMt,"dpt"),OMt.forEach(t),jlo=r(DRe," \u2014 "),qI=n(DRe,"A",{href:!0});var VMt=s(qI);Dlo=r(VMt,"DPTConfig"),VMt.forEach(t),Glo=r(DRe," (DPT model)"),DRe.forEach(t),Olo=i(L),ig=n(L,"LI",{});var GRe=s(ig);Ome=n(GRe,"STRONG",{});var XMt=s(Ome);Vlo=r(XMt,"electra"),XMt.forEach(t),Xlo=r(GRe," \u2014 "),jI=n(GRe,"A",{href:!0});var zMt=s(jI);zlo=r(zMt,"ElectraConfig"),zMt.forEach(t),Qlo=r(GRe," (ELECTRA model)"),GRe.forEach(t),Wlo=i(L),dg=n(L,"LI",{});var ORe=s(dg);Vme=n(ORe,"STRONG",{});var QMt=s(Vme);Ulo=r(QMt,"encoder-decoder"),QMt.forEach(t),Hlo=r(ORe," \u2014 "),DI=n(ORe,"A",{href:!0});var WMt=s(DI);Jlo=r(WMt,"EncoderDecoderConfig"),WMt.forEach(t),Ylo=r(ORe," (Encoder decoder model)"),ORe.forEach(t),Klo=i(L),mg=n(L,"LI",{});var VRe=s(mg);Xme=n(VRe,"STRONG",{});var UMt=s(Xme);Zlo=r(UMt,"ernie"),UMt.forEach(t),eio=r(VRe," \u2014 "),GI=n(VRe,"A",{href:!0});var HMt=s(GI);oio=r(HMt,"ErnieConfig"),HMt.forEach(t),rio=r(VRe," (ERNIE model)"),VRe.forEach(t),tio=i(L),cg=n(L,"LI",{});var XRe=s(cg);zme=n(XRe,"STRONG",{});var JMt=s(zme);aio=r(JMt,"esm"),JMt.forEach(t),nio=r(XRe," \u2014 "),OI=n(XRe,"A",{href:!0});var YMt=s(OI);sio=r(YMt,"EsmConfig"),YMt.forEach(t),lio=r(XRe," (ESM model)"),XRe.forEach(t),iio=i(L),fg=n(L,"LI",{});var zRe=s(fg);Qme=n(zRe,"STRONG",{});var KMt=s(Qme);dio=r(KMt,"flaubert"),KMt.forEach(t),mio=r(zRe," \u2014 "),VI=n(zRe,"A",{href:!0});var ZMt=s(VI);cio=r(ZMt,"FlaubertConfig"),ZMt.forEach(t),fio=r(zRe," (FlauBERT model)"),zRe.forEach(t),gio=i(L),gg=n(L,"LI",{});var QRe=s(gg);Wme=n(QRe,"STRONG",{});var eEt=s(Wme);hio=r(eEt,"flava"),eEt.forEach(t),uio=r(QRe," \u2014 "),XI=n(QRe,"A",{href:!0});var oEt=s(XI);pio=r(oEt,"FlavaConfig"),oEt.forEach(t),_io=r(QRe," (FLAVA model)"),QRe.forEach(t),bio=i(L),hg=n(L,"LI",{});var WRe=s(hg);Ume=n(WRe,"STRONG",{});var rEt=s(Ume);vio=r(rEt,"fnet"),rEt.forEach(t),Fio=r(WRe," \u2014 "),zI=n(WRe,"A",{href:!0});var tEt=s(zI);Tio=r(tEt,"FNetConfig"),tEt.forEach(t),Mio=r(WRe," (FNet model)"),WRe.forEach(t),Eio=i(L),ug=n(L,"LI",{});var URe=s(ug);Hme=n(URe,"STRONG",{});var aEt=s(Hme);Cio=r(aEt,"fsmt"),aEt.forEach(t),wio=r(URe," \u2014 "),QI=n(URe,"A",{href:!0});var nEt=s(QI);Aio=r(nEt,"FSMTConfig"),nEt.forEach(t),Lio=r(URe," (FairSeq Machine-Translation model)"),URe.forEach(t),yio=i(L),pg=n(L,"LI",{});var HRe=s(pg);Jme=n(HRe,"STRONG",{});var sEt=s(Jme);xio=r(sEt,"funnel"),sEt.forEach(t),$io=r(HRe," \u2014 "),WI=n(HRe,"A",{href:!0});var lEt=s(WI);kio=r(lEt,"FunnelConfig"),lEt.forEach(t),Sio=r(HRe," (Funnel Transformer model)"),HRe.forEach(t),Rio=i(L),_g=n(L,"LI",{});var JRe=s(_g);Yme=n(JRe,"STRONG",{});var iEt=s(Yme);Pio=r(iEt,"glpn"),iEt.forEach(t),Bio=r(JRe," \u2014 "),UI=n(JRe,"A",{href:!0});var dEt=s(UI);Iio=r(dEt,"GLPNConfig"),dEt.forEach(t),Nio=r(JRe," (GLPN model)"),JRe.forEach(t),qio=i(L),bg=n(L,"LI",{});var YRe=s(bg);Kme=n(YRe,"STRONG",{});var mEt=s(Kme);jio=r(mEt,"gpt2"),mEt.forEach(t),Dio=r(YRe," \u2014 "),HI=n(YRe,"A",{href:!0});var cEt=s(HI);Gio=r(cEt,"GPT2Config"),cEt.forEach(t),Oio=r(YRe," (OpenAI GPT-2 model)"),YRe.forEach(t),Vio=i(L),vg=n(L,"LI",{});var KRe=s(vg);Zme=n(KRe,"STRONG",{});var fEt=s(Zme);Xio=r(fEt,"gpt_neo"),fEt.forEach(t),zio=r(KRe," \u2014 "),JI=n(KRe,"A",{href:!0});var gEt=s(JI);Qio=r(gEt,"GPTNeoConfig"),gEt.forEach(t),Wio=r(KRe," (GPT Neo model)"),KRe.forEach(t),Uio=i(L),Fg=n(L,"LI",{});var ZRe=s(Fg);ece=n(ZRe,"STRONG",{});var hEt=s(ece);Hio=r(hEt,"gpt_neox"),hEt.forEach(t),Jio=r(ZRe," \u2014 "),YI=n(ZRe,"A",{href:!0});var uEt=s(YI);Yio=r(uEt,"GPTNeoXConfig"),uEt.forEach(t),Kio=r(ZRe," (GPT NeoX model)"),ZRe.forEach(t),Zio=i(L),Tg=n(L,"LI",{});var ePe=s(Tg);oce=n(ePe,"STRONG",{});var pEt=s(oce);edo=r(pEt,"gpt_neox_japanese"),pEt.forEach(t),odo=r(ePe," \u2014 "),KI=n(ePe,"A",{href:!0});var _Et=s(KI);rdo=r(_Et,"GPTNeoXJapaneseConfig"),_Et.forEach(t),tdo=r(ePe," (GPT NeoX Japanese model)"),ePe.forEach(t),ado=i(L),Mg=n(L,"LI",{});var oPe=s(Mg);rce=n(oPe,"STRONG",{});var bEt=s(rce);ndo=r(bEt,"gptj"),bEt.forEach(t),sdo=r(oPe," \u2014 "),ZI=n(oPe,"A",{href:!0});var vEt=s(ZI);ldo=r(vEt,"GPTJConfig"),vEt.forEach(t),ido=r(oPe," (GPT-J model)"),oPe.forEach(t),ddo=i(L),Eg=n(L,"LI",{});var rPe=s(Eg);tce=n(rPe,"STRONG",{});var FEt=s(tce);mdo=r(FEt,"groupvit"),FEt.forEach(t),cdo=r(rPe," \u2014 "),eN=n(rPe,"A",{href:!0});var TEt=s(eN);fdo=r(TEt,"GroupViTConfig"),TEt.forEach(t),gdo=r(rPe," (GroupViT model)"),rPe.forEach(t),hdo=i(L),Cg=n(L,"LI",{});var tPe=s(Cg);ace=n(tPe,"STRONG",{});var MEt=s(ace);udo=r(MEt,"hubert"),MEt.forEach(t),pdo=r(tPe," \u2014 "),oN=n(tPe,"A",{href:!0});var EEt=s(oN);_do=r(EEt,"HubertConfig"),EEt.forEach(t),bdo=r(tPe," (Hubert model)"),tPe.forEach(t),vdo=i(L),wg=n(L,"LI",{});var aPe=s(wg);nce=n(aPe,"STRONG",{});var CEt=s(nce);Fdo=r(CEt,"ibert"),CEt.forEach(t),Tdo=r(aPe," \u2014 "),rN=n(aPe,"A",{href:!0});var wEt=s(rN);Mdo=r(wEt,"IBertConfig"),wEt.forEach(t),Edo=r(aPe," (I-BERT model)"),aPe.forEach(t),Cdo=i(L),Ag=n(L,"LI",{});var nPe=s(Ag);sce=n(nPe,"STRONG",{});var AEt=s(sce);wdo=r(AEt,"imagegpt"),AEt.forEach(t),Ado=r(nPe," \u2014 "),tN=n(nPe,"A",{href:!0});var LEt=s(tN);Ldo=r(LEt,"ImageGPTConfig"),LEt.forEach(t),ydo=r(nPe," (ImageGPT model)"),nPe.forEach(t),xdo=i(L),Lg=n(L,"LI",{});var sPe=s(Lg);lce=n(sPe,"STRONG",{});var yEt=s(lce);$do=r(yEt,"layoutlm"),yEt.forEach(t),kdo=r(sPe," \u2014 "),aN=n(sPe,"A",{href:!0});var xEt=s(aN);Sdo=r(xEt,"LayoutLMConfig"),xEt.forEach(t),Rdo=r(sPe," (LayoutLM model)"),sPe.forEach(t),Pdo=i(L),yg=n(L,"LI",{});var lPe=s(yg);ice=n(lPe,"STRONG",{});var $Et=s(ice);Bdo=r($Et,"layoutlmv2"),$Et.forEach(t),Ido=r(lPe," \u2014 "),nN=n(lPe,"A",{href:!0});var kEt=s(nN);Ndo=r(kEt,"LayoutLMv2Config"),kEt.forEach(t),qdo=r(lPe," (LayoutLMv2 model)"),lPe.forEach(t),jdo=i(L),xg=n(L,"LI",{});var iPe=s(xg);dce=n(iPe,"STRONG",{});var SEt=s(dce);Ddo=r(SEt,"layoutlmv3"),SEt.forEach(t),Gdo=r(iPe," \u2014 "),sN=n(iPe,"A",{href:!0});var REt=s(sN);Odo=r(REt,"LayoutLMv3Config"),REt.forEach(t),Vdo=r(iPe," (LayoutLMv3 model)"),iPe.forEach(t),Xdo=i(L),$g=n(L,"LI",{});var dPe=s($g);mce=n(dPe,"STRONG",{});var PEt=s(mce);zdo=r(PEt,"led"),PEt.forEach(t),Qdo=r(dPe," \u2014 "),lN=n(dPe,"A",{href:!0});var BEt=s(lN);Wdo=r(BEt,"LEDConfig"),BEt.forEach(t),Udo=r(dPe," (LED model)"),dPe.forEach(t),Hdo=i(L),kg=n(L,"LI",{});var mPe=s(kg);cce=n(mPe,"STRONG",{});var IEt=s(cce);Jdo=r(IEt,"levit"),IEt.forEach(t),Ydo=r(mPe," \u2014 "),iN=n(mPe,"A",{href:!0});var NEt=s(iN);Kdo=r(NEt,"LevitConfig"),NEt.forEach(t),Zdo=r(mPe," (LeViT model)"),mPe.forEach(t),emo=i(L),Sg=n(L,"LI",{});var cPe=s(Sg);fce=n(cPe,"STRONG",{});var qEt=s(fce);omo=r(qEt,"longformer"),qEt.forEach(t),rmo=r(cPe," \u2014 "),dN=n(cPe,"A",{href:!0});var jEt=s(dN);tmo=r(jEt,"LongformerConfig"),jEt.forEach(t),amo=r(cPe," (Longformer model)"),cPe.forEach(t),nmo=i(L),Rg=n(L,"LI",{});var fPe=s(Rg);gce=n(fPe,"STRONG",{});var DEt=s(gce);smo=r(DEt,"longt5"),DEt.forEach(t),lmo=r(fPe," \u2014 "),mN=n(fPe,"A",{href:!0});var GEt=s(mN);imo=r(GEt,"LongT5Config"),GEt.forEach(t),dmo=r(fPe," (LongT5 model)"),fPe.forEach(t),mmo=i(L),Pg=n(L,"LI",{});var gPe=s(Pg);hce=n(gPe,"STRONG",{});var OEt=s(hce);cmo=r(OEt,"luke"),OEt.forEach(t),fmo=r(gPe," \u2014 "),cN=n(gPe,"A",{href:!0});var VEt=s(cN);gmo=r(VEt,"LukeConfig"),VEt.forEach(t),hmo=r(gPe," (LUKE model)"),gPe.forEach(t),umo=i(L),Bg=n(L,"LI",{});var hPe=s(Bg);uce=n(hPe,"STRONG",{});var XEt=s(uce);pmo=r(XEt,"lxmert"),XEt.forEach(t),_mo=r(hPe," \u2014 "),fN=n(hPe,"A",{href:!0});var zEt=s(fN);bmo=r(zEt,"LxmertConfig"),zEt.forEach(t),vmo=r(hPe," (LXMERT model)"),hPe.forEach(t),Fmo=i(L),Ig=n(L,"LI",{});var uPe=s(Ig);pce=n(uPe,"STRONG",{});var QEt=s(pce);Tmo=r(QEt,"m2m_100"),QEt.forEach(t),Mmo=r(uPe," \u2014 "),gN=n(uPe,"A",{href:!0});var WEt=s(gN);Emo=r(WEt,"M2M100Config"),WEt.forEach(t),Cmo=r(uPe," (M2M100 model)"),uPe.forEach(t),wmo=i(L),Ng=n(L,"LI",{});var pPe=s(Ng);_ce=n(pPe,"STRONG",{});var UEt=s(_ce);Amo=r(UEt,"marian"),UEt.forEach(t),Lmo=r(pPe," \u2014 "),hN=n(pPe,"A",{href:!0});var HEt=s(hN);ymo=r(HEt,"MarianConfig"),HEt.forEach(t),xmo=r(pPe," (Marian model)"),pPe.forEach(t),$mo=i(L),qg=n(L,"LI",{});var _Pe=s(qg);bce=n(_Pe,"STRONG",{});var JEt=s(bce);kmo=r(JEt,"markuplm"),JEt.forEach(t),Smo=r(_Pe," \u2014 "),uN=n(_Pe,"A",{href:!0});var YEt=s(uN);Rmo=r(YEt,"MarkupLMConfig"),YEt.forEach(t),Pmo=r(_Pe," (MarkupLM model)"),_Pe.forEach(t),Bmo=i(L),jg=n(L,"LI",{});var bPe=s(jg);vce=n(bPe,"STRONG",{});var KEt=s(vce);Imo=r(KEt,"maskformer"),KEt.forEach(t),Nmo=r(bPe," \u2014 "),pN=n(bPe,"A",{href:!0});var ZEt=s(pN);qmo=r(ZEt,"MaskFormerConfig"),ZEt.forEach(t),jmo=r(bPe," (MaskFormer model)"),bPe.forEach(t),Dmo=i(L),Dg=n(L,"LI",{});var vPe=s(Dg);Fce=n(vPe,"STRONG",{});var e4t=s(Fce);Gmo=r(e4t,"mbart"),e4t.forEach(t),Omo=r(vPe," \u2014 "),_N=n(vPe,"A",{href:!0});var o4t=s(_N);Vmo=r(o4t,"MBartConfig"),o4t.forEach(t),Xmo=r(vPe," (mBART model)"),vPe.forEach(t),zmo=i(L),Gg=n(L,"LI",{});var FPe=s(Gg);Tce=n(FPe,"STRONG",{});var r4t=s(Tce);Qmo=r(r4t,"mctct"),r4t.forEach(t),Wmo=r(FPe," \u2014 "),bN=n(FPe,"A",{href:!0});var t4t=s(bN);Umo=r(t4t,"MCTCTConfig"),t4t.forEach(t),Hmo=r(FPe," (M-CTC-T model)"),FPe.forEach(t),Jmo=i(L),Og=n(L,"LI",{});var TPe=s(Og);Mce=n(TPe,"STRONG",{});var a4t=s(Mce);Ymo=r(a4t,"megatron-bert"),a4t.forEach(t),Kmo=r(TPe," \u2014 "),vN=n(TPe,"A",{href:!0});var n4t=s(vN);Zmo=r(n4t,"MegatronBertConfig"),n4t.forEach(t),eco=r(TPe," (Megatron-BERT model)"),TPe.forEach(t),oco=i(L),Vg=n(L,"LI",{});var MPe=s(Vg);Ece=n(MPe,"STRONG",{});var s4t=s(Ece);rco=r(s4t,"mobilebert"),s4t.forEach(t),tco=r(MPe," \u2014 "),FN=n(MPe,"A",{href:!0});var l4t=s(FN);aco=r(l4t,"MobileBertConfig"),l4t.forEach(t),nco=r(MPe," (MobileBERT model)"),MPe.forEach(t),sco=i(L),Xg=n(L,"LI",{});var EPe=s(Xg);Cce=n(EPe,"STRONG",{});var i4t=s(Cce);lco=r(i4t,"mobilevit"),i4t.forEach(t),ico=r(EPe," \u2014 "),TN=n(EPe,"A",{href:!0});var d4t=s(TN);dco=r(d4t,"MobileViTConfig"),d4t.forEach(t),mco=r(EPe," (MobileViT model)"),EPe.forEach(t),cco=i(L),zg=n(L,"LI",{});var CPe=s(zg);wce=n(CPe,"STRONG",{});var m4t=s(wce);fco=r(m4t,"mpnet"),m4t.forEach(t),gco=r(CPe," \u2014 "),MN=n(CPe,"A",{href:!0});var c4t=s(MN);hco=r(c4t,"MPNetConfig"),c4t.forEach(t),uco=r(CPe," (MPNet model)"),CPe.forEach(t),pco=i(L),Qg=n(L,"LI",{});var wPe=s(Qg);Ace=n(wPe,"STRONG",{});var f4t=s(Ace);_co=r(f4t,"mt5"),f4t.forEach(t),bco=r(wPe," \u2014 "),EN=n(wPe,"A",{href:!0});var g4t=s(EN);vco=r(g4t,"MT5Config"),g4t.forEach(t),Fco=r(wPe," (MT5 model)"),wPe.forEach(t),Tco=i(L),Wg=n(L,"LI",{});var APe=s(Wg);Lce=n(APe,"STRONG",{});var h4t=s(Lce);Mco=r(h4t,"mvp"),h4t.forEach(t),Eco=r(APe," \u2014 "),CN=n(APe,"A",{href:!0});var u4t=s(CN);Cco=r(u4t,"MvpConfig"),u4t.forEach(t),wco=r(APe," (MVP model)"),APe.forEach(t),Aco=i(L),Ug=n(L,"LI",{});var LPe=s(Ug);yce=n(LPe,"STRONG",{});var p4t=s(yce);Lco=r(p4t,"nezha"),p4t.forEach(t),yco=r(LPe," \u2014 "),wN=n(LPe,"A",{href:!0});var _4t=s(wN);xco=r(_4t,"NezhaConfig"),_4t.forEach(t),$co=r(LPe," (Nezha model)"),LPe.forEach(t),kco=i(L),Hg=n(L,"LI",{});var yPe=s(Hg);xce=n(yPe,"STRONG",{});var b4t=s(xce);Sco=r(b4t,"nystromformer"),b4t.forEach(t),Rco=r(yPe," \u2014 "),AN=n(yPe,"A",{href:!0});var v4t=s(AN);Pco=r(v4t,"NystromformerConfig"),v4t.forEach(t),Bco=r(yPe," (Nystr\xF6mformer model)"),yPe.forEach(t),Ico=i(L),Jg=n(L,"LI",{});var xPe=s(Jg);$ce=n(xPe,"STRONG",{});var F4t=s($ce);Nco=r(F4t,"openai-gpt"),F4t.forEach(t),qco=r(xPe," \u2014 "),LN=n(xPe,"A",{href:!0});var T4t=s(LN);jco=r(T4t,"OpenAIGPTConfig"),T4t.forEach(t),Dco=r(xPe," (OpenAI GPT model)"),xPe.forEach(t),Gco=i(L),Yg=n(L,"LI",{});var $Pe=s(Yg);kce=n($Pe,"STRONG",{});var M4t=s(kce);Oco=r(M4t,"opt"),M4t.forEach(t),Vco=r($Pe," \u2014 "),yN=n($Pe,"A",{href:!0});var E4t=s(yN);Xco=r(E4t,"OPTConfig"),E4t.forEach(t),zco=r($Pe," (OPT model)"),$Pe.forEach(t),Qco=i(L),Kg=n(L,"LI",{});var kPe=s(Kg);Sce=n(kPe,"STRONG",{});var C4t=s(Sce);Wco=r(C4t,"owlvit"),C4t.forEach(t),Uco=r(kPe," \u2014 "),xN=n(kPe,"A",{href:!0});var w4t=s(xN);Hco=r(w4t,"OwlViTConfig"),w4t.forEach(t),Jco=r(kPe," (OWL-ViT model)"),kPe.forEach(t),Yco=i(L),Zg=n(L,"LI",{});var SPe=s(Zg);Rce=n(SPe,"STRONG",{});var A4t=s(Rce);Kco=r(A4t,"pegasus"),A4t.forEach(t),Zco=r(SPe," \u2014 "),$N=n(SPe,"A",{href:!0});var L4t=s($N);efo=r(L4t,"PegasusConfig"),L4t.forEach(t),ofo=r(SPe," (Pegasus model)"),SPe.forEach(t),rfo=i(L),eh=n(L,"LI",{});var RPe=s(eh);Pce=n(RPe,"STRONG",{});var y4t=s(Pce);tfo=r(y4t,"pegasus_x"),y4t.forEach(t),afo=r(RPe," \u2014 "),kN=n(RPe,"A",{href:!0});var x4t=s(kN);nfo=r(x4t,"PegasusXConfig"),x4t.forEach(t),sfo=r(RPe," (PEGASUS-X model)"),RPe.forEach(t),lfo=i(L),oh=n(L,"LI",{});var PPe=s(oh);Bce=n(PPe,"STRONG",{});var $4t=s(Bce);ifo=r($4t,"perceiver"),$4t.forEach(t),dfo=r(PPe," \u2014 "),SN=n(PPe,"A",{href:!0});var k4t=s(SN);mfo=r(k4t,"PerceiverConfig"),k4t.forEach(t),cfo=r(PPe," (Perceiver model)"),PPe.forEach(t),ffo=i(L),rh=n(L,"LI",{});var BPe=s(rh);Ice=n(BPe,"STRONG",{});var S4t=s(Ice);gfo=r(S4t,"plbart"),S4t.forEach(t),hfo=r(BPe," \u2014 "),RN=n(BPe,"A",{href:!0});var R4t=s(RN);ufo=r(R4t,"PLBartConfig"),R4t.forEach(t),pfo=r(BPe," (PLBart model)"),BPe.forEach(t),_fo=i(L),th=n(L,"LI",{});var IPe=s(th);Nce=n(IPe,"STRONG",{});var P4t=s(Nce);bfo=r(P4t,"poolformer"),P4t.forEach(t),vfo=r(IPe," \u2014 "),PN=n(IPe,"A",{href:!0});var B4t=s(PN);Ffo=r(B4t,"PoolFormerConfig"),B4t.forEach(t),Tfo=r(IPe," (PoolFormer model)"),IPe.forEach(t),Mfo=i(L),ah=n(L,"LI",{});var NPe=s(ah);qce=n(NPe,"STRONG",{});var I4t=s(qce);Efo=r(I4t,"prophetnet"),I4t.forEach(t),Cfo=r(NPe," \u2014 "),BN=n(NPe,"A",{href:!0});var N4t=s(BN);wfo=r(N4t,"ProphetNetConfig"),N4t.forEach(t),Afo=r(NPe," (ProphetNet model)"),NPe.forEach(t),Lfo=i(L),nh=n(L,"LI",{});var qPe=s(nh);jce=n(qPe,"STRONG",{});var q4t=s(jce);yfo=r(q4t,"qdqbert"),q4t.forEach(t),xfo=r(qPe," \u2014 "),IN=n(qPe,"A",{href:!0});var j4t=s(IN);$fo=r(j4t,"QDQBertConfig"),j4t.forEach(t),kfo=r(qPe," (QDQBert model)"),qPe.forEach(t),Sfo=i(L),sh=n(L,"LI",{});var jPe=s(sh);Dce=n(jPe,"STRONG",{});var D4t=s(Dce);Rfo=r(D4t,"rag"),D4t.forEach(t),Pfo=r(jPe," \u2014 "),NN=n(jPe,"A",{href:!0});var G4t=s(NN);Bfo=r(G4t,"RagConfig"),G4t.forEach(t),Ifo=r(jPe," (RAG model)"),jPe.forEach(t),Nfo=i(L),lh=n(L,"LI",{});var DPe=s(lh);Gce=n(DPe,"STRONG",{});var O4t=s(Gce);qfo=r(O4t,"realm"),O4t.forEach(t),jfo=r(DPe," \u2014 "),qN=n(DPe,"A",{href:!0});var V4t=s(qN);Dfo=r(V4t,"RealmConfig"),V4t.forEach(t),Gfo=r(DPe," (REALM model)"),DPe.forEach(t),Ofo=i(L),ih=n(L,"LI",{});var GPe=s(ih);Oce=n(GPe,"STRONG",{});var X4t=s(Oce);Vfo=r(X4t,"reformer"),X4t.forEach(t),Xfo=r(GPe," \u2014 "),jN=n(GPe,"A",{href:!0});var z4t=s(jN);zfo=r(z4t,"ReformerConfig"),z4t.forEach(t),Qfo=r(GPe," (Reformer model)"),GPe.forEach(t),Wfo=i(L),dh=n(L,"LI",{});var OPe=s(dh);Vce=n(OPe,"STRONG",{});var Q4t=s(Vce);Ufo=r(Q4t,"regnet"),Q4t.forEach(t),Hfo=r(OPe," \u2014 "),DN=n(OPe,"A",{href:!0});var W4t=s(DN);Jfo=r(W4t,"RegNetConfig"),W4t.forEach(t),Yfo=r(OPe," (RegNet model)"),OPe.forEach(t),Kfo=i(L),mh=n(L,"LI",{});var VPe=s(mh);Xce=n(VPe,"STRONG",{});var U4t=s(Xce);Zfo=r(U4t,"rembert"),U4t.forEach(t),ego=r(VPe," \u2014 "),GN=n(VPe,"A",{href:!0});var H4t=s(GN);ogo=r(H4t,"RemBertConfig"),H4t.forEach(t),rgo=r(VPe," (RemBERT model)"),VPe.forEach(t),tgo=i(L),ch=n(L,"LI",{});var XPe=s(ch);zce=n(XPe,"STRONG",{});var J4t=s(zce);ago=r(J4t,"resnet"),J4t.forEach(t),ngo=r(XPe," \u2014 "),ON=n(XPe,"A",{href:!0});var Y4t=s(ON);sgo=r(Y4t,"ResNetConfig"),Y4t.forEach(t),lgo=r(XPe," (ResNet model)"),XPe.forEach(t),igo=i(L),fh=n(L,"LI",{});var zPe=s(fh);Qce=n(zPe,"STRONG",{});var K4t=s(Qce);dgo=r(K4t,"retribert"),K4t.forEach(t),mgo=r(zPe," \u2014 "),VN=n(zPe,"A",{href:!0});var Z4t=s(VN);cgo=r(Z4t,"RetriBertConfig"),Z4t.forEach(t),fgo=r(zPe," (RetriBERT model)"),zPe.forEach(t),ggo=i(L),gh=n(L,"LI",{});var QPe=s(gh);Wce=n(QPe,"STRONG",{});var eCt=s(Wce);hgo=r(eCt,"roberta"),eCt.forEach(t),ugo=r(QPe," \u2014 "),XN=n(QPe,"A",{href:!0});var oCt=s(XN);pgo=r(oCt,"RobertaConfig"),oCt.forEach(t),_go=r(QPe," (RoBERTa model)"),QPe.forEach(t),bgo=i(L),hh=n(L,"LI",{});var WPe=s(hh);Uce=n(WPe,"STRONG",{});var rCt=s(Uce);vgo=r(rCt,"roformer"),rCt.forEach(t),Fgo=r(WPe," \u2014 "),zN=n(WPe,"A",{href:!0});var tCt=s(zN);Tgo=r(tCt,"RoFormerConfig"),tCt.forEach(t),Mgo=r(WPe," (RoFormer model)"),WPe.forEach(t),Ego=i(L),uh=n(L,"LI",{});var UPe=s(uh);Hce=n(UPe,"STRONG",{});var aCt=s(Hce);Cgo=r(aCt,"segformer"),aCt.forEach(t),wgo=r(UPe," \u2014 "),QN=n(UPe,"A",{href:!0});var nCt=s(QN);Ago=r(nCt,"SegformerConfig"),nCt.forEach(t),Lgo=r(UPe," (SegFormer model)"),UPe.forEach(t),ygo=i(L),ph=n(L,"LI",{});var HPe=s(ph);Jce=n(HPe,"STRONG",{});var sCt=s(Jce);xgo=r(sCt,"sew"),sCt.forEach(t),$go=r(HPe," \u2014 "),WN=n(HPe,"A",{href:!0});var lCt=s(WN);kgo=r(lCt,"SEWConfig"),lCt.forEach(t),Sgo=r(HPe," (SEW model)"),HPe.forEach(t),Rgo=i(L),_h=n(L,"LI",{});var JPe=s(_h);Yce=n(JPe,"STRONG",{});var iCt=s(Yce);Pgo=r(iCt,"sew-d"),iCt.forEach(t),Bgo=r(JPe," \u2014 "),UN=n(JPe,"A",{href:!0});var dCt=s(UN);Igo=r(dCt,"SEWDConfig"),dCt.forEach(t),Ngo=r(JPe," (SEW-D model)"),JPe.forEach(t),qgo=i(L),bh=n(L,"LI",{});var YPe=s(bh);Kce=n(YPe,"STRONG",{});var mCt=s(Kce);jgo=r(mCt,"speech-encoder-decoder"),mCt.forEach(t),Dgo=r(YPe," \u2014 "),HN=n(YPe,"A",{href:!0});var cCt=s(HN);Ggo=r(cCt,"SpeechEncoderDecoderConfig"),cCt.forEach(t),Ogo=r(YPe," (Speech Encoder decoder model)"),YPe.forEach(t),Vgo=i(L),vh=n(L,"LI",{});var KPe=s(vh);Zce=n(KPe,"STRONG",{});var fCt=s(Zce);Xgo=r(fCt,"speech_to_text"),fCt.forEach(t),zgo=r(KPe," \u2014 "),JN=n(KPe,"A",{href:!0});var gCt=s(JN);Qgo=r(gCt,"Speech2TextConfig"),gCt.forEach(t),Wgo=r(KPe," (Speech2Text model)"),KPe.forEach(t),Ugo=i(L),Fh=n(L,"LI",{});var ZPe=s(Fh);efe=n(ZPe,"STRONG",{});var hCt=s(efe);Hgo=r(hCt,"speech_to_text_2"),hCt.forEach(t),Jgo=r(ZPe," \u2014 "),YN=n(ZPe,"A",{href:!0});var uCt=s(YN);Ygo=r(uCt,"Speech2Text2Config"),uCt.forEach(t),Kgo=r(ZPe," (Speech2Text2 model)"),ZPe.forEach(t),Zgo=i(L),Th=n(L,"LI",{});var eBe=s(Th);ofe=n(eBe,"STRONG",{});var pCt=s(ofe);eho=r(pCt,"splinter"),pCt.forEach(t),oho=r(eBe," \u2014 "),KN=n(eBe,"A",{href:!0});var _Ct=s(KN);rho=r(_Ct,"SplinterConfig"),_Ct.forEach(t),tho=r(eBe," (Splinter model)"),eBe.forEach(t),aho=i(L),Mh=n(L,"LI",{});var oBe=s(Mh);rfe=n(oBe,"STRONG",{});var bCt=s(rfe);nho=r(bCt,"squeezebert"),bCt.forEach(t),sho=r(oBe," \u2014 "),ZN=n(oBe,"A",{href:!0});var vCt=s(ZN);lho=r(vCt,"SqueezeBertConfig"),vCt.forEach(t),iho=r(oBe," (SqueezeBERT model)"),oBe.forEach(t),dho=i(L),Eh=n(L,"LI",{});var rBe=s(Eh);tfe=n(rBe,"STRONG",{});var FCt=s(tfe);mho=r(FCt,"swin"),FCt.forEach(t),cho=r(rBe," \u2014 "),eq=n(rBe,"A",{href:!0});var TCt=s(eq);fho=r(TCt,"SwinConfig"),TCt.forEach(t),gho=r(rBe," (Swin Transformer model)"),rBe.forEach(t),hho=i(L),Ch=n(L,"LI",{});var tBe=s(Ch);afe=n(tBe,"STRONG",{});var MCt=s(afe);uho=r(MCt,"swinv2"),MCt.forEach(t),pho=r(tBe," \u2014 "),oq=n(tBe,"A",{href:!0});var ECt=s(oq);_ho=r(ECt,"Swinv2Config"),ECt.forEach(t),bho=r(tBe," (Swin Transformer V2 model)"),tBe.forEach(t),vho=i(L),wh=n(L,"LI",{});var aBe=s(wh);nfe=n(aBe,"STRONG",{});var CCt=s(nfe);Fho=r(CCt,"t5"),CCt.forEach(t),Tho=r(aBe," \u2014 "),rq=n(aBe,"A",{href:!0});var wCt=s(rq);Mho=r(wCt,"T5Config"),wCt.forEach(t),Eho=r(aBe," (T5 model)"),aBe.forEach(t),Cho=i(L),Ah=n(L,"LI",{});var nBe=s(Ah);sfe=n(nBe,"STRONG",{});var ACt=s(sfe);who=r(ACt,"tapas"),ACt.forEach(t),Aho=r(nBe," \u2014 "),tq=n(nBe,"A",{href:!0});var LCt=s(tq);Lho=r(LCt,"TapasConfig"),LCt.forEach(t),yho=r(nBe," (TAPAS model)"),nBe.forEach(t),xho=i(L),Lh=n(L,"LI",{});var sBe=s(Lh);lfe=n(sBe,"STRONG",{});var yCt=s(lfe);$ho=r(yCt,"time_series_transformer"),yCt.forEach(t),kho=r(sBe," \u2014 "),aq=n(sBe,"A",{href:!0});var xCt=s(aq);Sho=r(xCt,"TimeSeriesTransformerConfig"),xCt.forEach(t),Rho=r(sBe," (Time Series Transformer model)"),sBe.forEach(t),Pho=i(L),yh=n(L,"LI",{});var lBe=s(yh);ife=n(lBe,"STRONG",{});var $Ct=s(ife);Bho=r($Ct,"trajectory_transformer"),$Ct.forEach(t),Iho=r(lBe," \u2014 "),nq=n(lBe,"A",{href:!0});var kCt=s(nq);Nho=r(kCt,"TrajectoryTransformerConfig"),kCt.forEach(t),qho=r(lBe," (Trajectory Transformer model)"),lBe.forEach(t),jho=i(L),xh=n(L,"LI",{});var iBe=s(xh);dfe=n(iBe,"STRONG",{});var SCt=s(dfe);Dho=r(SCt,"transfo-xl"),SCt.forEach(t),Gho=r(iBe," \u2014 "),sq=n(iBe,"A",{href:!0});var RCt=s(sq);Oho=r(RCt,"TransfoXLConfig"),RCt.forEach(t),Vho=r(iBe," (Transformer-XL model)"),iBe.forEach(t),Xho=i(L),$h=n(L,"LI",{});var dBe=s($h);mfe=n(dBe,"STRONG",{});var PCt=s(mfe);zho=r(PCt,"trocr"),PCt.forEach(t),Qho=r(dBe," \u2014 "),lq=n(dBe,"A",{href:!0});var BCt=s(lq);Who=r(BCt,"TrOCRConfig"),BCt.forEach(t),Uho=r(dBe," (TrOCR model)"),dBe.forEach(t),Hho=i(L),kh=n(L,"LI",{});var mBe=s(kh);cfe=n(mBe,"STRONG",{});var ICt=s(cfe);Jho=r(ICt,"unispeech"),ICt.forEach(t),Yho=r(mBe," \u2014 "),iq=n(mBe,"A",{href:!0});var NCt=s(iq);Kho=r(NCt,"UniSpeechConfig"),NCt.forEach(t),Zho=r(mBe," (UniSpeech model)"),mBe.forEach(t),euo=i(L),Sh=n(L,"LI",{});var cBe=s(Sh);ffe=n(cBe,"STRONG",{});var qCt=s(ffe);ouo=r(qCt,"unispeech-sat"),qCt.forEach(t),ruo=r(cBe," \u2014 "),dq=n(cBe,"A",{href:!0});var jCt=s(dq);tuo=r(jCt,"UniSpeechSatConfig"),jCt.forEach(t),auo=r(cBe," (UniSpeechSat model)"),cBe.forEach(t),nuo=i(L),Rh=n(L,"LI",{});var fBe=s(Rh);gfe=n(fBe,"STRONG",{});var DCt=s(gfe);suo=r(DCt,"van"),DCt.forEach(t),luo=r(fBe," \u2014 "),mq=n(fBe,"A",{href:!0});var GCt=s(mq);iuo=r(GCt,"VanConfig"),GCt.forEach(t),duo=r(fBe," (VAN model)"),fBe.forEach(t),muo=i(L),Ph=n(L,"LI",{});var gBe=s(Ph);hfe=n(gBe,"STRONG",{});var OCt=s(hfe);cuo=r(OCt,"videomae"),OCt.forEach(t),fuo=r(gBe," \u2014 "),cq=n(gBe,"A",{href:!0});var VCt=s(cq);guo=r(VCt,"VideoMAEConfig"),VCt.forEach(t),huo=r(gBe," (VideoMAE model)"),gBe.forEach(t),uuo=i(L),Bh=n(L,"LI",{});var hBe=s(Bh);ufe=n(hBe,"STRONG",{});var XCt=s(ufe);puo=r(XCt,"vilt"),XCt.forEach(t),_uo=r(hBe," \u2014 "),fq=n(hBe,"A",{href:!0});var zCt=s(fq);buo=r(zCt,"ViltConfig"),zCt.forEach(t),vuo=r(hBe," (ViLT model)"),hBe.forEach(t),Fuo=i(L),Ih=n(L,"LI",{});var uBe=s(Ih);pfe=n(uBe,"STRONG",{});var QCt=s(pfe);Tuo=r(QCt,"vision-encoder-decoder"),QCt.forEach(t),Muo=r(uBe," \u2014 "),gq=n(uBe,"A",{href:!0});var WCt=s(gq);Euo=r(WCt,"VisionEncoderDecoderConfig"),WCt.forEach(t),Cuo=r(uBe," (Vision Encoder decoder model)"),uBe.forEach(t),wuo=i(L),Nh=n(L,"LI",{});var pBe=s(Nh);_fe=n(pBe,"STRONG",{});var UCt=s(_fe);Auo=r(UCt,"vision-text-dual-encoder"),UCt.forEach(t),Luo=r(pBe," \u2014 "),hq=n(pBe,"A",{href:!0});var HCt=s(hq);yuo=r(HCt,"VisionTextDualEncoderConfig"),HCt.forEach(t),xuo=r(pBe," (VisionTextDualEncoder model)"),pBe.forEach(t),$uo=i(L),qh=n(L,"LI",{});var _Be=s(qh);bfe=n(_Be,"STRONG",{});var JCt=s(bfe);kuo=r(JCt,"visual_bert"),JCt.forEach(t),Suo=r(_Be," \u2014 "),uq=n(_Be,"A",{href:!0});var YCt=s(uq);Ruo=r(YCt,"VisualBertConfig"),YCt.forEach(t),Puo=r(_Be," (VisualBERT model)"),_Be.forEach(t),Buo=i(L),jh=n(L,"LI",{});var bBe=s(jh);vfe=n(bBe,"STRONG",{});var KCt=s(vfe);Iuo=r(KCt,"vit"),KCt.forEach(t),Nuo=r(bBe," \u2014 "),pq=n(bBe,"A",{href:!0});var ZCt=s(pq);quo=r(ZCt,"ViTConfig"),ZCt.forEach(t),juo=r(bBe," (ViT model)"),bBe.forEach(t),Duo=i(L),Dh=n(L,"LI",{});var vBe=s(Dh);Ffe=n(vBe,"STRONG",{});var e3t=s(Ffe);Guo=r(e3t,"vit_mae"),e3t.forEach(t),Ouo=r(vBe," \u2014 "),_q=n(vBe,"A",{href:!0});var o3t=s(_q);Vuo=r(o3t,"ViTMAEConfig"),o3t.forEach(t),Xuo=r(vBe," (ViTMAE model)"),vBe.forEach(t),zuo=i(L),Gh=n(L,"LI",{});var FBe=s(Gh);Tfe=n(FBe,"STRONG",{});var r3t=s(Tfe);Quo=r(r3t,"vit_msn"),r3t.forEach(t),Wuo=r(FBe," \u2014 "),bq=n(FBe,"A",{href:!0});var t3t=s(bq);Uuo=r(t3t,"ViTMSNConfig"),t3t.forEach(t),Huo=r(FBe," (ViTMSN model)"),FBe.forEach(t),Juo=i(L),Oh=n(L,"LI",{});var TBe=s(Oh);Mfe=n(TBe,"STRONG",{});var a3t=s(Mfe);Yuo=r(a3t,"wav2vec2"),a3t.forEach(t),Kuo=r(TBe," \u2014 "),vq=n(TBe,"A",{href:!0});var n3t=s(vq);Zuo=r(n3t,"Wav2Vec2Config"),n3t.forEach(t),epo=r(TBe," (Wav2Vec2 model)"),TBe.forEach(t),opo=i(L),Vh=n(L,"LI",{});var MBe=s(Vh);Efe=n(MBe,"STRONG",{});var s3t=s(Efe);rpo=r(s3t,"wav2vec2-conformer"),s3t.forEach(t),tpo=r(MBe," \u2014 "),Fq=n(MBe,"A",{href:!0});var l3t=s(Fq);apo=r(l3t,"Wav2Vec2ConformerConfig"),l3t.forEach(t),npo=r(MBe," (Wav2Vec2-Conformer model)"),MBe.forEach(t),spo=i(L),Xh=n(L,"LI",{});var EBe=s(Xh);Cfe=n(EBe,"STRONG",{});var i3t=s(Cfe);lpo=r(i3t,"wavlm"),i3t.forEach(t),ipo=r(EBe," \u2014 "),Tq=n(EBe,"A",{href:!0});var d3t=s(Tq);dpo=r(d3t,"WavLMConfig"),d3t.forEach(t),mpo=r(EBe," (WavLM model)"),EBe.forEach(t),cpo=i(L),zh=n(L,"LI",{});var CBe=s(zh);wfe=n(CBe,"STRONG",{});var m3t=s(wfe);fpo=r(m3t,"xclip"),m3t.forEach(t),gpo=r(CBe," \u2014 "),Mq=n(CBe,"A",{href:!0});var c3t=s(Mq);hpo=r(c3t,"XCLIPConfig"),c3t.forEach(t),upo=r(CBe," (X-CLIP model)"),CBe.forEach(t),ppo=i(L),Qh=n(L,"LI",{});var wBe=s(Qh);Afe=n(wBe,"STRONG",{});var f3t=s(Afe);_po=r(f3t,"xglm"),f3t.forEach(t),bpo=r(wBe," \u2014 "),Eq=n(wBe,"A",{href:!0});var g3t=s(Eq);vpo=r(g3t,"XGLMConfig"),g3t.forEach(t),Fpo=r(wBe," (XGLM model)"),wBe.forEach(t),Tpo=i(L),Wh=n(L,"LI",{});var ABe=s(Wh);Lfe=n(ABe,"STRONG",{});var h3t=s(Lfe);Mpo=r(h3t,"xlm"),h3t.forEach(t),Epo=r(ABe," \u2014 "),Cq=n(ABe,"A",{href:!0});var u3t=s(Cq);Cpo=r(u3t,"XLMConfig"),u3t.forEach(t),wpo=r(ABe," (XLM model)"),ABe.forEach(t),Apo=i(L),Uh=n(L,"LI",{});var LBe=s(Uh);yfe=n(LBe,"STRONG",{});var p3t=s(yfe);Lpo=r(p3t,"xlm-prophetnet"),p3t.forEach(t),ypo=r(LBe," \u2014 "),wq=n(LBe,"A",{href:!0});var _3t=s(wq);xpo=r(_3t,"XLMProphetNetConfig"),_3t.forEach(t),$po=r(LBe," (XLM-ProphetNet model)"),LBe.forEach(t),kpo=i(L),Hh=n(L,"LI",{});var yBe=s(Hh);xfe=n(yBe,"STRONG",{});var b3t=s(xfe);Spo=r(b3t,"xlm-roberta"),b3t.forEach(t),Rpo=r(yBe," \u2014 "),Aq=n(yBe,"A",{href:!0});var v3t=s(Aq);Ppo=r(v3t,"XLMRobertaConfig"),v3t.forEach(t),Bpo=r(yBe," (XLM-RoBERTa model)"),yBe.forEach(t),Ipo=i(L),Jh=n(L,"LI",{});var xBe=s(Jh);$fe=n(xBe,"STRONG",{});var F3t=s($fe);Npo=r(F3t,"xlm-roberta-xl"),F3t.forEach(t),qpo=r(xBe," \u2014 "),Lq=n(xBe,"A",{href:!0});var T3t=s(Lq);jpo=r(T3t,"XLMRobertaXLConfig"),T3t.forEach(t),Dpo=r(xBe," (XLM-RoBERTa-XL model)"),xBe.forEach(t),Gpo=i(L),Yh=n(L,"LI",{});var $Be=s(Yh);kfe=n($Be,"STRONG",{});var M3t=s(kfe);Opo=r(M3t,"xlnet"),M3t.forEach(t),Vpo=r($Be," \u2014 "),yq=n($Be,"A",{href:!0});var E3t=s(yq);Xpo=r(E3t,"XLNetConfig"),E3t.forEach(t),zpo=r($Be," (XLNet model)"),$Be.forEach(t),Qpo=i(L),Kh=n(L,"LI",{});var kBe=s(Kh);Sfe=n(kBe,"STRONG",{});var C3t=s(Sfe);Wpo=r(C3t,"yolos"),C3t.forEach(t),Upo=r(kBe," \u2014 "),xq=n(kBe,"A",{href:!0});var w3t=s(xq);Hpo=r(w3t,"YolosConfig"),w3t.forEach(t),Jpo=r(kBe," (YOLOS model)"),kBe.forEach(t),Ypo=i(L),Zh=n(L,"LI",{});var SBe=s(Zh);Rfe=n(SBe,"STRONG",{});var A3t=s(Rfe);Kpo=r(A3t,"yoso"),A3t.forEach(t),Zpo=r(SBe," \u2014 "),$q=n(SBe,"A",{href:!0});var L3t=s($q);e_o=r(L3t,"YosoConfig"),L3t.forEach(t),o_o=r(SBe," (YOSO model)"),SBe.forEach(t),L.forEach(t),r_o=i(ut),T(eu.$$.fragment,ut),ut.forEach(t),t_o=i(ht),ou=n(ht,"DIV",{class:!0});var ero=s(ou);T(lx.$$.fragment,ero),a_o=i(ero),Pfe=n(ero,"P",{});var y3t=s(Pfe);n_o=r(y3t,"Register a new configuration for this class."),y3t.forEach(t),ero.forEach(t),ht.forEach(t),WZe=i(c),gd=n(c,"H2",{class:!0});var oro=s(gd);ru=n(oro,"A",{id:!0,class:!0,href:!0});var x3t=s(ru);Bfe=n(x3t,"SPAN",{});var $3t=s(Bfe);T(ix.$$.fragment,$3t),$3t.forEach(t),x3t.forEach(t),s_o=i(oro),Ife=n(oro,"SPAN",{});var k3t=s(Ife);l_o=r(k3t,"AutoTokenizer"),k3t.forEach(t),oro.forEach(t),UZe=i(c),ko=n(c,"DIV",{class:!0});var Ml=s(ko);T(dx.$$.fragment,Ml),i_o=i(Ml),mx=n(Ml,"P",{});var rro=s(mx);d_o=r(rro,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),kq=n(rro,"A",{href:!0});var S3t=s(kq);m_o=r(S3t,"AutoTokenizer.from_pretrained()"),S3t.forEach(t),c_o=r(rro," class method."),rro.forEach(t),f_o=i(Ml),cx=n(Ml,"P",{});var tro=s(cx);g_o=r(tro,"This class cannot be instantiated directly using "),Nfe=n(tro,"CODE",{});var R3t=s(Nfe);h_o=r(R3t,"__init__()"),R3t.forEach(t),u_o=r(tro," (throws an error)."),tro.forEach(t),p_o=i(Ml),Br=n(Ml,"DIV",{class:!0});var El=s(Br);T(fx.$$.fragment,El),__o=i(El),qfe=n(El,"P",{});var P3t=s(qfe);b_o=r(P3t,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),P3t.forEach(t),v_o=i(El),Ua=n(El,"P",{});var Qy=s(Ua);F_o=r(Qy,"The tokenizer class to instantiate is selected based on the "),jfe=n(Qy,"CODE",{});var B3t=s(jfe);T_o=r(B3t,"model_type"),B3t.forEach(t),M_o=r(Qy,` property of the config object (either
passed as an argument or loaded from `),Dfe=n(Qy,"CODE",{});var I3t=s(Dfe);E_o=r(I3t,"pretrained_model_name_or_path"),I3t.forEach(t),C_o=r(Qy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gfe=n(Qy,"CODE",{});var N3t=s(Gfe);w_o=r(N3t,"pretrained_model_name_or_path"),N3t.forEach(t),A_o=r(Qy,":"),Qy.forEach(t),L_o=i(El),k=n(El,"UL",{});var S=s(k);ns=n(S,"LI",{});var NP=s(ns);Ofe=n(NP,"STRONG",{});var q3t=s(Ofe);y_o=r(q3t,"albert"),q3t.forEach(t),x_o=r(NP," \u2014 "),Sq=n(NP,"A",{href:!0});var j3t=s(Sq);$_o=r(j3t,"AlbertTokenizer"),j3t.forEach(t),k_o=r(NP," or "),Rq=n(NP,"A",{href:!0});var D3t=s(Rq);S_o=r(D3t,"AlbertTokenizerFast"),D3t.forEach(t),R_o=r(NP," (ALBERT model)"),NP.forEach(t),P_o=i(S),ss=n(S,"LI",{});var qP=s(ss);Vfe=n(qP,"STRONG",{});var G3t=s(Vfe);B_o=r(G3t,"bart"),G3t.forEach(t),I_o=r(qP," \u2014 "),Pq=n(qP,"A",{href:!0});var O3t=s(Pq);N_o=r(O3t,"BartTokenizer"),O3t.forEach(t),q_o=r(qP," or "),Bq=n(qP,"A",{href:!0});var V3t=s(Bq);j_o=r(V3t,"BartTokenizerFast"),V3t.forEach(t),D_o=r(qP," (BART model)"),qP.forEach(t),G_o=i(S),ls=n(S,"LI",{});var jP=s(ls);Xfe=n(jP,"STRONG",{});var X3t=s(Xfe);O_o=r(X3t,"barthez"),X3t.forEach(t),V_o=r(jP," \u2014 "),Iq=n(jP,"A",{href:!0});var z3t=s(Iq);X_o=r(z3t,"BarthezTokenizer"),z3t.forEach(t),z_o=r(jP," or "),Nq=n(jP,"A",{href:!0});var Q3t=s(Nq);Q_o=r(Q3t,"BarthezTokenizerFast"),Q3t.forEach(t),W_o=r(jP," (BARThez model)"),jP.forEach(t),U_o=i(S),tu=n(S,"LI",{});var RBe=s(tu);zfe=n(RBe,"STRONG",{});var W3t=s(zfe);H_o=r(W3t,"bartpho"),W3t.forEach(t),J_o=r(RBe," \u2014 "),qq=n(RBe,"A",{href:!0});var U3t=s(qq);Y_o=r(U3t,"BartphoTokenizer"),U3t.forEach(t),K_o=r(RBe," (BARTpho model)"),RBe.forEach(t),Z_o=i(S),is=n(S,"LI",{});var DP=s(is);Qfe=n(DP,"STRONG",{});var H3t=s(Qfe);e2o=r(H3t,"bert"),H3t.forEach(t),o2o=r(DP," \u2014 "),jq=n(DP,"A",{href:!0});var J3t=s(jq);r2o=r(J3t,"BertTokenizer"),J3t.forEach(t),t2o=r(DP," or "),Dq=n(DP,"A",{href:!0});var Y3t=s(Dq);a2o=r(Y3t,"BertTokenizerFast"),Y3t.forEach(t),n2o=r(DP," (BERT model)"),DP.forEach(t),s2o=i(S),au=n(S,"LI",{});var PBe=s(au);Wfe=n(PBe,"STRONG",{});var K3t=s(Wfe);l2o=r(K3t,"bert-generation"),K3t.forEach(t),i2o=r(PBe," \u2014 "),Gq=n(PBe,"A",{href:!0});var Z3t=s(Gq);d2o=r(Z3t,"BertGenerationTokenizer"),Z3t.forEach(t),m2o=r(PBe," (Bert Generation model)"),PBe.forEach(t),c2o=i(S),nu=n(S,"LI",{});var BBe=s(nu);Ufe=n(BBe,"STRONG",{});var e5t=s(Ufe);f2o=r(e5t,"bert-japanese"),e5t.forEach(t),g2o=r(BBe," \u2014 "),Oq=n(BBe,"A",{href:!0});var o5t=s(Oq);h2o=r(o5t,"BertJapaneseTokenizer"),o5t.forEach(t),u2o=r(BBe," (BertJapanese model)"),BBe.forEach(t),p2o=i(S),su=n(S,"LI",{});var IBe=s(su);Hfe=n(IBe,"STRONG",{});var r5t=s(Hfe);_2o=r(r5t,"bertweet"),r5t.forEach(t),b2o=r(IBe," \u2014 "),Vq=n(IBe,"A",{href:!0});var t5t=s(Vq);v2o=r(t5t,"BertweetTokenizer"),t5t.forEach(t),F2o=r(IBe," (BERTweet model)"),IBe.forEach(t),T2o=i(S),ds=n(S,"LI",{});var GP=s(ds);Jfe=n(GP,"STRONG",{});var a5t=s(Jfe);M2o=r(a5t,"big_bird"),a5t.forEach(t),E2o=r(GP," \u2014 "),Xq=n(GP,"A",{href:!0});var n5t=s(Xq);C2o=r(n5t,"BigBirdTokenizer"),n5t.forEach(t),w2o=r(GP," or "),zq=n(GP,"A",{href:!0});var s5t=s(zq);A2o=r(s5t,"BigBirdTokenizerFast"),s5t.forEach(t),L2o=r(GP," (BigBird model)"),GP.forEach(t),y2o=i(S),ms=n(S,"LI",{});var OP=s(ms);Yfe=n(OP,"STRONG",{});var l5t=s(Yfe);x2o=r(l5t,"bigbird_pegasus"),l5t.forEach(t),$2o=r(OP," \u2014 "),Qq=n(OP,"A",{href:!0});var i5t=s(Qq);k2o=r(i5t,"PegasusTokenizer"),i5t.forEach(t),S2o=r(OP," or "),Wq=n(OP,"A",{href:!0});var d5t=s(Wq);R2o=r(d5t,"PegasusTokenizerFast"),d5t.forEach(t),P2o=r(OP," (BigBird-Pegasus model)"),OP.forEach(t),B2o=i(S),cs=n(S,"LI",{});var VP=s(cs);Kfe=n(VP,"STRONG",{});var m5t=s(Kfe);I2o=r(m5t,"blenderbot"),m5t.forEach(t),N2o=r(VP," \u2014 "),Uq=n(VP,"A",{href:!0});var c5t=s(Uq);q2o=r(c5t,"BlenderbotTokenizer"),c5t.forEach(t),j2o=r(VP," or "),Hq=n(VP,"A",{href:!0});var f5t=s(Hq);D2o=r(f5t,"BlenderbotTokenizerFast"),f5t.forEach(t),G2o=r(VP," (Blenderbot model)"),VP.forEach(t),O2o=i(S),lu=n(S,"LI",{});var NBe=s(lu);Zfe=n(NBe,"STRONG",{});var g5t=s(Zfe);V2o=r(g5t,"blenderbot-small"),g5t.forEach(t),X2o=r(NBe," \u2014 "),Jq=n(NBe,"A",{href:!0});var h5t=s(Jq);z2o=r(h5t,"BlenderbotSmallTokenizer"),h5t.forEach(t),Q2o=r(NBe," (BlenderbotSmall model)"),NBe.forEach(t),W2o=i(S),iu=n(S,"LI",{});var qBe=s(iu);ege=n(qBe,"STRONG",{});var u5t=s(ege);U2o=r(u5t,"bloom"),u5t.forEach(t),H2o=r(qBe," \u2014 "),Yq=n(qBe,"A",{href:!0});var p5t=s(Yq);J2o=r(p5t,"BloomTokenizerFast"),p5t.forEach(t),Y2o=r(qBe," (BLOOM model)"),qBe.forEach(t),K2o=i(S),du=n(S,"LI",{});var jBe=s(du);oge=n(jBe,"STRONG",{});var _5t=s(oge);Z2o=r(_5t,"byt5"),_5t.forEach(t),e1o=r(jBe," \u2014 "),Kq=n(jBe,"A",{href:!0});var b5t=s(Kq);o1o=r(b5t,"ByT5Tokenizer"),b5t.forEach(t),r1o=r(jBe," (ByT5 model)"),jBe.forEach(t),t1o=i(S),fs=n(S,"LI",{});var XP=s(fs);rge=n(XP,"STRONG",{});var v5t=s(rge);a1o=r(v5t,"camembert"),v5t.forEach(t),n1o=r(XP," \u2014 "),Zq=n(XP,"A",{href:!0});var F5t=s(Zq);s1o=r(F5t,"CamembertTokenizer"),F5t.forEach(t),l1o=r(XP," or "),ej=n(XP,"A",{href:!0});var T5t=s(ej);i1o=r(T5t,"CamembertTokenizerFast"),T5t.forEach(t),d1o=r(XP," (CamemBERT model)"),XP.forEach(t),m1o=i(S),mu=n(S,"LI",{});var DBe=s(mu);tge=n(DBe,"STRONG",{});var M5t=s(tge);c1o=r(M5t,"canine"),M5t.forEach(t),f1o=r(DBe," \u2014 "),oj=n(DBe,"A",{href:!0});var E5t=s(oj);g1o=r(E5t,"CanineTokenizer"),E5t.forEach(t),h1o=r(DBe," (CANINE model)"),DBe.forEach(t),u1o=i(S),gs=n(S,"LI",{});var zP=s(gs);age=n(zP,"STRONG",{});var C5t=s(age);p1o=r(C5t,"clip"),C5t.forEach(t),_1o=r(zP," \u2014 "),rj=n(zP,"A",{href:!0});var w5t=s(rj);b1o=r(w5t,"CLIPTokenizer"),w5t.forEach(t),v1o=r(zP," or "),tj=n(zP,"A",{href:!0});var A5t=s(tj);F1o=r(A5t,"CLIPTokenizerFast"),A5t.forEach(t),T1o=r(zP," (CLIP model)"),zP.forEach(t),M1o=i(S),hs=n(S,"LI",{});var QP=s(hs);nge=n(QP,"STRONG",{});var L5t=s(nge);E1o=r(L5t,"codegen"),L5t.forEach(t),C1o=r(QP," \u2014 "),aj=n(QP,"A",{href:!0});var y5t=s(aj);w1o=r(y5t,"CodeGenTokenizer"),y5t.forEach(t),A1o=r(QP," or "),nj=n(QP,"A",{href:!0});var x5t=s(nj);L1o=r(x5t,"CodeGenTokenizerFast"),x5t.forEach(t),y1o=r(QP," (CodeGen model)"),QP.forEach(t),x1o=i(S),us=n(S,"LI",{});var WP=s(us);sge=n(WP,"STRONG",{});var $5t=s(sge);$1o=r($5t,"convbert"),$5t.forEach(t),k1o=r(WP," \u2014 "),sj=n(WP,"A",{href:!0});var k5t=s(sj);S1o=r(k5t,"ConvBertTokenizer"),k5t.forEach(t),R1o=r(WP," or "),lj=n(WP,"A",{href:!0});var S5t=s(lj);P1o=r(S5t,"ConvBertTokenizerFast"),S5t.forEach(t),B1o=r(WP," (ConvBERT model)"),WP.forEach(t),I1o=i(S),ps=n(S,"LI",{});var UP=s(ps);lge=n(UP,"STRONG",{});var R5t=s(lge);N1o=r(R5t,"cpm"),R5t.forEach(t),q1o=r(UP," \u2014 "),ij=n(UP,"A",{href:!0});var P5t=s(ij);j1o=r(P5t,"CpmTokenizer"),P5t.forEach(t),D1o=r(UP," or "),dj=n(UP,"A",{href:!0});var B5t=s(dj);G1o=r(B5t,"CpmTokenizerFast"),B5t.forEach(t),O1o=r(UP," (CPM model)"),UP.forEach(t),V1o=i(S),cu=n(S,"LI",{});var GBe=s(cu);ige=n(GBe,"STRONG",{});var I5t=s(ige);X1o=r(I5t,"ctrl"),I5t.forEach(t),z1o=r(GBe," \u2014 "),mj=n(GBe,"A",{href:!0});var N5t=s(mj);Q1o=r(N5t,"CTRLTokenizer"),N5t.forEach(t),W1o=r(GBe," (CTRL model)"),GBe.forEach(t),U1o=i(S),_s=n(S,"LI",{});var HP=s(_s);dge=n(HP,"STRONG",{});var q5t=s(dge);H1o=r(q5t,"data2vec-text"),q5t.forEach(t),J1o=r(HP," \u2014 "),cj=n(HP,"A",{href:!0});var j5t=s(cj);Y1o=r(j5t,"RobertaTokenizer"),j5t.forEach(t),K1o=r(HP," or "),fj=n(HP,"A",{href:!0});var D5t=s(fj);Z1o=r(D5t,"RobertaTokenizerFast"),D5t.forEach(t),ebo=r(HP," (Data2VecText model)"),HP.forEach(t),obo=i(S),bs=n(S,"LI",{});var JP=s(bs);mge=n(JP,"STRONG",{});var G5t=s(mge);rbo=r(G5t,"deberta"),G5t.forEach(t),tbo=r(JP," \u2014 "),gj=n(JP,"A",{href:!0});var O5t=s(gj);abo=r(O5t,"DebertaTokenizer"),O5t.forEach(t),nbo=r(JP," or "),hj=n(JP,"A",{href:!0});var V5t=s(hj);sbo=r(V5t,"DebertaTokenizerFast"),V5t.forEach(t),lbo=r(JP," (DeBERTa model)"),JP.forEach(t),ibo=i(S),vs=n(S,"LI",{});var YP=s(vs);cge=n(YP,"STRONG",{});var X5t=s(cge);dbo=r(X5t,"deberta-v2"),X5t.forEach(t),mbo=r(YP," \u2014 "),uj=n(YP,"A",{href:!0});var z5t=s(uj);cbo=r(z5t,"DebertaV2Tokenizer"),z5t.forEach(t),fbo=r(YP," or "),pj=n(YP,"A",{href:!0});var Q5t=s(pj);gbo=r(Q5t,"DebertaV2TokenizerFast"),Q5t.forEach(t),hbo=r(YP," (DeBERTa-v2 model)"),YP.forEach(t),ubo=i(S),Fs=n(S,"LI",{});var KP=s(Fs);fge=n(KP,"STRONG",{});var W5t=s(fge);pbo=r(W5t,"distilbert"),W5t.forEach(t),_bo=r(KP," \u2014 "),_j=n(KP,"A",{href:!0});var U5t=s(_j);bbo=r(U5t,"DistilBertTokenizer"),U5t.forEach(t),vbo=r(KP," or "),bj=n(KP,"A",{href:!0});var H5t=s(bj);Fbo=r(H5t,"DistilBertTokenizerFast"),H5t.forEach(t),Tbo=r(KP," (DistilBERT model)"),KP.forEach(t),Mbo=i(S),Ts=n(S,"LI",{});var ZP=s(Ts);gge=n(ZP,"STRONG",{});var J5t=s(gge);Ebo=r(J5t,"dpr"),J5t.forEach(t),Cbo=r(ZP," \u2014 "),vj=n(ZP,"A",{href:!0});var Y5t=s(vj);wbo=r(Y5t,"DPRQuestionEncoderTokenizer"),Y5t.forEach(t),Abo=r(ZP," or "),Fj=n(ZP,"A",{href:!0});var K5t=s(Fj);Lbo=r(K5t,"DPRQuestionEncoderTokenizerFast"),K5t.forEach(t),ybo=r(ZP," (DPR model)"),ZP.forEach(t),xbo=i(S),Ms=n(S,"LI",{});var eB=s(Ms);hge=n(eB,"STRONG",{});var Z5t=s(hge);$bo=r(Z5t,"electra"),Z5t.forEach(t),kbo=r(eB," \u2014 "),Tj=n(eB,"A",{href:!0});var e0t=s(Tj);Sbo=r(e0t,"ElectraTokenizer"),e0t.forEach(t),Rbo=r(eB," or "),Mj=n(eB,"A",{href:!0});var o0t=s(Mj);Pbo=r(o0t,"ElectraTokenizerFast"),o0t.forEach(t),Bbo=r(eB," (ELECTRA model)"),eB.forEach(t),Ibo=i(S),Es=n(S,"LI",{});var oB=s(Es);uge=n(oB,"STRONG",{});var r0t=s(uge);Nbo=r(r0t,"ernie"),r0t.forEach(t),qbo=r(oB," \u2014 "),Ej=n(oB,"A",{href:!0});var t0t=s(Ej);jbo=r(t0t,"BertTokenizer"),t0t.forEach(t),Dbo=r(oB," or "),Cj=n(oB,"A",{href:!0});var a0t=s(Cj);Gbo=r(a0t,"BertTokenizerFast"),a0t.forEach(t),Obo=r(oB," (ERNIE model)"),oB.forEach(t),Vbo=i(S),fu=n(S,"LI",{});var OBe=s(fu);pge=n(OBe,"STRONG",{});var n0t=s(pge);Xbo=r(n0t,"flaubert"),n0t.forEach(t),zbo=r(OBe," \u2014 "),wj=n(OBe,"A",{href:!0});var s0t=s(wj);Qbo=r(s0t,"FlaubertTokenizer"),s0t.forEach(t),Wbo=r(OBe," (FlauBERT model)"),OBe.forEach(t),Ubo=i(S),Cs=n(S,"LI",{});var rB=s(Cs);_ge=n(rB,"STRONG",{});var l0t=s(_ge);Hbo=r(l0t,"fnet"),l0t.forEach(t),Jbo=r(rB," \u2014 "),Aj=n(rB,"A",{href:!0});var i0t=s(Aj);Ybo=r(i0t,"FNetTokenizer"),i0t.forEach(t),Kbo=r(rB," or "),Lj=n(rB,"A",{href:!0});var d0t=s(Lj);Zbo=r(d0t,"FNetTokenizerFast"),d0t.forEach(t),evo=r(rB," (FNet model)"),rB.forEach(t),ovo=i(S),gu=n(S,"LI",{});var VBe=s(gu);bge=n(VBe,"STRONG",{});var m0t=s(bge);rvo=r(m0t,"fsmt"),m0t.forEach(t),tvo=r(VBe," \u2014 "),yj=n(VBe,"A",{href:!0});var c0t=s(yj);avo=r(c0t,"FSMTTokenizer"),c0t.forEach(t),nvo=r(VBe," (FairSeq Machine-Translation model)"),VBe.forEach(t),svo=i(S),ws=n(S,"LI",{});var tB=s(ws);vge=n(tB,"STRONG",{});var f0t=s(vge);lvo=r(f0t,"funnel"),f0t.forEach(t),ivo=r(tB," \u2014 "),xj=n(tB,"A",{href:!0});var g0t=s(xj);dvo=r(g0t,"FunnelTokenizer"),g0t.forEach(t),mvo=r(tB," or "),$j=n(tB,"A",{href:!0});var h0t=s($j);cvo=r(h0t,"FunnelTokenizerFast"),h0t.forEach(t),fvo=r(tB," (Funnel Transformer model)"),tB.forEach(t),gvo=i(S),As=n(S,"LI",{});var aB=s(As);Fge=n(aB,"STRONG",{});var u0t=s(Fge);hvo=r(u0t,"gpt2"),u0t.forEach(t),uvo=r(aB," \u2014 "),kj=n(aB,"A",{href:!0});var p0t=s(kj);pvo=r(p0t,"GPT2Tokenizer"),p0t.forEach(t),_vo=r(aB," or "),Sj=n(aB,"A",{href:!0});var _0t=s(Sj);bvo=r(_0t,"GPT2TokenizerFast"),_0t.forEach(t),vvo=r(aB," (OpenAI GPT-2 model)"),aB.forEach(t),Fvo=i(S),Ls=n(S,"LI",{});var nB=s(Ls);Tge=n(nB,"STRONG",{});var b0t=s(Tge);Tvo=r(b0t,"gpt_neo"),b0t.forEach(t),Mvo=r(nB," \u2014 "),Rj=n(nB,"A",{href:!0});var v0t=s(Rj);Evo=r(v0t,"GPT2Tokenizer"),v0t.forEach(t),Cvo=r(nB," or "),Pj=n(nB,"A",{href:!0});var F0t=s(Pj);wvo=r(F0t,"GPT2TokenizerFast"),F0t.forEach(t),Avo=r(nB," (GPT Neo model)"),nB.forEach(t),Lvo=i(S),hu=n(S,"LI",{});var XBe=s(hu);Mge=n(XBe,"STRONG",{});var T0t=s(Mge);yvo=r(T0t,"gpt_neox"),T0t.forEach(t),xvo=r(XBe," \u2014 "),Bj=n(XBe,"A",{href:!0});var M0t=s(Bj);$vo=r(M0t,"GPTNeoXTokenizerFast"),M0t.forEach(t),kvo=r(XBe," (GPT NeoX model)"),XBe.forEach(t),Svo=i(S),uu=n(S,"LI",{});var zBe=s(uu);Ege=n(zBe,"STRONG",{});var E0t=s(Ege);Rvo=r(E0t,"gpt_neox_japanese"),E0t.forEach(t),Pvo=r(zBe," \u2014 "),Ij=n(zBe,"A",{href:!0});var C0t=s(Ij);Bvo=r(C0t,"GPTNeoXJapaneseTokenizer"),C0t.forEach(t),Ivo=r(zBe," (GPT NeoX Japanese model)"),zBe.forEach(t),Nvo=i(S),ys=n(S,"LI",{});var sB=s(ys);Cge=n(sB,"STRONG",{});var w0t=s(Cge);qvo=r(w0t,"gptj"),w0t.forEach(t),jvo=r(sB," \u2014 "),Nj=n(sB,"A",{href:!0});var A0t=s(Nj);Dvo=r(A0t,"GPT2Tokenizer"),A0t.forEach(t),Gvo=r(sB," or "),qj=n(sB,"A",{href:!0});var L0t=s(qj);Ovo=r(L0t,"GPT2TokenizerFast"),L0t.forEach(t),Vvo=r(sB," (GPT-J model)"),sB.forEach(t),Xvo=i(S),xs=n(S,"LI",{});var lB=s(xs);wge=n(lB,"STRONG",{});var y0t=s(wge);zvo=r(y0t,"groupvit"),y0t.forEach(t),Qvo=r(lB," \u2014 "),jj=n(lB,"A",{href:!0});var x0t=s(jj);Wvo=r(x0t,"CLIPTokenizer"),x0t.forEach(t),Uvo=r(lB," or "),Dj=n(lB,"A",{href:!0});var $0t=s(Dj);Hvo=r($0t,"CLIPTokenizerFast"),$0t.forEach(t),Jvo=r(lB," (GroupViT model)"),lB.forEach(t),Yvo=i(S),$s=n(S,"LI",{});var iB=s($s);Age=n(iB,"STRONG",{});var k0t=s(Age);Kvo=r(k0t,"herbert"),k0t.forEach(t),Zvo=r(iB," \u2014 "),Gj=n(iB,"A",{href:!0});var S0t=s(Gj);eFo=r(S0t,"HerbertTokenizer"),S0t.forEach(t),oFo=r(iB," or "),Oj=n(iB,"A",{href:!0});var R0t=s(Oj);rFo=r(R0t,"HerbertTokenizerFast"),R0t.forEach(t),tFo=r(iB," (HerBERT model)"),iB.forEach(t),aFo=i(S),pu=n(S,"LI",{});var QBe=s(pu);Lge=n(QBe,"STRONG",{});var P0t=s(Lge);nFo=r(P0t,"hubert"),P0t.forEach(t),sFo=r(QBe," \u2014 "),Vj=n(QBe,"A",{href:!0});var B0t=s(Vj);lFo=r(B0t,"Wav2Vec2CTCTokenizer"),B0t.forEach(t),iFo=r(QBe," (Hubert model)"),QBe.forEach(t),dFo=i(S),ks=n(S,"LI",{});var dB=s(ks);yge=n(dB,"STRONG",{});var I0t=s(yge);mFo=r(I0t,"ibert"),I0t.forEach(t),cFo=r(dB," \u2014 "),Xj=n(dB,"A",{href:!0});var N0t=s(Xj);fFo=r(N0t,"RobertaTokenizer"),N0t.forEach(t),gFo=r(dB," or "),zj=n(dB,"A",{href:!0});var q0t=s(zj);hFo=r(q0t,"RobertaTokenizerFast"),q0t.forEach(t),uFo=r(dB," (I-BERT model)"),dB.forEach(t),pFo=i(S),Ss=n(S,"LI",{});var mB=s(Ss);xge=n(mB,"STRONG",{});var j0t=s(xge);_Fo=r(j0t,"layoutlm"),j0t.forEach(t),bFo=r(mB," \u2014 "),Qj=n(mB,"A",{href:!0});var D0t=s(Qj);vFo=r(D0t,"LayoutLMTokenizer"),D0t.forEach(t),FFo=r(mB," or "),Wj=n(mB,"A",{href:!0});var G0t=s(Wj);TFo=r(G0t,"LayoutLMTokenizerFast"),G0t.forEach(t),MFo=r(mB," (LayoutLM model)"),mB.forEach(t),EFo=i(S),Rs=n(S,"LI",{});var cB=s(Rs);$ge=n(cB,"STRONG",{});var O0t=s($ge);CFo=r(O0t,"layoutlmv2"),O0t.forEach(t),wFo=r(cB," \u2014 "),Uj=n(cB,"A",{href:!0});var V0t=s(Uj);AFo=r(V0t,"LayoutLMv2Tokenizer"),V0t.forEach(t),LFo=r(cB," or "),Hj=n(cB,"A",{href:!0});var X0t=s(Hj);yFo=r(X0t,"LayoutLMv2TokenizerFast"),X0t.forEach(t),xFo=r(cB," (LayoutLMv2 model)"),cB.forEach(t),$Fo=i(S),Ps=n(S,"LI",{});var fB=s(Ps);kge=n(fB,"STRONG",{});var z0t=s(kge);kFo=r(z0t,"layoutlmv3"),z0t.forEach(t),SFo=r(fB," \u2014 "),Jj=n(fB,"A",{href:!0});var Q0t=s(Jj);RFo=r(Q0t,"LayoutLMv3Tokenizer"),Q0t.forEach(t),PFo=r(fB," or "),Yj=n(fB,"A",{href:!0});var W0t=s(Yj);BFo=r(W0t,"LayoutLMv3TokenizerFast"),W0t.forEach(t),IFo=r(fB," (LayoutLMv3 model)"),fB.forEach(t),NFo=i(S),Bs=n(S,"LI",{});var gB=s(Bs);Sge=n(gB,"STRONG",{});var U0t=s(Sge);qFo=r(U0t,"layoutxlm"),U0t.forEach(t),jFo=r(gB," \u2014 "),Kj=n(gB,"A",{href:!0});var H0t=s(Kj);DFo=r(H0t,"LayoutXLMTokenizer"),H0t.forEach(t),GFo=r(gB," or "),Zj=n(gB,"A",{href:!0});var J0t=s(Zj);OFo=r(J0t,"LayoutXLMTokenizerFast"),J0t.forEach(t),VFo=r(gB," (LayoutXLM model)"),gB.forEach(t),XFo=i(S),Is=n(S,"LI",{});var hB=s(Is);Rge=n(hB,"STRONG",{});var Y0t=s(Rge);zFo=r(Y0t,"led"),Y0t.forEach(t),QFo=r(hB," \u2014 "),eD=n(hB,"A",{href:!0});var K0t=s(eD);WFo=r(K0t,"LEDTokenizer"),K0t.forEach(t),UFo=r(hB," or "),oD=n(hB,"A",{href:!0});var Z0t=s(oD);HFo=r(Z0t,"LEDTokenizerFast"),Z0t.forEach(t),JFo=r(hB," (LED model)"),hB.forEach(t),YFo=i(S),Ns=n(S,"LI",{});var uB=s(Ns);Pge=n(uB,"STRONG",{});var ewt=s(Pge);KFo=r(ewt,"longformer"),ewt.forEach(t),ZFo=r(uB," \u2014 "),rD=n(uB,"A",{href:!0});var owt=s(rD);eTo=r(owt,"LongformerTokenizer"),owt.forEach(t),oTo=r(uB," or "),tD=n(uB,"A",{href:!0});var rwt=s(tD);rTo=r(rwt,"LongformerTokenizerFast"),rwt.forEach(t),tTo=r(uB," (Longformer model)"),uB.forEach(t),aTo=i(S),qs=n(S,"LI",{});var pB=s(qs);Bge=n(pB,"STRONG",{});var twt=s(Bge);nTo=r(twt,"longt5"),twt.forEach(t),sTo=r(pB," \u2014 "),aD=n(pB,"A",{href:!0});var awt=s(aD);lTo=r(awt,"T5Tokenizer"),awt.forEach(t),iTo=r(pB," or "),nD=n(pB,"A",{href:!0});var nwt=s(nD);dTo=r(nwt,"T5TokenizerFast"),nwt.forEach(t),mTo=r(pB," (LongT5 model)"),pB.forEach(t),cTo=i(S),_u=n(S,"LI",{});var WBe=s(_u);Ige=n(WBe,"STRONG",{});var swt=s(Ige);fTo=r(swt,"luke"),swt.forEach(t),gTo=r(WBe," \u2014 "),sD=n(WBe,"A",{href:!0});var lwt=s(sD);hTo=r(lwt,"LukeTokenizer"),lwt.forEach(t),uTo=r(WBe," (LUKE model)"),WBe.forEach(t),pTo=i(S),js=n(S,"LI",{});var _B=s(js);Nge=n(_B,"STRONG",{});var iwt=s(Nge);_To=r(iwt,"lxmert"),iwt.forEach(t),bTo=r(_B," \u2014 "),lD=n(_B,"A",{href:!0});var dwt=s(lD);vTo=r(dwt,"LxmertTokenizer"),dwt.forEach(t),FTo=r(_B," or "),iD=n(_B,"A",{href:!0});var mwt=s(iD);TTo=r(mwt,"LxmertTokenizerFast"),mwt.forEach(t),MTo=r(_B," (LXMERT model)"),_B.forEach(t),ETo=i(S),bu=n(S,"LI",{});var UBe=s(bu);qge=n(UBe,"STRONG",{});var cwt=s(qge);CTo=r(cwt,"m2m_100"),cwt.forEach(t),wTo=r(UBe," \u2014 "),dD=n(UBe,"A",{href:!0});var fwt=s(dD);ATo=r(fwt,"M2M100Tokenizer"),fwt.forEach(t),LTo=r(UBe," (M2M100 model)"),UBe.forEach(t),yTo=i(S),vu=n(S,"LI",{});var HBe=s(vu);jge=n(HBe,"STRONG",{});var gwt=s(jge);xTo=r(gwt,"marian"),gwt.forEach(t),$To=r(HBe," \u2014 "),mD=n(HBe,"A",{href:!0});var hwt=s(mD);kTo=r(hwt,"MarianTokenizer"),hwt.forEach(t),STo=r(HBe," (Marian model)"),HBe.forEach(t),RTo=i(S),Ds=n(S,"LI",{});var bB=s(Ds);Dge=n(bB,"STRONG",{});var uwt=s(Dge);PTo=r(uwt,"mbart"),uwt.forEach(t),BTo=r(bB," \u2014 "),cD=n(bB,"A",{href:!0});var pwt=s(cD);ITo=r(pwt,"MBartTokenizer"),pwt.forEach(t),NTo=r(bB," or "),fD=n(bB,"A",{href:!0});var _wt=s(fD);qTo=r(_wt,"MBartTokenizerFast"),_wt.forEach(t),jTo=r(bB," (mBART model)"),bB.forEach(t),DTo=i(S),Gs=n(S,"LI",{});var vB=s(Gs);Gge=n(vB,"STRONG",{});var bwt=s(Gge);GTo=r(bwt,"mbart50"),bwt.forEach(t),OTo=r(vB," \u2014 "),gD=n(vB,"A",{href:!0});var vwt=s(gD);VTo=r(vwt,"MBart50Tokenizer"),vwt.forEach(t),XTo=r(vB," or "),hD=n(vB,"A",{href:!0});var Fwt=s(hD);zTo=r(Fwt,"MBart50TokenizerFast"),Fwt.forEach(t),QTo=r(vB," (mBART-50 model)"),vB.forEach(t),WTo=i(S),Os=n(S,"LI",{});var FB=s(Os);Oge=n(FB,"STRONG",{});var Twt=s(Oge);UTo=r(Twt,"megatron-bert"),Twt.forEach(t),HTo=r(FB," \u2014 "),uD=n(FB,"A",{href:!0});var Mwt=s(uD);JTo=r(Mwt,"BertTokenizer"),Mwt.forEach(t),YTo=r(FB," or "),pD=n(FB,"A",{href:!0});var Ewt=s(pD);KTo=r(Ewt,"BertTokenizerFast"),Ewt.forEach(t),ZTo=r(FB," (Megatron-BERT model)"),FB.forEach(t),eMo=i(S),Fu=n(S,"LI",{});var JBe=s(Fu);Vge=n(JBe,"STRONG",{});var Cwt=s(Vge);oMo=r(Cwt,"mluke"),Cwt.forEach(t),rMo=r(JBe," \u2014 "),_D=n(JBe,"A",{href:!0});var wwt=s(_D);tMo=r(wwt,"MLukeTokenizer"),wwt.forEach(t),aMo=r(JBe," (mLUKE model)"),JBe.forEach(t),nMo=i(S),Vs=n(S,"LI",{});var TB=s(Vs);Xge=n(TB,"STRONG",{});var Awt=s(Xge);sMo=r(Awt,"mobilebert"),Awt.forEach(t),lMo=r(TB," \u2014 "),bD=n(TB,"A",{href:!0});var Lwt=s(bD);iMo=r(Lwt,"MobileBertTokenizer"),Lwt.forEach(t),dMo=r(TB," or "),vD=n(TB,"A",{href:!0});var ywt=s(vD);mMo=r(ywt,"MobileBertTokenizerFast"),ywt.forEach(t),cMo=r(TB," (MobileBERT model)"),TB.forEach(t),fMo=i(S),Xs=n(S,"LI",{});var MB=s(Xs);zge=n(MB,"STRONG",{});var xwt=s(zge);gMo=r(xwt,"mpnet"),xwt.forEach(t),hMo=r(MB," \u2014 "),FD=n(MB,"A",{href:!0});var $wt=s(FD);uMo=r($wt,"MPNetTokenizer"),$wt.forEach(t),pMo=r(MB," or "),TD=n(MB,"A",{href:!0});var kwt=s(TD);_Mo=r(kwt,"MPNetTokenizerFast"),kwt.forEach(t),bMo=r(MB," (MPNet model)"),MB.forEach(t),vMo=i(S),zs=n(S,"LI",{});var EB=s(zs);Qge=n(EB,"STRONG",{});var Swt=s(Qge);FMo=r(Swt,"mt5"),Swt.forEach(t),TMo=r(EB," \u2014 "),MD=n(EB,"A",{href:!0});var Rwt=s(MD);MMo=r(Rwt,"MT5Tokenizer"),Rwt.forEach(t),EMo=r(EB," or "),ED=n(EB,"A",{href:!0});var Pwt=s(ED);CMo=r(Pwt,"MT5TokenizerFast"),Pwt.forEach(t),wMo=r(EB," (MT5 model)"),EB.forEach(t),AMo=i(S),Qs=n(S,"LI",{});var CB=s(Qs);Wge=n(CB,"STRONG",{});var Bwt=s(Wge);LMo=r(Bwt,"mvp"),Bwt.forEach(t),yMo=r(CB," \u2014 "),CD=n(CB,"A",{href:!0});var Iwt=s(CD);xMo=r(Iwt,"MvpTokenizer"),Iwt.forEach(t),$Mo=r(CB," or "),wD=n(CB,"A",{href:!0});var Nwt=s(wD);kMo=r(Nwt,"MvpTokenizerFast"),Nwt.forEach(t),SMo=r(CB," (MVP model)"),CB.forEach(t),RMo=i(S),Ws=n(S,"LI",{});var wB=s(Ws);Uge=n(wB,"STRONG",{});var qwt=s(Uge);PMo=r(qwt,"nezha"),qwt.forEach(t),BMo=r(wB," \u2014 "),AD=n(wB,"A",{href:!0});var jwt=s(AD);IMo=r(jwt,"BertTokenizer"),jwt.forEach(t),NMo=r(wB," or "),LD=n(wB,"A",{href:!0});var Dwt=s(LD);qMo=r(Dwt,"BertTokenizerFast"),Dwt.forEach(t),jMo=r(wB," (Nezha model)"),wB.forEach(t),DMo=i(S),Us=n(S,"LI",{});var AB=s(Us);Hge=n(AB,"STRONG",{});var Gwt=s(Hge);GMo=r(Gwt,"nllb"),Gwt.forEach(t),OMo=r(AB," \u2014 "),yD=n(AB,"A",{href:!0});var Owt=s(yD);VMo=r(Owt,"NllbTokenizer"),Owt.forEach(t),XMo=r(AB," or "),xD=n(AB,"A",{href:!0});var Vwt=s(xD);zMo=r(Vwt,"NllbTokenizerFast"),Vwt.forEach(t),QMo=r(AB," (NLLB model)"),AB.forEach(t),WMo=i(S),Hs=n(S,"LI",{});var LB=s(Hs);Jge=n(LB,"STRONG",{});var Xwt=s(Jge);UMo=r(Xwt,"nystromformer"),Xwt.forEach(t),HMo=r(LB," \u2014 "),$D=n(LB,"A",{href:!0});var zwt=s($D);JMo=r(zwt,"AlbertTokenizer"),zwt.forEach(t),YMo=r(LB," or "),kD=n(LB,"A",{href:!0});var Qwt=s(kD);KMo=r(Qwt,"AlbertTokenizerFast"),Qwt.forEach(t),ZMo=r(LB," (Nystr\xF6mformer model)"),LB.forEach(t),eEo=i(S),Js=n(S,"LI",{});var yB=s(Js);Yge=n(yB,"STRONG",{});var Wwt=s(Yge);oEo=r(Wwt,"openai-gpt"),Wwt.forEach(t),rEo=r(yB," \u2014 "),SD=n(yB,"A",{href:!0});var Uwt=s(SD);tEo=r(Uwt,"OpenAIGPTTokenizer"),Uwt.forEach(t),aEo=r(yB," or "),RD=n(yB,"A",{href:!0});var Hwt=s(RD);nEo=r(Hwt,"OpenAIGPTTokenizerFast"),Hwt.forEach(t),sEo=r(yB," (OpenAI GPT model)"),yB.forEach(t),lEo=i(S),Tu=n(S,"LI",{});var YBe=s(Tu);Kge=n(YBe,"STRONG",{});var Jwt=s(Kge);iEo=r(Jwt,"opt"),Jwt.forEach(t),dEo=r(YBe," \u2014 "),PD=n(YBe,"A",{href:!0});var Ywt=s(PD);mEo=r(Ywt,"GPT2Tokenizer"),Ywt.forEach(t),cEo=r(YBe," (OPT model)"),YBe.forEach(t),fEo=i(S),Ys=n(S,"LI",{});var xB=s(Ys);Zge=n(xB,"STRONG",{});var Kwt=s(Zge);gEo=r(Kwt,"owlvit"),Kwt.forEach(t),hEo=r(xB," \u2014 "),BD=n(xB,"A",{href:!0});var Zwt=s(BD);uEo=r(Zwt,"CLIPTokenizer"),Zwt.forEach(t),pEo=r(xB," or "),ID=n(xB,"A",{href:!0});var eAt=s(ID);_Eo=r(eAt,"CLIPTokenizerFast"),eAt.forEach(t),bEo=r(xB," (OWL-ViT model)"),xB.forEach(t),vEo=i(S),Ks=n(S,"LI",{});var $B=s(Ks);ehe=n($B,"STRONG",{});var oAt=s(ehe);FEo=r(oAt,"pegasus"),oAt.forEach(t),TEo=r($B," \u2014 "),ND=n($B,"A",{href:!0});var rAt=s(ND);MEo=r(rAt,"PegasusTokenizer"),rAt.forEach(t),EEo=r($B," or "),qD=n($B,"A",{href:!0});var tAt=s(qD);CEo=r(tAt,"PegasusTokenizerFast"),tAt.forEach(t),wEo=r($B," (Pegasus model)"),$B.forEach(t),AEo=i(S),Mu=n(S,"LI",{});var KBe=s(Mu);ohe=n(KBe,"STRONG",{});var aAt=s(ohe);LEo=r(aAt,"perceiver"),aAt.forEach(t),yEo=r(KBe," \u2014 "),jD=n(KBe,"A",{href:!0});var nAt=s(jD);xEo=r(nAt,"PerceiverTokenizer"),nAt.forEach(t),$Eo=r(KBe," (Perceiver model)"),KBe.forEach(t),kEo=i(S),Eu=n(S,"LI",{});var ZBe=s(Eu);rhe=n(ZBe,"STRONG",{});var sAt=s(rhe);SEo=r(sAt,"phobert"),sAt.forEach(t),REo=r(ZBe," \u2014 "),DD=n(ZBe,"A",{href:!0});var lAt=s(DD);PEo=r(lAt,"PhobertTokenizer"),lAt.forEach(t),BEo=r(ZBe," (PhoBERT model)"),ZBe.forEach(t),IEo=i(S),Cu=n(S,"LI",{});var eIe=s(Cu);the=n(eIe,"STRONG",{});var iAt=s(the);NEo=r(iAt,"plbart"),iAt.forEach(t),qEo=r(eIe," \u2014 "),GD=n(eIe,"A",{href:!0});var dAt=s(GD);jEo=r(dAt,"PLBartTokenizer"),dAt.forEach(t),DEo=r(eIe," (PLBart model)"),eIe.forEach(t),GEo=i(S),wu=n(S,"LI",{});var oIe=s(wu);ahe=n(oIe,"STRONG",{});var mAt=s(ahe);OEo=r(mAt,"prophetnet"),mAt.forEach(t),VEo=r(oIe," \u2014 "),OD=n(oIe,"A",{href:!0});var cAt=s(OD);XEo=r(cAt,"ProphetNetTokenizer"),cAt.forEach(t),zEo=r(oIe," (ProphetNet model)"),oIe.forEach(t),QEo=i(S),Zs=n(S,"LI",{});var kB=s(Zs);nhe=n(kB,"STRONG",{});var fAt=s(nhe);WEo=r(fAt,"qdqbert"),fAt.forEach(t),UEo=r(kB," \u2014 "),VD=n(kB,"A",{href:!0});var gAt=s(VD);HEo=r(gAt,"BertTokenizer"),gAt.forEach(t),JEo=r(kB," or "),XD=n(kB,"A",{href:!0});var hAt=s(XD);YEo=r(hAt,"BertTokenizerFast"),hAt.forEach(t),KEo=r(kB," (QDQBert model)"),kB.forEach(t),ZEo=i(S),Au=n(S,"LI",{});var rIe=s(Au);she=n(rIe,"STRONG",{});var uAt=s(she);e4o=r(uAt,"rag"),uAt.forEach(t),o4o=r(rIe," \u2014 "),zD=n(rIe,"A",{href:!0});var pAt=s(zD);r4o=r(pAt,"RagTokenizer"),pAt.forEach(t),t4o=r(rIe," (RAG model)"),rIe.forEach(t),a4o=i(S),el=n(S,"LI",{});var SB=s(el);lhe=n(SB,"STRONG",{});var _At=s(lhe);n4o=r(_At,"realm"),_At.forEach(t),s4o=r(SB," \u2014 "),QD=n(SB,"A",{href:!0});var bAt=s(QD);l4o=r(bAt,"RealmTokenizer"),bAt.forEach(t),i4o=r(SB," or "),WD=n(SB,"A",{href:!0});var vAt=s(WD);d4o=r(vAt,"RealmTokenizerFast"),vAt.forEach(t),m4o=r(SB," (REALM model)"),SB.forEach(t),c4o=i(S),ol=n(S,"LI",{});var RB=s(ol);ihe=n(RB,"STRONG",{});var FAt=s(ihe);f4o=r(FAt,"reformer"),FAt.forEach(t),g4o=r(RB," \u2014 "),UD=n(RB,"A",{href:!0});var TAt=s(UD);h4o=r(TAt,"ReformerTokenizer"),TAt.forEach(t),u4o=r(RB," or "),HD=n(RB,"A",{href:!0});var MAt=s(HD);p4o=r(MAt,"ReformerTokenizerFast"),MAt.forEach(t),_4o=r(RB," (Reformer model)"),RB.forEach(t),b4o=i(S),rl=n(S,"LI",{});var PB=s(rl);dhe=n(PB,"STRONG",{});var EAt=s(dhe);v4o=r(EAt,"rembert"),EAt.forEach(t),F4o=r(PB," \u2014 "),JD=n(PB,"A",{href:!0});var CAt=s(JD);T4o=r(CAt,"RemBertTokenizer"),CAt.forEach(t),M4o=r(PB," or "),YD=n(PB,"A",{href:!0});var wAt=s(YD);E4o=r(wAt,"RemBertTokenizerFast"),wAt.forEach(t),C4o=r(PB," (RemBERT model)"),PB.forEach(t),w4o=i(S),tl=n(S,"LI",{});var BB=s(tl);mhe=n(BB,"STRONG",{});var AAt=s(mhe);A4o=r(AAt,"retribert"),AAt.forEach(t),L4o=r(BB," \u2014 "),KD=n(BB,"A",{href:!0});var LAt=s(KD);y4o=r(LAt,"RetriBertTokenizer"),LAt.forEach(t),x4o=r(BB," or "),ZD=n(BB,"A",{href:!0});var yAt=s(ZD);$4o=r(yAt,"RetriBertTokenizerFast"),yAt.forEach(t),k4o=r(BB," (RetriBERT model)"),BB.forEach(t),S4o=i(S),al=n(S,"LI",{});var IB=s(al);che=n(IB,"STRONG",{});var xAt=s(che);R4o=r(xAt,"roberta"),xAt.forEach(t),P4o=r(IB," \u2014 "),eG=n(IB,"A",{href:!0});var $At=s(eG);B4o=r($At,"RobertaTokenizer"),$At.forEach(t),I4o=r(IB," or "),oG=n(IB,"A",{href:!0});var kAt=s(oG);N4o=r(kAt,"RobertaTokenizerFast"),kAt.forEach(t),q4o=r(IB," (RoBERTa model)"),IB.forEach(t),j4o=i(S),nl=n(S,"LI",{});var NB=s(nl);fhe=n(NB,"STRONG",{});var SAt=s(fhe);D4o=r(SAt,"roformer"),SAt.forEach(t),G4o=r(NB," \u2014 "),rG=n(NB,"A",{href:!0});var RAt=s(rG);O4o=r(RAt,"RoFormerTokenizer"),RAt.forEach(t),V4o=r(NB," or "),tG=n(NB,"A",{href:!0});var PAt=s(tG);X4o=r(PAt,"RoFormerTokenizerFast"),PAt.forEach(t),z4o=r(NB," (RoFormer model)"),NB.forEach(t),Q4o=i(S),Lu=n(S,"LI",{});var tIe=s(Lu);ghe=n(tIe,"STRONG",{});var BAt=s(ghe);W4o=r(BAt,"speech_to_text"),BAt.forEach(t),U4o=r(tIe," \u2014 "),aG=n(tIe,"A",{href:!0});var IAt=s(aG);H4o=r(IAt,"Speech2TextTokenizer"),IAt.forEach(t),J4o=r(tIe," (Speech2Text model)"),tIe.forEach(t),Y4o=i(S),yu=n(S,"LI",{});var aIe=s(yu);hhe=n(aIe,"STRONG",{});var NAt=s(hhe);K4o=r(NAt,"speech_to_text_2"),NAt.forEach(t),Z4o=r(aIe," \u2014 "),nG=n(aIe,"A",{href:!0});var qAt=s(nG);eCo=r(qAt,"Speech2Text2Tokenizer"),qAt.forEach(t),oCo=r(aIe," (Speech2Text2 model)"),aIe.forEach(t),rCo=i(S),sl=n(S,"LI",{});var qB=s(sl);uhe=n(qB,"STRONG",{});var jAt=s(uhe);tCo=r(jAt,"splinter"),jAt.forEach(t),aCo=r(qB," \u2014 "),sG=n(qB,"A",{href:!0});var DAt=s(sG);nCo=r(DAt,"SplinterTokenizer"),DAt.forEach(t),sCo=r(qB," or "),lG=n(qB,"A",{href:!0});var GAt=s(lG);lCo=r(GAt,"SplinterTokenizerFast"),GAt.forEach(t),iCo=r(qB," (Splinter model)"),qB.forEach(t),dCo=i(S),ll=n(S,"LI",{});var jB=s(ll);phe=n(jB,"STRONG",{});var OAt=s(phe);mCo=r(OAt,"squeezebert"),OAt.forEach(t),cCo=r(jB," \u2014 "),iG=n(jB,"A",{href:!0});var VAt=s(iG);fCo=r(VAt,"SqueezeBertTokenizer"),VAt.forEach(t),gCo=r(jB," or "),dG=n(jB,"A",{href:!0});var XAt=s(dG);hCo=r(XAt,"SqueezeBertTokenizerFast"),XAt.forEach(t),uCo=r(jB," (SqueezeBERT model)"),jB.forEach(t),pCo=i(S),il=n(S,"LI",{});var DB=s(il);_he=n(DB,"STRONG",{});var zAt=s(_he);_Co=r(zAt,"t5"),zAt.forEach(t),bCo=r(DB," \u2014 "),mG=n(DB,"A",{href:!0});var QAt=s(mG);vCo=r(QAt,"T5Tokenizer"),QAt.forEach(t),FCo=r(DB," or "),cG=n(DB,"A",{href:!0});var WAt=s(cG);TCo=r(WAt,"T5TokenizerFast"),WAt.forEach(t),MCo=r(DB," (T5 model)"),DB.forEach(t),ECo=i(S),xu=n(S,"LI",{});var nIe=s(xu);bhe=n(nIe,"STRONG",{});var UAt=s(bhe);CCo=r(UAt,"tapas"),UAt.forEach(t),wCo=r(nIe," \u2014 "),fG=n(nIe,"A",{href:!0});var HAt=s(fG);ACo=r(HAt,"TapasTokenizer"),HAt.forEach(t),LCo=r(nIe," (TAPAS model)"),nIe.forEach(t),yCo=i(S),$u=n(S,"LI",{});var sIe=s($u);vhe=n(sIe,"STRONG",{});var JAt=s(vhe);xCo=r(JAt,"tapex"),JAt.forEach(t),$Co=r(sIe," \u2014 "),gG=n(sIe,"A",{href:!0});var YAt=s(gG);kCo=r(YAt,"TapexTokenizer"),YAt.forEach(t),SCo=r(sIe," (TAPEX model)"),sIe.forEach(t),RCo=i(S),ku=n(S,"LI",{});var lIe=s(ku);Fhe=n(lIe,"STRONG",{});var KAt=s(Fhe);PCo=r(KAt,"transfo-xl"),KAt.forEach(t),BCo=r(lIe," \u2014 "),hG=n(lIe,"A",{href:!0});var ZAt=s(hG);ICo=r(ZAt,"TransfoXLTokenizer"),ZAt.forEach(t),NCo=r(lIe," (Transformer-XL model)"),lIe.forEach(t),qCo=i(S),dl=n(S,"LI",{});var GB=s(dl);The=n(GB,"STRONG",{});var e6t=s(The);jCo=r(e6t,"vilt"),e6t.forEach(t),DCo=r(GB," \u2014 "),uG=n(GB,"A",{href:!0});var o6t=s(uG);GCo=r(o6t,"BertTokenizer"),o6t.forEach(t),OCo=r(GB," or "),pG=n(GB,"A",{href:!0});var r6t=s(pG);VCo=r(r6t,"BertTokenizerFast"),r6t.forEach(t),XCo=r(GB," (ViLT model)"),GB.forEach(t),zCo=i(S),ml=n(S,"LI",{});var OB=s(ml);Mhe=n(OB,"STRONG",{});var t6t=s(Mhe);QCo=r(t6t,"visual_bert"),t6t.forEach(t),WCo=r(OB," \u2014 "),_G=n(OB,"A",{href:!0});var a6t=s(_G);UCo=r(a6t,"BertTokenizer"),a6t.forEach(t),HCo=r(OB," or "),bG=n(OB,"A",{href:!0});var n6t=s(bG);JCo=r(n6t,"BertTokenizerFast"),n6t.forEach(t),YCo=r(OB," (VisualBERT model)"),OB.forEach(t),KCo=i(S),Su=n(S,"LI",{});var iIe=s(Su);Ehe=n(iIe,"STRONG",{});var s6t=s(Ehe);ZCo=r(s6t,"wav2vec2"),s6t.forEach(t),e3o=r(iIe," \u2014 "),vG=n(iIe,"A",{href:!0});var l6t=s(vG);o3o=r(l6t,"Wav2Vec2CTCTokenizer"),l6t.forEach(t),r3o=r(iIe," (Wav2Vec2 model)"),iIe.forEach(t),t3o=i(S),Ru=n(S,"LI",{});var dIe=s(Ru);Che=n(dIe,"STRONG",{});var i6t=s(Che);a3o=r(i6t,"wav2vec2-conformer"),i6t.forEach(t),n3o=r(dIe," \u2014 "),FG=n(dIe,"A",{href:!0});var d6t=s(FG);s3o=r(d6t,"Wav2Vec2CTCTokenizer"),d6t.forEach(t),l3o=r(dIe," (Wav2Vec2-Conformer model)"),dIe.forEach(t),i3o=i(S),Pu=n(S,"LI",{});var mIe=s(Pu);whe=n(mIe,"STRONG",{});var m6t=s(whe);d3o=r(m6t,"wav2vec2_phoneme"),m6t.forEach(t),m3o=r(mIe," \u2014 "),TG=n(mIe,"A",{href:!0});var c6t=s(TG);c3o=r(c6t,"Wav2Vec2PhonemeCTCTokenizer"),c6t.forEach(t),f3o=r(mIe," (Wav2Vec2Phoneme model)"),mIe.forEach(t),g3o=i(S),cl=n(S,"LI",{});var VB=s(cl);Ahe=n(VB,"STRONG",{});var f6t=s(Ahe);h3o=r(f6t,"xclip"),f6t.forEach(t),u3o=r(VB," \u2014 "),MG=n(VB,"A",{href:!0});var g6t=s(MG);p3o=r(g6t,"CLIPTokenizer"),g6t.forEach(t),_3o=r(VB," or "),EG=n(VB,"A",{href:!0});var h6t=s(EG);b3o=r(h6t,"CLIPTokenizerFast"),h6t.forEach(t),v3o=r(VB," (X-CLIP model)"),VB.forEach(t),F3o=i(S),fl=n(S,"LI",{});var XB=s(fl);Lhe=n(XB,"STRONG",{});var u6t=s(Lhe);T3o=r(u6t,"xglm"),u6t.forEach(t),M3o=r(XB," \u2014 "),CG=n(XB,"A",{href:!0});var p6t=s(CG);E3o=r(p6t,"XGLMTokenizer"),p6t.forEach(t),C3o=r(XB," or "),wG=n(XB,"A",{href:!0});var _6t=s(wG);w3o=r(_6t,"XGLMTokenizerFast"),_6t.forEach(t),A3o=r(XB," (XGLM model)"),XB.forEach(t),L3o=i(S),Bu=n(S,"LI",{});var cIe=s(Bu);yhe=n(cIe,"STRONG",{});var b6t=s(yhe);y3o=r(b6t,"xlm"),b6t.forEach(t),x3o=r(cIe," \u2014 "),AG=n(cIe,"A",{href:!0});var v6t=s(AG);$3o=r(v6t,"XLMTokenizer"),v6t.forEach(t),k3o=r(cIe," (XLM model)"),cIe.forEach(t),S3o=i(S),Iu=n(S,"LI",{});var fIe=s(Iu);xhe=n(fIe,"STRONG",{});var F6t=s(xhe);R3o=r(F6t,"xlm-prophetnet"),F6t.forEach(t),P3o=r(fIe," \u2014 "),LG=n(fIe,"A",{href:!0});var T6t=s(LG);B3o=r(T6t,"XLMProphetNetTokenizer"),T6t.forEach(t),I3o=r(fIe," (XLM-ProphetNet model)"),fIe.forEach(t),N3o=i(S),gl=n(S,"LI",{});var zB=s(gl);$he=n(zB,"STRONG",{});var M6t=s($he);q3o=r(M6t,"xlm-roberta"),M6t.forEach(t),j3o=r(zB," \u2014 "),yG=n(zB,"A",{href:!0});var E6t=s(yG);D3o=r(E6t,"XLMRobertaTokenizer"),E6t.forEach(t),G3o=r(zB," or "),xG=n(zB,"A",{href:!0});var C6t=s(xG);O3o=r(C6t,"XLMRobertaTokenizerFast"),C6t.forEach(t),V3o=r(zB," (XLM-RoBERTa model)"),zB.forEach(t),X3o=i(S),hl=n(S,"LI",{});var QB=s(hl);khe=n(QB,"STRONG",{});var w6t=s(khe);z3o=r(w6t,"xlm-roberta-xl"),w6t.forEach(t),Q3o=r(QB," \u2014 "),$G=n(QB,"A",{href:!0});var A6t=s($G);W3o=r(A6t,"XLMRobertaTokenizer"),A6t.forEach(t),U3o=r(QB," or "),kG=n(QB,"A",{href:!0});var L6t=s(kG);H3o=r(L6t,"XLMRobertaTokenizerFast"),L6t.forEach(t),J3o=r(QB," (XLM-RoBERTa-XL model)"),QB.forEach(t),Y3o=i(S),ul=n(S,"LI",{});var WB=s(ul);She=n(WB,"STRONG",{});var y6t=s(She);K3o=r(y6t,"xlnet"),y6t.forEach(t),Z3o=r(WB," \u2014 "),SG=n(WB,"A",{href:!0});var x6t=s(SG);e5o=r(x6t,"XLNetTokenizer"),x6t.forEach(t),o5o=r(WB," or "),RG=n(WB,"A",{href:!0});var $6t=s(RG);r5o=r($6t,"XLNetTokenizerFast"),$6t.forEach(t),t5o=r(WB," (XLNet model)"),WB.forEach(t),a5o=i(S),pl=n(S,"LI",{});var UB=s(pl);Rhe=n(UB,"STRONG",{});var k6t=s(Rhe);n5o=r(k6t,"yoso"),k6t.forEach(t),s5o=r(UB," \u2014 "),PG=n(UB,"A",{href:!0});var S6t=s(PG);l5o=r(S6t,"AlbertTokenizer"),S6t.forEach(t),i5o=r(UB," or "),BG=n(UB,"A",{href:!0});var R6t=s(BG);d5o=r(R6t,"AlbertTokenizerFast"),R6t.forEach(t),m5o=r(UB," (YOSO model)"),UB.forEach(t),S.forEach(t),c5o=i(El),T(Nu.$$.fragment,El),El.forEach(t),f5o=i(Ml),qu=n(Ml,"DIV",{class:!0});var aro=s(qu);T(gx.$$.fragment,aro),g5o=i(aro),Phe=n(aro,"P",{});var P6t=s(Phe);h5o=r(P6t,"Register a new tokenizer in this mapping."),P6t.forEach(t),aro.forEach(t),Ml.forEach(t),HZe=i(c),hd=n(c,"H2",{class:!0});var nro=s(hd);ju=n(nro,"A",{id:!0,class:!0,href:!0});var B6t=s(ju);Bhe=n(B6t,"SPAN",{});var I6t=s(Bhe);T(hx.$$.fragment,I6t),I6t.forEach(t),B6t.forEach(t),u5o=i(nro),Ihe=n(nro,"SPAN",{});var N6t=s(Ihe);p5o=r(N6t,"AutoFeatureExtractor"),N6t.forEach(t),nro.forEach(t),JZe=i(c),So=n(c,"DIV",{class:!0});var Cl=s(So);T(ux.$$.fragment,Cl),_5o=i(Cl),px=n(Cl,"P",{});var sro=s(px);b5o=r(sro,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),IG=n(sro,"A",{href:!0});var q6t=s(IG);v5o=r(q6t,"AutoFeatureExtractor.from_pretrained()"),q6t.forEach(t),F5o=r(sro," class method."),sro.forEach(t),T5o=i(Cl),_x=n(Cl,"P",{});var lro=s(_x);M5o=r(lro,"This class cannot be instantiated directly using "),Nhe=n(lro,"CODE",{});var j6t=s(Nhe);E5o=r(j6t,"__init__()"),j6t.forEach(t),C5o=r(lro," (throws an error)."),lro.forEach(t),w5o=i(Cl),Ye=n(Cl,"DIV",{class:!0});var ba=s(Ye);T(bx.$$.fragment,ba),A5o=i(ba),qhe=n(ba,"P",{});var D6t=s(qhe);L5o=r(D6t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),D6t.forEach(t),y5o=i(ba),Ha=n(ba,"P",{});var Wy=s(Ha);x5o=r(Wy,"The feature extractor class to instantiate is selected based on the "),jhe=n(Wy,"CODE",{});var G6t=s(jhe);$5o=r(G6t,"model_type"),G6t.forEach(t),k5o=r(Wy,` property of the config object
(either passed as an argument or loaded from `),Dhe=n(Wy,"CODE",{});var O6t=s(Dhe);S5o=r(O6t,"pretrained_model_name_or_path"),O6t.forEach(t),R5o=r(Wy,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ghe=n(Wy,"CODE",{});var V6t=s(Ghe);P5o=r(V6t,"pretrained_model_name_or_path"),V6t.forEach(t),B5o=r(Wy,":"),Wy.forEach(t),I5o=i(ba),z=n(ba,"UL",{});var W=s(z);Du=n(W,"LI",{});var gIe=s(Du);Ohe=n(gIe,"STRONG",{});var X6t=s(Ohe);N5o=r(X6t,"beit"),X6t.forEach(t),q5o=r(gIe," \u2014 "),NG=n(gIe,"A",{href:!0});var z6t=s(NG);j5o=r(z6t,"BeitFeatureExtractor"),z6t.forEach(t),D5o=r(gIe," (BEiT model)"),gIe.forEach(t),G5o=i(W),Gu=n(W,"LI",{});var hIe=s(Gu);Vhe=n(hIe,"STRONG",{});var Q6t=s(Vhe);O5o=r(Q6t,"clip"),Q6t.forEach(t),V5o=r(hIe," \u2014 "),qG=n(hIe,"A",{href:!0});var W6t=s(qG);X5o=r(W6t,"CLIPFeatureExtractor"),W6t.forEach(t),z5o=r(hIe," (CLIP model)"),hIe.forEach(t),Q5o=i(W),Ou=n(W,"LI",{});var uIe=s(Ou);Xhe=n(uIe,"STRONG",{});var U6t=s(Xhe);W5o=r(U6t,"conditional_detr"),U6t.forEach(t),U5o=r(uIe," \u2014 "),jG=n(uIe,"A",{href:!0});var H6t=s(jG);H5o=r(H6t,"ConditionalDetrFeatureExtractor"),H6t.forEach(t),J5o=r(uIe," (Conditional DETR model)"),uIe.forEach(t),Y5o=i(W),Vu=n(W,"LI",{});var pIe=s(Vu);zhe=n(pIe,"STRONG",{});var J6t=s(zhe);K5o=r(J6t,"convnext"),J6t.forEach(t),Z5o=r(pIe," \u2014 "),DG=n(pIe,"A",{href:!0});var Y6t=s(DG);e0o=r(Y6t,"ConvNextFeatureExtractor"),Y6t.forEach(t),o0o=r(pIe," (ConvNeXT model)"),pIe.forEach(t),r0o=i(W),Xu=n(W,"LI",{});var _Ie=s(Xu);Qhe=n(_Ie,"STRONG",{});var K6t=s(Qhe);t0o=r(K6t,"cvt"),K6t.forEach(t),a0o=r(_Ie," \u2014 "),GG=n(_Ie,"A",{href:!0});var Z6t=s(GG);n0o=r(Z6t,"ConvNextFeatureExtractor"),Z6t.forEach(t),s0o=r(_Ie," (CvT model)"),_Ie.forEach(t),l0o=i(W),zu=n(W,"LI",{});var bIe=s(zu);Whe=n(bIe,"STRONG",{});var e7t=s(Whe);i0o=r(e7t,"data2vec-audio"),e7t.forEach(t),d0o=r(bIe," \u2014 "),OG=n(bIe,"A",{href:!0});var o7t=s(OG);m0o=r(o7t,"Wav2Vec2FeatureExtractor"),o7t.forEach(t),c0o=r(bIe," (Data2VecAudio model)"),bIe.forEach(t),f0o=i(W),Qu=n(W,"LI",{});var vIe=s(Qu);Uhe=n(vIe,"STRONG",{});var r7t=s(Uhe);g0o=r(r7t,"data2vec-vision"),r7t.forEach(t),h0o=r(vIe," \u2014 "),VG=n(vIe,"A",{href:!0});var t7t=s(VG);u0o=r(t7t,"BeitFeatureExtractor"),t7t.forEach(t),p0o=r(vIe," (Data2VecVision model)"),vIe.forEach(t),_0o=i(W),Wu=n(W,"LI",{});var FIe=s(Wu);Hhe=n(FIe,"STRONG",{});var a7t=s(Hhe);b0o=r(a7t,"deformable_detr"),a7t.forEach(t),v0o=r(FIe," \u2014 "),XG=n(FIe,"A",{href:!0});var n7t=s(XG);F0o=r(n7t,"DeformableDetrFeatureExtractor"),n7t.forEach(t),T0o=r(FIe," (Deformable DETR model)"),FIe.forEach(t),M0o=i(W),Uu=n(W,"LI",{});var TIe=s(Uu);Jhe=n(TIe,"STRONG",{});var s7t=s(Jhe);E0o=r(s7t,"deit"),s7t.forEach(t),C0o=r(TIe," \u2014 "),zG=n(TIe,"A",{href:!0});var l7t=s(zG);w0o=r(l7t,"DeiTFeatureExtractor"),l7t.forEach(t),A0o=r(TIe," (DeiT model)"),TIe.forEach(t),L0o=i(W),Hu=n(W,"LI",{});var MIe=s(Hu);Yhe=n(MIe,"STRONG",{});var i7t=s(Yhe);y0o=r(i7t,"detr"),i7t.forEach(t),x0o=r(MIe," \u2014 "),QG=n(MIe,"A",{href:!0});var d7t=s(QG);$0o=r(d7t,"DetrFeatureExtractor"),d7t.forEach(t),k0o=r(MIe," (DETR model)"),MIe.forEach(t),S0o=i(W),Ju=n(W,"LI",{});var EIe=s(Ju);Khe=n(EIe,"STRONG",{});var m7t=s(Khe);R0o=r(m7t,"donut"),m7t.forEach(t),P0o=r(EIe," \u2014 "),WG=n(EIe,"A",{href:!0});var c7t=s(WG);B0o=r(c7t,"DonutFeatureExtractor"),c7t.forEach(t),I0o=r(EIe," (Donut model)"),EIe.forEach(t),N0o=i(W),Yu=n(W,"LI",{});var CIe=s(Yu);Zhe=n(CIe,"STRONG",{});var f7t=s(Zhe);q0o=r(f7t,"dpt"),f7t.forEach(t),j0o=r(CIe," \u2014 "),UG=n(CIe,"A",{href:!0});var g7t=s(UG);D0o=r(g7t,"DPTFeatureExtractor"),g7t.forEach(t),G0o=r(CIe," (DPT model)"),CIe.forEach(t),O0o=i(W),Ku=n(W,"LI",{});var wIe=s(Ku);eue=n(wIe,"STRONG",{});var h7t=s(eue);V0o=r(h7t,"flava"),h7t.forEach(t),X0o=r(wIe," \u2014 "),HG=n(wIe,"A",{href:!0});var u7t=s(HG);z0o=r(u7t,"FlavaFeatureExtractor"),u7t.forEach(t),Q0o=r(wIe," (FLAVA model)"),wIe.forEach(t),W0o=i(W),Zu=n(W,"LI",{});var AIe=s(Zu);oue=n(AIe,"STRONG",{});var p7t=s(oue);U0o=r(p7t,"glpn"),p7t.forEach(t),H0o=r(AIe," \u2014 "),JG=n(AIe,"A",{href:!0});var _7t=s(JG);J0o=r(_7t,"GLPNFeatureExtractor"),_7t.forEach(t),Y0o=r(AIe," (GLPN model)"),AIe.forEach(t),K0o=i(W),ep=n(W,"LI",{});var LIe=s(ep);rue=n(LIe,"STRONG",{});var b7t=s(rue);Z0o=r(b7t,"groupvit"),b7t.forEach(t),ewo=r(LIe," \u2014 "),YG=n(LIe,"A",{href:!0});var v7t=s(YG);owo=r(v7t,"CLIPFeatureExtractor"),v7t.forEach(t),rwo=r(LIe," (GroupViT model)"),LIe.forEach(t),two=i(W),op=n(W,"LI",{});var yIe=s(op);tue=n(yIe,"STRONG",{});var F7t=s(tue);awo=r(F7t,"hubert"),F7t.forEach(t),nwo=r(yIe," \u2014 "),KG=n(yIe,"A",{href:!0});var T7t=s(KG);swo=r(T7t,"Wav2Vec2FeatureExtractor"),T7t.forEach(t),lwo=r(yIe," (Hubert model)"),yIe.forEach(t),iwo=i(W),rp=n(W,"LI",{});var xIe=s(rp);aue=n(xIe,"STRONG",{});var M7t=s(aue);dwo=r(M7t,"imagegpt"),M7t.forEach(t),mwo=r(xIe," \u2014 "),ZG=n(xIe,"A",{href:!0});var E7t=s(ZG);cwo=r(E7t,"ImageGPTFeatureExtractor"),E7t.forEach(t),fwo=r(xIe," (ImageGPT model)"),xIe.forEach(t),gwo=i(W),tp=n(W,"LI",{});var $Ie=s(tp);nue=n($Ie,"STRONG",{});var C7t=s(nue);hwo=r(C7t,"layoutlmv2"),C7t.forEach(t),uwo=r($Ie," \u2014 "),eO=n($Ie,"A",{href:!0});var w7t=s(eO);pwo=r(w7t,"LayoutLMv2FeatureExtractor"),w7t.forEach(t),_wo=r($Ie," (LayoutLMv2 model)"),$Ie.forEach(t),bwo=i(W),ap=n(W,"LI",{});var kIe=s(ap);sue=n(kIe,"STRONG",{});var A7t=s(sue);vwo=r(A7t,"layoutlmv3"),A7t.forEach(t),Fwo=r(kIe," \u2014 "),oO=n(kIe,"A",{href:!0});var L7t=s(oO);Two=r(L7t,"LayoutLMv3FeatureExtractor"),L7t.forEach(t),Mwo=r(kIe," (LayoutLMv3 model)"),kIe.forEach(t),Ewo=i(W),np=n(W,"LI",{});var SIe=s(np);lue=n(SIe,"STRONG",{});var y7t=s(lue);Cwo=r(y7t,"levit"),y7t.forEach(t),wwo=r(SIe," \u2014 "),rO=n(SIe,"A",{href:!0});var x7t=s(rO);Awo=r(x7t,"LevitFeatureExtractor"),x7t.forEach(t),Lwo=r(SIe," (LeViT model)"),SIe.forEach(t),ywo=i(W),sp=n(W,"LI",{});var RIe=s(sp);iue=n(RIe,"STRONG",{});var $7t=s(iue);xwo=r($7t,"maskformer"),$7t.forEach(t),$wo=r(RIe," \u2014 "),tO=n(RIe,"A",{href:!0});var k7t=s(tO);kwo=r(k7t,"MaskFormerFeatureExtractor"),k7t.forEach(t),Swo=r(RIe," (MaskFormer model)"),RIe.forEach(t),Rwo=i(W),lp=n(W,"LI",{});var PIe=s(lp);due=n(PIe,"STRONG",{});var S7t=s(due);Pwo=r(S7t,"mctct"),S7t.forEach(t),Bwo=r(PIe," \u2014 "),aO=n(PIe,"A",{href:!0});var R7t=s(aO);Iwo=r(R7t,"MCTCTFeatureExtractor"),R7t.forEach(t),Nwo=r(PIe," (M-CTC-T model)"),PIe.forEach(t),qwo=i(W),ip=n(W,"LI",{});var BIe=s(ip);mue=n(BIe,"STRONG",{});var P7t=s(mue);jwo=r(P7t,"mobilevit"),P7t.forEach(t),Dwo=r(BIe," \u2014 "),nO=n(BIe,"A",{href:!0});var B7t=s(nO);Gwo=r(B7t,"MobileViTFeatureExtractor"),B7t.forEach(t),Owo=r(BIe," (MobileViT model)"),BIe.forEach(t),Vwo=i(W),dp=n(W,"LI",{});var IIe=s(dp);cue=n(IIe,"STRONG",{});var I7t=s(cue);Xwo=r(I7t,"owlvit"),I7t.forEach(t),zwo=r(IIe," \u2014 "),sO=n(IIe,"A",{href:!0});var N7t=s(sO);Qwo=r(N7t,"OwlViTFeatureExtractor"),N7t.forEach(t),Wwo=r(IIe," (OWL-ViT model)"),IIe.forEach(t),Uwo=i(W),mp=n(W,"LI",{});var NIe=s(mp);fue=n(NIe,"STRONG",{});var q7t=s(fue);Hwo=r(q7t,"perceiver"),q7t.forEach(t),Jwo=r(NIe," \u2014 "),lO=n(NIe,"A",{href:!0});var j7t=s(lO);Ywo=r(j7t,"PerceiverFeatureExtractor"),j7t.forEach(t),Kwo=r(NIe," (Perceiver model)"),NIe.forEach(t),Zwo=i(W),cp=n(W,"LI",{});var qIe=s(cp);gue=n(qIe,"STRONG",{});var D7t=s(gue);eAo=r(D7t,"poolformer"),D7t.forEach(t),oAo=r(qIe," \u2014 "),iO=n(qIe,"A",{href:!0});var G7t=s(iO);rAo=r(G7t,"PoolFormerFeatureExtractor"),G7t.forEach(t),tAo=r(qIe," (PoolFormer model)"),qIe.forEach(t),aAo=i(W),fp=n(W,"LI",{});var jIe=s(fp);hue=n(jIe,"STRONG",{});var O7t=s(hue);nAo=r(O7t,"regnet"),O7t.forEach(t),sAo=r(jIe," \u2014 "),dO=n(jIe,"A",{href:!0});var V7t=s(dO);lAo=r(V7t,"ConvNextFeatureExtractor"),V7t.forEach(t),iAo=r(jIe," (RegNet model)"),jIe.forEach(t),dAo=i(W),gp=n(W,"LI",{});var DIe=s(gp);uue=n(DIe,"STRONG",{});var X7t=s(uue);mAo=r(X7t,"resnet"),X7t.forEach(t),cAo=r(DIe," \u2014 "),mO=n(DIe,"A",{href:!0});var z7t=s(mO);fAo=r(z7t,"ConvNextFeatureExtractor"),z7t.forEach(t),gAo=r(DIe," (ResNet model)"),DIe.forEach(t),hAo=i(W),hp=n(W,"LI",{});var GIe=s(hp);pue=n(GIe,"STRONG",{});var Q7t=s(pue);uAo=r(Q7t,"segformer"),Q7t.forEach(t),pAo=r(GIe," \u2014 "),cO=n(GIe,"A",{href:!0});var W7t=s(cO);_Ao=r(W7t,"SegformerFeatureExtractor"),W7t.forEach(t),bAo=r(GIe," (SegFormer model)"),GIe.forEach(t),vAo=i(W),up=n(W,"LI",{});var OIe=s(up);_ue=n(OIe,"STRONG",{});var U7t=s(_ue);FAo=r(U7t,"speech_to_text"),U7t.forEach(t),TAo=r(OIe," \u2014 "),fO=n(OIe,"A",{href:!0});var H7t=s(fO);MAo=r(H7t,"Speech2TextFeatureExtractor"),H7t.forEach(t),EAo=r(OIe," (Speech2Text model)"),OIe.forEach(t),CAo=i(W),pp=n(W,"LI",{});var VIe=s(pp);bue=n(VIe,"STRONG",{});var J7t=s(bue);wAo=r(J7t,"swin"),J7t.forEach(t),AAo=r(VIe," \u2014 "),gO=n(VIe,"A",{href:!0});var Y7t=s(gO);LAo=r(Y7t,"ViTFeatureExtractor"),Y7t.forEach(t),yAo=r(VIe," (Swin Transformer model)"),VIe.forEach(t),xAo=i(W),_p=n(W,"LI",{});var XIe=s(_p);vue=n(XIe,"STRONG",{});var K7t=s(vue);$Ao=r(K7t,"swinv2"),K7t.forEach(t),kAo=r(XIe," \u2014 "),hO=n(XIe,"A",{href:!0});var Z7t=s(hO);SAo=r(Z7t,"ViTFeatureExtractor"),Z7t.forEach(t),RAo=r(XIe," (Swin Transformer V2 model)"),XIe.forEach(t),PAo=i(W),bp=n(W,"LI",{});var zIe=s(bp);Fue=n(zIe,"STRONG",{});var eLt=s(Fue);BAo=r(eLt,"van"),eLt.forEach(t),IAo=r(zIe," \u2014 "),uO=n(zIe,"A",{href:!0});var oLt=s(uO);NAo=r(oLt,"ConvNextFeatureExtractor"),oLt.forEach(t),qAo=r(zIe," (VAN model)"),zIe.forEach(t),jAo=i(W),vp=n(W,"LI",{});var QIe=s(vp);Tue=n(QIe,"STRONG",{});var rLt=s(Tue);DAo=r(rLt,"videomae"),rLt.forEach(t),GAo=r(QIe," \u2014 "),pO=n(QIe,"A",{href:!0});var tLt=s(pO);OAo=r(tLt,"VideoMAEFeatureExtractor"),tLt.forEach(t),VAo=r(QIe," (VideoMAE model)"),QIe.forEach(t),XAo=i(W),Fp=n(W,"LI",{});var WIe=s(Fp);Mue=n(WIe,"STRONG",{});var aLt=s(Mue);zAo=r(aLt,"vilt"),aLt.forEach(t),QAo=r(WIe," \u2014 "),_O=n(WIe,"A",{href:!0});var nLt=s(_O);WAo=r(nLt,"ViltFeatureExtractor"),nLt.forEach(t),UAo=r(WIe," (ViLT model)"),WIe.forEach(t),HAo=i(W),Tp=n(W,"LI",{});var UIe=s(Tp);Eue=n(UIe,"STRONG",{});var sLt=s(Eue);JAo=r(sLt,"vit"),sLt.forEach(t),YAo=r(UIe," \u2014 "),bO=n(UIe,"A",{href:!0});var lLt=s(bO);KAo=r(lLt,"ViTFeatureExtractor"),lLt.forEach(t),ZAo=r(UIe," (ViT model)"),UIe.forEach(t),e6o=i(W),Mp=n(W,"LI",{});var HIe=s(Mp);Cue=n(HIe,"STRONG",{});var iLt=s(Cue);o6o=r(iLt,"vit_mae"),iLt.forEach(t),r6o=r(HIe," \u2014 "),vO=n(HIe,"A",{href:!0});var dLt=s(vO);t6o=r(dLt,"ViTFeatureExtractor"),dLt.forEach(t),a6o=r(HIe," (ViTMAE model)"),HIe.forEach(t),n6o=i(W),Ep=n(W,"LI",{});var JIe=s(Ep);wue=n(JIe,"STRONG",{});var mLt=s(wue);s6o=r(mLt,"vit_msn"),mLt.forEach(t),l6o=r(JIe," \u2014 "),FO=n(JIe,"A",{href:!0});var cLt=s(FO);i6o=r(cLt,"ViTFeatureExtractor"),cLt.forEach(t),d6o=r(JIe," (ViTMSN model)"),JIe.forEach(t),m6o=i(W),Cp=n(W,"LI",{});var YIe=s(Cp);Aue=n(YIe,"STRONG",{});var fLt=s(Aue);c6o=r(fLt,"wav2vec2"),fLt.forEach(t),f6o=r(YIe," \u2014 "),TO=n(YIe,"A",{href:!0});var gLt=s(TO);g6o=r(gLt,"Wav2Vec2FeatureExtractor"),gLt.forEach(t),h6o=r(YIe," (Wav2Vec2 model)"),YIe.forEach(t),u6o=i(W),wp=n(W,"LI",{});var KIe=s(wp);Lue=n(KIe,"STRONG",{});var hLt=s(Lue);p6o=r(hLt,"wav2vec2-conformer"),hLt.forEach(t),_6o=r(KIe," \u2014 "),MO=n(KIe,"A",{href:!0});var uLt=s(MO);b6o=r(uLt,"Wav2Vec2FeatureExtractor"),uLt.forEach(t),v6o=r(KIe," (Wav2Vec2-Conformer model)"),KIe.forEach(t),F6o=i(W),Ap=n(W,"LI",{});var ZIe=s(Ap);yue=n(ZIe,"STRONG",{});var pLt=s(yue);T6o=r(pLt,"xclip"),pLt.forEach(t),M6o=r(ZIe," \u2014 "),EO=n(ZIe,"A",{href:!0});var _Lt=s(EO);E6o=r(_Lt,"CLIPFeatureExtractor"),_Lt.forEach(t),C6o=r(ZIe," (X-CLIP model)"),ZIe.forEach(t),w6o=i(W),Lp=n(W,"LI",{});var eNe=s(Lp);xue=n(eNe,"STRONG",{});var bLt=s(xue);A6o=r(bLt,"yolos"),bLt.forEach(t),L6o=r(eNe," \u2014 "),CO=n(eNe,"A",{href:!0});var vLt=s(CO);y6o=r(vLt,"YolosFeatureExtractor"),vLt.forEach(t),x6o=r(eNe," (YOLOS model)"),eNe.forEach(t),W.forEach(t),$6o=i(ba),T(yp.$$.fragment,ba),k6o=i(ba),T(xp.$$.fragment,ba),ba.forEach(t),S6o=i(Cl),$p=n(Cl,"DIV",{class:!0});var iro=s($p);T(vx.$$.fragment,iro),R6o=i(iro),$ue=n(iro,"P",{});var FLt=s($ue);P6o=r(FLt,"Register a new feature extractor for this class."),FLt.forEach(t),iro.forEach(t),Cl.forEach(t),YZe=i(c),ud=n(c,"H2",{class:!0});var dro=s(ud);kp=n(dro,"A",{id:!0,class:!0,href:!0});var TLt=s(kp);kue=n(TLt,"SPAN",{});var MLt=s(kue);T(Fx.$$.fragment,MLt),MLt.forEach(t),TLt.forEach(t),B6o=i(dro),Sue=n(dro,"SPAN",{});var ELt=s(Sue);I6o=r(ELt,"AutoProcessor"),ELt.forEach(t),dro.forEach(t),KZe=i(c),Ro=n(c,"DIV",{class:!0});var wl=s(Ro);T(Tx.$$.fragment,wl),N6o=i(wl),Mx=n(wl,"P",{});var mro=s(Mx);q6o=r(mro,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),wO=n(mro,"A",{href:!0});var CLt=s(wO);j6o=r(CLt,"AutoProcessor.from_pretrained()"),CLt.forEach(t),D6o=r(mro," class method."),mro.forEach(t),G6o=i(wl),Ex=n(wl,"P",{});var cro=s(Ex);O6o=r(cro,"This class cannot be instantiated directly using "),Rue=n(cro,"CODE",{});var wLt=s(Rue);V6o=r(wLt,"__init__()"),wLt.forEach(t),X6o=r(cro," (throws an error)."),cro.forEach(t),z6o=i(wl),Ke=n(wl,"DIV",{class:!0});var va=s(Ke);T(Cx.$$.fragment,va),Q6o=i(va),Pue=n(va,"P",{});var ALt=s(Pue);W6o=r(ALt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),ALt.forEach(t),U6o=i(va),pd=n(va,"P",{});var Yle=s(pd);H6o=r(Yle,"The processor class to instantiate is selected based on the "),Bue=n(Yle,"CODE",{});var LLt=s(Bue);J6o=r(LLt,"model_type"),LLt.forEach(t),Y6o=r(Yle,` property of the config object (either
passed as an argument or loaded from `),Iue=n(Yle,"CODE",{});var yLt=s(Iue);K6o=r(yLt,"pretrained_model_name_or_path"),yLt.forEach(t),Z6o=r(Yle," if possible):"),Yle.forEach(t),e7o=i(va),le=n(va,"UL",{});var ce=s(le);Sp=n(ce,"LI",{});var oNe=s(Sp);Nue=n(oNe,"STRONG",{});var xLt=s(Nue);o7o=r(xLt,"clip"),xLt.forEach(t),r7o=r(oNe," \u2014 "),AO=n(oNe,"A",{href:!0});var $Lt=s(AO);t7o=r($Lt,"CLIPProcessor"),$Lt.forEach(t),a7o=r(oNe," (CLIP model)"),oNe.forEach(t),n7o=i(ce),Rp=n(ce,"LI",{});var rNe=s(Rp);que=n(rNe,"STRONG",{});var kLt=s(que);s7o=r(kLt,"donut"),kLt.forEach(t),l7o=r(rNe," \u2014 "),LO=n(rNe,"A",{href:!0});var SLt=s(LO);i7o=r(SLt,"DonutProcessor"),SLt.forEach(t),d7o=r(rNe," (Donut model)"),rNe.forEach(t),m7o=i(ce),Pp=n(ce,"LI",{});var tNe=s(Pp);jue=n(tNe,"STRONG",{});var RLt=s(jue);c7o=r(RLt,"flava"),RLt.forEach(t),f7o=r(tNe," \u2014 "),yO=n(tNe,"A",{href:!0});var PLt=s(yO);g7o=r(PLt,"FlavaProcessor"),PLt.forEach(t),h7o=r(tNe," (FLAVA model)"),tNe.forEach(t),u7o=i(ce),Bp=n(ce,"LI",{});var aNe=s(Bp);Due=n(aNe,"STRONG",{});var BLt=s(Due);p7o=r(BLt,"groupvit"),BLt.forEach(t),_7o=r(aNe," \u2014 "),xO=n(aNe,"A",{href:!0});var ILt=s(xO);b7o=r(ILt,"CLIPProcessor"),ILt.forEach(t),v7o=r(aNe," (GroupViT model)"),aNe.forEach(t),F7o=i(ce),Ip=n(ce,"LI",{});var nNe=s(Ip);Gue=n(nNe,"STRONG",{});var NLt=s(Gue);T7o=r(NLt,"layoutlmv2"),NLt.forEach(t),M7o=r(nNe," \u2014 "),$O=n(nNe,"A",{href:!0});var qLt=s($O);E7o=r(qLt,"LayoutLMv2Processor"),qLt.forEach(t),C7o=r(nNe," (LayoutLMv2 model)"),nNe.forEach(t),w7o=i(ce),Np=n(ce,"LI",{});var sNe=s(Np);Oue=n(sNe,"STRONG",{});var jLt=s(Oue);A7o=r(jLt,"layoutlmv3"),jLt.forEach(t),L7o=r(sNe," \u2014 "),kO=n(sNe,"A",{href:!0});var DLt=s(kO);y7o=r(DLt,"LayoutLMv3Processor"),DLt.forEach(t),x7o=r(sNe," (LayoutLMv3 model)"),sNe.forEach(t),$7o=i(ce),qp=n(ce,"LI",{});var lNe=s(qp);Vue=n(lNe,"STRONG",{});var GLt=s(Vue);k7o=r(GLt,"layoutxlm"),GLt.forEach(t),S7o=r(lNe," \u2014 "),SO=n(lNe,"A",{href:!0});var OLt=s(SO);R7o=r(OLt,"LayoutXLMProcessor"),OLt.forEach(t),P7o=r(lNe," (LayoutXLM model)"),lNe.forEach(t),B7o=i(ce),jp=n(ce,"LI",{});var iNe=s(jp);Xue=n(iNe,"STRONG",{});var VLt=s(Xue);I7o=r(VLt,"markuplm"),VLt.forEach(t),N7o=r(iNe," \u2014 "),RO=n(iNe,"A",{href:!0});var XLt=s(RO);q7o=r(XLt,"MarkupLMProcessor"),XLt.forEach(t),j7o=r(iNe," (MarkupLM model)"),iNe.forEach(t),D7o=i(ce),Dp=n(ce,"LI",{});var dNe=s(Dp);zue=n(dNe,"STRONG",{});var zLt=s(zue);G7o=r(zLt,"owlvit"),zLt.forEach(t),O7o=r(dNe," \u2014 "),PO=n(dNe,"A",{href:!0});var QLt=s(PO);V7o=r(QLt,"OwlViTProcessor"),QLt.forEach(t),X7o=r(dNe," (OWL-ViT model)"),dNe.forEach(t),z7o=i(ce),Gp=n(ce,"LI",{});var mNe=s(Gp);Que=n(mNe,"STRONG",{});var WLt=s(Que);Q7o=r(WLt,"sew"),WLt.forEach(t),W7o=r(mNe," \u2014 "),BO=n(mNe,"A",{href:!0});var ULt=s(BO);U7o=r(ULt,"Wav2Vec2Processor"),ULt.forEach(t),H7o=r(mNe," (SEW model)"),mNe.forEach(t),J7o=i(ce),Op=n(ce,"LI",{});var cNe=s(Op);Wue=n(cNe,"STRONG",{});var HLt=s(Wue);Y7o=r(HLt,"sew-d"),HLt.forEach(t),K7o=r(cNe," \u2014 "),IO=n(cNe,"A",{href:!0});var JLt=s(IO);Z7o=r(JLt,"Wav2Vec2Processor"),JLt.forEach(t),eLo=r(cNe," (SEW-D model)"),cNe.forEach(t),oLo=i(ce),Vp=n(ce,"LI",{});var fNe=s(Vp);Uue=n(fNe,"STRONG",{});var YLt=s(Uue);rLo=r(YLt,"speech_to_text"),YLt.forEach(t),tLo=r(fNe," \u2014 "),NO=n(fNe,"A",{href:!0});var KLt=s(NO);aLo=r(KLt,"Speech2TextProcessor"),KLt.forEach(t),nLo=r(fNe," (Speech2Text model)"),fNe.forEach(t),sLo=i(ce),Xp=n(ce,"LI",{});var gNe=s(Xp);Hue=n(gNe,"STRONG",{});var ZLt=s(Hue);lLo=r(ZLt,"speech_to_text_2"),ZLt.forEach(t),iLo=r(gNe," \u2014 "),qO=n(gNe,"A",{href:!0});var eyt=s(qO);dLo=r(eyt,"Speech2Text2Processor"),eyt.forEach(t),mLo=r(gNe," (Speech2Text2 model)"),gNe.forEach(t),cLo=i(ce),zp=n(ce,"LI",{});var hNe=s(zp);Jue=n(hNe,"STRONG",{});var oyt=s(Jue);fLo=r(oyt,"trocr"),oyt.forEach(t),gLo=r(hNe," \u2014 "),jO=n(hNe,"A",{href:!0});var ryt=s(jO);hLo=r(ryt,"TrOCRProcessor"),ryt.forEach(t),uLo=r(hNe," (TrOCR model)"),hNe.forEach(t),pLo=i(ce),Qp=n(ce,"LI",{});var uNe=s(Qp);Yue=n(uNe,"STRONG",{});var tyt=s(Yue);_Lo=r(tyt,"unispeech"),tyt.forEach(t),bLo=r(uNe," \u2014 "),DO=n(uNe,"A",{href:!0});var ayt=s(DO);vLo=r(ayt,"Wav2Vec2Processor"),ayt.forEach(t),FLo=r(uNe," (UniSpeech model)"),uNe.forEach(t),TLo=i(ce),Wp=n(ce,"LI",{});var pNe=s(Wp);Kue=n(pNe,"STRONG",{});var nyt=s(Kue);MLo=r(nyt,"unispeech-sat"),nyt.forEach(t),ELo=r(pNe," \u2014 "),GO=n(pNe,"A",{href:!0});var syt=s(GO);CLo=r(syt,"Wav2Vec2Processor"),syt.forEach(t),wLo=r(pNe," (UniSpeechSat model)"),pNe.forEach(t),ALo=i(ce),Up=n(ce,"LI",{});var _Ne=s(Up);Zue=n(_Ne,"STRONG",{});var lyt=s(Zue);LLo=r(lyt,"vilt"),lyt.forEach(t),yLo=r(_Ne," \u2014 "),OO=n(_Ne,"A",{href:!0});var iyt=s(OO);xLo=r(iyt,"ViltProcessor"),iyt.forEach(t),$Lo=r(_Ne," (ViLT model)"),_Ne.forEach(t),kLo=i(ce),Hp=n(ce,"LI",{});var bNe=s(Hp);epe=n(bNe,"STRONG",{});var dyt=s(epe);SLo=r(dyt,"vision-text-dual-encoder"),dyt.forEach(t),RLo=r(bNe," \u2014 "),VO=n(bNe,"A",{href:!0});var myt=s(VO);PLo=r(myt,"VisionTextDualEncoderProcessor"),myt.forEach(t),BLo=r(bNe," (VisionTextDualEncoder model)"),bNe.forEach(t),ILo=i(ce),Jp=n(ce,"LI",{});var vNe=s(Jp);ope=n(vNe,"STRONG",{});var cyt=s(ope);NLo=r(cyt,"wav2vec2"),cyt.forEach(t),qLo=r(vNe," \u2014 "),XO=n(vNe,"A",{href:!0});var fyt=s(XO);jLo=r(fyt,"Wav2Vec2Processor"),fyt.forEach(t),DLo=r(vNe," (Wav2Vec2 model)"),vNe.forEach(t),GLo=i(ce),Yp=n(ce,"LI",{});var FNe=s(Yp);rpe=n(FNe,"STRONG",{});var gyt=s(rpe);OLo=r(gyt,"wav2vec2-conformer"),gyt.forEach(t),VLo=r(FNe," \u2014 "),zO=n(FNe,"A",{href:!0});var hyt=s(zO);XLo=r(hyt,"Wav2Vec2Processor"),hyt.forEach(t),zLo=r(FNe," (Wav2Vec2-Conformer model)"),FNe.forEach(t),QLo=i(ce),Kp=n(ce,"LI",{});var TNe=s(Kp);tpe=n(TNe,"STRONG",{});var uyt=s(tpe);WLo=r(uyt,"wavlm"),uyt.forEach(t),ULo=r(TNe," \u2014 "),QO=n(TNe,"A",{href:!0});var pyt=s(QO);HLo=r(pyt,"Wav2Vec2Processor"),pyt.forEach(t),JLo=r(TNe," (WavLM model)"),TNe.forEach(t),YLo=i(ce),Zp=n(ce,"LI",{});var MNe=s(Zp);ape=n(MNe,"STRONG",{});var _yt=s(ape);KLo=r(_yt,"xclip"),_yt.forEach(t),ZLo=r(MNe," \u2014 "),WO=n(MNe,"A",{href:!0});var byt=s(WO);eyo=r(byt,"CLIPProcessor"),byt.forEach(t),oyo=r(MNe," (X-CLIP model)"),MNe.forEach(t),ce.forEach(t),ryo=i(va),T(e_.$$.fragment,va),tyo=i(va),T(o_.$$.fragment,va),va.forEach(t),ayo=i(wl),r_=n(wl,"DIV",{class:!0});var fro=s(r_);T(wx.$$.fragment,fro),nyo=i(fro),npe=n(fro,"P",{});var vyt=s(npe);syo=r(vyt,"Register a new processor for this class."),vyt.forEach(t),fro.forEach(t),wl.forEach(t),ZZe=i(c),_d=n(c,"H2",{class:!0});var gro=s(_d);t_=n(gro,"A",{id:!0,class:!0,href:!0});var Fyt=s(t_);spe=n(Fyt,"SPAN",{});var Tyt=s(spe);T(Ax.$$.fragment,Tyt),Tyt.forEach(t),Fyt.forEach(t),lyo=i(gro),lpe=n(gro,"SPAN",{});var Myt=s(lpe);iyo=r(Myt,"AutoModel"),Myt.forEach(t),gro.forEach(t),eeo=i(c),Po=n(c,"DIV",{class:!0});var Al=s(Po);T(Lx.$$.fragment,Al),dyo=i(Al),bd=n(Al,"P",{});var Kle=s(bd);myo=r(Kle,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),UO=n(Kle,"A",{href:!0});var Eyt=s(UO);cyo=r(Eyt,"from_pretrained()"),Eyt.forEach(t),fyo=r(Kle," class method or the "),HO=n(Kle,"A",{href:!0});var Cyt=s(HO);gyo=r(Cyt,"from_config()"),Cyt.forEach(t),hyo=r(Kle,` class
method.`),Kle.forEach(t),uyo=i(Al),yx=n(Al,"P",{});var hro=s(yx);pyo=r(hro,"This class cannot be instantiated directly using "),ipe=n(hro,"CODE",{});var wyt=s(ipe);_yo=r(wyt,"__init__()"),wyt.forEach(t),byo=r(hro," (throws an error)."),hro.forEach(t),vyo=i(Al),_t=n(Al,"DIV",{class:!0});var Uy=s(_t);T(xx.$$.fragment,Uy),Fyo=i(Uy),dpe=n(Uy,"P",{});var Ayt=s(dpe);Tyo=r(Ayt,"Instantiates one of the base model classes of the library from a configuration."),Ayt.forEach(t),Myo=i(Uy),vd=n(Uy,"P",{});var Zle=s(vd);Eyo=r(Zle,`Note:
Loading a model from its configuration file does `),mpe=n(Zle,"STRONG",{});var Lyt=s(mpe);Cyo=r(Lyt,"not"),Lyt.forEach(t),wyo=r(Zle,` load the model weights. It only affects the
model\u2019s configuration. Use `),JO=n(Zle,"A",{href:!0});var yyt=s(JO);Ayo=r(yyt,"from_pretrained()"),yyt.forEach(t),Lyo=r(Zle," to load the model weights."),Zle.forEach(t),yyo=i(Uy),T(a_.$$.fragment,Uy),Uy.forEach(t),xyo=i(Al),Ze=n(Al,"DIV",{class:!0});var Fa=s(Ze);T($x.$$.fragment,Fa),$yo=i(Fa),cpe=n(Fa,"P",{});var xyt=s(cpe);kyo=r(xyt,"Instantiate one of the base model classes of the library from a pretrained model."),xyt.forEach(t),Syo=i(Fa),Ja=n(Fa,"P",{});var Hy=s(Ja);Ryo=r(Hy,"The model class to instantiate is selected based on the "),fpe=n(Hy,"CODE",{});var $yt=s(fpe);Pyo=r($yt,"model_type"),$yt.forEach(t),Byo=r(Hy,` property of the config object (either
passed as an argument or loaded from `),gpe=n(Hy,"CODE",{});var kyt=s(gpe);Iyo=r(kyt,"pretrained_model_name_or_path"),kyt.forEach(t),Nyo=r(Hy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hpe=n(Hy,"CODE",{});var Syt=s(hpe);qyo=r(Syt,"pretrained_model_name_or_path"),Syt.forEach(t),jyo=r(Hy,":"),Hy.forEach(t),Dyo=i(Fa),y=n(Fa,"UL",{});var x=s(y);n_=n(x,"LI",{});var ENe=s(n_);upe=n(ENe,"STRONG",{});var Ryt=s(upe);Gyo=r(Ryt,"albert"),Ryt.forEach(t),Oyo=r(ENe," \u2014 "),YO=n(ENe,"A",{href:!0});var Pyt=s(YO);Vyo=r(Pyt,"AlbertModel"),Pyt.forEach(t),Xyo=r(ENe," (ALBERT model)"),ENe.forEach(t),zyo=i(x),s_=n(x,"LI",{});var CNe=s(s_);ppe=n(CNe,"STRONG",{});var Byt=s(ppe);Qyo=r(Byt,"bart"),Byt.forEach(t),Wyo=r(CNe," \u2014 "),KO=n(CNe,"A",{href:!0});var Iyt=s(KO);Uyo=r(Iyt,"BartModel"),Iyt.forEach(t),Hyo=r(CNe," (BART model)"),CNe.forEach(t),Jyo=i(x),l_=n(x,"LI",{});var wNe=s(l_);_pe=n(wNe,"STRONG",{});var Nyt=s(_pe);Yyo=r(Nyt,"beit"),Nyt.forEach(t),Kyo=r(wNe," \u2014 "),ZO=n(wNe,"A",{href:!0});var qyt=s(ZO);Zyo=r(qyt,"BeitModel"),qyt.forEach(t),e8o=r(wNe," (BEiT model)"),wNe.forEach(t),o8o=i(x),i_=n(x,"LI",{});var ANe=s(i_);bpe=n(ANe,"STRONG",{});var jyt=s(bpe);r8o=r(jyt,"bert"),jyt.forEach(t),t8o=r(ANe," \u2014 "),eV=n(ANe,"A",{href:!0});var Dyt=s(eV);a8o=r(Dyt,"BertModel"),Dyt.forEach(t),n8o=r(ANe," (BERT model)"),ANe.forEach(t),s8o=i(x),d_=n(x,"LI",{});var LNe=s(d_);vpe=n(LNe,"STRONG",{});var Gyt=s(vpe);l8o=r(Gyt,"bert-generation"),Gyt.forEach(t),i8o=r(LNe," \u2014 "),oV=n(LNe,"A",{href:!0});var Oyt=s(oV);d8o=r(Oyt,"BertGenerationEncoder"),Oyt.forEach(t),m8o=r(LNe," (Bert Generation model)"),LNe.forEach(t),c8o=i(x),m_=n(x,"LI",{});var yNe=s(m_);Fpe=n(yNe,"STRONG",{});var Vyt=s(Fpe);f8o=r(Vyt,"big_bird"),Vyt.forEach(t),g8o=r(yNe," \u2014 "),rV=n(yNe,"A",{href:!0});var Xyt=s(rV);h8o=r(Xyt,"BigBirdModel"),Xyt.forEach(t),u8o=r(yNe," (BigBird model)"),yNe.forEach(t),p8o=i(x),c_=n(x,"LI",{});var xNe=s(c_);Tpe=n(xNe,"STRONG",{});var zyt=s(Tpe);_8o=r(zyt,"bigbird_pegasus"),zyt.forEach(t),b8o=r(xNe," \u2014 "),tV=n(xNe,"A",{href:!0});var Qyt=s(tV);v8o=r(Qyt,"BigBirdPegasusModel"),Qyt.forEach(t),F8o=r(xNe," (BigBird-Pegasus model)"),xNe.forEach(t),T8o=i(x),f_=n(x,"LI",{});var $Ne=s(f_);Mpe=n($Ne,"STRONG",{});var Wyt=s(Mpe);M8o=r(Wyt,"blenderbot"),Wyt.forEach(t),E8o=r($Ne," \u2014 "),aV=n($Ne,"A",{href:!0});var Uyt=s(aV);C8o=r(Uyt,"BlenderbotModel"),Uyt.forEach(t),w8o=r($Ne," (Blenderbot model)"),$Ne.forEach(t),A8o=i(x),g_=n(x,"LI",{});var kNe=s(g_);Epe=n(kNe,"STRONG",{});var Hyt=s(Epe);L8o=r(Hyt,"blenderbot-small"),Hyt.forEach(t),y8o=r(kNe," \u2014 "),nV=n(kNe,"A",{href:!0});var Jyt=s(nV);x8o=r(Jyt,"BlenderbotSmallModel"),Jyt.forEach(t),$8o=r(kNe," (BlenderbotSmall model)"),kNe.forEach(t),k8o=i(x),h_=n(x,"LI",{});var SNe=s(h_);Cpe=n(SNe,"STRONG",{});var Yyt=s(Cpe);S8o=r(Yyt,"bloom"),Yyt.forEach(t),R8o=r(SNe," \u2014 "),sV=n(SNe,"A",{href:!0});var Kyt=s(sV);P8o=r(Kyt,"BloomModel"),Kyt.forEach(t),B8o=r(SNe," (BLOOM model)"),SNe.forEach(t),I8o=i(x),u_=n(x,"LI",{});var RNe=s(u_);wpe=n(RNe,"STRONG",{});var Zyt=s(wpe);N8o=r(Zyt,"camembert"),Zyt.forEach(t),q8o=r(RNe," \u2014 "),lV=n(RNe,"A",{href:!0});var e8t=s(lV);j8o=r(e8t,"CamembertModel"),e8t.forEach(t),D8o=r(RNe," (CamemBERT model)"),RNe.forEach(t),G8o=i(x),p_=n(x,"LI",{});var PNe=s(p_);Ape=n(PNe,"STRONG",{});var o8t=s(Ape);O8o=r(o8t,"canine"),o8t.forEach(t),V8o=r(PNe," \u2014 "),iV=n(PNe,"A",{href:!0});var r8t=s(iV);X8o=r(r8t,"CanineModel"),r8t.forEach(t),z8o=r(PNe," (CANINE model)"),PNe.forEach(t),Q8o=i(x),__=n(x,"LI",{});var BNe=s(__);Lpe=n(BNe,"STRONG",{});var t8t=s(Lpe);W8o=r(t8t,"clip"),t8t.forEach(t),U8o=r(BNe," \u2014 "),dV=n(BNe,"A",{href:!0});var a8t=s(dV);H8o=r(a8t,"CLIPModel"),a8t.forEach(t),J8o=r(BNe," (CLIP model)"),BNe.forEach(t),Y8o=i(x),b_=n(x,"LI",{});var INe=s(b_);ype=n(INe,"STRONG",{});var n8t=s(ype);K8o=r(n8t,"codegen"),n8t.forEach(t),Z8o=r(INe," \u2014 "),mV=n(INe,"A",{href:!0});var s8t=s(mV);e9o=r(s8t,"CodeGenModel"),s8t.forEach(t),o9o=r(INe," (CodeGen model)"),INe.forEach(t),r9o=i(x),v_=n(x,"LI",{});var NNe=s(v_);xpe=n(NNe,"STRONG",{});var l8t=s(xpe);t9o=r(l8t,"conditional_detr"),l8t.forEach(t),a9o=r(NNe," \u2014 "),cV=n(NNe,"A",{href:!0});var i8t=s(cV);n9o=r(i8t,"ConditionalDetrModel"),i8t.forEach(t),s9o=r(NNe," (Conditional DETR model)"),NNe.forEach(t),l9o=i(x),F_=n(x,"LI",{});var qNe=s(F_);$pe=n(qNe,"STRONG",{});var d8t=s($pe);i9o=r(d8t,"convbert"),d8t.forEach(t),d9o=r(qNe," \u2014 "),fV=n(qNe,"A",{href:!0});var m8t=s(fV);m9o=r(m8t,"ConvBertModel"),m8t.forEach(t),c9o=r(qNe," (ConvBERT model)"),qNe.forEach(t),f9o=i(x),T_=n(x,"LI",{});var jNe=s(T_);kpe=n(jNe,"STRONG",{});var c8t=s(kpe);g9o=r(c8t,"convnext"),c8t.forEach(t),h9o=r(jNe," \u2014 "),gV=n(jNe,"A",{href:!0});var f8t=s(gV);u9o=r(f8t,"ConvNextModel"),f8t.forEach(t),p9o=r(jNe," (ConvNeXT model)"),jNe.forEach(t),_9o=i(x),M_=n(x,"LI",{});var DNe=s(M_);Spe=n(DNe,"STRONG",{});var g8t=s(Spe);b9o=r(g8t,"ctrl"),g8t.forEach(t),v9o=r(DNe," \u2014 "),hV=n(DNe,"A",{href:!0});var h8t=s(hV);F9o=r(h8t,"CTRLModel"),h8t.forEach(t),T9o=r(DNe," (CTRL model)"),DNe.forEach(t),M9o=i(x),E_=n(x,"LI",{});var GNe=s(E_);Rpe=n(GNe,"STRONG",{});var u8t=s(Rpe);E9o=r(u8t,"cvt"),u8t.forEach(t),C9o=r(GNe," \u2014 "),uV=n(GNe,"A",{href:!0});var p8t=s(uV);w9o=r(p8t,"CvtModel"),p8t.forEach(t),A9o=r(GNe," (CvT model)"),GNe.forEach(t),L9o=i(x),C_=n(x,"LI",{});var ONe=s(C_);Ppe=n(ONe,"STRONG",{});var _8t=s(Ppe);y9o=r(_8t,"data2vec-audio"),_8t.forEach(t),x9o=r(ONe," \u2014 "),pV=n(ONe,"A",{href:!0});var b8t=s(pV);$9o=r(b8t,"Data2VecAudioModel"),b8t.forEach(t),k9o=r(ONe," (Data2VecAudio model)"),ONe.forEach(t),S9o=i(x),w_=n(x,"LI",{});var VNe=s(w_);Bpe=n(VNe,"STRONG",{});var v8t=s(Bpe);R9o=r(v8t,"data2vec-text"),v8t.forEach(t),P9o=r(VNe," \u2014 "),_V=n(VNe,"A",{href:!0});var F8t=s(_V);B9o=r(F8t,"Data2VecTextModel"),F8t.forEach(t),I9o=r(VNe," (Data2VecText model)"),VNe.forEach(t),N9o=i(x),A_=n(x,"LI",{});var XNe=s(A_);Ipe=n(XNe,"STRONG",{});var T8t=s(Ipe);q9o=r(T8t,"data2vec-vision"),T8t.forEach(t),j9o=r(XNe," \u2014 "),bV=n(XNe,"A",{href:!0});var M8t=s(bV);D9o=r(M8t,"Data2VecVisionModel"),M8t.forEach(t),G9o=r(XNe," (Data2VecVision model)"),XNe.forEach(t),O9o=i(x),L_=n(x,"LI",{});var zNe=s(L_);Npe=n(zNe,"STRONG",{});var E8t=s(Npe);V9o=r(E8t,"deberta"),E8t.forEach(t),X9o=r(zNe," \u2014 "),vV=n(zNe,"A",{href:!0});var C8t=s(vV);z9o=r(C8t,"DebertaModel"),C8t.forEach(t),Q9o=r(zNe," (DeBERTa model)"),zNe.forEach(t),W9o=i(x),y_=n(x,"LI",{});var QNe=s(y_);qpe=n(QNe,"STRONG",{});var w8t=s(qpe);U9o=r(w8t,"deberta-v2"),w8t.forEach(t),H9o=r(QNe," \u2014 "),FV=n(QNe,"A",{href:!0});var A8t=s(FV);J9o=r(A8t,"DebertaV2Model"),A8t.forEach(t),Y9o=r(QNe," (DeBERTa-v2 model)"),QNe.forEach(t),K9o=i(x),x_=n(x,"LI",{});var WNe=s(x_);jpe=n(WNe,"STRONG",{});var L8t=s(jpe);Z9o=r(L8t,"decision_transformer"),L8t.forEach(t),exo=r(WNe," \u2014 "),TV=n(WNe,"A",{href:!0});var y8t=s(TV);oxo=r(y8t,"DecisionTransformerModel"),y8t.forEach(t),rxo=r(WNe," (Decision Transformer model)"),WNe.forEach(t),txo=i(x),$_=n(x,"LI",{});var UNe=s($_);Dpe=n(UNe,"STRONG",{});var x8t=s(Dpe);axo=r(x8t,"deformable_detr"),x8t.forEach(t),nxo=r(UNe," \u2014 "),MV=n(UNe,"A",{href:!0});var $8t=s(MV);sxo=r($8t,"DeformableDetrModel"),$8t.forEach(t),lxo=r(UNe," (Deformable DETR model)"),UNe.forEach(t),ixo=i(x),k_=n(x,"LI",{});var HNe=s(k_);Gpe=n(HNe,"STRONG",{});var k8t=s(Gpe);dxo=r(k8t,"deit"),k8t.forEach(t),mxo=r(HNe," \u2014 "),EV=n(HNe,"A",{href:!0});var S8t=s(EV);cxo=r(S8t,"DeiTModel"),S8t.forEach(t),fxo=r(HNe," (DeiT model)"),HNe.forEach(t),gxo=i(x),S_=n(x,"LI",{});var JNe=s(S_);Ope=n(JNe,"STRONG",{});var R8t=s(Ope);hxo=r(R8t,"detr"),R8t.forEach(t),uxo=r(JNe," \u2014 "),CV=n(JNe,"A",{href:!0});var P8t=s(CV);pxo=r(P8t,"DetrModel"),P8t.forEach(t),_xo=r(JNe," (DETR model)"),JNe.forEach(t),bxo=i(x),R_=n(x,"LI",{});var YNe=s(R_);Vpe=n(YNe,"STRONG",{});var B8t=s(Vpe);vxo=r(B8t,"distilbert"),B8t.forEach(t),Fxo=r(YNe," \u2014 "),wV=n(YNe,"A",{href:!0});var I8t=s(wV);Txo=r(I8t,"DistilBertModel"),I8t.forEach(t),Mxo=r(YNe," (DistilBERT model)"),YNe.forEach(t),Exo=i(x),P_=n(x,"LI",{});var KNe=s(P_);Xpe=n(KNe,"STRONG",{});var N8t=s(Xpe);Cxo=r(N8t,"donut-swin"),N8t.forEach(t),wxo=r(KNe," \u2014 "),AV=n(KNe,"A",{href:!0});var q8t=s(AV);Axo=r(q8t,"DonutSwinModel"),q8t.forEach(t),Lxo=r(KNe," (DonutSwin model)"),KNe.forEach(t),yxo=i(x),B_=n(x,"LI",{});var ZNe=s(B_);zpe=n(ZNe,"STRONG",{});var j8t=s(zpe);xxo=r(j8t,"dpr"),j8t.forEach(t),$xo=r(ZNe," \u2014 "),LV=n(ZNe,"A",{href:!0});var D8t=s(LV);kxo=r(D8t,"DPRQuestionEncoder"),D8t.forEach(t),Sxo=r(ZNe," (DPR model)"),ZNe.forEach(t),Rxo=i(x),I_=n(x,"LI",{});var eqe=s(I_);Qpe=n(eqe,"STRONG",{});var G8t=s(Qpe);Pxo=r(G8t,"dpt"),G8t.forEach(t),Bxo=r(eqe," \u2014 "),yV=n(eqe,"A",{href:!0});var O8t=s(yV);Ixo=r(O8t,"DPTModel"),O8t.forEach(t),Nxo=r(eqe," (DPT model)"),eqe.forEach(t),qxo=i(x),N_=n(x,"LI",{});var oqe=s(N_);Wpe=n(oqe,"STRONG",{});var V8t=s(Wpe);jxo=r(V8t,"electra"),V8t.forEach(t),Dxo=r(oqe," \u2014 "),xV=n(oqe,"A",{href:!0});var X8t=s(xV);Gxo=r(X8t,"ElectraModel"),X8t.forEach(t),Oxo=r(oqe," (ELECTRA model)"),oqe.forEach(t),Vxo=i(x),q_=n(x,"LI",{});var rqe=s(q_);Upe=n(rqe,"STRONG",{});var z8t=s(Upe);Xxo=r(z8t,"ernie"),z8t.forEach(t),zxo=r(rqe," \u2014 "),$V=n(rqe,"A",{href:!0});var Q8t=s($V);Qxo=r(Q8t,"ErnieModel"),Q8t.forEach(t),Wxo=r(rqe," (ERNIE model)"),rqe.forEach(t),Uxo=i(x),j_=n(x,"LI",{});var tqe=s(j_);Hpe=n(tqe,"STRONG",{});var W8t=s(Hpe);Hxo=r(W8t,"esm"),W8t.forEach(t),Jxo=r(tqe," \u2014 "),kV=n(tqe,"A",{href:!0});var U8t=s(kV);Yxo=r(U8t,"EsmModel"),U8t.forEach(t),Kxo=r(tqe," (ESM model)"),tqe.forEach(t),Zxo=i(x),D_=n(x,"LI",{});var aqe=s(D_);Jpe=n(aqe,"STRONG",{});var H8t=s(Jpe);e$o=r(H8t,"flaubert"),H8t.forEach(t),o$o=r(aqe," \u2014 "),SV=n(aqe,"A",{href:!0});var J8t=s(SV);r$o=r(J8t,"FlaubertModel"),J8t.forEach(t),t$o=r(aqe," (FlauBERT model)"),aqe.forEach(t),a$o=i(x),G_=n(x,"LI",{});var nqe=s(G_);Ype=n(nqe,"STRONG",{});var Y8t=s(Ype);n$o=r(Y8t,"flava"),Y8t.forEach(t),s$o=r(nqe," \u2014 "),RV=n(nqe,"A",{href:!0});var K8t=s(RV);l$o=r(K8t,"FlavaModel"),K8t.forEach(t),i$o=r(nqe," (FLAVA model)"),nqe.forEach(t),d$o=i(x),O_=n(x,"LI",{});var sqe=s(O_);Kpe=n(sqe,"STRONG",{});var Z8t=s(Kpe);m$o=r(Z8t,"fnet"),Z8t.forEach(t),c$o=r(sqe," \u2014 "),PV=n(sqe,"A",{href:!0});var e9t=s(PV);f$o=r(e9t,"FNetModel"),e9t.forEach(t),g$o=r(sqe," (FNet model)"),sqe.forEach(t),h$o=i(x),V_=n(x,"LI",{});var lqe=s(V_);Zpe=n(lqe,"STRONG",{});var o9t=s(Zpe);u$o=r(o9t,"fsmt"),o9t.forEach(t),p$o=r(lqe," \u2014 "),BV=n(lqe,"A",{href:!0});var r9t=s(BV);_$o=r(r9t,"FSMTModel"),r9t.forEach(t),b$o=r(lqe," (FairSeq Machine-Translation model)"),lqe.forEach(t),v$o=i(x),_l=n(x,"LI",{});var HB=s(_l);e_e=n(HB,"STRONG",{});var t9t=s(e_e);F$o=r(t9t,"funnel"),t9t.forEach(t),T$o=r(HB," \u2014 "),IV=n(HB,"A",{href:!0});var a9t=s(IV);M$o=r(a9t,"FunnelModel"),a9t.forEach(t),E$o=r(HB," or "),NV=n(HB,"A",{href:!0});var n9t=s(NV);C$o=r(n9t,"FunnelBaseModel"),n9t.forEach(t),w$o=r(HB," (Funnel Transformer model)"),HB.forEach(t),A$o=i(x),X_=n(x,"LI",{});var iqe=s(X_);o_e=n(iqe,"STRONG",{});var s9t=s(o_e);L$o=r(s9t,"glpn"),s9t.forEach(t),y$o=r(iqe," \u2014 "),qV=n(iqe,"A",{href:!0});var l9t=s(qV);x$o=r(l9t,"GLPNModel"),l9t.forEach(t),$$o=r(iqe," (GLPN model)"),iqe.forEach(t),k$o=i(x),z_=n(x,"LI",{});var dqe=s(z_);r_e=n(dqe,"STRONG",{});var i9t=s(r_e);S$o=r(i9t,"gpt2"),i9t.forEach(t),R$o=r(dqe," \u2014 "),jV=n(dqe,"A",{href:!0});var d9t=s(jV);P$o=r(d9t,"GPT2Model"),d9t.forEach(t),B$o=r(dqe," (OpenAI GPT-2 model)"),dqe.forEach(t),I$o=i(x),Q_=n(x,"LI",{});var mqe=s(Q_);t_e=n(mqe,"STRONG",{});var m9t=s(t_e);N$o=r(m9t,"gpt_neo"),m9t.forEach(t),q$o=r(mqe," \u2014 "),DV=n(mqe,"A",{href:!0});var c9t=s(DV);j$o=r(c9t,"GPTNeoModel"),c9t.forEach(t),D$o=r(mqe," (GPT Neo model)"),mqe.forEach(t),G$o=i(x),W_=n(x,"LI",{});var cqe=s(W_);a_e=n(cqe,"STRONG",{});var f9t=s(a_e);O$o=r(f9t,"gpt_neox"),f9t.forEach(t),V$o=r(cqe," \u2014 "),GV=n(cqe,"A",{href:!0});var g9t=s(GV);X$o=r(g9t,"GPTNeoXModel"),g9t.forEach(t),z$o=r(cqe," (GPT NeoX model)"),cqe.forEach(t),Q$o=i(x),U_=n(x,"LI",{});var fqe=s(U_);n_e=n(fqe,"STRONG",{});var h9t=s(n_e);W$o=r(h9t,"gpt_neox_japanese"),h9t.forEach(t),U$o=r(fqe," \u2014 "),OV=n(fqe,"A",{href:!0});var u9t=s(OV);H$o=r(u9t,"GPTNeoXJapaneseModel"),u9t.forEach(t),J$o=r(fqe," (GPT NeoX Japanese model)"),fqe.forEach(t),Y$o=i(x),H_=n(x,"LI",{});var gqe=s(H_);s_e=n(gqe,"STRONG",{});var p9t=s(s_e);K$o=r(p9t,"gptj"),p9t.forEach(t),Z$o=r(gqe," \u2014 "),VV=n(gqe,"A",{href:!0});var _9t=s(VV);eko=r(_9t,"GPTJModel"),_9t.forEach(t),oko=r(gqe," (GPT-J model)"),gqe.forEach(t),rko=i(x),J_=n(x,"LI",{});var hqe=s(J_);l_e=n(hqe,"STRONG",{});var b9t=s(l_e);tko=r(b9t,"groupvit"),b9t.forEach(t),ako=r(hqe," \u2014 "),XV=n(hqe,"A",{href:!0});var v9t=s(XV);nko=r(v9t,"GroupViTModel"),v9t.forEach(t),sko=r(hqe," (GroupViT model)"),hqe.forEach(t),lko=i(x),Y_=n(x,"LI",{});var uqe=s(Y_);i_e=n(uqe,"STRONG",{});var F9t=s(i_e);iko=r(F9t,"hubert"),F9t.forEach(t),dko=r(uqe," \u2014 "),zV=n(uqe,"A",{href:!0});var T9t=s(zV);mko=r(T9t,"HubertModel"),T9t.forEach(t),cko=r(uqe," (Hubert model)"),uqe.forEach(t),fko=i(x),K_=n(x,"LI",{});var pqe=s(K_);d_e=n(pqe,"STRONG",{});var M9t=s(d_e);gko=r(M9t,"ibert"),M9t.forEach(t),hko=r(pqe," \u2014 "),QV=n(pqe,"A",{href:!0});var E9t=s(QV);uko=r(E9t,"IBertModel"),E9t.forEach(t),pko=r(pqe," (I-BERT model)"),pqe.forEach(t),_ko=i(x),Z_=n(x,"LI",{});var _qe=s(Z_);m_e=n(_qe,"STRONG",{});var C9t=s(m_e);bko=r(C9t,"imagegpt"),C9t.forEach(t),vko=r(_qe," \u2014 "),WV=n(_qe,"A",{href:!0});var w9t=s(WV);Fko=r(w9t,"ImageGPTModel"),w9t.forEach(t),Tko=r(_qe," (ImageGPT model)"),_qe.forEach(t),Mko=i(x),e2=n(x,"LI",{});var bqe=s(e2);c_e=n(bqe,"STRONG",{});var A9t=s(c_e);Eko=r(A9t,"layoutlm"),A9t.forEach(t),Cko=r(bqe," \u2014 "),UV=n(bqe,"A",{href:!0});var L9t=s(UV);wko=r(L9t,"LayoutLMModel"),L9t.forEach(t),Ako=r(bqe," (LayoutLM model)"),bqe.forEach(t),Lko=i(x),o2=n(x,"LI",{});var vqe=s(o2);f_e=n(vqe,"STRONG",{});var y9t=s(f_e);yko=r(y9t,"layoutlmv2"),y9t.forEach(t),xko=r(vqe," \u2014 "),HV=n(vqe,"A",{href:!0});var x9t=s(HV);$ko=r(x9t,"LayoutLMv2Model"),x9t.forEach(t),kko=r(vqe," (LayoutLMv2 model)"),vqe.forEach(t),Sko=i(x),r2=n(x,"LI",{});var Fqe=s(r2);g_e=n(Fqe,"STRONG",{});var $9t=s(g_e);Rko=r($9t,"layoutlmv3"),$9t.forEach(t),Pko=r(Fqe," \u2014 "),JV=n(Fqe,"A",{href:!0});var k9t=s(JV);Bko=r(k9t,"LayoutLMv3Model"),k9t.forEach(t),Iko=r(Fqe," (LayoutLMv3 model)"),Fqe.forEach(t),Nko=i(x),t2=n(x,"LI",{});var Tqe=s(t2);h_e=n(Tqe,"STRONG",{});var S9t=s(h_e);qko=r(S9t,"led"),S9t.forEach(t),jko=r(Tqe," \u2014 "),YV=n(Tqe,"A",{href:!0});var R9t=s(YV);Dko=r(R9t,"LEDModel"),R9t.forEach(t),Gko=r(Tqe," (LED model)"),Tqe.forEach(t),Oko=i(x),a2=n(x,"LI",{});var Mqe=s(a2);u_e=n(Mqe,"STRONG",{});var P9t=s(u_e);Vko=r(P9t,"levit"),P9t.forEach(t),Xko=r(Mqe," \u2014 "),KV=n(Mqe,"A",{href:!0});var B9t=s(KV);zko=r(B9t,"LevitModel"),B9t.forEach(t),Qko=r(Mqe," (LeViT model)"),Mqe.forEach(t),Wko=i(x),n2=n(x,"LI",{});var Eqe=s(n2);p_e=n(Eqe,"STRONG",{});var I9t=s(p_e);Uko=r(I9t,"longformer"),I9t.forEach(t),Hko=r(Eqe," \u2014 "),ZV=n(Eqe,"A",{href:!0});var N9t=s(ZV);Jko=r(N9t,"LongformerModel"),N9t.forEach(t),Yko=r(Eqe," (Longformer model)"),Eqe.forEach(t),Kko=i(x),s2=n(x,"LI",{});var Cqe=s(s2);__e=n(Cqe,"STRONG",{});var q9t=s(__e);Zko=r(q9t,"longt5"),q9t.forEach(t),eSo=r(Cqe," \u2014 "),eX=n(Cqe,"A",{href:!0});var j9t=s(eX);oSo=r(j9t,"LongT5Model"),j9t.forEach(t),rSo=r(Cqe," (LongT5 model)"),Cqe.forEach(t),tSo=i(x),l2=n(x,"LI",{});var wqe=s(l2);b_e=n(wqe,"STRONG",{});var D9t=s(b_e);aSo=r(D9t,"luke"),D9t.forEach(t),nSo=r(wqe," \u2014 "),oX=n(wqe,"A",{href:!0});var G9t=s(oX);sSo=r(G9t,"LukeModel"),G9t.forEach(t),lSo=r(wqe," (LUKE model)"),wqe.forEach(t),iSo=i(x),i2=n(x,"LI",{});var Aqe=s(i2);v_e=n(Aqe,"STRONG",{});var O9t=s(v_e);dSo=r(O9t,"lxmert"),O9t.forEach(t),mSo=r(Aqe," \u2014 "),rX=n(Aqe,"A",{href:!0});var V9t=s(rX);cSo=r(V9t,"LxmertModel"),V9t.forEach(t),fSo=r(Aqe," (LXMERT model)"),Aqe.forEach(t),gSo=i(x),d2=n(x,"LI",{});var Lqe=s(d2);F_e=n(Lqe,"STRONG",{});var X9t=s(F_e);hSo=r(X9t,"m2m_100"),X9t.forEach(t),uSo=r(Lqe," \u2014 "),tX=n(Lqe,"A",{href:!0});var z9t=s(tX);pSo=r(z9t,"M2M100Model"),z9t.forEach(t),_So=r(Lqe," (M2M100 model)"),Lqe.forEach(t),bSo=i(x),m2=n(x,"LI",{});var yqe=s(m2);T_e=n(yqe,"STRONG",{});var Q9t=s(T_e);vSo=r(Q9t,"marian"),Q9t.forEach(t),FSo=r(yqe," \u2014 "),aX=n(yqe,"A",{href:!0});var W9t=s(aX);TSo=r(W9t,"MarianModel"),W9t.forEach(t),MSo=r(yqe," (Marian model)"),yqe.forEach(t),ESo=i(x),c2=n(x,"LI",{});var xqe=s(c2);M_e=n(xqe,"STRONG",{});var U9t=s(M_e);CSo=r(U9t,"markuplm"),U9t.forEach(t),wSo=r(xqe," \u2014 "),nX=n(xqe,"A",{href:!0});var H9t=s(nX);ASo=r(H9t,"MarkupLMModel"),H9t.forEach(t),LSo=r(xqe," (MarkupLM model)"),xqe.forEach(t),ySo=i(x),f2=n(x,"LI",{});var $qe=s(f2);E_e=n($qe,"STRONG",{});var J9t=s(E_e);xSo=r(J9t,"maskformer"),J9t.forEach(t),$So=r($qe," \u2014 "),sX=n($qe,"A",{href:!0});var Y9t=s(sX);kSo=r(Y9t,"MaskFormerModel"),Y9t.forEach(t),SSo=r($qe," (MaskFormer model)"),$qe.forEach(t),RSo=i(x),g2=n(x,"LI",{});var kqe=s(g2);C_e=n(kqe,"STRONG",{});var K9t=s(C_e);PSo=r(K9t,"mbart"),K9t.forEach(t),BSo=r(kqe," \u2014 "),lX=n(kqe,"A",{href:!0});var Z9t=s(lX);ISo=r(Z9t,"MBartModel"),Z9t.forEach(t),NSo=r(kqe," (mBART model)"),kqe.forEach(t),qSo=i(x),h2=n(x,"LI",{});var Sqe=s(h2);w_e=n(Sqe,"STRONG",{});var ext=s(w_e);jSo=r(ext,"mctct"),ext.forEach(t),DSo=r(Sqe," \u2014 "),iX=n(Sqe,"A",{href:!0});var oxt=s(iX);GSo=r(oxt,"MCTCTModel"),oxt.forEach(t),OSo=r(Sqe," (M-CTC-T model)"),Sqe.forEach(t),VSo=i(x),u2=n(x,"LI",{});var Rqe=s(u2);A_e=n(Rqe,"STRONG",{});var rxt=s(A_e);XSo=r(rxt,"megatron-bert"),rxt.forEach(t),zSo=r(Rqe," \u2014 "),dX=n(Rqe,"A",{href:!0});var txt=s(dX);QSo=r(txt,"MegatronBertModel"),txt.forEach(t),WSo=r(Rqe," (Megatron-BERT model)"),Rqe.forEach(t),USo=i(x),p2=n(x,"LI",{});var Pqe=s(p2);L_e=n(Pqe,"STRONG",{});var axt=s(L_e);HSo=r(axt,"mobilebert"),axt.forEach(t),JSo=r(Pqe," \u2014 "),mX=n(Pqe,"A",{href:!0});var nxt=s(mX);YSo=r(nxt,"MobileBertModel"),nxt.forEach(t),KSo=r(Pqe," (MobileBERT model)"),Pqe.forEach(t),ZSo=i(x),_2=n(x,"LI",{});var Bqe=s(_2);y_e=n(Bqe,"STRONG",{});var sxt=s(y_e);eRo=r(sxt,"mobilevit"),sxt.forEach(t),oRo=r(Bqe," \u2014 "),cX=n(Bqe,"A",{href:!0});var lxt=s(cX);rRo=r(lxt,"MobileViTModel"),lxt.forEach(t),tRo=r(Bqe," (MobileViT model)"),Bqe.forEach(t),aRo=i(x),b2=n(x,"LI",{});var Iqe=s(b2);x_e=n(Iqe,"STRONG",{});var ixt=s(x_e);nRo=r(ixt,"mpnet"),ixt.forEach(t),sRo=r(Iqe," \u2014 "),fX=n(Iqe,"A",{href:!0});var dxt=s(fX);lRo=r(dxt,"MPNetModel"),dxt.forEach(t),iRo=r(Iqe," (MPNet model)"),Iqe.forEach(t),dRo=i(x),v2=n(x,"LI",{});var Nqe=s(v2);$_e=n(Nqe,"STRONG",{});var mxt=s($_e);mRo=r(mxt,"mt5"),mxt.forEach(t),cRo=r(Nqe," \u2014 "),gX=n(Nqe,"A",{href:!0});var cxt=s(gX);fRo=r(cxt,"MT5Model"),cxt.forEach(t),gRo=r(Nqe," (MT5 model)"),Nqe.forEach(t),hRo=i(x),F2=n(x,"LI",{});var qqe=s(F2);k_e=n(qqe,"STRONG",{});var fxt=s(k_e);uRo=r(fxt,"mvp"),fxt.forEach(t),pRo=r(qqe," \u2014 "),hX=n(qqe,"A",{href:!0});var gxt=s(hX);_Ro=r(gxt,"MvpModel"),gxt.forEach(t),bRo=r(qqe," (MVP model)"),qqe.forEach(t),vRo=i(x),T2=n(x,"LI",{});var jqe=s(T2);S_e=n(jqe,"STRONG",{});var hxt=s(S_e);FRo=r(hxt,"nezha"),hxt.forEach(t),TRo=r(jqe," \u2014 "),uX=n(jqe,"A",{href:!0});var uxt=s(uX);MRo=r(uxt,"NezhaModel"),uxt.forEach(t),ERo=r(jqe," (Nezha model)"),jqe.forEach(t),CRo=i(x),M2=n(x,"LI",{});var Dqe=s(M2);R_e=n(Dqe,"STRONG",{});var pxt=s(R_e);wRo=r(pxt,"nllb"),pxt.forEach(t),ARo=r(Dqe," \u2014 "),pX=n(Dqe,"A",{href:!0});var _xt=s(pX);LRo=r(_xt,"M2M100Model"),_xt.forEach(t),yRo=r(Dqe," (NLLB model)"),Dqe.forEach(t),xRo=i(x),E2=n(x,"LI",{});var Gqe=s(E2);P_e=n(Gqe,"STRONG",{});var bxt=s(P_e);$Ro=r(bxt,"nystromformer"),bxt.forEach(t),kRo=r(Gqe," \u2014 "),_X=n(Gqe,"A",{href:!0});var vxt=s(_X);SRo=r(vxt,"NystromformerModel"),vxt.forEach(t),RRo=r(Gqe," (Nystr\xF6mformer model)"),Gqe.forEach(t),PRo=i(x),C2=n(x,"LI",{});var Oqe=s(C2);B_e=n(Oqe,"STRONG",{});var Fxt=s(B_e);BRo=r(Fxt,"openai-gpt"),Fxt.forEach(t),IRo=r(Oqe," \u2014 "),bX=n(Oqe,"A",{href:!0});var Txt=s(bX);NRo=r(Txt,"OpenAIGPTModel"),Txt.forEach(t),qRo=r(Oqe," (OpenAI GPT model)"),Oqe.forEach(t),jRo=i(x),w2=n(x,"LI",{});var Vqe=s(w2);I_e=n(Vqe,"STRONG",{});var Mxt=s(I_e);DRo=r(Mxt,"opt"),Mxt.forEach(t),GRo=r(Vqe," \u2014 "),vX=n(Vqe,"A",{href:!0});var Ext=s(vX);ORo=r(Ext,"OPTModel"),Ext.forEach(t),VRo=r(Vqe," (OPT model)"),Vqe.forEach(t),XRo=i(x),A2=n(x,"LI",{});var Xqe=s(A2);N_e=n(Xqe,"STRONG",{});var Cxt=s(N_e);zRo=r(Cxt,"owlvit"),Cxt.forEach(t),QRo=r(Xqe," \u2014 "),FX=n(Xqe,"A",{href:!0});var wxt=s(FX);WRo=r(wxt,"OwlViTModel"),wxt.forEach(t),URo=r(Xqe," (OWL-ViT model)"),Xqe.forEach(t),HRo=i(x),L2=n(x,"LI",{});var zqe=s(L2);q_e=n(zqe,"STRONG",{});var Axt=s(q_e);JRo=r(Axt,"pegasus"),Axt.forEach(t),YRo=r(zqe," \u2014 "),TX=n(zqe,"A",{href:!0});var Lxt=s(TX);KRo=r(Lxt,"PegasusModel"),Lxt.forEach(t),ZRo=r(zqe," (Pegasus model)"),zqe.forEach(t),ePo=i(x),y2=n(x,"LI",{});var Qqe=s(y2);j_e=n(Qqe,"STRONG",{});var yxt=s(j_e);oPo=r(yxt,"pegasus_x"),yxt.forEach(t),rPo=r(Qqe," \u2014 "),MX=n(Qqe,"A",{href:!0});var xxt=s(MX);tPo=r(xxt,"PegasusXModel"),xxt.forEach(t),aPo=r(Qqe," (PEGASUS-X model)"),Qqe.forEach(t),nPo=i(x),x2=n(x,"LI",{});var Wqe=s(x2);D_e=n(Wqe,"STRONG",{});var $xt=s(D_e);sPo=r($xt,"perceiver"),$xt.forEach(t),lPo=r(Wqe," \u2014 "),EX=n(Wqe,"A",{href:!0});var kxt=s(EX);iPo=r(kxt,"PerceiverModel"),kxt.forEach(t),dPo=r(Wqe," (Perceiver model)"),Wqe.forEach(t),mPo=i(x),$2=n(x,"LI",{});var Uqe=s($2);G_e=n(Uqe,"STRONG",{});var Sxt=s(G_e);cPo=r(Sxt,"plbart"),Sxt.forEach(t),fPo=r(Uqe," \u2014 "),CX=n(Uqe,"A",{href:!0});var Rxt=s(CX);gPo=r(Rxt,"PLBartModel"),Rxt.forEach(t),hPo=r(Uqe," (PLBart model)"),Uqe.forEach(t),uPo=i(x),k2=n(x,"LI",{});var Hqe=s(k2);O_e=n(Hqe,"STRONG",{});var Pxt=s(O_e);pPo=r(Pxt,"poolformer"),Pxt.forEach(t),_Po=r(Hqe," \u2014 "),wX=n(Hqe,"A",{href:!0});var Bxt=s(wX);bPo=r(Bxt,"PoolFormerModel"),Bxt.forEach(t),vPo=r(Hqe," (PoolFormer model)"),Hqe.forEach(t),FPo=i(x),S2=n(x,"LI",{});var Jqe=s(S2);V_e=n(Jqe,"STRONG",{});var Ixt=s(V_e);TPo=r(Ixt,"prophetnet"),Ixt.forEach(t),MPo=r(Jqe," \u2014 "),AX=n(Jqe,"A",{href:!0});var Nxt=s(AX);EPo=r(Nxt,"ProphetNetModel"),Nxt.forEach(t),CPo=r(Jqe," (ProphetNet model)"),Jqe.forEach(t),wPo=i(x),R2=n(x,"LI",{});var Yqe=s(R2);X_e=n(Yqe,"STRONG",{});var qxt=s(X_e);APo=r(qxt,"qdqbert"),qxt.forEach(t),LPo=r(Yqe," \u2014 "),LX=n(Yqe,"A",{href:!0});var jxt=s(LX);yPo=r(jxt,"QDQBertModel"),jxt.forEach(t),xPo=r(Yqe," (QDQBert model)"),Yqe.forEach(t),$Po=i(x),P2=n(x,"LI",{});var Kqe=s(P2);z_e=n(Kqe,"STRONG",{});var Dxt=s(z_e);kPo=r(Dxt,"reformer"),Dxt.forEach(t),SPo=r(Kqe," \u2014 "),yX=n(Kqe,"A",{href:!0});var Gxt=s(yX);RPo=r(Gxt,"ReformerModel"),Gxt.forEach(t),PPo=r(Kqe," (Reformer model)"),Kqe.forEach(t),BPo=i(x),B2=n(x,"LI",{});var Zqe=s(B2);Q_e=n(Zqe,"STRONG",{});var Oxt=s(Q_e);IPo=r(Oxt,"regnet"),Oxt.forEach(t),NPo=r(Zqe," \u2014 "),xX=n(Zqe,"A",{href:!0});var Vxt=s(xX);qPo=r(Vxt,"RegNetModel"),Vxt.forEach(t),jPo=r(Zqe," (RegNet model)"),Zqe.forEach(t),DPo=i(x),I2=n(x,"LI",{});var eje=s(I2);W_e=n(eje,"STRONG",{});var Xxt=s(W_e);GPo=r(Xxt,"rembert"),Xxt.forEach(t),OPo=r(eje," \u2014 "),$X=n(eje,"A",{href:!0});var zxt=s($X);VPo=r(zxt,"RemBertModel"),zxt.forEach(t),XPo=r(eje," (RemBERT model)"),eje.forEach(t),zPo=i(x),N2=n(x,"LI",{});var oje=s(N2);U_e=n(oje,"STRONG",{});var Qxt=s(U_e);QPo=r(Qxt,"resnet"),Qxt.forEach(t),WPo=r(oje," \u2014 "),kX=n(oje,"A",{href:!0});var Wxt=s(kX);UPo=r(Wxt,"ResNetModel"),Wxt.forEach(t),HPo=r(oje," (ResNet model)"),oje.forEach(t),JPo=i(x),q2=n(x,"LI",{});var rje=s(q2);H_e=n(rje,"STRONG",{});var Uxt=s(H_e);YPo=r(Uxt,"retribert"),Uxt.forEach(t),KPo=r(rje," \u2014 "),SX=n(rje,"A",{href:!0});var Hxt=s(SX);ZPo=r(Hxt,"RetriBertModel"),Hxt.forEach(t),eBo=r(rje," (RetriBERT model)"),rje.forEach(t),oBo=i(x),j2=n(x,"LI",{});var tje=s(j2);J_e=n(tje,"STRONG",{});var Jxt=s(J_e);rBo=r(Jxt,"roberta"),Jxt.forEach(t),tBo=r(tje," \u2014 "),RX=n(tje,"A",{href:!0});var Yxt=s(RX);aBo=r(Yxt,"RobertaModel"),Yxt.forEach(t),nBo=r(tje," (RoBERTa model)"),tje.forEach(t),sBo=i(x),D2=n(x,"LI",{});var aje=s(D2);Y_e=n(aje,"STRONG",{});var Kxt=s(Y_e);lBo=r(Kxt,"roformer"),Kxt.forEach(t),iBo=r(aje," \u2014 "),PX=n(aje,"A",{href:!0});var Zxt=s(PX);dBo=r(Zxt,"RoFormerModel"),Zxt.forEach(t),mBo=r(aje," (RoFormer model)"),aje.forEach(t),cBo=i(x),G2=n(x,"LI",{});var nje=s(G2);K_e=n(nje,"STRONG",{});var e$t=s(K_e);fBo=r(e$t,"segformer"),e$t.forEach(t),gBo=r(nje," \u2014 "),BX=n(nje,"A",{href:!0});var o$t=s(BX);hBo=r(o$t,"SegformerModel"),o$t.forEach(t),uBo=r(nje," (SegFormer model)"),nje.forEach(t),pBo=i(x),O2=n(x,"LI",{});var sje=s(O2);Z_e=n(sje,"STRONG",{});var r$t=s(Z_e);_Bo=r(r$t,"sew"),r$t.forEach(t),bBo=r(sje," \u2014 "),IX=n(sje,"A",{href:!0});var t$t=s(IX);vBo=r(t$t,"SEWModel"),t$t.forEach(t),FBo=r(sje," (SEW model)"),sje.forEach(t),TBo=i(x),V2=n(x,"LI",{});var lje=s(V2);e2e=n(lje,"STRONG",{});var a$t=s(e2e);MBo=r(a$t,"sew-d"),a$t.forEach(t),EBo=r(lje," \u2014 "),NX=n(lje,"A",{href:!0});var n$t=s(NX);CBo=r(n$t,"SEWDModel"),n$t.forEach(t),wBo=r(lje," (SEW-D model)"),lje.forEach(t),ABo=i(x),X2=n(x,"LI",{});var ije=s(X2);o2e=n(ije,"STRONG",{});var s$t=s(o2e);LBo=r(s$t,"speech_to_text"),s$t.forEach(t),yBo=r(ije," \u2014 "),qX=n(ije,"A",{href:!0});var l$t=s(qX);xBo=r(l$t,"Speech2TextModel"),l$t.forEach(t),$Bo=r(ije," (Speech2Text model)"),ije.forEach(t),kBo=i(x),z2=n(x,"LI",{});var dje=s(z2);r2e=n(dje,"STRONG",{});var i$t=s(r2e);SBo=r(i$t,"splinter"),i$t.forEach(t),RBo=r(dje," \u2014 "),jX=n(dje,"A",{href:!0});var d$t=s(jX);PBo=r(d$t,"SplinterModel"),d$t.forEach(t),BBo=r(dje," (Splinter model)"),dje.forEach(t),IBo=i(x),Q2=n(x,"LI",{});var mje=s(Q2);t2e=n(mje,"STRONG",{});var m$t=s(t2e);NBo=r(m$t,"squeezebert"),m$t.forEach(t),qBo=r(mje," \u2014 "),DX=n(mje,"A",{href:!0});var c$t=s(DX);jBo=r(c$t,"SqueezeBertModel"),c$t.forEach(t),DBo=r(mje," (SqueezeBERT model)"),mje.forEach(t),GBo=i(x),W2=n(x,"LI",{});var cje=s(W2);a2e=n(cje,"STRONG",{});var f$t=s(a2e);OBo=r(f$t,"swin"),f$t.forEach(t),VBo=r(cje," \u2014 "),GX=n(cje,"A",{href:!0});var g$t=s(GX);XBo=r(g$t,"SwinModel"),g$t.forEach(t),zBo=r(cje," (Swin Transformer model)"),cje.forEach(t),QBo=i(x),U2=n(x,"LI",{});var fje=s(U2);n2e=n(fje,"STRONG",{});var h$t=s(n2e);WBo=r(h$t,"swinv2"),h$t.forEach(t),UBo=r(fje," \u2014 "),OX=n(fje,"A",{href:!0});var u$t=s(OX);HBo=r(u$t,"Swinv2Model"),u$t.forEach(t),JBo=r(fje," (Swin Transformer V2 model)"),fje.forEach(t),YBo=i(x),H2=n(x,"LI",{});var gje=s(H2);s2e=n(gje,"STRONG",{});var p$t=s(s2e);KBo=r(p$t,"t5"),p$t.forEach(t),ZBo=r(gje," \u2014 "),VX=n(gje,"A",{href:!0});var _$t=s(VX);eIo=r(_$t,"T5Model"),_$t.forEach(t),oIo=r(gje," (T5 model)"),gje.forEach(t),rIo=i(x),J2=n(x,"LI",{});var hje=s(J2);l2e=n(hje,"STRONG",{});var b$t=s(l2e);tIo=r(b$t,"tapas"),b$t.forEach(t),aIo=r(hje," \u2014 "),XX=n(hje,"A",{href:!0});var v$t=s(XX);nIo=r(v$t,"TapasModel"),v$t.forEach(t),sIo=r(hje," (TAPAS model)"),hje.forEach(t),lIo=i(x),Y2=n(x,"LI",{});var uje=s(Y2);i2e=n(uje,"STRONG",{});var F$t=s(i2e);iIo=r(F$t,"time_series_transformer"),F$t.forEach(t),dIo=r(uje," \u2014 "),zX=n(uje,"A",{href:!0});var T$t=s(zX);mIo=r(T$t,"TimeSeriesTransformerModel"),T$t.forEach(t),cIo=r(uje," (Time Series Transformer model)"),uje.forEach(t),fIo=i(x),K2=n(x,"LI",{});var pje=s(K2);d2e=n(pje,"STRONG",{});var M$t=s(d2e);gIo=r(M$t,"trajectory_transformer"),M$t.forEach(t),hIo=r(pje," \u2014 "),QX=n(pje,"A",{href:!0});var E$t=s(QX);uIo=r(E$t,"TrajectoryTransformerModel"),E$t.forEach(t),pIo=r(pje," (Trajectory Transformer model)"),pje.forEach(t),_Io=i(x),Z2=n(x,"LI",{});var _je=s(Z2);m2e=n(_je,"STRONG",{});var C$t=s(m2e);bIo=r(C$t,"transfo-xl"),C$t.forEach(t),vIo=r(_je," \u2014 "),WX=n(_je,"A",{href:!0});var w$t=s(WX);FIo=r(w$t,"TransfoXLModel"),w$t.forEach(t),TIo=r(_je," (Transformer-XL model)"),_je.forEach(t),MIo=i(x),e1=n(x,"LI",{});var bje=s(e1);c2e=n(bje,"STRONG",{});var A$t=s(c2e);EIo=r(A$t,"unispeech"),A$t.forEach(t),CIo=r(bje," \u2014 "),UX=n(bje,"A",{href:!0});var L$t=s(UX);wIo=r(L$t,"UniSpeechModel"),L$t.forEach(t),AIo=r(bje," (UniSpeech model)"),bje.forEach(t),LIo=i(x),o1=n(x,"LI",{});var vje=s(o1);f2e=n(vje,"STRONG",{});var y$t=s(f2e);yIo=r(y$t,"unispeech-sat"),y$t.forEach(t),xIo=r(vje," \u2014 "),HX=n(vje,"A",{href:!0});var x$t=s(HX);$Io=r(x$t,"UniSpeechSatModel"),x$t.forEach(t),kIo=r(vje," (UniSpeechSat model)"),vje.forEach(t),SIo=i(x),r1=n(x,"LI",{});var Fje=s(r1);g2e=n(Fje,"STRONG",{});var $$t=s(g2e);RIo=r($$t,"van"),$$t.forEach(t),PIo=r(Fje," \u2014 "),JX=n(Fje,"A",{href:!0});var k$t=s(JX);BIo=r(k$t,"VanModel"),k$t.forEach(t),IIo=r(Fje," (VAN model)"),Fje.forEach(t),NIo=i(x),t1=n(x,"LI",{});var Tje=s(t1);h2e=n(Tje,"STRONG",{});var S$t=s(h2e);qIo=r(S$t,"videomae"),S$t.forEach(t),jIo=r(Tje," \u2014 "),YX=n(Tje,"A",{href:!0});var R$t=s(YX);DIo=r(R$t,"VideoMAEModel"),R$t.forEach(t),GIo=r(Tje," (VideoMAE model)"),Tje.forEach(t),OIo=i(x),a1=n(x,"LI",{});var Mje=s(a1);u2e=n(Mje,"STRONG",{});var P$t=s(u2e);VIo=r(P$t,"vilt"),P$t.forEach(t),XIo=r(Mje," \u2014 "),KX=n(Mje,"A",{href:!0});var B$t=s(KX);zIo=r(B$t,"ViltModel"),B$t.forEach(t),QIo=r(Mje," (ViLT model)"),Mje.forEach(t),WIo=i(x),n1=n(x,"LI",{});var Eje=s(n1);p2e=n(Eje,"STRONG",{});var I$t=s(p2e);UIo=r(I$t,"vision-text-dual-encoder"),I$t.forEach(t),HIo=r(Eje," \u2014 "),ZX=n(Eje,"A",{href:!0});var N$t=s(ZX);JIo=r(N$t,"VisionTextDualEncoderModel"),N$t.forEach(t),YIo=r(Eje," (VisionTextDualEncoder model)"),Eje.forEach(t),KIo=i(x),s1=n(x,"LI",{});var Cje=s(s1);_2e=n(Cje,"STRONG",{});var q$t=s(_2e);ZIo=r(q$t,"visual_bert"),q$t.forEach(t),eNo=r(Cje," \u2014 "),ez=n(Cje,"A",{href:!0});var j$t=s(ez);oNo=r(j$t,"VisualBertModel"),j$t.forEach(t),rNo=r(Cje," (VisualBERT model)"),Cje.forEach(t),tNo=i(x),l1=n(x,"LI",{});var wje=s(l1);b2e=n(wje,"STRONG",{});var D$t=s(b2e);aNo=r(D$t,"vit"),D$t.forEach(t),nNo=r(wje," \u2014 "),oz=n(wje,"A",{href:!0});var G$t=s(oz);sNo=r(G$t,"ViTModel"),G$t.forEach(t),lNo=r(wje," (ViT model)"),wje.forEach(t),iNo=i(x),i1=n(x,"LI",{});var Aje=s(i1);v2e=n(Aje,"STRONG",{});var O$t=s(v2e);dNo=r(O$t,"vit_mae"),O$t.forEach(t),mNo=r(Aje," \u2014 "),rz=n(Aje,"A",{href:!0});var V$t=s(rz);cNo=r(V$t,"ViTMAEModel"),V$t.forEach(t),fNo=r(Aje," (ViTMAE model)"),Aje.forEach(t),gNo=i(x),d1=n(x,"LI",{});var Lje=s(d1);F2e=n(Lje,"STRONG",{});var X$t=s(F2e);hNo=r(X$t,"vit_msn"),X$t.forEach(t),uNo=r(Lje," \u2014 "),tz=n(Lje,"A",{href:!0});var z$t=s(tz);pNo=r(z$t,"ViTMSNModel"),z$t.forEach(t),_No=r(Lje," (ViTMSN model)"),Lje.forEach(t),bNo=i(x),m1=n(x,"LI",{});var yje=s(m1);T2e=n(yje,"STRONG",{});var Q$t=s(T2e);vNo=r(Q$t,"wav2vec2"),Q$t.forEach(t),FNo=r(yje," \u2014 "),az=n(yje,"A",{href:!0});var W$t=s(az);TNo=r(W$t,"Wav2Vec2Model"),W$t.forEach(t),MNo=r(yje," (Wav2Vec2 model)"),yje.forEach(t),ENo=i(x),c1=n(x,"LI",{});var xje=s(c1);M2e=n(xje,"STRONG",{});var U$t=s(M2e);CNo=r(U$t,"wav2vec2-conformer"),U$t.forEach(t),wNo=r(xje," \u2014 "),nz=n(xje,"A",{href:!0});var H$t=s(nz);ANo=r(H$t,"Wav2Vec2ConformerModel"),H$t.forEach(t),LNo=r(xje," (Wav2Vec2-Conformer model)"),xje.forEach(t),yNo=i(x),f1=n(x,"LI",{});var $je=s(f1);E2e=n($je,"STRONG",{});var J$t=s(E2e);xNo=r(J$t,"wavlm"),J$t.forEach(t),$No=r($je," \u2014 "),sz=n($je,"A",{href:!0});var Y$t=s(sz);kNo=r(Y$t,"WavLMModel"),Y$t.forEach(t),SNo=r($je," (WavLM model)"),$je.forEach(t),RNo=i(x),g1=n(x,"LI",{});var kje=s(g1);C2e=n(kje,"STRONG",{});var K$t=s(C2e);PNo=r(K$t,"xclip"),K$t.forEach(t),BNo=r(kje," \u2014 "),lz=n(kje,"A",{href:!0});var Z$t=s(lz);INo=r(Z$t,"XCLIPModel"),Z$t.forEach(t),NNo=r(kje," (X-CLIP model)"),kje.forEach(t),qNo=i(x),h1=n(x,"LI",{});var Sje=s(h1);w2e=n(Sje,"STRONG",{});var ekt=s(w2e);jNo=r(ekt,"xglm"),ekt.forEach(t),DNo=r(Sje," \u2014 "),iz=n(Sje,"A",{href:!0});var okt=s(iz);GNo=r(okt,"XGLMModel"),okt.forEach(t),ONo=r(Sje," (XGLM model)"),Sje.forEach(t),VNo=i(x),u1=n(x,"LI",{});var Rje=s(u1);A2e=n(Rje,"STRONG",{});var rkt=s(A2e);XNo=r(rkt,"xlm"),rkt.forEach(t),zNo=r(Rje," \u2014 "),dz=n(Rje,"A",{href:!0});var tkt=s(dz);QNo=r(tkt,"XLMModel"),tkt.forEach(t),WNo=r(Rje," (XLM model)"),Rje.forEach(t),UNo=i(x),p1=n(x,"LI",{});var Pje=s(p1);L2e=n(Pje,"STRONG",{});var akt=s(L2e);HNo=r(akt,"xlm-prophetnet"),akt.forEach(t),JNo=r(Pje," \u2014 "),mz=n(Pje,"A",{href:!0});var nkt=s(mz);YNo=r(nkt,"XLMProphetNetModel"),nkt.forEach(t),KNo=r(Pje," (XLM-ProphetNet model)"),Pje.forEach(t),ZNo=i(x),_1=n(x,"LI",{});var Bje=s(_1);y2e=n(Bje,"STRONG",{});var skt=s(y2e);eqo=r(skt,"xlm-roberta"),skt.forEach(t),oqo=r(Bje," \u2014 "),cz=n(Bje,"A",{href:!0});var lkt=s(cz);rqo=r(lkt,"XLMRobertaModel"),lkt.forEach(t),tqo=r(Bje," (XLM-RoBERTa model)"),Bje.forEach(t),aqo=i(x),b1=n(x,"LI",{});var Ije=s(b1);x2e=n(Ije,"STRONG",{});var ikt=s(x2e);nqo=r(ikt,"xlm-roberta-xl"),ikt.forEach(t),sqo=r(Ije," \u2014 "),fz=n(Ije,"A",{href:!0});var dkt=s(fz);lqo=r(dkt,"XLMRobertaXLModel"),dkt.forEach(t),iqo=r(Ije," (XLM-RoBERTa-XL model)"),Ije.forEach(t),dqo=i(x),v1=n(x,"LI",{});var Nje=s(v1);$2e=n(Nje,"STRONG",{});var mkt=s($2e);mqo=r(mkt,"xlnet"),mkt.forEach(t),cqo=r(Nje," \u2014 "),gz=n(Nje,"A",{href:!0});var ckt=s(gz);fqo=r(ckt,"XLNetModel"),ckt.forEach(t),gqo=r(Nje," (XLNet model)"),Nje.forEach(t),hqo=i(x),F1=n(x,"LI",{});var qje=s(F1);k2e=n(qje,"STRONG",{});var fkt=s(k2e);uqo=r(fkt,"yolos"),fkt.forEach(t),pqo=r(qje," \u2014 "),hz=n(qje,"A",{href:!0});var gkt=s(hz);_qo=r(gkt,"YolosModel"),gkt.forEach(t),bqo=r(qje," (YOLOS model)"),qje.forEach(t),vqo=i(x),T1=n(x,"LI",{});var jje=s(T1);S2e=n(jje,"STRONG",{});var hkt=s(S2e);Fqo=r(hkt,"yoso"),hkt.forEach(t),Tqo=r(jje," \u2014 "),uz=n(jje,"A",{href:!0});var ukt=s(uz);Mqo=r(ukt,"YosoModel"),ukt.forEach(t),Eqo=r(jje," (YOSO model)"),jje.forEach(t),x.forEach(t),Cqo=i(Fa),M1=n(Fa,"P",{});var Dje=s(M1);wqo=r(Dje,"The model is set in evaluation mode by default using "),R2e=n(Dje,"CODE",{});var pkt=s(R2e);Aqo=r(pkt,"model.eval()"),pkt.forEach(t),Lqo=r(Dje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=n(Dje,"CODE",{});var _kt=s(P2e);yqo=r(_kt,"model.train()"),_kt.forEach(t),Dje.forEach(t),xqo=i(Fa),T(E1.$$.fragment,Fa),Fa.forEach(t),Al.forEach(t),oeo=i(c),Fd=n(c,"H2",{class:!0});var uro=s(Fd);C1=n(uro,"A",{id:!0,class:!0,href:!0});var bkt=s(C1);B2e=n(bkt,"SPAN",{});var vkt=s(B2e);T(kx.$$.fragment,vkt),vkt.forEach(t),bkt.forEach(t),$qo=i(uro),I2e=n(uro,"SPAN",{});var Fkt=s(I2e);kqo=r(Fkt,"AutoModelForPreTraining"),Fkt.forEach(t),uro.forEach(t),reo=i(c),Bo=n(c,"DIV",{class:!0});var Ll=s(Bo);T(Sx.$$.fragment,Ll),Sqo=i(Ll),Td=n(Ll,"P",{});var eie=s(Td);Rqo=r(eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),pz=n(eie,"A",{href:!0});var Tkt=s(pz);Pqo=r(Tkt,"from_pretrained()"),Tkt.forEach(t),Bqo=r(eie," class method or the "),_z=n(eie,"A",{href:!0});var Mkt=s(_z);Iqo=r(Mkt,"from_config()"),Mkt.forEach(t),Nqo=r(eie,` class
method.`),eie.forEach(t),qqo=i(Ll),Rx=n(Ll,"P",{});var pro=s(Rx);jqo=r(pro,"This class cannot be instantiated directly using "),N2e=n(pro,"CODE",{});var Ekt=s(N2e);Dqo=r(Ekt,"__init__()"),Ekt.forEach(t),Gqo=r(pro," (throws an error)."),pro.forEach(t),Oqo=i(Ll),bt=n(Ll,"DIV",{class:!0});var Jy=s(bt);T(Px.$$.fragment,Jy),Vqo=i(Jy),q2e=n(Jy,"P",{});var Ckt=s(q2e);Xqo=r(Ckt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ckt.forEach(t),zqo=i(Jy),Md=n(Jy,"P",{});var oie=s(Md);Qqo=r(oie,`Note:
Loading a model from its configuration file does `),j2e=n(oie,"STRONG",{});var wkt=s(j2e);Wqo=r(wkt,"not"),wkt.forEach(t),Uqo=r(oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),bz=n(oie,"A",{href:!0});var Akt=s(bz);Hqo=r(Akt,"from_pretrained()"),Akt.forEach(t),Jqo=r(oie," to load the model weights."),oie.forEach(t),Yqo=i(Jy),T(w1.$$.fragment,Jy),Jy.forEach(t),Kqo=i(Ll),eo=n(Ll,"DIV",{class:!0});var Ta=s(eo);T(Bx.$$.fragment,Ta),Zqo=i(Ta),D2e=n(Ta,"P",{});var Lkt=s(D2e);ejo=r(Lkt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Lkt.forEach(t),ojo=i(Ta),Ya=n(Ta,"P",{});var Yy=s(Ya);rjo=r(Yy,"The model class to instantiate is selected based on the "),G2e=n(Yy,"CODE",{});var ykt=s(G2e);tjo=r(ykt,"model_type"),ykt.forEach(t),ajo=r(Yy,` property of the config object (either
passed as an argument or loaded from `),O2e=n(Yy,"CODE",{});var xkt=s(O2e);njo=r(xkt,"pretrained_model_name_or_path"),xkt.forEach(t),sjo=r(Yy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=n(Yy,"CODE",{});var $kt=s(V2e);ljo=r($kt,"pretrained_model_name_or_path"),$kt.forEach(t),ijo=r(Yy,":"),Yy.forEach(t),djo=i(Ta),G=n(Ta,"UL",{});var O=s(G);A1=n(O,"LI",{});var Gje=s(A1);X2e=n(Gje,"STRONG",{});var kkt=s(X2e);mjo=r(kkt,"albert"),kkt.forEach(t),cjo=r(Gje," \u2014 "),vz=n(Gje,"A",{href:!0});var Skt=s(vz);fjo=r(Skt,"AlbertForPreTraining"),Skt.forEach(t),gjo=r(Gje," (ALBERT model)"),Gje.forEach(t),hjo=i(O),L1=n(O,"LI",{});var Oje=s(L1);z2e=n(Oje,"STRONG",{});var Rkt=s(z2e);ujo=r(Rkt,"bart"),Rkt.forEach(t),pjo=r(Oje," \u2014 "),Fz=n(Oje,"A",{href:!0});var Pkt=s(Fz);_jo=r(Pkt,"BartForConditionalGeneration"),Pkt.forEach(t),bjo=r(Oje," (BART model)"),Oje.forEach(t),vjo=i(O),y1=n(O,"LI",{});var Vje=s(y1);Q2e=n(Vje,"STRONG",{});var Bkt=s(Q2e);Fjo=r(Bkt,"bert"),Bkt.forEach(t),Tjo=r(Vje," \u2014 "),Tz=n(Vje,"A",{href:!0});var Ikt=s(Tz);Mjo=r(Ikt,"BertForPreTraining"),Ikt.forEach(t),Ejo=r(Vje," (BERT model)"),Vje.forEach(t),Cjo=i(O),x1=n(O,"LI",{});var Xje=s(x1);W2e=n(Xje,"STRONG",{});var Nkt=s(W2e);wjo=r(Nkt,"big_bird"),Nkt.forEach(t),Ajo=r(Xje," \u2014 "),Mz=n(Xje,"A",{href:!0});var qkt=s(Mz);Ljo=r(qkt,"BigBirdForPreTraining"),qkt.forEach(t),yjo=r(Xje," (BigBird model)"),Xje.forEach(t),xjo=i(O),$1=n(O,"LI",{});var zje=s($1);U2e=n(zje,"STRONG",{});var jkt=s(U2e);$jo=r(jkt,"bloom"),jkt.forEach(t),kjo=r(zje," \u2014 "),Ez=n(zje,"A",{href:!0});var Dkt=s(Ez);Sjo=r(Dkt,"BloomForCausalLM"),Dkt.forEach(t),Rjo=r(zje," (BLOOM model)"),zje.forEach(t),Pjo=i(O),k1=n(O,"LI",{});var Qje=s(k1);H2e=n(Qje,"STRONG",{});var Gkt=s(H2e);Bjo=r(Gkt,"camembert"),Gkt.forEach(t),Ijo=r(Qje," \u2014 "),Cz=n(Qje,"A",{href:!0});var Okt=s(Cz);Njo=r(Okt,"CamembertForMaskedLM"),Okt.forEach(t),qjo=r(Qje," (CamemBERT model)"),Qje.forEach(t),jjo=i(O),S1=n(O,"LI",{});var Wje=s(S1);J2e=n(Wje,"STRONG",{});var Vkt=s(J2e);Djo=r(Vkt,"ctrl"),Vkt.forEach(t),Gjo=r(Wje," \u2014 "),wz=n(Wje,"A",{href:!0});var Xkt=s(wz);Ojo=r(Xkt,"CTRLLMHeadModel"),Xkt.forEach(t),Vjo=r(Wje," (CTRL model)"),Wje.forEach(t),Xjo=i(O),R1=n(O,"LI",{});var Uje=s(R1);Y2e=n(Uje,"STRONG",{});var zkt=s(Y2e);zjo=r(zkt,"data2vec-text"),zkt.forEach(t),Qjo=r(Uje," \u2014 "),Az=n(Uje,"A",{href:!0});var Qkt=s(Az);Wjo=r(Qkt,"Data2VecTextForMaskedLM"),Qkt.forEach(t),Ujo=r(Uje," (Data2VecText model)"),Uje.forEach(t),Hjo=i(O),P1=n(O,"LI",{});var Hje=s(P1);K2e=n(Hje,"STRONG",{});var Wkt=s(K2e);Jjo=r(Wkt,"deberta"),Wkt.forEach(t),Yjo=r(Hje," \u2014 "),Lz=n(Hje,"A",{href:!0});var Ukt=s(Lz);Kjo=r(Ukt,"DebertaForMaskedLM"),Ukt.forEach(t),Zjo=r(Hje," (DeBERTa model)"),Hje.forEach(t),eDo=i(O),B1=n(O,"LI",{});var Jje=s(B1);Z2e=n(Jje,"STRONG",{});var Hkt=s(Z2e);oDo=r(Hkt,"deberta-v2"),Hkt.forEach(t),rDo=r(Jje," \u2014 "),yz=n(Jje,"A",{href:!0});var Jkt=s(yz);tDo=r(Jkt,"DebertaV2ForMaskedLM"),Jkt.forEach(t),aDo=r(Jje," (DeBERTa-v2 model)"),Jje.forEach(t),nDo=i(O),I1=n(O,"LI",{});var Yje=s(I1);e1e=n(Yje,"STRONG",{});var Ykt=s(e1e);sDo=r(Ykt,"distilbert"),Ykt.forEach(t),lDo=r(Yje," \u2014 "),xz=n(Yje,"A",{href:!0});var Kkt=s(xz);iDo=r(Kkt,"DistilBertForMaskedLM"),Kkt.forEach(t),dDo=r(Yje," (DistilBERT model)"),Yje.forEach(t),mDo=i(O),N1=n(O,"LI",{});var Kje=s(N1);o1e=n(Kje,"STRONG",{});var Zkt=s(o1e);cDo=r(Zkt,"electra"),Zkt.forEach(t),fDo=r(Kje," \u2014 "),$z=n(Kje,"A",{href:!0});var eSt=s($z);gDo=r(eSt,"ElectraForPreTraining"),eSt.forEach(t),hDo=r(Kje," (ELECTRA model)"),Kje.forEach(t),uDo=i(O),q1=n(O,"LI",{});var Zje=s(q1);r1e=n(Zje,"STRONG",{});var oSt=s(r1e);pDo=r(oSt,"ernie"),oSt.forEach(t),_Do=r(Zje," \u2014 "),kz=n(Zje,"A",{href:!0});var rSt=s(kz);bDo=r(rSt,"ErnieForPreTraining"),rSt.forEach(t),vDo=r(Zje," (ERNIE model)"),Zje.forEach(t),FDo=i(O),j1=n(O,"LI",{});var eDe=s(j1);t1e=n(eDe,"STRONG",{});var tSt=s(t1e);TDo=r(tSt,"flaubert"),tSt.forEach(t),MDo=r(eDe," \u2014 "),Sz=n(eDe,"A",{href:!0});var aSt=s(Sz);EDo=r(aSt,"FlaubertWithLMHeadModel"),aSt.forEach(t),CDo=r(eDe," (FlauBERT model)"),eDe.forEach(t),wDo=i(O),D1=n(O,"LI",{});var oDe=s(D1);a1e=n(oDe,"STRONG",{});var nSt=s(a1e);ADo=r(nSt,"flava"),nSt.forEach(t),LDo=r(oDe," \u2014 "),Rz=n(oDe,"A",{href:!0});var sSt=s(Rz);yDo=r(sSt,"FlavaForPreTraining"),sSt.forEach(t),xDo=r(oDe," (FLAVA model)"),oDe.forEach(t),$Do=i(O),G1=n(O,"LI",{});var rDe=s(G1);n1e=n(rDe,"STRONG",{});var lSt=s(n1e);kDo=r(lSt,"fnet"),lSt.forEach(t),SDo=r(rDe," \u2014 "),Pz=n(rDe,"A",{href:!0});var iSt=s(Pz);RDo=r(iSt,"FNetForPreTraining"),iSt.forEach(t),PDo=r(rDe," (FNet model)"),rDe.forEach(t),BDo=i(O),O1=n(O,"LI",{});var tDe=s(O1);s1e=n(tDe,"STRONG",{});var dSt=s(s1e);IDo=r(dSt,"fsmt"),dSt.forEach(t),NDo=r(tDe," \u2014 "),Bz=n(tDe,"A",{href:!0});var mSt=s(Bz);qDo=r(mSt,"FSMTForConditionalGeneration"),mSt.forEach(t),jDo=r(tDe," (FairSeq Machine-Translation model)"),tDe.forEach(t),DDo=i(O),V1=n(O,"LI",{});var aDe=s(V1);l1e=n(aDe,"STRONG",{});var cSt=s(l1e);GDo=r(cSt,"funnel"),cSt.forEach(t),ODo=r(aDe," \u2014 "),Iz=n(aDe,"A",{href:!0});var fSt=s(Iz);VDo=r(fSt,"FunnelForPreTraining"),fSt.forEach(t),XDo=r(aDe," (Funnel Transformer model)"),aDe.forEach(t),zDo=i(O),X1=n(O,"LI",{});var nDe=s(X1);i1e=n(nDe,"STRONG",{});var gSt=s(i1e);QDo=r(gSt,"gpt2"),gSt.forEach(t),WDo=r(nDe," \u2014 "),Nz=n(nDe,"A",{href:!0});var hSt=s(Nz);UDo=r(hSt,"GPT2LMHeadModel"),hSt.forEach(t),HDo=r(nDe," (OpenAI GPT-2 model)"),nDe.forEach(t),JDo=i(O),z1=n(O,"LI",{});var sDe=s(z1);d1e=n(sDe,"STRONG",{});var uSt=s(d1e);YDo=r(uSt,"ibert"),uSt.forEach(t),KDo=r(sDe," \u2014 "),qz=n(sDe,"A",{href:!0});var pSt=s(qz);ZDo=r(pSt,"IBertForMaskedLM"),pSt.forEach(t),eGo=r(sDe," (I-BERT model)"),sDe.forEach(t),oGo=i(O),Q1=n(O,"LI",{});var lDe=s(Q1);m1e=n(lDe,"STRONG",{});var _St=s(m1e);rGo=r(_St,"layoutlm"),_St.forEach(t),tGo=r(lDe," \u2014 "),jz=n(lDe,"A",{href:!0});var bSt=s(jz);aGo=r(bSt,"LayoutLMForMaskedLM"),bSt.forEach(t),nGo=r(lDe," (LayoutLM model)"),lDe.forEach(t),sGo=i(O),W1=n(O,"LI",{});var iDe=s(W1);c1e=n(iDe,"STRONG",{});var vSt=s(c1e);lGo=r(vSt,"longformer"),vSt.forEach(t),iGo=r(iDe," \u2014 "),Dz=n(iDe,"A",{href:!0});var FSt=s(Dz);dGo=r(FSt,"LongformerForMaskedLM"),FSt.forEach(t),mGo=r(iDe," (Longformer model)"),iDe.forEach(t),cGo=i(O),U1=n(O,"LI",{});var dDe=s(U1);f1e=n(dDe,"STRONG",{});var TSt=s(f1e);fGo=r(TSt,"luke"),TSt.forEach(t),gGo=r(dDe," \u2014 "),Gz=n(dDe,"A",{href:!0});var MSt=s(Gz);hGo=r(MSt,"LukeForMaskedLM"),MSt.forEach(t),uGo=r(dDe," (LUKE model)"),dDe.forEach(t),pGo=i(O),H1=n(O,"LI",{});var mDe=s(H1);g1e=n(mDe,"STRONG",{});var ESt=s(g1e);_Go=r(ESt,"lxmert"),ESt.forEach(t),bGo=r(mDe," \u2014 "),Oz=n(mDe,"A",{href:!0});var CSt=s(Oz);vGo=r(CSt,"LxmertForPreTraining"),CSt.forEach(t),FGo=r(mDe," (LXMERT model)"),mDe.forEach(t),TGo=i(O),J1=n(O,"LI",{});var cDe=s(J1);h1e=n(cDe,"STRONG",{});var wSt=s(h1e);MGo=r(wSt,"megatron-bert"),wSt.forEach(t),EGo=r(cDe," \u2014 "),Vz=n(cDe,"A",{href:!0});var ASt=s(Vz);CGo=r(ASt,"MegatronBertForPreTraining"),ASt.forEach(t),wGo=r(cDe," (Megatron-BERT model)"),cDe.forEach(t),AGo=i(O),Y1=n(O,"LI",{});var fDe=s(Y1);u1e=n(fDe,"STRONG",{});var LSt=s(u1e);LGo=r(LSt,"mobilebert"),LSt.forEach(t),yGo=r(fDe," \u2014 "),Xz=n(fDe,"A",{href:!0});var ySt=s(Xz);xGo=r(ySt,"MobileBertForPreTraining"),ySt.forEach(t),$Go=r(fDe," (MobileBERT model)"),fDe.forEach(t),kGo=i(O),K1=n(O,"LI",{});var gDe=s(K1);p1e=n(gDe,"STRONG",{});var xSt=s(p1e);SGo=r(xSt,"mpnet"),xSt.forEach(t),RGo=r(gDe," \u2014 "),zz=n(gDe,"A",{href:!0});var $St=s(zz);PGo=r($St,"MPNetForMaskedLM"),$St.forEach(t),BGo=r(gDe," (MPNet model)"),gDe.forEach(t),IGo=i(O),Z1=n(O,"LI",{});var hDe=s(Z1);_1e=n(hDe,"STRONG",{});var kSt=s(_1e);NGo=r(kSt,"mvp"),kSt.forEach(t),qGo=r(hDe," \u2014 "),Qz=n(hDe,"A",{href:!0});var SSt=s(Qz);jGo=r(SSt,"MvpForConditionalGeneration"),SSt.forEach(t),DGo=r(hDe," (MVP model)"),hDe.forEach(t),GGo=i(O),eb=n(O,"LI",{});var uDe=s(eb);b1e=n(uDe,"STRONG",{});var RSt=s(b1e);OGo=r(RSt,"nezha"),RSt.forEach(t),VGo=r(uDe," \u2014 "),Wz=n(uDe,"A",{href:!0});var PSt=s(Wz);XGo=r(PSt,"NezhaForPreTraining"),PSt.forEach(t),zGo=r(uDe," (Nezha model)"),uDe.forEach(t),QGo=i(O),ob=n(O,"LI",{});var pDe=s(ob);v1e=n(pDe,"STRONG",{});var BSt=s(v1e);WGo=r(BSt,"openai-gpt"),BSt.forEach(t),UGo=r(pDe," \u2014 "),Uz=n(pDe,"A",{href:!0});var ISt=s(Uz);HGo=r(ISt,"OpenAIGPTLMHeadModel"),ISt.forEach(t),JGo=r(pDe," (OpenAI GPT model)"),pDe.forEach(t),YGo=i(O),rb=n(O,"LI",{});var _De=s(rb);F1e=n(_De,"STRONG",{});var NSt=s(F1e);KGo=r(NSt,"retribert"),NSt.forEach(t),ZGo=r(_De," \u2014 "),Hz=n(_De,"A",{href:!0});var qSt=s(Hz);eOo=r(qSt,"RetriBertModel"),qSt.forEach(t),oOo=r(_De," (RetriBERT model)"),_De.forEach(t),rOo=i(O),tb=n(O,"LI",{});var bDe=s(tb);T1e=n(bDe,"STRONG",{});var jSt=s(T1e);tOo=r(jSt,"roberta"),jSt.forEach(t),aOo=r(bDe," \u2014 "),Jz=n(bDe,"A",{href:!0});var DSt=s(Jz);nOo=r(DSt,"RobertaForMaskedLM"),DSt.forEach(t),sOo=r(bDe," (RoBERTa model)"),bDe.forEach(t),lOo=i(O),ab=n(O,"LI",{});var vDe=s(ab);M1e=n(vDe,"STRONG",{});var GSt=s(M1e);iOo=r(GSt,"splinter"),GSt.forEach(t),dOo=r(vDe," \u2014 "),Yz=n(vDe,"A",{href:!0});var OSt=s(Yz);mOo=r(OSt,"SplinterForPreTraining"),OSt.forEach(t),cOo=r(vDe," (Splinter model)"),vDe.forEach(t),fOo=i(O),nb=n(O,"LI",{});var FDe=s(nb);E1e=n(FDe,"STRONG",{});var VSt=s(E1e);gOo=r(VSt,"squeezebert"),VSt.forEach(t),hOo=r(FDe," \u2014 "),Kz=n(FDe,"A",{href:!0});var XSt=s(Kz);uOo=r(XSt,"SqueezeBertForMaskedLM"),XSt.forEach(t),pOo=r(FDe," (SqueezeBERT model)"),FDe.forEach(t),_Oo=i(O),sb=n(O,"LI",{});var TDe=s(sb);C1e=n(TDe,"STRONG",{});var zSt=s(C1e);bOo=r(zSt,"t5"),zSt.forEach(t),vOo=r(TDe," \u2014 "),Zz=n(TDe,"A",{href:!0});var QSt=s(Zz);FOo=r(QSt,"T5ForConditionalGeneration"),QSt.forEach(t),TOo=r(TDe," (T5 model)"),TDe.forEach(t),MOo=i(O),lb=n(O,"LI",{});var MDe=s(lb);w1e=n(MDe,"STRONG",{});var WSt=s(w1e);EOo=r(WSt,"tapas"),WSt.forEach(t),COo=r(MDe," \u2014 "),eQ=n(MDe,"A",{href:!0});var USt=s(eQ);wOo=r(USt,"TapasForMaskedLM"),USt.forEach(t),AOo=r(MDe," (TAPAS model)"),MDe.forEach(t),LOo=i(O),ib=n(O,"LI",{});var EDe=s(ib);A1e=n(EDe,"STRONG",{});var HSt=s(A1e);yOo=r(HSt,"transfo-xl"),HSt.forEach(t),xOo=r(EDe," \u2014 "),oQ=n(EDe,"A",{href:!0});var JSt=s(oQ);$Oo=r(JSt,"TransfoXLLMHeadModel"),JSt.forEach(t),kOo=r(EDe," (Transformer-XL model)"),EDe.forEach(t),SOo=i(O),db=n(O,"LI",{});var CDe=s(db);L1e=n(CDe,"STRONG",{});var YSt=s(L1e);ROo=r(YSt,"unispeech"),YSt.forEach(t),POo=r(CDe," \u2014 "),rQ=n(CDe,"A",{href:!0});var KSt=s(rQ);BOo=r(KSt,"UniSpeechForPreTraining"),KSt.forEach(t),IOo=r(CDe," (UniSpeech model)"),CDe.forEach(t),NOo=i(O),mb=n(O,"LI",{});var wDe=s(mb);y1e=n(wDe,"STRONG",{});var ZSt=s(y1e);qOo=r(ZSt,"unispeech-sat"),ZSt.forEach(t),jOo=r(wDe," \u2014 "),tQ=n(wDe,"A",{href:!0});var eRt=s(tQ);DOo=r(eRt,"UniSpeechSatForPreTraining"),eRt.forEach(t),GOo=r(wDe," (UniSpeechSat model)"),wDe.forEach(t),OOo=i(O),cb=n(O,"LI",{});var ADe=s(cb);x1e=n(ADe,"STRONG",{});var oRt=s(x1e);VOo=r(oRt,"videomae"),oRt.forEach(t),XOo=r(ADe," \u2014 "),aQ=n(ADe,"A",{href:!0});var rRt=s(aQ);zOo=r(rRt,"VideoMAEForPreTraining"),rRt.forEach(t),QOo=r(ADe," (VideoMAE model)"),ADe.forEach(t),WOo=i(O),fb=n(O,"LI",{});var LDe=s(fb);$1e=n(LDe,"STRONG",{});var tRt=s($1e);UOo=r(tRt,"visual_bert"),tRt.forEach(t),HOo=r(LDe," \u2014 "),nQ=n(LDe,"A",{href:!0});var aRt=s(nQ);JOo=r(aRt,"VisualBertForPreTraining"),aRt.forEach(t),YOo=r(LDe," (VisualBERT model)"),LDe.forEach(t),KOo=i(O),gb=n(O,"LI",{});var yDe=s(gb);k1e=n(yDe,"STRONG",{});var nRt=s(k1e);ZOo=r(nRt,"vit_mae"),nRt.forEach(t),eVo=r(yDe," \u2014 "),sQ=n(yDe,"A",{href:!0});var sRt=s(sQ);oVo=r(sRt,"ViTMAEForPreTraining"),sRt.forEach(t),rVo=r(yDe," (ViTMAE model)"),yDe.forEach(t),tVo=i(O),hb=n(O,"LI",{});var xDe=s(hb);S1e=n(xDe,"STRONG",{});var lRt=s(S1e);aVo=r(lRt,"wav2vec2"),lRt.forEach(t),nVo=r(xDe," \u2014 "),lQ=n(xDe,"A",{href:!0});var iRt=s(lQ);sVo=r(iRt,"Wav2Vec2ForPreTraining"),iRt.forEach(t),lVo=r(xDe," (Wav2Vec2 model)"),xDe.forEach(t),iVo=i(O),ub=n(O,"LI",{});var $De=s(ub);R1e=n($De,"STRONG",{});var dRt=s(R1e);dVo=r(dRt,"wav2vec2-conformer"),dRt.forEach(t),mVo=r($De," \u2014 "),iQ=n($De,"A",{href:!0});var mRt=s(iQ);cVo=r(mRt,"Wav2Vec2ConformerForPreTraining"),mRt.forEach(t),fVo=r($De," (Wav2Vec2-Conformer model)"),$De.forEach(t),gVo=i(O),pb=n(O,"LI",{});var kDe=s(pb);P1e=n(kDe,"STRONG",{});var cRt=s(P1e);hVo=r(cRt,"xlm"),cRt.forEach(t),uVo=r(kDe," \u2014 "),dQ=n(kDe,"A",{href:!0});var fRt=s(dQ);pVo=r(fRt,"XLMWithLMHeadModel"),fRt.forEach(t),_Vo=r(kDe," (XLM model)"),kDe.forEach(t),bVo=i(O),_b=n(O,"LI",{});var SDe=s(_b);B1e=n(SDe,"STRONG",{});var gRt=s(B1e);vVo=r(gRt,"xlm-roberta"),gRt.forEach(t),FVo=r(SDe," \u2014 "),mQ=n(SDe,"A",{href:!0});var hRt=s(mQ);TVo=r(hRt,"XLMRobertaForMaskedLM"),hRt.forEach(t),MVo=r(SDe," (XLM-RoBERTa model)"),SDe.forEach(t),EVo=i(O),bb=n(O,"LI",{});var RDe=s(bb);I1e=n(RDe,"STRONG",{});var uRt=s(I1e);CVo=r(uRt,"xlm-roberta-xl"),uRt.forEach(t),wVo=r(RDe," \u2014 "),cQ=n(RDe,"A",{href:!0});var pRt=s(cQ);AVo=r(pRt,"XLMRobertaXLForMaskedLM"),pRt.forEach(t),LVo=r(RDe," (XLM-RoBERTa-XL model)"),RDe.forEach(t),yVo=i(O),vb=n(O,"LI",{});var PDe=s(vb);N1e=n(PDe,"STRONG",{});var _Rt=s(N1e);xVo=r(_Rt,"xlnet"),_Rt.forEach(t),$Vo=r(PDe," \u2014 "),fQ=n(PDe,"A",{href:!0});var bRt=s(fQ);kVo=r(bRt,"XLNetLMHeadModel"),bRt.forEach(t),SVo=r(PDe," (XLNet model)"),PDe.forEach(t),O.forEach(t),RVo=i(Ta),Fb=n(Ta,"P",{});var BDe=s(Fb);PVo=r(BDe,"The model is set in evaluation mode by default using "),q1e=n(BDe,"CODE",{});var vRt=s(q1e);BVo=r(vRt,"model.eval()"),vRt.forEach(t),IVo=r(BDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j1e=n(BDe,"CODE",{});var FRt=s(j1e);NVo=r(FRt,"model.train()"),FRt.forEach(t),BDe.forEach(t),qVo=i(Ta),T(Tb.$$.fragment,Ta),Ta.forEach(t),Ll.forEach(t),teo=i(c),Ed=n(c,"H2",{class:!0});var _ro=s(Ed);Mb=n(_ro,"A",{id:!0,class:!0,href:!0});var TRt=s(Mb);D1e=n(TRt,"SPAN",{});var MRt=s(D1e);T(Ix.$$.fragment,MRt),MRt.forEach(t),TRt.forEach(t),jVo=i(_ro),G1e=n(_ro,"SPAN",{});var ERt=s(G1e);DVo=r(ERt,"AutoModelForCausalLM"),ERt.forEach(t),_ro.forEach(t),aeo=i(c),Io=n(c,"DIV",{class:!0});var yl=s(Io);T(Nx.$$.fragment,yl),GVo=i(yl),Cd=n(yl,"P",{});var rie=s(Cd);OVo=r(rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),gQ=n(rie,"A",{href:!0});var CRt=s(gQ);VVo=r(CRt,"from_pretrained()"),CRt.forEach(t),XVo=r(rie," class method or the "),hQ=n(rie,"A",{href:!0});var wRt=s(hQ);zVo=r(wRt,"from_config()"),wRt.forEach(t),QVo=r(rie,` class
method.`),rie.forEach(t),WVo=i(yl),qx=n(yl,"P",{});var bro=s(qx);UVo=r(bro,"This class cannot be instantiated directly using "),O1e=n(bro,"CODE",{});var ARt=s(O1e);HVo=r(ARt,"__init__()"),ARt.forEach(t),JVo=r(bro," (throws an error)."),bro.forEach(t),YVo=i(yl),vt=n(yl,"DIV",{class:!0});var Ky=s(vt);T(jx.$$.fragment,Ky),KVo=i(Ky),V1e=n(Ky,"P",{});var LRt=s(V1e);ZVo=r(LRt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),LRt.forEach(t),eXo=i(Ky),wd=n(Ky,"P",{});var tie=s(wd);oXo=r(tie,`Note:
Loading a model from its configuration file does `),X1e=n(tie,"STRONG",{});var yRt=s(X1e);rXo=r(yRt,"not"),yRt.forEach(t),tXo=r(tie,` load the model weights. It only affects the
model\u2019s configuration. Use `),uQ=n(tie,"A",{href:!0});var xRt=s(uQ);aXo=r(xRt,"from_pretrained()"),xRt.forEach(t),nXo=r(tie," to load the model weights."),tie.forEach(t),sXo=i(Ky),T(Eb.$$.fragment,Ky),Ky.forEach(t),lXo=i(yl),oo=n(yl,"DIV",{class:!0});var Ma=s(oo);T(Dx.$$.fragment,Ma),iXo=i(Ma),z1e=n(Ma,"P",{});var $Rt=s(z1e);dXo=r($Rt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),$Rt.forEach(t),mXo=i(Ma),Ka=n(Ma,"P",{});var Zy=s(Ka);cXo=r(Zy,"The model class to instantiate is selected based on the "),Q1e=n(Zy,"CODE",{});var kRt=s(Q1e);fXo=r(kRt,"model_type"),kRt.forEach(t),gXo=r(Zy,` property of the config object (either
passed as an argument or loaded from `),W1e=n(Zy,"CODE",{});var SRt=s(W1e);hXo=r(SRt,"pretrained_model_name_or_path"),SRt.forEach(t),uXo=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=n(Zy,"CODE",{});var RRt=s(U1e);pXo=r(RRt,"pretrained_model_name_or_path"),RRt.forEach(t),_Xo=r(Zy,":"),Zy.forEach(t),bXo=i(Ma),Q=n(Ma,"UL",{});var U=s(Q);Cb=n(U,"LI",{});var IDe=s(Cb);H1e=n(IDe,"STRONG",{});var PRt=s(H1e);vXo=r(PRt,"bart"),PRt.forEach(t),FXo=r(IDe," \u2014 "),pQ=n(IDe,"A",{href:!0});var BRt=s(pQ);TXo=r(BRt,"BartForCausalLM"),BRt.forEach(t),MXo=r(IDe," (BART model)"),IDe.forEach(t),EXo=i(U),wb=n(U,"LI",{});var NDe=s(wb);J1e=n(NDe,"STRONG",{});var IRt=s(J1e);CXo=r(IRt,"bert"),IRt.forEach(t),wXo=r(NDe," \u2014 "),_Q=n(NDe,"A",{href:!0});var NRt=s(_Q);AXo=r(NRt,"BertLMHeadModel"),NRt.forEach(t),LXo=r(NDe," (BERT model)"),NDe.forEach(t),yXo=i(U),Ab=n(U,"LI",{});var qDe=s(Ab);Y1e=n(qDe,"STRONG",{});var qRt=s(Y1e);xXo=r(qRt,"bert-generation"),qRt.forEach(t),$Xo=r(qDe," \u2014 "),bQ=n(qDe,"A",{href:!0});var jRt=s(bQ);kXo=r(jRt,"BertGenerationDecoder"),jRt.forEach(t),SXo=r(qDe," (Bert Generation model)"),qDe.forEach(t),RXo=i(U),Lb=n(U,"LI",{});var jDe=s(Lb);K1e=n(jDe,"STRONG",{});var DRt=s(K1e);PXo=r(DRt,"big_bird"),DRt.forEach(t),BXo=r(jDe," \u2014 "),vQ=n(jDe,"A",{href:!0});var GRt=s(vQ);IXo=r(GRt,"BigBirdForCausalLM"),GRt.forEach(t),NXo=r(jDe," (BigBird model)"),jDe.forEach(t),qXo=i(U),yb=n(U,"LI",{});var DDe=s(yb);Z1e=n(DDe,"STRONG",{});var ORt=s(Z1e);jXo=r(ORt,"bigbird_pegasus"),ORt.forEach(t),DXo=r(DDe," \u2014 "),FQ=n(DDe,"A",{href:!0});var VRt=s(FQ);GXo=r(VRt,"BigBirdPegasusForCausalLM"),VRt.forEach(t),OXo=r(DDe," (BigBird-Pegasus model)"),DDe.forEach(t),VXo=i(U),xb=n(U,"LI",{});var GDe=s(xb);ebe=n(GDe,"STRONG",{});var XRt=s(ebe);XXo=r(XRt,"blenderbot"),XRt.forEach(t),zXo=r(GDe," \u2014 "),TQ=n(GDe,"A",{href:!0});var zRt=s(TQ);QXo=r(zRt,"BlenderbotForCausalLM"),zRt.forEach(t),WXo=r(GDe," (Blenderbot model)"),GDe.forEach(t),UXo=i(U),$b=n(U,"LI",{});var ODe=s($b);obe=n(ODe,"STRONG",{});var QRt=s(obe);HXo=r(QRt,"blenderbot-small"),QRt.forEach(t),JXo=r(ODe," \u2014 "),MQ=n(ODe,"A",{href:!0});var WRt=s(MQ);YXo=r(WRt,"BlenderbotSmallForCausalLM"),WRt.forEach(t),KXo=r(ODe," (BlenderbotSmall model)"),ODe.forEach(t),ZXo=i(U),kb=n(U,"LI",{});var VDe=s(kb);rbe=n(VDe,"STRONG",{});var URt=s(rbe);ezo=r(URt,"bloom"),URt.forEach(t),ozo=r(VDe," \u2014 "),EQ=n(VDe,"A",{href:!0});var HRt=s(EQ);rzo=r(HRt,"BloomForCausalLM"),HRt.forEach(t),tzo=r(VDe," (BLOOM model)"),VDe.forEach(t),azo=i(U),Sb=n(U,"LI",{});var XDe=s(Sb);tbe=n(XDe,"STRONG",{});var JRt=s(tbe);nzo=r(JRt,"camembert"),JRt.forEach(t),szo=r(XDe," \u2014 "),CQ=n(XDe,"A",{href:!0});var YRt=s(CQ);lzo=r(YRt,"CamembertForCausalLM"),YRt.forEach(t),izo=r(XDe," (CamemBERT model)"),XDe.forEach(t),dzo=i(U),Rb=n(U,"LI",{});var zDe=s(Rb);abe=n(zDe,"STRONG",{});var KRt=s(abe);mzo=r(KRt,"codegen"),KRt.forEach(t),czo=r(zDe," \u2014 "),wQ=n(zDe,"A",{href:!0});var ZRt=s(wQ);fzo=r(ZRt,"CodeGenForCausalLM"),ZRt.forEach(t),gzo=r(zDe," (CodeGen model)"),zDe.forEach(t),hzo=i(U),Pb=n(U,"LI",{});var QDe=s(Pb);nbe=n(QDe,"STRONG",{});var ePt=s(nbe);uzo=r(ePt,"ctrl"),ePt.forEach(t),pzo=r(QDe," \u2014 "),AQ=n(QDe,"A",{href:!0});var oPt=s(AQ);_zo=r(oPt,"CTRLLMHeadModel"),oPt.forEach(t),bzo=r(QDe," (CTRL model)"),QDe.forEach(t),vzo=i(U),Bb=n(U,"LI",{});var WDe=s(Bb);sbe=n(WDe,"STRONG",{});var rPt=s(sbe);Fzo=r(rPt,"data2vec-text"),rPt.forEach(t),Tzo=r(WDe," \u2014 "),LQ=n(WDe,"A",{href:!0});var tPt=s(LQ);Mzo=r(tPt,"Data2VecTextForCausalLM"),tPt.forEach(t),Ezo=r(WDe," (Data2VecText model)"),WDe.forEach(t),Czo=i(U),Ib=n(U,"LI",{});var UDe=s(Ib);lbe=n(UDe,"STRONG",{});var aPt=s(lbe);wzo=r(aPt,"electra"),aPt.forEach(t),Azo=r(UDe," \u2014 "),yQ=n(UDe,"A",{href:!0});var nPt=s(yQ);Lzo=r(nPt,"ElectraForCausalLM"),nPt.forEach(t),yzo=r(UDe," (ELECTRA model)"),UDe.forEach(t),xzo=i(U),Nb=n(U,"LI",{});var HDe=s(Nb);ibe=n(HDe,"STRONG",{});var sPt=s(ibe);$zo=r(sPt,"ernie"),sPt.forEach(t),kzo=r(HDe," \u2014 "),xQ=n(HDe,"A",{href:!0});var lPt=s(xQ);Szo=r(lPt,"ErnieForCausalLM"),lPt.forEach(t),Rzo=r(HDe," (ERNIE model)"),HDe.forEach(t),Pzo=i(U),qb=n(U,"LI",{});var JDe=s(qb);dbe=n(JDe,"STRONG",{});var iPt=s(dbe);Bzo=r(iPt,"gpt2"),iPt.forEach(t),Izo=r(JDe," \u2014 "),$Q=n(JDe,"A",{href:!0});var dPt=s($Q);Nzo=r(dPt,"GPT2LMHeadModel"),dPt.forEach(t),qzo=r(JDe," (OpenAI GPT-2 model)"),JDe.forEach(t),jzo=i(U),jb=n(U,"LI",{});var YDe=s(jb);mbe=n(YDe,"STRONG",{});var mPt=s(mbe);Dzo=r(mPt,"gpt_neo"),mPt.forEach(t),Gzo=r(YDe," \u2014 "),kQ=n(YDe,"A",{href:!0});var cPt=s(kQ);Ozo=r(cPt,"GPTNeoForCausalLM"),cPt.forEach(t),Vzo=r(YDe," (GPT Neo model)"),YDe.forEach(t),Xzo=i(U),Db=n(U,"LI",{});var KDe=s(Db);cbe=n(KDe,"STRONG",{});var fPt=s(cbe);zzo=r(fPt,"gpt_neox"),fPt.forEach(t),Qzo=r(KDe," \u2014 "),SQ=n(KDe,"A",{href:!0});var gPt=s(SQ);Wzo=r(gPt,"GPTNeoXForCausalLM"),gPt.forEach(t),Uzo=r(KDe," (GPT NeoX model)"),KDe.forEach(t),Hzo=i(U),Gb=n(U,"LI",{});var ZDe=s(Gb);fbe=n(ZDe,"STRONG",{});var hPt=s(fbe);Jzo=r(hPt,"gpt_neox_japanese"),hPt.forEach(t),Yzo=r(ZDe," \u2014 "),RQ=n(ZDe,"A",{href:!0});var uPt=s(RQ);Kzo=r(uPt,"GPTNeoXJapaneseForCausalLM"),uPt.forEach(t),Zzo=r(ZDe," (GPT NeoX Japanese model)"),ZDe.forEach(t),eQo=i(U),Ob=n(U,"LI",{});var eGe=s(Ob);gbe=n(eGe,"STRONG",{});var pPt=s(gbe);oQo=r(pPt,"gptj"),pPt.forEach(t),rQo=r(eGe," \u2014 "),PQ=n(eGe,"A",{href:!0});var _Pt=s(PQ);tQo=r(_Pt,"GPTJForCausalLM"),_Pt.forEach(t),aQo=r(eGe," (GPT-J model)"),eGe.forEach(t),nQo=i(U),Vb=n(U,"LI",{});var oGe=s(Vb);hbe=n(oGe,"STRONG",{});var bPt=s(hbe);sQo=r(bPt,"marian"),bPt.forEach(t),lQo=r(oGe," \u2014 "),BQ=n(oGe,"A",{href:!0});var vPt=s(BQ);iQo=r(vPt,"MarianForCausalLM"),vPt.forEach(t),dQo=r(oGe," (Marian model)"),oGe.forEach(t),mQo=i(U),Xb=n(U,"LI",{});var rGe=s(Xb);ube=n(rGe,"STRONG",{});var FPt=s(ube);cQo=r(FPt,"mbart"),FPt.forEach(t),fQo=r(rGe," \u2014 "),IQ=n(rGe,"A",{href:!0});var TPt=s(IQ);gQo=r(TPt,"MBartForCausalLM"),TPt.forEach(t),hQo=r(rGe," (mBART model)"),rGe.forEach(t),uQo=i(U),zb=n(U,"LI",{});var tGe=s(zb);pbe=n(tGe,"STRONG",{});var MPt=s(pbe);pQo=r(MPt,"megatron-bert"),MPt.forEach(t),_Qo=r(tGe," \u2014 "),NQ=n(tGe,"A",{href:!0});var EPt=s(NQ);bQo=r(EPt,"MegatronBertForCausalLM"),EPt.forEach(t),vQo=r(tGe," (Megatron-BERT model)"),tGe.forEach(t),FQo=i(U),Qb=n(U,"LI",{});var aGe=s(Qb);_be=n(aGe,"STRONG",{});var CPt=s(_be);TQo=r(CPt,"mvp"),CPt.forEach(t),MQo=r(aGe," \u2014 "),qQ=n(aGe,"A",{href:!0});var wPt=s(qQ);EQo=r(wPt,"MvpForCausalLM"),wPt.forEach(t),CQo=r(aGe," (MVP model)"),aGe.forEach(t),wQo=i(U),Wb=n(U,"LI",{});var nGe=s(Wb);bbe=n(nGe,"STRONG",{});var APt=s(bbe);AQo=r(APt,"openai-gpt"),APt.forEach(t),LQo=r(nGe," \u2014 "),jQ=n(nGe,"A",{href:!0});var LPt=s(jQ);yQo=r(LPt,"OpenAIGPTLMHeadModel"),LPt.forEach(t),xQo=r(nGe," (OpenAI GPT model)"),nGe.forEach(t),$Qo=i(U),Ub=n(U,"LI",{});var sGe=s(Ub);vbe=n(sGe,"STRONG",{});var yPt=s(vbe);kQo=r(yPt,"opt"),yPt.forEach(t),SQo=r(sGe," \u2014 "),DQ=n(sGe,"A",{href:!0});var xPt=s(DQ);RQo=r(xPt,"OPTForCausalLM"),xPt.forEach(t),PQo=r(sGe," (OPT model)"),sGe.forEach(t),BQo=i(U),Hb=n(U,"LI",{});var lGe=s(Hb);Fbe=n(lGe,"STRONG",{});var $Pt=s(Fbe);IQo=r($Pt,"pegasus"),$Pt.forEach(t),NQo=r(lGe," \u2014 "),GQ=n(lGe,"A",{href:!0});var kPt=s(GQ);qQo=r(kPt,"PegasusForCausalLM"),kPt.forEach(t),jQo=r(lGe," (Pegasus model)"),lGe.forEach(t),DQo=i(U),Jb=n(U,"LI",{});var iGe=s(Jb);Tbe=n(iGe,"STRONG",{});var SPt=s(Tbe);GQo=r(SPt,"plbart"),SPt.forEach(t),OQo=r(iGe," \u2014 "),OQ=n(iGe,"A",{href:!0});var RPt=s(OQ);VQo=r(RPt,"PLBartForCausalLM"),RPt.forEach(t),XQo=r(iGe," (PLBart model)"),iGe.forEach(t),zQo=i(U),Yb=n(U,"LI",{});var dGe=s(Yb);Mbe=n(dGe,"STRONG",{});var PPt=s(Mbe);QQo=r(PPt,"prophetnet"),PPt.forEach(t),WQo=r(dGe," \u2014 "),VQ=n(dGe,"A",{href:!0});var BPt=s(VQ);UQo=r(BPt,"ProphetNetForCausalLM"),BPt.forEach(t),HQo=r(dGe," (ProphetNet model)"),dGe.forEach(t),JQo=i(U),Kb=n(U,"LI",{});var mGe=s(Kb);Ebe=n(mGe,"STRONG",{});var IPt=s(Ebe);YQo=r(IPt,"qdqbert"),IPt.forEach(t),KQo=r(mGe," \u2014 "),XQ=n(mGe,"A",{href:!0});var NPt=s(XQ);ZQo=r(NPt,"QDQBertLMHeadModel"),NPt.forEach(t),eWo=r(mGe," (QDQBert model)"),mGe.forEach(t),oWo=i(U),Zb=n(U,"LI",{});var cGe=s(Zb);Cbe=n(cGe,"STRONG",{});var qPt=s(Cbe);rWo=r(qPt,"reformer"),qPt.forEach(t),tWo=r(cGe," \u2014 "),zQ=n(cGe,"A",{href:!0});var jPt=s(zQ);aWo=r(jPt,"ReformerModelWithLMHead"),jPt.forEach(t),nWo=r(cGe," (Reformer model)"),cGe.forEach(t),sWo=i(U),ev=n(U,"LI",{});var fGe=s(ev);wbe=n(fGe,"STRONG",{});var DPt=s(wbe);lWo=r(DPt,"rembert"),DPt.forEach(t),iWo=r(fGe," \u2014 "),QQ=n(fGe,"A",{href:!0});var GPt=s(QQ);dWo=r(GPt,"RemBertForCausalLM"),GPt.forEach(t),mWo=r(fGe," (RemBERT model)"),fGe.forEach(t),cWo=i(U),ov=n(U,"LI",{});var gGe=s(ov);Abe=n(gGe,"STRONG",{});var OPt=s(Abe);fWo=r(OPt,"roberta"),OPt.forEach(t),gWo=r(gGe," \u2014 "),WQ=n(gGe,"A",{href:!0});var VPt=s(WQ);hWo=r(VPt,"RobertaForCausalLM"),VPt.forEach(t),uWo=r(gGe," (RoBERTa model)"),gGe.forEach(t),pWo=i(U),rv=n(U,"LI",{});var hGe=s(rv);Lbe=n(hGe,"STRONG",{});var XPt=s(Lbe);_Wo=r(XPt,"roformer"),XPt.forEach(t),bWo=r(hGe," \u2014 "),UQ=n(hGe,"A",{href:!0});var zPt=s(UQ);vWo=r(zPt,"RoFormerForCausalLM"),zPt.forEach(t),FWo=r(hGe," (RoFormer model)"),hGe.forEach(t),TWo=i(U),tv=n(U,"LI",{});var uGe=s(tv);ybe=n(uGe,"STRONG",{});var QPt=s(ybe);MWo=r(QPt,"speech_to_text_2"),QPt.forEach(t),EWo=r(uGe," \u2014 "),HQ=n(uGe,"A",{href:!0});var WPt=s(HQ);CWo=r(WPt,"Speech2Text2ForCausalLM"),WPt.forEach(t),wWo=r(uGe," (Speech2Text2 model)"),uGe.forEach(t),AWo=i(U),av=n(U,"LI",{});var pGe=s(av);xbe=n(pGe,"STRONG",{});var UPt=s(xbe);LWo=r(UPt,"transfo-xl"),UPt.forEach(t),yWo=r(pGe," \u2014 "),JQ=n(pGe,"A",{href:!0});var HPt=s(JQ);xWo=r(HPt,"TransfoXLLMHeadModel"),HPt.forEach(t),$Wo=r(pGe," (Transformer-XL model)"),pGe.forEach(t),kWo=i(U),nv=n(U,"LI",{});var _Ge=s(nv);$be=n(_Ge,"STRONG",{});var JPt=s($be);SWo=r(JPt,"trocr"),JPt.forEach(t),RWo=r(_Ge," \u2014 "),YQ=n(_Ge,"A",{href:!0});var YPt=s(YQ);PWo=r(YPt,"TrOCRForCausalLM"),YPt.forEach(t),BWo=r(_Ge," (TrOCR model)"),_Ge.forEach(t),IWo=i(U),sv=n(U,"LI",{});var bGe=s(sv);kbe=n(bGe,"STRONG",{});var KPt=s(kbe);NWo=r(KPt,"xglm"),KPt.forEach(t),qWo=r(bGe," \u2014 "),KQ=n(bGe,"A",{href:!0});var ZPt=s(KQ);jWo=r(ZPt,"XGLMForCausalLM"),ZPt.forEach(t),DWo=r(bGe," (XGLM model)"),bGe.forEach(t),GWo=i(U),lv=n(U,"LI",{});var vGe=s(lv);Sbe=n(vGe,"STRONG",{});var eBt=s(Sbe);OWo=r(eBt,"xlm"),eBt.forEach(t),VWo=r(vGe," \u2014 "),ZQ=n(vGe,"A",{href:!0});var oBt=s(ZQ);XWo=r(oBt,"XLMWithLMHeadModel"),oBt.forEach(t),zWo=r(vGe," (XLM model)"),vGe.forEach(t),QWo=i(U),iv=n(U,"LI",{});var FGe=s(iv);Rbe=n(FGe,"STRONG",{});var rBt=s(Rbe);WWo=r(rBt,"xlm-prophetnet"),rBt.forEach(t),UWo=r(FGe," \u2014 "),eW=n(FGe,"A",{href:!0});var tBt=s(eW);HWo=r(tBt,"XLMProphetNetForCausalLM"),tBt.forEach(t),JWo=r(FGe," (XLM-ProphetNet model)"),FGe.forEach(t),YWo=i(U),dv=n(U,"LI",{});var TGe=s(dv);Pbe=n(TGe,"STRONG",{});var aBt=s(Pbe);KWo=r(aBt,"xlm-roberta"),aBt.forEach(t),ZWo=r(TGe," \u2014 "),oW=n(TGe,"A",{href:!0});var nBt=s(oW);eUo=r(nBt,"XLMRobertaForCausalLM"),nBt.forEach(t),oUo=r(TGe," (XLM-RoBERTa model)"),TGe.forEach(t),rUo=i(U),mv=n(U,"LI",{});var MGe=s(mv);Bbe=n(MGe,"STRONG",{});var sBt=s(Bbe);tUo=r(sBt,"xlm-roberta-xl"),sBt.forEach(t),aUo=r(MGe," \u2014 "),rW=n(MGe,"A",{href:!0});var lBt=s(rW);nUo=r(lBt,"XLMRobertaXLForCausalLM"),lBt.forEach(t),sUo=r(MGe," (XLM-RoBERTa-XL model)"),MGe.forEach(t),lUo=i(U),cv=n(U,"LI",{});var EGe=s(cv);Ibe=n(EGe,"STRONG",{});var iBt=s(Ibe);iUo=r(iBt,"xlnet"),iBt.forEach(t),dUo=r(EGe," \u2014 "),tW=n(EGe,"A",{href:!0});var dBt=s(tW);mUo=r(dBt,"XLNetLMHeadModel"),dBt.forEach(t),cUo=r(EGe," (XLNet model)"),EGe.forEach(t),U.forEach(t),fUo=i(Ma),fv=n(Ma,"P",{});var CGe=s(fv);gUo=r(CGe,"The model is set in evaluation mode by default using "),Nbe=n(CGe,"CODE",{});var mBt=s(Nbe);hUo=r(mBt,"model.eval()"),mBt.forEach(t),uUo=r(CGe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qbe=n(CGe,"CODE",{});var cBt=s(qbe);pUo=r(cBt,"model.train()"),cBt.forEach(t),CGe.forEach(t),_Uo=i(Ma),T(gv.$$.fragment,Ma),Ma.forEach(t),yl.forEach(t),neo=i(c),Ad=n(c,"H2",{class:!0});var vro=s(Ad);hv=n(vro,"A",{id:!0,class:!0,href:!0});var fBt=s(hv);jbe=n(fBt,"SPAN",{});var gBt=s(jbe);T(Gx.$$.fragment,gBt),gBt.forEach(t),fBt.forEach(t),bUo=i(vro),Dbe=n(vro,"SPAN",{});var hBt=s(Dbe);vUo=r(hBt,"AutoModelForMaskedLM"),hBt.forEach(t),vro.forEach(t),seo=i(c),No=n(c,"DIV",{class:!0});var xl=s(No);T(Ox.$$.fragment,xl),FUo=i(xl),Ld=n(xl,"P",{});var aie=s(Ld);TUo=r(aie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aW=n(aie,"A",{href:!0});var uBt=s(aW);MUo=r(uBt,"from_pretrained()"),uBt.forEach(t),EUo=r(aie," class method or the "),nW=n(aie,"A",{href:!0});var pBt=s(nW);CUo=r(pBt,"from_config()"),pBt.forEach(t),wUo=r(aie,` class
method.`),aie.forEach(t),AUo=i(xl),Vx=n(xl,"P",{});var Fro=s(Vx);LUo=r(Fro,"This class cannot be instantiated directly using "),Gbe=n(Fro,"CODE",{});var _Bt=s(Gbe);yUo=r(_Bt,"__init__()"),_Bt.forEach(t),xUo=r(Fro," (throws an error)."),Fro.forEach(t),$Uo=i(xl),Ft=n(xl,"DIV",{class:!0});var e8=s(Ft);T(Xx.$$.fragment,e8),kUo=i(e8),Obe=n(e8,"P",{});var bBt=s(Obe);SUo=r(bBt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),bBt.forEach(t),RUo=i(e8),yd=n(e8,"P",{});var nie=s(yd);PUo=r(nie,`Note:
Loading a model from its configuration file does `),Vbe=n(nie,"STRONG",{});var vBt=s(Vbe);BUo=r(vBt,"not"),vBt.forEach(t),IUo=r(nie,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(nie,"A",{href:!0});var FBt=s(sW);NUo=r(FBt,"from_pretrained()"),FBt.forEach(t),qUo=r(nie," to load the model weights."),nie.forEach(t),jUo=i(e8),T(uv.$$.fragment,e8),e8.forEach(t),DUo=i(xl),ro=n(xl,"DIV",{class:!0});var Ea=s(ro);T(zx.$$.fragment,Ea),GUo=i(Ea),Xbe=n(Ea,"P",{});var TBt=s(Xbe);OUo=r(TBt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),TBt.forEach(t),VUo=i(Ea),Za=n(Ea,"P",{});var o8=s(Za);XUo=r(o8,"The model class to instantiate is selected based on the "),zbe=n(o8,"CODE",{});var MBt=s(zbe);zUo=r(MBt,"model_type"),MBt.forEach(t),QUo=r(o8,` property of the config object (either
passed as an argument or loaded from `),Qbe=n(o8,"CODE",{});var EBt=s(Qbe);WUo=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),UUo=r(o8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wbe=n(o8,"CODE",{});var CBt=s(Wbe);HUo=r(CBt,"pretrained_model_name_or_path"),CBt.forEach(t),JUo=r(o8,":"),o8.forEach(t),YUo=i(Ea),J=n(Ea,"UL",{});var K=s(J);pv=n(K,"LI",{});var wGe=s(pv);Ube=n(wGe,"STRONG",{});var wBt=s(Ube);KUo=r(wBt,"albert"),wBt.forEach(t),ZUo=r(wGe," \u2014 "),lW=n(wGe,"A",{href:!0});var ABt=s(lW);eHo=r(ABt,"AlbertForMaskedLM"),ABt.forEach(t),oHo=r(wGe," (ALBERT model)"),wGe.forEach(t),rHo=i(K),_v=n(K,"LI",{});var AGe=s(_v);Hbe=n(AGe,"STRONG",{});var LBt=s(Hbe);tHo=r(LBt,"bart"),LBt.forEach(t),aHo=r(AGe," \u2014 "),iW=n(AGe,"A",{href:!0});var yBt=s(iW);nHo=r(yBt,"BartForConditionalGeneration"),yBt.forEach(t),sHo=r(AGe," (BART model)"),AGe.forEach(t),lHo=i(K),bv=n(K,"LI",{});var LGe=s(bv);Jbe=n(LGe,"STRONG",{});var xBt=s(Jbe);iHo=r(xBt,"bert"),xBt.forEach(t),dHo=r(LGe," \u2014 "),dW=n(LGe,"A",{href:!0});var $Bt=s(dW);mHo=r($Bt,"BertForMaskedLM"),$Bt.forEach(t),cHo=r(LGe," (BERT model)"),LGe.forEach(t),fHo=i(K),vv=n(K,"LI",{});var yGe=s(vv);Ybe=n(yGe,"STRONG",{});var kBt=s(Ybe);gHo=r(kBt,"big_bird"),kBt.forEach(t),hHo=r(yGe," \u2014 "),mW=n(yGe,"A",{href:!0});var SBt=s(mW);uHo=r(SBt,"BigBirdForMaskedLM"),SBt.forEach(t),pHo=r(yGe," (BigBird model)"),yGe.forEach(t),_Ho=i(K),Fv=n(K,"LI",{});var xGe=s(Fv);Kbe=n(xGe,"STRONG",{});var RBt=s(Kbe);bHo=r(RBt,"camembert"),RBt.forEach(t),vHo=r(xGe," \u2014 "),cW=n(xGe,"A",{href:!0});var PBt=s(cW);FHo=r(PBt,"CamembertForMaskedLM"),PBt.forEach(t),THo=r(xGe," (CamemBERT model)"),xGe.forEach(t),MHo=i(K),Tv=n(K,"LI",{});var $Ge=s(Tv);Zbe=n($Ge,"STRONG",{});var BBt=s(Zbe);EHo=r(BBt,"convbert"),BBt.forEach(t),CHo=r($Ge," \u2014 "),fW=n($Ge,"A",{href:!0});var IBt=s(fW);wHo=r(IBt,"ConvBertForMaskedLM"),IBt.forEach(t),AHo=r($Ge," (ConvBERT model)"),$Ge.forEach(t),LHo=i(K),Mv=n(K,"LI",{});var kGe=s(Mv);eve=n(kGe,"STRONG",{});var NBt=s(eve);yHo=r(NBt,"data2vec-text"),NBt.forEach(t),xHo=r(kGe," \u2014 "),gW=n(kGe,"A",{href:!0});var qBt=s(gW);$Ho=r(qBt,"Data2VecTextForMaskedLM"),qBt.forEach(t),kHo=r(kGe," (Data2VecText model)"),kGe.forEach(t),SHo=i(K),Ev=n(K,"LI",{});var SGe=s(Ev);ove=n(SGe,"STRONG",{});var jBt=s(ove);RHo=r(jBt,"deberta"),jBt.forEach(t),PHo=r(SGe," \u2014 "),hW=n(SGe,"A",{href:!0});var DBt=s(hW);BHo=r(DBt,"DebertaForMaskedLM"),DBt.forEach(t),IHo=r(SGe," (DeBERTa model)"),SGe.forEach(t),NHo=i(K),Cv=n(K,"LI",{});var RGe=s(Cv);rve=n(RGe,"STRONG",{});var GBt=s(rve);qHo=r(GBt,"deberta-v2"),GBt.forEach(t),jHo=r(RGe," \u2014 "),uW=n(RGe,"A",{href:!0});var OBt=s(uW);DHo=r(OBt,"DebertaV2ForMaskedLM"),OBt.forEach(t),GHo=r(RGe," (DeBERTa-v2 model)"),RGe.forEach(t),OHo=i(K),wv=n(K,"LI",{});var PGe=s(wv);tve=n(PGe,"STRONG",{});var VBt=s(tve);VHo=r(VBt,"distilbert"),VBt.forEach(t),XHo=r(PGe," \u2014 "),pW=n(PGe,"A",{href:!0});var XBt=s(pW);zHo=r(XBt,"DistilBertForMaskedLM"),XBt.forEach(t),QHo=r(PGe," (DistilBERT model)"),PGe.forEach(t),WHo=i(K),Av=n(K,"LI",{});var BGe=s(Av);ave=n(BGe,"STRONG",{});var zBt=s(ave);UHo=r(zBt,"electra"),zBt.forEach(t),HHo=r(BGe," \u2014 "),_W=n(BGe,"A",{href:!0});var QBt=s(_W);JHo=r(QBt,"ElectraForMaskedLM"),QBt.forEach(t),YHo=r(BGe," (ELECTRA model)"),BGe.forEach(t),KHo=i(K),Lv=n(K,"LI",{});var IGe=s(Lv);nve=n(IGe,"STRONG",{});var WBt=s(nve);ZHo=r(WBt,"ernie"),WBt.forEach(t),eJo=r(IGe," \u2014 "),bW=n(IGe,"A",{href:!0});var UBt=s(bW);oJo=r(UBt,"ErnieForMaskedLM"),UBt.forEach(t),rJo=r(IGe," (ERNIE model)"),IGe.forEach(t),tJo=i(K),yv=n(K,"LI",{});var NGe=s(yv);sve=n(NGe,"STRONG",{});var HBt=s(sve);aJo=r(HBt,"flaubert"),HBt.forEach(t),nJo=r(NGe," \u2014 "),vW=n(NGe,"A",{href:!0});var JBt=s(vW);sJo=r(JBt,"FlaubertWithLMHeadModel"),JBt.forEach(t),lJo=r(NGe," (FlauBERT model)"),NGe.forEach(t),iJo=i(K),xv=n(K,"LI",{});var qGe=s(xv);lve=n(qGe,"STRONG",{});var YBt=s(lve);dJo=r(YBt,"fnet"),YBt.forEach(t),mJo=r(qGe," \u2014 "),FW=n(qGe,"A",{href:!0});var KBt=s(FW);cJo=r(KBt,"FNetForMaskedLM"),KBt.forEach(t),fJo=r(qGe," (FNet model)"),qGe.forEach(t),gJo=i(K),$v=n(K,"LI",{});var jGe=s($v);ive=n(jGe,"STRONG",{});var ZBt=s(ive);hJo=r(ZBt,"funnel"),ZBt.forEach(t),uJo=r(jGe," \u2014 "),TW=n(jGe,"A",{href:!0});var eIt=s(TW);pJo=r(eIt,"FunnelForMaskedLM"),eIt.forEach(t),_Jo=r(jGe," (Funnel Transformer model)"),jGe.forEach(t),bJo=i(K),kv=n(K,"LI",{});var DGe=s(kv);dve=n(DGe,"STRONG",{});var oIt=s(dve);vJo=r(oIt,"ibert"),oIt.forEach(t),FJo=r(DGe," \u2014 "),MW=n(DGe,"A",{href:!0});var rIt=s(MW);TJo=r(rIt,"IBertForMaskedLM"),rIt.forEach(t),MJo=r(DGe," (I-BERT model)"),DGe.forEach(t),EJo=i(K),Sv=n(K,"LI",{});var GGe=s(Sv);mve=n(GGe,"STRONG",{});var tIt=s(mve);CJo=r(tIt,"layoutlm"),tIt.forEach(t),wJo=r(GGe," \u2014 "),EW=n(GGe,"A",{href:!0});var aIt=s(EW);AJo=r(aIt,"LayoutLMForMaskedLM"),aIt.forEach(t),LJo=r(GGe," (LayoutLM model)"),GGe.forEach(t),yJo=i(K),Rv=n(K,"LI",{});var OGe=s(Rv);cve=n(OGe,"STRONG",{});var nIt=s(cve);xJo=r(nIt,"longformer"),nIt.forEach(t),$Jo=r(OGe," \u2014 "),CW=n(OGe,"A",{href:!0});var sIt=s(CW);kJo=r(sIt,"LongformerForMaskedLM"),sIt.forEach(t),SJo=r(OGe," (Longformer model)"),OGe.forEach(t),RJo=i(K),Pv=n(K,"LI",{});var VGe=s(Pv);fve=n(VGe,"STRONG",{});var lIt=s(fve);PJo=r(lIt,"luke"),lIt.forEach(t),BJo=r(VGe," \u2014 "),wW=n(VGe,"A",{href:!0});var iIt=s(wW);IJo=r(iIt,"LukeForMaskedLM"),iIt.forEach(t),NJo=r(VGe," (LUKE model)"),VGe.forEach(t),qJo=i(K),Bv=n(K,"LI",{});var XGe=s(Bv);gve=n(XGe,"STRONG",{});var dIt=s(gve);jJo=r(dIt,"mbart"),dIt.forEach(t),DJo=r(XGe," \u2014 "),AW=n(XGe,"A",{href:!0});var mIt=s(AW);GJo=r(mIt,"MBartForConditionalGeneration"),mIt.forEach(t),OJo=r(XGe," (mBART model)"),XGe.forEach(t),VJo=i(K),Iv=n(K,"LI",{});var zGe=s(Iv);hve=n(zGe,"STRONG",{});var cIt=s(hve);XJo=r(cIt,"megatron-bert"),cIt.forEach(t),zJo=r(zGe," \u2014 "),LW=n(zGe,"A",{href:!0});var fIt=s(LW);QJo=r(fIt,"MegatronBertForMaskedLM"),fIt.forEach(t),WJo=r(zGe," (Megatron-BERT model)"),zGe.forEach(t),UJo=i(K),Nv=n(K,"LI",{});var QGe=s(Nv);uve=n(QGe,"STRONG",{});var gIt=s(uve);HJo=r(gIt,"mobilebert"),gIt.forEach(t),JJo=r(QGe," \u2014 "),yW=n(QGe,"A",{href:!0});var hIt=s(yW);YJo=r(hIt,"MobileBertForMaskedLM"),hIt.forEach(t),KJo=r(QGe," (MobileBERT model)"),QGe.forEach(t),ZJo=i(K),qv=n(K,"LI",{});var WGe=s(qv);pve=n(WGe,"STRONG",{});var uIt=s(pve);eYo=r(uIt,"mpnet"),uIt.forEach(t),oYo=r(WGe," \u2014 "),xW=n(WGe,"A",{href:!0});var pIt=s(xW);rYo=r(pIt,"MPNetForMaskedLM"),pIt.forEach(t),tYo=r(WGe," (MPNet model)"),WGe.forEach(t),aYo=i(K),jv=n(K,"LI",{});var UGe=s(jv);_ve=n(UGe,"STRONG",{});var _It=s(_ve);nYo=r(_It,"mvp"),_It.forEach(t),sYo=r(UGe," \u2014 "),$W=n(UGe,"A",{href:!0});var bIt=s($W);lYo=r(bIt,"MvpForConditionalGeneration"),bIt.forEach(t),iYo=r(UGe," (MVP model)"),UGe.forEach(t),dYo=i(K),Dv=n(K,"LI",{});var HGe=s(Dv);bve=n(HGe,"STRONG",{});var vIt=s(bve);mYo=r(vIt,"nezha"),vIt.forEach(t),cYo=r(HGe," \u2014 "),kW=n(HGe,"A",{href:!0});var FIt=s(kW);fYo=r(FIt,"NezhaForMaskedLM"),FIt.forEach(t),gYo=r(HGe," (Nezha model)"),HGe.forEach(t),hYo=i(K),Gv=n(K,"LI",{});var JGe=s(Gv);vve=n(JGe,"STRONG",{});var TIt=s(vve);uYo=r(TIt,"nystromformer"),TIt.forEach(t),pYo=r(JGe," \u2014 "),SW=n(JGe,"A",{href:!0});var MIt=s(SW);_Yo=r(MIt,"NystromformerForMaskedLM"),MIt.forEach(t),bYo=r(JGe," (Nystr\xF6mformer model)"),JGe.forEach(t),vYo=i(K),Ov=n(K,"LI",{});var YGe=s(Ov);Fve=n(YGe,"STRONG",{});var EIt=s(Fve);FYo=r(EIt,"perceiver"),EIt.forEach(t),TYo=r(YGe," \u2014 "),RW=n(YGe,"A",{href:!0});var CIt=s(RW);MYo=r(CIt,"PerceiverForMaskedLM"),CIt.forEach(t),EYo=r(YGe," (Perceiver model)"),YGe.forEach(t),CYo=i(K),Vv=n(K,"LI",{});var KGe=s(Vv);Tve=n(KGe,"STRONG",{});var wIt=s(Tve);wYo=r(wIt,"qdqbert"),wIt.forEach(t),AYo=r(KGe," \u2014 "),PW=n(KGe,"A",{href:!0});var AIt=s(PW);LYo=r(AIt,"QDQBertForMaskedLM"),AIt.forEach(t),yYo=r(KGe," (QDQBert model)"),KGe.forEach(t),xYo=i(K),Xv=n(K,"LI",{});var ZGe=s(Xv);Mve=n(ZGe,"STRONG",{});var LIt=s(Mve);$Yo=r(LIt,"reformer"),LIt.forEach(t),kYo=r(ZGe," \u2014 "),BW=n(ZGe,"A",{href:!0});var yIt=s(BW);SYo=r(yIt,"ReformerForMaskedLM"),yIt.forEach(t),RYo=r(ZGe," (Reformer model)"),ZGe.forEach(t),PYo=i(K),zv=n(K,"LI",{});var eOe=s(zv);Eve=n(eOe,"STRONG",{});var xIt=s(Eve);BYo=r(xIt,"rembert"),xIt.forEach(t),IYo=r(eOe," \u2014 "),IW=n(eOe,"A",{href:!0});var $It=s(IW);NYo=r($It,"RemBertForMaskedLM"),$It.forEach(t),qYo=r(eOe," (RemBERT model)"),eOe.forEach(t),jYo=i(K),Qv=n(K,"LI",{});var oOe=s(Qv);Cve=n(oOe,"STRONG",{});var kIt=s(Cve);DYo=r(kIt,"roberta"),kIt.forEach(t),GYo=r(oOe," \u2014 "),NW=n(oOe,"A",{href:!0});var SIt=s(NW);OYo=r(SIt,"RobertaForMaskedLM"),SIt.forEach(t),VYo=r(oOe," (RoBERTa model)"),oOe.forEach(t),XYo=i(K),Wv=n(K,"LI",{});var rOe=s(Wv);wve=n(rOe,"STRONG",{});var RIt=s(wve);zYo=r(RIt,"roformer"),RIt.forEach(t),QYo=r(rOe," \u2014 "),qW=n(rOe,"A",{href:!0});var PIt=s(qW);WYo=r(PIt,"RoFormerForMaskedLM"),PIt.forEach(t),UYo=r(rOe," (RoFormer model)"),rOe.forEach(t),HYo=i(K),Uv=n(K,"LI",{});var tOe=s(Uv);Ave=n(tOe,"STRONG",{});var BIt=s(Ave);JYo=r(BIt,"squeezebert"),BIt.forEach(t),YYo=r(tOe," \u2014 "),jW=n(tOe,"A",{href:!0});var IIt=s(jW);KYo=r(IIt,"SqueezeBertForMaskedLM"),IIt.forEach(t),ZYo=r(tOe," (SqueezeBERT model)"),tOe.forEach(t),eKo=i(K),Hv=n(K,"LI",{});var aOe=s(Hv);Lve=n(aOe,"STRONG",{});var NIt=s(Lve);oKo=r(NIt,"tapas"),NIt.forEach(t),rKo=r(aOe," \u2014 "),DW=n(aOe,"A",{href:!0});var qIt=s(DW);tKo=r(qIt,"TapasForMaskedLM"),qIt.forEach(t),aKo=r(aOe," (TAPAS model)"),aOe.forEach(t),nKo=i(K),Jv=n(K,"LI",{});var nOe=s(Jv);yve=n(nOe,"STRONG",{});var jIt=s(yve);sKo=r(jIt,"wav2vec2"),jIt.forEach(t),lKo=r(nOe," \u2014 "),xve=n(nOe,"CODE",{});var DIt=s(xve);iKo=r(DIt,"Wav2Vec2ForMaskedLM"),DIt.forEach(t),dKo=r(nOe," (Wav2Vec2 model)"),nOe.forEach(t),mKo=i(K),Yv=n(K,"LI",{});var sOe=s(Yv);$ve=n(sOe,"STRONG",{});var GIt=s($ve);cKo=r(GIt,"xlm"),GIt.forEach(t),fKo=r(sOe," \u2014 "),GW=n(sOe,"A",{href:!0});var OIt=s(GW);gKo=r(OIt,"XLMWithLMHeadModel"),OIt.forEach(t),hKo=r(sOe," (XLM model)"),sOe.forEach(t),uKo=i(K),Kv=n(K,"LI",{});var lOe=s(Kv);kve=n(lOe,"STRONG",{});var VIt=s(kve);pKo=r(VIt,"xlm-roberta"),VIt.forEach(t),_Ko=r(lOe," \u2014 "),OW=n(lOe,"A",{href:!0});var XIt=s(OW);bKo=r(XIt,"XLMRobertaForMaskedLM"),XIt.forEach(t),vKo=r(lOe," (XLM-RoBERTa model)"),lOe.forEach(t),FKo=i(K),Zv=n(K,"LI",{});var iOe=s(Zv);Sve=n(iOe,"STRONG",{});var zIt=s(Sve);TKo=r(zIt,"xlm-roberta-xl"),zIt.forEach(t),MKo=r(iOe," \u2014 "),VW=n(iOe,"A",{href:!0});var QIt=s(VW);EKo=r(QIt,"XLMRobertaXLForMaskedLM"),QIt.forEach(t),CKo=r(iOe," (XLM-RoBERTa-XL model)"),iOe.forEach(t),wKo=i(K),eF=n(K,"LI",{});var dOe=s(eF);Rve=n(dOe,"STRONG",{});var WIt=s(Rve);AKo=r(WIt,"yoso"),WIt.forEach(t),LKo=r(dOe," \u2014 "),XW=n(dOe,"A",{href:!0});var UIt=s(XW);yKo=r(UIt,"YosoForMaskedLM"),UIt.forEach(t),xKo=r(dOe," (YOSO model)"),dOe.forEach(t),K.forEach(t),$Ko=i(Ea),oF=n(Ea,"P",{});var mOe=s(oF);kKo=r(mOe,"The model is set in evaluation mode by default using "),Pve=n(mOe,"CODE",{});var HIt=s(Pve);SKo=r(HIt,"model.eval()"),HIt.forEach(t),RKo=r(mOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bve=n(mOe,"CODE",{});var JIt=s(Bve);PKo=r(JIt,"model.train()"),JIt.forEach(t),mOe.forEach(t),BKo=i(Ea),T(rF.$$.fragment,Ea),Ea.forEach(t),xl.forEach(t),leo=i(c),xd=n(c,"H2",{class:!0});var Tro=s(xd);tF=n(Tro,"A",{id:!0,class:!0,href:!0});var YIt=s(tF);Ive=n(YIt,"SPAN",{});var KIt=s(Ive);T(Qx.$$.fragment,KIt),KIt.forEach(t),YIt.forEach(t),IKo=i(Tro),Nve=n(Tro,"SPAN",{});var ZIt=s(Nve);NKo=r(ZIt,"AutoModelForSeq2SeqLM"),ZIt.forEach(t),Tro.forEach(t),ieo=i(c),qo=n(c,"DIV",{class:!0});var $l=s(qo);T(Wx.$$.fragment,$l),qKo=i($l),$d=n($l,"P",{});var sie=s($d);jKo=r(sie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),zW=n(sie,"A",{href:!0});var eNt=s(zW);DKo=r(eNt,"from_pretrained()"),eNt.forEach(t),GKo=r(sie," class method or the "),QW=n(sie,"A",{href:!0});var oNt=s(QW);OKo=r(oNt,"from_config()"),oNt.forEach(t),VKo=r(sie,` class
method.`),sie.forEach(t),XKo=i($l),Ux=n($l,"P",{});var Mro=s(Ux);zKo=r(Mro,"This class cannot be instantiated directly using "),qve=n(Mro,"CODE",{});var rNt=s(qve);QKo=r(rNt,"__init__()"),rNt.forEach(t),WKo=r(Mro," (throws an error)."),Mro.forEach(t),UKo=i($l),Tt=n($l,"DIV",{class:!0});var r8=s(Tt);T(Hx.$$.fragment,r8),HKo=i(r8),jve=n(r8,"P",{});var tNt=s(jve);JKo=r(tNt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),tNt.forEach(t),YKo=i(r8),kd=n(r8,"P",{});var lie=s(kd);KKo=r(lie,`Note:
Loading a model from its configuration file does `),Dve=n(lie,"STRONG",{});var aNt=s(Dve);ZKo=r(aNt,"not"),aNt.forEach(t),eZo=r(lie,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(lie,"A",{href:!0});var nNt=s(WW);oZo=r(nNt,"from_pretrained()"),nNt.forEach(t),rZo=r(lie," to load the model weights."),lie.forEach(t),tZo=i(r8),T(aF.$$.fragment,r8),r8.forEach(t),aZo=i($l),to=n($l,"DIV",{class:!0});var Ca=s(to);T(Jx.$$.fragment,Ca),nZo=i(Ca),Gve=n(Ca,"P",{});var sNt=s(Gve);sZo=r(sNt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),sNt.forEach(t),lZo=i(Ca),en=n(Ca,"P",{});var t8=s(en);iZo=r(t8,"The model class to instantiate is selected based on the "),Ove=n(t8,"CODE",{});var lNt=s(Ove);dZo=r(lNt,"model_type"),lNt.forEach(t),mZo=r(t8,` property of the config object (either
passed as an argument or loaded from `),Vve=n(t8,"CODE",{});var iNt=s(Vve);cZo=r(iNt,"pretrained_model_name_or_path"),iNt.forEach(t),fZo=r(t8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xve=n(t8,"CODE",{});var dNt=s(Xve);gZo=r(dNt,"pretrained_model_name_or_path"),dNt.forEach(t),hZo=r(t8,":"),t8.forEach(t),uZo=i(Ca),fe=n(Ca,"UL",{});var pe=s(fe);nF=n(pe,"LI",{});var cOe=s(nF);zve=n(cOe,"STRONG",{});var mNt=s(zve);pZo=r(mNt,"bart"),mNt.forEach(t),_Zo=r(cOe," \u2014 "),UW=n(cOe,"A",{href:!0});var cNt=s(UW);bZo=r(cNt,"BartForConditionalGeneration"),cNt.forEach(t),vZo=r(cOe," (BART model)"),cOe.forEach(t),FZo=i(pe),sF=n(pe,"LI",{});var fOe=s(sF);Qve=n(fOe,"STRONG",{});var fNt=s(Qve);TZo=r(fNt,"bigbird_pegasus"),fNt.forEach(t),MZo=r(fOe," \u2014 "),HW=n(fOe,"A",{href:!0});var gNt=s(HW);EZo=r(gNt,"BigBirdPegasusForConditionalGeneration"),gNt.forEach(t),CZo=r(fOe," (BigBird-Pegasus model)"),fOe.forEach(t),wZo=i(pe),lF=n(pe,"LI",{});var gOe=s(lF);Wve=n(gOe,"STRONG",{});var hNt=s(Wve);AZo=r(hNt,"blenderbot"),hNt.forEach(t),LZo=r(gOe," \u2014 "),JW=n(gOe,"A",{href:!0});var uNt=s(JW);yZo=r(uNt,"BlenderbotForConditionalGeneration"),uNt.forEach(t),xZo=r(gOe," (Blenderbot model)"),gOe.forEach(t),$Zo=i(pe),iF=n(pe,"LI",{});var hOe=s(iF);Uve=n(hOe,"STRONG",{});var pNt=s(Uve);kZo=r(pNt,"blenderbot-small"),pNt.forEach(t),SZo=r(hOe," \u2014 "),YW=n(hOe,"A",{href:!0});var _Nt=s(YW);RZo=r(_Nt,"BlenderbotSmallForConditionalGeneration"),_Nt.forEach(t),PZo=r(hOe," (BlenderbotSmall model)"),hOe.forEach(t),BZo=i(pe),dF=n(pe,"LI",{});var uOe=s(dF);Hve=n(uOe,"STRONG",{});var bNt=s(Hve);IZo=r(bNt,"encoder-decoder"),bNt.forEach(t),NZo=r(uOe," \u2014 "),KW=n(uOe,"A",{href:!0});var vNt=s(KW);qZo=r(vNt,"EncoderDecoderModel"),vNt.forEach(t),jZo=r(uOe," (Encoder decoder model)"),uOe.forEach(t),DZo=i(pe),mF=n(pe,"LI",{});var pOe=s(mF);Jve=n(pOe,"STRONG",{});var FNt=s(Jve);GZo=r(FNt,"fsmt"),FNt.forEach(t),OZo=r(pOe," \u2014 "),ZW=n(pOe,"A",{href:!0});var TNt=s(ZW);VZo=r(TNt,"FSMTForConditionalGeneration"),TNt.forEach(t),XZo=r(pOe," (FairSeq Machine-Translation model)"),pOe.forEach(t),zZo=i(pe),cF=n(pe,"LI",{});var _Oe=s(cF);Yve=n(_Oe,"STRONG",{});var MNt=s(Yve);QZo=r(MNt,"led"),MNt.forEach(t),WZo=r(_Oe," \u2014 "),eU=n(_Oe,"A",{href:!0});var ENt=s(eU);UZo=r(ENt,"LEDForConditionalGeneration"),ENt.forEach(t),HZo=r(_Oe," (LED model)"),_Oe.forEach(t),JZo=i(pe),fF=n(pe,"LI",{});var bOe=s(fF);Kve=n(bOe,"STRONG",{});var CNt=s(Kve);YZo=r(CNt,"longt5"),CNt.forEach(t),KZo=r(bOe," \u2014 "),oU=n(bOe,"A",{href:!0});var wNt=s(oU);ZZo=r(wNt,"LongT5ForConditionalGeneration"),wNt.forEach(t),eer=r(bOe," (LongT5 model)"),bOe.forEach(t),oer=i(pe),gF=n(pe,"LI",{});var vOe=s(gF);Zve=n(vOe,"STRONG",{});var ANt=s(Zve);rer=r(ANt,"m2m_100"),ANt.forEach(t),ter=r(vOe," \u2014 "),rU=n(vOe,"A",{href:!0});var LNt=s(rU);aer=r(LNt,"M2M100ForConditionalGeneration"),LNt.forEach(t),ner=r(vOe," (M2M100 model)"),vOe.forEach(t),ser=i(pe),hF=n(pe,"LI",{});var FOe=s(hF);eFe=n(FOe,"STRONG",{});var yNt=s(eFe);ler=r(yNt,"marian"),yNt.forEach(t),ier=r(FOe," \u2014 "),tU=n(FOe,"A",{href:!0});var xNt=s(tU);der=r(xNt,"MarianMTModel"),xNt.forEach(t),mer=r(FOe," (Marian model)"),FOe.forEach(t),cer=i(pe),uF=n(pe,"LI",{});var TOe=s(uF);oFe=n(TOe,"STRONG",{});var $Nt=s(oFe);fer=r($Nt,"mbart"),$Nt.forEach(t),ger=r(TOe," \u2014 "),aU=n(TOe,"A",{href:!0});var kNt=s(aU);her=r(kNt,"MBartForConditionalGeneration"),kNt.forEach(t),uer=r(TOe," (mBART model)"),TOe.forEach(t),per=i(pe),pF=n(pe,"LI",{});var MOe=s(pF);rFe=n(MOe,"STRONG",{});var SNt=s(rFe);_er=r(SNt,"mt5"),SNt.forEach(t),ber=r(MOe," \u2014 "),nU=n(MOe,"A",{href:!0});var RNt=s(nU);ver=r(RNt,"MT5ForConditionalGeneration"),RNt.forEach(t),Fer=r(MOe," (MT5 model)"),MOe.forEach(t),Ter=i(pe),_F=n(pe,"LI",{});var EOe=s(_F);tFe=n(EOe,"STRONG",{});var PNt=s(tFe);Mer=r(PNt,"mvp"),PNt.forEach(t),Eer=r(EOe," \u2014 "),sU=n(EOe,"A",{href:!0});var BNt=s(sU);Cer=r(BNt,"MvpForConditionalGeneration"),BNt.forEach(t),wer=r(EOe," (MVP model)"),EOe.forEach(t),Aer=i(pe),bF=n(pe,"LI",{});var COe=s(bF);aFe=n(COe,"STRONG",{});var INt=s(aFe);Ler=r(INt,"nllb"),INt.forEach(t),yer=r(COe," \u2014 "),lU=n(COe,"A",{href:!0});var NNt=s(lU);xer=r(NNt,"M2M100ForConditionalGeneration"),NNt.forEach(t),$er=r(COe," (NLLB model)"),COe.forEach(t),ker=i(pe),vF=n(pe,"LI",{});var wOe=s(vF);nFe=n(wOe,"STRONG",{});var qNt=s(nFe);Ser=r(qNt,"pegasus"),qNt.forEach(t),Rer=r(wOe," \u2014 "),iU=n(wOe,"A",{href:!0});var jNt=s(iU);Per=r(jNt,"PegasusForConditionalGeneration"),jNt.forEach(t),Ber=r(wOe," (Pegasus model)"),wOe.forEach(t),Ier=i(pe),FF=n(pe,"LI",{});var AOe=s(FF);sFe=n(AOe,"STRONG",{});var DNt=s(sFe);Ner=r(DNt,"pegasus_x"),DNt.forEach(t),qer=r(AOe," \u2014 "),dU=n(AOe,"A",{href:!0});var GNt=s(dU);jer=r(GNt,"PegasusXForConditionalGeneration"),GNt.forEach(t),Der=r(AOe," (PEGASUS-X model)"),AOe.forEach(t),Ger=i(pe),TF=n(pe,"LI",{});var LOe=s(TF);lFe=n(LOe,"STRONG",{});var ONt=s(lFe);Oer=r(ONt,"plbart"),ONt.forEach(t),Ver=r(LOe," \u2014 "),mU=n(LOe,"A",{href:!0});var VNt=s(mU);Xer=r(VNt,"PLBartForConditionalGeneration"),VNt.forEach(t),zer=r(LOe," (PLBart model)"),LOe.forEach(t),Qer=i(pe),MF=n(pe,"LI",{});var yOe=s(MF);iFe=n(yOe,"STRONG",{});var XNt=s(iFe);Wer=r(XNt,"prophetnet"),XNt.forEach(t),Uer=r(yOe," \u2014 "),cU=n(yOe,"A",{href:!0});var zNt=s(cU);Her=r(zNt,"ProphetNetForConditionalGeneration"),zNt.forEach(t),Jer=r(yOe," (ProphetNet model)"),yOe.forEach(t),Yer=i(pe),EF=n(pe,"LI",{});var xOe=s(EF);dFe=n(xOe,"STRONG",{});var QNt=s(dFe);Ker=r(QNt,"t5"),QNt.forEach(t),Zer=r(xOe," \u2014 "),fU=n(xOe,"A",{href:!0});var WNt=s(fU);eor=r(WNt,"T5ForConditionalGeneration"),WNt.forEach(t),oor=r(xOe," (T5 model)"),xOe.forEach(t),ror=i(pe),CF=n(pe,"LI",{});var $Oe=s(CF);mFe=n($Oe,"STRONG",{});var UNt=s(mFe);tor=r(UNt,"xlm-prophetnet"),UNt.forEach(t),aor=r($Oe," \u2014 "),gU=n($Oe,"A",{href:!0});var HNt=s(gU);nor=r(HNt,"XLMProphetNetForConditionalGeneration"),HNt.forEach(t),sor=r($Oe," (XLM-ProphetNet model)"),$Oe.forEach(t),pe.forEach(t),lor=i(Ca),wF=n(Ca,"P",{});var kOe=s(wF);ior=r(kOe,"The model is set in evaluation mode by default using "),cFe=n(kOe,"CODE",{});var JNt=s(cFe);dor=r(JNt,"model.eval()"),JNt.forEach(t),mor=r(kOe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fFe=n(kOe,"CODE",{});var YNt=s(fFe);cor=r(YNt,"model.train()"),YNt.forEach(t),kOe.forEach(t),gor=i(Ca),T(AF.$$.fragment,Ca),Ca.forEach(t),$l.forEach(t),deo=i(c),Sd=n(c,"H2",{class:!0});var Ero=s(Sd);LF=n(Ero,"A",{id:!0,class:!0,href:!0});var KNt=s(LF);gFe=n(KNt,"SPAN",{});var ZNt=s(gFe);T(Yx.$$.fragment,ZNt),ZNt.forEach(t),KNt.forEach(t),hor=i(Ero),hFe=n(Ero,"SPAN",{});var eqt=s(hFe);uor=r(eqt,"AutoModelForSequenceClassification"),eqt.forEach(t),Ero.forEach(t),meo=i(c),jo=n(c,"DIV",{class:!0});var kl=s(jo);T(Kx.$$.fragment,kl),por=i(kl),Rd=n(kl,"P",{});var iie=s(Rd);_or=r(iie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hU=n(iie,"A",{href:!0});var oqt=s(hU);bor=r(oqt,"from_pretrained()"),oqt.forEach(t),vor=r(iie," class method or the "),uU=n(iie,"A",{href:!0});var rqt=s(uU);For=r(rqt,"from_config()"),rqt.forEach(t),Tor=r(iie,` class
method.`),iie.forEach(t),Mor=i(kl),Zx=n(kl,"P",{});var Cro=s(Zx);Eor=r(Cro,"This class cannot be instantiated directly using "),uFe=n(Cro,"CODE",{});var tqt=s(uFe);Cor=r(tqt,"__init__()"),tqt.forEach(t),wor=r(Cro," (throws an error)."),Cro.forEach(t),Aor=i(kl),Mt=n(kl,"DIV",{class:!0});var a8=s(Mt);T(e$.$$.fragment,a8),Lor=i(a8),pFe=n(a8,"P",{});var aqt=s(pFe);yor=r(aqt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),aqt.forEach(t),xor=i(a8),Pd=n(a8,"P",{});var die=s(Pd);$or=r(die,`Note:
Loading a model from its configuration file does `),_Fe=n(die,"STRONG",{});var nqt=s(_Fe);kor=r(nqt,"not"),nqt.forEach(t),Sor=r(die,` load the model weights. It only affects the
model\u2019s configuration. Use `),pU=n(die,"A",{href:!0});var sqt=s(pU);Ror=r(sqt,"from_pretrained()"),sqt.forEach(t),Por=r(die," to load the model weights."),die.forEach(t),Bor=i(a8),T(yF.$$.fragment,a8),a8.forEach(t),Ior=i(kl),ao=n(kl,"DIV",{class:!0});var wa=s(ao);T(o$.$$.fragment,wa),Nor=i(wa),bFe=n(wa,"P",{});var lqt=s(bFe);qor=r(lqt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),lqt.forEach(t),jor=i(wa),on=n(wa,"P",{});var n8=s(on);Dor=r(n8,"The model class to instantiate is selected based on the "),vFe=n(n8,"CODE",{});var iqt=s(vFe);Gor=r(iqt,"model_type"),iqt.forEach(t),Oor=r(n8,` property of the config object (either
passed as an argument or loaded from `),FFe=n(n8,"CODE",{});var dqt=s(FFe);Vor=r(dqt,"pretrained_model_name_or_path"),dqt.forEach(t),Xor=r(n8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=n(n8,"CODE",{});var mqt=s(TFe);zor=r(mqt,"pretrained_model_name_or_path"),mqt.forEach(t),Qor=r(n8,":"),n8.forEach(t),Wor=i(wa),B=n(wa,"UL",{});var j=s(B);xF=n(j,"LI",{});var SOe=s(xF);MFe=n(SOe,"STRONG",{});var cqt=s(MFe);Uor=r(cqt,"albert"),cqt.forEach(t),Hor=r(SOe," \u2014 "),_U=n(SOe,"A",{href:!0});var fqt=s(_U);Jor=r(fqt,"AlbertForSequenceClassification"),fqt.forEach(t),Yor=r(SOe," (ALBERT model)"),SOe.forEach(t),Kor=i(j),$F=n(j,"LI",{});var ROe=s($F);EFe=n(ROe,"STRONG",{});var gqt=s(EFe);Zor=r(gqt,"bart"),gqt.forEach(t),err=r(ROe," \u2014 "),bU=n(ROe,"A",{href:!0});var hqt=s(bU);orr=r(hqt,"BartForSequenceClassification"),hqt.forEach(t),rrr=r(ROe," (BART model)"),ROe.forEach(t),trr=i(j),kF=n(j,"LI",{});var POe=s(kF);CFe=n(POe,"STRONG",{});var uqt=s(CFe);arr=r(uqt,"bert"),uqt.forEach(t),nrr=r(POe," \u2014 "),vU=n(POe,"A",{href:!0});var pqt=s(vU);srr=r(pqt,"BertForSequenceClassification"),pqt.forEach(t),lrr=r(POe," (BERT model)"),POe.forEach(t),irr=i(j),SF=n(j,"LI",{});var BOe=s(SF);wFe=n(BOe,"STRONG",{});var _qt=s(wFe);drr=r(_qt,"big_bird"),_qt.forEach(t),mrr=r(BOe," \u2014 "),FU=n(BOe,"A",{href:!0});var bqt=s(FU);crr=r(bqt,"BigBirdForSequenceClassification"),bqt.forEach(t),frr=r(BOe," (BigBird model)"),BOe.forEach(t),grr=i(j),RF=n(j,"LI",{});var IOe=s(RF);AFe=n(IOe,"STRONG",{});var vqt=s(AFe);hrr=r(vqt,"bigbird_pegasus"),vqt.forEach(t),urr=r(IOe," \u2014 "),TU=n(IOe,"A",{href:!0});var Fqt=s(TU);prr=r(Fqt,"BigBirdPegasusForSequenceClassification"),Fqt.forEach(t),_rr=r(IOe," (BigBird-Pegasus model)"),IOe.forEach(t),brr=i(j),PF=n(j,"LI",{});var NOe=s(PF);LFe=n(NOe,"STRONG",{});var Tqt=s(LFe);vrr=r(Tqt,"bloom"),Tqt.forEach(t),Frr=r(NOe," \u2014 "),MU=n(NOe,"A",{href:!0});var Mqt=s(MU);Trr=r(Mqt,"BloomForSequenceClassification"),Mqt.forEach(t),Mrr=r(NOe," (BLOOM model)"),NOe.forEach(t),Err=i(j),BF=n(j,"LI",{});var qOe=s(BF);yFe=n(qOe,"STRONG",{});var Eqt=s(yFe);Crr=r(Eqt,"camembert"),Eqt.forEach(t),wrr=r(qOe," \u2014 "),EU=n(qOe,"A",{href:!0});var Cqt=s(EU);Arr=r(Cqt,"CamembertForSequenceClassification"),Cqt.forEach(t),Lrr=r(qOe," (CamemBERT model)"),qOe.forEach(t),yrr=i(j),IF=n(j,"LI",{});var jOe=s(IF);xFe=n(jOe,"STRONG",{});var wqt=s(xFe);xrr=r(wqt,"canine"),wqt.forEach(t),$rr=r(jOe," \u2014 "),CU=n(jOe,"A",{href:!0});var Aqt=s(CU);krr=r(Aqt,"CanineForSequenceClassification"),Aqt.forEach(t),Srr=r(jOe," (CANINE model)"),jOe.forEach(t),Rrr=i(j),NF=n(j,"LI",{});var DOe=s(NF);$Fe=n(DOe,"STRONG",{});var Lqt=s($Fe);Prr=r(Lqt,"convbert"),Lqt.forEach(t),Brr=r(DOe," \u2014 "),wU=n(DOe,"A",{href:!0});var yqt=s(wU);Irr=r(yqt,"ConvBertForSequenceClassification"),yqt.forEach(t),Nrr=r(DOe," (ConvBERT model)"),DOe.forEach(t),qrr=i(j),qF=n(j,"LI",{});var GOe=s(qF);kFe=n(GOe,"STRONG",{});var xqt=s(kFe);jrr=r(xqt,"ctrl"),xqt.forEach(t),Drr=r(GOe," \u2014 "),AU=n(GOe,"A",{href:!0});var $qt=s(AU);Grr=r($qt,"CTRLForSequenceClassification"),$qt.forEach(t),Orr=r(GOe," (CTRL model)"),GOe.forEach(t),Vrr=i(j),jF=n(j,"LI",{});var OOe=s(jF);SFe=n(OOe,"STRONG",{});var kqt=s(SFe);Xrr=r(kqt,"data2vec-text"),kqt.forEach(t),zrr=r(OOe," \u2014 "),LU=n(OOe,"A",{href:!0});var Sqt=s(LU);Qrr=r(Sqt,"Data2VecTextForSequenceClassification"),Sqt.forEach(t),Wrr=r(OOe," (Data2VecText model)"),OOe.forEach(t),Urr=i(j),DF=n(j,"LI",{});var VOe=s(DF);RFe=n(VOe,"STRONG",{});var Rqt=s(RFe);Hrr=r(Rqt,"deberta"),Rqt.forEach(t),Jrr=r(VOe," \u2014 "),yU=n(VOe,"A",{href:!0});var Pqt=s(yU);Yrr=r(Pqt,"DebertaForSequenceClassification"),Pqt.forEach(t),Krr=r(VOe," (DeBERTa model)"),VOe.forEach(t),Zrr=i(j),GF=n(j,"LI",{});var XOe=s(GF);PFe=n(XOe,"STRONG",{});var Bqt=s(PFe);etr=r(Bqt,"deberta-v2"),Bqt.forEach(t),otr=r(XOe," \u2014 "),xU=n(XOe,"A",{href:!0});var Iqt=s(xU);rtr=r(Iqt,"DebertaV2ForSequenceClassification"),Iqt.forEach(t),ttr=r(XOe," (DeBERTa-v2 model)"),XOe.forEach(t),atr=i(j),OF=n(j,"LI",{});var zOe=s(OF);BFe=n(zOe,"STRONG",{});var Nqt=s(BFe);ntr=r(Nqt,"distilbert"),Nqt.forEach(t),str=r(zOe," \u2014 "),$U=n(zOe,"A",{href:!0});var qqt=s($U);ltr=r(qqt,"DistilBertForSequenceClassification"),qqt.forEach(t),itr=r(zOe," (DistilBERT model)"),zOe.forEach(t),dtr=i(j),VF=n(j,"LI",{});var QOe=s(VF);IFe=n(QOe,"STRONG",{});var jqt=s(IFe);mtr=r(jqt,"electra"),jqt.forEach(t),ctr=r(QOe," \u2014 "),kU=n(QOe,"A",{href:!0});var Dqt=s(kU);ftr=r(Dqt,"ElectraForSequenceClassification"),Dqt.forEach(t),gtr=r(QOe," (ELECTRA model)"),QOe.forEach(t),htr=i(j),XF=n(j,"LI",{});var WOe=s(XF);NFe=n(WOe,"STRONG",{});var Gqt=s(NFe);utr=r(Gqt,"ernie"),Gqt.forEach(t),ptr=r(WOe," \u2014 "),SU=n(WOe,"A",{href:!0});var Oqt=s(SU);_tr=r(Oqt,"ErnieForSequenceClassification"),Oqt.forEach(t),btr=r(WOe," (ERNIE model)"),WOe.forEach(t),vtr=i(j),zF=n(j,"LI",{});var UOe=s(zF);qFe=n(UOe,"STRONG",{});var Vqt=s(qFe);Ftr=r(Vqt,"esm"),Vqt.forEach(t),Ttr=r(UOe," \u2014 "),RU=n(UOe,"A",{href:!0});var Xqt=s(RU);Mtr=r(Xqt,"EsmForSequenceClassification"),Xqt.forEach(t),Etr=r(UOe," (ESM model)"),UOe.forEach(t),Ctr=i(j),QF=n(j,"LI",{});var HOe=s(QF);jFe=n(HOe,"STRONG",{});var zqt=s(jFe);wtr=r(zqt,"flaubert"),zqt.forEach(t),Atr=r(HOe," \u2014 "),PU=n(HOe,"A",{href:!0});var Qqt=s(PU);Ltr=r(Qqt,"FlaubertForSequenceClassification"),Qqt.forEach(t),ytr=r(HOe," (FlauBERT model)"),HOe.forEach(t),xtr=i(j),WF=n(j,"LI",{});var JOe=s(WF);DFe=n(JOe,"STRONG",{});var Wqt=s(DFe);$tr=r(Wqt,"fnet"),Wqt.forEach(t),ktr=r(JOe," \u2014 "),BU=n(JOe,"A",{href:!0});var Uqt=s(BU);Str=r(Uqt,"FNetForSequenceClassification"),Uqt.forEach(t),Rtr=r(JOe," (FNet model)"),JOe.forEach(t),Ptr=i(j),UF=n(j,"LI",{});var YOe=s(UF);GFe=n(YOe,"STRONG",{});var Hqt=s(GFe);Btr=r(Hqt,"funnel"),Hqt.forEach(t),Itr=r(YOe," \u2014 "),IU=n(YOe,"A",{href:!0});var Jqt=s(IU);Ntr=r(Jqt,"FunnelForSequenceClassification"),Jqt.forEach(t),qtr=r(YOe," (Funnel Transformer model)"),YOe.forEach(t),jtr=i(j),HF=n(j,"LI",{});var KOe=s(HF);OFe=n(KOe,"STRONG",{});var Yqt=s(OFe);Dtr=r(Yqt,"gpt2"),Yqt.forEach(t),Gtr=r(KOe," \u2014 "),NU=n(KOe,"A",{href:!0});var Kqt=s(NU);Otr=r(Kqt,"GPT2ForSequenceClassification"),Kqt.forEach(t),Vtr=r(KOe," (OpenAI GPT-2 model)"),KOe.forEach(t),Xtr=i(j),JF=n(j,"LI",{});var ZOe=s(JF);VFe=n(ZOe,"STRONG",{});var Zqt=s(VFe);ztr=r(Zqt,"gpt_neo"),Zqt.forEach(t),Qtr=r(ZOe," \u2014 "),qU=n(ZOe,"A",{href:!0});var ejt=s(qU);Wtr=r(ejt,"GPTNeoForSequenceClassification"),ejt.forEach(t),Utr=r(ZOe," (GPT Neo model)"),ZOe.forEach(t),Htr=i(j),YF=n(j,"LI",{});var eVe=s(YF);XFe=n(eVe,"STRONG",{});var ojt=s(XFe);Jtr=r(ojt,"gptj"),ojt.forEach(t),Ytr=r(eVe," \u2014 "),jU=n(eVe,"A",{href:!0});var rjt=s(jU);Ktr=r(rjt,"GPTJForSequenceClassification"),rjt.forEach(t),Ztr=r(eVe," (GPT-J model)"),eVe.forEach(t),ear=i(j),KF=n(j,"LI",{});var oVe=s(KF);zFe=n(oVe,"STRONG",{});var tjt=s(zFe);oar=r(tjt,"ibert"),tjt.forEach(t),rar=r(oVe," \u2014 "),DU=n(oVe,"A",{href:!0});var ajt=s(DU);tar=r(ajt,"IBertForSequenceClassification"),ajt.forEach(t),aar=r(oVe," (I-BERT model)"),oVe.forEach(t),nar=i(j),ZF=n(j,"LI",{});var rVe=s(ZF);QFe=n(rVe,"STRONG",{});var njt=s(QFe);sar=r(njt,"layoutlm"),njt.forEach(t),lar=r(rVe," \u2014 "),GU=n(rVe,"A",{href:!0});var sjt=s(GU);iar=r(sjt,"LayoutLMForSequenceClassification"),sjt.forEach(t),dar=r(rVe," (LayoutLM model)"),rVe.forEach(t),mar=i(j),eT=n(j,"LI",{});var tVe=s(eT);WFe=n(tVe,"STRONG",{});var ljt=s(WFe);car=r(ljt,"layoutlmv2"),ljt.forEach(t),far=r(tVe," \u2014 "),OU=n(tVe,"A",{href:!0});var ijt=s(OU);gar=r(ijt,"LayoutLMv2ForSequenceClassification"),ijt.forEach(t),har=r(tVe," (LayoutLMv2 model)"),tVe.forEach(t),uar=i(j),oT=n(j,"LI",{});var aVe=s(oT);UFe=n(aVe,"STRONG",{});var djt=s(UFe);par=r(djt,"layoutlmv3"),djt.forEach(t),_ar=r(aVe," \u2014 "),VU=n(aVe,"A",{href:!0});var mjt=s(VU);bar=r(mjt,"LayoutLMv3ForSequenceClassification"),mjt.forEach(t),Far=r(aVe," (LayoutLMv3 model)"),aVe.forEach(t),Tar=i(j),rT=n(j,"LI",{});var nVe=s(rT);HFe=n(nVe,"STRONG",{});var cjt=s(HFe);Mar=r(cjt,"led"),cjt.forEach(t),Ear=r(nVe," \u2014 "),XU=n(nVe,"A",{href:!0});var fjt=s(XU);Car=r(fjt,"LEDForSequenceClassification"),fjt.forEach(t),war=r(nVe," (LED model)"),nVe.forEach(t),Aar=i(j),tT=n(j,"LI",{});var sVe=s(tT);JFe=n(sVe,"STRONG",{});var gjt=s(JFe);Lar=r(gjt,"longformer"),gjt.forEach(t),yar=r(sVe," \u2014 "),zU=n(sVe,"A",{href:!0});var hjt=s(zU);xar=r(hjt,"LongformerForSequenceClassification"),hjt.forEach(t),$ar=r(sVe," (Longformer model)"),sVe.forEach(t),kar=i(j),aT=n(j,"LI",{});var lVe=s(aT);YFe=n(lVe,"STRONG",{});var ujt=s(YFe);Sar=r(ujt,"luke"),ujt.forEach(t),Rar=r(lVe," \u2014 "),QU=n(lVe,"A",{href:!0});var pjt=s(QU);Par=r(pjt,"LukeForSequenceClassification"),pjt.forEach(t),Bar=r(lVe," (LUKE model)"),lVe.forEach(t),Iar=i(j),nT=n(j,"LI",{});var iVe=s(nT);KFe=n(iVe,"STRONG",{});var _jt=s(KFe);Nar=r(_jt,"markuplm"),_jt.forEach(t),qar=r(iVe," \u2014 "),WU=n(iVe,"A",{href:!0});var bjt=s(WU);jar=r(bjt,"MarkupLMForSequenceClassification"),bjt.forEach(t),Dar=r(iVe," (MarkupLM model)"),iVe.forEach(t),Gar=i(j),sT=n(j,"LI",{});var dVe=s(sT);ZFe=n(dVe,"STRONG",{});var vjt=s(ZFe);Oar=r(vjt,"mbart"),vjt.forEach(t),Var=r(dVe," \u2014 "),UU=n(dVe,"A",{href:!0});var Fjt=s(UU);Xar=r(Fjt,"MBartForSequenceClassification"),Fjt.forEach(t),zar=r(dVe," (mBART model)"),dVe.forEach(t),Qar=i(j),lT=n(j,"LI",{});var mVe=s(lT);eTe=n(mVe,"STRONG",{});var Tjt=s(eTe);War=r(Tjt,"megatron-bert"),Tjt.forEach(t),Uar=r(mVe," \u2014 "),HU=n(mVe,"A",{href:!0});var Mjt=s(HU);Har=r(Mjt,"MegatronBertForSequenceClassification"),Mjt.forEach(t),Jar=r(mVe," (Megatron-BERT model)"),mVe.forEach(t),Yar=i(j),iT=n(j,"LI",{});var cVe=s(iT);oTe=n(cVe,"STRONG",{});var Ejt=s(oTe);Kar=r(Ejt,"mobilebert"),Ejt.forEach(t),Zar=r(cVe," \u2014 "),JU=n(cVe,"A",{href:!0});var Cjt=s(JU);enr=r(Cjt,"MobileBertForSequenceClassification"),Cjt.forEach(t),onr=r(cVe," (MobileBERT model)"),cVe.forEach(t),rnr=i(j),dT=n(j,"LI",{});var fVe=s(dT);rTe=n(fVe,"STRONG",{});var wjt=s(rTe);tnr=r(wjt,"mpnet"),wjt.forEach(t),anr=r(fVe," \u2014 "),YU=n(fVe,"A",{href:!0});var Ajt=s(YU);nnr=r(Ajt,"MPNetForSequenceClassification"),Ajt.forEach(t),snr=r(fVe," (MPNet model)"),fVe.forEach(t),lnr=i(j),mT=n(j,"LI",{});var gVe=s(mT);tTe=n(gVe,"STRONG",{});var Ljt=s(tTe);inr=r(Ljt,"mvp"),Ljt.forEach(t),dnr=r(gVe," \u2014 "),KU=n(gVe,"A",{href:!0});var yjt=s(KU);mnr=r(yjt,"MvpForSequenceClassification"),yjt.forEach(t),cnr=r(gVe," (MVP model)"),gVe.forEach(t),fnr=i(j),cT=n(j,"LI",{});var hVe=s(cT);aTe=n(hVe,"STRONG",{});var xjt=s(aTe);gnr=r(xjt,"nezha"),xjt.forEach(t),hnr=r(hVe," \u2014 "),ZU=n(hVe,"A",{href:!0});var $jt=s(ZU);unr=r($jt,"NezhaForSequenceClassification"),$jt.forEach(t),pnr=r(hVe," (Nezha model)"),hVe.forEach(t),_nr=i(j),fT=n(j,"LI",{});var uVe=s(fT);nTe=n(uVe,"STRONG",{});var kjt=s(nTe);bnr=r(kjt,"nystromformer"),kjt.forEach(t),vnr=r(uVe," \u2014 "),eH=n(uVe,"A",{href:!0});var Sjt=s(eH);Fnr=r(Sjt,"NystromformerForSequenceClassification"),Sjt.forEach(t),Tnr=r(uVe," (Nystr\xF6mformer model)"),uVe.forEach(t),Mnr=i(j),gT=n(j,"LI",{});var pVe=s(gT);sTe=n(pVe,"STRONG",{});var Rjt=s(sTe);Enr=r(Rjt,"openai-gpt"),Rjt.forEach(t),Cnr=r(pVe," \u2014 "),oH=n(pVe,"A",{href:!0});var Pjt=s(oH);wnr=r(Pjt,"OpenAIGPTForSequenceClassification"),Pjt.forEach(t),Anr=r(pVe," (OpenAI GPT model)"),pVe.forEach(t),Lnr=i(j),hT=n(j,"LI",{});var _Ve=s(hT);lTe=n(_Ve,"STRONG",{});var Bjt=s(lTe);ynr=r(Bjt,"opt"),Bjt.forEach(t),xnr=r(_Ve," \u2014 "),rH=n(_Ve,"A",{href:!0});var Ijt=s(rH);$nr=r(Ijt,"OPTForSequenceClassification"),Ijt.forEach(t),knr=r(_Ve," (OPT model)"),_Ve.forEach(t),Snr=i(j),uT=n(j,"LI",{});var bVe=s(uT);iTe=n(bVe,"STRONG",{});var Njt=s(iTe);Rnr=r(Njt,"perceiver"),Njt.forEach(t),Pnr=r(bVe," \u2014 "),tH=n(bVe,"A",{href:!0});var qjt=s(tH);Bnr=r(qjt,"PerceiverForSequenceClassification"),qjt.forEach(t),Inr=r(bVe," (Perceiver model)"),bVe.forEach(t),Nnr=i(j),pT=n(j,"LI",{});var vVe=s(pT);dTe=n(vVe,"STRONG",{});var jjt=s(dTe);qnr=r(jjt,"plbart"),jjt.forEach(t),jnr=r(vVe," \u2014 "),aH=n(vVe,"A",{href:!0});var Djt=s(aH);Dnr=r(Djt,"PLBartForSequenceClassification"),Djt.forEach(t),Gnr=r(vVe," (PLBart model)"),vVe.forEach(t),Onr=i(j),_T=n(j,"LI",{});var FVe=s(_T);mTe=n(FVe,"STRONG",{});var Gjt=s(mTe);Vnr=r(Gjt,"qdqbert"),Gjt.forEach(t),Xnr=r(FVe," \u2014 "),nH=n(FVe,"A",{href:!0});var Ojt=s(nH);znr=r(Ojt,"QDQBertForSequenceClassification"),Ojt.forEach(t),Qnr=r(FVe," (QDQBert model)"),FVe.forEach(t),Wnr=i(j),bT=n(j,"LI",{});var TVe=s(bT);cTe=n(TVe,"STRONG",{});var Vjt=s(cTe);Unr=r(Vjt,"reformer"),Vjt.forEach(t),Hnr=r(TVe," \u2014 "),sH=n(TVe,"A",{href:!0});var Xjt=s(sH);Jnr=r(Xjt,"ReformerForSequenceClassification"),Xjt.forEach(t),Ynr=r(TVe," (Reformer model)"),TVe.forEach(t),Knr=i(j),vT=n(j,"LI",{});var MVe=s(vT);fTe=n(MVe,"STRONG",{});var zjt=s(fTe);Znr=r(zjt,"rembert"),zjt.forEach(t),esr=r(MVe," \u2014 "),lH=n(MVe,"A",{href:!0});var Qjt=s(lH);osr=r(Qjt,"RemBertForSequenceClassification"),Qjt.forEach(t),rsr=r(MVe," (RemBERT model)"),MVe.forEach(t),tsr=i(j),FT=n(j,"LI",{});var EVe=s(FT);gTe=n(EVe,"STRONG",{});var Wjt=s(gTe);asr=r(Wjt,"roberta"),Wjt.forEach(t),nsr=r(EVe," \u2014 "),iH=n(EVe,"A",{href:!0});var Ujt=s(iH);ssr=r(Ujt,"RobertaForSequenceClassification"),Ujt.forEach(t),lsr=r(EVe," (RoBERTa model)"),EVe.forEach(t),isr=i(j),TT=n(j,"LI",{});var CVe=s(TT);hTe=n(CVe,"STRONG",{});var Hjt=s(hTe);dsr=r(Hjt,"roformer"),Hjt.forEach(t),msr=r(CVe," \u2014 "),dH=n(CVe,"A",{href:!0});var Jjt=s(dH);csr=r(Jjt,"RoFormerForSequenceClassification"),Jjt.forEach(t),fsr=r(CVe," (RoFormer model)"),CVe.forEach(t),gsr=i(j),MT=n(j,"LI",{});var wVe=s(MT);uTe=n(wVe,"STRONG",{});var Yjt=s(uTe);hsr=r(Yjt,"squeezebert"),Yjt.forEach(t),usr=r(wVe," \u2014 "),mH=n(wVe,"A",{href:!0});var Kjt=s(mH);psr=r(Kjt,"SqueezeBertForSequenceClassification"),Kjt.forEach(t),_sr=r(wVe," (SqueezeBERT model)"),wVe.forEach(t),bsr=i(j),ET=n(j,"LI",{});var AVe=s(ET);pTe=n(AVe,"STRONG",{});var Zjt=s(pTe);vsr=r(Zjt,"tapas"),Zjt.forEach(t),Fsr=r(AVe," \u2014 "),cH=n(AVe,"A",{href:!0});var eDt=s(cH);Tsr=r(eDt,"TapasForSequenceClassification"),eDt.forEach(t),Msr=r(AVe," (TAPAS model)"),AVe.forEach(t),Esr=i(j),CT=n(j,"LI",{});var LVe=s(CT);_Te=n(LVe,"STRONG",{});var oDt=s(_Te);Csr=r(oDt,"transfo-xl"),oDt.forEach(t),wsr=r(LVe," \u2014 "),fH=n(LVe,"A",{href:!0});var rDt=s(fH);Asr=r(rDt,"TransfoXLForSequenceClassification"),rDt.forEach(t),Lsr=r(LVe," (Transformer-XL model)"),LVe.forEach(t),ysr=i(j),wT=n(j,"LI",{});var yVe=s(wT);bTe=n(yVe,"STRONG",{});var tDt=s(bTe);xsr=r(tDt,"xlm"),tDt.forEach(t),$sr=r(yVe," \u2014 "),gH=n(yVe,"A",{href:!0});var aDt=s(gH);ksr=r(aDt,"XLMForSequenceClassification"),aDt.forEach(t),Ssr=r(yVe," (XLM model)"),yVe.forEach(t),Rsr=i(j),AT=n(j,"LI",{});var xVe=s(AT);vTe=n(xVe,"STRONG",{});var nDt=s(vTe);Psr=r(nDt,"xlm-roberta"),nDt.forEach(t),Bsr=r(xVe," \u2014 "),hH=n(xVe,"A",{href:!0});var sDt=s(hH);Isr=r(sDt,"XLMRobertaForSequenceClassification"),sDt.forEach(t),Nsr=r(xVe," (XLM-RoBERTa model)"),xVe.forEach(t),qsr=i(j),LT=n(j,"LI",{});var $Ve=s(LT);FTe=n($Ve,"STRONG",{});var lDt=s(FTe);jsr=r(lDt,"xlm-roberta-xl"),lDt.forEach(t),Dsr=r($Ve," \u2014 "),uH=n($Ve,"A",{href:!0});var iDt=s(uH);Gsr=r(iDt,"XLMRobertaXLForSequenceClassification"),iDt.forEach(t),Osr=r($Ve," (XLM-RoBERTa-XL model)"),$Ve.forEach(t),Vsr=i(j),yT=n(j,"LI",{});var kVe=s(yT);TTe=n(kVe,"STRONG",{});var dDt=s(TTe);Xsr=r(dDt,"xlnet"),dDt.forEach(t),zsr=r(kVe," \u2014 "),pH=n(kVe,"A",{href:!0});var mDt=s(pH);Qsr=r(mDt,"XLNetForSequenceClassification"),mDt.forEach(t),Wsr=r(kVe," (XLNet model)"),kVe.forEach(t),Usr=i(j),xT=n(j,"LI",{});var SVe=s(xT);MTe=n(SVe,"STRONG",{});var cDt=s(MTe);Hsr=r(cDt,"yoso"),cDt.forEach(t),Jsr=r(SVe," \u2014 "),_H=n(SVe,"A",{href:!0});var fDt=s(_H);Ysr=r(fDt,"YosoForSequenceClassification"),fDt.forEach(t),Ksr=r(SVe," (YOSO model)"),SVe.forEach(t),j.forEach(t),Zsr=i(wa),$T=n(wa,"P",{});var RVe=s($T);elr=r(RVe,"The model is set in evaluation mode by default using "),ETe=n(RVe,"CODE",{});var gDt=s(ETe);olr=r(gDt,"model.eval()"),gDt.forEach(t),rlr=r(RVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CTe=n(RVe,"CODE",{});var hDt=s(CTe);tlr=r(hDt,"model.train()"),hDt.forEach(t),RVe.forEach(t),alr=i(wa),T(kT.$$.fragment,wa),wa.forEach(t),kl.forEach(t),ceo=i(c),Bd=n(c,"H2",{class:!0});var wro=s(Bd);ST=n(wro,"A",{id:!0,class:!0,href:!0});var uDt=s(ST);wTe=n(uDt,"SPAN",{});var pDt=s(wTe);T(r$.$$.fragment,pDt),pDt.forEach(t),uDt.forEach(t),nlr=i(wro),ATe=n(wro,"SPAN",{});var _Dt=s(ATe);slr=r(_Dt,"AutoModelForMultipleChoice"),_Dt.forEach(t),wro.forEach(t),feo=i(c),Do=n(c,"DIV",{class:!0});var Sl=s(Do);T(t$.$$.fragment,Sl),llr=i(Sl),Id=n(Sl,"P",{});var mie=s(Id);ilr=r(mie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),bH=n(mie,"A",{href:!0});var bDt=s(bH);dlr=r(bDt,"from_pretrained()"),bDt.forEach(t),mlr=r(mie," class method or the "),vH=n(mie,"A",{href:!0});var vDt=s(vH);clr=r(vDt,"from_config()"),vDt.forEach(t),flr=r(mie,` class
method.`),mie.forEach(t),glr=i(Sl),a$=n(Sl,"P",{});var Aro=s(a$);hlr=r(Aro,"This class cannot be instantiated directly using "),LTe=n(Aro,"CODE",{});var FDt=s(LTe);ulr=r(FDt,"__init__()"),FDt.forEach(t),plr=r(Aro," (throws an error)."),Aro.forEach(t),_lr=i(Sl),Et=n(Sl,"DIV",{class:!0});var s8=s(Et);T(n$.$$.fragment,s8),blr=i(s8),yTe=n(s8,"P",{});var TDt=s(yTe);vlr=r(TDt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),TDt.forEach(t),Flr=i(s8),Nd=n(s8,"P",{});var cie=s(Nd);Tlr=r(cie,`Note:
Loading a model from its configuration file does `),xTe=n(cie,"STRONG",{});var MDt=s(xTe);Mlr=r(MDt,"not"),MDt.forEach(t),Elr=r(cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=n(cie,"A",{href:!0});var EDt=s(FH);Clr=r(EDt,"from_pretrained()"),EDt.forEach(t),wlr=r(cie," to load the model weights."),cie.forEach(t),Alr=i(s8),T(RT.$$.fragment,s8),s8.forEach(t),Llr=i(Sl),no=n(Sl,"DIV",{class:!0});var Aa=s(no);T(s$.$$.fragment,Aa),ylr=i(Aa),$Te=n(Aa,"P",{});var CDt=s($Te);xlr=r(CDt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),CDt.forEach(t),$lr=i(Aa),rn=n(Aa,"P",{});var l8=s(rn);klr=r(l8,"The model class to instantiate is selected based on the "),kTe=n(l8,"CODE",{});var wDt=s(kTe);Slr=r(wDt,"model_type"),wDt.forEach(t),Rlr=r(l8,` property of the config object (either
passed as an argument or loaded from `),STe=n(l8,"CODE",{});var ADt=s(STe);Plr=r(ADt,"pretrained_model_name_or_path"),ADt.forEach(t),Blr=r(l8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=n(l8,"CODE",{});var LDt=s(RTe);Ilr=r(LDt,"pretrained_model_name_or_path"),LDt.forEach(t),Nlr=r(l8,":"),l8.forEach(t),qlr=i(Aa),Z=n(Aa,"UL",{});var ee=s(Z);PT=n(ee,"LI",{});var PVe=s(PT);PTe=n(PVe,"STRONG",{});var yDt=s(PTe);jlr=r(yDt,"albert"),yDt.forEach(t),Dlr=r(PVe," \u2014 "),TH=n(PVe,"A",{href:!0});var xDt=s(TH);Glr=r(xDt,"AlbertForMultipleChoice"),xDt.forEach(t),Olr=r(PVe," (ALBERT model)"),PVe.forEach(t),Vlr=i(ee),BT=n(ee,"LI",{});var BVe=s(BT);BTe=n(BVe,"STRONG",{});var $Dt=s(BTe);Xlr=r($Dt,"bert"),$Dt.forEach(t),zlr=r(BVe," \u2014 "),MH=n(BVe,"A",{href:!0});var kDt=s(MH);Qlr=r(kDt,"BertForMultipleChoice"),kDt.forEach(t),Wlr=r(BVe," (BERT model)"),BVe.forEach(t),Ulr=i(ee),IT=n(ee,"LI",{});var IVe=s(IT);ITe=n(IVe,"STRONG",{});var SDt=s(ITe);Hlr=r(SDt,"big_bird"),SDt.forEach(t),Jlr=r(IVe," \u2014 "),EH=n(IVe,"A",{href:!0});var RDt=s(EH);Ylr=r(RDt,"BigBirdForMultipleChoice"),RDt.forEach(t),Klr=r(IVe," (BigBird model)"),IVe.forEach(t),Zlr=i(ee),NT=n(ee,"LI",{});var NVe=s(NT);NTe=n(NVe,"STRONG",{});var PDt=s(NTe);eir=r(PDt,"camembert"),PDt.forEach(t),oir=r(NVe," \u2014 "),CH=n(NVe,"A",{href:!0});var BDt=s(CH);rir=r(BDt,"CamembertForMultipleChoice"),BDt.forEach(t),tir=r(NVe," (CamemBERT model)"),NVe.forEach(t),air=i(ee),qT=n(ee,"LI",{});var qVe=s(qT);qTe=n(qVe,"STRONG",{});var IDt=s(qTe);nir=r(IDt,"canine"),IDt.forEach(t),sir=r(qVe," \u2014 "),wH=n(qVe,"A",{href:!0});var NDt=s(wH);lir=r(NDt,"CanineForMultipleChoice"),NDt.forEach(t),iir=r(qVe," (CANINE model)"),qVe.forEach(t),dir=i(ee),jT=n(ee,"LI",{});var jVe=s(jT);jTe=n(jVe,"STRONG",{});var qDt=s(jTe);mir=r(qDt,"convbert"),qDt.forEach(t),cir=r(jVe," \u2014 "),AH=n(jVe,"A",{href:!0});var jDt=s(AH);fir=r(jDt,"ConvBertForMultipleChoice"),jDt.forEach(t),gir=r(jVe," (ConvBERT model)"),jVe.forEach(t),hir=i(ee),DT=n(ee,"LI",{});var DVe=s(DT);DTe=n(DVe,"STRONG",{});var DDt=s(DTe);uir=r(DDt,"data2vec-text"),DDt.forEach(t),pir=r(DVe," \u2014 "),LH=n(DVe,"A",{href:!0});var GDt=s(LH);_ir=r(GDt,"Data2VecTextForMultipleChoice"),GDt.forEach(t),bir=r(DVe," (Data2VecText model)"),DVe.forEach(t),vir=i(ee),GT=n(ee,"LI",{});var GVe=s(GT);GTe=n(GVe,"STRONG",{});var ODt=s(GTe);Fir=r(ODt,"deberta-v2"),ODt.forEach(t),Tir=r(GVe," \u2014 "),yH=n(GVe,"A",{href:!0});var VDt=s(yH);Mir=r(VDt,"DebertaV2ForMultipleChoice"),VDt.forEach(t),Eir=r(GVe," (DeBERTa-v2 model)"),GVe.forEach(t),Cir=i(ee),OT=n(ee,"LI",{});var OVe=s(OT);OTe=n(OVe,"STRONG",{});var XDt=s(OTe);wir=r(XDt,"distilbert"),XDt.forEach(t),Air=r(OVe," \u2014 "),xH=n(OVe,"A",{href:!0});var zDt=s(xH);Lir=r(zDt,"DistilBertForMultipleChoice"),zDt.forEach(t),yir=r(OVe," (DistilBERT model)"),OVe.forEach(t),xir=i(ee),VT=n(ee,"LI",{});var VVe=s(VT);VTe=n(VVe,"STRONG",{});var QDt=s(VTe);$ir=r(QDt,"electra"),QDt.forEach(t),kir=r(VVe," \u2014 "),$H=n(VVe,"A",{href:!0});var WDt=s($H);Sir=r(WDt,"ElectraForMultipleChoice"),WDt.forEach(t),Rir=r(VVe," (ELECTRA model)"),VVe.forEach(t),Pir=i(ee),XT=n(ee,"LI",{});var XVe=s(XT);XTe=n(XVe,"STRONG",{});var UDt=s(XTe);Bir=r(UDt,"ernie"),UDt.forEach(t),Iir=r(XVe," \u2014 "),kH=n(XVe,"A",{href:!0});var HDt=s(kH);Nir=r(HDt,"ErnieForMultipleChoice"),HDt.forEach(t),qir=r(XVe," (ERNIE model)"),XVe.forEach(t),jir=i(ee),zT=n(ee,"LI",{});var zVe=s(zT);zTe=n(zVe,"STRONG",{});var JDt=s(zTe);Dir=r(JDt,"flaubert"),JDt.forEach(t),Gir=r(zVe," \u2014 "),SH=n(zVe,"A",{href:!0});var YDt=s(SH);Oir=r(YDt,"FlaubertForMultipleChoice"),YDt.forEach(t),Vir=r(zVe," (FlauBERT model)"),zVe.forEach(t),Xir=i(ee),QT=n(ee,"LI",{});var QVe=s(QT);QTe=n(QVe,"STRONG",{});var KDt=s(QTe);zir=r(KDt,"fnet"),KDt.forEach(t),Qir=r(QVe," \u2014 "),RH=n(QVe,"A",{href:!0});var ZDt=s(RH);Wir=r(ZDt,"FNetForMultipleChoice"),ZDt.forEach(t),Uir=r(QVe," (FNet model)"),QVe.forEach(t),Hir=i(ee),WT=n(ee,"LI",{});var WVe=s(WT);WTe=n(WVe,"STRONG",{});var eGt=s(WTe);Jir=r(eGt,"funnel"),eGt.forEach(t),Yir=r(WVe," \u2014 "),PH=n(WVe,"A",{href:!0});var oGt=s(PH);Kir=r(oGt,"FunnelForMultipleChoice"),oGt.forEach(t),Zir=r(WVe," (Funnel Transformer model)"),WVe.forEach(t),edr=i(ee),UT=n(ee,"LI",{});var UVe=s(UT);UTe=n(UVe,"STRONG",{});var rGt=s(UTe);odr=r(rGt,"ibert"),rGt.forEach(t),rdr=r(UVe," \u2014 "),BH=n(UVe,"A",{href:!0});var tGt=s(BH);tdr=r(tGt,"IBertForMultipleChoice"),tGt.forEach(t),adr=r(UVe," (I-BERT model)"),UVe.forEach(t),ndr=i(ee),HT=n(ee,"LI",{});var HVe=s(HT);HTe=n(HVe,"STRONG",{});var aGt=s(HTe);sdr=r(aGt,"longformer"),aGt.forEach(t),ldr=r(HVe," \u2014 "),IH=n(HVe,"A",{href:!0});var nGt=s(IH);idr=r(nGt,"LongformerForMultipleChoice"),nGt.forEach(t),ddr=r(HVe," (Longformer model)"),HVe.forEach(t),mdr=i(ee),JT=n(ee,"LI",{});var JVe=s(JT);JTe=n(JVe,"STRONG",{});var sGt=s(JTe);cdr=r(sGt,"luke"),sGt.forEach(t),fdr=r(JVe," \u2014 "),NH=n(JVe,"A",{href:!0});var lGt=s(NH);gdr=r(lGt,"LukeForMultipleChoice"),lGt.forEach(t),hdr=r(JVe," (LUKE model)"),JVe.forEach(t),udr=i(ee),YT=n(ee,"LI",{});var YVe=s(YT);YTe=n(YVe,"STRONG",{});var iGt=s(YTe);pdr=r(iGt,"megatron-bert"),iGt.forEach(t),_dr=r(YVe," \u2014 "),qH=n(YVe,"A",{href:!0});var dGt=s(qH);bdr=r(dGt,"MegatronBertForMultipleChoice"),dGt.forEach(t),vdr=r(YVe," (Megatron-BERT model)"),YVe.forEach(t),Fdr=i(ee),KT=n(ee,"LI",{});var KVe=s(KT);KTe=n(KVe,"STRONG",{});var mGt=s(KTe);Tdr=r(mGt,"mobilebert"),mGt.forEach(t),Mdr=r(KVe," \u2014 "),jH=n(KVe,"A",{href:!0});var cGt=s(jH);Edr=r(cGt,"MobileBertForMultipleChoice"),cGt.forEach(t),Cdr=r(KVe," (MobileBERT model)"),KVe.forEach(t),wdr=i(ee),ZT=n(ee,"LI",{});var ZVe=s(ZT);ZTe=n(ZVe,"STRONG",{});var fGt=s(ZTe);Adr=r(fGt,"mpnet"),fGt.forEach(t),Ldr=r(ZVe," \u2014 "),DH=n(ZVe,"A",{href:!0});var gGt=s(DH);ydr=r(gGt,"MPNetForMultipleChoice"),gGt.forEach(t),xdr=r(ZVe," (MPNet model)"),ZVe.forEach(t),$dr=i(ee),eM=n(ee,"LI",{});var eXe=s(eM);eMe=n(eXe,"STRONG",{});var hGt=s(eMe);kdr=r(hGt,"nezha"),hGt.forEach(t),Sdr=r(eXe," \u2014 "),GH=n(eXe,"A",{href:!0});var uGt=s(GH);Rdr=r(uGt,"NezhaForMultipleChoice"),uGt.forEach(t),Pdr=r(eXe," (Nezha model)"),eXe.forEach(t),Bdr=i(ee),oM=n(ee,"LI",{});var oXe=s(oM);oMe=n(oXe,"STRONG",{});var pGt=s(oMe);Idr=r(pGt,"nystromformer"),pGt.forEach(t),Ndr=r(oXe," \u2014 "),OH=n(oXe,"A",{href:!0});var _Gt=s(OH);qdr=r(_Gt,"NystromformerForMultipleChoice"),_Gt.forEach(t),jdr=r(oXe," (Nystr\xF6mformer model)"),oXe.forEach(t),Ddr=i(ee),rM=n(ee,"LI",{});var rXe=s(rM);rMe=n(rXe,"STRONG",{});var bGt=s(rMe);Gdr=r(bGt,"qdqbert"),bGt.forEach(t),Odr=r(rXe," \u2014 "),VH=n(rXe,"A",{href:!0});var vGt=s(VH);Vdr=r(vGt,"QDQBertForMultipleChoice"),vGt.forEach(t),Xdr=r(rXe," (QDQBert model)"),rXe.forEach(t),zdr=i(ee),tM=n(ee,"LI",{});var tXe=s(tM);tMe=n(tXe,"STRONG",{});var FGt=s(tMe);Qdr=r(FGt,"rembert"),FGt.forEach(t),Wdr=r(tXe," \u2014 "),XH=n(tXe,"A",{href:!0});var TGt=s(XH);Udr=r(TGt,"RemBertForMultipleChoice"),TGt.forEach(t),Hdr=r(tXe," (RemBERT model)"),tXe.forEach(t),Jdr=i(ee),aM=n(ee,"LI",{});var aXe=s(aM);aMe=n(aXe,"STRONG",{});var MGt=s(aMe);Ydr=r(MGt,"roberta"),MGt.forEach(t),Kdr=r(aXe," \u2014 "),zH=n(aXe,"A",{href:!0});var EGt=s(zH);Zdr=r(EGt,"RobertaForMultipleChoice"),EGt.forEach(t),emr=r(aXe," (RoBERTa model)"),aXe.forEach(t),omr=i(ee),nM=n(ee,"LI",{});var nXe=s(nM);nMe=n(nXe,"STRONG",{});var CGt=s(nMe);rmr=r(CGt,"roformer"),CGt.forEach(t),tmr=r(nXe," \u2014 "),QH=n(nXe,"A",{href:!0});var wGt=s(QH);amr=r(wGt,"RoFormerForMultipleChoice"),wGt.forEach(t),nmr=r(nXe," (RoFormer model)"),nXe.forEach(t),smr=i(ee),sM=n(ee,"LI",{});var sXe=s(sM);sMe=n(sXe,"STRONG",{});var AGt=s(sMe);lmr=r(AGt,"squeezebert"),AGt.forEach(t),imr=r(sXe," \u2014 "),WH=n(sXe,"A",{href:!0});var LGt=s(WH);dmr=r(LGt,"SqueezeBertForMultipleChoice"),LGt.forEach(t),mmr=r(sXe," (SqueezeBERT model)"),sXe.forEach(t),cmr=i(ee),lM=n(ee,"LI",{});var lXe=s(lM);lMe=n(lXe,"STRONG",{});var yGt=s(lMe);fmr=r(yGt,"xlm"),yGt.forEach(t),gmr=r(lXe," \u2014 "),UH=n(lXe,"A",{href:!0});var xGt=s(UH);hmr=r(xGt,"XLMForMultipleChoice"),xGt.forEach(t),umr=r(lXe," (XLM model)"),lXe.forEach(t),pmr=i(ee),iM=n(ee,"LI",{});var iXe=s(iM);iMe=n(iXe,"STRONG",{});var $Gt=s(iMe);_mr=r($Gt,"xlm-roberta"),$Gt.forEach(t),bmr=r(iXe," \u2014 "),HH=n(iXe,"A",{href:!0});var kGt=s(HH);vmr=r(kGt,"XLMRobertaForMultipleChoice"),kGt.forEach(t),Fmr=r(iXe," (XLM-RoBERTa model)"),iXe.forEach(t),Tmr=i(ee),dM=n(ee,"LI",{});var dXe=s(dM);dMe=n(dXe,"STRONG",{});var SGt=s(dMe);Mmr=r(SGt,"xlm-roberta-xl"),SGt.forEach(t),Emr=r(dXe," \u2014 "),JH=n(dXe,"A",{href:!0});var RGt=s(JH);Cmr=r(RGt,"XLMRobertaXLForMultipleChoice"),RGt.forEach(t),wmr=r(dXe," (XLM-RoBERTa-XL model)"),dXe.forEach(t),Amr=i(ee),mM=n(ee,"LI",{});var mXe=s(mM);mMe=n(mXe,"STRONG",{});var PGt=s(mMe);Lmr=r(PGt,"xlnet"),PGt.forEach(t),ymr=r(mXe," \u2014 "),YH=n(mXe,"A",{href:!0});var BGt=s(YH);xmr=r(BGt,"XLNetForMultipleChoice"),BGt.forEach(t),$mr=r(mXe," (XLNet model)"),mXe.forEach(t),kmr=i(ee),cM=n(ee,"LI",{});var cXe=s(cM);cMe=n(cXe,"STRONG",{});var IGt=s(cMe);Smr=r(IGt,"yoso"),IGt.forEach(t),Rmr=r(cXe," \u2014 "),KH=n(cXe,"A",{href:!0});var NGt=s(KH);Pmr=r(NGt,"YosoForMultipleChoice"),NGt.forEach(t),Bmr=r(cXe," (YOSO model)"),cXe.forEach(t),ee.forEach(t),Imr=i(Aa),fM=n(Aa,"P",{});var fXe=s(fM);Nmr=r(fXe,"The model is set in evaluation mode by default using "),fMe=n(fXe,"CODE",{});var qGt=s(fMe);qmr=r(qGt,"model.eval()"),qGt.forEach(t),jmr=r(fXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gMe=n(fXe,"CODE",{});var jGt=s(gMe);Dmr=r(jGt,"model.train()"),jGt.forEach(t),fXe.forEach(t),Gmr=i(Aa),T(gM.$$.fragment,Aa),Aa.forEach(t),Sl.forEach(t),geo=i(c),qd=n(c,"H2",{class:!0});var Lro=s(qd);hM=n(Lro,"A",{id:!0,class:!0,href:!0});var DGt=s(hM);hMe=n(DGt,"SPAN",{});var GGt=s(hMe);T(l$.$$.fragment,GGt),GGt.forEach(t),DGt.forEach(t),Omr=i(Lro),uMe=n(Lro,"SPAN",{});var OGt=s(uMe);Vmr=r(OGt,"AutoModelForNextSentencePrediction"),OGt.forEach(t),Lro.forEach(t),heo=i(c),Go=n(c,"DIV",{class:!0});var Rl=s(Go);T(i$.$$.fragment,Rl),Xmr=i(Rl),jd=n(Rl,"P",{});var fie=s(jd);zmr=r(fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ZH=n(fie,"A",{href:!0});var VGt=s(ZH);Qmr=r(VGt,"from_pretrained()"),VGt.forEach(t),Wmr=r(fie," class method or the "),eJ=n(fie,"A",{href:!0});var XGt=s(eJ);Umr=r(XGt,"from_config()"),XGt.forEach(t),Hmr=r(fie,` class
method.`),fie.forEach(t),Jmr=i(Rl),d$=n(Rl,"P",{});var yro=s(d$);Ymr=r(yro,"This class cannot be instantiated directly using "),pMe=n(yro,"CODE",{});var zGt=s(pMe);Kmr=r(zGt,"__init__()"),zGt.forEach(t),Zmr=r(yro," (throws an error)."),yro.forEach(t),ecr=i(Rl),Ct=n(Rl,"DIV",{class:!0});var i8=s(Ct);T(m$.$$.fragment,i8),ocr=i(i8),_Me=n(i8,"P",{});var QGt=s(_Me);rcr=r(QGt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),QGt.forEach(t),tcr=i(i8),Dd=n(i8,"P",{});var gie=s(Dd);acr=r(gie,`Note:
Loading a model from its configuration file does `),bMe=n(gie,"STRONG",{});var WGt=s(bMe);ncr=r(WGt,"not"),WGt.forEach(t),scr=r(gie,` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=n(gie,"A",{href:!0});var UGt=s(oJ);lcr=r(UGt,"from_pretrained()"),UGt.forEach(t),icr=r(gie," to load the model weights."),gie.forEach(t),dcr=i(i8),T(uM.$$.fragment,i8),i8.forEach(t),mcr=i(Rl),so=n(Rl,"DIV",{class:!0});var La=s(so);T(c$.$$.fragment,La),ccr=i(La),vMe=n(La,"P",{});var HGt=s(vMe);fcr=r(HGt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),HGt.forEach(t),gcr=i(La),tn=n(La,"P",{});var d8=s(tn);hcr=r(d8,"The model class to instantiate is selected based on the "),FMe=n(d8,"CODE",{});var JGt=s(FMe);ucr=r(JGt,"model_type"),JGt.forEach(t),pcr=r(d8,` property of the config object (either
passed as an argument or loaded from `),TMe=n(d8,"CODE",{});var YGt=s(TMe);_cr=r(YGt,"pretrained_model_name_or_path"),YGt.forEach(t),bcr=r(d8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MMe=n(d8,"CODE",{});var KGt=s(MMe);vcr=r(KGt,"pretrained_model_name_or_path"),KGt.forEach(t),Fcr=r(d8,":"),d8.forEach(t),Tcr=i(La),Ue=n(La,"UL",{});var mt=s(Ue);pM=n(mt,"LI",{});var gXe=s(pM);EMe=n(gXe,"STRONG",{});var ZGt=s(EMe);Mcr=r(ZGt,"bert"),ZGt.forEach(t),Ecr=r(gXe," \u2014 "),rJ=n(gXe,"A",{href:!0});var eOt=s(rJ);Ccr=r(eOt,"BertForNextSentencePrediction"),eOt.forEach(t),wcr=r(gXe," (BERT model)"),gXe.forEach(t),Acr=i(mt),_M=n(mt,"LI",{});var hXe=s(_M);CMe=n(hXe,"STRONG",{});var oOt=s(CMe);Lcr=r(oOt,"ernie"),oOt.forEach(t),ycr=r(hXe," \u2014 "),tJ=n(hXe,"A",{href:!0});var rOt=s(tJ);xcr=r(rOt,"ErnieForNextSentencePrediction"),rOt.forEach(t),$cr=r(hXe," (ERNIE model)"),hXe.forEach(t),kcr=i(mt),bM=n(mt,"LI",{});var uXe=s(bM);wMe=n(uXe,"STRONG",{});var tOt=s(wMe);Scr=r(tOt,"fnet"),tOt.forEach(t),Rcr=r(uXe," \u2014 "),aJ=n(uXe,"A",{href:!0});var aOt=s(aJ);Pcr=r(aOt,"FNetForNextSentencePrediction"),aOt.forEach(t),Bcr=r(uXe," (FNet model)"),uXe.forEach(t),Icr=i(mt),vM=n(mt,"LI",{});var pXe=s(vM);AMe=n(pXe,"STRONG",{});var nOt=s(AMe);Ncr=r(nOt,"megatron-bert"),nOt.forEach(t),qcr=r(pXe," \u2014 "),nJ=n(pXe,"A",{href:!0});var sOt=s(nJ);jcr=r(sOt,"MegatronBertForNextSentencePrediction"),sOt.forEach(t),Dcr=r(pXe," (Megatron-BERT model)"),pXe.forEach(t),Gcr=i(mt),FM=n(mt,"LI",{});var _Xe=s(FM);LMe=n(_Xe,"STRONG",{});var lOt=s(LMe);Ocr=r(lOt,"mobilebert"),lOt.forEach(t),Vcr=r(_Xe," \u2014 "),sJ=n(_Xe,"A",{href:!0});var iOt=s(sJ);Xcr=r(iOt,"MobileBertForNextSentencePrediction"),iOt.forEach(t),zcr=r(_Xe," (MobileBERT model)"),_Xe.forEach(t),Qcr=i(mt),TM=n(mt,"LI",{});var bXe=s(TM);yMe=n(bXe,"STRONG",{});var dOt=s(yMe);Wcr=r(dOt,"nezha"),dOt.forEach(t),Ucr=r(bXe," \u2014 "),lJ=n(bXe,"A",{href:!0});var mOt=s(lJ);Hcr=r(mOt,"NezhaForNextSentencePrediction"),mOt.forEach(t),Jcr=r(bXe," (Nezha model)"),bXe.forEach(t),Ycr=i(mt),MM=n(mt,"LI",{});var vXe=s(MM);xMe=n(vXe,"STRONG",{});var cOt=s(xMe);Kcr=r(cOt,"qdqbert"),cOt.forEach(t),Zcr=r(vXe," \u2014 "),iJ=n(vXe,"A",{href:!0});var fOt=s(iJ);efr=r(fOt,"QDQBertForNextSentencePrediction"),fOt.forEach(t),ofr=r(vXe," (QDQBert model)"),vXe.forEach(t),mt.forEach(t),rfr=i(La),EM=n(La,"P",{});var FXe=s(EM);tfr=r(FXe,"The model is set in evaluation mode by default using "),$Me=n(FXe,"CODE",{});var gOt=s($Me);afr=r(gOt,"model.eval()"),gOt.forEach(t),nfr=r(FXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kMe=n(FXe,"CODE",{});var hOt=s(kMe);sfr=r(hOt,"model.train()"),hOt.forEach(t),FXe.forEach(t),lfr=i(La),T(CM.$$.fragment,La),La.forEach(t),Rl.forEach(t),ueo=i(c),Gd=n(c,"H2",{class:!0});var xro=s(Gd);wM=n(xro,"A",{id:!0,class:!0,href:!0});var uOt=s(wM);SMe=n(uOt,"SPAN",{});var pOt=s(SMe);T(f$.$$.fragment,pOt),pOt.forEach(t),uOt.forEach(t),ifr=i(xro),RMe=n(xro,"SPAN",{});var _Ot=s(RMe);dfr=r(_Ot,"AutoModelForTokenClassification"),_Ot.forEach(t),xro.forEach(t),peo=i(c),Oo=n(c,"DIV",{class:!0});var Pl=s(Oo);T(g$.$$.fragment,Pl),mfr=i(Pl),Od=n(Pl,"P",{});var hie=s(Od);cfr=r(hie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),dJ=n(hie,"A",{href:!0});var bOt=s(dJ);ffr=r(bOt,"from_pretrained()"),bOt.forEach(t),gfr=r(hie," class method or the "),mJ=n(hie,"A",{href:!0});var vOt=s(mJ);hfr=r(vOt,"from_config()"),vOt.forEach(t),ufr=r(hie,` class
method.`),hie.forEach(t),pfr=i(Pl),h$=n(Pl,"P",{});var $ro=s(h$);_fr=r($ro,"This class cannot be instantiated directly using "),PMe=n($ro,"CODE",{});var FOt=s(PMe);bfr=r(FOt,"__init__()"),FOt.forEach(t),vfr=r($ro," (throws an error)."),$ro.forEach(t),Ffr=i(Pl),wt=n(Pl,"DIV",{class:!0});var m8=s(wt);T(u$.$$.fragment,m8),Tfr=i(m8),BMe=n(m8,"P",{});var TOt=s(BMe);Mfr=r(TOt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),TOt.forEach(t),Efr=i(m8),Vd=n(m8,"P",{});var uie=s(Vd);Cfr=r(uie,`Note:
Loading a model from its configuration file does `),IMe=n(uie,"STRONG",{});var MOt=s(IMe);wfr=r(MOt,"not"),MOt.forEach(t),Afr=r(uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),cJ=n(uie,"A",{href:!0});var EOt=s(cJ);Lfr=r(EOt,"from_pretrained()"),EOt.forEach(t),yfr=r(uie," to load the model weights."),uie.forEach(t),xfr=i(m8),T(AM.$$.fragment,m8),m8.forEach(t),$fr=i(Pl),lo=n(Pl,"DIV",{class:!0});var ya=s(lo);T(p$.$$.fragment,ya),kfr=i(ya),NMe=n(ya,"P",{});var COt=s(NMe);Sfr=r(COt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),COt.forEach(t),Rfr=i(ya),an=n(ya,"P",{});var c8=s(an);Pfr=r(c8,"The model class to instantiate is selected based on the "),qMe=n(c8,"CODE",{});var wOt=s(qMe);Bfr=r(wOt,"model_type"),wOt.forEach(t),Ifr=r(c8,` property of the config object (either
passed as an argument or loaded from `),jMe=n(c8,"CODE",{});var AOt=s(jMe);Nfr=r(AOt,"pretrained_model_name_or_path"),AOt.forEach(t),qfr=r(c8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DMe=n(c8,"CODE",{});var LOt=s(DMe);jfr=r(LOt,"pretrained_model_name_or_path"),LOt.forEach(t),Dfr=r(c8,":"),c8.forEach(t),Gfr=i(ya),H=n(ya,"UL",{});var Y=s(H);LM=n(Y,"LI",{});var TXe=s(LM);GMe=n(TXe,"STRONG",{});var yOt=s(GMe);Ofr=r(yOt,"albert"),yOt.forEach(t),Vfr=r(TXe," \u2014 "),fJ=n(TXe,"A",{href:!0});var xOt=s(fJ);Xfr=r(xOt,"AlbertForTokenClassification"),xOt.forEach(t),zfr=r(TXe," (ALBERT model)"),TXe.forEach(t),Qfr=i(Y),yM=n(Y,"LI",{});var MXe=s(yM);OMe=n(MXe,"STRONG",{});var $Ot=s(OMe);Wfr=r($Ot,"bert"),$Ot.forEach(t),Ufr=r(MXe," \u2014 "),gJ=n(MXe,"A",{href:!0});var kOt=s(gJ);Hfr=r(kOt,"BertForTokenClassification"),kOt.forEach(t),Jfr=r(MXe," (BERT model)"),MXe.forEach(t),Yfr=i(Y),xM=n(Y,"LI",{});var EXe=s(xM);VMe=n(EXe,"STRONG",{});var SOt=s(VMe);Kfr=r(SOt,"big_bird"),SOt.forEach(t),Zfr=r(EXe," \u2014 "),hJ=n(EXe,"A",{href:!0});var ROt=s(hJ);egr=r(ROt,"BigBirdForTokenClassification"),ROt.forEach(t),ogr=r(EXe," (BigBird model)"),EXe.forEach(t),rgr=i(Y),$M=n(Y,"LI",{});var CXe=s($M);XMe=n(CXe,"STRONG",{});var POt=s(XMe);tgr=r(POt,"bloom"),POt.forEach(t),agr=r(CXe," \u2014 "),uJ=n(CXe,"A",{href:!0});var BOt=s(uJ);ngr=r(BOt,"BloomForTokenClassification"),BOt.forEach(t),sgr=r(CXe," (BLOOM model)"),CXe.forEach(t),lgr=i(Y),kM=n(Y,"LI",{});var wXe=s(kM);zMe=n(wXe,"STRONG",{});var IOt=s(zMe);igr=r(IOt,"camembert"),IOt.forEach(t),dgr=r(wXe," \u2014 "),pJ=n(wXe,"A",{href:!0});var NOt=s(pJ);mgr=r(NOt,"CamembertForTokenClassification"),NOt.forEach(t),cgr=r(wXe," (CamemBERT model)"),wXe.forEach(t),fgr=i(Y),SM=n(Y,"LI",{});var AXe=s(SM);QMe=n(AXe,"STRONG",{});var qOt=s(QMe);ggr=r(qOt,"canine"),qOt.forEach(t),hgr=r(AXe," \u2014 "),_J=n(AXe,"A",{href:!0});var jOt=s(_J);ugr=r(jOt,"CanineForTokenClassification"),jOt.forEach(t),pgr=r(AXe," (CANINE model)"),AXe.forEach(t),_gr=i(Y),RM=n(Y,"LI",{});var LXe=s(RM);WMe=n(LXe,"STRONG",{});var DOt=s(WMe);bgr=r(DOt,"convbert"),DOt.forEach(t),vgr=r(LXe," \u2014 "),bJ=n(LXe,"A",{href:!0});var GOt=s(bJ);Fgr=r(GOt,"ConvBertForTokenClassification"),GOt.forEach(t),Tgr=r(LXe," (ConvBERT model)"),LXe.forEach(t),Mgr=i(Y),PM=n(Y,"LI",{});var yXe=s(PM);UMe=n(yXe,"STRONG",{});var OOt=s(UMe);Egr=r(OOt,"data2vec-text"),OOt.forEach(t),Cgr=r(yXe," \u2014 "),vJ=n(yXe,"A",{href:!0});var VOt=s(vJ);wgr=r(VOt,"Data2VecTextForTokenClassification"),VOt.forEach(t),Agr=r(yXe," (Data2VecText model)"),yXe.forEach(t),Lgr=i(Y),BM=n(Y,"LI",{});var xXe=s(BM);HMe=n(xXe,"STRONG",{});var XOt=s(HMe);ygr=r(XOt,"deberta"),XOt.forEach(t),xgr=r(xXe," \u2014 "),FJ=n(xXe,"A",{href:!0});var zOt=s(FJ);$gr=r(zOt,"DebertaForTokenClassification"),zOt.forEach(t),kgr=r(xXe," (DeBERTa model)"),xXe.forEach(t),Sgr=i(Y),IM=n(Y,"LI",{});var $Xe=s(IM);JMe=n($Xe,"STRONG",{});var QOt=s(JMe);Rgr=r(QOt,"deberta-v2"),QOt.forEach(t),Pgr=r($Xe," \u2014 "),TJ=n($Xe,"A",{href:!0});var WOt=s(TJ);Bgr=r(WOt,"DebertaV2ForTokenClassification"),WOt.forEach(t),Igr=r($Xe," (DeBERTa-v2 model)"),$Xe.forEach(t),Ngr=i(Y),NM=n(Y,"LI",{});var kXe=s(NM);YMe=n(kXe,"STRONG",{});var UOt=s(YMe);qgr=r(UOt,"distilbert"),UOt.forEach(t),jgr=r(kXe," \u2014 "),MJ=n(kXe,"A",{href:!0});var HOt=s(MJ);Dgr=r(HOt,"DistilBertForTokenClassification"),HOt.forEach(t),Ggr=r(kXe," (DistilBERT model)"),kXe.forEach(t),Ogr=i(Y),qM=n(Y,"LI",{});var SXe=s(qM);KMe=n(SXe,"STRONG",{});var JOt=s(KMe);Vgr=r(JOt,"electra"),JOt.forEach(t),Xgr=r(SXe," \u2014 "),EJ=n(SXe,"A",{href:!0});var YOt=s(EJ);zgr=r(YOt,"ElectraForTokenClassification"),YOt.forEach(t),Qgr=r(SXe," (ELECTRA model)"),SXe.forEach(t),Wgr=i(Y),jM=n(Y,"LI",{});var RXe=s(jM);ZMe=n(RXe,"STRONG",{});var KOt=s(ZMe);Ugr=r(KOt,"ernie"),KOt.forEach(t),Hgr=r(RXe," \u2014 "),CJ=n(RXe,"A",{href:!0});var ZOt=s(CJ);Jgr=r(ZOt,"ErnieForTokenClassification"),ZOt.forEach(t),Ygr=r(RXe," (ERNIE model)"),RXe.forEach(t),Kgr=i(Y),DM=n(Y,"LI",{});var PXe=s(DM);eEe=n(PXe,"STRONG",{});var eVt=s(eEe);Zgr=r(eVt,"esm"),eVt.forEach(t),ehr=r(PXe," \u2014 "),wJ=n(PXe,"A",{href:!0});var oVt=s(wJ);ohr=r(oVt,"EsmForTokenClassification"),oVt.forEach(t),rhr=r(PXe," (ESM model)"),PXe.forEach(t),thr=i(Y),GM=n(Y,"LI",{});var BXe=s(GM);oEe=n(BXe,"STRONG",{});var rVt=s(oEe);ahr=r(rVt,"flaubert"),rVt.forEach(t),nhr=r(BXe," \u2014 "),AJ=n(BXe,"A",{href:!0});var tVt=s(AJ);shr=r(tVt,"FlaubertForTokenClassification"),tVt.forEach(t),lhr=r(BXe," (FlauBERT model)"),BXe.forEach(t),ihr=i(Y),OM=n(Y,"LI",{});var IXe=s(OM);rEe=n(IXe,"STRONG",{});var aVt=s(rEe);dhr=r(aVt,"fnet"),aVt.forEach(t),mhr=r(IXe," \u2014 "),LJ=n(IXe,"A",{href:!0});var nVt=s(LJ);chr=r(nVt,"FNetForTokenClassification"),nVt.forEach(t),fhr=r(IXe," (FNet model)"),IXe.forEach(t),ghr=i(Y),VM=n(Y,"LI",{});var NXe=s(VM);tEe=n(NXe,"STRONG",{});var sVt=s(tEe);hhr=r(sVt,"funnel"),sVt.forEach(t),uhr=r(NXe," \u2014 "),yJ=n(NXe,"A",{href:!0});var lVt=s(yJ);phr=r(lVt,"FunnelForTokenClassification"),lVt.forEach(t),_hr=r(NXe," (Funnel Transformer model)"),NXe.forEach(t),bhr=i(Y),XM=n(Y,"LI",{});var qXe=s(XM);aEe=n(qXe,"STRONG",{});var iVt=s(aEe);vhr=r(iVt,"gpt2"),iVt.forEach(t),Fhr=r(qXe," \u2014 "),xJ=n(qXe,"A",{href:!0});var dVt=s(xJ);Thr=r(dVt,"GPT2ForTokenClassification"),dVt.forEach(t),Mhr=r(qXe," (OpenAI GPT-2 model)"),qXe.forEach(t),Ehr=i(Y),zM=n(Y,"LI",{});var jXe=s(zM);nEe=n(jXe,"STRONG",{});var mVt=s(nEe);Chr=r(mVt,"ibert"),mVt.forEach(t),whr=r(jXe," \u2014 "),$J=n(jXe,"A",{href:!0});var cVt=s($J);Ahr=r(cVt,"IBertForTokenClassification"),cVt.forEach(t),Lhr=r(jXe," (I-BERT model)"),jXe.forEach(t),yhr=i(Y),QM=n(Y,"LI",{});var DXe=s(QM);sEe=n(DXe,"STRONG",{});var fVt=s(sEe);xhr=r(fVt,"layoutlm"),fVt.forEach(t),$hr=r(DXe," \u2014 "),kJ=n(DXe,"A",{href:!0});var gVt=s(kJ);khr=r(gVt,"LayoutLMForTokenClassification"),gVt.forEach(t),Shr=r(DXe," (LayoutLM model)"),DXe.forEach(t),Rhr=i(Y),WM=n(Y,"LI",{});var GXe=s(WM);lEe=n(GXe,"STRONG",{});var hVt=s(lEe);Phr=r(hVt,"layoutlmv2"),hVt.forEach(t),Bhr=r(GXe," \u2014 "),SJ=n(GXe,"A",{href:!0});var uVt=s(SJ);Ihr=r(uVt,"LayoutLMv2ForTokenClassification"),uVt.forEach(t),Nhr=r(GXe," (LayoutLMv2 model)"),GXe.forEach(t),qhr=i(Y),UM=n(Y,"LI",{});var OXe=s(UM);iEe=n(OXe,"STRONG",{});var pVt=s(iEe);jhr=r(pVt,"layoutlmv3"),pVt.forEach(t),Dhr=r(OXe," \u2014 "),RJ=n(OXe,"A",{href:!0});var _Vt=s(RJ);Ghr=r(_Vt,"LayoutLMv3ForTokenClassification"),_Vt.forEach(t),Ohr=r(OXe," (LayoutLMv3 model)"),OXe.forEach(t),Vhr=i(Y),HM=n(Y,"LI",{});var VXe=s(HM);dEe=n(VXe,"STRONG",{});var bVt=s(dEe);Xhr=r(bVt,"longformer"),bVt.forEach(t),zhr=r(VXe," \u2014 "),PJ=n(VXe,"A",{href:!0});var vVt=s(PJ);Qhr=r(vVt,"LongformerForTokenClassification"),vVt.forEach(t),Whr=r(VXe," (Longformer model)"),VXe.forEach(t),Uhr=i(Y),JM=n(Y,"LI",{});var XXe=s(JM);mEe=n(XXe,"STRONG",{});var FVt=s(mEe);Hhr=r(FVt,"luke"),FVt.forEach(t),Jhr=r(XXe," \u2014 "),BJ=n(XXe,"A",{href:!0});var TVt=s(BJ);Yhr=r(TVt,"LukeForTokenClassification"),TVt.forEach(t),Khr=r(XXe," (LUKE model)"),XXe.forEach(t),Zhr=i(Y),YM=n(Y,"LI",{});var zXe=s(YM);cEe=n(zXe,"STRONG",{});var MVt=s(cEe);eur=r(MVt,"markuplm"),MVt.forEach(t),our=r(zXe," \u2014 "),IJ=n(zXe,"A",{href:!0});var EVt=s(IJ);rur=r(EVt,"MarkupLMForTokenClassification"),EVt.forEach(t),tur=r(zXe," (MarkupLM model)"),zXe.forEach(t),aur=i(Y),KM=n(Y,"LI",{});var QXe=s(KM);fEe=n(QXe,"STRONG",{});var CVt=s(fEe);nur=r(CVt,"megatron-bert"),CVt.forEach(t),sur=r(QXe," \u2014 "),NJ=n(QXe,"A",{href:!0});var wVt=s(NJ);lur=r(wVt,"MegatronBertForTokenClassification"),wVt.forEach(t),iur=r(QXe," (Megatron-BERT model)"),QXe.forEach(t),dur=i(Y),ZM=n(Y,"LI",{});var WXe=s(ZM);gEe=n(WXe,"STRONG",{});var AVt=s(gEe);mur=r(AVt,"mobilebert"),AVt.forEach(t),cur=r(WXe," \u2014 "),qJ=n(WXe,"A",{href:!0});var LVt=s(qJ);fur=r(LVt,"MobileBertForTokenClassification"),LVt.forEach(t),gur=r(WXe," (MobileBERT model)"),WXe.forEach(t),hur=i(Y),eE=n(Y,"LI",{});var UXe=s(eE);hEe=n(UXe,"STRONG",{});var yVt=s(hEe);uur=r(yVt,"mpnet"),yVt.forEach(t),pur=r(UXe," \u2014 "),jJ=n(UXe,"A",{href:!0});var xVt=s(jJ);_ur=r(xVt,"MPNetForTokenClassification"),xVt.forEach(t),bur=r(UXe," (MPNet model)"),UXe.forEach(t),vur=i(Y),oE=n(Y,"LI",{});var HXe=s(oE);uEe=n(HXe,"STRONG",{});var $Vt=s(uEe);Fur=r($Vt,"nezha"),$Vt.forEach(t),Tur=r(HXe," \u2014 "),DJ=n(HXe,"A",{href:!0});var kVt=s(DJ);Mur=r(kVt,"NezhaForTokenClassification"),kVt.forEach(t),Eur=r(HXe," (Nezha model)"),HXe.forEach(t),Cur=i(Y),rE=n(Y,"LI",{});var JXe=s(rE);pEe=n(JXe,"STRONG",{});var SVt=s(pEe);wur=r(SVt,"nystromformer"),SVt.forEach(t),Aur=r(JXe," \u2014 "),GJ=n(JXe,"A",{href:!0});var RVt=s(GJ);Lur=r(RVt,"NystromformerForTokenClassification"),RVt.forEach(t),yur=r(JXe," (Nystr\xF6mformer model)"),JXe.forEach(t),xur=i(Y),tE=n(Y,"LI",{});var YXe=s(tE);_Ee=n(YXe,"STRONG",{});var PVt=s(_Ee);$ur=r(PVt,"qdqbert"),PVt.forEach(t),kur=r(YXe," \u2014 "),OJ=n(YXe,"A",{href:!0});var BVt=s(OJ);Sur=r(BVt,"QDQBertForTokenClassification"),BVt.forEach(t),Rur=r(YXe," (QDQBert model)"),YXe.forEach(t),Pur=i(Y),aE=n(Y,"LI",{});var KXe=s(aE);bEe=n(KXe,"STRONG",{});var IVt=s(bEe);Bur=r(IVt,"rembert"),IVt.forEach(t),Iur=r(KXe," \u2014 "),VJ=n(KXe,"A",{href:!0});var NVt=s(VJ);Nur=r(NVt,"RemBertForTokenClassification"),NVt.forEach(t),qur=r(KXe," (RemBERT model)"),KXe.forEach(t),jur=i(Y),nE=n(Y,"LI",{});var ZXe=s(nE);vEe=n(ZXe,"STRONG",{});var qVt=s(vEe);Dur=r(qVt,"roberta"),qVt.forEach(t),Gur=r(ZXe," \u2014 "),XJ=n(ZXe,"A",{href:!0});var jVt=s(XJ);Our=r(jVt,"RobertaForTokenClassification"),jVt.forEach(t),Vur=r(ZXe," (RoBERTa model)"),ZXe.forEach(t),Xur=i(Y),sE=n(Y,"LI",{});var eze=s(sE);FEe=n(eze,"STRONG",{});var DVt=s(FEe);zur=r(DVt,"roformer"),DVt.forEach(t),Qur=r(eze," \u2014 "),zJ=n(eze,"A",{href:!0});var GVt=s(zJ);Wur=r(GVt,"RoFormerForTokenClassification"),GVt.forEach(t),Uur=r(eze," (RoFormer model)"),eze.forEach(t),Hur=i(Y),lE=n(Y,"LI",{});var oze=s(lE);TEe=n(oze,"STRONG",{});var OVt=s(TEe);Jur=r(OVt,"squeezebert"),OVt.forEach(t),Yur=r(oze," \u2014 "),QJ=n(oze,"A",{href:!0});var VVt=s(QJ);Kur=r(VVt,"SqueezeBertForTokenClassification"),VVt.forEach(t),Zur=r(oze," (SqueezeBERT model)"),oze.forEach(t),epr=i(Y),iE=n(Y,"LI",{});var rze=s(iE);MEe=n(rze,"STRONG",{});var XVt=s(MEe);opr=r(XVt,"xlm"),XVt.forEach(t),rpr=r(rze," \u2014 "),WJ=n(rze,"A",{href:!0});var zVt=s(WJ);tpr=r(zVt,"XLMForTokenClassification"),zVt.forEach(t),apr=r(rze," (XLM model)"),rze.forEach(t),npr=i(Y),dE=n(Y,"LI",{});var tze=s(dE);EEe=n(tze,"STRONG",{});var QVt=s(EEe);spr=r(QVt,"xlm-roberta"),QVt.forEach(t),lpr=r(tze," \u2014 "),UJ=n(tze,"A",{href:!0});var WVt=s(UJ);ipr=r(WVt,"XLMRobertaForTokenClassification"),WVt.forEach(t),dpr=r(tze," (XLM-RoBERTa model)"),tze.forEach(t),mpr=i(Y),mE=n(Y,"LI",{});var aze=s(mE);CEe=n(aze,"STRONG",{});var UVt=s(CEe);cpr=r(UVt,"xlm-roberta-xl"),UVt.forEach(t),fpr=r(aze," \u2014 "),HJ=n(aze,"A",{href:!0});var HVt=s(HJ);gpr=r(HVt,"XLMRobertaXLForTokenClassification"),HVt.forEach(t),hpr=r(aze," (XLM-RoBERTa-XL model)"),aze.forEach(t),upr=i(Y),cE=n(Y,"LI",{});var nze=s(cE);wEe=n(nze,"STRONG",{});var JVt=s(wEe);ppr=r(JVt,"xlnet"),JVt.forEach(t),_pr=r(nze," \u2014 "),JJ=n(nze,"A",{href:!0});var YVt=s(JJ);bpr=r(YVt,"XLNetForTokenClassification"),YVt.forEach(t),vpr=r(nze," (XLNet model)"),nze.forEach(t),Fpr=i(Y),fE=n(Y,"LI",{});var sze=s(fE);AEe=n(sze,"STRONG",{});var KVt=s(AEe);Tpr=r(KVt,"yoso"),KVt.forEach(t),Mpr=r(sze," \u2014 "),YJ=n(sze,"A",{href:!0});var ZVt=s(YJ);Epr=r(ZVt,"YosoForTokenClassification"),ZVt.forEach(t),Cpr=r(sze," (YOSO model)"),sze.forEach(t),Y.forEach(t),wpr=i(ya),gE=n(ya,"P",{});var lze=s(gE);Apr=r(lze,"The model is set in evaluation mode by default using "),LEe=n(lze,"CODE",{});var eXt=s(LEe);Lpr=r(eXt,"model.eval()"),eXt.forEach(t),ypr=r(lze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yEe=n(lze,"CODE",{});var oXt=s(yEe);xpr=r(oXt,"model.train()"),oXt.forEach(t),lze.forEach(t),$pr=i(ya),T(hE.$$.fragment,ya),ya.forEach(t),Pl.forEach(t),_eo=i(c),Xd=n(c,"H2",{class:!0});var kro=s(Xd);uE=n(kro,"A",{id:!0,class:!0,href:!0});var rXt=s(uE);xEe=n(rXt,"SPAN",{});var tXt=s(xEe);T(_$.$$.fragment,tXt),tXt.forEach(t),rXt.forEach(t),kpr=i(kro),$Ee=n(kro,"SPAN",{});var aXt=s($Ee);Spr=r(aXt,"AutoModelForQuestionAnswering"),aXt.forEach(t),kro.forEach(t),beo=i(c),Vo=n(c,"DIV",{class:!0});var Bl=s(Vo);T(b$.$$.fragment,Bl),Rpr=i(Bl),zd=n(Bl,"P",{});var pie=s(zd);Ppr=r(pie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KJ=n(pie,"A",{href:!0});var nXt=s(KJ);Bpr=r(nXt,"from_pretrained()"),nXt.forEach(t),Ipr=r(pie," class method or the "),ZJ=n(pie,"A",{href:!0});var sXt=s(ZJ);Npr=r(sXt,"from_config()"),sXt.forEach(t),qpr=r(pie,` class
method.`),pie.forEach(t),jpr=i(Bl),v$=n(Bl,"P",{});var Sro=s(v$);Dpr=r(Sro,"This class cannot be instantiated directly using "),kEe=n(Sro,"CODE",{});var lXt=s(kEe);Gpr=r(lXt,"__init__()"),lXt.forEach(t),Opr=r(Sro," (throws an error)."),Sro.forEach(t),Vpr=i(Bl),At=n(Bl,"DIV",{class:!0});var f8=s(At);T(F$.$$.fragment,f8),Xpr=i(f8),SEe=n(f8,"P",{});var iXt=s(SEe);zpr=r(iXt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),iXt.forEach(t),Qpr=i(f8),Qd=n(f8,"P",{});var _ie=s(Qd);Wpr=r(_ie,`Note:
Loading a model from its configuration file does `),REe=n(_ie,"STRONG",{});var dXt=s(REe);Upr=r(dXt,"not"),dXt.forEach(t),Hpr=r(_ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),eY=n(_ie,"A",{href:!0});var mXt=s(eY);Jpr=r(mXt,"from_pretrained()"),mXt.forEach(t),Ypr=r(_ie," to load the model weights."),_ie.forEach(t),Kpr=i(f8),T(pE.$$.fragment,f8),f8.forEach(t),Zpr=i(Bl),io=n(Bl,"DIV",{class:!0});var xa=s(io);T(T$.$$.fragment,xa),e_r=i(xa),PEe=n(xa,"P",{});var cXt=s(PEe);o_r=r(cXt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cXt.forEach(t),r_r=i(xa),nn=n(xa,"P",{});var g8=s(nn);t_r=r(g8,"The model class to instantiate is selected based on the "),BEe=n(g8,"CODE",{});var fXt=s(BEe);a_r=r(fXt,"model_type"),fXt.forEach(t),n_r=r(g8,` property of the config object (either
passed as an argument or loaded from `),IEe=n(g8,"CODE",{});var gXt=s(IEe);s_r=r(gXt,"pretrained_model_name_or_path"),gXt.forEach(t),l_r=r(g8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NEe=n(g8,"CODE",{});var hXt=s(NEe);i_r=r(hXt,"pretrained_model_name_or_path"),hXt.forEach(t),d_r=r(g8,":"),g8.forEach(t),m_r=i(xa),V=n(xa,"UL",{});var X=s(V);_E=n(X,"LI",{});var ize=s(_E);qEe=n(ize,"STRONG",{});var uXt=s(qEe);c_r=r(uXt,"albert"),uXt.forEach(t),f_r=r(ize," \u2014 "),oY=n(ize,"A",{href:!0});var pXt=s(oY);g_r=r(pXt,"AlbertForQuestionAnswering"),pXt.forEach(t),h_r=r(ize," (ALBERT model)"),ize.forEach(t),u_r=i(X),bE=n(X,"LI",{});var dze=s(bE);jEe=n(dze,"STRONG",{});var _Xt=s(jEe);p_r=r(_Xt,"bart"),_Xt.forEach(t),__r=r(dze," \u2014 "),rY=n(dze,"A",{href:!0});var bXt=s(rY);b_r=r(bXt,"BartForQuestionAnswering"),bXt.forEach(t),v_r=r(dze," (BART model)"),dze.forEach(t),F_r=i(X),vE=n(X,"LI",{});var mze=s(vE);DEe=n(mze,"STRONG",{});var vXt=s(DEe);T_r=r(vXt,"bert"),vXt.forEach(t),M_r=r(mze," \u2014 "),tY=n(mze,"A",{href:!0});var FXt=s(tY);E_r=r(FXt,"BertForQuestionAnswering"),FXt.forEach(t),C_r=r(mze," (BERT model)"),mze.forEach(t),w_r=i(X),FE=n(X,"LI",{});var cze=s(FE);GEe=n(cze,"STRONG",{});var TXt=s(GEe);A_r=r(TXt,"big_bird"),TXt.forEach(t),L_r=r(cze," \u2014 "),aY=n(cze,"A",{href:!0});var MXt=s(aY);y_r=r(MXt,"BigBirdForQuestionAnswering"),MXt.forEach(t),x_r=r(cze," (BigBird model)"),cze.forEach(t),$_r=i(X),TE=n(X,"LI",{});var fze=s(TE);OEe=n(fze,"STRONG",{});var EXt=s(OEe);k_r=r(EXt,"bigbird_pegasus"),EXt.forEach(t),S_r=r(fze," \u2014 "),nY=n(fze,"A",{href:!0});var CXt=s(nY);R_r=r(CXt,"BigBirdPegasusForQuestionAnswering"),CXt.forEach(t),P_r=r(fze," (BigBird-Pegasus model)"),fze.forEach(t),B_r=i(X),ME=n(X,"LI",{});var gze=s(ME);VEe=n(gze,"STRONG",{});var wXt=s(VEe);I_r=r(wXt,"camembert"),wXt.forEach(t),N_r=r(gze," \u2014 "),sY=n(gze,"A",{href:!0});var AXt=s(sY);q_r=r(AXt,"CamembertForQuestionAnswering"),AXt.forEach(t),j_r=r(gze," (CamemBERT model)"),gze.forEach(t),D_r=i(X),EE=n(X,"LI",{});var hze=s(EE);XEe=n(hze,"STRONG",{});var LXt=s(XEe);G_r=r(LXt,"canine"),LXt.forEach(t),O_r=r(hze," \u2014 "),lY=n(hze,"A",{href:!0});var yXt=s(lY);V_r=r(yXt,"CanineForQuestionAnswering"),yXt.forEach(t),X_r=r(hze," (CANINE model)"),hze.forEach(t),z_r=i(X),CE=n(X,"LI",{});var uze=s(CE);zEe=n(uze,"STRONG",{});var xXt=s(zEe);Q_r=r(xXt,"convbert"),xXt.forEach(t),W_r=r(uze," \u2014 "),iY=n(uze,"A",{href:!0});var $Xt=s(iY);U_r=r($Xt,"ConvBertForQuestionAnswering"),$Xt.forEach(t),H_r=r(uze," (ConvBERT model)"),uze.forEach(t),J_r=i(X),wE=n(X,"LI",{});var pze=s(wE);QEe=n(pze,"STRONG",{});var kXt=s(QEe);Y_r=r(kXt,"data2vec-text"),kXt.forEach(t),K_r=r(pze," \u2014 "),dY=n(pze,"A",{href:!0});var SXt=s(dY);Z_r=r(SXt,"Data2VecTextForQuestionAnswering"),SXt.forEach(t),e2r=r(pze," (Data2VecText model)"),pze.forEach(t),o2r=i(X),AE=n(X,"LI",{});var _ze=s(AE);WEe=n(_ze,"STRONG",{});var RXt=s(WEe);r2r=r(RXt,"deberta"),RXt.forEach(t),t2r=r(_ze," \u2014 "),mY=n(_ze,"A",{href:!0});var PXt=s(mY);a2r=r(PXt,"DebertaForQuestionAnswering"),PXt.forEach(t),n2r=r(_ze," (DeBERTa model)"),_ze.forEach(t),s2r=i(X),LE=n(X,"LI",{});var bze=s(LE);UEe=n(bze,"STRONG",{});var BXt=s(UEe);l2r=r(BXt,"deberta-v2"),BXt.forEach(t),i2r=r(bze," \u2014 "),cY=n(bze,"A",{href:!0});var IXt=s(cY);d2r=r(IXt,"DebertaV2ForQuestionAnswering"),IXt.forEach(t),m2r=r(bze," (DeBERTa-v2 model)"),bze.forEach(t),c2r=i(X),yE=n(X,"LI",{});var vze=s(yE);HEe=n(vze,"STRONG",{});var NXt=s(HEe);f2r=r(NXt,"distilbert"),NXt.forEach(t),g2r=r(vze," \u2014 "),fY=n(vze,"A",{href:!0});var qXt=s(fY);h2r=r(qXt,"DistilBertForQuestionAnswering"),qXt.forEach(t),u2r=r(vze," (DistilBERT model)"),vze.forEach(t),p2r=i(X),xE=n(X,"LI",{});var Fze=s(xE);JEe=n(Fze,"STRONG",{});var jXt=s(JEe);_2r=r(jXt,"electra"),jXt.forEach(t),b2r=r(Fze," \u2014 "),gY=n(Fze,"A",{href:!0});var DXt=s(gY);v2r=r(DXt,"ElectraForQuestionAnswering"),DXt.forEach(t),F2r=r(Fze," (ELECTRA model)"),Fze.forEach(t),T2r=i(X),$E=n(X,"LI",{});var Tze=s($E);YEe=n(Tze,"STRONG",{});var GXt=s(YEe);M2r=r(GXt,"ernie"),GXt.forEach(t),E2r=r(Tze," \u2014 "),hY=n(Tze,"A",{href:!0});var OXt=s(hY);C2r=r(OXt,"ErnieForQuestionAnswering"),OXt.forEach(t),w2r=r(Tze," (ERNIE model)"),Tze.forEach(t),A2r=i(X),kE=n(X,"LI",{});var Mze=s(kE);KEe=n(Mze,"STRONG",{});var VXt=s(KEe);L2r=r(VXt,"flaubert"),VXt.forEach(t),y2r=r(Mze," \u2014 "),uY=n(Mze,"A",{href:!0});var XXt=s(uY);x2r=r(XXt,"FlaubertForQuestionAnsweringSimple"),XXt.forEach(t),$2r=r(Mze," (FlauBERT model)"),Mze.forEach(t),k2r=i(X),SE=n(X,"LI",{});var Eze=s(SE);ZEe=n(Eze,"STRONG",{});var zXt=s(ZEe);S2r=r(zXt,"fnet"),zXt.forEach(t),R2r=r(Eze," \u2014 "),pY=n(Eze,"A",{href:!0});var QXt=s(pY);P2r=r(QXt,"FNetForQuestionAnswering"),QXt.forEach(t),B2r=r(Eze," (FNet model)"),Eze.forEach(t),I2r=i(X),RE=n(X,"LI",{});var Cze=s(RE);e4e=n(Cze,"STRONG",{});var WXt=s(e4e);N2r=r(WXt,"funnel"),WXt.forEach(t),q2r=r(Cze," \u2014 "),_Y=n(Cze,"A",{href:!0});var UXt=s(_Y);j2r=r(UXt,"FunnelForQuestionAnswering"),UXt.forEach(t),D2r=r(Cze," (Funnel Transformer model)"),Cze.forEach(t),G2r=i(X),PE=n(X,"LI",{});var wze=s(PE);o4e=n(wze,"STRONG",{});var HXt=s(o4e);O2r=r(HXt,"gptj"),HXt.forEach(t),V2r=r(wze," \u2014 "),bY=n(wze,"A",{href:!0});var JXt=s(bY);X2r=r(JXt,"GPTJForQuestionAnswering"),JXt.forEach(t),z2r=r(wze," (GPT-J model)"),wze.forEach(t),Q2r=i(X),BE=n(X,"LI",{});var Aze=s(BE);r4e=n(Aze,"STRONG",{});var YXt=s(r4e);W2r=r(YXt,"ibert"),YXt.forEach(t),U2r=r(Aze," \u2014 "),vY=n(Aze,"A",{href:!0});var KXt=s(vY);H2r=r(KXt,"IBertForQuestionAnswering"),KXt.forEach(t),J2r=r(Aze," (I-BERT model)"),Aze.forEach(t),Y2r=i(X),IE=n(X,"LI",{});var Lze=s(IE);t4e=n(Lze,"STRONG",{});var ZXt=s(t4e);K2r=r(ZXt,"layoutlmv2"),ZXt.forEach(t),Z2r=r(Lze," \u2014 "),FY=n(Lze,"A",{href:!0});var ezt=s(FY);e1r=r(ezt,"LayoutLMv2ForQuestionAnswering"),ezt.forEach(t),o1r=r(Lze," (LayoutLMv2 model)"),Lze.forEach(t),r1r=i(X),NE=n(X,"LI",{});var yze=s(NE);a4e=n(yze,"STRONG",{});var ozt=s(a4e);t1r=r(ozt,"layoutlmv3"),ozt.forEach(t),a1r=r(yze," \u2014 "),TY=n(yze,"A",{href:!0});var rzt=s(TY);n1r=r(rzt,"LayoutLMv3ForQuestionAnswering"),rzt.forEach(t),s1r=r(yze," (LayoutLMv3 model)"),yze.forEach(t),l1r=i(X),qE=n(X,"LI",{});var xze=s(qE);n4e=n(xze,"STRONG",{});var tzt=s(n4e);i1r=r(tzt,"led"),tzt.forEach(t),d1r=r(xze," \u2014 "),MY=n(xze,"A",{href:!0});var azt=s(MY);m1r=r(azt,"LEDForQuestionAnswering"),azt.forEach(t),c1r=r(xze," (LED model)"),xze.forEach(t),f1r=i(X),jE=n(X,"LI",{});var $ze=s(jE);s4e=n($ze,"STRONG",{});var nzt=s(s4e);g1r=r(nzt,"longformer"),nzt.forEach(t),h1r=r($ze," \u2014 "),EY=n($ze,"A",{href:!0});var szt=s(EY);u1r=r(szt,"LongformerForQuestionAnswering"),szt.forEach(t),p1r=r($ze," (Longformer model)"),$ze.forEach(t),_1r=i(X),DE=n(X,"LI",{});var kze=s(DE);l4e=n(kze,"STRONG",{});var lzt=s(l4e);b1r=r(lzt,"luke"),lzt.forEach(t),v1r=r(kze," \u2014 "),CY=n(kze,"A",{href:!0});var izt=s(CY);F1r=r(izt,"LukeForQuestionAnswering"),izt.forEach(t),T1r=r(kze," (LUKE model)"),kze.forEach(t),M1r=i(X),GE=n(X,"LI",{});var Sze=s(GE);i4e=n(Sze,"STRONG",{});var dzt=s(i4e);E1r=r(dzt,"lxmert"),dzt.forEach(t),C1r=r(Sze," \u2014 "),wY=n(Sze,"A",{href:!0});var mzt=s(wY);w1r=r(mzt,"LxmertForQuestionAnswering"),mzt.forEach(t),A1r=r(Sze," (LXMERT model)"),Sze.forEach(t),L1r=i(X),OE=n(X,"LI",{});var Rze=s(OE);d4e=n(Rze,"STRONG",{});var czt=s(d4e);y1r=r(czt,"markuplm"),czt.forEach(t),x1r=r(Rze," \u2014 "),AY=n(Rze,"A",{href:!0});var fzt=s(AY);$1r=r(fzt,"MarkupLMForQuestionAnswering"),fzt.forEach(t),k1r=r(Rze," (MarkupLM model)"),Rze.forEach(t),S1r=i(X),VE=n(X,"LI",{});var Pze=s(VE);m4e=n(Pze,"STRONG",{});var gzt=s(m4e);R1r=r(gzt,"mbart"),gzt.forEach(t),P1r=r(Pze," \u2014 "),LY=n(Pze,"A",{href:!0});var hzt=s(LY);B1r=r(hzt,"MBartForQuestionAnswering"),hzt.forEach(t),I1r=r(Pze," (mBART model)"),Pze.forEach(t),N1r=i(X),XE=n(X,"LI",{});var Bze=s(XE);c4e=n(Bze,"STRONG",{});var uzt=s(c4e);q1r=r(uzt,"megatron-bert"),uzt.forEach(t),j1r=r(Bze," \u2014 "),yY=n(Bze,"A",{href:!0});var pzt=s(yY);D1r=r(pzt,"MegatronBertForQuestionAnswering"),pzt.forEach(t),G1r=r(Bze," (Megatron-BERT model)"),Bze.forEach(t),O1r=i(X),zE=n(X,"LI",{});var Ize=s(zE);f4e=n(Ize,"STRONG",{});var _zt=s(f4e);V1r=r(_zt,"mobilebert"),_zt.forEach(t),X1r=r(Ize," \u2014 "),xY=n(Ize,"A",{href:!0});var bzt=s(xY);z1r=r(bzt,"MobileBertForQuestionAnswering"),bzt.forEach(t),Q1r=r(Ize," (MobileBERT model)"),Ize.forEach(t),W1r=i(X),QE=n(X,"LI",{});var Nze=s(QE);g4e=n(Nze,"STRONG",{});var vzt=s(g4e);U1r=r(vzt,"mpnet"),vzt.forEach(t),H1r=r(Nze," \u2014 "),$Y=n(Nze,"A",{href:!0});var Fzt=s($Y);J1r=r(Fzt,"MPNetForQuestionAnswering"),Fzt.forEach(t),Y1r=r(Nze," (MPNet model)"),Nze.forEach(t),K1r=i(X),WE=n(X,"LI",{});var qze=s(WE);h4e=n(qze,"STRONG",{});var Tzt=s(h4e);Z1r=r(Tzt,"mvp"),Tzt.forEach(t),ebr=r(qze," \u2014 "),kY=n(qze,"A",{href:!0});var Mzt=s(kY);obr=r(Mzt,"MvpForQuestionAnswering"),Mzt.forEach(t),rbr=r(qze," (MVP model)"),qze.forEach(t),tbr=i(X),UE=n(X,"LI",{});var jze=s(UE);u4e=n(jze,"STRONG",{});var Ezt=s(u4e);abr=r(Ezt,"nezha"),Ezt.forEach(t),nbr=r(jze," \u2014 "),SY=n(jze,"A",{href:!0});var Czt=s(SY);sbr=r(Czt,"NezhaForQuestionAnswering"),Czt.forEach(t),lbr=r(jze," (Nezha model)"),jze.forEach(t),ibr=i(X),HE=n(X,"LI",{});var Dze=s(HE);p4e=n(Dze,"STRONG",{});var wzt=s(p4e);dbr=r(wzt,"nystromformer"),wzt.forEach(t),mbr=r(Dze," \u2014 "),RY=n(Dze,"A",{href:!0});var Azt=s(RY);cbr=r(Azt,"NystromformerForQuestionAnswering"),Azt.forEach(t),fbr=r(Dze," (Nystr\xF6mformer model)"),Dze.forEach(t),gbr=i(X),JE=n(X,"LI",{});var Gze=s(JE);_4e=n(Gze,"STRONG",{});var Lzt=s(_4e);hbr=r(Lzt,"qdqbert"),Lzt.forEach(t),ubr=r(Gze," \u2014 "),PY=n(Gze,"A",{href:!0});var yzt=s(PY);pbr=r(yzt,"QDQBertForQuestionAnswering"),yzt.forEach(t),_br=r(Gze," (QDQBert model)"),Gze.forEach(t),bbr=i(X),YE=n(X,"LI",{});var Oze=s(YE);b4e=n(Oze,"STRONG",{});var xzt=s(b4e);vbr=r(xzt,"reformer"),xzt.forEach(t),Fbr=r(Oze," \u2014 "),BY=n(Oze,"A",{href:!0});var $zt=s(BY);Tbr=r($zt,"ReformerForQuestionAnswering"),$zt.forEach(t),Mbr=r(Oze," (Reformer model)"),Oze.forEach(t),Ebr=i(X),KE=n(X,"LI",{});var Vze=s(KE);v4e=n(Vze,"STRONG",{});var kzt=s(v4e);Cbr=r(kzt,"rembert"),kzt.forEach(t),wbr=r(Vze," \u2014 "),IY=n(Vze,"A",{href:!0});var Szt=s(IY);Abr=r(Szt,"RemBertForQuestionAnswering"),Szt.forEach(t),Lbr=r(Vze," (RemBERT model)"),Vze.forEach(t),ybr=i(X),ZE=n(X,"LI",{});var Xze=s(ZE);F4e=n(Xze,"STRONG",{});var Rzt=s(F4e);xbr=r(Rzt,"roberta"),Rzt.forEach(t),$br=r(Xze," \u2014 "),NY=n(Xze,"A",{href:!0});var Pzt=s(NY);kbr=r(Pzt,"RobertaForQuestionAnswering"),Pzt.forEach(t),Sbr=r(Xze," (RoBERTa model)"),Xze.forEach(t),Rbr=i(X),e4=n(X,"LI",{});var zze=s(e4);T4e=n(zze,"STRONG",{});var Bzt=s(T4e);Pbr=r(Bzt,"roformer"),Bzt.forEach(t),Bbr=r(zze," \u2014 "),qY=n(zze,"A",{href:!0});var Izt=s(qY);Ibr=r(Izt,"RoFormerForQuestionAnswering"),Izt.forEach(t),Nbr=r(zze," (RoFormer model)"),zze.forEach(t),qbr=i(X),o4=n(X,"LI",{});var Qze=s(o4);M4e=n(Qze,"STRONG",{});var Nzt=s(M4e);jbr=r(Nzt,"splinter"),Nzt.forEach(t),Dbr=r(Qze," \u2014 "),jY=n(Qze,"A",{href:!0});var qzt=s(jY);Gbr=r(qzt,"SplinterForQuestionAnswering"),qzt.forEach(t),Obr=r(Qze," (Splinter model)"),Qze.forEach(t),Vbr=i(X),r4=n(X,"LI",{});var Wze=s(r4);E4e=n(Wze,"STRONG",{});var jzt=s(E4e);Xbr=r(jzt,"squeezebert"),jzt.forEach(t),zbr=r(Wze," \u2014 "),DY=n(Wze,"A",{href:!0});var Dzt=s(DY);Qbr=r(Dzt,"SqueezeBertForQuestionAnswering"),Dzt.forEach(t),Wbr=r(Wze," (SqueezeBERT model)"),Wze.forEach(t),Ubr=i(X),t4=n(X,"LI",{});var Uze=s(t4);C4e=n(Uze,"STRONG",{});var Gzt=s(C4e);Hbr=r(Gzt,"xlm"),Gzt.forEach(t),Jbr=r(Uze," \u2014 "),GY=n(Uze,"A",{href:!0});var Ozt=s(GY);Ybr=r(Ozt,"XLMForQuestionAnsweringSimple"),Ozt.forEach(t),Kbr=r(Uze," (XLM model)"),Uze.forEach(t),Zbr=i(X),a4=n(X,"LI",{});var Hze=s(a4);w4e=n(Hze,"STRONG",{});var Vzt=s(w4e);evr=r(Vzt,"xlm-roberta"),Vzt.forEach(t),ovr=r(Hze," \u2014 "),OY=n(Hze,"A",{href:!0});var Xzt=s(OY);rvr=r(Xzt,"XLMRobertaForQuestionAnswering"),Xzt.forEach(t),tvr=r(Hze," (XLM-RoBERTa model)"),Hze.forEach(t),avr=i(X),n4=n(X,"LI",{});var Jze=s(n4);A4e=n(Jze,"STRONG",{});var zzt=s(A4e);nvr=r(zzt,"xlm-roberta-xl"),zzt.forEach(t),svr=r(Jze," \u2014 "),VY=n(Jze,"A",{href:!0});var Qzt=s(VY);lvr=r(Qzt,"XLMRobertaXLForQuestionAnswering"),Qzt.forEach(t),ivr=r(Jze," (XLM-RoBERTa-XL model)"),Jze.forEach(t),dvr=i(X),s4=n(X,"LI",{});var Yze=s(s4);L4e=n(Yze,"STRONG",{});var Wzt=s(L4e);mvr=r(Wzt,"xlnet"),Wzt.forEach(t),cvr=r(Yze," \u2014 "),XY=n(Yze,"A",{href:!0});var Uzt=s(XY);fvr=r(Uzt,"XLNetForQuestionAnsweringSimple"),Uzt.forEach(t),gvr=r(Yze," (XLNet model)"),Yze.forEach(t),hvr=i(X),l4=n(X,"LI",{});var Kze=s(l4);y4e=n(Kze,"STRONG",{});var Hzt=s(y4e);uvr=r(Hzt,"yoso"),Hzt.forEach(t),pvr=r(Kze," \u2014 "),zY=n(Kze,"A",{href:!0});var Jzt=s(zY);_vr=r(Jzt,"YosoForQuestionAnswering"),Jzt.forEach(t),bvr=r(Kze," (YOSO model)"),Kze.forEach(t),X.forEach(t),vvr=i(xa),i4=n(xa,"P",{});var Zze=s(i4);Fvr=r(Zze,"The model is set in evaluation mode by default using "),x4e=n(Zze,"CODE",{});var Yzt=s(x4e);Tvr=r(Yzt,"model.eval()"),Yzt.forEach(t),Mvr=r(Zze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$4e=n(Zze,"CODE",{});var Kzt=s($4e);Evr=r(Kzt,"model.train()"),Kzt.forEach(t),Zze.forEach(t),Cvr=i(xa),T(d4.$$.fragment,xa),xa.forEach(t),Bl.forEach(t),veo=i(c),Wd=n(c,"H2",{class:!0});var Rro=s(Wd);m4=n(Rro,"A",{id:!0,class:!0,href:!0});var Zzt=s(m4);k4e=n(Zzt,"SPAN",{});var eQt=s(k4e);T(M$.$$.fragment,eQt),eQt.forEach(t),Zzt.forEach(t),wvr=i(Rro),S4e=n(Rro,"SPAN",{});var oQt=s(S4e);Avr=r(oQt,"AutoModelForTableQuestionAnswering"),oQt.forEach(t),Rro.forEach(t),Feo=i(c),Xo=n(c,"DIV",{class:!0});var Il=s(Xo);T(E$.$$.fragment,Il),Lvr=i(Il),Ud=n(Il,"P",{});var bie=s(Ud);yvr=r(bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),QY=n(bie,"A",{href:!0});var rQt=s(QY);xvr=r(rQt,"from_pretrained()"),rQt.forEach(t),$vr=r(bie," class method or the "),WY=n(bie,"A",{href:!0});var tQt=s(WY);kvr=r(tQt,"from_config()"),tQt.forEach(t),Svr=r(bie,` class
method.`),bie.forEach(t),Rvr=i(Il),C$=n(Il,"P",{});var Pro=s(C$);Pvr=r(Pro,"This class cannot be instantiated directly using "),R4e=n(Pro,"CODE",{});var aQt=s(R4e);Bvr=r(aQt,"__init__()"),aQt.forEach(t),Ivr=r(Pro," (throws an error)."),Pro.forEach(t),Nvr=i(Il),Lt=n(Il,"DIV",{class:!0});var h8=s(Lt);T(w$.$$.fragment,h8),qvr=i(h8),P4e=n(h8,"P",{});var nQt=s(P4e);jvr=r(nQt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),nQt.forEach(t),Dvr=i(h8),Hd=n(h8,"P",{});var vie=s(Hd);Gvr=r(vie,`Note:
Loading a model from its configuration file does `),B4e=n(vie,"STRONG",{});var sQt=s(B4e);Ovr=r(sQt,"not"),sQt.forEach(t),Vvr=r(vie,` load the model weights. It only affects the
model\u2019s configuration. Use `),UY=n(vie,"A",{href:!0});var lQt=s(UY);Xvr=r(lQt,"from_pretrained()"),lQt.forEach(t),zvr=r(vie," to load the model weights."),vie.forEach(t),Qvr=i(h8),T(c4.$$.fragment,h8),h8.forEach(t),Wvr=i(Il),mo=n(Il,"DIV",{class:!0});var $a=s(mo);T(A$.$$.fragment,$a),Uvr=i($a),I4e=n($a,"P",{});var iQt=s(I4e);Hvr=r(iQt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),iQt.forEach(t),Jvr=i($a),sn=n($a,"P",{});var u8=s(sn);Yvr=r(u8,"The model class to instantiate is selected based on the "),N4e=n(u8,"CODE",{});var dQt=s(N4e);Kvr=r(dQt,"model_type"),dQt.forEach(t),Zvr=r(u8,` property of the config object (either
passed as an argument or loaded from `),q4e=n(u8,"CODE",{});var mQt=s(q4e);eFr=r(mQt,"pretrained_model_name_or_path"),mQt.forEach(t),oFr=r(u8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j4e=n(u8,"CODE",{});var cQt=s(j4e);rFr=r(cQt,"pretrained_model_name_or_path"),cQt.forEach(t),tFr=r(u8,":"),u8.forEach(t),aFr=i($a),D4e=n($a,"UL",{});var fQt=s(D4e);f4=n(fQt,"LI",{});var eQe=s(f4);G4e=n(eQe,"STRONG",{});var gQt=s(G4e);nFr=r(gQt,"tapas"),gQt.forEach(t),sFr=r(eQe," \u2014 "),HY=n(eQe,"A",{href:!0});var hQt=s(HY);lFr=r(hQt,"TapasForQuestionAnswering"),hQt.forEach(t),iFr=r(eQe," (TAPAS model)"),eQe.forEach(t),fQt.forEach(t),dFr=i($a),g4=n($a,"P",{});var oQe=s(g4);mFr=r(oQe,"The model is set in evaluation mode by default using "),O4e=n(oQe,"CODE",{});var uQt=s(O4e);cFr=r(uQt,"model.eval()"),uQt.forEach(t),fFr=r(oQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V4e=n(oQe,"CODE",{});var pQt=s(V4e);gFr=r(pQt,"model.train()"),pQt.forEach(t),oQe.forEach(t),hFr=i($a),T(h4.$$.fragment,$a),$a.forEach(t),Il.forEach(t),Teo=i(c),Jd=n(c,"H2",{class:!0});var Bro=s(Jd);u4=n(Bro,"A",{id:!0,class:!0,href:!0});var _Qt=s(u4);X4e=n(_Qt,"SPAN",{});var bQt=s(X4e);T(L$.$$.fragment,bQt),bQt.forEach(t),_Qt.forEach(t),uFr=i(Bro),z4e=n(Bro,"SPAN",{});var vQt=s(z4e);pFr=r(vQt,"AutoModelForDocumentQuestionAnswering"),vQt.forEach(t),Bro.forEach(t),Meo=i(c),zo=n(c,"DIV",{class:!0});var Nl=s(zo);T(y$.$$.fragment,Nl),_Fr=i(Nl),Yd=n(Nl,"P",{});var Fie=s(Yd);bFr=r(Fie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),JY=n(Fie,"A",{href:!0});var FQt=s(JY);vFr=r(FQt,"from_pretrained()"),FQt.forEach(t),FFr=r(Fie," class method or the "),YY=n(Fie,"A",{href:!0});var TQt=s(YY);TFr=r(TQt,"from_config()"),TQt.forEach(t),MFr=r(Fie,` class
method.`),Fie.forEach(t),EFr=i(Nl),x$=n(Nl,"P",{});var Iro=s(x$);CFr=r(Iro,"This class cannot be instantiated directly using "),Q4e=n(Iro,"CODE",{});var MQt=s(Q4e);wFr=r(MQt,"__init__()"),MQt.forEach(t),AFr=r(Iro," (throws an error)."),Iro.forEach(t),LFr=i(Nl),yt=n(Nl,"DIV",{class:!0});var p8=s(yt);T($$.$$.fragment,p8),yFr=i(p8),W4e=n(p8,"P",{});var EQt=s(W4e);xFr=r(EQt,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),EQt.forEach(t),$Fr=i(p8),Kd=n(p8,"P",{});var Tie=s(Kd);kFr=r(Tie,`Note:
Loading a model from its configuration file does `),U4e=n(Tie,"STRONG",{});var CQt=s(U4e);SFr=r(CQt,"not"),CQt.forEach(t),RFr=r(Tie,` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=n(Tie,"A",{href:!0});var wQt=s(KY);PFr=r(wQt,"from_pretrained()"),wQt.forEach(t),BFr=r(Tie," to load the model weights."),Tie.forEach(t),IFr=i(p8),T(p4.$$.fragment,p8),p8.forEach(t),NFr=i(Nl),co=n(Nl,"DIV",{class:!0});var ka=s(co);T(k$.$$.fragment,ka),qFr=i(ka),H4e=n(ka,"P",{});var AQt=s(H4e);jFr=r(AQt,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),AQt.forEach(t),DFr=i(ka),ln=n(ka,"P",{});var _8=s(ln);GFr=r(_8,"The model class to instantiate is selected based on the "),J4e=n(_8,"CODE",{});var LQt=s(J4e);OFr=r(LQt,"model_type"),LQt.forEach(t),VFr=r(_8,` property of the config object (either
passed as an argument or loaded from `),Y4e=n(_8,"CODE",{});var yQt=s(Y4e);XFr=r(yQt,"pretrained_model_name_or_path"),yQt.forEach(t),zFr=r(_8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=n(_8,"CODE",{});var xQt=s(K4e);QFr=r(xQt,"pretrained_model_name_or_path"),xQt.forEach(t),WFr=r(_8,":"),_8.forEach(t),UFr=i(ka),Zd=n(ka,"UL",{});var Mie=s(Zd);_4=n(Mie,"LI",{});var rQe=s(_4);Z4e=n(rQe,"STRONG",{});var $Qt=s(Z4e);HFr=r($Qt,"layoutlm"),$Qt.forEach(t),JFr=r(rQe," \u2014 "),ZY=n(rQe,"A",{href:!0});var kQt=s(ZY);YFr=r(kQt,"LayoutLMForQuestionAnswering"),kQt.forEach(t),KFr=r(rQe," (LayoutLM model)"),rQe.forEach(t),ZFr=i(Mie),b4=n(Mie,"LI",{});var tQe=s(b4);eCe=n(tQe,"STRONG",{});var SQt=s(eCe);eTr=r(SQt,"layoutlmv2"),SQt.forEach(t),oTr=r(tQe," \u2014 "),eK=n(tQe,"A",{href:!0});var RQt=s(eK);rTr=r(RQt,"LayoutLMv2ForQuestionAnswering"),RQt.forEach(t),tTr=r(tQe," (LayoutLMv2 model)"),tQe.forEach(t),aTr=i(Mie),v4=n(Mie,"LI",{});var aQe=s(v4);oCe=n(aQe,"STRONG",{});var PQt=s(oCe);nTr=r(PQt,"layoutlmv3"),PQt.forEach(t),sTr=r(aQe," \u2014 "),oK=n(aQe,"A",{href:!0});var BQt=s(oK);lTr=r(BQt,"LayoutLMv3ForQuestionAnswering"),BQt.forEach(t),iTr=r(aQe," (LayoutLMv3 model)"),aQe.forEach(t),Mie.forEach(t),dTr=i(ka),F4=n(ka,"P",{});var nQe=s(F4);mTr=r(nQe,"The model is set in evaluation mode by default using "),rCe=n(nQe,"CODE",{});var IQt=s(rCe);cTr=r(IQt,"model.eval()"),IQt.forEach(t),fTr=r(nQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tCe=n(nQe,"CODE",{});var NQt=s(tCe);gTr=r(NQt,"model.train()"),NQt.forEach(t),nQe.forEach(t),hTr=i(ka),T(T4.$$.fragment,ka),ka.forEach(t),Nl.forEach(t),Eeo=i(c),em=n(c,"H2",{class:!0});var Nro=s(em);M4=n(Nro,"A",{id:!0,class:!0,href:!0});var qQt=s(M4);aCe=n(qQt,"SPAN",{});var jQt=s(aCe);T(S$.$$.fragment,jQt),jQt.forEach(t),qQt.forEach(t),uTr=i(Nro),nCe=n(Nro,"SPAN",{});var DQt=s(nCe);pTr=r(DQt,"AutoModelForImageClassification"),DQt.forEach(t),Nro.forEach(t),Ceo=i(c),Qo=n(c,"DIV",{class:!0});var ql=s(Qo);T(R$.$$.fragment,ql),_Tr=i(ql),om=n(ql,"P",{});var Eie=s(om);bTr=r(Eie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rK=n(Eie,"A",{href:!0});var GQt=s(rK);vTr=r(GQt,"from_pretrained()"),GQt.forEach(t),FTr=r(Eie," class method or the "),tK=n(Eie,"A",{href:!0});var OQt=s(tK);TTr=r(OQt,"from_config()"),OQt.forEach(t),MTr=r(Eie,` class
method.`),Eie.forEach(t),ETr=i(ql),P$=n(ql,"P",{});var qro=s(P$);CTr=r(qro,"This class cannot be instantiated directly using "),sCe=n(qro,"CODE",{});var VQt=s(sCe);wTr=r(VQt,"__init__()"),VQt.forEach(t),ATr=r(qro," (throws an error)."),qro.forEach(t),LTr=i(ql),xt=n(ql,"DIV",{class:!0});var b8=s(xt);T(B$.$$.fragment,b8),yTr=i(b8),lCe=n(b8,"P",{});var XQt=s(lCe);xTr=r(XQt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),XQt.forEach(t),$Tr=i(b8),rm=n(b8,"P",{});var Cie=s(rm);kTr=r(Cie,`Note:
Loading a model from its configuration file does `),iCe=n(Cie,"STRONG",{});var zQt=s(iCe);STr=r(zQt,"not"),zQt.forEach(t),RTr=r(Cie,` load the model weights. It only affects the
model\u2019s configuration. Use `),aK=n(Cie,"A",{href:!0});var QQt=s(aK);PTr=r(QQt,"from_pretrained()"),QQt.forEach(t),BTr=r(Cie," to load the model weights."),Cie.forEach(t),ITr=i(b8),T(E4.$$.fragment,b8),b8.forEach(t),NTr=i(ql),fo=n(ql,"DIV",{class:!0});var Sa=s(fo);T(I$.$$.fragment,Sa),qTr=i(Sa),dCe=n(Sa,"P",{});var WQt=s(dCe);jTr=r(WQt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),WQt.forEach(t),DTr=i(Sa),dn=n(Sa,"P",{});var v8=s(dn);GTr=r(v8,"The model class to instantiate is selected based on the "),mCe=n(v8,"CODE",{});var UQt=s(mCe);OTr=r(UQt,"model_type"),UQt.forEach(t),VTr=r(v8,` property of the config object (either
passed as an argument or loaded from `),cCe=n(v8,"CODE",{});var HQt=s(cCe);XTr=r(HQt,"pretrained_model_name_or_path"),HQt.forEach(t),zTr=r(v8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=n(v8,"CODE",{});var JQt=s(fCe);QTr=r(JQt,"pretrained_model_name_or_path"),JQt.forEach(t),WTr=r(v8,":"),v8.forEach(t),UTr=i(Sa),be=n(Sa,"UL",{});var Fe=s(be);C4=n(Fe,"LI",{});var sQe=s(C4);gCe=n(sQe,"STRONG",{});var YQt=s(gCe);HTr=r(YQt,"beit"),YQt.forEach(t),JTr=r(sQe," \u2014 "),nK=n(sQe,"A",{href:!0});var KQt=s(nK);YTr=r(KQt,"BeitForImageClassification"),KQt.forEach(t),KTr=r(sQe," (BEiT model)"),sQe.forEach(t),ZTr=i(Fe),w4=n(Fe,"LI",{});var lQe=s(w4);hCe=n(lQe,"STRONG",{});var ZQt=s(hCe);eMr=r(ZQt,"convnext"),ZQt.forEach(t),oMr=r(lQe," \u2014 "),sK=n(lQe,"A",{href:!0});var eWt=s(sK);rMr=r(eWt,"ConvNextForImageClassification"),eWt.forEach(t),tMr=r(lQe," (ConvNeXT model)"),lQe.forEach(t),aMr=i(Fe),A4=n(Fe,"LI",{});var iQe=s(A4);uCe=n(iQe,"STRONG",{});var oWt=s(uCe);nMr=r(oWt,"cvt"),oWt.forEach(t),sMr=r(iQe," \u2014 "),lK=n(iQe,"A",{href:!0});var rWt=s(lK);lMr=r(rWt,"CvtForImageClassification"),rWt.forEach(t),iMr=r(iQe," (CvT model)"),iQe.forEach(t),dMr=i(Fe),L4=n(Fe,"LI",{});var dQe=s(L4);pCe=n(dQe,"STRONG",{});var tWt=s(pCe);mMr=r(tWt,"data2vec-vision"),tWt.forEach(t),cMr=r(dQe," \u2014 "),iK=n(dQe,"A",{href:!0});var aWt=s(iK);fMr=r(aWt,"Data2VecVisionForImageClassification"),aWt.forEach(t),gMr=r(dQe," (Data2VecVision model)"),dQe.forEach(t),hMr=i(Fe),bl=n(Fe,"LI",{});var JB=s(bl);_Ce=n(JB,"STRONG",{});var nWt=s(_Ce);uMr=r(nWt,"deit"),nWt.forEach(t),pMr=r(JB," \u2014 "),dK=n(JB,"A",{href:!0});var sWt=s(dK);_Mr=r(sWt,"DeiTForImageClassification"),sWt.forEach(t),bMr=r(JB," or "),mK=n(JB,"A",{href:!0});var lWt=s(mK);vMr=r(lWt,"DeiTForImageClassificationWithTeacher"),lWt.forEach(t),FMr=r(JB," (DeiT model)"),JB.forEach(t),TMr=i(Fe),y4=n(Fe,"LI",{});var mQe=s(y4);bCe=n(mQe,"STRONG",{});var iWt=s(bCe);MMr=r(iWt,"imagegpt"),iWt.forEach(t),EMr=r(mQe," \u2014 "),cK=n(mQe,"A",{href:!0});var dWt=s(cK);CMr=r(dWt,"ImageGPTForImageClassification"),dWt.forEach(t),wMr=r(mQe," (ImageGPT model)"),mQe.forEach(t),AMr=i(Fe),vl=n(Fe,"LI",{});var YB=s(vl);vCe=n(YB,"STRONG",{});var mWt=s(vCe);LMr=r(mWt,"levit"),mWt.forEach(t),yMr=r(YB," \u2014 "),fK=n(YB,"A",{href:!0});var cWt=s(fK);xMr=r(cWt,"LevitForImageClassification"),cWt.forEach(t),$Mr=r(YB," or "),gK=n(YB,"A",{href:!0});var fWt=s(gK);kMr=r(fWt,"LevitForImageClassificationWithTeacher"),fWt.forEach(t),SMr=r(YB," (LeViT model)"),YB.forEach(t),RMr=i(Fe),x4=n(Fe,"LI",{});var cQe=s(x4);FCe=n(cQe,"STRONG",{});var gWt=s(FCe);PMr=r(gWt,"mobilevit"),gWt.forEach(t),BMr=r(cQe," \u2014 "),hK=n(cQe,"A",{href:!0});var hWt=s(hK);IMr=r(hWt,"MobileViTForImageClassification"),hWt.forEach(t),NMr=r(cQe," (MobileViT model)"),cQe.forEach(t),qMr=i(Fe),$t=n(Fe,"LI",{});var Mf=s($t);TCe=n(Mf,"STRONG",{});var uWt=s(TCe);jMr=r(uWt,"perceiver"),uWt.forEach(t),DMr=r(Mf," \u2014 "),uK=n(Mf,"A",{href:!0});var pWt=s(uK);GMr=r(pWt,"PerceiverForImageClassificationLearned"),pWt.forEach(t),OMr=r(Mf," or "),pK=n(Mf,"A",{href:!0});var _Wt=s(pK);VMr=r(_Wt,"PerceiverForImageClassificationFourier"),_Wt.forEach(t),XMr=r(Mf," or "),_K=n(Mf,"A",{href:!0});var bWt=s(_K);zMr=r(bWt,"PerceiverForImageClassificationConvProcessing"),bWt.forEach(t),QMr=r(Mf," (Perceiver model)"),Mf.forEach(t),WMr=i(Fe),$4=n(Fe,"LI",{});var fQe=s($4);MCe=n(fQe,"STRONG",{});var vWt=s(MCe);UMr=r(vWt,"poolformer"),vWt.forEach(t),HMr=r(fQe," \u2014 "),bK=n(fQe,"A",{href:!0});var FWt=s(bK);JMr=r(FWt,"PoolFormerForImageClassification"),FWt.forEach(t),YMr=r(fQe," (PoolFormer model)"),fQe.forEach(t),KMr=i(Fe),k4=n(Fe,"LI",{});var gQe=s(k4);ECe=n(gQe,"STRONG",{});var TWt=s(ECe);ZMr=r(TWt,"regnet"),TWt.forEach(t),eEr=r(gQe," \u2014 "),vK=n(gQe,"A",{href:!0});var MWt=s(vK);oEr=r(MWt,"RegNetForImageClassification"),MWt.forEach(t),rEr=r(gQe," (RegNet model)"),gQe.forEach(t),tEr=i(Fe),S4=n(Fe,"LI",{});var hQe=s(S4);CCe=n(hQe,"STRONG",{});var EWt=s(CCe);aEr=r(EWt,"resnet"),EWt.forEach(t),nEr=r(hQe," \u2014 "),FK=n(hQe,"A",{href:!0});var CWt=s(FK);sEr=r(CWt,"ResNetForImageClassification"),CWt.forEach(t),lEr=r(hQe," (ResNet model)"),hQe.forEach(t),iEr=i(Fe),R4=n(Fe,"LI",{});var uQe=s(R4);wCe=n(uQe,"STRONG",{});var wWt=s(wCe);dEr=r(wWt,"segformer"),wWt.forEach(t),mEr=r(uQe," \u2014 "),TK=n(uQe,"A",{href:!0});var AWt=s(TK);cEr=r(AWt,"SegformerForImageClassification"),AWt.forEach(t),fEr=r(uQe," (SegFormer model)"),uQe.forEach(t),gEr=i(Fe),P4=n(Fe,"LI",{});var pQe=s(P4);ACe=n(pQe,"STRONG",{});var LWt=s(ACe);hEr=r(LWt,"swin"),LWt.forEach(t),uEr=r(pQe," \u2014 "),MK=n(pQe,"A",{href:!0});var yWt=s(MK);pEr=r(yWt,"SwinForImageClassification"),yWt.forEach(t),_Er=r(pQe," (Swin Transformer model)"),pQe.forEach(t),bEr=i(Fe),B4=n(Fe,"LI",{});var _Qe=s(B4);LCe=n(_Qe,"STRONG",{});var xWt=s(LCe);vEr=r(xWt,"swinv2"),xWt.forEach(t),FEr=r(_Qe," \u2014 "),EK=n(_Qe,"A",{href:!0});var $Wt=s(EK);TEr=r($Wt,"Swinv2ForImageClassification"),$Wt.forEach(t),MEr=r(_Qe," (Swin Transformer V2 model)"),_Qe.forEach(t),EEr=i(Fe),I4=n(Fe,"LI",{});var bQe=s(I4);yCe=n(bQe,"STRONG",{});var kWt=s(yCe);CEr=r(kWt,"van"),kWt.forEach(t),wEr=r(bQe," \u2014 "),CK=n(bQe,"A",{href:!0});var SWt=s(CK);AEr=r(SWt,"VanForImageClassification"),SWt.forEach(t),LEr=r(bQe," (VAN model)"),bQe.forEach(t),yEr=i(Fe),N4=n(Fe,"LI",{});var vQe=s(N4);xCe=n(vQe,"STRONG",{});var RWt=s(xCe);xEr=r(RWt,"vit"),RWt.forEach(t),$Er=r(vQe," \u2014 "),wK=n(vQe,"A",{href:!0});var PWt=s(wK);kEr=r(PWt,"ViTForImageClassification"),PWt.forEach(t),SEr=r(vQe," (ViT model)"),vQe.forEach(t),REr=i(Fe),q4=n(Fe,"LI",{});var FQe=s(q4);$Ce=n(FQe,"STRONG",{});var BWt=s($Ce);PEr=r(BWt,"vit_msn"),BWt.forEach(t),BEr=r(FQe," \u2014 "),AK=n(FQe,"A",{href:!0});var IWt=s(AK);IEr=r(IWt,"ViTMSNForImageClassification"),IWt.forEach(t),NEr=r(FQe," (ViTMSN model)"),FQe.forEach(t),Fe.forEach(t),qEr=i(Sa),j4=n(Sa,"P",{});var TQe=s(j4);jEr=r(TQe,"The model is set in evaluation mode by default using "),kCe=n(TQe,"CODE",{});var NWt=s(kCe);DEr=r(NWt,"model.eval()"),NWt.forEach(t),GEr=r(TQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),SCe=n(TQe,"CODE",{});var qWt=s(SCe);OEr=r(qWt,"model.train()"),qWt.forEach(t),TQe.forEach(t),VEr=i(Sa),T(D4.$$.fragment,Sa),Sa.forEach(t),ql.forEach(t),weo=i(c),tm=n(c,"H2",{class:!0});var jro=s(tm);G4=n(jro,"A",{id:!0,class:!0,href:!0});var jWt=s(G4);RCe=n(jWt,"SPAN",{});var DWt=s(RCe);T(N$.$$.fragment,DWt),DWt.forEach(t),jWt.forEach(t),XEr=i(jro),PCe=n(jro,"SPAN",{});var GWt=s(PCe);zEr=r(GWt,"AutoModelForVideoClassification"),GWt.forEach(t),jro.forEach(t),Aeo=i(c),Wo=n(c,"DIV",{class:!0});var jl=s(Wo);T(q$.$$.fragment,jl),QEr=i(jl),am=n(jl,"P",{});var wie=s(am);WEr=r(wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),LK=n(wie,"A",{href:!0});var OWt=s(LK);UEr=r(OWt,"from_pretrained()"),OWt.forEach(t),HEr=r(wie," class method or the "),yK=n(wie,"A",{href:!0});var VWt=s(yK);JEr=r(VWt,"from_config()"),VWt.forEach(t),YEr=r(wie,` class
method.`),wie.forEach(t),KEr=i(jl),j$=n(jl,"P",{});var Dro=s(j$);ZEr=r(Dro,"This class cannot be instantiated directly using "),BCe=n(Dro,"CODE",{});var XWt=s(BCe);e4r=r(XWt,"__init__()"),XWt.forEach(t),o4r=r(Dro," (throws an error)."),Dro.forEach(t),r4r=i(jl),kt=n(jl,"DIV",{class:!0});var F8=s(kt);T(D$.$$.fragment,F8),t4r=i(F8),ICe=n(F8,"P",{});var zWt=s(ICe);a4r=r(zWt,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),zWt.forEach(t),n4r=i(F8),nm=n(F8,"P",{});var Aie=s(nm);s4r=r(Aie,`Note:
Loading a model from its configuration file does `),NCe=n(Aie,"STRONG",{});var QWt=s(NCe);l4r=r(QWt,"not"),QWt.forEach(t),i4r=r(Aie,` load the model weights. It only affects the
model\u2019s configuration. Use `),xK=n(Aie,"A",{href:!0});var WWt=s(xK);d4r=r(WWt,"from_pretrained()"),WWt.forEach(t),m4r=r(Aie," to load the model weights."),Aie.forEach(t),c4r=i(F8),T(O4.$$.fragment,F8),F8.forEach(t),f4r=i(jl),go=n(jl,"DIV",{class:!0});var Ra=s(go);T(G$.$$.fragment,Ra),g4r=i(Ra),qCe=n(Ra,"P",{});var UWt=s(qCe);h4r=r(UWt,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),UWt.forEach(t),u4r=i(Ra),mn=n(Ra,"P",{});var T8=s(mn);p4r=r(T8,"The model class to instantiate is selected based on the "),jCe=n(T8,"CODE",{});var HWt=s(jCe);_4r=r(HWt,"model_type"),HWt.forEach(t),b4r=r(T8,` property of the config object (either
passed as an argument or loaded from `),DCe=n(T8,"CODE",{});var JWt=s(DCe);v4r=r(JWt,"pretrained_model_name_or_path"),JWt.forEach(t),F4r=r(T8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GCe=n(T8,"CODE",{});var YWt=s(GCe);T4r=r(YWt,"pretrained_model_name_or_path"),YWt.forEach(t),M4r=r(T8,":"),T8.forEach(t),E4r=i(Ra),OCe=n(Ra,"UL",{});var KWt=s(OCe);V4=n(KWt,"LI",{});var MQe=s(V4);VCe=n(MQe,"STRONG",{});var ZWt=s(VCe);C4r=r(ZWt,"videomae"),ZWt.forEach(t),w4r=r(MQe," \u2014 "),$K=n(MQe,"A",{href:!0});var eUt=s($K);A4r=r(eUt,"VideoMAEForVideoClassification"),eUt.forEach(t),L4r=r(MQe," (VideoMAE model)"),MQe.forEach(t),KWt.forEach(t),y4r=i(Ra),X4=n(Ra,"P",{});var EQe=s(X4);x4r=r(EQe,"The model is set in evaluation mode by default using "),XCe=n(EQe,"CODE",{});var oUt=s(XCe);$4r=r(oUt,"model.eval()"),oUt.forEach(t),k4r=r(EQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zCe=n(EQe,"CODE",{});var rUt=s(zCe);S4r=r(rUt,"model.train()"),rUt.forEach(t),EQe.forEach(t),R4r=i(Ra),T(z4.$$.fragment,Ra),Ra.forEach(t),jl.forEach(t),Leo=i(c),sm=n(c,"H2",{class:!0});var Gro=s(sm);Q4=n(Gro,"A",{id:!0,class:!0,href:!0});var tUt=s(Q4);QCe=n(tUt,"SPAN",{});var aUt=s(QCe);T(O$.$$.fragment,aUt),aUt.forEach(t),tUt.forEach(t),P4r=i(Gro),WCe=n(Gro,"SPAN",{});var nUt=s(WCe);B4r=r(nUt,"AutoModelForVision2Seq"),nUt.forEach(t),Gro.forEach(t),yeo=i(c),Uo=n(c,"DIV",{class:!0});var Dl=s(Uo);T(V$.$$.fragment,Dl),I4r=i(Dl),lm=n(Dl,"P",{});var Lie=s(lm);N4r=r(Lie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),kK=n(Lie,"A",{href:!0});var sUt=s(kK);q4r=r(sUt,"from_pretrained()"),sUt.forEach(t),j4r=r(Lie," class method or the "),SK=n(Lie,"A",{href:!0});var lUt=s(SK);D4r=r(lUt,"from_config()"),lUt.forEach(t),G4r=r(Lie,` class
method.`),Lie.forEach(t),O4r=i(Dl),X$=n(Dl,"P",{});var Oro=s(X$);V4r=r(Oro,"This class cannot be instantiated directly using "),UCe=n(Oro,"CODE",{});var iUt=s(UCe);X4r=r(iUt,"__init__()"),iUt.forEach(t),z4r=r(Oro," (throws an error)."),Oro.forEach(t),Q4r=i(Dl),St=n(Dl,"DIV",{class:!0});var M8=s(St);T(z$.$$.fragment,M8),W4r=i(M8),HCe=n(M8,"P",{});var dUt=s(HCe);U4r=r(dUt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dUt.forEach(t),H4r=i(M8),im=n(M8,"P",{});var yie=s(im);J4r=r(yie,`Note:
Loading a model from its configuration file does `),JCe=n(yie,"STRONG",{});var mUt=s(JCe);Y4r=r(mUt,"not"),mUt.forEach(t),K4r=r(yie,` load the model weights. It only affects the
model\u2019s configuration. Use `),RK=n(yie,"A",{href:!0});var cUt=s(RK);Z4r=r(cUt,"from_pretrained()"),cUt.forEach(t),eCr=r(yie," to load the model weights."),yie.forEach(t),oCr=i(M8),T(W4.$$.fragment,M8),M8.forEach(t),rCr=i(Dl),ho=n(Dl,"DIV",{class:!0});var Pa=s(ho);T(Q$.$$.fragment,Pa),tCr=i(Pa),YCe=n(Pa,"P",{});var fUt=s(YCe);aCr=r(fUt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fUt.forEach(t),nCr=i(Pa),cn=n(Pa,"P",{});var E8=s(cn);sCr=r(E8,"The model class to instantiate is selected based on the "),KCe=n(E8,"CODE",{});var gUt=s(KCe);lCr=r(gUt,"model_type"),gUt.forEach(t),iCr=r(E8,` property of the config object (either
passed as an argument or loaded from `),ZCe=n(E8,"CODE",{});var hUt=s(ZCe);dCr=r(hUt,"pretrained_model_name_or_path"),hUt.forEach(t),mCr=r(E8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e3e=n(E8,"CODE",{});var uUt=s(e3e);cCr=r(uUt,"pretrained_model_name_or_path"),uUt.forEach(t),fCr=r(E8,":"),E8.forEach(t),gCr=i(Pa),o3e=n(Pa,"UL",{});var pUt=s(o3e);U4=n(pUt,"LI",{});var CQe=s(U4);r3e=n(CQe,"STRONG",{});var _Ut=s(r3e);hCr=r(_Ut,"vision-encoder-decoder"),_Ut.forEach(t),uCr=r(CQe," \u2014 "),PK=n(CQe,"A",{href:!0});var bUt=s(PK);pCr=r(bUt,"VisionEncoderDecoderModel"),bUt.forEach(t),_Cr=r(CQe," (Vision Encoder decoder model)"),CQe.forEach(t),pUt.forEach(t),bCr=i(Pa),H4=n(Pa,"P",{});var wQe=s(H4);vCr=r(wQe,"The model is set in evaluation mode by default using "),t3e=n(wQe,"CODE",{});var vUt=s(t3e);FCr=r(vUt,"model.eval()"),vUt.forEach(t),TCr=r(wQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a3e=n(wQe,"CODE",{});var FUt=s(a3e);MCr=r(FUt,"model.train()"),FUt.forEach(t),wQe.forEach(t),ECr=i(Pa),T(J4.$$.fragment,Pa),Pa.forEach(t),Dl.forEach(t),xeo=i(c),dm=n(c,"H2",{class:!0});var Vro=s(dm);Y4=n(Vro,"A",{id:!0,class:!0,href:!0});var TUt=s(Y4);n3e=n(TUt,"SPAN",{});var MUt=s(n3e);T(W$.$$.fragment,MUt),MUt.forEach(t),TUt.forEach(t),CCr=i(Vro),s3e=n(Vro,"SPAN",{});var EUt=s(s3e);wCr=r(EUt,"AutoModelForVisualQuestionAnswering"),EUt.forEach(t),Vro.forEach(t),$eo=i(c),Ho=n(c,"DIV",{class:!0});var Gl=s(Ho);T(U$.$$.fragment,Gl),ACr=i(Gl),mm=n(Gl,"P",{});var xie=s(mm);LCr=r(xie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),BK=n(xie,"A",{href:!0});var CUt=s(BK);yCr=r(CUt,"from_pretrained()"),CUt.forEach(t),xCr=r(xie," class method or the "),IK=n(xie,"A",{href:!0});var wUt=s(IK);$Cr=r(wUt,"from_config()"),wUt.forEach(t),kCr=r(xie,` class
method.`),xie.forEach(t),SCr=i(Gl),H$=n(Gl,"P",{});var Xro=s(H$);RCr=r(Xro,"This class cannot be instantiated directly using "),l3e=n(Xro,"CODE",{});var AUt=s(l3e);PCr=r(AUt,"__init__()"),AUt.forEach(t),BCr=r(Xro," (throws an error)."),Xro.forEach(t),ICr=i(Gl),Rt=n(Gl,"DIV",{class:!0});var C8=s(Rt);T(J$.$$.fragment,C8),NCr=i(C8),i3e=n(C8,"P",{});var LUt=s(i3e);qCr=r(LUt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),LUt.forEach(t),jCr=i(C8),cm=n(C8,"P",{});var $ie=s(cm);DCr=r($ie,`Note:
Loading a model from its configuration file does `),d3e=n($ie,"STRONG",{});var yUt=s(d3e);GCr=r(yUt,"not"),yUt.forEach(t),OCr=r($ie,` load the model weights. It only affects the
model\u2019s configuration. Use `),NK=n($ie,"A",{href:!0});var xUt=s(NK);VCr=r(xUt,"from_pretrained()"),xUt.forEach(t),XCr=r($ie," to load the model weights."),$ie.forEach(t),zCr=i(C8),T(K4.$$.fragment,C8),C8.forEach(t),QCr=i(Gl),uo=n(Gl,"DIV",{class:!0});var Ba=s(uo);T(Y$.$$.fragment,Ba),WCr=i(Ba),m3e=n(Ba,"P",{});var $Ut=s(m3e);UCr=r($Ut,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),$Ut.forEach(t),HCr=i(Ba),fn=n(Ba,"P",{});var w8=s(fn);JCr=r(w8,"The model class to instantiate is selected based on the "),c3e=n(w8,"CODE",{});var kUt=s(c3e);YCr=r(kUt,"model_type"),kUt.forEach(t),KCr=r(w8,` property of the config object (either
passed as an argument or loaded from `),f3e=n(w8,"CODE",{});var SUt=s(f3e);ZCr=r(SUt,"pretrained_model_name_or_path"),SUt.forEach(t),e3r=r(w8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g3e=n(w8,"CODE",{});var RUt=s(g3e);o3r=r(RUt,"pretrained_model_name_or_path"),RUt.forEach(t),r3r=r(w8,":"),w8.forEach(t),t3r=i(Ba),h3e=n(Ba,"UL",{});var PUt=s(h3e);Z4=n(PUt,"LI",{});var AQe=s(Z4);u3e=n(AQe,"STRONG",{});var BUt=s(u3e);a3r=r(BUt,"vilt"),BUt.forEach(t),n3r=r(AQe," \u2014 "),qK=n(AQe,"A",{href:!0});var IUt=s(qK);s3r=r(IUt,"ViltForQuestionAnswering"),IUt.forEach(t),l3r=r(AQe," (ViLT model)"),AQe.forEach(t),PUt.forEach(t),i3r=i(Ba),eC=n(Ba,"P",{});var LQe=s(eC);d3r=r(LQe,"The model is set in evaluation mode by default using "),p3e=n(LQe,"CODE",{});var NUt=s(p3e);m3r=r(NUt,"model.eval()"),NUt.forEach(t),c3r=r(LQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_3e=n(LQe,"CODE",{});var qUt=s(_3e);f3r=r(qUt,"model.train()"),qUt.forEach(t),LQe.forEach(t),g3r=i(Ba),T(oC.$$.fragment,Ba),Ba.forEach(t),Gl.forEach(t),keo=i(c),fm=n(c,"H2",{class:!0});var zro=s(fm);rC=n(zro,"A",{id:!0,class:!0,href:!0});var jUt=s(rC);b3e=n(jUt,"SPAN",{});var DUt=s(b3e);T(K$.$$.fragment,DUt),DUt.forEach(t),jUt.forEach(t),h3r=i(zro),v3e=n(zro,"SPAN",{});var GUt=s(v3e);u3r=r(GUt,"AutoModelForAudioClassification"),GUt.forEach(t),zro.forEach(t),Seo=i(c),Jo=n(c,"DIV",{class:!0});var Ol=s(Jo);T(Z$.$$.fragment,Ol),p3r=i(Ol),gm=n(Ol,"P",{});var kie=s(gm);_3r=r(kie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),jK=n(kie,"A",{href:!0});var OUt=s(jK);b3r=r(OUt,"from_pretrained()"),OUt.forEach(t),v3r=r(kie," class method or the "),DK=n(kie,"A",{href:!0});var VUt=s(DK);F3r=r(VUt,"from_config()"),VUt.forEach(t),T3r=r(kie,` class
method.`),kie.forEach(t),M3r=i(Ol),ek=n(Ol,"P",{});var Qro=s(ek);E3r=r(Qro,"This class cannot be instantiated directly using "),F3e=n(Qro,"CODE",{});var XUt=s(F3e);C3r=r(XUt,"__init__()"),XUt.forEach(t),w3r=r(Qro," (throws an error)."),Qro.forEach(t),A3r=i(Ol),Pt=n(Ol,"DIV",{class:!0});var A8=s(Pt);T(ok.$$.fragment,A8),L3r=i(A8),T3e=n(A8,"P",{});var zUt=s(T3e);y3r=r(zUt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),zUt.forEach(t),x3r=i(A8),hm=n(A8,"P",{});var Sie=s(hm);$3r=r(Sie,`Note:
Loading a model from its configuration file does `),M3e=n(Sie,"STRONG",{});var QUt=s(M3e);k3r=r(QUt,"not"),QUt.forEach(t),S3r=r(Sie,` load the model weights. It only affects the
model\u2019s configuration. Use `),GK=n(Sie,"A",{href:!0});var WUt=s(GK);R3r=r(WUt,"from_pretrained()"),WUt.forEach(t),P3r=r(Sie," to load the model weights."),Sie.forEach(t),B3r=i(A8),T(tC.$$.fragment,A8),A8.forEach(t),I3r=i(Ol),po=n(Ol,"DIV",{class:!0});var Ia=s(po);T(rk.$$.fragment,Ia),N3r=i(Ia),E3e=n(Ia,"P",{});var UUt=s(E3e);q3r=r(UUt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),UUt.forEach(t),j3r=i(Ia),gn=n(Ia,"P",{});var L8=s(gn);D3r=r(L8,"The model class to instantiate is selected based on the "),C3e=n(L8,"CODE",{});var HUt=s(C3e);G3r=r(HUt,"model_type"),HUt.forEach(t),O3r=r(L8,` property of the config object (either
passed as an argument or loaded from `),w3e=n(L8,"CODE",{});var JUt=s(w3e);V3r=r(JUt,"pretrained_model_name_or_path"),JUt.forEach(t),X3r=r(L8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A3e=n(L8,"CODE",{});var YUt=s(A3e);z3r=r(YUt,"pretrained_model_name_or_path"),YUt.forEach(t),Q3r=r(L8,":"),L8.forEach(t),W3r=i(Ia),Pe=n(Ia,"UL",{});var Qe=s(Pe);aC=n(Qe,"LI",{});var yQe=s(aC);L3e=n(yQe,"STRONG",{});var KUt=s(L3e);U3r=r(KUt,"data2vec-audio"),KUt.forEach(t),H3r=r(yQe," \u2014 "),OK=n(yQe,"A",{href:!0});var ZUt=s(OK);J3r=r(ZUt,"Data2VecAudioForSequenceClassification"),ZUt.forEach(t),Y3r=r(yQe," (Data2VecAudio model)"),yQe.forEach(t),K3r=i(Qe),nC=n(Qe,"LI",{});var xQe=s(nC);y3e=n(xQe,"STRONG",{});var eHt=s(y3e);Z3r=r(eHt,"hubert"),eHt.forEach(t),e5r=r(xQe," \u2014 "),VK=n(xQe,"A",{href:!0});var oHt=s(VK);o5r=r(oHt,"HubertForSequenceClassification"),oHt.forEach(t),r5r=r(xQe," (Hubert model)"),xQe.forEach(t),t5r=i(Qe),sC=n(Qe,"LI",{});var $Qe=s(sC);x3e=n($Qe,"STRONG",{});var rHt=s(x3e);a5r=r(rHt,"sew"),rHt.forEach(t),n5r=r($Qe," \u2014 "),XK=n($Qe,"A",{href:!0});var tHt=s(XK);s5r=r(tHt,"SEWForSequenceClassification"),tHt.forEach(t),l5r=r($Qe," (SEW model)"),$Qe.forEach(t),i5r=i(Qe),lC=n(Qe,"LI",{});var kQe=s(lC);$3e=n(kQe,"STRONG",{});var aHt=s($3e);d5r=r(aHt,"sew-d"),aHt.forEach(t),m5r=r(kQe," \u2014 "),zK=n(kQe,"A",{href:!0});var nHt=s(zK);c5r=r(nHt,"SEWDForSequenceClassification"),nHt.forEach(t),f5r=r(kQe," (SEW-D model)"),kQe.forEach(t),g5r=i(Qe),iC=n(Qe,"LI",{});var SQe=s(iC);k3e=n(SQe,"STRONG",{});var sHt=s(k3e);h5r=r(sHt,"unispeech"),sHt.forEach(t),u5r=r(SQe," \u2014 "),QK=n(SQe,"A",{href:!0});var lHt=s(QK);p5r=r(lHt,"UniSpeechForSequenceClassification"),lHt.forEach(t),_5r=r(SQe," (UniSpeech model)"),SQe.forEach(t),b5r=i(Qe),dC=n(Qe,"LI",{});var RQe=s(dC);S3e=n(RQe,"STRONG",{});var iHt=s(S3e);v5r=r(iHt,"unispeech-sat"),iHt.forEach(t),F5r=r(RQe," \u2014 "),WK=n(RQe,"A",{href:!0});var dHt=s(WK);T5r=r(dHt,"UniSpeechSatForSequenceClassification"),dHt.forEach(t),M5r=r(RQe," (UniSpeechSat model)"),RQe.forEach(t),E5r=i(Qe),mC=n(Qe,"LI",{});var PQe=s(mC);R3e=n(PQe,"STRONG",{});var mHt=s(R3e);C5r=r(mHt,"wav2vec2"),mHt.forEach(t),w5r=r(PQe," \u2014 "),UK=n(PQe,"A",{href:!0});var cHt=s(UK);A5r=r(cHt,"Wav2Vec2ForSequenceClassification"),cHt.forEach(t),L5r=r(PQe," (Wav2Vec2 model)"),PQe.forEach(t),y5r=i(Qe),cC=n(Qe,"LI",{});var BQe=s(cC);P3e=n(BQe,"STRONG",{});var fHt=s(P3e);x5r=r(fHt,"wav2vec2-conformer"),fHt.forEach(t),$5r=r(BQe," \u2014 "),HK=n(BQe,"A",{href:!0});var gHt=s(HK);k5r=r(gHt,"Wav2Vec2ConformerForSequenceClassification"),gHt.forEach(t),S5r=r(BQe," (Wav2Vec2-Conformer model)"),BQe.forEach(t),R5r=i(Qe),fC=n(Qe,"LI",{});var IQe=s(fC);B3e=n(IQe,"STRONG",{});var hHt=s(B3e);P5r=r(hHt,"wavlm"),hHt.forEach(t),B5r=r(IQe," \u2014 "),JK=n(IQe,"A",{href:!0});var uHt=s(JK);I5r=r(uHt,"WavLMForSequenceClassification"),uHt.forEach(t),N5r=r(IQe," (WavLM model)"),IQe.forEach(t),Qe.forEach(t),q5r=i(Ia),gC=n(Ia,"P",{});var NQe=s(gC);j5r=r(NQe,"The model is set in evaluation mode by default using "),I3e=n(NQe,"CODE",{});var pHt=s(I3e);D5r=r(pHt,"model.eval()"),pHt.forEach(t),G5r=r(NQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N3e=n(NQe,"CODE",{});var _Ht=s(N3e);O5r=r(_Ht,"model.train()"),_Ht.forEach(t),NQe.forEach(t),V5r=i(Ia),T(hC.$$.fragment,Ia),Ia.forEach(t),Ol.forEach(t),Reo=i(c),um=n(c,"H2",{class:!0});var Wro=s(um);uC=n(Wro,"A",{id:!0,class:!0,href:!0});var bHt=s(uC);q3e=n(bHt,"SPAN",{});var vHt=s(q3e);T(tk.$$.fragment,vHt),vHt.forEach(t),bHt.forEach(t),X5r=i(Wro),j3e=n(Wro,"SPAN",{});var FHt=s(j3e);z5r=r(FHt,"AutoModelForAudioFrameClassification"),FHt.forEach(t),Wro.forEach(t),Peo=i(c),Yo=n(c,"DIV",{class:!0});var Vl=s(Yo);T(ak.$$.fragment,Vl),Q5r=i(Vl),pm=n(Vl,"P",{});var Rie=s(pm);W5r=r(Rie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),YK=n(Rie,"A",{href:!0});var THt=s(YK);U5r=r(THt,"from_pretrained()"),THt.forEach(t),H5r=r(Rie," class method or the "),KK=n(Rie,"A",{href:!0});var MHt=s(KK);J5r=r(MHt,"from_config()"),MHt.forEach(t),Y5r=r(Rie,` class
method.`),Rie.forEach(t),K5r=i(Vl),nk=n(Vl,"P",{});var Uro=s(nk);Z5r=r(Uro,"This class cannot be instantiated directly using "),D3e=n(Uro,"CODE",{});var EHt=s(D3e);e0r=r(EHt,"__init__()"),EHt.forEach(t),o0r=r(Uro," (throws an error)."),Uro.forEach(t),r0r=i(Vl),Bt=n(Vl,"DIV",{class:!0});var y8=s(Bt);T(sk.$$.fragment,y8),t0r=i(y8),G3e=n(y8,"P",{});var CHt=s(G3e);a0r=r(CHt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),CHt.forEach(t),n0r=i(y8),_m=n(y8,"P",{});var Pie=s(_m);s0r=r(Pie,`Note:
Loading a model from its configuration file does `),O3e=n(Pie,"STRONG",{});var wHt=s(O3e);l0r=r(wHt,"not"),wHt.forEach(t),i0r=r(Pie,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZK=n(Pie,"A",{href:!0});var AHt=s(ZK);d0r=r(AHt,"from_pretrained()"),AHt.forEach(t),m0r=r(Pie," to load the model weights."),Pie.forEach(t),c0r=i(y8),T(pC.$$.fragment,y8),y8.forEach(t),f0r=i(Vl),_o=n(Vl,"DIV",{class:!0});var Na=s(_o);T(lk.$$.fragment,Na),g0r=i(Na),V3e=n(Na,"P",{});var LHt=s(V3e);h0r=r(LHt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),LHt.forEach(t),u0r=i(Na),hn=n(Na,"P",{});var x8=s(hn);p0r=r(x8,"The model class to instantiate is selected based on the "),X3e=n(x8,"CODE",{});var yHt=s(X3e);_0r=r(yHt,"model_type"),yHt.forEach(t),b0r=r(x8,` property of the config object (either
passed as an argument or loaded from `),z3e=n(x8,"CODE",{});var xHt=s(z3e);v0r=r(xHt,"pretrained_model_name_or_path"),xHt.forEach(t),F0r=r(x8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q3e=n(x8,"CODE",{});var $Ht=s(Q3e);T0r=r($Ht,"pretrained_model_name_or_path"),$Ht.forEach(t),M0r=r(x8,":"),x8.forEach(t),E0r=i(Na),ct=n(Na,"UL",{});var Xl=s(ct);_C=n(Xl,"LI",{});var qQe=s(_C);W3e=n(qQe,"STRONG",{});var kHt=s(W3e);C0r=r(kHt,"data2vec-audio"),kHt.forEach(t),w0r=r(qQe," \u2014 "),eZ=n(qQe,"A",{href:!0});var SHt=s(eZ);A0r=r(SHt,"Data2VecAudioForAudioFrameClassification"),SHt.forEach(t),L0r=r(qQe," (Data2VecAudio model)"),qQe.forEach(t),y0r=i(Xl),bC=n(Xl,"LI",{});var jQe=s(bC);U3e=n(jQe,"STRONG",{});var RHt=s(U3e);x0r=r(RHt,"unispeech-sat"),RHt.forEach(t),$0r=r(jQe," \u2014 "),oZ=n(jQe,"A",{href:!0});var PHt=s(oZ);k0r=r(PHt,"UniSpeechSatForAudioFrameClassification"),PHt.forEach(t),S0r=r(jQe," (UniSpeechSat model)"),jQe.forEach(t),R0r=i(Xl),vC=n(Xl,"LI",{});var DQe=s(vC);H3e=n(DQe,"STRONG",{});var BHt=s(H3e);P0r=r(BHt,"wav2vec2"),BHt.forEach(t),B0r=r(DQe," \u2014 "),rZ=n(DQe,"A",{href:!0});var IHt=s(rZ);I0r=r(IHt,"Wav2Vec2ForAudioFrameClassification"),IHt.forEach(t),N0r=r(DQe," (Wav2Vec2 model)"),DQe.forEach(t),q0r=i(Xl),FC=n(Xl,"LI",{});var GQe=s(FC);J3e=n(GQe,"STRONG",{});var NHt=s(J3e);j0r=r(NHt,"wav2vec2-conformer"),NHt.forEach(t),D0r=r(GQe," \u2014 "),tZ=n(GQe,"A",{href:!0});var qHt=s(tZ);G0r=r(qHt,"Wav2Vec2ConformerForAudioFrameClassification"),qHt.forEach(t),O0r=r(GQe," (Wav2Vec2-Conformer model)"),GQe.forEach(t),V0r=i(Xl),TC=n(Xl,"LI",{});var OQe=s(TC);Y3e=n(OQe,"STRONG",{});var jHt=s(Y3e);X0r=r(jHt,"wavlm"),jHt.forEach(t),z0r=r(OQe," \u2014 "),aZ=n(OQe,"A",{href:!0});var DHt=s(aZ);Q0r=r(DHt,"WavLMForAudioFrameClassification"),DHt.forEach(t),W0r=r(OQe," (WavLM model)"),OQe.forEach(t),Xl.forEach(t),U0r=i(Na),MC=n(Na,"P",{});var VQe=s(MC);H0r=r(VQe,"The model is set in evaluation mode by default using "),K3e=n(VQe,"CODE",{});var GHt=s(K3e);J0r=r(GHt,"model.eval()"),GHt.forEach(t),Y0r=r(VQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z3e=n(VQe,"CODE",{});var OHt=s(Z3e);K0r=r(OHt,"model.train()"),OHt.forEach(t),VQe.forEach(t),Z0r=i(Na),T(EC.$$.fragment,Na),Na.forEach(t),Vl.forEach(t),Beo=i(c),bm=n(c,"H2",{class:!0});var Hro=s(bm);CC=n(Hro,"A",{id:!0,class:!0,href:!0});var VHt=s(CC);e5e=n(VHt,"SPAN",{});var XHt=s(e5e);T(ik.$$.fragment,XHt),XHt.forEach(t),VHt.forEach(t),ewr=i(Hro),o5e=n(Hro,"SPAN",{});var zHt=s(o5e);owr=r(zHt,"AutoModelForCTC"),zHt.forEach(t),Hro.forEach(t),Ieo=i(c),Ko=n(c,"DIV",{class:!0});var zl=s(Ko);T(dk.$$.fragment,zl),rwr=i(zl),vm=n(zl,"P",{});var Bie=s(vm);twr=r(Bie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),nZ=n(Bie,"A",{href:!0});var QHt=s(nZ);awr=r(QHt,"from_pretrained()"),QHt.forEach(t),nwr=r(Bie," class method or the "),sZ=n(Bie,"A",{href:!0});var WHt=s(sZ);swr=r(WHt,"from_config()"),WHt.forEach(t),lwr=r(Bie,` class
method.`),Bie.forEach(t),iwr=i(zl),mk=n(zl,"P",{});var Jro=s(mk);dwr=r(Jro,"This class cannot be instantiated directly using "),r5e=n(Jro,"CODE",{});var UHt=s(r5e);mwr=r(UHt,"__init__()"),UHt.forEach(t),cwr=r(Jro," (throws an error)."),Jro.forEach(t),fwr=i(zl),It=n(zl,"DIV",{class:!0});var $8=s(It);T(ck.$$.fragment,$8),gwr=i($8),t5e=n($8,"P",{});var HHt=s(t5e);hwr=r(HHt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),HHt.forEach(t),uwr=i($8),Fm=n($8,"P",{});var Iie=s(Fm);pwr=r(Iie,`Note:
Loading a model from its configuration file does `),a5e=n(Iie,"STRONG",{});var JHt=s(a5e);_wr=r(JHt,"not"),JHt.forEach(t),bwr=r(Iie,` load the model weights. It only affects the
model\u2019s configuration. Use `),lZ=n(Iie,"A",{href:!0});var YHt=s(lZ);vwr=r(YHt,"from_pretrained()"),YHt.forEach(t),Fwr=r(Iie," to load the model weights."),Iie.forEach(t),Twr=i($8),T(wC.$$.fragment,$8),$8.forEach(t),Mwr=i(zl),bo=n(zl,"DIV",{class:!0});var qa=s(bo);T(fk.$$.fragment,qa),Ewr=i(qa),n5e=n(qa,"P",{});var KHt=s(n5e);Cwr=r(KHt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),KHt.forEach(t),wwr=i(qa),un=n(qa,"P",{});var k8=s(un);Awr=r(k8,"The model class to instantiate is selected based on the "),s5e=n(k8,"CODE",{});var ZHt=s(s5e);Lwr=r(ZHt,"model_type"),ZHt.forEach(t),ywr=r(k8,` property of the config object (either
passed as an argument or loaded from `),l5e=n(k8,"CODE",{});var eJt=s(l5e);xwr=r(eJt,"pretrained_model_name_or_path"),eJt.forEach(t),$wr=r(k8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i5e=n(k8,"CODE",{});var oJt=s(i5e);kwr=r(oJt,"pretrained_model_name_or_path"),oJt.forEach(t),Swr=r(k8,":"),k8.forEach(t),Rwr=i(qa),Le=n(qa,"UL",{});var Ie=s(Le);AC=n(Ie,"LI",{});var XQe=s(AC);d5e=n(XQe,"STRONG",{});var rJt=s(d5e);Pwr=r(rJt,"data2vec-audio"),rJt.forEach(t),Bwr=r(XQe," \u2014 "),iZ=n(XQe,"A",{href:!0});var tJt=s(iZ);Iwr=r(tJt,"Data2VecAudioForCTC"),tJt.forEach(t),Nwr=r(XQe," (Data2VecAudio model)"),XQe.forEach(t),qwr=i(Ie),LC=n(Ie,"LI",{});var zQe=s(LC);m5e=n(zQe,"STRONG",{});var aJt=s(m5e);jwr=r(aJt,"hubert"),aJt.forEach(t),Dwr=r(zQe," \u2014 "),dZ=n(zQe,"A",{href:!0});var nJt=s(dZ);Gwr=r(nJt,"HubertForCTC"),nJt.forEach(t),Owr=r(zQe," (Hubert model)"),zQe.forEach(t),Vwr=i(Ie),yC=n(Ie,"LI",{});var QQe=s(yC);c5e=n(QQe,"STRONG",{});var sJt=s(c5e);Xwr=r(sJt,"mctct"),sJt.forEach(t),zwr=r(QQe," \u2014 "),mZ=n(QQe,"A",{href:!0});var lJt=s(mZ);Qwr=r(lJt,"MCTCTForCTC"),lJt.forEach(t),Wwr=r(QQe," (M-CTC-T model)"),QQe.forEach(t),Uwr=i(Ie),xC=n(Ie,"LI",{});var WQe=s(xC);f5e=n(WQe,"STRONG",{});var iJt=s(f5e);Hwr=r(iJt,"sew"),iJt.forEach(t),Jwr=r(WQe," \u2014 "),cZ=n(WQe,"A",{href:!0});var dJt=s(cZ);Ywr=r(dJt,"SEWForCTC"),dJt.forEach(t),Kwr=r(WQe," (SEW model)"),WQe.forEach(t),Zwr=i(Ie),$C=n(Ie,"LI",{});var UQe=s($C);g5e=n(UQe,"STRONG",{});var mJt=s(g5e);eAr=r(mJt,"sew-d"),mJt.forEach(t),oAr=r(UQe," \u2014 "),fZ=n(UQe,"A",{href:!0});var cJt=s(fZ);rAr=r(cJt,"SEWDForCTC"),cJt.forEach(t),tAr=r(UQe," (SEW-D model)"),UQe.forEach(t),aAr=i(Ie),kC=n(Ie,"LI",{});var HQe=s(kC);h5e=n(HQe,"STRONG",{});var fJt=s(h5e);nAr=r(fJt,"unispeech"),fJt.forEach(t),sAr=r(HQe," \u2014 "),gZ=n(HQe,"A",{href:!0});var gJt=s(gZ);lAr=r(gJt,"UniSpeechForCTC"),gJt.forEach(t),iAr=r(HQe," (UniSpeech model)"),HQe.forEach(t),dAr=i(Ie),SC=n(Ie,"LI",{});var JQe=s(SC);u5e=n(JQe,"STRONG",{});var hJt=s(u5e);mAr=r(hJt,"unispeech-sat"),hJt.forEach(t),cAr=r(JQe," \u2014 "),hZ=n(JQe,"A",{href:!0});var uJt=s(hZ);fAr=r(uJt,"UniSpeechSatForCTC"),uJt.forEach(t),gAr=r(JQe," (UniSpeechSat model)"),JQe.forEach(t),hAr=i(Ie),RC=n(Ie,"LI",{});var YQe=s(RC);p5e=n(YQe,"STRONG",{});var pJt=s(p5e);uAr=r(pJt,"wav2vec2"),pJt.forEach(t),pAr=r(YQe," \u2014 "),uZ=n(YQe,"A",{href:!0});var _Jt=s(uZ);_Ar=r(_Jt,"Wav2Vec2ForCTC"),_Jt.forEach(t),bAr=r(YQe," (Wav2Vec2 model)"),YQe.forEach(t),vAr=i(Ie),PC=n(Ie,"LI",{});var KQe=s(PC);_5e=n(KQe,"STRONG",{});var bJt=s(_5e);FAr=r(bJt,"wav2vec2-conformer"),bJt.forEach(t),TAr=r(KQe," \u2014 "),pZ=n(KQe,"A",{href:!0});var vJt=s(pZ);MAr=r(vJt,"Wav2Vec2ConformerForCTC"),vJt.forEach(t),EAr=r(KQe," (Wav2Vec2-Conformer model)"),KQe.forEach(t),CAr=i(Ie),BC=n(Ie,"LI",{});var ZQe=s(BC);b5e=n(ZQe,"STRONG",{});var FJt=s(b5e);wAr=r(FJt,"wavlm"),FJt.forEach(t),AAr=r(ZQe," \u2014 "),_Z=n(ZQe,"A",{href:!0});var TJt=s(_Z);LAr=r(TJt,"WavLMForCTC"),TJt.forEach(t),yAr=r(ZQe," (WavLM model)"),ZQe.forEach(t),Ie.forEach(t),xAr=i(qa),IC=n(qa,"P",{});var eWe=s(IC);$Ar=r(eWe,"The model is set in evaluation mode by default using "),v5e=n(eWe,"CODE",{});var MJt=s(v5e);kAr=r(MJt,"model.eval()"),MJt.forEach(t),SAr=r(eWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F5e=n(eWe,"CODE",{});var EJt=s(F5e);RAr=r(EJt,"model.train()"),EJt.forEach(t),eWe.forEach(t),PAr=i(qa),T(NC.$$.fragment,qa),qa.forEach(t),zl.forEach(t),Neo=i(c),Tm=n(c,"H2",{class:!0});var Yro=s(Tm);qC=n(Yro,"A",{id:!0,class:!0,href:!0});var CJt=s(qC);T5e=n(CJt,"SPAN",{});var wJt=s(T5e);T(gk.$$.fragment,wJt),wJt.forEach(t),CJt.forEach(t),BAr=i(Yro),M5e=n(Yro,"SPAN",{});var AJt=s(M5e);IAr=r(AJt,"AutoModelForSpeechSeq2Seq"),AJt.forEach(t),Yro.forEach(t),qeo=i(c),Zo=n(c,"DIV",{class:!0});var Ql=s(Zo);T(hk.$$.fragment,Ql),NAr=i(Ql),Mm=n(Ql,"P",{});var Nie=s(Mm);qAr=r(Nie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),bZ=n(Nie,"A",{href:!0});var LJt=s(bZ);jAr=r(LJt,"from_pretrained()"),LJt.forEach(t),DAr=r(Nie," class method or the "),vZ=n(Nie,"A",{href:!0});var yJt=s(vZ);GAr=r(yJt,"from_config()"),yJt.forEach(t),OAr=r(Nie,` class
method.`),Nie.forEach(t),VAr=i(Ql),uk=n(Ql,"P",{});var Kro=s(uk);XAr=r(Kro,"This class cannot be instantiated directly using "),E5e=n(Kro,"CODE",{});var xJt=s(E5e);zAr=r(xJt,"__init__()"),xJt.forEach(t),QAr=r(Kro," (throws an error)."),Kro.forEach(t),WAr=i(Ql),Nt=n(Ql,"DIV",{class:!0});var S8=s(Nt);T(pk.$$.fragment,S8),UAr=i(S8),C5e=n(S8,"P",{});var $Jt=s(C5e);HAr=r($Jt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$Jt.forEach(t),JAr=i(S8),Em=n(S8,"P",{});var qie=s(Em);YAr=r(qie,`Note:
Loading a model from its configuration file does `),w5e=n(qie,"STRONG",{});var kJt=s(w5e);KAr=r(kJt,"not"),kJt.forEach(t),ZAr=r(qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),FZ=n(qie,"A",{href:!0});var SJt=s(FZ);e6r=r(SJt,"from_pretrained()"),SJt.forEach(t),o6r=r(qie," to load the model weights."),qie.forEach(t),r6r=i(S8),T(jC.$$.fragment,S8),S8.forEach(t),t6r=i(Ql),vo=n(Ql,"DIV",{class:!0});var ja=s(vo);T(_k.$$.fragment,ja),a6r=i(ja),A5e=n(ja,"P",{});var RJt=s(A5e);n6r=r(RJt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),RJt.forEach(t),s6r=i(ja),pn=n(ja,"P",{});var R8=s(pn);l6r=r(R8,"The model class to instantiate is selected based on the "),L5e=n(R8,"CODE",{});var PJt=s(L5e);i6r=r(PJt,"model_type"),PJt.forEach(t),d6r=r(R8,` property of the config object (either
passed as an argument or loaded from `),y5e=n(R8,"CODE",{});var BJt=s(y5e);m6r=r(BJt,"pretrained_model_name_or_path"),BJt.forEach(t),c6r=r(R8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(R8,"CODE",{});var IJt=s(x5e);f6r=r(IJt,"pretrained_model_name_or_path"),IJt.forEach(t),g6r=r(R8,":"),R8.forEach(t),h6r=i(ja),bk=n(ja,"UL",{});var Zro=s(bk);DC=n(Zro,"LI",{});var oWe=s(DC);$5e=n(oWe,"STRONG",{});var NJt=s($5e);u6r=r(NJt,"speech-encoder-decoder"),NJt.forEach(t),p6r=r(oWe," \u2014 "),TZ=n(oWe,"A",{href:!0});var qJt=s(TZ);_6r=r(qJt,"SpeechEncoderDecoderModel"),qJt.forEach(t),b6r=r(oWe," (Speech Encoder decoder model)"),oWe.forEach(t),v6r=i(Zro),GC=n(Zro,"LI",{});var rWe=s(GC);k5e=n(rWe,"STRONG",{});var jJt=s(k5e);F6r=r(jJt,"speech_to_text"),jJt.forEach(t),T6r=r(rWe," \u2014 "),MZ=n(rWe,"A",{href:!0});var DJt=s(MZ);M6r=r(DJt,"Speech2TextForConditionalGeneration"),DJt.forEach(t),E6r=r(rWe," (Speech2Text model)"),rWe.forEach(t),Zro.forEach(t),C6r=i(ja),OC=n(ja,"P",{});var tWe=s(OC);w6r=r(tWe,"The model is set in evaluation mode by default using "),S5e=n(tWe,"CODE",{});var GJt=s(S5e);A6r=r(GJt,"model.eval()"),GJt.forEach(t),L6r=r(tWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R5e=n(tWe,"CODE",{});var OJt=s(R5e);y6r=r(OJt,"model.train()"),OJt.forEach(t),tWe.forEach(t),x6r=i(ja),T(VC.$$.fragment,ja),ja.forEach(t),Ql.forEach(t),jeo=i(c),Cm=n(c,"H2",{class:!0});var eto=s(Cm);XC=n(eto,"A",{id:!0,class:!0,href:!0});var VJt=s(XC);P5e=n(VJt,"SPAN",{});var XJt=s(P5e);T(vk.$$.fragment,XJt),XJt.forEach(t),VJt.forEach(t),$6r=i(eto),B5e=n(eto,"SPAN",{});var zJt=s(B5e);k6r=r(zJt,"AutoModelForAudioXVector"),zJt.forEach(t),eto.forEach(t),Deo=i(c),er=n(c,"DIV",{class:!0});var Wl=s(er);T(Fk.$$.fragment,Wl),S6r=i(Wl),wm=n(Wl,"P",{});var jie=s(wm);R6r=r(jie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),EZ=n(jie,"A",{href:!0});var QJt=s(EZ);P6r=r(QJt,"from_pretrained()"),QJt.forEach(t),B6r=r(jie," class method or the "),CZ=n(jie,"A",{href:!0});var WJt=s(CZ);I6r=r(WJt,"from_config()"),WJt.forEach(t),N6r=r(jie,` class
method.`),jie.forEach(t),q6r=i(Wl),Tk=n(Wl,"P",{});var oto=s(Tk);j6r=r(oto,"This class cannot be instantiated directly using "),I5e=n(oto,"CODE",{});var UJt=s(I5e);D6r=r(UJt,"__init__()"),UJt.forEach(t),G6r=r(oto," (throws an error)."),oto.forEach(t),O6r=i(Wl),qt=n(Wl,"DIV",{class:!0});var P8=s(qt);T(Mk.$$.fragment,P8),V6r=i(P8),N5e=n(P8,"P",{});var HJt=s(N5e);X6r=r(HJt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),HJt.forEach(t),z6r=i(P8),Am=n(P8,"P",{});var Die=s(Am);Q6r=r(Die,`Note:
Loading a model from its configuration file does `),q5e=n(Die,"STRONG",{});var JJt=s(q5e);W6r=r(JJt,"not"),JJt.forEach(t),U6r=r(Die,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Die,"A",{href:!0});var YJt=s(wZ);H6r=r(YJt,"from_pretrained()"),YJt.forEach(t),J6r=r(Die," to load the model weights."),Die.forEach(t),Y6r=i(P8),T(zC.$$.fragment,P8),P8.forEach(t),K6r=i(Wl),Fo=n(Wl,"DIV",{class:!0});var Da=s(Fo);T(Ek.$$.fragment,Da),Z6r=i(Da),j5e=n(Da,"P",{});var KJt=s(j5e);e7r=r(KJt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),KJt.forEach(t),o7r=i(Da),_n=n(Da,"P",{});var B8=s(_n);r7r=r(B8,"The model class to instantiate is selected based on the "),D5e=n(B8,"CODE",{});var ZJt=s(D5e);t7r=r(ZJt,"model_type"),ZJt.forEach(t),a7r=r(B8,` property of the config object (either
passed as an argument or loaded from `),G5e=n(B8,"CODE",{});var eYt=s(G5e);n7r=r(eYt,"pretrained_model_name_or_path"),eYt.forEach(t),s7r=r(B8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O5e=n(B8,"CODE",{});var oYt=s(O5e);l7r=r(oYt,"pretrained_model_name_or_path"),oYt.forEach(t),i7r=r(B8,":"),B8.forEach(t),d7r=i(Da),ft=n(Da,"UL",{});var Ul=s(ft);QC=n(Ul,"LI",{});var aWe=s(QC);V5e=n(aWe,"STRONG",{});var rYt=s(V5e);m7r=r(rYt,"data2vec-audio"),rYt.forEach(t),c7r=r(aWe," \u2014 "),AZ=n(aWe,"A",{href:!0});var tYt=s(AZ);f7r=r(tYt,"Data2VecAudioForXVector"),tYt.forEach(t),g7r=r(aWe," (Data2VecAudio model)"),aWe.forEach(t),h7r=i(Ul),WC=n(Ul,"LI",{});var nWe=s(WC);X5e=n(nWe,"STRONG",{});var aYt=s(X5e);u7r=r(aYt,"unispeech-sat"),aYt.forEach(t),p7r=r(nWe," \u2014 "),LZ=n(nWe,"A",{href:!0});var nYt=s(LZ);_7r=r(nYt,"UniSpeechSatForXVector"),nYt.forEach(t),b7r=r(nWe," (UniSpeechSat model)"),nWe.forEach(t),v7r=i(Ul),UC=n(Ul,"LI",{});var sWe=s(UC);z5e=n(sWe,"STRONG",{});var sYt=s(z5e);F7r=r(sYt,"wav2vec2"),sYt.forEach(t),T7r=r(sWe," \u2014 "),yZ=n(sWe,"A",{href:!0});var lYt=s(yZ);M7r=r(lYt,"Wav2Vec2ForXVector"),lYt.forEach(t),E7r=r(sWe," (Wav2Vec2 model)"),sWe.forEach(t),C7r=i(Ul),HC=n(Ul,"LI",{});var lWe=s(HC);Q5e=n(lWe,"STRONG",{});var iYt=s(Q5e);w7r=r(iYt,"wav2vec2-conformer"),iYt.forEach(t),A7r=r(lWe," \u2014 "),xZ=n(lWe,"A",{href:!0});var dYt=s(xZ);L7r=r(dYt,"Wav2Vec2ConformerForXVector"),dYt.forEach(t),y7r=r(lWe," (Wav2Vec2-Conformer model)"),lWe.forEach(t),x7r=i(Ul),JC=n(Ul,"LI",{});var iWe=s(JC);W5e=n(iWe,"STRONG",{});var mYt=s(W5e);$7r=r(mYt,"wavlm"),mYt.forEach(t),k7r=r(iWe," \u2014 "),$Z=n(iWe,"A",{href:!0});var cYt=s($Z);S7r=r(cYt,"WavLMForXVector"),cYt.forEach(t),R7r=r(iWe," (WavLM model)"),iWe.forEach(t),Ul.forEach(t),P7r=i(Da),YC=n(Da,"P",{});var dWe=s(YC);B7r=r(dWe,"The model is set in evaluation mode by default using "),U5e=n(dWe,"CODE",{});var fYt=s(U5e);I7r=r(fYt,"model.eval()"),fYt.forEach(t),N7r=r(dWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H5e=n(dWe,"CODE",{});var gYt=s(H5e);q7r=r(gYt,"model.train()"),gYt.forEach(t),dWe.forEach(t),j7r=i(Da),T(KC.$$.fragment,Da),Da.forEach(t),Wl.forEach(t),Geo=i(c),Lm=n(c,"H2",{class:!0});var rto=s(Lm);ZC=n(rto,"A",{id:!0,class:!0,href:!0});var hYt=s(ZC);J5e=n(hYt,"SPAN",{});var uYt=s(J5e);T(Ck.$$.fragment,uYt),uYt.forEach(t),hYt.forEach(t),D7r=i(rto),Y5e=n(rto,"SPAN",{});var pYt=s(Y5e);G7r=r(pYt,"AutoModelForMaskedImageModeling"),pYt.forEach(t),rto.forEach(t),Oeo=i(c),or=n(c,"DIV",{class:!0});var Hl=s(or);T(wk.$$.fragment,Hl),O7r=i(Hl),ym=n(Hl,"P",{});var Gie=s(ym);V7r=r(Gie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),kZ=n(Gie,"A",{href:!0});var _Yt=s(kZ);X7r=r(_Yt,"from_pretrained()"),_Yt.forEach(t),z7r=r(Gie," class method or the "),SZ=n(Gie,"A",{href:!0});var bYt=s(SZ);Q7r=r(bYt,"from_config()"),bYt.forEach(t),W7r=r(Gie,` class
method.`),Gie.forEach(t),U7r=i(Hl),Ak=n(Hl,"P",{});var tto=s(Ak);H7r=r(tto,"This class cannot be instantiated directly using "),K5e=n(tto,"CODE",{});var vYt=s(K5e);J7r=r(vYt,"__init__()"),vYt.forEach(t),Y7r=r(tto," (throws an error)."),tto.forEach(t),K7r=i(Hl),jt=n(Hl,"DIV",{class:!0});var I8=s(jt);T(Lk.$$.fragment,I8),Z7r=i(I8),Z5e=n(I8,"P",{});var FYt=s(Z5e);eLr=r(FYt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),FYt.forEach(t),oLr=i(I8),xm=n(I8,"P",{});var Oie=s(xm);rLr=r(Oie,`Note:
Loading a model from its configuration file does `),e0e=n(Oie,"STRONG",{});var TYt=s(e0e);tLr=r(TYt,"not"),TYt.forEach(t),aLr=r(Oie,` load the model weights. It only affects the
model\u2019s configuration. Use `),RZ=n(Oie,"A",{href:!0});var MYt=s(RZ);nLr=r(MYt,"from_pretrained()"),MYt.forEach(t),sLr=r(Oie," to load the model weights."),Oie.forEach(t),lLr=i(I8),T(e3.$$.fragment,I8),I8.forEach(t),iLr=i(Hl),To=n(Hl,"DIV",{class:!0});var Ga=s(To);T(yk.$$.fragment,Ga),dLr=i(Ga),o0e=n(Ga,"P",{});var EYt=s(o0e);mLr=r(EYt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),EYt.forEach(t),cLr=i(Ga),bn=n(Ga,"P",{});var N8=s(bn);fLr=r(N8,"The model class to instantiate is selected based on the "),r0e=n(N8,"CODE",{});var CYt=s(r0e);gLr=r(CYt,"model_type"),CYt.forEach(t),hLr=r(N8,` property of the config object (either
passed as an argument or loaded from `),t0e=n(N8,"CODE",{});var wYt=s(t0e);uLr=r(wYt,"pretrained_model_name_or_path"),wYt.forEach(t),pLr=r(N8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=n(N8,"CODE",{});var AYt=s(a0e);_Lr=r(AYt,"pretrained_model_name_or_path"),AYt.forEach(t),bLr=r(N8,":"),N8.forEach(t),vLr=i(Ga),vn=n(Ga,"UL",{});var q8=s(vn);o3=n(q8,"LI",{});var mWe=s(o3);n0e=n(mWe,"STRONG",{});var LYt=s(n0e);FLr=r(LYt,"deit"),LYt.forEach(t),TLr=r(mWe," \u2014 "),PZ=n(mWe,"A",{href:!0});var yYt=s(PZ);MLr=r(yYt,"DeiTForMaskedImageModeling"),yYt.forEach(t),ELr=r(mWe," (DeiT model)"),mWe.forEach(t),CLr=i(q8),r3=n(q8,"LI",{});var cWe=s(r3);s0e=n(cWe,"STRONG",{});var xYt=s(s0e);wLr=r(xYt,"swin"),xYt.forEach(t),ALr=r(cWe," \u2014 "),BZ=n(cWe,"A",{href:!0});var $Yt=s(BZ);LLr=r($Yt,"SwinForMaskedImageModeling"),$Yt.forEach(t),yLr=r(cWe," (Swin Transformer model)"),cWe.forEach(t),xLr=i(q8),t3=n(q8,"LI",{});var fWe=s(t3);l0e=n(fWe,"STRONG",{});var kYt=s(l0e);$Lr=r(kYt,"swinv2"),kYt.forEach(t),kLr=r(fWe," \u2014 "),IZ=n(fWe,"A",{href:!0});var SYt=s(IZ);SLr=r(SYt,"Swinv2ForMaskedImageModeling"),SYt.forEach(t),RLr=r(fWe," (Swin Transformer V2 model)"),fWe.forEach(t),PLr=i(q8),a3=n(q8,"LI",{});var gWe=s(a3);i0e=n(gWe,"STRONG",{});var RYt=s(i0e);BLr=r(RYt,"vit"),RYt.forEach(t),ILr=r(gWe," \u2014 "),NZ=n(gWe,"A",{href:!0});var PYt=s(NZ);NLr=r(PYt,"ViTForMaskedImageModeling"),PYt.forEach(t),qLr=r(gWe," (ViT model)"),gWe.forEach(t),q8.forEach(t),jLr=i(Ga),n3=n(Ga,"P",{});var hWe=s(n3);DLr=r(hWe,"The model is set in evaluation mode by default using "),d0e=n(hWe,"CODE",{});var BYt=s(d0e);GLr=r(BYt,"model.eval()"),BYt.forEach(t),OLr=r(hWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m0e=n(hWe,"CODE",{});var IYt=s(m0e);VLr=r(IYt,"model.train()"),IYt.forEach(t),hWe.forEach(t),XLr=i(Ga),T(s3.$$.fragment,Ga),Ga.forEach(t),Hl.forEach(t),Veo=i(c),$m=n(c,"H2",{class:!0});var ato=s($m);l3=n(ato,"A",{id:!0,class:!0,href:!0});var NYt=s(l3);c0e=n(NYt,"SPAN",{});var qYt=s(c0e);T(xk.$$.fragment,qYt),qYt.forEach(t),NYt.forEach(t),zLr=i(ato),f0e=n(ato,"SPAN",{});var jYt=s(f0e);QLr=r(jYt,"AutoModelForObjectDetection"),jYt.forEach(t),ato.forEach(t),Xeo=i(c),rr=n(c,"DIV",{class:!0});var Jl=s(rr);T($k.$$.fragment,Jl),WLr=i(Jl),km=n(Jl,"P",{});var Vie=s(km);ULr=r(Vie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),qZ=n(Vie,"A",{href:!0});var DYt=s(qZ);HLr=r(DYt,"from_pretrained()"),DYt.forEach(t),JLr=r(Vie," class method or the "),jZ=n(Vie,"A",{href:!0});var GYt=s(jZ);YLr=r(GYt,"from_config()"),GYt.forEach(t),KLr=r(Vie,` class
method.`),Vie.forEach(t),ZLr=i(Jl),kk=n(Jl,"P",{});var nto=s(kk);eyr=r(nto,"This class cannot be instantiated directly using "),g0e=n(nto,"CODE",{});var OYt=s(g0e);oyr=r(OYt,"__init__()"),OYt.forEach(t),ryr=r(nto," (throws an error)."),nto.forEach(t),tyr=i(Jl),Dt=n(Jl,"DIV",{class:!0});var j8=s(Dt);T(Sk.$$.fragment,j8),ayr=i(j8),h0e=n(j8,"P",{});var VYt=s(h0e);nyr=r(VYt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),VYt.forEach(t),syr=i(j8),Sm=n(j8,"P",{});var Xie=s(Sm);lyr=r(Xie,`Note:
Loading a model from its configuration file does `),u0e=n(Xie,"STRONG",{});var XYt=s(u0e);iyr=r(XYt,"not"),XYt.forEach(t),dyr=r(Xie,` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=n(Xie,"A",{href:!0});var zYt=s(DZ);myr=r(zYt,"from_pretrained()"),zYt.forEach(t),cyr=r(Xie," to load the model weights."),Xie.forEach(t),fyr=i(j8),T(i3.$$.fragment,j8),j8.forEach(t),gyr=i(Jl),Mo=n(Jl,"DIV",{class:!0});var Oa=s(Mo);T(Rk.$$.fragment,Oa),hyr=i(Oa),p0e=n(Oa,"P",{});var QYt=s(p0e);uyr=r(QYt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),QYt.forEach(t),pyr=i(Oa),Fn=n(Oa,"P",{});var D8=s(Fn);_yr=r(D8,"The model class to instantiate is selected based on the "),_0e=n(D8,"CODE",{});var WYt=s(_0e);byr=r(WYt,"model_type"),WYt.forEach(t),vyr=r(D8,` property of the config object (either
passed as an argument or loaded from `),b0e=n(D8,"CODE",{});var UYt=s(b0e);Fyr=r(UYt,"pretrained_model_name_or_path"),UYt.forEach(t),Tyr=r(D8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v0e=n(D8,"CODE",{});var HYt=s(v0e);Myr=r(HYt,"pretrained_model_name_or_path"),HYt.forEach(t),Eyr=r(D8,":"),D8.forEach(t),Cyr=i(Oa),Tn=n(Oa,"UL",{});var G8=s(Tn);d3=n(G8,"LI",{});var uWe=s(d3);F0e=n(uWe,"STRONG",{});var JYt=s(F0e);wyr=r(JYt,"conditional_detr"),JYt.forEach(t),Ayr=r(uWe," \u2014 "),GZ=n(uWe,"A",{href:!0});var YYt=s(GZ);Lyr=r(YYt,"ConditionalDetrForObjectDetection"),YYt.forEach(t),yyr=r(uWe," (Conditional DETR model)"),uWe.forEach(t),xyr=i(G8),m3=n(G8,"LI",{});var pWe=s(m3);T0e=n(pWe,"STRONG",{});var KYt=s(T0e);$yr=r(KYt,"deformable_detr"),KYt.forEach(t),kyr=r(pWe," \u2014 "),OZ=n(pWe,"A",{href:!0});var ZYt=s(OZ);Syr=r(ZYt,"DeformableDetrForObjectDetection"),ZYt.forEach(t),Ryr=r(pWe," (Deformable DETR model)"),pWe.forEach(t),Pyr=i(G8),c3=n(G8,"LI",{});var _We=s(c3);M0e=n(_We,"STRONG",{});var eKt=s(M0e);Byr=r(eKt,"detr"),eKt.forEach(t),Iyr=r(_We," \u2014 "),VZ=n(_We,"A",{href:!0});var oKt=s(VZ);Nyr=r(oKt,"DetrForObjectDetection"),oKt.forEach(t),qyr=r(_We," (DETR model)"),_We.forEach(t),jyr=i(G8),f3=n(G8,"LI",{});var bWe=s(f3);E0e=n(bWe,"STRONG",{});var rKt=s(E0e);Dyr=r(rKt,"yolos"),rKt.forEach(t),Gyr=r(bWe," \u2014 "),XZ=n(bWe,"A",{href:!0});var tKt=s(XZ);Oyr=r(tKt,"YolosForObjectDetection"),tKt.forEach(t),Vyr=r(bWe," (YOLOS model)"),bWe.forEach(t),G8.forEach(t),Xyr=i(Oa),g3=n(Oa,"P",{});var vWe=s(g3);zyr=r(vWe,"The model is set in evaluation mode by default using "),C0e=n(vWe,"CODE",{});var aKt=s(C0e);Qyr=r(aKt,"model.eval()"),aKt.forEach(t),Wyr=r(vWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w0e=n(vWe,"CODE",{});var nKt=s(w0e);Uyr=r(nKt,"model.train()"),nKt.forEach(t),vWe.forEach(t),Hyr=i(Oa),T(h3.$$.fragment,Oa),Oa.forEach(t),Jl.forEach(t),zeo=i(c),Rm=n(c,"H2",{class:!0});var sto=s(Rm);u3=n(sto,"A",{id:!0,class:!0,href:!0});var sKt=s(u3);A0e=n(sKt,"SPAN",{});var lKt=s(A0e);T(Pk.$$.fragment,lKt),lKt.forEach(t),sKt.forEach(t),Jyr=i(sto),L0e=n(sto,"SPAN",{});var iKt=s(L0e);Yyr=r(iKt,"AutoModelForImageSegmentation"),iKt.forEach(t),sto.forEach(t),Qeo=i(c),tr=n(c,"DIV",{class:!0});var Yl=s(tr);T(Bk.$$.fragment,Yl),Kyr=i(Yl),Pm=n(Yl,"P",{});var zie=s(Pm);Zyr=r(zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),zZ=n(zie,"A",{href:!0});var dKt=s(zZ);e8r=r(dKt,"from_pretrained()"),dKt.forEach(t),o8r=r(zie," class method or the "),QZ=n(zie,"A",{href:!0});var mKt=s(QZ);r8r=r(mKt,"from_config()"),mKt.forEach(t),t8r=r(zie,` class
method.`),zie.forEach(t),a8r=i(Yl),Ik=n(Yl,"P",{});var lto=s(Ik);n8r=r(lto,"This class cannot be instantiated directly using "),y0e=n(lto,"CODE",{});var cKt=s(y0e);s8r=r(cKt,"__init__()"),cKt.forEach(t),l8r=r(lto," (throws an error)."),lto.forEach(t),i8r=i(Yl),Gt=n(Yl,"DIV",{class:!0});var O8=s(Gt);T(Nk.$$.fragment,O8),d8r=i(O8),x0e=n(O8,"P",{});var fKt=s(x0e);m8r=r(fKt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),fKt.forEach(t),c8r=i(O8),Bm=n(O8,"P",{});var Qie=s(Bm);f8r=r(Qie,`Note:
Loading a model from its configuration file does `),$0e=n(Qie,"STRONG",{});var gKt=s($0e);g8r=r(gKt,"not"),gKt.forEach(t),h8r=r(Qie,` load the model weights. It only affects the
model\u2019s configuration. Use `),WZ=n(Qie,"A",{href:!0});var hKt=s(WZ);u8r=r(hKt,"from_pretrained()"),hKt.forEach(t),p8r=r(Qie," to load the model weights."),Qie.forEach(t),_8r=i(O8),T(p3.$$.fragment,O8),O8.forEach(t),b8r=i(Yl),Eo=n(Yl,"DIV",{class:!0});var Va=s(Eo);T(qk.$$.fragment,Va),v8r=i(Va),k0e=n(Va,"P",{});var uKt=s(k0e);F8r=r(uKt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),uKt.forEach(t),T8r=i(Va),Mn=n(Va,"P",{});var V8=s(Mn);M8r=r(V8,"The model class to instantiate is selected based on the "),S0e=n(V8,"CODE",{});var pKt=s(S0e);E8r=r(pKt,"model_type"),pKt.forEach(t),C8r=r(V8,` property of the config object (either
passed as an argument or loaded from `),R0e=n(V8,"CODE",{});var _Kt=s(R0e);w8r=r(_Kt,"pretrained_model_name_or_path"),_Kt.forEach(t),A8r=r(V8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P0e=n(V8,"CODE",{});var bKt=s(P0e);L8r=r(bKt,"pretrained_model_name_or_path"),bKt.forEach(t),y8r=r(V8,":"),V8.forEach(t),x8r=i(Va),B0e=n(Va,"UL",{});var vKt=s(B0e);_3=n(vKt,"LI",{});var FWe=s(_3);I0e=n(FWe,"STRONG",{});var FKt=s(I0e);$8r=r(FKt,"detr"),FKt.forEach(t),k8r=r(FWe," \u2014 "),UZ=n(FWe,"A",{href:!0});var TKt=s(UZ);S8r=r(TKt,"DetrForSegmentation"),TKt.forEach(t),R8r=r(FWe," (DETR model)"),FWe.forEach(t),vKt.forEach(t),P8r=i(Va),b3=n(Va,"P",{});var TWe=s(b3);B8r=r(TWe,"The model is set in evaluation mode by default using "),N0e=n(TWe,"CODE",{});var MKt=s(N0e);I8r=r(MKt,"model.eval()"),MKt.forEach(t),N8r=r(TWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q0e=n(TWe,"CODE",{});var EKt=s(q0e);q8r=r(EKt,"model.train()"),EKt.forEach(t),TWe.forEach(t),j8r=i(Va),T(v3.$$.fragment,Va),Va.forEach(t),Yl.forEach(t),Weo=i(c),Im=n(c,"H2",{class:!0});var ito=s(Im);F3=n(ito,"A",{id:!0,class:!0,href:!0});var CKt=s(F3);j0e=n(CKt,"SPAN",{});var wKt=s(j0e);T(jk.$$.fragment,wKt),wKt.forEach(t),CKt.forEach(t),D8r=i(ito),D0e=n(ito,"SPAN",{});var AKt=s(D0e);G8r=r(AKt,"AutoModelForSemanticSegmentation"),AKt.forEach(t),ito.forEach(t),Ueo=i(c),ar=n(c,"DIV",{class:!0});var Kl=s(ar);T(Dk.$$.fragment,Kl),O8r=i(Kl),Nm=n(Kl,"P",{});var Wie=s(Nm);V8r=r(Wie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),HZ=n(Wie,"A",{href:!0});var LKt=s(HZ);X8r=r(LKt,"from_pretrained()"),LKt.forEach(t),z8r=r(Wie," class method or the "),JZ=n(Wie,"A",{href:!0});var yKt=s(JZ);Q8r=r(yKt,"from_config()"),yKt.forEach(t),W8r=r(Wie,` class
method.`),Wie.forEach(t),U8r=i(Kl),Gk=n(Kl,"P",{});var dto=s(Gk);H8r=r(dto,"This class cannot be instantiated directly using "),G0e=n(dto,"CODE",{});var xKt=s(G0e);J8r=r(xKt,"__init__()"),xKt.forEach(t),Y8r=r(dto," (throws an error)."),dto.forEach(t),K8r=i(Kl),Ot=n(Kl,"DIV",{class:!0});var X8=s(Ot);T(Ok.$$.fragment,X8),Z8r=i(X8),O0e=n(X8,"P",{});var $Kt=s(O0e);e9r=r($Kt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),$Kt.forEach(t),o9r=i(X8),qm=n(X8,"P",{});var Uie=s(qm);r9r=r(Uie,`Note:
Loading a model from its configuration file does `),V0e=n(Uie,"STRONG",{});var kKt=s(V0e);t9r=r(kKt,"not"),kKt.forEach(t),a9r=r(Uie,` load the model weights. It only affects the
model\u2019s configuration. Use `),YZ=n(Uie,"A",{href:!0});var SKt=s(YZ);n9r=r(SKt,"from_pretrained()"),SKt.forEach(t),s9r=r(Uie," to load the model weights."),Uie.forEach(t),l9r=i(X8),T(T3.$$.fragment,X8),X8.forEach(t),i9r=i(Kl),Co=n(Kl,"DIV",{class:!0});var Xa=s(Co);T(Vk.$$.fragment,Xa),d9r=i(Xa),X0e=n(Xa,"P",{});var RKt=s(X0e);m9r=r(RKt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),RKt.forEach(t),c9r=i(Xa),En=n(Xa,"P",{});var z8=s(En);f9r=r(z8,"The model class to instantiate is selected based on the "),z0e=n(z8,"CODE",{});var PKt=s(z0e);g9r=r(PKt,"model_type"),PKt.forEach(t),h9r=r(z8,` property of the config object (either
passed as an argument or loaded from `),Q0e=n(z8,"CODE",{});var BKt=s(Q0e);u9r=r(BKt,"pretrained_model_name_or_path"),BKt.forEach(t),p9r=r(z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W0e=n(z8,"CODE",{});var IKt=s(W0e);_9r=r(IKt,"pretrained_model_name_or_path"),IKt.forEach(t),b9r=r(z8,":"),z8.forEach(t),v9r=i(Xa),gt=n(Xa,"UL",{});var Zl=s(gt);M3=n(Zl,"LI",{});var MWe=s(M3);U0e=n(MWe,"STRONG",{});var NKt=s(U0e);F9r=r(NKt,"beit"),NKt.forEach(t),T9r=r(MWe," \u2014 "),KZ=n(MWe,"A",{href:!0});var qKt=s(KZ);M9r=r(qKt,"BeitForSemanticSegmentation"),qKt.forEach(t),E9r=r(MWe," (BEiT model)"),MWe.forEach(t),C9r=i(Zl),E3=n(Zl,"LI",{});var EWe=s(E3);H0e=n(EWe,"STRONG",{});var jKt=s(H0e);w9r=r(jKt,"data2vec-vision"),jKt.forEach(t),A9r=r(EWe," \u2014 "),ZZ=n(EWe,"A",{href:!0});var DKt=s(ZZ);L9r=r(DKt,"Data2VecVisionForSemanticSegmentation"),DKt.forEach(t),y9r=r(EWe," (Data2VecVision model)"),EWe.forEach(t),x9r=i(Zl),C3=n(Zl,"LI",{});var CWe=s(C3);J0e=n(CWe,"STRONG",{});var GKt=s(J0e);$9r=r(GKt,"dpt"),GKt.forEach(t),k9r=r(CWe," \u2014 "),eee=n(CWe,"A",{href:!0});var OKt=s(eee);S9r=r(OKt,"DPTForSemanticSegmentation"),OKt.forEach(t),R9r=r(CWe," (DPT model)"),CWe.forEach(t),P9r=i(Zl),w3=n(Zl,"LI",{});var wWe=s(w3);Y0e=n(wWe,"STRONG",{});var VKt=s(Y0e);B9r=r(VKt,"mobilevit"),VKt.forEach(t),I9r=r(wWe," \u2014 "),oee=n(wWe,"A",{href:!0});var XKt=s(oee);N9r=r(XKt,"MobileViTForSemanticSegmentation"),XKt.forEach(t),q9r=r(wWe," (MobileViT model)"),wWe.forEach(t),j9r=i(Zl),A3=n(Zl,"LI",{});var AWe=s(A3);K0e=n(AWe,"STRONG",{});var zKt=s(K0e);D9r=r(zKt,"segformer"),zKt.forEach(t),G9r=r(AWe," \u2014 "),ree=n(AWe,"A",{href:!0});var QKt=s(ree);O9r=r(QKt,"SegformerForSemanticSegmentation"),QKt.forEach(t),V9r=r(AWe," (SegFormer model)"),AWe.forEach(t),Zl.forEach(t),X9r=i(Xa),L3=n(Xa,"P",{});var LWe=s(L3);z9r=r(LWe,"The model is set in evaluation mode by default using "),Z0e=n(LWe,"CODE",{});var WKt=s(Z0e);Q9r=r(WKt,"model.eval()"),WKt.forEach(t),W9r=r(LWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ewe=n(LWe,"CODE",{});var UKt=s(ewe);U9r=r(UKt,"model.train()"),UKt.forEach(t),LWe.forEach(t),H9r=i(Xa),T(y3.$$.fragment,Xa),Xa.forEach(t),Kl.forEach(t),Heo=i(c),jm=n(c,"H2",{class:!0});var mto=s(jm);x3=n(mto,"A",{id:!0,class:!0,href:!0});var HKt=s(x3);owe=n(HKt,"SPAN",{});var JKt=s(owe);T(Xk.$$.fragment,JKt),JKt.forEach(t),HKt.forEach(t),J9r=i(mto),rwe=n(mto,"SPAN",{});var YKt=s(rwe);Y9r=r(YKt,"AutoModelForInstanceSegmentation"),YKt.forEach(t),mto.forEach(t),Jeo=i(c),nr=n(c,"DIV",{class:!0});var ei=s(nr);T(zk.$$.fragment,ei),K9r=i(ei),Dm=n(ei,"P",{});var Hie=s(Dm);Z9r=r(Hie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),tee=n(Hie,"A",{href:!0});var KKt=s(tee);exr=r(KKt,"from_pretrained()"),KKt.forEach(t),oxr=r(Hie," class method or the "),aee=n(Hie,"A",{href:!0});var ZKt=s(aee);rxr=r(ZKt,"from_config()"),ZKt.forEach(t),txr=r(Hie,` class
method.`),Hie.forEach(t),axr=i(ei),Qk=n(ei,"P",{});var cto=s(Qk);nxr=r(cto,"This class cannot be instantiated directly using "),twe=n(cto,"CODE",{});var eZt=s(twe);sxr=r(eZt,"__init__()"),eZt.forEach(t),lxr=r(cto," (throws an error)."),cto.forEach(t),ixr=i(ei),Vt=n(ei,"DIV",{class:!0});var Q8=s(Vt);T(Wk.$$.fragment,Q8),dxr=i(Q8),awe=n(Q8,"P",{});var oZt=s(awe);mxr=r(oZt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),oZt.forEach(t),cxr=i(Q8),Gm=n(Q8,"P",{});var Jie=s(Gm);fxr=r(Jie,`Note:
Loading a model from its configuration file does `),nwe=n(Jie,"STRONG",{});var rZt=s(nwe);gxr=r(rZt,"not"),rZt.forEach(t),hxr=r(Jie,` load the model weights. It only affects the
model\u2019s configuration. Use `),nee=n(Jie,"A",{href:!0});var tZt=s(nee);uxr=r(tZt,"from_pretrained()"),tZt.forEach(t),pxr=r(Jie," to load the model weights."),Jie.forEach(t),_xr=i(Q8),T($3.$$.fragment,Q8),Q8.forEach(t),bxr=i(ei),wo=n(ei,"DIV",{class:!0});var za=s(wo);T(Uk.$$.fragment,za),vxr=i(za),swe=n(za,"P",{});var aZt=s(swe);Fxr=r(aZt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),aZt.forEach(t),Txr=i(za),Cn=n(za,"P",{});var W8=s(Cn);Mxr=r(W8,"The model class to instantiate is selected based on the "),lwe=n(W8,"CODE",{});var nZt=s(lwe);Exr=r(nZt,"model_type"),nZt.forEach(t),Cxr=r(W8,` property of the config object (either
passed as an argument or loaded from `),iwe=n(W8,"CODE",{});var sZt=s(iwe);wxr=r(sZt,"pretrained_model_name_or_path"),sZt.forEach(t),Axr=r(W8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=n(W8,"CODE",{});var lZt=s(dwe);Lxr=r(lZt,"pretrained_model_name_or_path"),lZt.forEach(t),yxr=r(W8,":"),W8.forEach(t),xxr=i(za),mwe=n(za,"UL",{});var iZt=s(mwe);k3=n(iZt,"LI",{});var yWe=s(k3);cwe=n(yWe,"STRONG",{});var dZt=s(cwe);$xr=r(dZt,"maskformer"),dZt.forEach(t),kxr=r(yWe," \u2014 "),see=n(yWe,"A",{href:!0});var mZt=s(see);Sxr=r(mZt,"MaskFormerForInstanceSegmentation"),mZt.forEach(t),Rxr=r(yWe," (MaskFormer model)"),yWe.forEach(t),iZt.forEach(t),Pxr=i(za),S3=n(za,"P",{});var xWe=s(S3);Bxr=r(xWe,"The model is set in evaluation mode by default using "),fwe=n(xWe,"CODE",{});var cZt=s(fwe);Ixr=r(cZt,"model.eval()"),cZt.forEach(t),Nxr=r(xWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gwe=n(xWe,"CODE",{});var fZt=s(gwe);qxr=r(fZt,"model.train()"),fZt.forEach(t),xWe.forEach(t),jxr=i(za),T(R3.$$.fragment,za),za.forEach(t),ei.forEach(t),Yeo=i(c),Om=n(c,"H2",{class:!0});var fto=s(Om);P3=n(fto,"A",{id:!0,class:!0,href:!0});var gZt=s(P3);hwe=n(gZt,"SPAN",{});var hZt=s(hwe);T(Hk.$$.fragment,hZt),hZt.forEach(t),gZt.forEach(t),Dxr=i(fto),uwe=n(fto,"SPAN",{});var uZt=s(uwe);Gxr=r(uZt,"TFAutoModel"),uZt.forEach(t),fto.forEach(t),Keo=i(c),sr=n(c,"DIV",{class:!0});var oi=s(sr);T(Jk.$$.fragment,oi),Oxr=i(oi),Vm=n(oi,"P",{});var Yie=s(Vm);Vxr=r(Yie,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),lee=n(Yie,"A",{href:!0});var pZt=s(lee);Xxr=r(pZt,"from_pretrained()"),pZt.forEach(t),zxr=r(Yie," class method or the "),iee=n(Yie,"A",{href:!0});var _Zt=s(iee);Qxr=r(_Zt,"from_config()"),_Zt.forEach(t),Wxr=r(Yie,` class
method.`),Yie.forEach(t),Uxr=i(oi),Yk=n(oi,"P",{});var gto=s(Yk);Hxr=r(gto,"This class cannot be instantiated directly using "),pwe=n(gto,"CODE",{});var bZt=s(pwe);Jxr=r(bZt,"__init__()"),bZt.forEach(t),Yxr=r(gto," (throws an error)."),gto.forEach(t),Kxr=i(oi),Xt=n(oi,"DIV",{class:!0});var U8=s(Xt);T(Kk.$$.fragment,U8),Zxr=i(U8),_we=n(U8,"P",{});var vZt=s(_we);e$r=r(vZt,"Instantiates one of the base model classes of the library from a configuration."),vZt.forEach(t),o$r=i(U8),Xm=n(U8,"P",{});var Kie=s(Xm);r$r=r(Kie,`Note:
Loading a model from its configuration file does `),bwe=n(Kie,"STRONG",{});var FZt=s(bwe);t$r=r(FZt,"not"),FZt.forEach(t),a$r=r(Kie,` load the model weights. It only affects the
model\u2019s configuration. Use `),dee=n(Kie,"A",{href:!0});var TZt=s(dee);n$r=r(TZt,"from_pretrained()"),TZt.forEach(t),s$r=r(Kie," to load the model weights."),Kie.forEach(t),l$r=i(U8),T(B3.$$.fragment,U8),U8.forEach(t),i$r=i(oi),Ir=n(oi,"DIV",{class:!0});var ri=s(Ir);T(Zk.$$.fragment,ri),d$r=i(ri),vwe=n(ri,"P",{});var MZt=s(vwe);m$r=r(MZt,"Instantiate one of the base model classes of the library from a pretrained model."),MZt.forEach(t),c$r=i(ri),wn=n(ri,"P",{});var H8=s(wn);f$r=r(H8,"The model class to instantiate is selected based on the "),Fwe=n(H8,"CODE",{});var EZt=s(Fwe);g$r=r(EZt,"model_type"),EZt.forEach(t),h$r=r(H8,` property of the config object (either
passed as an argument or loaded from `),Twe=n(H8,"CODE",{});var CZt=s(Twe);u$r=r(CZt,"pretrained_model_name_or_path"),CZt.forEach(t),p$r=r(H8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mwe=n(H8,"CODE",{});var wZt=s(Mwe);_$r=r(wZt,"pretrained_model_name_or_path"),wZt.forEach(t),b$r=r(H8,":"),H8.forEach(t),v$r=i(ri),I=n(ri,"UL",{});var D=s(I);I3=n(D,"LI",{});var $We=s(I3);Ewe=n($We,"STRONG",{});var AZt=s(Ewe);F$r=r(AZt,"albert"),AZt.forEach(t),T$r=r($We," \u2014 "),mee=n($We,"A",{href:!0});var LZt=s(mee);M$r=r(LZt,"TFAlbertModel"),LZt.forEach(t),E$r=r($We," (ALBERT model)"),$We.forEach(t),C$r=i(D),N3=n(D,"LI",{});var kWe=s(N3);Cwe=n(kWe,"STRONG",{});var yZt=s(Cwe);w$r=r(yZt,"bart"),yZt.forEach(t),A$r=r(kWe," \u2014 "),cee=n(kWe,"A",{href:!0});var xZt=s(cee);L$r=r(xZt,"TFBartModel"),xZt.forEach(t),y$r=r(kWe," (BART model)"),kWe.forEach(t),x$r=i(D),q3=n(D,"LI",{});var SWe=s(q3);wwe=n(SWe,"STRONG",{});var $Zt=s(wwe);$$r=r($Zt,"bert"),$Zt.forEach(t),k$r=r(SWe," \u2014 "),fee=n(SWe,"A",{href:!0});var kZt=s(fee);S$r=r(kZt,"TFBertModel"),kZt.forEach(t),R$r=r(SWe," (BERT model)"),SWe.forEach(t),P$r=i(D),j3=n(D,"LI",{});var RWe=s(j3);Awe=n(RWe,"STRONG",{});var SZt=s(Awe);B$r=r(SZt,"blenderbot"),SZt.forEach(t),I$r=r(RWe," \u2014 "),gee=n(RWe,"A",{href:!0});var RZt=s(gee);N$r=r(RZt,"TFBlenderbotModel"),RZt.forEach(t),q$r=r(RWe," (Blenderbot model)"),RWe.forEach(t),j$r=i(D),D3=n(D,"LI",{});var PWe=s(D3);Lwe=n(PWe,"STRONG",{});var PZt=s(Lwe);D$r=r(PZt,"blenderbot-small"),PZt.forEach(t),G$r=r(PWe," \u2014 "),hee=n(PWe,"A",{href:!0});var BZt=s(hee);O$r=r(BZt,"TFBlenderbotSmallModel"),BZt.forEach(t),V$r=r(PWe," (BlenderbotSmall model)"),PWe.forEach(t),X$r=i(D),G3=n(D,"LI",{});var BWe=s(G3);ywe=n(BWe,"STRONG",{});var IZt=s(ywe);z$r=r(IZt,"camembert"),IZt.forEach(t),Q$r=r(BWe," \u2014 "),uee=n(BWe,"A",{href:!0});var NZt=s(uee);W$r=r(NZt,"TFCamembertModel"),NZt.forEach(t),U$r=r(BWe," (CamemBERT model)"),BWe.forEach(t),H$r=i(D),O3=n(D,"LI",{});var IWe=s(O3);xwe=n(IWe,"STRONG",{});var qZt=s(xwe);J$r=r(qZt,"clip"),qZt.forEach(t),Y$r=r(IWe," \u2014 "),pee=n(IWe,"A",{href:!0});var jZt=s(pee);K$r=r(jZt,"TFCLIPModel"),jZt.forEach(t),Z$r=r(IWe," (CLIP model)"),IWe.forEach(t),ekr=i(D),V3=n(D,"LI",{});var NWe=s(V3);$we=n(NWe,"STRONG",{});var DZt=s($we);okr=r(DZt,"convbert"),DZt.forEach(t),rkr=r(NWe," \u2014 "),_ee=n(NWe,"A",{href:!0});var GZt=s(_ee);tkr=r(GZt,"TFConvBertModel"),GZt.forEach(t),akr=r(NWe," (ConvBERT model)"),NWe.forEach(t),nkr=i(D),X3=n(D,"LI",{});var qWe=s(X3);kwe=n(qWe,"STRONG",{});var OZt=s(kwe);skr=r(OZt,"convnext"),OZt.forEach(t),lkr=r(qWe," \u2014 "),bee=n(qWe,"A",{href:!0});var VZt=s(bee);ikr=r(VZt,"TFConvNextModel"),VZt.forEach(t),dkr=r(qWe," (ConvNeXT model)"),qWe.forEach(t),mkr=i(D),z3=n(D,"LI",{});var jWe=s(z3);Swe=n(jWe,"STRONG",{});var XZt=s(Swe);ckr=r(XZt,"ctrl"),XZt.forEach(t),fkr=r(jWe," \u2014 "),vee=n(jWe,"A",{href:!0});var zZt=s(vee);gkr=r(zZt,"TFCTRLModel"),zZt.forEach(t),hkr=r(jWe," (CTRL model)"),jWe.forEach(t),ukr=i(D),Q3=n(D,"LI",{});var DWe=s(Q3);Rwe=n(DWe,"STRONG",{});var QZt=s(Rwe);pkr=r(QZt,"data2vec-vision"),QZt.forEach(t),_kr=r(DWe," \u2014 "),Fee=n(DWe,"A",{href:!0});var WZt=s(Fee);bkr=r(WZt,"TFData2VecVisionModel"),WZt.forEach(t),vkr=r(DWe," (Data2VecVision model)"),DWe.forEach(t),Fkr=i(D),W3=n(D,"LI",{});var GWe=s(W3);Pwe=n(GWe,"STRONG",{});var UZt=s(Pwe);Tkr=r(UZt,"deberta"),UZt.forEach(t),Mkr=r(GWe," \u2014 "),Tee=n(GWe,"A",{href:!0});var HZt=s(Tee);Ekr=r(HZt,"TFDebertaModel"),HZt.forEach(t),Ckr=r(GWe," (DeBERTa model)"),GWe.forEach(t),wkr=i(D),U3=n(D,"LI",{});var OWe=s(U3);Bwe=n(OWe,"STRONG",{});var JZt=s(Bwe);Akr=r(JZt,"deberta-v2"),JZt.forEach(t),Lkr=r(OWe," \u2014 "),Mee=n(OWe,"A",{href:!0});var YZt=s(Mee);ykr=r(YZt,"TFDebertaV2Model"),YZt.forEach(t),xkr=r(OWe," (DeBERTa-v2 model)"),OWe.forEach(t),$kr=i(D),H3=n(D,"LI",{});var VWe=s(H3);Iwe=n(VWe,"STRONG",{});var KZt=s(Iwe);kkr=r(KZt,"deit"),KZt.forEach(t),Skr=r(VWe," \u2014 "),Eee=n(VWe,"A",{href:!0});var ZZt=s(Eee);Rkr=r(ZZt,"TFDeiTModel"),ZZt.forEach(t),Pkr=r(VWe," (DeiT model)"),VWe.forEach(t),Bkr=i(D),J3=n(D,"LI",{});var XWe=s(J3);Nwe=n(XWe,"STRONG",{});var eea=s(Nwe);Ikr=r(eea,"distilbert"),eea.forEach(t),Nkr=r(XWe," \u2014 "),Cee=n(XWe,"A",{href:!0});var oea=s(Cee);qkr=r(oea,"TFDistilBertModel"),oea.forEach(t),jkr=r(XWe," (DistilBERT model)"),XWe.forEach(t),Dkr=i(D),Y3=n(D,"LI",{});var zWe=s(Y3);qwe=n(zWe,"STRONG",{});var rea=s(qwe);Gkr=r(rea,"dpr"),rea.forEach(t),Okr=r(zWe," \u2014 "),wee=n(zWe,"A",{href:!0});var tea=s(wee);Vkr=r(tea,"TFDPRQuestionEncoder"),tea.forEach(t),Xkr=r(zWe," (DPR model)"),zWe.forEach(t),zkr=i(D),K3=n(D,"LI",{});var QWe=s(K3);jwe=n(QWe,"STRONG",{});var aea=s(jwe);Qkr=r(aea,"electra"),aea.forEach(t),Wkr=r(QWe," \u2014 "),Aee=n(QWe,"A",{href:!0});var nea=s(Aee);Ukr=r(nea,"TFElectraModel"),nea.forEach(t),Hkr=r(QWe," (ELECTRA model)"),QWe.forEach(t),Jkr=i(D),Z3=n(D,"LI",{});var WWe=s(Z3);Dwe=n(WWe,"STRONG",{});var sea=s(Dwe);Ykr=r(sea,"flaubert"),sea.forEach(t),Kkr=r(WWe," \u2014 "),Lee=n(WWe,"A",{href:!0});var lea=s(Lee);Zkr=r(lea,"TFFlaubertModel"),lea.forEach(t),eSr=r(WWe," (FlauBERT model)"),WWe.forEach(t),oSr=i(D),Fl=n(D,"LI",{});var KB=s(Fl);Gwe=n(KB,"STRONG",{});var iea=s(Gwe);rSr=r(iea,"funnel"),iea.forEach(t),tSr=r(KB," \u2014 "),yee=n(KB,"A",{href:!0});var dea=s(yee);aSr=r(dea,"TFFunnelModel"),dea.forEach(t),nSr=r(KB," or "),xee=n(KB,"A",{href:!0});var mea=s(xee);sSr=r(mea,"TFFunnelBaseModel"),mea.forEach(t),lSr=r(KB," (Funnel Transformer model)"),KB.forEach(t),iSr=i(D),e5=n(D,"LI",{});var UWe=s(e5);Owe=n(UWe,"STRONG",{});var cea=s(Owe);dSr=r(cea,"gpt2"),cea.forEach(t),mSr=r(UWe," \u2014 "),$ee=n(UWe,"A",{href:!0});var fea=s($ee);cSr=r(fea,"TFGPT2Model"),fea.forEach(t),fSr=r(UWe," (OpenAI GPT-2 model)"),UWe.forEach(t),gSr=i(D),o5=n(D,"LI",{});var HWe=s(o5);Vwe=n(HWe,"STRONG",{});var gea=s(Vwe);hSr=r(gea,"gptj"),gea.forEach(t),uSr=r(HWe," \u2014 "),kee=n(HWe,"A",{href:!0});var hea=s(kee);pSr=r(hea,"TFGPTJModel"),hea.forEach(t),_Sr=r(HWe," (GPT-J model)"),HWe.forEach(t),bSr=i(D),r5=n(D,"LI",{});var JWe=s(r5);Xwe=n(JWe,"STRONG",{});var uea=s(Xwe);vSr=r(uea,"groupvit"),uea.forEach(t),FSr=r(JWe," \u2014 "),See=n(JWe,"A",{href:!0});var pea=s(See);TSr=r(pea,"TFGroupViTModel"),pea.forEach(t),MSr=r(JWe," (GroupViT model)"),JWe.forEach(t),ESr=i(D),t5=n(D,"LI",{});var YWe=s(t5);zwe=n(YWe,"STRONG",{});var _ea=s(zwe);CSr=r(_ea,"hubert"),_ea.forEach(t),wSr=r(YWe," \u2014 "),Ree=n(YWe,"A",{href:!0});var bea=s(Ree);ASr=r(bea,"TFHubertModel"),bea.forEach(t),LSr=r(YWe," (Hubert model)"),YWe.forEach(t),ySr=i(D),a5=n(D,"LI",{});var KWe=s(a5);Qwe=n(KWe,"STRONG",{});var vea=s(Qwe);xSr=r(vea,"layoutlm"),vea.forEach(t),$Sr=r(KWe," \u2014 "),Pee=n(KWe,"A",{href:!0});var Fea=s(Pee);kSr=r(Fea,"TFLayoutLMModel"),Fea.forEach(t),SSr=r(KWe," (LayoutLM model)"),KWe.forEach(t),RSr=i(D),n5=n(D,"LI",{});var ZWe=s(n5);Wwe=n(ZWe,"STRONG",{});var Tea=s(Wwe);PSr=r(Tea,"layoutlmv3"),Tea.forEach(t),BSr=r(ZWe," \u2014 "),Bee=n(ZWe,"A",{href:!0});var Mea=s(Bee);ISr=r(Mea,"TFLayoutLMv3Model"),Mea.forEach(t),NSr=r(ZWe," (LayoutLMv3 model)"),ZWe.forEach(t),qSr=i(D),s5=n(D,"LI",{});var eUe=s(s5);Uwe=n(eUe,"STRONG",{});var Eea=s(Uwe);jSr=r(Eea,"led"),Eea.forEach(t),DSr=r(eUe," \u2014 "),Iee=n(eUe,"A",{href:!0});var Cea=s(Iee);GSr=r(Cea,"TFLEDModel"),Cea.forEach(t),OSr=r(eUe," (LED model)"),eUe.forEach(t),VSr=i(D),l5=n(D,"LI",{});var oUe=s(l5);Hwe=n(oUe,"STRONG",{});var wea=s(Hwe);XSr=r(wea,"longformer"),wea.forEach(t),zSr=r(oUe," \u2014 "),Nee=n(oUe,"A",{href:!0});var Aea=s(Nee);QSr=r(Aea,"TFLongformerModel"),Aea.forEach(t),WSr=r(oUe," (Longformer model)"),oUe.forEach(t),USr=i(D),i5=n(D,"LI",{});var rUe=s(i5);Jwe=n(rUe,"STRONG",{});var Lea=s(Jwe);HSr=r(Lea,"lxmert"),Lea.forEach(t),JSr=r(rUe," \u2014 "),qee=n(rUe,"A",{href:!0});var yea=s(qee);YSr=r(yea,"TFLxmertModel"),yea.forEach(t),KSr=r(rUe," (LXMERT model)"),rUe.forEach(t),ZSr=i(D),d5=n(D,"LI",{});var tUe=s(d5);Ywe=n(tUe,"STRONG",{});var xea=s(Ywe);eRr=r(xea,"marian"),xea.forEach(t),oRr=r(tUe," \u2014 "),jee=n(tUe,"A",{href:!0});var $ea=s(jee);rRr=r($ea,"TFMarianModel"),$ea.forEach(t),tRr=r(tUe," (Marian model)"),tUe.forEach(t),aRr=i(D),m5=n(D,"LI",{});var aUe=s(m5);Kwe=n(aUe,"STRONG",{});var kea=s(Kwe);nRr=r(kea,"mbart"),kea.forEach(t),sRr=r(aUe," \u2014 "),Dee=n(aUe,"A",{href:!0});var Sea=s(Dee);lRr=r(Sea,"TFMBartModel"),Sea.forEach(t),iRr=r(aUe," (mBART model)"),aUe.forEach(t),dRr=i(D),c5=n(D,"LI",{});var nUe=s(c5);Zwe=n(nUe,"STRONG",{});var Rea=s(Zwe);mRr=r(Rea,"mobilebert"),Rea.forEach(t),cRr=r(nUe," \u2014 "),Gee=n(nUe,"A",{href:!0});var Pea=s(Gee);fRr=r(Pea,"TFMobileBertModel"),Pea.forEach(t),gRr=r(nUe," (MobileBERT model)"),nUe.forEach(t),hRr=i(D),f5=n(D,"LI",{});var sUe=s(f5);eAe=n(sUe,"STRONG",{});var Bea=s(eAe);uRr=r(Bea,"mobilevit"),Bea.forEach(t),pRr=r(sUe," \u2014 "),Oee=n(sUe,"A",{href:!0});var Iea=s(Oee);_Rr=r(Iea,"TFMobileViTModel"),Iea.forEach(t),bRr=r(sUe," (MobileViT model)"),sUe.forEach(t),vRr=i(D),g5=n(D,"LI",{});var lUe=s(g5);oAe=n(lUe,"STRONG",{});var Nea=s(oAe);FRr=r(Nea,"mpnet"),Nea.forEach(t),TRr=r(lUe," \u2014 "),Vee=n(lUe,"A",{href:!0});var qea=s(Vee);MRr=r(qea,"TFMPNetModel"),qea.forEach(t),ERr=r(lUe," (MPNet model)"),lUe.forEach(t),CRr=i(D),h5=n(D,"LI",{});var iUe=s(h5);rAe=n(iUe,"STRONG",{});var jea=s(rAe);wRr=r(jea,"mt5"),jea.forEach(t),ARr=r(iUe," \u2014 "),Xee=n(iUe,"A",{href:!0});var Dea=s(Xee);LRr=r(Dea,"TFMT5Model"),Dea.forEach(t),yRr=r(iUe," (MT5 model)"),iUe.forEach(t),xRr=i(D),u5=n(D,"LI",{});var dUe=s(u5);tAe=n(dUe,"STRONG",{});var Gea=s(tAe);$Rr=r(Gea,"openai-gpt"),Gea.forEach(t),kRr=r(dUe," \u2014 "),zee=n(dUe,"A",{href:!0});var Oea=s(zee);SRr=r(Oea,"TFOpenAIGPTModel"),Oea.forEach(t),RRr=r(dUe," (OpenAI GPT model)"),dUe.forEach(t),PRr=i(D),p5=n(D,"LI",{});var mUe=s(p5);aAe=n(mUe,"STRONG",{});var Vea=s(aAe);BRr=r(Vea,"opt"),Vea.forEach(t),IRr=r(mUe," \u2014 "),Qee=n(mUe,"A",{href:!0});var Xea=s(Qee);NRr=r(Xea,"TFOPTModel"),Xea.forEach(t),qRr=r(mUe," (OPT model)"),mUe.forEach(t),jRr=i(D),_5=n(D,"LI",{});var cUe=s(_5);nAe=n(cUe,"STRONG",{});var zea=s(nAe);DRr=r(zea,"pegasus"),zea.forEach(t),GRr=r(cUe," \u2014 "),Wee=n(cUe,"A",{href:!0});var Qea=s(Wee);ORr=r(Qea,"TFPegasusModel"),Qea.forEach(t),VRr=r(cUe," (Pegasus model)"),cUe.forEach(t),XRr=i(D),b5=n(D,"LI",{});var fUe=s(b5);sAe=n(fUe,"STRONG",{});var Wea=s(sAe);zRr=r(Wea,"regnet"),Wea.forEach(t),QRr=r(fUe," \u2014 "),Uee=n(fUe,"A",{href:!0});var Uea=s(Uee);WRr=r(Uea,"TFRegNetModel"),Uea.forEach(t),URr=r(fUe," (RegNet model)"),fUe.forEach(t),HRr=i(D),v5=n(D,"LI",{});var gUe=s(v5);lAe=n(gUe,"STRONG",{});var Hea=s(lAe);JRr=r(Hea,"rembert"),Hea.forEach(t),YRr=r(gUe," \u2014 "),Hee=n(gUe,"A",{href:!0});var Jea=s(Hee);KRr=r(Jea,"TFRemBertModel"),Jea.forEach(t),ZRr=r(gUe," (RemBERT model)"),gUe.forEach(t),ePr=i(D),F5=n(D,"LI",{});var hUe=s(F5);iAe=n(hUe,"STRONG",{});var Yea=s(iAe);oPr=r(Yea,"resnet"),Yea.forEach(t),rPr=r(hUe," \u2014 "),Jee=n(hUe,"A",{href:!0});var Kea=s(Jee);tPr=r(Kea,"TFResNetModel"),Kea.forEach(t),aPr=r(hUe," (ResNet model)"),hUe.forEach(t),nPr=i(D),T5=n(D,"LI",{});var uUe=s(T5);dAe=n(uUe,"STRONG",{});var Zea=s(dAe);sPr=r(Zea,"roberta"),Zea.forEach(t),lPr=r(uUe," \u2014 "),Yee=n(uUe,"A",{href:!0});var eoa=s(Yee);iPr=r(eoa,"TFRobertaModel"),eoa.forEach(t),dPr=r(uUe," (RoBERTa model)"),uUe.forEach(t),mPr=i(D),M5=n(D,"LI",{});var pUe=s(M5);mAe=n(pUe,"STRONG",{});var ooa=s(mAe);cPr=r(ooa,"roformer"),ooa.forEach(t),fPr=r(pUe," \u2014 "),Kee=n(pUe,"A",{href:!0});var roa=s(Kee);gPr=r(roa,"TFRoFormerModel"),roa.forEach(t),hPr=r(pUe," (RoFormer model)"),pUe.forEach(t),uPr=i(D),E5=n(D,"LI",{});var _Ue=s(E5);cAe=n(_Ue,"STRONG",{});var toa=s(cAe);pPr=r(toa,"segformer"),toa.forEach(t),_Pr=r(_Ue," \u2014 "),Zee=n(_Ue,"A",{href:!0});var aoa=s(Zee);bPr=r(aoa,"TFSegformerModel"),aoa.forEach(t),vPr=r(_Ue," (SegFormer model)"),_Ue.forEach(t),FPr=i(D),C5=n(D,"LI",{});var bUe=s(C5);fAe=n(bUe,"STRONG",{});var noa=s(fAe);TPr=r(noa,"speech_to_text"),noa.forEach(t),MPr=r(bUe," \u2014 "),eoe=n(bUe,"A",{href:!0});var soa=s(eoe);EPr=r(soa,"TFSpeech2TextModel"),soa.forEach(t),CPr=r(bUe," (Speech2Text model)"),bUe.forEach(t),wPr=i(D),w5=n(D,"LI",{});var vUe=s(w5);gAe=n(vUe,"STRONG",{});var loa=s(gAe);APr=r(loa,"swin"),loa.forEach(t),LPr=r(vUe," \u2014 "),ooe=n(vUe,"A",{href:!0});var ioa=s(ooe);yPr=r(ioa,"TFSwinModel"),ioa.forEach(t),xPr=r(vUe," (Swin Transformer model)"),vUe.forEach(t),$Pr=i(D),A5=n(D,"LI",{});var FUe=s(A5);hAe=n(FUe,"STRONG",{});var doa=s(hAe);kPr=r(doa,"t5"),doa.forEach(t),SPr=r(FUe," \u2014 "),roe=n(FUe,"A",{href:!0});var moa=s(roe);RPr=r(moa,"TFT5Model"),moa.forEach(t),PPr=r(FUe," (T5 model)"),FUe.forEach(t),BPr=i(D),L5=n(D,"LI",{});var TUe=s(L5);uAe=n(TUe,"STRONG",{});var coa=s(uAe);IPr=r(coa,"tapas"),coa.forEach(t),NPr=r(TUe," \u2014 "),toe=n(TUe,"A",{href:!0});var foa=s(toe);qPr=r(foa,"TFTapasModel"),foa.forEach(t),jPr=r(TUe," (TAPAS model)"),TUe.forEach(t),DPr=i(D),y5=n(D,"LI",{});var MUe=s(y5);pAe=n(MUe,"STRONG",{});var goa=s(pAe);GPr=r(goa,"transfo-xl"),goa.forEach(t),OPr=r(MUe," \u2014 "),aoe=n(MUe,"A",{href:!0});var hoa=s(aoe);VPr=r(hoa,"TFTransfoXLModel"),hoa.forEach(t),XPr=r(MUe," (Transformer-XL model)"),MUe.forEach(t),zPr=i(D),x5=n(D,"LI",{});var EUe=s(x5);_Ae=n(EUe,"STRONG",{});var uoa=s(_Ae);QPr=r(uoa,"vit"),uoa.forEach(t),WPr=r(EUe," \u2014 "),noe=n(EUe,"A",{href:!0});var poa=s(noe);UPr=r(poa,"TFViTModel"),poa.forEach(t),HPr=r(EUe," (ViT model)"),EUe.forEach(t),JPr=i(D),$5=n(D,"LI",{});var CUe=s($5);bAe=n(CUe,"STRONG",{});var _oa=s(bAe);YPr=r(_oa,"vit_mae"),_oa.forEach(t),KPr=r(CUe," \u2014 "),soe=n(CUe,"A",{href:!0});var boa=s(soe);ZPr=r(boa,"TFViTMAEModel"),boa.forEach(t),eBr=r(CUe," (ViTMAE model)"),CUe.forEach(t),oBr=i(D),k5=n(D,"LI",{});var wUe=s(k5);vAe=n(wUe,"STRONG",{});var voa=s(vAe);rBr=r(voa,"wav2vec2"),voa.forEach(t),tBr=r(wUe," \u2014 "),loe=n(wUe,"A",{href:!0});var Foa=s(loe);aBr=r(Foa,"TFWav2Vec2Model"),Foa.forEach(t),nBr=r(wUe," (Wav2Vec2 model)"),wUe.forEach(t),sBr=i(D),S5=n(D,"LI",{});var AUe=s(S5);FAe=n(AUe,"STRONG",{});var Toa=s(FAe);lBr=r(Toa,"xglm"),Toa.forEach(t),iBr=r(AUe," \u2014 "),ioe=n(AUe,"A",{href:!0});var Moa=s(ioe);dBr=r(Moa,"TFXGLMModel"),Moa.forEach(t),mBr=r(AUe," (XGLM model)"),AUe.forEach(t),cBr=i(D),R5=n(D,"LI",{});var LUe=s(R5);TAe=n(LUe,"STRONG",{});var Eoa=s(TAe);fBr=r(Eoa,"xlm"),Eoa.forEach(t),gBr=r(LUe," \u2014 "),doe=n(LUe,"A",{href:!0});var Coa=s(doe);hBr=r(Coa,"TFXLMModel"),Coa.forEach(t),uBr=r(LUe," (XLM model)"),LUe.forEach(t),pBr=i(D),P5=n(D,"LI",{});var yUe=s(P5);MAe=n(yUe,"STRONG",{});var woa=s(MAe);_Br=r(woa,"xlm-roberta"),woa.forEach(t),bBr=r(yUe," \u2014 "),moe=n(yUe,"A",{href:!0});var Aoa=s(moe);vBr=r(Aoa,"TFXLMRobertaModel"),Aoa.forEach(t),FBr=r(yUe," (XLM-RoBERTa model)"),yUe.forEach(t),TBr=i(D),B5=n(D,"LI",{});var xUe=s(B5);EAe=n(xUe,"STRONG",{});var Loa=s(EAe);MBr=r(Loa,"xlnet"),Loa.forEach(t),EBr=r(xUe," \u2014 "),coe=n(xUe,"A",{href:!0});var yoa=s(coe);CBr=r(yoa,"TFXLNetModel"),yoa.forEach(t),wBr=r(xUe," (XLNet model)"),xUe.forEach(t),D.forEach(t),ABr=i(ri),T(I5.$$.fragment,ri),ri.forEach(t),oi.forEach(t),Zeo=i(c),zm=n(c,"H2",{class:!0});var hto=s(zm);N5=n(hto,"A",{id:!0,class:!0,href:!0});var xoa=s(N5);CAe=n(xoa,"SPAN",{});var $oa=s(CAe);T(eS.$$.fragment,$oa),$oa.forEach(t),xoa.forEach(t),LBr=i(hto),wAe=n(hto,"SPAN",{});var koa=s(wAe);yBr=r(koa,"TFAutoModelForPreTraining"),koa.forEach(t),hto.forEach(t),eoo=i(c),lr=n(c,"DIV",{class:!0});var ti=s(lr);T(oS.$$.fragment,ti),xBr=i(ti),Qm=n(ti,"P",{});var Zie=s(Qm);$Br=r(Zie,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),foe=n(Zie,"A",{href:!0});var Soa=s(foe);kBr=r(Soa,"from_pretrained()"),Soa.forEach(t),SBr=r(Zie," class method or the "),goe=n(Zie,"A",{href:!0});var Roa=s(goe);RBr=r(Roa,"from_config()"),Roa.forEach(t),PBr=r(Zie,` class
method.`),Zie.forEach(t),BBr=i(ti),rS=n(ti,"P",{});var uto=s(rS);IBr=r(uto,"This class cannot be instantiated directly using "),AAe=n(uto,"CODE",{});var Poa=s(AAe);NBr=r(Poa,"__init__()"),Poa.forEach(t),qBr=r(uto," (throws an error)."),uto.forEach(t),jBr=i(ti),zt=n(ti,"DIV",{class:!0});var J8=s(zt);T(tS.$$.fragment,J8),DBr=i(J8),LAe=n(J8,"P",{});var Boa=s(LAe);GBr=r(Boa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Boa.forEach(t),OBr=i(J8),Wm=n(J8,"P",{});var ede=s(Wm);VBr=r(ede,`Note:
Loading a model from its configuration file does `),yAe=n(ede,"STRONG",{});var Ioa=s(yAe);XBr=r(Ioa,"not"),Ioa.forEach(t),zBr=r(ede,` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=n(ede,"A",{href:!0});var Noa=s(hoe);QBr=r(Noa,"from_pretrained()"),Noa.forEach(t),WBr=r(ede," to load the model weights."),ede.forEach(t),UBr=i(J8),T(q5.$$.fragment,J8),J8.forEach(t),HBr=i(ti),Nr=n(ti,"DIV",{class:!0});var ai=s(Nr);T(aS.$$.fragment,ai),JBr=i(ai),xAe=n(ai,"P",{});var qoa=s(xAe);YBr=r(qoa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),qoa.forEach(t),KBr=i(ai),An=n(ai,"P",{});var Y8=s(An);ZBr=r(Y8,"The model class to instantiate is selected based on the "),$Ae=n(Y8,"CODE",{});var joa=s($Ae);eIr=r(joa,"model_type"),joa.forEach(t),oIr=r(Y8,` property of the config object (either
passed as an argument or loaded from `),kAe=n(Y8,"CODE",{});var Doa=s(kAe);rIr=r(Doa,"pretrained_model_name_or_path"),Doa.forEach(t),tIr=r(Y8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SAe=n(Y8,"CODE",{});var Goa=s(SAe);aIr=r(Goa,"pretrained_model_name_or_path"),Goa.forEach(t),nIr=r(Y8,":"),Y8.forEach(t),sIr=i(ai),se=n(ai,"UL",{});var ie=s(se);j5=n(ie,"LI",{});var $Ue=s(j5);RAe=n($Ue,"STRONG",{});var Ooa=s(RAe);lIr=r(Ooa,"albert"),Ooa.forEach(t),iIr=r($Ue," \u2014 "),uoe=n($Ue,"A",{href:!0});var Voa=s(uoe);dIr=r(Voa,"TFAlbertForPreTraining"),Voa.forEach(t),mIr=r($Ue," (ALBERT model)"),$Ue.forEach(t),cIr=i(ie),D5=n(ie,"LI",{});var kUe=s(D5);PAe=n(kUe,"STRONG",{});var Xoa=s(PAe);fIr=r(Xoa,"bart"),Xoa.forEach(t),gIr=r(kUe," \u2014 "),poe=n(kUe,"A",{href:!0});var zoa=s(poe);hIr=r(zoa,"TFBartForConditionalGeneration"),zoa.forEach(t),uIr=r(kUe," (BART model)"),kUe.forEach(t),pIr=i(ie),G5=n(ie,"LI",{});var SUe=s(G5);BAe=n(SUe,"STRONG",{});var Qoa=s(BAe);_Ir=r(Qoa,"bert"),Qoa.forEach(t),bIr=r(SUe," \u2014 "),_oe=n(SUe,"A",{href:!0});var Woa=s(_oe);vIr=r(Woa,"TFBertForPreTraining"),Woa.forEach(t),FIr=r(SUe," (BERT model)"),SUe.forEach(t),TIr=i(ie),O5=n(ie,"LI",{});var RUe=s(O5);IAe=n(RUe,"STRONG",{});var Uoa=s(IAe);MIr=r(Uoa,"camembert"),Uoa.forEach(t),EIr=r(RUe," \u2014 "),boe=n(RUe,"A",{href:!0});var Hoa=s(boe);CIr=r(Hoa,"TFCamembertForMaskedLM"),Hoa.forEach(t),wIr=r(RUe," (CamemBERT model)"),RUe.forEach(t),AIr=i(ie),V5=n(ie,"LI",{});var PUe=s(V5);NAe=n(PUe,"STRONG",{});var Joa=s(NAe);LIr=r(Joa,"ctrl"),Joa.forEach(t),yIr=r(PUe," \u2014 "),voe=n(PUe,"A",{href:!0});var Yoa=s(voe);xIr=r(Yoa,"TFCTRLLMHeadModel"),Yoa.forEach(t),$Ir=r(PUe," (CTRL model)"),PUe.forEach(t),kIr=i(ie),X5=n(ie,"LI",{});var BUe=s(X5);qAe=n(BUe,"STRONG",{});var Koa=s(qAe);SIr=r(Koa,"distilbert"),Koa.forEach(t),RIr=r(BUe," \u2014 "),Foe=n(BUe,"A",{href:!0});var Zoa=s(Foe);PIr=r(Zoa,"TFDistilBertForMaskedLM"),Zoa.forEach(t),BIr=r(BUe," (DistilBERT model)"),BUe.forEach(t),IIr=i(ie),z5=n(ie,"LI",{});var IUe=s(z5);jAe=n(IUe,"STRONG",{});var era=s(jAe);NIr=r(era,"electra"),era.forEach(t),qIr=r(IUe," \u2014 "),Toe=n(IUe,"A",{href:!0});var ora=s(Toe);jIr=r(ora,"TFElectraForPreTraining"),ora.forEach(t),DIr=r(IUe," (ELECTRA model)"),IUe.forEach(t),GIr=i(ie),Q5=n(ie,"LI",{});var NUe=s(Q5);DAe=n(NUe,"STRONG",{});var rra=s(DAe);OIr=r(rra,"flaubert"),rra.forEach(t),VIr=r(NUe," \u2014 "),Moe=n(NUe,"A",{href:!0});var tra=s(Moe);XIr=r(tra,"TFFlaubertWithLMHeadModel"),tra.forEach(t),zIr=r(NUe," (FlauBERT model)"),NUe.forEach(t),QIr=i(ie),W5=n(ie,"LI",{});var qUe=s(W5);GAe=n(qUe,"STRONG",{});var ara=s(GAe);WIr=r(ara,"funnel"),ara.forEach(t),UIr=r(qUe," \u2014 "),Eoe=n(qUe,"A",{href:!0});var nra=s(Eoe);HIr=r(nra,"TFFunnelForPreTraining"),nra.forEach(t),JIr=r(qUe," (Funnel Transformer model)"),qUe.forEach(t),YIr=i(ie),U5=n(ie,"LI",{});var jUe=s(U5);OAe=n(jUe,"STRONG",{});var sra=s(OAe);KIr=r(sra,"gpt2"),sra.forEach(t),ZIr=r(jUe," \u2014 "),Coe=n(jUe,"A",{href:!0});var lra=s(Coe);eNr=r(lra,"TFGPT2LMHeadModel"),lra.forEach(t),oNr=r(jUe," (OpenAI GPT-2 model)"),jUe.forEach(t),rNr=i(ie),H5=n(ie,"LI",{});var DUe=s(H5);VAe=n(DUe,"STRONG",{});var ira=s(VAe);tNr=r(ira,"layoutlm"),ira.forEach(t),aNr=r(DUe," \u2014 "),woe=n(DUe,"A",{href:!0});var dra=s(woe);nNr=r(dra,"TFLayoutLMForMaskedLM"),dra.forEach(t),sNr=r(DUe," (LayoutLM model)"),DUe.forEach(t),lNr=i(ie),J5=n(ie,"LI",{});var GUe=s(J5);XAe=n(GUe,"STRONG",{});var mra=s(XAe);iNr=r(mra,"lxmert"),mra.forEach(t),dNr=r(GUe," \u2014 "),Aoe=n(GUe,"A",{href:!0});var cra=s(Aoe);mNr=r(cra,"TFLxmertForPreTraining"),cra.forEach(t),cNr=r(GUe," (LXMERT model)"),GUe.forEach(t),fNr=i(ie),Y5=n(ie,"LI",{});var OUe=s(Y5);zAe=n(OUe,"STRONG",{});var fra=s(zAe);gNr=r(fra,"mobilebert"),fra.forEach(t),hNr=r(OUe," \u2014 "),Loe=n(OUe,"A",{href:!0});var gra=s(Loe);uNr=r(gra,"TFMobileBertForPreTraining"),gra.forEach(t),pNr=r(OUe," (MobileBERT model)"),OUe.forEach(t),_Nr=i(ie),K5=n(ie,"LI",{});var VUe=s(K5);QAe=n(VUe,"STRONG",{});var hra=s(QAe);bNr=r(hra,"mpnet"),hra.forEach(t),vNr=r(VUe," \u2014 "),yoe=n(VUe,"A",{href:!0});var ura=s(yoe);FNr=r(ura,"TFMPNetForMaskedLM"),ura.forEach(t),TNr=r(VUe," (MPNet model)"),VUe.forEach(t),MNr=i(ie),Z5=n(ie,"LI",{});var XUe=s(Z5);WAe=n(XUe,"STRONG",{});var pra=s(WAe);ENr=r(pra,"openai-gpt"),pra.forEach(t),CNr=r(XUe," \u2014 "),xoe=n(XUe,"A",{href:!0});var _ra=s(xoe);wNr=r(_ra,"TFOpenAIGPTLMHeadModel"),_ra.forEach(t),ANr=r(XUe," (OpenAI GPT model)"),XUe.forEach(t),LNr=i(ie),e0=n(ie,"LI",{});var zUe=s(e0);UAe=n(zUe,"STRONG",{});var bra=s(UAe);yNr=r(bra,"roberta"),bra.forEach(t),xNr=r(zUe," \u2014 "),$oe=n(zUe,"A",{href:!0});var vra=s($oe);$Nr=r(vra,"TFRobertaForMaskedLM"),vra.forEach(t),kNr=r(zUe," (RoBERTa model)"),zUe.forEach(t),SNr=i(ie),o0=n(ie,"LI",{});var QUe=s(o0);HAe=n(QUe,"STRONG",{});var Fra=s(HAe);RNr=r(Fra,"t5"),Fra.forEach(t),PNr=r(QUe," \u2014 "),koe=n(QUe,"A",{href:!0});var Tra=s(koe);BNr=r(Tra,"TFT5ForConditionalGeneration"),Tra.forEach(t),INr=r(QUe," (T5 model)"),QUe.forEach(t),NNr=i(ie),r0=n(ie,"LI",{});var WUe=s(r0);JAe=n(WUe,"STRONG",{});var Mra=s(JAe);qNr=r(Mra,"tapas"),Mra.forEach(t),jNr=r(WUe," \u2014 "),Soe=n(WUe,"A",{href:!0});var Era=s(Soe);DNr=r(Era,"TFTapasForMaskedLM"),Era.forEach(t),GNr=r(WUe," (TAPAS model)"),WUe.forEach(t),ONr=i(ie),t0=n(ie,"LI",{});var UUe=s(t0);YAe=n(UUe,"STRONG",{});var Cra=s(YAe);VNr=r(Cra,"transfo-xl"),Cra.forEach(t),XNr=r(UUe," \u2014 "),Roe=n(UUe,"A",{href:!0});var wra=s(Roe);zNr=r(wra,"TFTransfoXLLMHeadModel"),wra.forEach(t),QNr=r(UUe," (Transformer-XL model)"),UUe.forEach(t),WNr=i(ie),a0=n(ie,"LI",{});var HUe=s(a0);KAe=n(HUe,"STRONG",{});var Ara=s(KAe);UNr=r(Ara,"vit_mae"),Ara.forEach(t),HNr=r(HUe," \u2014 "),Poe=n(HUe,"A",{href:!0});var Lra=s(Poe);JNr=r(Lra,"TFViTMAEForPreTraining"),Lra.forEach(t),YNr=r(HUe," (ViTMAE model)"),HUe.forEach(t),KNr=i(ie),n0=n(ie,"LI",{});var JUe=s(n0);ZAe=n(JUe,"STRONG",{});var yra=s(ZAe);ZNr=r(yra,"xlm"),yra.forEach(t),eqr=r(JUe," \u2014 "),Boe=n(JUe,"A",{href:!0});var xra=s(Boe);oqr=r(xra,"TFXLMWithLMHeadModel"),xra.forEach(t),rqr=r(JUe," (XLM model)"),JUe.forEach(t),tqr=i(ie),s0=n(ie,"LI",{});var YUe=s(s0);e6e=n(YUe,"STRONG",{});var $ra=s(e6e);aqr=r($ra,"xlm-roberta"),$ra.forEach(t),nqr=r(YUe," \u2014 "),Ioe=n(YUe,"A",{href:!0});var kra=s(Ioe);sqr=r(kra,"TFXLMRobertaForMaskedLM"),kra.forEach(t),lqr=r(YUe," (XLM-RoBERTa model)"),YUe.forEach(t),iqr=i(ie),l0=n(ie,"LI",{});var KUe=s(l0);o6e=n(KUe,"STRONG",{});var Sra=s(o6e);dqr=r(Sra,"xlnet"),Sra.forEach(t),mqr=r(KUe," \u2014 "),Noe=n(KUe,"A",{href:!0});var Rra=s(Noe);cqr=r(Rra,"TFXLNetLMHeadModel"),Rra.forEach(t),fqr=r(KUe," (XLNet model)"),KUe.forEach(t),ie.forEach(t),gqr=i(ai),T(i0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),ooo=i(c),Um=n(c,"H2",{class:!0});var pto=s(Um);d0=n(pto,"A",{id:!0,class:!0,href:!0});var Pra=s(d0);r6e=n(Pra,"SPAN",{});var Bra=s(r6e);T(nS.$$.fragment,Bra),Bra.forEach(t),Pra.forEach(t),hqr=i(pto),t6e=n(pto,"SPAN",{});var Ira=s(t6e);uqr=r(Ira,"TFAutoModelForCausalLM"),Ira.forEach(t),pto.forEach(t),roo=i(c),ir=n(c,"DIV",{class:!0});var ni=s(ir);T(sS.$$.fragment,ni),pqr=i(ni),Hm=n(ni,"P",{});var ode=s(Hm);_qr=r(ode,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),qoe=n(ode,"A",{href:!0});var Nra=s(qoe);bqr=r(Nra,"from_pretrained()"),Nra.forEach(t),vqr=r(ode," class method or the "),joe=n(ode,"A",{href:!0});var qra=s(joe);Fqr=r(qra,"from_config()"),qra.forEach(t),Tqr=r(ode,` class
method.`),ode.forEach(t),Mqr=i(ni),lS=n(ni,"P",{});var _to=s(lS);Eqr=r(_to,"This class cannot be instantiated directly using "),a6e=n(_to,"CODE",{});var jra=s(a6e);Cqr=r(jra,"__init__()"),jra.forEach(t),wqr=r(_to," (throws an error)."),_to.forEach(t),Aqr=i(ni),Qt=n(ni,"DIV",{class:!0});var K8=s(Qt);T(iS.$$.fragment,K8),Lqr=i(K8),n6e=n(K8,"P",{});var Dra=s(n6e);yqr=r(Dra,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Dra.forEach(t),xqr=i(K8),Jm=n(K8,"P",{});var rde=s(Jm);$qr=r(rde,`Note:
Loading a model from its configuration file does `),s6e=n(rde,"STRONG",{});var Gra=s(s6e);kqr=r(Gra,"not"),Gra.forEach(t),Sqr=r(rde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=n(rde,"A",{href:!0});var Ora=s(Doe);Rqr=r(Ora,"from_pretrained()"),Ora.forEach(t),Pqr=r(rde," to load the model weights."),rde.forEach(t),Bqr=i(K8),T(m0.$$.fragment,K8),K8.forEach(t),Iqr=i(ni),qr=n(ni,"DIV",{class:!0});var si=s(qr);T(dS.$$.fragment,si),Nqr=i(si),l6e=n(si,"P",{});var Vra=s(l6e);qqr=r(Vra,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Vra.forEach(t),jqr=i(si),Ln=n(si,"P",{});var Z8=s(Ln);Dqr=r(Z8,"The model class to instantiate is selected based on the "),i6e=n(Z8,"CODE",{});var Xra=s(i6e);Gqr=r(Xra,"model_type"),Xra.forEach(t),Oqr=r(Z8,` property of the config object (either
passed as an argument or loaded from `),d6e=n(Z8,"CODE",{});var zra=s(d6e);Vqr=r(zra,"pretrained_model_name_or_path"),zra.forEach(t),Xqr=r(Z8,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=n(Z8,"CODE",{});var Qra=s(m6e);zqr=r(Qra,"pretrained_model_name_or_path"),Qra.forEach(t),Qqr=r(Z8,":"),Z8.forEach(t),Wqr=i(si),Me=n(si,"UL",{});var Ce=s(Me);c0=n(Ce,"LI",{});var ZUe=s(c0);c6e=n(ZUe,"STRONG",{});var Wra=s(c6e);Uqr=r(Wra,"bert"),Wra.forEach(t),Hqr=r(ZUe," \u2014 "),Goe=n(ZUe,"A",{href:!0});var Ura=s(Goe);Jqr=r(Ura,"TFBertLMHeadModel"),Ura.forEach(t),Yqr=r(ZUe," (BERT model)"),ZUe.forEach(t),Kqr=i(Ce),f0=n(Ce,"LI",{});var eHe=s(f0);f6e=n(eHe,"STRONG",{});var Hra=s(f6e);Zqr=r(Hra,"camembert"),Hra.forEach(t),ejr=r(eHe," \u2014 "),Ooe=n(eHe,"A",{href:!0});var Jra=s(Ooe);ojr=r(Jra,"TFCamembertForCausalLM"),Jra.forEach(t),rjr=r(eHe," (CamemBERT model)"),eHe.forEach(t),tjr=i(Ce),g0=n(Ce,"LI",{});var oHe=s(g0);g6e=n(oHe,"STRONG",{});var Yra=s(g6e);ajr=r(Yra,"ctrl"),Yra.forEach(t),njr=r(oHe," \u2014 "),Voe=n(oHe,"A",{href:!0});var Kra=s(Voe);sjr=r(Kra,"TFCTRLLMHeadModel"),Kra.forEach(t),ljr=r(oHe," (CTRL model)"),oHe.forEach(t),ijr=i(Ce),h0=n(Ce,"LI",{});var rHe=s(h0);h6e=n(rHe,"STRONG",{});var Zra=s(h6e);djr=r(Zra,"gpt2"),Zra.forEach(t),mjr=r(rHe," \u2014 "),Xoe=n(rHe,"A",{href:!0});var eta=s(Xoe);cjr=r(eta,"TFGPT2LMHeadModel"),eta.forEach(t),fjr=r(rHe," (OpenAI GPT-2 model)"),rHe.forEach(t),gjr=i(Ce),u0=n(Ce,"LI",{});var tHe=s(u0);u6e=n(tHe,"STRONG",{});var ota=s(u6e);hjr=r(ota,"gptj"),ota.forEach(t),ujr=r(tHe," \u2014 "),zoe=n(tHe,"A",{href:!0});var rta=s(zoe);pjr=r(rta,"TFGPTJForCausalLM"),rta.forEach(t),_jr=r(tHe," (GPT-J model)"),tHe.forEach(t),bjr=i(Ce),p0=n(Ce,"LI",{});var aHe=s(p0);p6e=n(aHe,"STRONG",{});var tta=s(p6e);vjr=r(tta,"openai-gpt"),tta.forEach(t),Fjr=r(aHe," \u2014 "),Qoe=n(aHe,"A",{href:!0});var ata=s(Qoe);Tjr=r(ata,"TFOpenAIGPTLMHeadModel"),ata.forEach(t),Mjr=r(aHe," (OpenAI GPT model)"),aHe.forEach(t),Ejr=i(Ce),_0=n(Ce,"LI",{});var nHe=s(_0);_6e=n(nHe,"STRONG",{});var nta=s(_6e);Cjr=r(nta,"opt"),nta.forEach(t),wjr=r(nHe," \u2014 "),Woe=n(nHe,"A",{href:!0});var sta=s(Woe);Ajr=r(sta,"TFOPTForCausalLM"),sta.forEach(t),Ljr=r(nHe," (OPT model)"),nHe.forEach(t),yjr=i(Ce),b0=n(Ce,"LI",{});var sHe=s(b0);b6e=n(sHe,"STRONG",{});var lta=s(b6e);xjr=r(lta,"rembert"),lta.forEach(t),$jr=r(sHe," \u2014 "),Uoe=n(sHe,"A",{href:!0});var ita=s(Uoe);kjr=r(ita,"TFRemBertForCausalLM"),ita.forEach(t),Sjr=r(sHe," (RemBERT model)"),sHe.forEach(t),Rjr=i(Ce),v0=n(Ce,"LI",{});var lHe=s(v0);v6e=n(lHe,"STRONG",{});var dta=s(v6e);Pjr=r(dta,"roberta"),dta.forEach(t),Bjr=r(lHe," \u2014 "),Hoe=n(lHe,"A",{href:!0});var mta=s(Hoe);Ijr=r(mta,"TFRobertaForCausalLM"),mta.forEach(t),Njr=r(lHe," (RoBERTa model)"),lHe.forEach(t),qjr=i(Ce),F0=n(Ce,"LI",{});var iHe=s(F0);F6e=n(iHe,"STRONG",{});var cta=s(F6e);jjr=r(cta,"roformer"),cta.forEach(t),Djr=r(iHe," \u2014 "),Joe=n(iHe,"A",{href:!0});var fta=s(Joe);Gjr=r(fta,"TFRoFormerForCausalLM"),fta.forEach(t),Ojr=r(iHe," (RoFormer model)"),iHe.forEach(t),Vjr=i(Ce),T0=n(Ce,"LI",{});var dHe=s(T0);T6e=n(dHe,"STRONG",{});var gta=s(T6e);Xjr=r(gta,"transfo-xl"),gta.forEach(t),zjr=r(dHe," \u2014 "),Yoe=n(dHe,"A",{href:!0});var hta=s(Yoe);Qjr=r(hta,"TFTransfoXLLMHeadModel"),hta.forEach(t),Wjr=r(dHe," (Transformer-XL model)"),dHe.forEach(t),Ujr=i(Ce),M0=n(Ce,"LI",{});var mHe=s(M0);M6e=n(mHe,"STRONG",{});var uta=s(M6e);Hjr=r(uta,"xglm"),uta.forEach(t),Jjr=r(mHe," \u2014 "),Koe=n(mHe,"A",{href:!0});var pta=s(Koe);Yjr=r(pta,"TFXGLMForCausalLM"),pta.forEach(t),Kjr=r(mHe," (XGLM model)"),mHe.forEach(t),Zjr=i(Ce),E0=n(Ce,"LI",{});var cHe=s(E0);E6e=n(cHe,"STRONG",{});var _ta=s(E6e);eDr=r(_ta,"xlm"),_ta.forEach(t),oDr=r(cHe," \u2014 "),Zoe=n(cHe,"A",{href:!0});var bta=s(Zoe);rDr=r(bta,"TFXLMWithLMHeadModel"),bta.forEach(t),tDr=r(cHe," (XLM model)"),cHe.forEach(t),aDr=i(Ce),C0=n(Ce,"LI",{});var fHe=s(C0);C6e=n(fHe,"STRONG",{});var vta=s(C6e);nDr=r(vta,"xlnet"),vta.forEach(t),sDr=r(fHe," \u2014 "),ere=n(fHe,"A",{href:!0});var Fta=s(ere);lDr=r(Fta,"TFXLNetLMHeadModel"),Fta.forEach(t),iDr=r(fHe," (XLNet model)"),fHe.forEach(t),Ce.forEach(t),dDr=i(si),T(w0.$$.fragment,si),si.forEach(t),ni.forEach(t),too=i(c),Ym=n(c,"H2",{class:!0});var bto=s(Ym);A0=n(bto,"A",{id:!0,class:!0,href:!0});var Tta=s(A0);w6e=n(Tta,"SPAN",{});var Mta=s(w6e);T(mS.$$.fragment,Mta),Mta.forEach(t),Tta.forEach(t),mDr=i(bto),A6e=n(bto,"SPAN",{});var Eta=s(A6e);cDr=r(Eta,"TFAutoModelForImageClassification"),Eta.forEach(t),bto.forEach(t),aoo=i(c),dr=n(c,"DIV",{class:!0});var li=s(dr);T(cS.$$.fragment,li),fDr=i(li),Km=n(li,"P",{});var tde=s(Km);gDr=r(tde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),ore=n(tde,"A",{href:!0});var Cta=s(ore);hDr=r(Cta,"from_pretrained()"),Cta.forEach(t),uDr=r(tde," class method or the "),rre=n(tde,"A",{href:!0});var wta=s(rre);pDr=r(wta,"from_config()"),wta.forEach(t),_Dr=r(tde,` class
method.`),tde.forEach(t),bDr=i(li),fS=n(li,"P",{});var vto=s(fS);vDr=r(vto,"This class cannot be instantiated directly using "),L6e=n(vto,"CODE",{});var Ata=s(L6e);FDr=r(Ata,"__init__()"),Ata.forEach(t),TDr=r(vto," (throws an error)."),vto.forEach(t),MDr=i(li),Wt=n(li,"DIV",{class:!0});var e9=s(Wt);T(gS.$$.fragment,e9),EDr=i(e9),y6e=n(e9,"P",{});var Lta=s(y6e);CDr=r(Lta,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Lta.forEach(t),wDr=i(e9),Zm=n(e9,"P",{});var ade=s(Zm);ADr=r(ade,`Note:
Loading a model from its configuration file does `),x6e=n(ade,"STRONG",{});var yta=s(x6e);LDr=r(yta,"not"),yta.forEach(t),yDr=r(ade,` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=n(ade,"A",{href:!0});var xta=s(tre);xDr=r(xta,"from_pretrained()"),xta.forEach(t),$Dr=r(ade," to load the model weights."),ade.forEach(t),kDr=i(e9),T(L0.$$.fragment,e9),e9.forEach(t),SDr=i(li),jr=n(li,"DIV",{class:!0});var ii=s(jr);T(hS.$$.fragment,ii),RDr=i(ii),$6e=n(ii,"P",{});var $ta=s($6e);PDr=r($ta,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$ta.forEach(t),BDr=i(ii),yn=n(ii,"P",{});var o9=s(yn);IDr=r(o9,"The model class to instantiate is selected based on the "),k6e=n(o9,"CODE",{});var kta=s(k6e);NDr=r(kta,"model_type"),kta.forEach(t),qDr=r(o9,` property of the config object (either
passed as an argument or loaded from `),S6e=n(o9,"CODE",{});var Sta=s(S6e);jDr=r(Sta,"pretrained_model_name_or_path"),Sta.forEach(t),DDr=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R6e=n(o9,"CODE",{});var Rta=s(R6e);GDr=r(Rta,"pretrained_model_name_or_path"),Rta.forEach(t),ODr=r(o9,":"),o9.forEach(t),VDr=i(ii),Be=n(ii,"UL",{});var We=s(Be);y0=n(We,"LI",{});var gHe=s(y0);P6e=n(gHe,"STRONG",{});var Pta=s(P6e);XDr=r(Pta,"convnext"),Pta.forEach(t),zDr=r(gHe," \u2014 "),are=n(gHe,"A",{href:!0});var Bta=s(are);QDr=r(Bta,"TFConvNextForImageClassification"),Bta.forEach(t),WDr=r(gHe," (ConvNeXT model)"),gHe.forEach(t),UDr=i(We),x0=n(We,"LI",{});var hHe=s(x0);B6e=n(hHe,"STRONG",{});var Ita=s(B6e);HDr=r(Ita,"data2vec-vision"),Ita.forEach(t),JDr=r(hHe," \u2014 "),nre=n(hHe,"A",{href:!0});var Nta=s(nre);YDr=r(Nta,"TFData2VecVisionForImageClassification"),Nta.forEach(t),KDr=r(hHe," (Data2VecVision model)"),hHe.forEach(t),ZDr=i(We),Tl=n(We,"LI",{});var ZB=s(Tl);I6e=n(ZB,"STRONG",{});var qta=s(I6e);eGr=r(qta,"deit"),qta.forEach(t),oGr=r(ZB," \u2014 "),sre=n(ZB,"A",{href:!0});var jta=s(sre);rGr=r(jta,"TFDeiTForImageClassification"),jta.forEach(t),tGr=r(ZB," or "),lre=n(ZB,"A",{href:!0});var Dta=s(lre);aGr=r(Dta,"TFDeiTForImageClassificationWithTeacher"),Dta.forEach(t),nGr=r(ZB," (DeiT model)"),ZB.forEach(t),sGr=i(We),$0=n(We,"LI",{});var uHe=s($0);N6e=n(uHe,"STRONG",{});var Gta=s(N6e);lGr=r(Gta,"mobilevit"),Gta.forEach(t),iGr=r(uHe," \u2014 "),ire=n(uHe,"A",{href:!0});var Ota=s(ire);dGr=r(Ota,"TFMobileViTForImageClassification"),Ota.forEach(t),mGr=r(uHe," (MobileViT model)"),uHe.forEach(t),cGr=i(We),k0=n(We,"LI",{});var pHe=s(k0);q6e=n(pHe,"STRONG",{});var Vta=s(q6e);fGr=r(Vta,"regnet"),Vta.forEach(t),gGr=r(pHe," \u2014 "),dre=n(pHe,"A",{href:!0});var Xta=s(dre);hGr=r(Xta,"TFRegNetForImageClassification"),Xta.forEach(t),uGr=r(pHe," (RegNet model)"),pHe.forEach(t),pGr=i(We),S0=n(We,"LI",{});var _He=s(S0);j6e=n(_He,"STRONG",{});var zta=s(j6e);_Gr=r(zta,"resnet"),zta.forEach(t),bGr=r(_He," \u2014 "),mre=n(_He,"A",{href:!0});var Qta=s(mre);vGr=r(Qta,"TFResNetForImageClassification"),Qta.forEach(t),FGr=r(_He," (ResNet model)"),_He.forEach(t),TGr=i(We),R0=n(We,"LI",{});var bHe=s(R0);D6e=n(bHe,"STRONG",{});var Wta=s(D6e);MGr=r(Wta,"segformer"),Wta.forEach(t),EGr=r(bHe," \u2014 "),cre=n(bHe,"A",{href:!0});var Uta=s(cre);CGr=r(Uta,"TFSegformerForImageClassification"),Uta.forEach(t),wGr=r(bHe," (SegFormer model)"),bHe.forEach(t),AGr=i(We),P0=n(We,"LI",{});var vHe=s(P0);G6e=n(vHe,"STRONG",{});var Hta=s(G6e);LGr=r(Hta,"swin"),Hta.forEach(t),yGr=r(vHe," \u2014 "),fre=n(vHe,"A",{href:!0});var Jta=s(fre);xGr=r(Jta,"TFSwinForImageClassification"),Jta.forEach(t),$Gr=r(vHe," (Swin Transformer model)"),vHe.forEach(t),kGr=i(We),B0=n(We,"LI",{});var FHe=s(B0);O6e=n(FHe,"STRONG",{});var Yta=s(O6e);SGr=r(Yta,"vit"),Yta.forEach(t),RGr=r(FHe," \u2014 "),gre=n(FHe,"A",{href:!0});var Kta=s(gre);PGr=r(Kta,"TFViTForImageClassification"),Kta.forEach(t),BGr=r(FHe," (ViT model)"),FHe.forEach(t),We.forEach(t),IGr=i(ii),T(I0.$$.fragment,ii),ii.forEach(t),li.forEach(t),noo=i(c),ec=n(c,"H2",{class:!0});var Fto=s(ec);N0=n(Fto,"A",{id:!0,class:!0,href:!0});var Zta=s(N0);V6e=n(Zta,"SPAN",{});var eaa=s(V6e);T(uS.$$.fragment,eaa),eaa.forEach(t),Zta.forEach(t),NGr=i(Fto),X6e=n(Fto,"SPAN",{});var oaa=s(X6e);qGr=r(oaa,"TFAutoModelForSemanticSegmentation"),oaa.forEach(t),Fto.forEach(t),soo=i(c),mr=n(c,"DIV",{class:!0});var di=s(mr);T(pS.$$.fragment,di),jGr=i(di),oc=n(di,"P",{});var nde=s(oc);DGr=r(nde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),hre=n(nde,"A",{href:!0});var raa=s(hre);GGr=r(raa,"from_pretrained()"),raa.forEach(t),OGr=r(nde," class method or the "),ure=n(nde,"A",{href:!0});var taa=s(ure);VGr=r(taa,"from_config()"),taa.forEach(t),XGr=r(nde,` class
method.`),nde.forEach(t),zGr=i(di),_S=n(di,"P",{});var Tto=s(_S);QGr=r(Tto,"This class cannot be instantiated directly using "),z6e=n(Tto,"CODE",{});var aaa=s(z6e);WGr=r(aaa,"__init__()"),aaa.forEach(t),UGr=r(Tto," (throws an error)."),Tto.forEach(t),HGr=i(di),Ut=n(di,"DIV",{class:!0});var r9=s(Ut);T(bS.$$.fragment,r9),JGr=i(r9),Q6e=n(r9,"P",{});var naa=s(Q6e);YGr=r(naa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),naa.forEach(t),KGr=i(r9),rc=n(r9,"P",{});var sde=s(rc);ZGr=r(sde,`Note:
Loading a model from its configuration file does `),W6e=n(sde,"STRONG",{});var saa=s(W6e);eOr=r(saa,"not"),saa.forEach(t),oOr=r(sde,` load the model weights. It only affects the
model\u2019s configuration. Use `),pre=n(sde,"A",{href:!0});var laa=s(pre);rOr=r(laa,"from_pretrained()"),laa.forEach(t),tOr=r(sde," to load the model weights."),sde.forEach(t),aOr=i(r9),T(q0.$$.fragment,r9),r9.forEach(t),nOr=i(di),Dr=n(di,"DIV",{class:!0});var mi=s(Dr);T(vS.$$.fragment,mi),sOr=i(mi),U6e=n(mi,"P",{});var iaa=s(U6e);lOr=r(iaa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),iaa.forEach(t),iOr=i(mi),xn=n(mi,"P",{});var t9=s(xn);dOr=r(t9,"The model class to instantiate is selected based on the "),H6e=n(t9,"CODE",{});var daa=s(H6e);mOr=r(daa,"model_type"),daa.forEach(t),cOr=r(t9,` property of the config object (either
passed as an argument or loaded from `),J6e=n(t9,"CODE",{});var maa=s(J6e);fOr=r(maa,"pretrained_model_name_or_path"),maa.forEach(t),gOr=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=n(t9,"CODE",{});var caa=s(Y6e);hOr=r(caa,"pretrained_model_name_or_path"),caa.forEach(t),uOr=r(t9,":"),t9.forEach(t),pOr=i(mi),tc=n(mi,"UL",{});var lde=s(tc);j0=n(lde,"LI",{});var THe=s(j0);K6e=n(THe,"STRONG",{});var faa=s(K6e);_Or=r(faa,"data2vec-vision"),faa.forEach(t),bOr=r(THe," \u2014 "),_re=n(THe,"A",{href:!0});var gaa=s(_re);vOr=r(gaa,"TFData2VecVisionForSemanticSegmentation"),gaa.forEach(t),FOr=r(THe," (Data2VecVision model)"),THe.forEach(t),TOr=i(lde),D0=n(lde,"LI",{});var MHe=s(D0);Z6e=n(MHe,"STRONG",{});var haa=s(Z6e);MOr=r(haa,"mobilevit"),haa.forEach(t),EOr=r(MHe," \u2014 "),bre=n(MHe,"A",{href:!0});var uaa=s(bre);COr=r(uaa,"TFMobileViTForSemanticSegmentation"),uaa.forEach(t),wOr=r(MHe," (MobileViT model)"),MHe.forEach(t),AOr=i(lde),G0=n(lde,"LI",{});var EHe=s(G0);e7e=n(EHe,"STRONG",{});var paa=s(e7e);LOr=r(paa,"segformer"),paa.forEach(t),yOr=r(EHe," \u2014 "),vre=n(EHe,"A",{href:!0});var _aa=s(vre);xOr=r(_aa,"TFSegformerForSemanticSegmentation"),_aa.forEach(t),$Or=r(EHe," (SegFormer model)"),EHe.forEach(t),lde.forEach(t),kOr=i(mi),T(O0.$$.fragment,mi),mi.forEach(t),di.forEach(t),loo=i(c),ac=n(c,"H2",{class:!0});var Mto=s(ac);V0=n(Mto,"A",{id:!0,class:!0,href:!0});var baa=s(V0);o7e=n(baa,"SPAN",{});var vaa=s(o7e);T(FS.$$.fragment,vaa),vaa.forEach(t),baa.forEach(t),SOr=i(Mto),r7e=n(Mto,"SPAN",{});var Faa=s(r7e);ROr=r(Faa,"TFAutoModelForMaskedLM"),Faa.forEach(t),Mto.forEach(t),ioo=i(c),cr=n(c,"DIV",{class:!0});var ci=s(cr);T(TS.$$.fragment,ci),POr=i(ci),nc=n(ci,"P",{});var ide=s(nc);BOr=r(ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fre=n(ide,"A",{href:!0});var Taa=s(Fre);IOr=r(Taa,"from_pretrained()"),Taa.forEach(t),NOr=r(ide," class method or the "),Tre=n(ide,"A",{href:!0});var Maa=s(Tre);qOr=r(Maa,"from_config()"),Maa.forEach(t),jOr=r(ide,` class
method.`),ide.forEach(t),DOr=i(ci),MS=n(ci,"P",{});var Eto=s(MS);GOr=r(Eto,"This class cannot be instantiated directly using "),t7e=n(Eto,"CODE",{});var Eaa=s(t7e);OOr=r(Eaa,"__init__()"),Eaa.forEach(t),VOr=r(Eto," (throws an error)."),Eto.forEach(t),XOr=i(ci),Ht=n(ci,"DIV",{class:!0});var a9=s(Ht);T(ES.$$.fragment,a9),zOr=i(a9),a7e=n(a9,"P",{});var Caa=s(a7e);QOr=r(Caa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Caa.forEach(t),WOr=i(a9),sc=n(a9,"P",{});var dde=s(sc);UOr=r(dde,`Note:
Loading a model from its configuration file does `),n7e=n(dde,"STRONG",{});var waa=s(n7e);HOr=r(waa,"not"),waa.forEach(t),JOr=r(dde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mre=n(dde,"A",{href:!0});var Aaa=s(Mre);YOr=r(Aaa,"from_pretrained()"),Aaa.forEach(t),KOr=r(dde," to load the model weights."),dde.forEach(t),ZOr=i(a9),T(X0.$$.fragment,a9),a9.forEach(t),eVr=i(ci),Gr=n(ci,"DIV",{class:!0});var fi=s(Gr);T(CS.$$.fragment,fi),oVr=i(fi),s7e=n(fi,"P",{});var Laa=s(s7e);rVr=r(Laa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Laa.forEach(t),tVr=i(fi),$n=n(fi,"P",{});var n9=s($n);aVr=r(n9,"The model class to instantiate is selected based on the "),l7e=n(n9,"CODE",{});var yaa=s(l7e);nVr=r(yaa,"model_type"),yaa.forEach(t),sVr=r(n9,` property of the config object (either
passed as an argument or loaded from `),i7e=n(n9,"CODE",{});var xaa=s(i7e);lVr=r(xaa,"pretrained_model_name_or_path"),xaa.forEach(t),iVr=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(n9,"CODE",{});var $aa=s(d7e);dVr=r($aa,"pretrained_model_name_or_path"),$aa.forEach(t),mVr=r(n9,":"),n9.forEach(t),cVr=i(fi),ge=n(fi,"UL",{});var _e=s(ge);z0=n(_e,"LI",{});var CHe=s(z0);m7e=n(CHe,"STRONG",{});var kaa=s(m7e);fVr=r(kaa,"albert"),kaa.forEach(t),gVr=r(CHe," \u2014 "),Ere=n(CHe,"A",{href:!0});var Saa=s(Ere);hVr=r(Saa,"TFAlbertForMaskedLM"),Saa.forEach(t),uVr=r(CHe," (ALBERT model)"),CHe.forEach(t),pVr=i(_e),Q0=n(_e,"LI",{});var wHe=s(Q0);c7e=n(wHe,"STRONG",{});var Raa=s(c7e);_Vr=r(Raa,"bert"),Raa.forEach(t),bVr=r(wHe," \u2014 "),Cre=n(wHe,"A",{href:!0});var Paa=s(Cre);vVr=r(Paa,"TFBertForMaskedLM"),Paa.forEach(t),FVr=r(wHe," (BERT model)"),wHe.forEach(t),TVr=i(_e),W0=n(_e,"LI",{});var AHe=s(W0);f7e=n(AHe,"STRONG",{});var Baa=s(f7e);MVr=r(Baa,"camembert"),Baa.forEach(t),EVr=r(AHe," \u2014 "),wre=n(AHe,"A",{href:!0});var Iaa=s(wre);CVr=r(Iaa,"TFCamembertForMaskedLM"),Iaa.forEach(t),wVr=r(AHe," (CamemBERT model)"),AHe.forEach(t),AVr=i(_e),U0=n(_e,"LI",{});var LHe=s(U0);g7e=n(LHe,"STRONG",{});var Naa=s(g7e);LVr=r(Naa,"convbert"),Naa.forEach(t),yVr=r(LHe," \u2014 "),Are=n(LHe,"A",{href:!0});var qaa=s(Are);xVr=r(qaa,"TFConvBertForMaskedLM"),qaa.forEach(t),$Vr=r(LHe," (ConvBERT model)"),LHe.forEach(t),kVr=i(_e),H0=n(_e,"LI",{});var yHe=s(H0);h7e=n(yHe,"STRONG",{});var jaa=s(h7e);SVr=r(jaa,"deberta"),jaa.forEach(t),RVr=r(yHe," \u2014 "),Lre=n(yHe,"A",{href:!0});var Daa=s(Lre);PVr=r(Daa,"TFDebertaForMaskedLM"),Daa.forEach(t),BVr=r(yHe," (DeBERTa model)"),yHe.forEach(t),IVr=i(_e),J0=n(_e,"LI",{});var xHe=s(J0);u7e=n(xHe,"STRONG",{});var Gaa=s(u7e);NVr=r(Gaa,"deberta-v2"),Gaa.forEach(t),qVr=r(xHe," \u2014 "),yre=n(xHe,"A",{href:!0});var Oaa=s(yre);jVr=r(Oaa,"TFDebertaV2ForMaskedLM"),Oaa.forEach(t),DVr=r(xHe," (DeBERTa-v2 model)"),xHe.forEach(t),GVr=i(_e),Y0=n(_e,"LI",{});var $He=s(Y0);p7e=n($He,"STRONG",{});var Vaa=s(p7e);OVr=r(Vaa,"distilbert"),Vaa.forEach(t),VVr=r($He," \u2014 "),xre=n($He,"A",{href:!0});var Xaa=s(xre);XVr=r(Xaa,"TFDistilBertForMaskedLM"),Xaa.forEach(t),zVr=r($He," (DistilBERT model)"),$He.forEach(t),QVr=i(_e),K0=n(_e,"LI",{});var kHe=s(K0);_7e=n(kHe,"STRONG",{});var zaa=s(_7e);WVr=r(zaa,"electra"),zaa.forEach(t),UVr=r(kHe," \u2014 "),$re=n(kHe,"A",{href:!0});var Qaa=s($re);HVr=r(Qaa,"TFElectraForMaskedLM"),Qaa.forEach(t),JVr=r(kHe," (ELECTRA model)"),kHe.forEach(t),YVr=i(_e),Z0=n(_e,"LI",{});var SHe=s(Z0);b7e=n(SHe,"STRONG",{});var Waa=s(b7e);KVr=r(Waa,"flaubert"),Waa.forEach(t),ZVr=r(SHe," \u2014 "),kre=n(SHe,"A",{href:!0});var Uaa=s(kre);eXr=r(Uaa,"TFFlaubertWithLMHeadModel"),Uaa.forEach(t),oXr=r(SHe," (FlauBERT model)"),SHe.forEach(t),rXr=i(_e),ew=n(_e,"LI",{});var RHe=s(ew);v7e=n(RHe,"STRONG",{});var Haa=s(v7e);tXr=r(Haa,"funnel"),Haa.forEach(t),aXr=r(RHe," \u2014 "),Sre=n(RHe,"A",{href:!0});var Jaa=s(Sre);nXr=r(Jaa,"TFFunnelForMaskedLM"),Jaa.forEach(t),sXr=r(RHe," (Funnel Transformer model)"),RHe.forEach(t),lXr=i(_e),ow=n(_e,"LI",{});var PHe=s(ow);F7e=n(PHe,"STRONG",{});var Yaa=s(F7e);iXr=r(Yaa,"layoutlm"),Yaa.forEach(t),dXr=r(PHe," \u2014 "),Rre=n(PHe,"A",{href:!0});var Kaa=s(Rre);mXr=r(Kaa,"TFLayoutLMForMaskedLM"),Kaa.forEach(t),cXr=r(PHe," (LayoutLM model)"),PHe.forEach(t),fXr=i(_e),rw=n(_e,"LI",{});var BHe=s(rw);T7e=n(BHe,"STRONG",{});var Zaa=s(T7e);gXr=r(Zaa,"longformer"),Zaa.forEach(t),hXr=r(BHe," \u2014 "),Pre=n(BHe,"A",{href:!0});var ena=s(Pre);uXr=r(ena,"TFLongformerForMaskedLM"),ena.forEach(t),pXr=r(BHe," (Longformer model)"),BHe.forEach(t),_Xr=i(_e),tw=n(_e,"LI",{});var IHe=s(tw);M7e=n(IHe,"STRONG",{});var ona=s(M7e);bXr=r(ona,"mobilebert"),ona.forEach(t),vXr=r(IHe," \u2014 "),Bre=n(IHe,"A",{href:!0});var rna=s(Bre);FXr=r(rna,"TFMobileBertForMaskedLM"),rna.forEach(t),TXr=r(IHe," (MobileBERT model)"),IHe.forEach(t),MXr=i(_e),aw=n(_e,"LI",{});var NHe=s(aw);E7e=n(NHe,"STRONG",{});var tna=s(E7e);EXr=r(tna,"mpnet"),tna.forEach(t),CXr=r(NHe," \u2014 "),Ire=n(NHe,"A",{href:!0});var ana=s(Ire);wXr=r(ana,"TFMPNetForMaskedLM"),ana.forEach(t),AXr=r(NHe," (MPNet model)"),NHe.forEach(t),LXr=i(_e),nw=n(_e,"LI",{});var qHe=s(nw);C7e=n(qHe,"STRONG",{});var nna=s(C7e);yXr=r(nna,"rembert"),nna.forEach(t),xXr=r(qHe," \u2014 "),Nre=n(qHe,"A",{href:!0});var sna=s(Nre);$Xr=r(sna,"TFRemBertForMaskedLM"),sna.forEach(t),kXr=r(qHe," (RemBERT model)"),qHe.forEach(t),SXr=i(_e),sw=n(_e,"LI",{});var jHe=s(sw);w7e=n(jHe,"STRONG",{});var lna=s(w7e);RXr=r(lna,"roberta"),lna.forEach(t),PXr=r(jHe," \u2014 "),qre=n(jHe,"A",{href:!0});var ina=s(qre);BXr=r(ina,"TFRobertaForMaskedLM"),ina.forEach(t),IXr=r(jHe," (RoBERTa model)"),jHe.forEach(t),NXr=i(_e),lw=n(_e,"LI",{});var DHe=s(lw);A7e=n(DHe,"STRONG",{});var dna=s(A7e);qXr=r(dna,"roformer"),dna.forEach(t),jXr=r(DHe," \u2014 "),jre=n(DHe,"A",{href:!0});var mna=s(jre);DXr=r(mna,"TFRoFormerForMaskedLM"),mna.forEach(t),GXr=r(DHe," (RoFormer model)"),DHe.forEach(t),OXr=i(_e),iw=n(_e,"LI",{});var GHe=s(iw);L7e=n(GHe,"STRONG",{});var cna=s(L7e);VXr=r(cna,"tapas"),cna.forEach(t),XXr=r(GHe," \u2014 "),Dre=n(GHe,"A",{href:!0});var fna=s(Dre);zXr=r(fna,"TFTapasForMaskedLM"),fna.forEach(t),QXr=r(GHe," (TAPAS model)"),GHe.forEach(t),WXr=i(_e),dw=n(_e,"LI",{});var OHe=s(dw);y7e=n(OHe,"STRONG",{});var gna=s(y7e);UXr=r(gna,"xlm"),gna.forEach(t),HXr=r(OHe," \u2014 "),Gre=n(OHe,"A",{href:!0});var hna=s(Gre);JXr=r(hna,"TFXLMWithLMHeadModel"),hna.forEach(t),YXr=r(OHe," (XLM model)"),OHe.forEach(t),KXr=i(_e),mw=n(_e,"LI",{});var VHe=s(mw);x7e=n(VHe,"STRONG",{});var una=s(x7e);ZXr=r(una,"xlm-roberta"),una.forEach(t),ezr=r(VHe," \u2014 "),Ore=n(VHe,"A",{href:!0});var pna=s(Ore);ozr=r(pna,"TFXLMRobertaForMaskedLM"),pna.forEach(t),rzr=r(VHe," (XLM-RoBERTa model)"),VHe.forEach(t),_e.forEach(t),tzr=i(fi),T(cw.$$.fragment,fi),fi.forEach(t),ci.forEach(t),doo=i(c),lc=n(c,"H2",{class:!0});var Cto=s(lc);fw=n(Cto,"A",{id:!0,class:!0,href:!0});var _na=s(fw);$7e=n(_na,"SPAN",{});var bna=s($7e);T(wS.$$.fragment,bna),bna.forEach(t),_na.forEach(t),azr=i(Cto),k7e=n(Cto,"SPAN",{});var vna=s(k7e);nzr=r(vna,"TFAutoModelForSeq2SeqLM"),vna.forEach(t),Cto.forEach(t),moo=i(c),fr=n(c,"DIV",{class:!0});var gi=s(fr);T(AS.$$.fragment,gi),szr=i(gi),ic=n(gi,"P",{});var mde=s(ic);lzr=r(mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Vre=n(mde,"A",{href:!0});var Fna=s(Vre);izr=r(Fna,"from_pretrained()"),Fna.forEach(t),dzr=r(mde," class method or the "),Xre=n(mde,"A",{href:!0});var Tna=s(Xre);mzr=r(Tna,"from_config()"),Tna.forEach(t),czr=r(mde,` class
method.`),mde.forEach(t),fzr=i(gi),LS=n(gi,"P",{});var wto=s(LS);gzr=r(wto,"This class cannot be instantiated directly using "),S7e=n(wto,"CODE",{});var Mna=s(S7e);hzr=r(Mna,"__init__()"),Mna.forEach(t),uzr=r(wto," (throws an error)."),wto.forEach(t),pzr=i(gi),Jt=n(gi,"DIV",{class:!0});var s9=s(Jt);T(yS.$$.fragment,s9),_zr=i(s9),R7e=n(s9,"P",{});var Ena=s(R7e);bzr=r(Ena,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Ena.forEach(t),vzr=i(s9),dc=n(s9,"P",{});var cde=s(dc);Fzr=r(cde,`Note:
Loading a model from its configuration file does `),P7e=n(cde,"STRONG",{});var Cna=s(P7e);Tzr=r(Cna,"not"),Cna.forEach(t),Mzr=r(cde,` load the model weights. It only affects the
model\u2019s configuration. Use `),zre=n(cde,"A",{href:!0});var wna=s(zre);Ezr=r(wna,"from_pretrained()"),wna.forEach(t),Czr=r(cde," to load the model weights."),cde.forEach(t),wzr=i(s9),T(gw.$$.fragment,s9),s9.forEach(t),Azr=i(gi),Or=n(gi,"DIV",{class:!0});var hi=s(Or);T(xS.$$.fragment,hi),Lzr=i(hi),B7e=n(hi,"P",{});var Ana=s(B7e);yzr=r(Ana,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ana.forEach(t),xzr=i(hi),kn=n(hi,"P",{});var l9=s(kn);$zr=r(l9,"The model class to instantiate is selected based on the "),I7e=n(l9,"CODE",{});var Lna=s(I7e);kzr=r(Lna,"model_type"),Lna.forEach(t),Szr=r(l9,` property of the config object (either
passed as an argument or loaded from `),N7e=n(l9,"CODE",{});var yna=s(N7e);Rzr=r(yna,"pretrained_model_name_or_path"),yna.forEach(t),Pzr=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q7e=n(l9,"CODE",{});var xna=s(q7e);Bzr=r(xna,"pretrained_model_name_or_path"),xna.forEach(t),Izr=r(l9,":"),l9.forEach(t),Nzr=i(hi),ye=n(hi,"UL",{});var Ne=s(ye);hw=n(Ne,"LI",{});var XHe=s(hw);j7e=n(XHe,"STRONG",{});var $na=s(j7e);qzr=r($na,"bart"),$na.forEach(t),jzr=r(XHe," \u2014 "),Qre=n(XHe,"A",{href:!0});var kna=s(Qre);Dzr=r(kna,"TFBartForConditionalGeneration"),kna.forEach(t),Gzr=r(XHe," (BART model)"),XHe.forEach(t),Ozr=i(Ne),uw=n(Ne,"LI",{});var zHe=s(uw);D7e=n(zHe,"STRONG",{});var Sna=s(D7e);Vzr=r(Sna,"blenderbot"),Sna.forEach(t),Xzr=r(zHe," \u2014 "),Wre=n(zHe,"A",{href:!0});var Rna=s(Wre);zzr=r(Rna,"TFBlenderbotForConditionalGeneration"),Rna.forEach(t),Qzr=r(zHe," (Blenderbot model)"),zHe.forEach(t),Wzr=i(Ne),pw=n(Ne,"LI",{});var QHe=s(pw);G7e=n(QHe,"STRONG",{});var Pna=s(G7e);Uzr=r(Pna,"blenderbot-small"),Pna.forEach(t),Hzr=r(QHe," \u2014 "),Ure=n(QHe,"A",{href:!0});var Bna=s(Ure);Jzr=r(Bna,"TFBlenderbotSmallForConditionalGeneration"),Bna.forEach(t),Yzr=r(QHe," (BlenderbotSmall model)"),QHe.forEach(t),Kzr=i(Ne),_w=n(Ne,"LI",{});var WHe=s(_w);O7e=n(WHe,"STRONG",{});var Ina=s(O7e);Zzr=r(Ina,"encoder-decoder"),Ina.forEach(t),eQr=r(WHe," \u2014 "),Hre=n(WHe,"A",{href:!0});var Nna=s(Hre);oQr=r(Nna,"TFEncoderDecoderModel"),Nna.forEach(t),rQr=r(WHe," (Encoder decoder model)"),WHe.forEach(t),tQr=i(Ne),bw=n(Ne,"LI",{});var UHe=s(bw);V7e=n(UHe,"STRONG",{});var qna=s(V7e);aQr=r(qna,"led"),qna.forEach(t),nQr=r(UHe," \u2014 "),Jre=n(UHe,"A",{href:!0});var jna=s(Jre);sQr=r(jna,"TFLEDForConditionalGeneration"),jna.forEach(t),lQr=r(UHe," (LED model)"),UHe.forEach(t),iQr=i(Ne),vw=n(Ne,"LI",{});var HHe=s(vw);X7e=n(HHe,"STRONG",{});var Dna=s(X7e);dQr=r(Dna,"marian"),Dna.forEach(t),mQr=r(HHe," \u2014 "),Yre=n(HHe,"A",{href:!0});var Gna=s(Yre);cQr=r(Gna,"TFMarianMTModel"),Gna.forEach(t),fQr=r(HHe," (Marian model)"),HHe.forEach(t),gQr=i(Ne),Fw=n(Ne,"LI",{});var JHe=s(Fw);z7e=n(JHe,"STRONG",{});var Ona=s(z7e);hQr=r(Ona,"mbart"),Ona.forEach(t),uQr=r(JHe," \u2014 "),Kre=n(JHe,"A",{href:!0});var Vna=s(Kre);pQr=r(Vna,"TFMBartForConditionalGeneration"),Vna.forEach(t),_Qr=r(JHe," (mBART model)"),JHe.forEach(t),bQr=i(Ne),Tw=n(Ne,"LI",{});var YHe=s(Tw);Q7e=n(YHe,"STRONG",{});var Xna=s(Q7e);vQr=r(Xna,"mt5"),Xna.forEach(t),FQr=r(YHe," \u2014 "),Zre=n(YHe,"A",{href:!0});var zna=s(Zre);TQr=r(zna,"TFMT5ForConditionalGeneration"),zna.forEach(t),MQr=r(YHe," (MT5 model)"),YHe.forEach(t),EQr=i(Ne),Mw=n(Ne,"LI",{});var KHe=s(Mw);W7e=n(KHe,"STRONG",{});var Qna=s(W7e);CQr=r(Qna,"pegasus"),Qna.forEach(t),wQr=r(KHe," \u2014 "),ete=n(KHe,"A",{href:!0});var Wna=s(ete);AQr=r(Wna,"TFPegasusForConditionalGeneration"),Wna.forEach(t),LQr=r(KHe," (Pegasus model)"),KHe.forEach(t),yQr=i(Ne),Ew=n(Ne,"LI",{});var ZHe=s(Ew);U7e=n(ZHe,"STRONG",{});var Una=s(U7e);xQr=r(Una,"t5"),Una.forEach(t),$Qr=r(ZHe," \u2014 "),ote=n(ZHe,"A",{href:!0});var Hna=s(ote);kQr=r(Hna,"TFT5ForConditionalGeneration"),Hna.forEach(t),SQr=r(ZHe," (T5 model)"),ZHe.forEach(t),Ne.forEach(t),RQr=i(hi),T(Cw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),coo=i(c),mc=n(c,"H2",{class:!0});var Ato=s(mc);ww=n(Ato,"A",{id:!0,class:!0,href:!0});var Jna=s(ww);H7e=n(Jna,"SPAN",{});var Yna=s(H7e);T($S.$$.fragment,Yna),Yna.forEach(t),Jna.forEach(t),PQr=i(Ato),J7e=n(Ato,"SPAN",{});var Kna=s(J7e);BQr=r(Kna,"TFAutoModelForSequenceClassification"),Kna.forEach(t),Ato.forEach(t),foo=i(c),gr=n(c,"DIV",{class:!0});var ui=s(gr);T(kS.$$.fragment,ui),IQr=i(ui),cc=n(ui,"P",{});var fde=s(cc);NQr=r(fde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),rte=n(fde,"A",{href:!0});var Zna=s(rte);qQr=r(Zna,"from_pretrained()"),Zna.forEach(t),jQr=r(fde," class method or the "),tte=n(fde,"A",{href:!0});var esa=s(tte);DQr=r(esa,"from_config()"),esa.forEach(t),GQr=r(fde,` class
method.`),fde.forEach(t),OQr=i(ui),SS=n(ui,"P",{});var Lto=s(SS);VQr=r(Lto,"This class cannot be instantiated directly using "),Y7e=n(Lto,"CODE",{});var osa=s(Y7e);XQr=r(osa,"__init__()"),osa.forEach(t),zQr=r(Lto," (throws an error)."),Lto.forEach(t),QQr=i(ui),Yt=n(ui,"DIV",{class:!0});var i9=s(Yt);T(RS.$$.fragment,i9),WQr=i(i9),K7e=n(i9,"P",{});var rsa=s(K7e);UQr=r(rsa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),rsa.forEach(t),HQr=i(i9),fc=n(i9,"P",{});var gde=s(fc);JQr=r(gde,`Note:
Loading a model from its configuration file does `),Z7e=n(gde,"STRONG",{});var tsa=s(Z7e);YQr=r(tsa,"not"),tsa.forEach(t),KQr=r(gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),ate=n(gde,"A",{href:!0});var asa=s(ate);ZQr=r(asa,"from_pretrained()"),asa.forEach(t),eWr=r(gde," to load the model weights."),gde.forEach(t),oWr=i(i9),T(Aw.$$.fragment,i9),i9.forEach(t),rWr=i(ui),Vr=n(ui,"DIV",{class:!0});var pi=s(Vr);T(PS.$$.fragment,pi),tWr=i(pi),eLe=n(pi,"P",{});var nsa=s(eLe);aWr=r(nsa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nsa.forEach(t),nWr=i(pi),Sn=n(pi,"P",{});var d9=s(Sn);sWr=r(d9,"The model class to instantiate is selected based on the "),oLe=n(d9,"CODE",{});var ssa=s(oLe);lWr=r(ssa,"model_type"),ssa.forEach(t),iWr=r(d9,` property of the config object (either
passed as an argument or loaded from `),rLe=n(d9,"CODE",{});var lsa=s(rLe);dWr=r(lsa,"pretrained_model_name_or_path"),lsa.forEach(t),mWr=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tLe=n(d9,"CODE",{});var isa=s(tLe);cWr=r(isa,"pretrained_model_name_or_path"),isa.forEach(t),fWr=r(d9,":"),d9.forEach(t),gWr=i(pi),re=n(pi,"UL",{});var ae=s(re);Lw=n(ae,"LI",{});var eJe=s(Lw);aLe=n(eJe,"STRONG",{});var dsa=s(aLe);hWr=r(dsa,"albert"),dsa.forEach(t),uWr=r(eJe," \u2014 "),nte=n(eJe,"A",{href:!0});var msa=s(nte);pWr=r(msa,"TFAlbertForSequenceClassification"),msa.forEach(t),_Wr=r(eJe," (ALBERT model)"),eJe.forEach(t),bWr=i(ae),yw=n(ae,"LI",{});var oJe=s(yw);nLe=n(oJe,"STRONG",{});var csa=s(nLe);vWr=r(csa,"bert"),csa.forEach(t),FWr=r(oJe," \u2014 "),ste=n(oJe,"A",{href:!0});var fsa=s(ste);TWr=r(fsa,"TFBertForSequenceClassification"),fsa.forEach(t),MWr=r(oJe," (BERT model)"),oJe.forEach(t),EWr=i(ae),xw=n(ae,"LI",{});var rJe=s(xw);sLe=n(rJe,"STRONG",{});var gsa=s(sLe);CWr=r(gsa,"camembert"),gsa.forEach(t),wWr=r(rJe," \u2014 "),lte=n(rJe,"A",{href:!0});var hsa=s(lte);AWr=r(hsa,"TFCamembertForSequenceClassification"),hsa.forEach(t),LWr=r(rJe," (CamemBERT model)"),rJe.forEach(t),yWr=i(ae),$w=n(ae,"LI",{});var tJe=s($w);lLe=n(tJe,"STRONG",{});var usa=s(lLe);xWr=r(usa,"convbert"),usa.forEach(t),$Wr=r(tJe," \u2014 "),ite=n(tJe,"A",{href:!0});var psa=s(ite);kWr=r(psa,"TFConvBertForSequenceClassification"),psa.forEach(t),SWr=r(tJe," (ConvBERT model)"),tJe.forEach(t),RWr=i(ae),kw=n(ae,"LI",{});var aJe=s(kw);iLe=n(aJe,"STRONG",{});var _sa=s(iLe);PWr=r(_sa,"ctrl"),_sa.forEach(t),BWr=r(aJe," \u2014 "),dte=n(aJe,"A",{href:!0});var bsa=s(dte);IWr=r(bsa,"TFCTRLForSequenceClassification"),bsa.forEach(t),NWr=r(aJe," (CTRL model)"),aJe.forEach(t),qWr=i(ae),Sw=n(ae,"LI",{});var nJe=s(Sw);dLe=n(nJe,"STRONG",{});var vsa=s(dLe);jWr=r(vsa,"deberta"),vsa.forEach(t),DWr=r(nJe," \u2014 "),mte=n(nJe,"A",{href:!0});var Fsa=s(mte);GWr=r(Fsa,"TFDebertaForSequenceClassification"),Fsa.forEach(t),OWr=r(nJe," (DeBERTa model)"),nJe.forEach(t),VWr=i(ae),Rw=n(ae,"LI",{});var sJe=s(Rw);mLe=n(sJe,"STRONG",{});var Tsa=s(mLe);XWr=r(Tsa,"deberta-v2"),Tsa.forEach(t),zWr=r(sJe," \u2014 "),cte=n(sJe,"A",{href:!0});var Msa=s(cte);QWr=r(Msa,"TFDebertaV2ForSequenceClassification"),Msa.forEach(t),WWr=r(sJe," (DeBERTa-v2 model)"),sJe.forEach(t),UWr=i(ae),Pw=n(ae,"LI",{});var lJe=s(Pw);cLe=n(lJe,"STRONG",{});var Esa=s(cLe);HWr=r(Esa,"distilbert"),Esa.forEach(t),JWr=r(lJe," \u2014 "),fte=n(lJe,"A",{href:!0});var Csa=s(fte);YWr=r(Csa,"TFDistilBertForSequenceClassification"),Csa.forEach(t),KWr=r(lJe," (DistilBERT model)"),lJe.forEach(t),ZWr=i(ae),Bw=n(ae,"LI",{});var iJe=s(Bw);fLe=n(iJe,"STRONG",{});var wsa=s(fLe);eUr=r(wsa,"electra"),wsa.forEach(t),oUr=r(iJe," \u2014 "),gte=n(iJe,"A",{href:!0});var Asa=s(gte);rUr=r(Asa,"TFElectraForSequenceClassification"),Asa.forEach(t),tUr=r(iJe," (ELECTRA model)"),iJe.forEach(t),aUr=i(ae),Iw=n(ae,"LI",{});var dJe=s(Iw);gLe=n(dJe,"STRONG",{});var Lsa=s(gLe);nUr=r(Lsa,"flaubert"),Lsa.forEach(t),sUr=r(dJe," \u2014 "),hte=n(dJe,"A",{href:!0});var ysa=s(hte);lUr=r(ysa,"TFFlaubertForSequenceClassification"),ysa.forEach(t),iUr=r(dJe," (FlauBERT model)"),dJe.forEach(t),dUr=i(ae),Nw=n(ae,"LI",{});var mJe=s(Nw);hLe=n(mJe,"STRONG",{});var xsa=s(hLe);mUr=r(xsa,"funnel"),xsa.forEach(t),cUr=r(mJe," \u2014 "),ute=n(mJe,"A",{href:!0});var $sa=s(ute);fUr=r($sa,"TFFunnelForSequenceClassification"),$sa.forEach(t),gUr=r(mJe," (Funnel Transformer model)"),mJe.forEach(t),hUr=i(ae),qw=n(ae,"LI",{});var cJe=s(qw);uLe=n(cJe,"STRONG",{});var ksa=s(uLe);uUr=r(ksa,"gpt2"),ksa.forEach(t),pUr=r(cJe," \u2014 "),pte=n(cJe,"A",{href:!0});var Ssa=s(pte);_Ur=r(Ssa,"TFGPT2ForSequenceClassification"),Ssa.forEach(t),bUr=r(cJe," (OpenAI GPT-2 model)"),cJe.forEach(t),vUr=i(ae),jw=n(ae,"LI",{});var fJe=s(jw);pLe=n(fJe,"STRONG",{});var Rsa=s(pLe);FUr=r(Rsa,"gptj"),Rsa.forEach(t),TUr=r(fJe," \u2014 "),_te=n(fJe,"A",{href:!0});var Psa=s(_te);MUr=r(Psa,"TFGPTJForSequenceClassification"),Psa.forEach(t),EUr=r(fJe," (GPT-J model)"),fJe.forEach(t),CUr=i(ae),Dw=n(ae,"LI",{});var gJe=s(Dw);_Le=n(gJe,"STRONG",{});var Bsa=s(_Le);wUr=r(Bsa,"layoutlm"),Bsa.forEach(t),AUr=r(gJe," \u2014 "),bte=n(gJe,"A",{href:!0});var Isa=s(bte);LUr=r(Isa,"TFLayoutLMForSequenceClassification"),Isa.forEach(t),yUr=r(gJe," (LayoutLM model)"),gJe.forEach(t),xUr=i(ae),Gw=n(ae,"LI",{});var hJe=s(Gw);bLe=n(hJe,"STRONG",{});var Nsa=s(bLe);$Ur=r(Nsa,"layoutlmv3"),Nsa.forEach(t),kUr=r(hJe," \u2014 "),vte=n(hJe,"A",{href:!0});var qsa=s(vte);SUr=r(qsa,"TFLayoutLMv3ForSequenceClassification"),qsa.forEach(t),RUr=r(hJe," (LayoutLMv3 model)"),hJe.forEach(t),PUr=i(ae),Ow=n(ae,"LI",{});var uJe=s(Ow);vLe=n(uJe,"STRONG",{});var jsa=s(vLe);BUr=r(jsa,"longformer"),jsa.forEach(t),IUr=r(uJe," \u2014 "),Fte=n(uJe,"A",{href:!0});var Dsa=s(Fte);NUr=r(Dsa,"TFLongformerForSequenceClassification"),Dsa.forEach(t),qUr=r(uJe," (Longformer model)"),uJe.forEach(t),jUr=i(ae),Vw=n(ae,"LI",{});var pJe=s(Vw);FLe=n(pJe,"STRONG",{});var Gsa=s(FLe);DUr=r(Gsa,"mobilebert"),Gsa.forEach(t),GUr=r(pJe," \u2014 "),Tte=n(pJe,"A",{href:!0});var Osa=s(Tte);OUr=r(Osa,"TFMobileBertForSequenceClassification"),Osa.forEach(t),VUr=r(pJe," (MobileBERT model)"),pJe.forEach(t),XUr=i(ae),Xw=n(ae,"LI",{});var _Je=s(Xw);TLe=n(_Je,"STRONG",{});var Vsa=s(TLe);zUr=r(Vsa,"mpnet"),Vsa.forEach(t),QUr=r(_Je," \u2014 "),Mte=n(_Je,"A",{href:!0});var Xsa=s(Mte);WUr=r(Xsa,"TFMPNetForSequenceClassification"),Xsa.forEach(t),UUr=r(_Je," (MPNet model)"),_Je.forEach(t),HUr=i(ae),zw=n(ae,"LI",{});var bJe=s(zw);MLe=n(bJe,"STRONG",{});var zsa=s(MLe);JUr=r(zsa,"openai-gpt"),zsa.forEach(t),YUr=r(bJe," \u2014 "),Ete=n(bJe,"A",{href:!0});var Qsa=s(Ete);KUr=r(Qsa,"TFOpenAIGPTForSequenceClassification"),Qsa.forEach(t),ZUr=r(bJe," (OpenAI GPT model)"),bJe.forEach(t),eHr=i(ae),Qw=n(ae,"LI",{});var vJe=s(Qw);ELe=n(vJe,"STRONG",{});var Wsa=s(ELe);oHr=r(Wsa,"rembert"),Wsa.forEach(t),rHr=r(vJe," \u2014 "),Cte=n(vJe,"A",{href:!0});var Usa=s(Cte);tHr=r(Usa,"TFRemBertForSequenceClassification"),Usa.forEach(t),aHr=r(vJe," (RemBERT model)"),vJe.forEach(t),nHr=i(ae),Ww=n(ae,"LI",{});var FJe=s(Ww);CLe=n(FJe,"STRONG",{});var Hsa=s(CLe);sHr=r(Hsa,"roberta"),Hsa.forEach(t),lHr=r(FJe," \u2014 "),wte=n(FJe,"A",{href:!0});var Jsa=s(wte);iHr=r(Jsa,"TFRobertaForSequenceClassification"),Jsa.forEach(t),dHr=r(FJe," (RoBERTa model)"),FJe.forEach(t),mHr=i(ae),Uw=n(ae,"LI",{});var TJe=s(Uw);wLe=n(TJe,"STRONG",{});var Ysa=s(wLe);cHr=r(Ysa,"roformer"),Ysa.forEach(t),fHr=r(TJe," \u2014 "),Ate=n(TJe,"A",{href:!0});var Ksa=s(Ate);gHr=r(Ksa,"TFRoFormerForSequenceClassification"),Ksa.forEach(t),hHr=r(TJe," (RoFormer model)"),TJe.forEach(t),uHr=i(ae),Hw=n(ae,"LI",{});var MJe=s(Hw);ALe=n(MJe,"STRONG",{});var Zsa=s(ALe);pHr=r(Zsa,"tapas"),Zsa.forEach(t),_Hr=r(MJe," \u2014 "),Lte=n(MJe,"A",{href:!0});var ela=s(Lte);bHr=r(ela,"TFTapasForSequenceClassification"),ela.forEach(t),vHr=r(MJe," (TAPAS model)"),MJe.forEach(t),FHr=i(ae),Jw=n(ae,"LI",{});var EJe=s(Jw);LLe=n(EJe,"STRONG",{});var ola=s(LLe);THr=r(ola,"transfo-xl"),ola.forEach(t),MHr=r(EJe," \u2014 "),yte=n(EJe,"A",{href:!0});var rla=s(yte);EHr=r(rla,"TFTransfoXLForSequenceClassification"),rla.forEach(t),CHr=r(EJe," (Transformer-XL model)"),EJe.forEach(t),wHr=i(ae),Yw=n(ae,"LI",{});var CJe=s(Yw);yLe=n(CJe,"STRONG",{});var tla=s(yLe);AHr=r(tla,"xlm"),tla.forEach(t),LHr=r(CJe," \u2014 "),xte=n(CJe,"A",{href:!0});var ala=s(xte);yHr=r(ala,"TFXLMForSequenceClassification"),ala.forEach(t),xHr=r(CJe," (XLM model)"),CJe.forEach(t),$Hr=i(ae),Kw=n(ae,"LI",{});var wJe=s(Kw);xLe=n(wJe,"STRONG",{});var nla=s(xLe);kHr=r(nla,"xlm-roberta"),nla.forEach(t),SHr=r(wJe," \u2014 "),$te=n(wJe,"A",{href:!0});var sla=s($te);RHr=r(sla,"TFXLMRobertaForSequenceClassification"),sla.forEach(t),PHr=r(wJe," (XLM-RoBERTa model)"),wJe.forEach(t),BHr=i(ae),Zw=n(ae,"LI",{});var AJe=s(Zw);$Le=n(AJe,"STRONG",{});var lla=s($Le);IHr=r(lla,"xlnet"),lla.forEach(t),NHr=r(AJe," \u2014 "),kte=n(AJe,"A",{href:!0});var ila=s(kte);qHr=r(ila,"TFXLNetForSequenceClassification"),ila.forEach(t),jHr=r(AJe," (XLNet model)"),AJe.forEach(t),ae.forEach(t),DHr=i(pi),T(eA.$$.fragment,pi),pi.forEach(t),ui.forEach(t),goo=i(c),gc=n(c,"H2",{class:!0});var yto=s(gc);oA=n(yto,"A",{id:!0,class:!0,href:!0});var dla=s(oA);kLe=n(dla,"SPAN",{});var mla=s(kLe);T(BS.$$.fragment,mla),mla.forEach(t),dla.forEach(t),GHr=i(yto),SLe=n(yto,"SPAN",{});var cla=s(SLe);OHr=r(cla,"TFAutoModelForMultipleChoice"),cla.forEach(t),yto.forEach(t),hoo=i(c),hr=n(c,"DIV",{class:!0});var _i=s(hr);T(IS.$$.fragment,_i),VHr=i(_i),hc=n(_i,"P",{});var hde=s(hc);XHr=r(hde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ste=n(hde,"A",{href:!0});var fla=s(Ste);zHr=r(fla,"from_pretrained()"),fla.forEach(t),QHr=r(hde," class method or the "),Rte=n(hde,"A",{href:!0});var gla=s(Rte);WHr=r(gla,"from_config()"),gla.forEach(t),UHr=r(hde,` class
method.`),hde.forEach(t),HHr=i(_i),NS=n(_i,"P",{});var xto=s(NS);JHr=r(xto,"This class cannot be instantiated directly using "),RLe=n(xto,"CODE",{});var hla=s(RLe);YHr=r(hla,"__init__()"),hla.forEach(t),KHr=r(xto," (throws an error)."),xto.forEach(t),ZHr=i(_i),Kt=n(_i,"DIV",{class:!0});var m9=s(Kt);T(qS.$$.fragment,m9),eJr=i(m9),PLe=n(m9,"P",{});var ula=s(PLe);oJr=r(ula,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ula.forEach(t),rJr=i(m9),uc=n(m9,"P",{});var ude=s(uc);tJr=r(ude,`Note:
Loading a model from its configuration file does `),BLe=n(ude,"STRONG",{});var pla=s(BLe);aJr=r(pla,"not"),pla.forEach(t),nJr=r(ude,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pte=n(ude,"A",{href:!0});var _la=s(Pte);sJr=r(_la,"from_pretrained()"),_la.forEach(t),lJr=r(ude," to load the model weights."),ude.forEach(t),iJr=i(m9),T(rA.$$.fragment,m9),m9.forEach(t),dJr=i(_i),Xr=n(_i,"DIV",{class:!0});var bi=s(Xr);T(jS.$$.fragment,bi),mJr=i(bi),ILe=n(bi,"P",{});var bla=s(ILe);cJr=r(bla,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),bla.forEach(t),fJr=i(bi),Rn=n(bi,"P",{});var c9=s(Rn);gJr=r(c9,"The model class to instantiate is selected based on the "),NLe=n(c9,"CODE",{});var vla=s(NLe);hJr=r(vla,"model_type"),vla.forEach(t),uJr=r(c9,` property of the config object (either
passed as an argument or loaded from `),qLe=n(c9,"CODE",{});var Fla=s(qLe);pJr=r(Fla,"pretrained_model_name_or_path"),Fla.forEach(t),_Jr=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jLe=n(c9,"CODE",{});var Tla=s(jLe);bJr=r(Tla,"pretrained_model_name_or_path"),Tla.forEach(t),vJr=r(c9,":"),c9.forEach(t),FJr=i(bi),ve=n(bi,"UL",{});var Te=s(ve);tA=n(Te,"LI",{});var LJe=s(tA);DLe=n(LJe,"STRONG",{});var Mla=s(DLe);TJr=r(Mla,"albert"),Mla.forEach(t),MJr=r(LJe," \u2014 "),Bte=n(LJe,"A",{href:!0});var Ela=s(Bte);EJr=r(Ela,"TFAlbertForMultipleChoice"),Ela.forEach(t),CJr=r(LJe," (ALBERT model)"),LJe.forEach(t),wJr=i(Te),aA=n(Te,"LI",{});var yJe=s(aA);GLe=n(yJe,"STRONG",{});var Cla=s(GLe);AJr=r(Cla,"bert"),Cla.forEach(t),LJr=r(yJe," \u2014 "),Ite=n(yJe,"A",{href:!0});var wla=s(Ite);yJr=r(wla,"TFBertForMultipleChoice"),wla.forEach(t),xJr=r(yJe," (BERT model)"),yJe.forEach(t),$Jr=i(Te),nA=n(Te,"LI",{});var xJe=s(nA);OLe=n(xJe,"STRONG",{});var Ala=s(OLe);kJr=r(Ala,"camembert"),Ala.forEach(t),SJr=r(xJe," \u2014 "),Nte=n(xJe,"A",{href:!0});var Lla=s(Nte);RJr=r(Lla,"TFCamembertForMultipleChoice"),Lla.forEach(t),PJr=r(xJe," (CamemBERT model)"),xJe.forEach(t),BJr=i(Te),sA=n(Te,"LI",{});var $Je=s(sA);VLe=n($Je,"STRONG",{});var yla=s(VLe);IJr=r(yla,"convbert"),yla.forEach(t),NJr=r($Je," \u2014 "),qte=n($Je,"A",{href:!0});var xla=s(qte);qJr=r(xla,"TFConvBertForMultipleChoice"),xla.forEach(t),jJr=r($Je," (ConvBERT model)"),$Je.forEach(t),DJr=i(Te),lA=n(Te,"LI",{});var kJe=s(lA);XLe=n(kJe,"STRONG",{});var $la=s(XLe);GJr=r($la,"distilbert"),$la.forEach(t),OJr=r(kJe," \u2014 "),jte=n(kJe,"A",{href:!0});var kla=s(jte);VJr=r(kla,"TFDistilBertForMultipleChoice"),kla.forEach(t),XJr=r(kJe," (DistilBERT model)"),kJe.forEach(t),zJr=i(Te),iA=n(Te,"LI",{});var SJe=s(iA);zLe=n(SJe,"STRONG",{});var Sla=s(zLe);QJr=r(Sla,"electra"),Sla.forEach(t),WJr=r(SJe," \u2014 "),Dte=n(SJe,"A",{href:!0});var Rla=s(Dte);UJr=r(Rla,"TFElectraForMultipleChoice"),Rla.forEach(t),HJr=r(SJe," (ELECTRA model)"),SJe.forEach(t),JJr=i(Te),dA=n(Te,"LI",{});var RJe=s(dA);QLe=n(RJe,"STRONG",{});var Pla=s(QLe);YJr=r(Pla,"flaubert"),Pla.forEach(t),KJr=r(RJe," \u2014 "),Gte=n(RJe,"A",{href:!0});var Bla=s(Gte);ZJr=r(Bla,"TFFlaubertForMultipleChoice"),Bla.forEach(t),eYr=r(RJe," (FlauBERT model)"),RJe.forEach(t),oYr=i(Te),mA=n(Te,"LI",{});var PJe=s(mA);WLe=n(PJe,"STRONG",{});var Ila=s(WLe);rYr=r(Ila,"funnel"),Ila.forEach(t),tYr=r(PJe," \u2014 "),Ote=n(PJe,"A",{href:!0});var Nla=s(Ote);aYr=r(Nla,"TFFunnelForMultipleChoice"),Nla.forEach(t),nYr=r(PJe," (Funnel Transformer model)"),PJe.forEach(t),sYr=i(Te),cA=n(Te,"LI",{});var BJe=s(cA);ULe=n(BJe,"STRONG",{});var qla=s(ULe);lYr=r(qla,"longformer"),qla.forEach(t),iYr=r(BJe," \u2014 "),Vte=n(BJe,"A",{href:!0});var jla=s(Vte);dYr=r(jla,"TFLongformerForMultipleChoice"),jla.forEach(t),mYr=r(BJe," (Longformer model)"),BJe.forEach(t),cYr=i(Te),fA=n(Te,"LI",{});var IJe=s(fA);HLe=n(IJe,"STRONG",{});var Dla=s(HLe);fYr=r(Dla,"mobilebert"),Dla.forEach(t),gYr=r(IJe," \u2014 "),Xte=n(IJe,"A",{href:!0});var Gla=s(Xte);hYr=r(Gla,"TFMobileBertForMultipleChoice"),Gla.forEach(t),uYr=r(IJe," (MobileBERT model)"),IJe.forEach(t),pYr=i(Te),gA=n(Te,"LI",{});var NJe=s(gA);JLe=n(NJe,"STRONG",{});var Ola=s(JLe);_Yr=r(Ola,"mpnet"),Ola.forEach(t),bYr=r(NJe," \u2014 "),zte=n(NJe,"A",{href:!0});var Vla=s(zte);vYr=r(Vla,"TFMPNetForMultipleChoice"),Vla.forEach(t),FYr=r(NJe," (MPNet model)"),NJe.forEach(t),TYr=i(Te),hA=n(Te,"LI",{});var qJe=s(hA);YLe=n(qJe,"STRONG",{});var Xla=s(YLe);MYr=r(Xla,"rembert"),Xla.forEach(t),EYr=r(qJe," \u2014 "),Qte=n(qJe,"A",{href:!0});var zla=s(Qte);CYr=r(zla,"TFRemBertForMultipleChoice"),zla.forEach(t),wYr=r(qJe," (RemBERT model)"),qJe.forEach(t),AYr=i(Te),uA=n(Te,"LI",{});var jJe=s(uA);KLe=n(jJe,"STRONG",{});var Qla=s(KLe);LYr=r(Qla,"roberta"),Qla.forEach(t),yYr=r(jJe," \u2014 "),Wte=n(jJe,"A",{href:!0});var Wla=s(Wte);xYr=r(Wla,"TFRobertaForMultipleChoice"),Wla.forEach(t),$Yr=r(jJe," (RoBERTa model)"),jJe.forEach(t),kYr=i(Te),pA=n(Te,"LI",{});var DJe=s(pA);ZLe=n(DJe,"STRONG",{});var Ula=s(ZLe);SYr=r(Ula,"roformer"),Ula.forEach(t),RYr=r(DJe," \u2014 "),Ute=n(DJe,"A",{href:!0});var Hla=s(Ute);PYr=r(Hla,"TFRoFormerForMultipleChoice"),Hla.forEach(t),BYr=r(DJe," (RoFormer model)"),DJe.forEach(t),IYr=i(Te),_A=n(Te,"LI",{});var GJe=s(_A);eye=n(GJe,"STRONG",{});var Jla=s(eye);NYr=r(Jla,"xlm"),Jla.forEach(t),qYr=r(GJe," \u2014 "),Hte=n(GJe,"A",{href:!0});var Yla=s(Hte);jYr=r(Yla,"TFXLMForMultipleChoice"),Yla.forEach(t),DYr=r(GJe," (XLM model)"),GJe.forEach(t),GYr=i(Te),bA=n(Te,"LI",{});var OJe=s(bA);oye=n(OJe,"STRONG",{});var Kla=s(oye);OYr=r(Kla,"xlm-roberta"),Kla.forEach(t),VYr=r(OJe," \u2014 "),Jte=n(OJe,"A",{href:!0});var Zla=s(Jte);XYr=r(Zla,"TFXLMRobertaForMultipleChoice"),Zla.forEach(t),zYr=r(OJe," (XLM-RoBERTa model)"),OJe.forEach(t),QYr=i(Te),vA=n(Te,"LI",{});var VJe=s(vA);rye=n(VJe,"STRONG",{});var eia=s(rye);WYr=r(eia,"xlnet"),eia.forEach(t),UYr=r(VJe," \u2014 "),Yte=n(VJe,"A",{href:!0});var oia=s(Yte);HYr=r(oia,"TFXLNetForMultipleChoice"),oia.forEach(t),JYr=r(VJe," (XLNet model)"),VJe.forEach(t),Te.forEach(t),YYr=i(bi),T(FA.$$.fragment,bi),bi.forEach(t),_i.forEach(t),uoo=i(c),pc=n(c,"H2",{class:!0});var $to=s(pc);TA=n($to,"A",{id:!0,class:!0,href:!0});var ria=s(TA);tye=n(ria,"SPAN",{});var tia=s(tye);T(DS.$$.fragment,tia),tia.forEach(t),ria.forEach(t),KYr=i($to),aye=n($to,"SPAN",{});var aia=s(aye);ZYr=r(aia,"TFAutoModelForNextSentencePrediction"),aia.forEach(t),$to.forEach(t),poo=i(c),ur=n(c,"DIV",{class:!0});var vi=s(ur);T(GS.$$.fragment,vi),eKr=i(vi),_c=n(vi,"P",{});var pde=s(_c);oKr=r(pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Kte=n(pde,"A",{href:!0});var nia=s(Kte);rKr=r(nia,"from_pretrained()"),nia.forEach(t),tKr=r(pde," class method or the "),Zte=n(pde,"A",{href:!0});var sia=s(Zte);aKr=r(sia,"from_config()"),sia.forEach(t),nKr=r(pde,` class
method.`),pde.forEach(t),sKr=i(vi),OS=n(vi,"P",{});var kto=s(OS);lKr=r(kto,"This class cannot be instantiated directly using "),nye=n(kto,"CODE",{});var lia=s(nye);iKr=r(lia,"__init__()"),lia.forEach(t),dKr=r(kto," (throws an error)."),kto.forEach(t),mKr=i(vi),Zt=n(vi,"DIV",{class:!0});var f9=s(Zt);T(VS.$$.fragment,f9),cKr=i(f9),sye=n(f9,"P",{});var iia=s(sye);fKr=r(iia,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),iia.forEach(t),gKr=i(f9),bc=n(f9,"P",{});var _de=s(bc);hKr=r(_de,`Note:
Loading a model from its configuration file does `),lye=n(_de,"STRONG",{});var dia=s(lye);uKr=r(dia,"not"),dia.forEach(t),pKr=r(_de,` load the model weights. It only affects the
model\u2019s configuration. Use `),eae=n(_de,"A",{href:!0});var mia=s(eae);_Kr=r(mia,"from_pretrained()"),mia.forEach(t),bKr=r(_de," to load the model weights."),_de.forEach(t),vKr=i(f9),T(MA.$$.fragment,f9),f9.forEach(t),FKr=i(vi),zr=n(vi,"DIV",{class:!0});var Fi=s(zr);T(XS.$$.fragment,Fi),TKr=i(Fi),iye=n(Fi,"P",{});var cia=s(iye);MKr=r(cia,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),cia.forEach(t),EKr=i(Fi),Pn=n(Fi,"P",{});var g9=s(Pn);CKr=r(g9,"The model class to instantiate is selected based on the "),dye=n(g9,"CODE",{});var fia=s(dye);wKr=r(fia,"model_type"),fia.forEach(t),AKr=r(g9,` property of the config object (either
passed as an argument or loaded from `),mye=n(g9,"CODE",{});var gia=s(mye);LKr=r(gia,"pretrained_model_name_or_path"),gia.forEach(t),yKr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cye=n(g9,"CODE",{});var hia=s(cye);xKr=r(hia,"pretrained_model_name_or_path"),hia.forEach(t),$Kr=r(g9,":"),g9.forEach(t),kKr=i(Fi),zS=n(Fi,"UL",{});var Sto=s(zS);EA=n(Sto,"LI",{});var XJe=s(EA);fye=n(XJe,"STRONG",{});var uia=s(fye);SKr=r(uia,"bert"),uia.forEach(t),RKr=r(XJe," \u2014 "),oae=n(XJe,"A",{href:!0});var pia=s(oae);PKr=r(pia,"TFBertForNextSentencePrediction"),pia.forEach(t),BKr=r(XJe," (BERT model)"),XJe.forEach(t),IKr=i(Sto),CA=n(Sto,"LI",{});var zJe=s(CA);gye=n(zJe,"STRONG",{});var _ia=s(gye);NKr=r(_ia,"mobilebert"),_ia.forEach(t),qKr=r(zJe," \u2014 "),rae=n(zJe,"A",{href:!0});var bia=s(rae);jKr=r(bia,"TFMobileBertForNextSentencePrediction"),bia.forEach(t),DKr=r(zJe," (MobileBERT model)"),zJe.forEach(t),Sto.forEach(t),GKr=i(Fi),T(wA.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),_oo=i(c),vc=n(c,"H2",{class:!0});var Rto=s(vc);AA=n(Rto,"A",{id:!0,class:!0,href:!0});var via=s(AA);hye=n(via,"SPAN",{});var Fia=s(hye);T(QS.$$.fragment,Fia),Fia.forEach(t),via.forEach(t),OKr=i(Rto),uye=n(Rto,"SPAN",{});var Tia=s(uye);VKr=r(Tia,"TFAutoModelForTableQuestionAnswering"),Tia.forEach(t),Rto.forEach(t),boo=i(c),pr=n(c,"DIV",{class:!0});var Ti=s(pr);T(WS.$$.fragment,Ti),XKr=i(Ti),Fc=n(Ti,"P",{});var bde=s(Fc);zKr=r(bde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),tae=n(bde,"A",{href:!0});var Mia=s(tae);QKr=r(Mia,"from_pretrained()"),Mia.forEach(t),WKr=r(bde," class method or the "),aae=n(bde,"A",{href:!0});var Eia=s(aae);UKr=r(Eia,"from_config()"),Eia.forEach(t),HKr=r(bde,` class
method.`),bde.forEach(t),JKr=i(Ti),US=n(Ti,"P",{});var Pto=s(US);YKr=r(Pto,"This class cannot be instantiated directly using "),pye=n(Pto,"CODE",{});var Cia=s(pye);KKr=r(Cia,"__init__()"),Cia.forEach(t),ZKr=r(Pto," (throws an error)."),Pto.forEach(t),eZr=i(Ti),ea=n(Ti,"DIV",{class:!0});var h9=s(ea);T(HS.$$.fragment,h9),oZr=i(h9),_ye=n(h9,"P",{});var wia=s(_ye);rZr=r(wia,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),wia.forEach(t),tZr=i(h9),Tc=n(h9,"P",{});var vde=s(Tc);aZr=r(vde,`Note:
Loading a model from its configuration file does `),bye=n(vde,"STRONG",{});var Aia=s(bye);nZr=r(Aia,"not"),Aia.forEach(t),sZr=r(vde,` load the model weights. It only affects the
model\u2019s configuration. Use `),nae=n(vde,"A",{href:!0});var Lia=s(nae);lZr=r(Lia,"from_pretrained()"),Lia.forEach(t),iZr=r(vde," to load the model weights."),vde.forEach(t),dZr=i(h9),T(LA.$$.fragment,h9),h9.forEach(t),mZr=i(Ti),Qr=n(Ti,"DIV",{class:!0});var Mi=s(Qr);T(JS.$$.fragment,Mi),cZr=i(Mi),vye=n(Mi,"P",{});var yia=s(vye);fZr=r(yia,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),yia.forEach(t),gZr=i(Mi),Bn=n(Mi,"P",{});var u9=s(Bn);hZr=r(u9,"The model class to instantiate is selected based on the "),Fye=n(u9,"CODE",{});var xia=s(Fye);uZr=r(xia,"model_type"),xia.forEach(t),pZr=r(u9,` property of the config object (either
passed as an argument or loaded from `),Tye=n(u9,"CODE",{});var $ia=s(Tye);_Zr=r($ia,"pretrained_model_name_or_path"),$ia.forEach(t),bZr=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mye=n(u9,"CODE",{});var kia=s(Mye);vZr=r(kia,"pretrained_model_name_or_path"),kia.forEach(t),FZr=r(u9,":"),u9.forEach(t),TZr=i(Mi),Eye=n(Mi,"UL",{});var Sia=s(Eye);yA=n(Sia,"LI",{});var QJe=s(yA);Cye=n(QJe,"STRONG",{});var Ria=s(Cye);MZr=r(Ria,"tapas"),Ria.forEach(t),EZr=r(QJe," \u2014 "),sae=n(QJe,"A",{href:!0});var Pia=s(sae);CZr=r(Pia,"TFTapasForQuestionAnswering"),Pia.forEach(t),wZr=r(QJe," (TAPAS model)"),QJe.forEach(t),Sia.forEach(t),AZr=i(Mi),T(xA.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),voo=i(c),Mc=n(c,"H2",{class:!0});var Bto=s(Mc);$A=n(Bto,"A",{id:!0,class:!0,href:!0});var Bia=s($A);wye=n(Bia,"SPAN",{});var Iia=s(wye);T(YS.$$.fragment,Iia),Iia.forEach(t),Bia.forEach(t),LZr=i(Bto),Aye=n(Bto,"SPAN",{});var Nia=s(Aye);yZr=r(Nia,"TFAutoModelForDocumentQuestionAnswering"),Nia.forEach(t),Bto.forEach(t),Foo=i(c),_r=n(c,"DIV",{class:!0});var Ei=s(_r);T(KS.$$.fragment,Ei),xZr=i(Ei),Ec=n(Ei,"P",{});var Fde=s(Ec);$Zr=r(Fde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),lae=n(Fde,"A",{href:!0});var qia=s(lae);kZr=r(qia,"from_pretrained()"),qia.forEach(t),SZr=r(Fde," class method or the "),iae=n(Fde,"A",{href:!0});var jia=s(iae);RZr=r(jia,"from_config()"),jia.forEach(t),PZr=r(Fde,` class
method.`),Fde.forEach(t),BZr=i(Ei),ZS=n(Ei,"P",{});var Ito=s(ZS);IZr=r(Ito,"This class cannot be instantiated directly using "),Lye=n(Ito,"CODE",{});var Dia=s(Lye);NZr=r(Dia,"__init__()"),Dia.forEach(t),qZr=r(Ito," (throws an error)."),Ito.forEach(t),jZr=i(Ei),oa=n(Ei,"DIV",{class:!0});var p9=s(oa);T(eR.$$.fragment,p9),DZr=i(p9),yye=n(p9,"P",{});var Gia=s(yye);GZr=r(Gia,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Gia.forEach(t),OZr=i(p9),Cc=n(p9,"P",{});var Tde=s(Cc);VZr=r(Tde,`Note:
Loading a model from its configuration file does `),xye=n(Tde,"STRONG",{});var Oia=s(xye);XZr=r(Oia,"not"),Oia.forEach(t),zZr=r(Tde,` load the model weights. It only affects the
model\u2019s configuration. Use `),dae=n(Tde,"A",{href:!0});var Via=s(dae);QZr=r(Via,"from_pretrained()"),Via.forEach(t),WZr=r(Tde," to load the model weights."),Tde.forEach(t),UZr=i(p9),T(kA.$$.fragment,p9),p9.forEach(t),HZr=i(Ei),Wr=n(Ei,"DIV",{class:!0});var Ci=s(Wr);T(oR.$$.fragment,Ci),JZr=i(Ci),$ye=n(Ci,"P",{});var Xia=s($ye);YZr=r(Xia,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Xia.forEach(t),KZr=i(Ci),In=n(Ci,"P",{});var _9=s(In);ZZr=r(_9,"The model class to instantiate is selected based on the "),kye=n(_9,"CODE",{});var zia=s(kye);eet=r(zia,"model_type"),zia.forEach(t),oet=r(_9,` property of the config object (either
passed as an argument or loaded from `),Sye=n(_9,"CODE",{});var Qia=s(Sye);ret=r(Qia,"pretrained_model_name_or_path"),Qia.forEach(t),tet=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rye=n(_9,"CODE",{});var Wia=s(Rye);aet=r(Wia,"pretrained_model_name_or_path"),Wia.forEach(t),net=r(_9,":"),_9.forEach(t),set=i(Ci),Pye=n(Ci,"UL",{});var Uia=s(Pye);SA=n(Uia,"LI",{});var WJe=s(SA);Bye=n(WJe,"STRONG",{});var Hia=s(Bye);iet=r(Hia,"layoutlm"),Hia.forEach(t),det=r(WJe," \u2014 "),mae=n(WJe,"A",{href:!0});var Jia=s(mae);met=r(Jia,"TFLayoutLMForQuestionAnswering"),Jia.forEach(t),cet=r(WJe," (LayoutLM model)"),WJe.forEach(t),Uia.forEach(t),fet=i(Ci),T(RA.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),Too=i(c),wc=n(c,"H2",{class:!0});var Nto=s(wc);PA=n(Nto,"A",{id:!0,class:!0,href:!0});var Yia=s(PA);Iye=n(Yia,"SPAN",{});var Kia=s(Iye);T(rR.$$.fragment,Kia),Kia.forEach(t),Yia.forEach(t),get=i(Nto),Nye=n(Nto,"SPAN",{});var Zia=s(Nye);het=r(Zia,"TFAutoModelForTokenClassification"),Zia.forEach(t),Nto.forEach(t),Moo=i(c),br=n(c,"DIV",{class:!0});var wi=s(br);T(tR.$$.fragment,wi),uet=i(wi),Ac=n(wi,"P",{});var Mde=s(Ac);pet=r(Mde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),cae=n(Mde,"A",{href:!0});var eda=s(cae);_et=r(eda,"from_pretrained()"),eda.forEach(t),bet=r(Mde," class method or the "),fae=n(Mde,"A",{href:!0});var oda=s(fae);vet=r(oda,"from_config()"),oda.forEach(t),Fet=r(Mde,` class
method.`),Mde.forEach(t),Tet=i(wi),aR=n(wi,"P",{});var qto=s(aR);Met=r(qto,"This class cannot be instantiated directly using "),qye=n(qto,"CODE",{});var rda=s(qye);Eet=r(rda,"__init__()"),rda.forEach(t),Cet=r(qto," (throws an error)."),qto.forEach(t),wet=i(wi),ra=n(wi,"DIV",{class:!0});var b9=s(ra);T(nR.$$.fragment,b9),Aet=i(b9),jye=n(b9,"P",{});var tda=s(jye);Let=r(tda,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),tda.forEach(t),yet=i(b9),Lc=n(b9,"P",{});var Ede=s(Lc);xet=r(Ede,`Note:
Loading a model from its configuration file does `),Dye=n(Ede,"STRONG",{});var ada=s(Dye);$et=r(ada,"not"),ada.forEach(t),ket=r(Ede,` load the model weights. It only affects the
model\u2019s configuration. Use `),gae=n(Ede,"A",{href:!0});var nda=s(gae);Set=r(nda,"from_pretrained()"),nda.forEach(t),Ret=r(Ede," to load the model weights."),Ede.forEach(t),Pet=i(b9),T(BA.$$.fragment,b9),b9.forEach(t),Bet=i(wi),Ur=n(wi,"DIV",{class:!0});var Ai=s(Ur);T(sR.$$.fragment,Ai),Iet=i(Ai),Gye=n(Ai,"P",{});var sda=s(Gye);Net=r(sda,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),sda.forEach(t),qet=i(Ai),Nn=n(Ai,"P",{});var v9=s(Nn);jet=r(v9,"The model class to instantiate is selected based on the "),Oye=n(v9,"CODE",{});var lda=s(Oye);Det=r(lda,"model_type"),lda.forEach(t),Get=r(v9,` property of the config object (either
passed as an argument or loaded from `),Vye=n(v9,"CODE",{});var ida=s(Vye);Oet=r(ida,"pretrained_model_name_or_path"),ida.forEach(t),Vet=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xye=n(v9,"CODE",{});var dda=s(Xye);Xet=r(dda,"pretrained_model_name_or_path"),dda.forEach(t),zet=r(v9,":"),v9.forEach(t),Qet=i(Ai),de=n(Ai,"UL",{});var he=s(de);IA=n(he,"LI",{});var UJe=s(IA);zye=n(UJe,"STRONG",{});var mda=s(zye);Wet=r(mda,"albert"),mda.forEach(t),Uet=r(UJe," \u2014 "),hae=n(UJe,"A",{href:!0});var cda=s(hae);Het=r(cda,"TFAlbertForTokenClassification"),cda.forEach(t),Jet=r(UJe," (ALBERT model)"),UJe.forEach(t),Yet=i(he),NA=n(he,"LI",{});var HJe=s(NA);Qye=n(HJe,"STRONG",{});var fda=s(Qye);Ket=r(fda,"bert"),fda.forEach(t),Zet=r(HJe," \u2014 "),uae=n(HJe,"A",{href:!0});var gda=s(uae);eot=r(gda,"TFBertForTokenClassification"),gda.forEach(t),oot=r(HJe," (BERT model)"),HJe.forEach(t),rot=i(he),qA=n(he,"LI",{});var JJe=s(qA);Wye=n(JJe,"STRONG",{});var hda=s(Wye);tot=r(hda,"camembert"),hda.forEach(t),aot=r(JJe," \u2014 "),pae=n(JJe,"A",{href:!0});var uda=s(pae);not=r(uda,"TFCamembertForTokenClassification"),uda.forEach(t),sot=r(JJe," (CamemBERT model)"),JJe.forEach(t),lot=i(he),jA=n(he,"LI",{});var YJe=s(jA);Uye=n(YJe,"STRONG",{});var pda=s(Uye);iot=r(pda,"convbert"),pda.forEach(t),dot=r(YJe," \u2014 "),_ae=n(YJe,"A",{href:!0});var _da=s(_ae);mot=r(_da,"TFConvBertForTokenClassification"),_da.forEach(t),cot=r(YJe," (ConvBERT model)"),YJe.forEach(t),fot=i(he),DA=n(he,"LI",{});var KJe=s(DA);Hye=n(KJe,"STRONG",{});var bda=s(Hye);got=r(bda,"deberta"),bda.forEach(t),hot=r(KJe," \u2014 "),bae=n(KJe,"A",{href:!0});var vda=s(bae);uot=r(vda,"TFDebertaForTokenClassification"),vda.forEach(t),pot=r(KJe," (DeBERTa model)"),KJe.forEach(t),_ot=i(he),GA=n(he,"LI",{});var ZJe=s(GA);Jye=n(ZJe,"STRONG",{});var Fda=s(Jye);bot=r(Fda,"deberta-v2"),Fda.forEach(t),vot=r(ZJe," \u2014 "),vae=n(ZJe,"A",{href:!0});var Tda=s(vae);Fot=r(Tda,"TFDebertaV2ForTokenClassification"),Tda.forEach(t),Tot=r(ZJe," (DeBERTa-v2 model)"),ZJe.forEach(t),Mot=i(he),OA=n(he,"LI",{});var eYe=s(OA);Yye=n(eYe,"STRONG",{});var Mda=s(Yye);Eot=r(Mda,"distilbert"),Mda.forEach(t),Cot=r(eYe," \u2014 "),Fae=n(eYe,"A",{href:!0});var Eda=s(Fae);wot=r(Eda,"TFDistilBertForTokenClassification"),Eda.forEach(t),Aot=r(eYe," (DistilBERT model)"),eYe.forEach(t),Lot=i(he),VA=n(he,"LI",{});var oYe=s(VA);Kye=n(oYe,"STRONG",{});var Cda=s(Kye);yot=r(Cda,"electra"),Cda.forEach(t),xot=r(oYe," \u2014 "),Tae=n(oYe,"A",{href:!0});var wda=s(Tae);$ot=r(wda,"TFElectraForTokenClassification"),wda.forEach(t),kot=r(oYe," (ELECTRA model)"),oYe.forEach(t),Sot=i(he),XA=n(he,"LI",{});var rYe=s(XA);Zye=n(rYe,"STRONG",{});var Ada=s(Zye);Rot=r(Ada,"flaubert"),Ada.forEach(t),Pot=r(rYe," \u2014 "),Mae=n(rYe,"A",{href:!0});var Lda=s(Mae);Bot=r(Lda,"TFFlaubertForTokenClassification"),Lda.forEach(t),Iot=r(rYe," (FlauBERT model)"),rYe.forEach(t),Not=i(he),zA=n(he,"LI",{});var tYe=s(zA);e8e=n(tYe,"STRONG",{});var yda=s(e8e);qot=r(yda,"funnel"),yda.forEach(t),jot=r(tYe," \u2014 "),Eae=n(tYe,"A",{href:!0});var xda=s(Eae);Dot=r(xda,"TFFunnelForTokenClassification"),xda.forEach(t),Got=r(tYe," (Funnel Transformer model)"),tYe.forEach(t),Oot=i(he),QA=n(he,"LI",{});var aYe=s(QA);o8e=n(aYe,"STRONG",{});var $da=s(o8e);Vot=r($da,"layoutlm"),$da.forEach(t),Xot=r(aYe," \u2014 "),Cae=n(aYe,"A",{href:!0});var kda=s(Cae);zot=r(kda,"TFLayoutLMForTokenClassification"),kda.forEach(t),Qot=r(aYe," (LayoutLM model)"),aYe.forEach(t),Wot=i(he),WA=n(he,"LI",{});var nYe=s(WA);r8e=n(nYe,"STRONG",{});var Sda=s(r8e);Uot=r(Sda,"layoutlmv3"),Sda.forEach(t),Hot=r(nYe," \u2014 "),wae=n(nYe,"A",{href:!0});var Rda=s(wae);Jot=r(Rda,"TFLayoutLMv3ForTokenClassification"),Rda.forEach(t),Yot=r(nYe," (LayoutLMv3 model)"),nYe.forEach(t),Kot=i(he),UA=n(he,"LI",{});var sYe=s(UA);t8e=n(sYe,"STRONG",{});var Pda=s(t8e);Zot=r(Pda,"longformer"),Pda.forEach(t),ert=r(sYe," \u2014 "),Aae=n(sYe,"A",{href:!0});var Bda=s(Aae);ort=r(Bda,"TFLongformerForTokenClassification"),Bda.forEach(t),rrt=r(sYe," (Longformer model)"),sYe.forEach(t),trt=i(he),HA=n(he,"LI",{});var lYe=s(HA);a8e=n(lYe,"STRONG",{});var Ida=s(a8e);art=r(Ida,"mobilebert"),Ida.forEach(t),nrt=r(lYe," \u2014 "),Lae=n(lYe,"A",{href:!0});var Nda=s(Lae);srt=r(Nda,"TFMobileBertForTokenClassification"),Nda.forEach(t),lrt=r(lYe," (MobileBERT model)"),lYe.forEach(t),irt=i(he),JA=n(he,"LI",{});var iYe=s(JA);n8e=n(iYe,"STRONG",{});var qda=s(n8e);drt=r(qda,"mpnet"),qda.forEach(t),mrt=r(iYe," \u2014 "),yae=n(iYe,"A",{href:!0});var jda=s(yae);crt=r(jda,"TFMPNetForTokenClassification"),jda.forEach(t),frt=r(iYe," (MPNet model)"),iYe.forEach(t),grt=i(he),YA=n(he,"LI",{});var dYe=s(YA);s8e=n(dYe,"STRONG",{});var Dda=s(s8e);hrt=r(Dda,"rembert"),Dda.forEach(t),urt=r(dYe," \u2014 "),xae=n(dYe,"A",{href:!0});var Gda=s(xae);prt=r(Gda,"TFRemBertForTokenClassification"),Gda.forEach(t),_rt=r(dYe," (RemBERT model)"),dYe.forEach(t),brt=i(he),KA=n(he,"LI",{});var mYe=s(KA);l8e=n(mYe,"STRONG",{});var Oda=s(l8e);vrt=r(Oda,"roberta"),Oda.forEach(t),Frt=r(mYe," \u2014 "),$ae=n(mYe,"A",{href:!0});var Vda=s($ae);Trt=r(Vda,"TFRobertaForTokenClassification"),Vda.forEach(t),Mrt=r(mYe," (RoBERTa model)"),mYe.forEach(t),Ert=i(he),ZA=n(he,"LI",{});var cYe=s(ZA);i8e=n(cYe,"STRONG",{});var Xda=s(i8e);Crt=r(Xda,"roformer"),Xda.forEach(t),wrt=r(cYe," \u2014 "),kae=n(cYe,"A",{href:!0});var zda=s(kae);Art=r(zda,"TFRoFormerForTokenClassification"),zda.forEach(t),Lrt=r(cYe," (RoFormer model)"),cYe.forEach(t),yrt=i(he),e6=n(he,"LI",{});var fYe=s(e6);d8e=n(fYe,"STRONG",{});var Qda=s(d8e);xrt=r(Qda,"xlm"),Qda.forEach(t),$rt=r(fYe," \u2014 "),Sae=n(fYe,"A",{href:!0});var Wda=s(Sae);krt=r(Wda,"TFXLMForTokenClassification"),Wda.forEach(t),Srt=r(fYe," (XLM model)"),fYe.forEach(t),Rrt=i(he),o6=n(he,"LI",{});var gYe=s(o6);m8e=n(gYe,"STRONG",{});var Uda=s(m8e);Prt=r(Uda,"xlm-roberta"),Uda.forEach(t),Brt=r(gYe," \u2014 "),Rae=n(gYe,"A",{href:!0});var Hda=s(Rae);Irt=r(Hda,"TFXLMRobertaForTokenClassification"),Hda.forEach(t),Nrt=r(gYe," (XLM-RoBERTa model)"),gYe.forEach(t),qrt=i(he),r6=n(he,"LI",{});var hYe=s(r6);c8e=n(hYe,"STRONG",{});var Jda=s(c8e);jrt=r(Jda,"xlnet"),Jda.forEach(t),Drt=r(hYe," \u2014 "),Pae=n(hYe,"A",{href:!0});var Yda=s(Pae);Grt=r(Yda,"TFXLNetForTokenClassification"),Yda.forEach(t),Ort=r(hYe," (XLNet model)"),hYe.forEach(t),he.forEach(t),Vrt=i(Ai),T(t6.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),Eoo=i(c),yc=n(c,"H2",{class:!0});var jto=s(yc);a6=n(jto,"A",{id:!0,class:!0,href:!0});var Kda=s(a6);f8e=n(Kda,"SPAN",{});var Zda=s(f8e);T(lR.$$.fragment,Zda),Zda.forEach(t),Kda.forEach(t),Xrt=i(jto),g8e=n(jto,"SPAN",{});var ema=s(g8e);zrt=r(ema,"TFAutoModelForQuestionAnswering"),ema.forEach(t),jto.forEach(t),Coo=i(c),vr=n(c,"DIV",{class:!0});var Li=s(vr);T(iR.$$.fragment,Li),Qrt=i(Li),xc=n(Li,"P",{});var Cde=s(xc);Wrt=r(Cde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Bae=n(Cde,"A",{href:!0});var oma=s(Bae);Urt=r(oma,"from_pretrained()"),oma.forEach(t),Hrt=r(Cde," class method or the "),Iae=n(Cde,"A",{href:!0});var rma=s(Iae);Jrt=r(rma,"from_config()"),rma.forEach(t),Yrt=r(Cde,` class
method.`),Cde.forEach(t),Krt=i(Li),dR=n(Li,"P",{});var Dto=s(dR);Zrt=r(Dto,"This class cannot be instantiated directly using "),h8e=n(Dto,"CODE",{});var tma=s(h8e);ett=r(tma,"__init__()"),tma.forEach(t),ott=r(Dto," (throws an error)."),Dto.forEach(t),rtt=i(Li),ta=n(Li,"DIV",{class:!0});var F9=s(ta);T(mR.$$.fragment,F9),ttt=i(F9),u8e=n(F9,"P",{});var ama=s(u8e);att=r(ama,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ama.forEach(t),ntt=i(F9),$c=n(F9,"P",{});var wde=s($c);stt=r(wde,`Note:
Loading a model from its configuration file does `),p8e=n(wde,"STRONG",{});var nma=s(p8e);ltt=r(nma,"not"),nma.forEach(t),itt=r(wde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nae=n(wde,"A",{href:!0});var sma=s(Nae);dtt=r(sma,"from_pretrained()"),sma.forEach(t),mtt=r(wde," to load the model weights."),wde.forEach(t),ctt=i(F9),T(n6.$$.fragment,F9),F9.forEach(t),ftt=i(Li),Hr=n(Li,"DIV",{class:!0});var yi=s(Hr);T(cR.$$.fragment,yi),gtt=i(yi),_8e=n(yi,"P",{});var lma=s(_8e);htt=r(lma,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),lma.forEach(t),utt=i(yi),qn=n(yi,"P",{});var T9=s(qn);ptt=r(T9,"The model class to instantiate is selected based on the "),b8e=n(T9,"CODE",{});var ima=s(b8e);_tt=r(ima,"model_type"),ima.forEach(t),btt=r(T9,` property of the config object (either
passed as an argument or loaded from `),v8e=n(T9,"CODE",{});var dma=s(v8e);vtt=r(dma,"pretrained_model_name_or_path"),dma.forEach(t),Ftt=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F8e=n(T9,"CODE",{});var mma=s(F8e);Ttt=r(mma,"pretrained_model_name_or_path"),mma.forEach(t),Mtt=r(T9,":"),T9.forEach(t),Ett=i(yi),me=n(yi,"UL",{});var ue=s(me);s6=n(ue,"LI",{});var uYe=s(s6);T8e=n(uYe,"STRONG",{});var cma=s(T8e);Ctt=r(cma,"albert"),cma.forEach(t),wtt=r(uYe," \u2014 "),qae=n(uYe,"A",{href:!0});var fma=s(qae);Att=r(fma,"TFAlbertForQuestionAnswering"),fma.forEach(t),Ltt=r(uYe," (ALBERT model)"),uYe.forEach(t),ytt=i(ue),l6=n(ue,"LI",{});var pYe=s(l6);M8e=n(pYe,"STRONG",{});var gma=s(M8e);xtt=r(gma,"bert"),gma.forEach(t),$tt=r(pYe," \u2014 "),jae=n(pYe,"A",{href:!0});var hma=s(jae);ktt=r(hma,"TFBertForQuestionAnswering"),hma.forEach(t),Stt=r(pYe," (BERT model)"),pYe.forEach(t),Rtt=i(ue),i6=n(ue,"LI",{});var _Ye=s(i6);E8e=n(_Ye,"STRONG",{});var uma=s(E8e);Ptt=r(uma,"camembert"),uma.forEach(t),Btt=r(_Ye," \u2014 "),Dae=n(_Ye,"A",{href:!0});var pma=s(Dae);Itt=r(pma,"TFCamembertForQuestionAnswering"),pma.forEach(t),Ntt=r(_Ye," (CamemBERT model)"),_Ye.forEach(t),qtt=i(ue),d6=n(ue,"LI",{});var bYe=s(d6);C8e=n(bYe,"STRONG",{});var _ma=s(C8e);jtt=r(_ma,"convbert"),_ma.forEach(t),Dtt=r(bYe," \u2014 "),Gae=n(bYe,"A",{href:!0});var bma=s(Gae);Gtt=r(bma,"TFConvBertForQuestionAnswering"),bma.forEach(t),Ott=r(bYe," (ConvBERT model)"),bYe.forEach(t),Vtt=i(ue),m6=n(ue,"LI",{});var vYe=s(m6);w8e=n(vYe,"STRONG",{});var vma=s(w8e);Xtt=r(vma,"deberta"),vma.forEach(t),ztt=r(vYe," \u2014 "),Oae=n(vYe,"A",{href:!0});var Fma=s(Oae);Qtt=r(Fma,"TFDebertaForQuestionAnswering"),Fma.forEach(t),Wtt=r(vYe," (DeBERTa model)"),vYe.forEach(t),Utt=i(ue),c6=n(ue,"LI",{});var FYe=s(c6);A8e=n(FYe,"STRONG",{});var Tma=s(A8e);Htt=r(Tma,"deberta-v2"),Tma.forEach(t),Jtt=r(FYe," \u2014 "),Vae=n(FYe,"A",{href:!0});var Mma=s(Vae);Ytt=r(Mma,"TFDebertaV2ForQuestionAnswering"),Mma.forEach(t),Ktt=r(FYe," (DeBERTa-v2 model)"),FYe.forEach(t),Ztt=i(ue),f6=n(ue,"LI",{});var TYe=s(f6);L8e=n(TYe,"STRONG",{});var Ema=s(L8e);eat=r(Ema,"distilbert"),Ema.forEach(t),oat=r(TYe," \u2014 "),Xae=n(TYe,"A",{href:!0});var Cma=s(Xae);rat=r(Cma,"TFDistilBertForQuestionAnswering"),Cma.forEach(t),tat=r(TYe," (DistilBERT model)"),TYe.forEach(t),aat=i(ue),g6=n(ue,"LI",{});var MYe=s(g6);y8e=n(MYe,"STRONG",{});var wma=s(y8e);nat=r(wma,"electra"),wma.forEach(t),sat=r(MYe," \u2014 "),zae=n(MYe,"A",{href:!0});var Ama=s(zae);lat=r(Ama,"TFElectraForQuestionAnswering"),Ama.forEach(t),iat=r(MYe," (ELECTRA model)"),MYe.forEach(t),dat=i(ue),h6=n(ue,"LI",{});var EYe=s(h6);x8e=n(EYe,"STRONG",{});var Lma=s(x8e);mat=r(Lma,"flaubert"),Lma.forEach(t),cat=r(EYe," \u2014 "),Qae=n(EYe,"A",{href:!0});var yma=s(Qae);fat=r(yma,"TFFlaubertForQuestionAnsweringSimple"),yma.forEach(t),gat=r(EYe," (FlauBERT model)"),EYe.forEach(t),hat=i(ue),u6=n(ue,"LI",{});var CYe=s(u6);$8e=n(CYe,"STRONG",{});var xma=s($8e);uat=r(xma,"funnel"),xma.forEach(t),pat=r(CYe," \u2014 "),Wae=n(CYe,"A",{href:!0});var $ma=s(Wae);_at=r($ma,"TFFunnelForQuestionAnswering"),$ma.forEach(t),bat=r(CYe," (Funnel Transformer model)"),CYe.forEach(t),vat=i(ue),p6=n(ue,"LI",{});var wYe=s(p6);k8e=n(wYe,"STRONG",{});var kma=s(k8e);Fat=r(kma,"gptj"),kma.forEach(t),Tat=r(wYe," \u2014 "),Uae=n(wYe,"A",{href:!0});var Sma=s(Uae);Mat=r(Sma,"TFGPTJForQuestionAnswering"),Sma.forEach(t),Eat=r(wYe," (GPT-J model)"),wYe.forEach(t),Cat=i(ue),_6=n(ue,"LI",{});var AYe=s(_6);S8e=n(AYe,"STRONG",{});var Rma=s(S8e);wat=r(Rma,"layoutlmv3"),Rma.forEach(t),Aat=r(AYe," \u2014 "),Hae=n(AYe,"A",{href:!0});var Pma=s(Hae);Lat=r(Pma,"TFLayoutLMv3ForQuestionAnswering"),Pma.forEach(t),yat=r(AYe," (LayoutLMv3 model)"),AYe.forEach(t),xat=i(ue),b6=n(ue,"LI",{});var LYe=s(b6);R8e=n(LYe,"STRONG",{});var Bma=s(R8e);$at=r(Bma,"longformer"),Bma.forEach(t),kat=r(LYe," \u2014 "),Jae=n(LYe,"A",{href:!0});var Ima=s(Jae);Sat=r(Ima,"TFLongformerForQuestionAnswering"),Ima.forEach(t),Rat=r(LYe," (Longformer model)"),LYe.forEach(t),Pat=i(ue),v6=n(ue,"LI",{});var yYe=s(v6);P8e=n(yYe,"STRONG",{});var Nma=s(P8e);Bat=r(Nma,"mobilebert"),Nma.forEach(t),Iat=r(yYe," \u2014 "),Yae=n(yYe,"A",{href:!0});var qma=s(Yae);Nat=r(qma,"TFMobileBertForQuestionAnswering"),qma.forEach(t),qat=r(yYe," (MobileBERT model)"),yYe.forEach(t),jat=i(ue),F6=n(ue,"LI",{});var xYe=s(F6);B8e=n(xYe,"STRONG",{});var jma=s(B8e);Dat=r(jma,"mpnet"),jma.forEach(t),Gat=r(xYe," \u2014 "),Kae=n(xYe,"A",{href:!0});var Dma=s(Kae);Oat=r(Dma,"TFMPNetForQuestionAnswering"),Dma.forEach(t),Vat=r(xYe," (MPNet model)"),xYe.forEach(t),Xat=i(ue),T6=n(ue,"LI",{});var $Ye=s(T6);I8e=n($Ye,"STRONG",{});var Gma=s(I8e);zat=r(Gma,"rembert"),Gma.forEach(t),Qat=r($Ye," \u2014 "),Zae=n($Ye,"A",{href:!0});var Oma=s(Zae);Wat=r(Oma,"TFRemBertForQuestionAnswering"),Oma.forEach(t),Uat=r($Ye," (RemBERT model)"),$Ye.forEach(t),Hat=i(ue),M6=n(ue,"LI",{});var kYe=s(M6);N8e=n(kYe,"STRONG",{});var Vma=s(N8e);Jat=r(Vma,"roberta"),Vma.forEach(t),Yat=r(kYe," \u2014 "),ene=n(kYe,"A",{href:!0});var Xma=s(ene);Kat=r(Xma,"TFRobertaForQuestionAnswering"),Xma.forEach(t),Zat=r(kYe," (RoBERTa model)"),kYe.forEach(t),ent=i(ue),E6=n(ue,"LI",{});var SYe=s(E6);q8e=n(SYe,"STRONG",{});var zma=s(q8e);ont=r(zma,"roformer"),zma.forEach(t),rnt=r(SYe," \u2014 "),one=n(SYe,"A",{href:!0});var Qma=s(one);tnt=r(Qma,"TFRoFormerForQuestionAnswering"),Qma.forEach(t),ant=r(SYe," (RoFormer model)"),SYe.forEach(t),nnt=i(ue),C6=n(ue,"LI",{});var RYe=s(C6);j8e=n(RYe,"STRONG",{});var Wma=s(j8e);snt=r(Wma,"xlm"),Wma.forEach(t),lnt=r(RYe," \u2014 "),rne=n(RYe,"A",{href:!0});var Uma=s(rne);int=r(Uma,"TFXLMForQuestionAnsweringSimple"),Uma.forEach(t),dnt=r(RYe," (XLM model)"),RYe.forEach(t),mnt=i(ue),w6=n(ue,"LI",{});var PYe=s(w6);D8e=n(PYe,"STRONG",{});var Hma=s(D8e);cnt=r(Hma,"xlm-roberta"),Hma.forEach(t),fnt=r(PYe," \u2014 "),tne=n(PYe,"A",{href:!0});var Jma=s(tne);gnt=r(Jma,"TFXLMRobertaForQuestionAnswering"),Jma.forEach(t),hnt=r(PYe," (XLM-RoBERTa model)"),PYe.forEach(t),unt=i(ue),A6=n(ue,"LI",{});var BYe=s(A6);G8e=n(BYe,"STRONG",{});var Yma=s(G8e);pnt=r(Yma,"xlnet"),Yma.forEach(t),_nt=r(BYe," \u2014 "),ane=n(BYe,"A",{href:!0});var Kma=s(ane);bnt=r(Kma,"TFXLNetForQuestionAnsweringSimple"),Kma.forEach(t),vnt=r(BYe," (XLNet model)"),BYe.forEach(t),ue.forEach(t),Fnt=i(yi),T(L6.$$.fragment,yi),yi.forEach(t),Li.forEach(t),woo=i(c),kc=n(c,"H2",{class:!0});var Gto=s(kc);y6=n(Gto,"A",{id:!0,class:!0,href:!0});var Zma=s(y6);O8e=n(Zma,"SPAN",{});var eca=s(O8e);T(fR.$$.fragment,eca),eca.forEach(t),Zma.forEach(t),Tnt=i(Gto),V8e=n(Gto,"SPAN",{});var oca=s(V8e);Mnt=r(oca,"TFAutoModelForVision2Seq"),oca.forEach(t),Gto.forEach(t),Aoo=i(c),Fr=n(c,"DIV",{class:!0});var xi=s(Fr);T(gR.$$.fragment,xi),Ent=i(xi),Sc=n(xi,"P",{});var Ade=s(Sc);Cnt=r(Ade,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nne=n(Ade,"A",{href:!0});var rca=s(nne);wnt=r(rca,"from_pretrained()"),rca.forEach(t),Ant=r(Ade," class method or the "),sne=n(Ade,"A",{href:!0});var tca=s(sne);Lnt=r(tca,"from_config()"),tca.forEach(t),ynt=r(Ade,` class
method.`),Ade.forEach(t),xnt=i(xi),hR=n(xi,"P",{});var Oto=s(hR);$nt=r(Oto,"This class cannot be instantiated directly using "),X8e=n(Oto,"CODE",{});var aca=s(X8e);knt=r(aca,"__init__()"),aca.forEach(t),Snt=r(Oto," (throws an error)."),Oto.forEach(t),Rnt=i(xi),aa=n(xi,"DIV",{class:!0});var M9=s(aa);T(uR.$$.fragment,M9),Pnt=i(M9),z8e=n(M9,"P",{});var nca=s(z8e);Bnt=r(nca,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),nca.forEach(t),Int=i(M9),Rc=n(M9,"P",{});var Lde=s(Rc);Nnt=r(Lde,`Note:
Loading a model from its configuration file does `),Q8e=n(Lde,"STRONG",{});var sca=s(Q8e);qnt=r(sca,"not"),sca.forEach(t),jnt=r(Lde,` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=n(Lde,"A",{href:!0});var lca=s(lne);Dnt=r(lca,"from_pretrained()"),lca.forEach(t),Gnt=r(Lde," to load the model weights."),Lde.forEach(t),Ont=i(M9),T(x6.$$.fragment,M9),M9.forEach(t),Vnt=i(xi),Jr=n(xi,"DIV",{class:!0});var $i=s(Jr);T(pR.$$.fragment,$i),Xnt=i($i),W8e=n($i,"P",{});var ica=s(W8e);znt=r(ica,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ica.forEach(t),Qnt=i($i),jn=n($i,"P",{});var E9=s(jn);Wnt=r(E9,"The model class to instantiate is selected based on the "),U8e=n(E9,"CODE",{});var dca=s(U8e);Unt=r(dca,"model_type"),dca.forEach(t),Hnt=r(E9,` property of the config object (either
passed as an argument or loaded from `),H8e=n(E9,"CODE",{});var mca=s(H8e);Jnt=r(mca,"pretrained_model_name_or_path"),mca.forEach(t),Ynt=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J8e=n(E9,"CODE",{});var cca=s(J8e);Knt=r(cca,"pretrained_model_name_or_path"),cca.forEach(t),Znt=r(E9,":"),E9.forEach(t),est=i($i),Y8e=n($i,"UL",{});var fca=s(Y8e);$6=n(fca,"LI",{});var IYe=s($6);K8e=n(IYe,"STRONG",{});var gca=s(K8e);ost=r(gca,"vision-encoder-decoder"),gca.forEach(t),rst=r(IYe," \u2014 "),ine=n(IYe,"A",{href:!0});var hca=s(ine);tst=r(hca,"TFVisionEncoderDecoderModel"),hca.forEach(t),ast=r(IYe," (Vision Encoder decoder model)"),IYe.forEach(t),fca.forEach(t),nst=i($i),T(k6.$$.fragment,$i),$i.forEach(t),xi.forEach(t),Loo=i(c),Pc=n(c,"H2",{class:!0});var Vto=s(Pc);S6=n(Vto,"A",{id:!0,class:!0,href:!0});var uca=s(S6);Z8e=n(uca,"SPAN",{});var pca=s(Z8e);T(_R.$$.fragment,pca),pca.forEach(t),uca.forEach(t),sst=i(Vto),e9e=n(Vto,"SPAN",{});var _ca=s(e9e);lst=r(_ca,"TFAutoModelForSpeechSeq2Seq"),_ca.forEach(t),Vto.forEach(t),yoo=i(c),Tr=n(c,"DIV",{class:!0});var ki=s(Tr);T(bR.$$.fragment,ki),ist=i(ki),Bc=n(ki,"P",{});var yde=s(Bc);dst=r(yde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),dne=n(yde,"A",{href:!0});var bca=s(dne);mst=r(bca,"from_pretrained()"),bca.forEach(t),cst=r(yde," class method or the "),mne=n(yde,"A",{href:!0});var vca=s(mne);fst=r(vca,"from_config()"),vca.forEach(t),gst=r(yde,` class
method.`),yde.forEach(t),hst=i(ki),vR=n(ki,"P",{});var Xto=s(vR);ust=r(Xto,"This class cannot be instantiated directly using "),o9e=n(Xto,"CODE",{});var Fca=s(o9e);pst=r(Fca,"__init__()"),Fca.forEach(t),_st=r(Xto," (throws an error)."),Xto.forEach(t),bst=i(ki),na=n(ki,"DIV",{class:!0});var C9=s(na);T(FR.$$.fragment,C9),vst=i(C9),r9e=n(C9,"P",{});var Tca=s(r9e);Fst=r(Tca,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Tca.forEach(t),Tst=i(C9),Ic=n(C9,"P",{});var xde=s(Ic);Mst=r(xde,`Note:
Loading a model from its configuration file does `),t9e=n(xde,"STRONG",{});var Mca=s(t9e);Est=r(Mca,"not"),Mca.forEach(t),Cst=r(xde,` load the model weights. It only affects the
model\u2019s configuration. Use `),cne=n(xde,"A",{href:!0});var Eca=s(cne);wst=r(Eca,"from_pretrained()"),Eca.forEach(t),Ast=r(xde," to load the model weights."),xde.forEach(t),Lst=i(C9),T(R6.$$.fragment,C9),C9.forEach(t),yst=i(ki),Yr=n(ki,"DIV",{class:!0});var Si=s(Yr);T(TR.$$.fragment,Si),xst=i(Si),a9e=n(Si,"P",{});var Cca=s(a9e);$st=r(Cca,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Cca.forEach(t),kst=i(Si),Dn=n(Si,"P",{});var w9=s(Dn);Sst=r(w9,"The model class to instantiate is selected based on the "),n9e=n(w9,"CODE",{});var wca=s(n9e);Rst=r(wca,"model_type"),wca.forEach(t),Pst=r(w9,` property of the config object (either
passed as an argument or loaded from `),s9e=n(w9,"CODE",{});var Aca=s(s9e);Bst=r(Aca,"pretrained_model_name_or_path"),Aca.forEach(t),Ist=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l9e=n(w9,"CODE",{});var Lca=s(l9e);Nst=r(Lca,"pretrained_model_name_or_path"),Lca.forEach(t),qst=r(w9,":"),w9.forEach(t),jst=i(Si),i9e=n(Si,"UL",{});var yca=s(i9e);P6=n(yca,"LI",{});var NYe=s(P6);d9e=n(NYe,"STRONG",{});var xca=s(d9e);Dst=r(xca,"speech_to_text"),xca.forEach(t),Gst=r(NYe," \u2014 "),fne=n(NYe,"A",{href:!0});var $ca=s(fne);Ost=r($ca,"TFSpeech2TextForConditionalGeneration"),$ca.forEach(t),Vst=r(NYe," (Speech2Text model)"),NYe.forEach(t),yca.forEach(t),Xst=i(Si),T(B6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),xoo=i(c),Nc=n(c,"H2",{class:!0});var zto=s(Nc);I6=n(zto,"A",{id:!0,class:!0,href:!0});var kca=s(I6);m9e=n(kca,"SPAN",{});var Sca=s(m9e);T(MR.$$.fragment,Sca),Sca.forEach(t),kca.forEach(t),zst=i(zto),c9e=n(zto,"SPAN",{});var Rca=s(c9e);Qst=r(Rca,"FlaxAutoModel"),Rca.forEach(t),zto.forEach(t),$oo=i(c),Mr=n(c,"DIV",{class:!0});var Ri=s(Mr);T(ER.$$.fragment,Ri),Wst=i(Ri),qc=n(Ri,"P",{});var $de=s(qc);Ust=r($de,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),gne=n($de,"A",{href:!0});var Pca=s(gne);Hst=r(Pca,"from_pretrained()"),Pca.forEach(t),Jst=r($de," class method or the "),hne=n($de,"A",{href:!0});var Bca=s(hne);Yst=r(Bca,"from_config()"),Bca.forEach(t),Kst=r($de,` class
method.`),$de.forEach(t),Zst=i(Ri),CR=n(Ri,"P",{});var Qto=s(CR);elt=r(Qto,"This class cannot be instantiated directly using "),f9e=n(Qto,"CODE",{});var Ica=s(f9e);olt=r(Ica,"__init__()"),Ica.forEach(t),rlt=r(Qto," (throws an error)."),Qto.forEach(t),tlt=i(Ri),sa=n(Ri,"DIV",{class:!0});var A9=s(sa);T(wR.$$.fragment,A9),alt=i(A9),g9e=n(A9,"P",{});var Nca=s(g9e);nlt=r(Nca,"Instantiates one of the base model classes of the library from a configuration."),Nca.forEach(t),slt=i(A9),jc=n(A9,"P",{});var kde=s(jc);llt=r(kde,`Note:
Loading a model from its configuration file does `),h9e=n(kde,"STRONG",{});var qca=s(h9e);ilt=r(qca,"not"),qca.forEach(t),dlt=r(kde,` load the model weights. It only affects the
model\u2019s configuration. Use `),une=n(kde,"A",{href:!0});var jca=s(une);mlt=r(jca,"from_pretrained()"),jca.forEach(t),clt=r(kde," to load the model weights."),kde.forEach(t),flt=i(A9),T(N6.$$.fragment,A9),A9.forEach(t),glt=i(Ri),Kr=n(Ri,"DIV",{class:!0});var Pi=s(Kr);T(AR.$$.fragment,Pi),hlt=i(Pi),u9e=n(Pi,"P",{});var Dca=s(u9e);ult=r(Dca,"Instantiate one of the base model classes of the library from a pretrained model."),Dca.forEach(t),plt=i(Pi),Gn=n(Pi,"P",{});var L9=s(Gn);_lt=r(L9,"The model class to instantiate is selected based on the "),p9e=n(L9,"CODE",{});var Gca=s(p9e);blt=r(Gca,"model_type"),Gca.forEach(t),vlt=r(L9,` property of the config object (either
passed as an argument or loaded from `),_9e=n(L9,"CODE",{});var Oca=s(_9e);Flt=r(Oca,"pretrained_model_name_or_path"),Oca.forEach(t),Tlt=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b9e=n(L9,"CODE",{});var Vca=s(b9e);Mlt=r(Vca,"pretrained_model_name_or_path"),Vca.forEach(t),Elt=r(L9,":"),L9.forEach(t),Clt=i(Pi),te=n(Pi,"UL",{});var ne=s(te);q6=n(ne,"LI",{});var qYe=s(q6);v9e=n(qYe,"STRONG",{});var Xca=s(v9e);wlt=r(Xca,"albert"),Xca.forEach(t),Alt=r(qYe," \u2014 "),pne=n(qYe,"A",{href:!0});var zca=s(pne);Llt=r(zca,"FlaxAlbertModel"),zca.forEach(t),ylt=r(qYe," (ALBERT model)"),qYe.forEach(t),xlt=i(ne),j6=n(ne,"LI",{});var jYe=s(j6);F9e=n(jYe,"STRONG",{});var Qca=s(F9e);$lt=r(Qca,"bart"),Qca.forEach(t),klt=r(jYe," \u2014 "),_ne=n(jYe,"A",{href:!0});var Wca=s(_ne);Slt=r(Wca,"FlaxBartModel"),Wca.forEach(t),Rlt=r(jYe," (BART model)"),jYe.forEach(t),Plt=i(ne),D6=n(ne,"LI",{});var DYe=s(D6);T9e=n(DYe,"STRONG",{});var Uca=s(T9e);Blt=r(Uca,"beit"),Uca.forEach(t),Ilt=r(DYe," \u2014 "),bne=n(DYe,"A",{href:!0});var Hca=s(bne);Nlt=r(Hca,"FlaxBeitModel"),Hca.forEach(t),qlt=r(DYe," (BEiT model)"),DYe.forEach(t),jlt=i(ne),G6=n(ne,"LI",{});var GYe=s(G6);M9e=n(GYe,"STRONG",{});var Jca=s(M9e);Dlt=r(Jca,"bert"),Jca.forEach(t),Glt=r(GYe," \u2014 "),vne=n(GYe,"A",{href:!0});var Yca=s(vne);Olt=r(Yca,"FlaxBertModel"),Yca.forEach(t),Vlt=r(GYe," (BERT model)"),GYe.forEach(t),Xlt=i(ne),O6=n(ne,"LI",{});var OYe=s(O6);E9e=n(OYe,"STRONG",{});var Kca=s(E9e);zlt=r(Kca,"big_bird"),Kca.forEach(t),Qlt=r(OYe," \u2014 "),Fne=n(OYe,"A",{href:!0});var Zca=s(Fne);Wlt=r(Zca,"FlaxBigBirdModel"),Zca.forEach(t),Ult=r(OYe," (BigBird model)"),OYe.forEach(t),Hlt=i(ne),V6=n(ne,"LI",{});var VYe=s(V6);C9e=n(VYe,"STRONG",{});var efa=s(C9e);Jlt=r(efa,"blenderbot"),efa.forEach(t),Ylt=r(VYe," \u2014 "),Tne=n(VYe,"A",{href:!0});var ofa=s(Tne);Klt=r(ofa,"FlaxBlenderbotModel"),ofa.forEach(t),Zlt=r(VYe," (Blenderbot model)"),VYe.forEach(t),eit=i(ne),X6=n(ne,"LI",{});var XYe=s(X6);w9e=n(XYe,"STRONG",{});var rfa=s(w9e);oit=r(rfa,"blenderbot-small"),rfa.forEach(t),rit=r(XYe," \u2014 "),Mne=n(XYe,"A",{href:!0});var tfa=s(Mne);tit=r(tfa,"FlaxBlenderbotSmallModel"),tfa.forEach(t),ait=r(XYe," (BlenderbotSmall model)"),XYe.forEach(t),nit=i(ne),z6=n(ne,"LI",{});var zYe=s(z6);A9e=n(zYe,"STRONG",{});var afa=s(A9e);sit=r(afa,"clip"),afa.forEach(t),lit=r(zYe," \u2014 "),Ene=n(zYe,"A",{href:!0});var nfa=s(Ene);iit=r(nfa,"FlaxCLIPModel"),nfa.forEach(t),dit=r(zYe," (CLIP model)"),zYe.forEach(t),mit=i(ne),Q6=n(ne,"LI",{});var QYe=s(Q6);L9e=n(QYe,"STRONG",{});var sfa=s(L9e);cit=r(sfa,"distilbert"),sfa.forEach(t),fit=r(QYe," \u2014 "),Cne=n(QYe,"A",{href:!0});var lfa=s(Cne);git=r(lfa,"FlaxDistilBertModel"),lfa.forEach(t),hit=r(QYe," (DistilBERT model)"),QYe.forEach(t),uit=i(ne),W6=n(ne,"LI",{});var WYe=s(W6);y9e=n(WYe,"STRONG",{});var ifa=s(y9e);pit=r(ifa,"electra"),ifa.forEach(t),_it=r(WYe," \u2014 "),wne=n(WYe,"A",{href:!0});var dfa=s(wne);bit=r(dfa,"FlaxElectraModel"),dfa.forEach(t),vit=r(WYe," (ELECTRA model)"),WYe.forEach(t),Fit=i(ne),U6=n(ne,"LI",{});var UYe=s(U6);x9e=n(UYe,"STRONG",{});var mfa=s(x9e);Tit=r(mfa,"gpt2"),mfa.forEach(t),Mit=r(UYe," \u2014 "),Ane=n(UYe,"A",{href:!0});var cfa=s(Ane);Eit=r(cfa,"FlaxGPT2Model"),cfa.forEach(t),Cit=r(UYe," (OpenAI GPT-2 model)"),UYe.forEach(t),wit=i(ne),H6=n(ne,"LI",{});var HYe=s(H6);$9e=n(HYe,"STRONG",{});var ffa=s($9e);Ait=r(ffa,"gpt_neo"),ffa.forEach(t),Lit=r(HYe," \u2014 "),Lne=n(HYe,"A",{href:!0});var gfa=s(Lne);yit=r(gfa,"FlaxGPTNeoModel"),gfa.forEach(t),xit=r(HYe," (GPT Neo model)"),HYe.forEach(t),$it=i(ne),J6=n(ne,"LI",{});var JYe=s(J6);k9e=n(JYe,"STRONG",{});var hfa=s(k9e);kit=r(hfa,"gptj"),hfa.forEach(t),Sit=r(JYe," \u2014 "),yne=n(JYe,"A",{href:!0});var ufa=s(yne);Rit=r(ufa,"FlaxGPTJModel"),ufa.forEach(t),Pit=r(JYe," (GPT-J model)"),JYe.forEach(t),Bit=i(ne),Y6=n(ne,"LI",{});var YYe=s(Y6);S9e=n(YYe,"STRONG",{});var pfa=s(S9e);Iit=r(pfa,"longt5"),pfa.forEach(t),Nit=r(YYe," \u2014 "),xne=n(YYe,"A",{href:!0});var _fa=s(xne);qit=r(_fa,"FlaxLongT5Model"),_fa.forEach(t),jit=r(YYe," (LongT5 model)"),YYe.forEach(t),Dit=i(ne),K6=n(ne,"LI",{});var KYe=s(K6);R9e=n(KYe,"STRONG",{});var bfa=s(R9e);Git=r(bfa,"marian"),bfa.forEach(t),Oit=r(KYe," \u2014 "),$ne=n(KYe,"A",{href:!0});var vfa=s($ne);Vit=r(vfa,"FlaxMarianModel"),vfa.forEach(t),Xit=r(KYe," (Marian model)"),KYe.forEach(t),zit=i(ne),Z6=n(ne,"LI",{});var ZYe=s(Z6);P9e=n(ZYe,"STRONG",{});var Ffa=s(P9e);Qit=r(Ffa,"mbart"),Ffa.forEach(t),Wit=r(ZYe," \u2014 "),kne=n(ZYe,"A",{href:!0});var Tfa=s(kne);Uit=r(Tfa,"FlaxMBartModel"),Tfa.forEach(t),Hit=r(ZYe," (mBART model)"),ZYe.forEach(t),Jit=i(ne),e7=n(ne,"LI",{});var eKe=s(e7);B9e=n(eKe,"STRONG",{});var Mfa=s(B9e);Yit=r(Mfa,"mt5"),Mfa.forEach(t),Kit=r(eKe," \u2014 "),Sne=n(eKe,"A",{href:!0});var Efa=s(Sne);Zit=r(Efa,"FlaxMT5Model"),Efa.forEach(t),edt=r(eKe," (MT5 model)"),eKe.forEach(t),odt=i(ne),o7=n(ne,"LI",{});var oKe=s(o7);I9e=n(oKe,"STRONG",{});var Cfa=s(I9e);rdt=r(Cfa,"opt"),Cfa.forEach(t),tdt=r(oKe," \u2014 "),Rne=n(oKe,"A",{href:!0});var wfa=s(Rne);adt=r(wfa,"FlaxOPTModel"),wfa.forEach(t),ndt=r(oKe," (OPT model)"),oKe.forEach(t),sdt=i(ne),r7=n(ne,"LI",{});var rKe=s(r7);N9e=n(rKe,"STRONG",{});var Afa=s(N9e);ldt=r(Afa,"pegasus"),Afa.forEach(t),idt=r(rKe," \u2014 "),Pne=n(rKe,"A",{href:!0});var Lfa=s(Pne);ddt=r(Lfa,"FlaxPegasusModel"),Lfa.forEach(t),mdt=r(rKe," (Pegasus model)"),rKe.forEach(t),cdt=i(ne),t7=n(ne,"LI",{});var tKe=s(t7);q9e=n(tKe,"STRONG",{});var yfa=s(q9e);fdt=r(yfa,"roberta"),yfa.forEach(t),gdt=r(tKe," \u2014 "),Bne=n(tKe,"A",{href:!0});var xfa=s(Bne);hdt=r(xfa,"FlaxRobertaModel"),xfa.forEach(t),udt=r(tKe," (RoBERTa model)"),tKe.forEach(t),pdt=i(ne),a7=n(ne,"LI",{});var aKe=s(a7);j9e=n(aKe,"STRONG",{});var $fa=s(j9e);_dt=r($fa,"roformer"),$fa.forEach(t),bdt=r(aKe," \u2014 "),Ine=n(aKe,"A",{href:!0});var kfa=s(Ine);vdt=r(kfa,"FlaxRoFormerModel"),kfa.forEach(t),Fdt=r(aKe," (RoFormer model)"),aKe.forEach(t),Tdt=i(ne),n7=n(ne,"LI",{});var nKe=s(n7);D9e=n(nKe,"STRONG",{});var Sfa=s(D9e);Mdt=r(Sfa,"t5"),Sfa.forEach(t),Edt=r(nKe," \u2014 "),Nne=n(nKe,"A",{href:!0});var Rfa=s(Nne);Cdt=r(Rfa,"FlaxT5Model"),Rfa.forEach(t),wdt=r(nKe," (T5 model)"),nKe.forEach(t),Adt=i(ne),s7=n(ne,"LI",{});var sKe=s(s7);G9e=n(sKe,"STRONG",{});var Pfa=s(G9e);Ldt=r(Pfa,"vision-text-dual-encoder"),Pfa.forEach(t),ydt=r(sKe," \u2014 "),qne=n(sKe,"A",{href:!0});var Bfa=s(qne);xdt=r(Bfa,"FlaxVisionTextDualEncoderModel"),Bfa.forEach(t),$dt=r(sKe," (VisionTextDualEncoder model)"),sKe.forEach(t),kdt=i(ne),l7=n(ne,"LI",{});var lKe=s(l7);O9e=n(lKe,"STRONG",{});var Ifa=s(O9e);Sdt=r(Ifa,"vit"),Ifa.forEach(t),Rdt=r(lKe," \u2014 "),jne=n(lKe,"A",{href:!0});var Nfa=s(jne);Pdt=r(Nfa,"FlaxViTModel"),Nfa.forEach(t),Bdt=r(lKe," (ViT model)"),lKe.forEach(t),Idt=i(ne),i7=n(ne,"LI",{});var iKe=s(i7);V9e=n(iKe,"STRONG",{});var qfa=s(V9e);Ndt=r(qfa,"wav2vec2"),qfa.forEach(t),qdt=r(iKe," \u2014 "),Dne=n(iKe,"A",{href:!0});var jfa=s(Dne);jdt=r(jfa,"FlaxWav2Vec2Model"),jfa.forEach(t),Ddt=r(iKe," (Wav2Vec2 model)"),iKe.forEach(t),Gdt=i(ne),d7=n(ne,"LI",{});var dKe=s(d7);X9e=n(dKe,"STRONG",{});var Dfa=s(X9e);Odt=r(Dfa,"xglm"),Dfa.forEach(t),Vdt=r(dKe," \u2014 "),Gne=n(dKe,"A",{href:!0});var Gfa=s(Gne);Xdt=r(Gfa,"FlaxXGLMModel"),Gfa.forEach(t),zdt=r(dKe," (XGLM model)"),dKe.forEach(t),Qdt=i(ne),m7=n(ne,"LI",{});var mKe=s(m7);z9e=n(mKe,"STRONG",{});var Ofa=s(z9e);Wdt=r(Ofa,"xlm-roberta"),Ofa.forEach(t),Udt=r(mKe," \u2014 "),One=n(mKe,"A",{href:!0});var Vfa=s(One);Hdt=r(Vfa,"FlaxXLMRobertaModel"),Vfa.forEach(t),Jdt=r(mKe," (XLM-RoBERTa model)"),mKe.forEach(t),ne.forEach(t),Ydt=i(Pi),T(c7.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),koo=i(c),Dc=n(c,"H2",{class:!0});var Wto=s(Dc);f7=n(Wto,"A",{id:!0,class:!0,href:!0});var Xfa=s(f7);Q9e=n(Xfa,"SPAN",{});var zfa=s(Q9e);T(LR.$$.fragment,zfa),zfa.forEach(t),Xfa.forEach(t),Kdt=i(Wto),W9e=n(Wto,"SPAN",{});var Qfa=s(W9e);Zdt=r(Qfa,"FlaxAutoModelForCausalLM"),Qfa.forEach(t),Wto.forEach(t),Soo=i(c),Er=n(c,"DIV",{class:!0});var Bi=s(Er);T(yR.$$.fragment,Bi),emt=i(Bi),Gc=n(Bi,"P",{});var Sde=s(Gc);omt=r(Sde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Vne=n(Sde,"A",{href:!0});var Wfa=s(Vne);rmt=r(Wfa,"from_pretrained()"),Wfa.forEach(t),tmt=r(Sde," class method or the "),Xne=n(Sde,"A",{href:!0});var Ufa=s(Xne);amt=r(Ufa,"from_config()"),Ufa.forEach(t),nmt=r(Sde,` class
method.`),Sde.forEach(t),smt=i(Bi),xR=n(Bi,"P",{});var Uto=s(xR);lmt=r(Uto,"This class cannot be instantiated directly using "),U9e=n(Uto,"CODE",{});var Hfa=s(U9e);imt=r(Hfa,"__init__()"),Hfa.forEach(t),dmt=r(Uto," (throws an error)."),Uto.forEach(t),mmt=i(Bi),la=n(Bi,"DIV",{class:!0});var y9=s(la);T($R.$$.fragment,y9),cmt=i(y9),H9e=n(y9,"P",{});var Jfa=s(H9e);fmt=r(Jfa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Jfa.forEach(t),gmt=i(y9),Oc=n(y9,"P",{});var Rde=s(Oc);hmt=r(Rde,`Note:
Loading a model from its configuration file does `),J9e=n(Rde,"STRONG",{});var Yfa=s(J9e);umt=r(Yfa,"not"),Yfa.forEach(t),pmt=r(Rde,` load the model weights. It only affects the
model\u2019s configuration. Use `),zne=n(Rde,"A",{href:!0});var Kfa=s(zne);_mt=r(Kfa,"from_pretrained()"),Kfa.forEach(t),bmt=r(Rde," to load the model weights."),Rde.forEach(t),vmt=i(y9),T(g7.$$.fragment,y9),y9.forEach(t),Fmt=i(Bi),Zr=n(Bi,"DIV",{class:!0});var Ii=s(Zr);T(kR.$$.fragment,Ii),Tmt=i(Ii),Y9e=n(Ii,"P",{});var Zfa=s(Y9e);Mmt=r(Zfa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Zfa.forEach(t),Emt=i(Ii),On=n(Ii,"P",{});var x9=s(On);Cmt=r(x9,"The model class to instantiate is selected based on the "),K9e=n(x9,"CODE",{});var ega=s(K9e);wmt=r(ega,"model_type"),ega.forEach(t),Amt=r(x9,` property of the config object (either
passed as an argument or loaded from `),Z9e=n(x9,"CODE",{});var oga=s(Z9e);Lmt=r(oga,"pretrained_model_name_or_path"),oga.forEach(t),ymt=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),exe=n(x9,"CODE",{});var rga=s(exe);xmt=r(rga,"pretrained_model_name_or_path"),rga.forEach(t),$mt=r(x9,":"),x9.forEach(t),kmt=i(Ii),xe=n(Ii,"UL",{});var qe=s(xe);h7=n(qe,"LI",{});var cKe=s(h7);oxe=n(cKe,"STRONG",{});var tga=s(oxe);Smt=r(tga,"bart"),tga.forEach(t),Rmt=r(cKe," \u2014 "),Qne=n(cKe,"A",{href:!0});var aga=s(Qne);Pmt=r(aga,"FlaxBartForCausalLM"),aga.forEach(t),Bmt=r(cKe," (BART model)"),cKe.forEach(t),Imt=i(qe),u7=n(qe,"LI",{});var fKe=s(u7);rxe=n(fKe,"STRONG",{});var nga=s(rxe);Nmt=r(nga,"bert"),nga.forEach(t),qmt=r(fKe," \u2014 "),Wne=n(fKe,"A",{href:!0});var sga=s(Wne);jmt=r(sga,"FlaxBertForCausalLM"),sga.forEach(t),Dmt=r(fKe," (BERT model)"),fKe.forEach(t),Gmt=i(qe),p7=n(qe,"LI",{});var gKe=s(p7);txe=n(gKe,"STRONG",{});var lga=s(txe);Omt=r(lga,"big_bird"),lga.forEach(t),Vmt=r(gKe," \u2014 "),Une=n(gKe,"A",{href:!0});var iga=s(Une);Xmt=r(iga,"FlaxBigBirdForCausalLM"),iga.forEach(t),zmt=r(gKe," (BigBird model)"),gKe.forEach(t),Qmt=i(qe),_7=n(qe,"LI",{});var hKe=s(_7);axe=n(hKe,"STRONG",{});var dga=s(axe);Wmt=r(dga,"electra"),dga.forEach(t),Umt=r(hKe," \u2014 "),Hne=n(hKe,"A",{href:!0});var mga=s(Hne);Hmt=r(mga,"FlaxElectraForCausalLM"),mga.forEach(t),Jmt=r(hKe," (ELECTRA model)"),hKe.forEach(t),Ymt=i(qe),b7=n(qe,"LI",{});var uKe=s(b7);nxe=n(uKe,"STRONG",{});var cga=s(nxe);Kmt=r(cga,"gpt2"),cga.forEach(t),Zmt=r(uKe," \u2014 "),Jne=n(uKe,"A",{href:!0});var fga=s(Jne);ect=r(fga,"FlaxGPT2LMHeadModel"),fga.forEach(t),oct=r(uKe," (OpenAI GPT-2 model)"),uKe.forEach(t),rct=i(qe),v7=n(qe,"LI",{});var pKe=s(v7);sxe=n(pKe,"STRONG",{});var gga=s(sxe);tct=r(gga,"gpt_neo"),gga.forEach(t),act=r(pKe," \u2014 "),Yne=n(pKe,"A",{href:!0});var hga=s(Yne);nct=r(hga,"FlaxGPTNeoForCausalLM"),hga.forEach(t),sct=r(pKe," (GPT Neo model)"),pKe.forEach(t),lct=i(qe),F7=n(qe,"LI",{});var _Ke=s(F7);lxe=n(_Ke,"STRONG",{});var uga=s(lxe);ict=r(uga,"gptj"),uga.forEach(t),dct=r(_Ke," \u2014 "),Kne=n(_Ke,"A",{href:!0});var pga=s(Kne);mct=r(pga,"FlaxGPTJForCausalLM"),pga.forEach(t),cct=r(_Ke," (GPT-J model)"),_Ke.forEach(t),fct=i(qe),T7=n(qe,"LI",{});var bKe=s(T7);ixe=n(bKe,"STRONG",{});var _ga=s(ixe);gct=r(_ga,"opt"),_ga.forEach(t),hct=r(bKe," \u2014 "),Zne=n(bKe,"A",{href:!0});var bga=s(Zne);uct=r(bga,"FlaxOPTForCausalLM"),bga.forEach(t),pct=r(bKe," (OPT model)"),bKe.forEach(t),_ct=i(qe),M7=n(qe,"LI",{});var vKe=s(M7);dxe=n(vKe,"STRONG",{});var vga=s(dxe);bct=r(vga,"roberta"),vga.forEach(t),vct=r(vKe," \u2014 "),ese=n(vKe,"A",{href:!0});var Fga=s(ese);Fct=r(Fga,"FlaxRobertaForCausalLM"),Fga.forEach(t),Tct=r(vKe," (RoBERTa model)"),vKe.forEach(t),Mct=i(qe),E7=n(qe,"LI",{});var FKe=s(E7);mxe=n(FKe,"STRONG",{});var Tga=s(mxe);Ect=r(Tga,"xglm"),Tga.forEach(t),Cct=r(FKe," \u2014 "),ose=n(FKe,"A",{href:!0});var Mga=s(ose);wct=r(Mga,"FlaxXGLMForCausalLM"),Mga.forEach(t),Act=r(FKe," (XGLM model)"),FKe.forEach(t),qe.forEach(t),Lct=i(Ii),T(C7.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),Roo=i(c),Vc=n(c,"H2",{class:!0});var Hto=s(Vc);w7=n(Hto,"A",{id:!0,class:!0,href:!0});var Ega=s(w7);cxe=n(Ega,"SPAN",{});var Cga=s(cxe);T(SR.$$.fragment,Cga),Cga.forEach(t),Ega.forEach(t),yct=i(Hto),fxe=n(Hto,"SPAN",{});var wga=s(fxe);xct=r(wga,"FlaxAutoModelForPreTraining"),wga.forEach(t),Hto.forEach(t),Poo=i(c),Cr=n(c,"DIV",{class:!0});var Ni=s(Cr);T(RR.$$.fragment,Ni),$ct=i(Ni),Xc=n(Ni,"P",{});var Pde=s(Xc);kct=r(Pde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rse=n(Pde,"A",{href:!0});var Aga=s(rse);Sct=r(Aga,"from_pretrained()"),Aga.forEach(t),Rct=r(Pde," class method or the "),tse=n(Pde,"A",{href:!0});var Lga=s(tse);Pct=r(Lga,"from_config()"),Lga.forEach(t),Bct=r(Pde,` class
method.`),Pde.forEach(t),Ict=i(Ni),PR=n(Ni,"P",{});var Jto=s(PR);Nct=r(Jto,"This class cannot be instantiated directly using "),gxe=n(Jto,"CODE",{});var yga=s(gxe);qct=r(yga,"__init__()"),yga.forEach(t),jct=r(Jto," (throws an error)."),Jto.forEach(t),Dct=i(Ni),ia=n(Ni,"DIV",{class:!0});var $9=s(ia);T(BR.$$.fragment,$9),Gct=i($9),hxe=n($9,"P",{});var xga=s(hxe);Oct=r(xga,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xga.forEach(t),Vct=i($9),zc=n($9,"P",{});var Bde=s(zc);Xct=r(Bde,`Note:
Loading a model from its configuration file does `),uxe=n(Bde,"STRONG",{});var $ga=s(uxe);zct=r($ga,"not"),$ga.forEach(t),Qct=r(Bde,` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=n(Bde,"A",{href:!0});var kga=s(ase);Wct=r(kga,"from_pretrained()"),kga.forEach(t),Uct=r(Bde," to load the model weights."),Bde.forEach(t),Hct=i($9),T(A7.$$.fragment,$9),$9.forEach(t),Jct=i(Ni),et=n(Ni,"DIV",{class:!0});var qi=s(et);T(IR.$$.fragment,qi),Yct=i(qi),pxe=n(qi,"P",{});var Sga=s(pxe);Kct=r(Sga,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Sga.forEach(t),Zct=i(qi),Vn=n(qi,"P",{});var k9=s(Vn);eft=r(k9,"The model class to instantiate is selected based on the "),_xe=n(k9,"CODE",{});var Rga=s(_xe);oft=r(Rga,"model_type"),Rga.forEach(t),rft=r(k9,` property of the config object (either
passed as an argument or loaded from `),bxe=n(k9,"CODE",{});var Pga=s(bxe);tft=r(Pga,"pretrained_model_name_or_path"),Pga.forEach(t),aft=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vxe=n(k9,"CODE",{});var Bga=s(vxe);nft=r(Bga,"pretrained_model_name_or_path"),Bga.forEach(t),sft=r(k9,":"),k9.forEach(t),lft=i(qi),Ee=n(qi,"UL",{});var we=s(Ee);L7=n(we,"LI",{});var TKe=s(L7);Fxe=n(TKe,"STRONG",{});var Iga=s(Fxe);ift=r(Iga,"albert"),Iga.forEach(t),dft=r(TKe," \u2014 "),nse=n(TKe,"A",{href:!0});var Nga=s(nse);mft=r(Nga,"FlaxAlbertForPreTraining"),Nga.forEach(t),cft=r(TKe," (ALBERT model)"),TKe.forEach(t),fft=i(we),y7=n(we,"LI",{});var MKe=s(y7);Txe=n(MKe,"STRONG",{});var qga=s(Txe);gft=r(qga,"bart"),qga.forEach(t),hft=r(MKe," \u2014 "),sse=n(MKe,"A",{href:!0});var jga=s(sse);uft=r(jga,"FlaxBartForConditionalGeneration"),jga.forEach(t),pft=r(MKe," (BART model)"),MKe.forEach(t),_ft=i(we),x7=n(we,"LI",{});var EKe=s(x7);Mxe=n(EKe,"STRONG",{});var Dga=s(Mxe);bft=r(Dga,"bert"),Dga.forEach(t),vft=r(EKe," \u2014 "),lse=n(EKe,"A",{href:!0});var Gga=s(lse);Fft=r(Gga,"FlaxBertForPreTraining"),Gga.forEach(t),Tft=r(EKe," (BERT model)"),EKe.forEach(t),Mft=i(we),$7=n(we,"LI",{});var CKe=s($7);Exe=n(CKe,"STRONG",{});var Oga=s(Exe);Eft=r(Oga,"big_bird"),Oga.forEach(t),Cft=r(CKe," \u2014 "),ise=n(CKe,"A",{href:!0});var Vga=s(ise);wft=r(Vga,"FlaxBigBirdForPreTraining"),Vga.forEach(t),Aft=r(CKe," (BigBird model)"),CKe.forEach(t),Lft=i(we),k7=n(we,"LI",{});var wKe=s(k7);Cxe=n(wKe,"STRONG",{});var Xga=s(Cxe);yft=r(Xga,"electra"),Xga.forEach(t),xft=r(wKe," \u2014 "),dse=n(wKe,"A",{href:!0});var zga=s(dse);$ft=r(zga,"FlaxElectraForPreTraining"),zga.forEach(t),kft=r(wKe," (ELECTRA model)"),wKe.forEach(t),Sft=i(we),S7=n(we,"LI",{});var AKe=s(S7);wxe=n(AKe,"STRONG",{});var Qga=s(wxe);Rft=r(Qga,"longt5"),Qga.forEach(t),Pft=r(AKe," \u2014 "),mse=n(AKe,"A",{href:!0});var Wga=s(mse);Bft=r(Wga,"FlaxLongT5ForConditionalGeneration"),Wga.forEach(t),Ift=r(AKe," (LongT5 model)"),AKe.forEach(t),Nft=i(we),R7=n(we,"LI",{});var LKe=s(R7);Axe=n(LKe,"STRONG",{});var Uga=s(Axe);qft=r(Uga,"mbart"),Uga.forEach(t),jft=r(LKe," \u2014 "),cse=n(LKe,"A",{href:!0});var Hga=s(cse);Dft=r(Hga,"FlaxMBartForConditionalGeneration"),Hga.forEach(t),Gft=r(LKe," (mBART model)"),LKe.forEach(t),Oft=i(we),P7=n(we,"LI",{});var yKe=s(P7);Lxe=n(yKe,"STRONG",{});var Jga=s(Lxe);Vft=r(Jga,"mt5"),Jga.forEach(t),Xft=r(yKe," \u2014 "),fse=n(yKe,"A",{href:!0});var Yga=s(fse);zft=r(Yga,"FlaxMT5ForConditionalGeneration"),Yga.forEach(t),Qft=r(yKe," (MT5 model)"),yKe.forEach(t),Wft=i(we),B7=n(we,"LI",{});var xKe=s(B7);yxe=n(xKe,"STRONG",{});var Kga=s(yxe);Uft=r(Kga,"roberta"),Kga.forEach(t),Hft=r(xKe," \u2014 "),gse=n(xKe,"A",{href:!0});var Zga=s(gse);Jft=r(Zga,"FlaxRobertaForMaskedLM"),Zga.forEach(t),Yft=r(xKe," (RoBERTa model)"),xKe.forEach(t),Kft=i(we),I7=n(we,"LI",{});var $Ke=s(I7);xxe=n($Ke,"STRONG",{});var eha=s(xxe);Zft=r(eha,"roformer"),eha.forEach(t),egt=r($Ke," \u2014 "),hse=n($Ke,"A",{href:!0});var oha=s(hse);ogt=r(oha,"FlaxRoFormerForMaskedLM"),oha.forEach(t),rgt=r($Ke," (RoFormer model)"),$Ke.forEach(t),tgt=i(we),N7=n(we,"LI",{});var kKe=s(N7);$xe=n(kKe,"STRONG",{});var rha=s($xe);agt=r(rha,"t5"),rha.forEach(t),ngt=r(kKe," \u2014 "),use=n(kKe,"A",{href:!0});var tha=s(use);sgt=r(tha,"FlaxT5ForConditionalGeneration"),tha.forEach(t),lgt=r(kKe," (T5 model)"),kKe.forEach(t),igt=i(we),q7=n(we,"LI",{});var SKe=s(q7);kxe=n(SKe,"STRONG",{});var aha=s(kxe);dgt=r(aha,"wav2vec2"),aha.forEach(t),mgt=r(SKe," \u2014 "),pse=n(SKe,"A",{href:!0});var nha=s(pse);cgt=r(nha,"FlaxWav2Vec2ForPreTraining"),nha.forEach(t),fgt=r(SKe," (Wav2Vec2 model)"),SKe.forEach(t),ggt=i(we),j7=n(we,"LI",{});var RKe=s(j7);Sxe=n(RKe,"STRONG",{});var sha=s(Sxe);hgt=r(sha,"xlm-roberta"),sha.forEach(t),ugt=r(RKe," \u2014 "),_se=n(RKe,"A",{href:!0});var lha=s(_se);pgt=r(lha,"FlaxXLMRobertaForMaskedLM"),lha.forEach(t),_gt=r(RKe," (XLM-RoBERTa model)"),RKe.forEach(t),we.forEach(t),bgt=i(qi),T(D7.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),Boo=i(c),Qc=n(c,"H2",{class:!0});var Yto=s(Qc);G7=n(Yto,"A",{id:!0,class:!0,href:!0});var iha=s(G7);Rxe=n(iha,"SPAN",{});var dha=s(Rxe);T(NR.$$.fragment,dha),dha.forEach(t),iha.forEach(t),vgt=i(Yto),Pxe=n(Yto,"SPAN",{});var mha=s(Pxe);Fgt=r(mha,"FlaxAutoModelForMaskedLM"),mha.forEach(t),Yto.forEach(t),Ioo=i(c),wr=n(c,"DIV",{class:!0});var ji=s(wr);T(qR.$$.fragment,ji),Tgt=i(ji),Wc=n(ji,"P",{});var Ide=s(Wc);Mgt=r(Ide,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),bse=n(Ide,"A",{href:!0});var cha=s(bse);Egt=r(cha,"from_pretrained()"),cha.forEach(t),Cgt=r(Ide," class method or the "),vse=n(Ide,"A",{href:!0});var fha=s(vse);wgt=r(fha,"from_config()"),fha.forEach(t),Agt=r(Ide,` class
method.`),Ide.forEach(t),Lgt=i(ji),jR=n(ji,"P",{});var Kto=s(jR);ygt=r(Kto,"This class cannot be instantiated directly using "),Bxe=n(Kto,"CODE",{});var gha=s(Bxe);xgt=r(gha,"__init__()"),gha.forEach(t),$gt=r(Kto," (throws an error)."),Kto.forEach(t),kgt=i(ji),da=n(ji,"DIV",{class:!0});var S9=s(da);T(DR.$$.fragment,S9),Sgt=i(S9),Ixe=n(S9,"P",{});var hha=s(Ixe);Rgt=r(hha,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),hha.forEach(t),Pgt=i(S9),Uc=n(S9,"P",{});var Nde=s(Uc);Bgt=r(Nde,`Note:
Loading a model from its configuration file does `),Nxe=n(Nde,"STRONG",{});var uha=s(Nxe);Igt=r(uha,"not"),uha.forEach(t),Ngt=r(Nde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fse=n(Nde,"A",{href:!0});var pha=s(Fse);qgt=r(pha,"from_pretrained()"),pha.forEach(t),jgt=r(Nde," to load the model weights."),Nde.forEach(t),Dgt=i(S9),T(O7.$$.fragment,S9),S9.forEach(t),Ggt=i(ji),ot=n(ji,"DIV",{class:!0});var Di=s(ot);T(GR.$$.fragment,Di),Ogt=i(Di),qxe=n(Di,"P",{});var _ha=s(qxe);Vgt=r(_ha,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_ha.forEach(t),Xgt=i(Di),Xn=n(Di,"P",{});var R9=s(Xn);zgt=r(R9,"The model class to instantiate is selected based on the "),jxe=n(R9,"CODE",{});var bha=s(jxe);Qgt=r(bha,"model_type"),bha.forEach(t),Wgt=r(R9,` property of the config object (either
passed as an argument or loaded from `),Dxe=n(R9,"CODE",{});var vha=s(Dxe);Ugt=r(vha,"pretrained_model_name_or_path"),vha.forEach(t),Hgt=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=n(R9,"CODE",{});var Fha=s(Gxe);Jgt=r(Fha,"pretrained_model_name_or_path"),Fha.forEach(t),Ygt=r(R9,":"),R9.forEach(t),Kgt=i(Di),$e=n(Di,"UL",{});var je=s($e);V7=n(je,"LI",{});var PKe=s(V7);Oxe=n(PKe,"STRONG",{});var Tha=s(Oxe);Zgt=r(Tha,"albert"),Tha.forEach(t),eht=r(PKe," \u2014 "),Tse=n(PKe,"A",{href:!0});var Mha=s(Tse);oht=r(Mha,"FlaxAlbertForMaskedLM"),Mha.forEach(t),rht=r(PKe," (ALBERT model)"),PKe.forEach(t),tht=i(je),X7=n(je,"LI",{});var BKe=s(X7);Vxe=n(BKe,"STRONG",{});var Eha=s(Vxe);aht=r(Eha,"bart"),Eha.forEach(t),nht=r(BKe," \u2014 "),Mse=n(BKe,"A",{href:!0});var Cha=s(Mse);sht=r(Cha,"FlaxBartForConditionalGeneration"),Cha.forEach(t),lht=r(BKe," (BART model)"),BKe.forEach(t),iht=i(je),z7=n(je,"LI",{});var IKe=s(z7);Xxe=n(IKe,"STRONG",{});var wha=s(Xxe);dht=r(wha,"bert"),wha.forEach(t),mht=r(IKe," \u2014 "),Ese=n(IKe,"A",{href:!0});var Aha=s(Ese);cht=r(Aha,"FlaxBertForMaskedLM"),Aha.forEach(t),fht=r(IKe," (BERT model)"),IKe.forEach(t),ght=i(je),Q7=n(je,"LI",{});var NKe=s(Q7);zxe=n(NKe,"STRONG",{});var Lha=s(zxe);hht=r(Lha,"big_bird"),Lha.forEach(t),uht=r(NKe," \u2014 "),Cse=n(NKe,"A",{href:!0});var yha=s(Cse);pht=r(yha,"FlaxBigBirdForMaskedLM"),yha.forEach(t),_ht=r(NKe," (BigBird model)"),NKe.forEach(t),bht=i(je),W7=n(je,"LI",{});var qKe=s(W7);Qxe=n(qKe,"STRONG",{});var xha=s(Qxe);vht=r(xha,"distilbert"),xha.forEach(t),Fht=r(qKe," \u2014 "),wse=n(qKe,"A",{href:!0});var $ha=s(wse);Tht=r($ha,"FlaxDistilBertForMaskedLM"),$ha.forEach(t),Mht=r(qKe," (DistilBERT model)"),qKe.forEach(t),Eht=i(je),U7=n(je,"LI",{});var jKe=s(U7);Wxe=n(jKe,"STRONG",{});var kha=s(Wxe);Cht=r(kha,"electra"),kha.forEach(t),wht=r(jKe," \u2014 "),Ase=n(jKe,"A",{href:!0});var Sha=s(Ase);Aht=r(Sha,"FlaxElectraForMaskedLM"),Sha.forEach(t),Lht=r(jKe," (ELECTRA model)"),jKe.forEach(t),yht=i(je),H7=n(je,"LI",{});var DKe=s(H7);Uxe=n(DKe,"STRONG",{});var Rha=s(Uxe);xht=r(Rha,"mbart"),Rha.forEach(t),$ht=r(DKe," \u2014 "),Lse=n(DKe,"A",{href:!0});var Pha=s(Lse);kht=r(Pha,"FlaxMBartForConditionalGeneration"),Pha.forEach(t),Sht=r(DKe," (mBART model)"),DKe.forEach(t),Rht=i(je),J7=n(je,"LI",{});var GKe=s(J7);Hxe=n(GKe,"STRONG",{});var Bha=s(Hxe);Pht=r(Bha,"roberta"),Bha.forEach(t),Bht=r(GKe," \u2014 "),yse=n(GKe,"A",{href:!0});var Iha=s(yse);Iht=r(Iha,"FlaxRobertaForMaskedLM"),Iha.forEach(t),Nht=r(GKe," (RoBERTa model)"),GKe.forEach(t),qht=i(je),Y7=n(je,"LI",{});var OKe=s(Y7);Jxe=n(OKe,"STRONG",{});var Nha=s(Jxe);jht=r(Nha,"roformer"),Nha.forEach(t),Dht=r(OKe," \u2014 "),xse=n(OKe,"A",{href:!0});var qha=s(xse);Ght=r(qha,"FlaxRoFormerForMaskedLM"),qha.forEach(t),Oht=r(OKe," (RoFormer model)"),OKe.forEach(t),Vht=i(je),K7=n(je,"LI",{});var VKe=s(K7);Yxe=n(VKe,"STRONG",{});var jha=s(Yxe);Xht=r(jha,"xlm-roberta"),jha.forEach(t),zht=r(VKe," \u2014 "),$se=n(VKe,"A",{href:!0});var Dha=s($se);Qht=r(Dha,"FlaxXLMRobertaForMaskedLM"),Dha.forEach(t),Wht=r(VKe," (XLM-RoBERTa model)"),VKe.forEach(t),je.forEach(t),Uht=i(Di),T(Z7.$$.fragment,Di),Di.forEach(t),ji.forEach(t),Noo=i(c),Hc=n(c,"H2",{class:!0});var Zto=s(Hc);eL=n(Zto,"A",{id:!0,class:!0,href:!0});var Gha=s(eL);Kxe=n(Gha,"SPAN",{});var Oha=s(Kxe);T(OR.$$.fragment,Oha),Oha.forEach(t),Gha.forEach(t),Hht=i(Zto),Zxe=n(Zto,"SPAN",{});var Vha=s(Zxe);Jht=r(Vha,"FlaxAutoModelForSeq2SeqLM"),Vha.forEach(t),Zto.forEach(t),qoo=i(c),Ar=n(c,"DIV",{class:!0});var Gi=s(Ar);T(VR.$$.fragment,Gi),Yht=i(Gi),Jc=n(Gi,"P",{});var qde=s(Jc);Kht=r(qde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),kse=n(qde,"A",{href:!0});var Xha=s(kse);Zht=r(Xha,"from_pretrained()"),Xha.forEach(t),eut=r(qde," class method or the "),Sse=n(qde,"A",{href:!0});var zha=s(Sse);out=r(zha,"from_config()"),zha.forEach(t),rut=r(qde,` class
method.`),qde.forEach(t),tut=i(Gi),XR=n(Gi,"P",{});var eao=s(XR);aut=r(eao,"This class cannot be instantiated directly using "),e$e=n(eao,"CODE",{});var Qha=s(e$e);nut=r(Qha,"__init__()"),Qha.forEach(t),sut=r(eao," (throws an error)."),eao.forEach(t),lut=i(Gi),ma=n(Gi,"DIV",{class:!0});var P9=s(ma);T(zR.$$.fragment,P9),iut=i(P9),o$e=n(P9,"P",{});var Wha=s(o$e);dut=r(Wha,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Wha.forEach(t),mut=i(P9),Yc=n(P9,"P",{});var jde=s(Yc);cut=r(jde,`Note:
Loading a model from its configuration file does `),r$e=n(jde,"STRONG",{});var Uha=s(r$e);fut=r(Uha,"not"),Uha.forEach(t),gut=r(jde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rse=n(jde,"A",{href:!0});var Hha=s(Rse);hut=r(Hha,"from_pretrained()"),Hha.forEach(t),uut=r(jde," to load the model weights."),jde.forEach(t),put=i(P9),T(oL.$$.fragment,P9),P9.forEach(t),_ut=i(Gi),rt=n(Gi,"DIV",{class:!0});var Oi=s(rt);T(QR.$$.fragment,Oi),but=i(Oi),t$e=n(Oi,"P",{});var Jha=s(t$e);vut=r(Jha,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Jha.forEach(t),Fut=i(Oi),zn=n(Oi,"P",{});var B9=s(zn);Tut=r(B9,"The model class to instantiate is selected based on the "),a$e=n(B9,"CODE",{});var Yha=s(a$e);Mut=r(Yha,"model_type"),Yha.forEach(t),Eut=r(B9,` property of the config object (either
passed as an argument or loaded from `),n$e=n(B9,"CODE",{});var Kha=s(n$e);Cut=r(Kha,"pretrained_model_name_or_path"),Kha.forEach(t),wut=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s$e=n(B9,"CODE",{});var Zha=s(s$e);Aut=r(Zha,"pretrained_model_name_or_path"),Zha.forEach(t),Lut=r(B9,":"),B9.forEach(t),yut=i(Oi),ke=n(Oi,"UL",{});var De=s(ke);rL=n(De,"LI",{});var XKe=s(rL);l$e=n(XKe,"STRONG",{});var eua=s(l$e);xut=r(eua,"bart"),eua.forEach(t),$ut=r(XKe," \u2014 "),Pse=n(XKe,"A",{href:!0});var oua=s(Pse);kut=r(oua,"FlaxBartForConditionalGeneration"),oua.forEach(t),Sut=r(XKe," (BART model)"),XKe.forEach(t),Rut=i(De),tL=n(De,"LI",{});var zKe=s(tL);i$e=n(zKe,"STRONG",{});var rua=s(i$e);Put=r(rua,"blenderbot"),rua.forEach(t),But=r(zKe," \u2014 "),Bse=n(zKe,"A",{href:!0});var tua=s(Bse);Iut=r(tua,"FlaxBlenderbotForConditionalGeneration"),tua.forEach(t),Nut=r(zKe," (Blenderbot model)"),zKe.forEach(t),qut=i(De),aL=n(De,"LI",{});var QKe=s(aL);d$e=n(QKe,"STRONG",{});var aua=s(d$e);jut=r(aua,"blenderbot-small"),aua.forEach(t),Dut=r(QKe," \u2014 "),Ise=n(QKe,"A",{href:!0});var nua=s(Ise);Gut=r(nua,"FlaxBlenderbotSmallForConditionalGeneration"),nua.forEach(t),Out=r(QKe," (BlenderbotSmall model)"),QKe.forEach(t),Vut=i(De),nL=n(De,"LI",{});var WKe=s(nL);m$e=n(WKe,"STRONG",{});var sua=s(m$e);Xut=r(sua,"encoder-decoder"),sua.forEach(t),zut=r(WKe," \u2014 "),Nse=n(WKe,"A",{href:!0});var lua=s(Nse);Qut=r(lua,"FlaxEncoderDecoderModel"),lua.forEach(t),Wut=r(WKe," (Encoder decoder model)"),WKe.forEach(t),Uut=i(De),sL=n(De,"LI",{});var UKe=s(sL);c$e=n(UKe,"STRONG",{});var iua=s(c$e);Hut=r(iua,"longt5"),iua.forEach(t),Jut=r(UKe," \u2014 "),qse=n(UKe,"A",{href:!0});var dua=s(qse);Yut=r(dua,"FlaxLongT5ForConditionalGeneration"),dua.forEach(t),Kut=r(UKe," (LongT5 model)"),UKe.forEach(t),Zut=i(De),lL=n(De,"LI",{});var HKe=s(lL);f$e=n(HKe,"STRONG",{});var mua=s(f$e);ept=r(mua,"marian"),mua.forEach(t),opt=r(HKe," \u2014 "),jse=n(HKe,"A",{href:!0});var cua=s(jse);rpt=r(cua,"FlaxMarianMTModel"),cua.forEach(t),tpt=r(HKe," (Marian model)"),HKe.forEach(t),apt=i(De),iL=n(De,"LI",{});var JKe=s(iL);g$e=n(JKe,"STRONG",{});var fua=s(g$e);npt=r(fua,"mbart"),fua.forEach(t),spt=r(JKe," \u2014 "),Dse=n(JKe,"A",{href:!0});var gua=s(Dse);lpt=r(gua,"FlaxMBartForConditionalGeneration"),gua.forEach(t),ipt=r(JKe," (mBART model)"),JKe.forEach(t),dpt=i(De),dL=n(De,"LI",{});var YKe=s(dL);h$e=n(YKe,"STRONG",{});var hua=s(h$e);mpt=r(hua,"mt5"),hua.forEach(t),cpt=r(YKe," \u2014 "),Gse=n(YKe,"A",{href:!0});var uua=s(Gse);fpt=r(uua,"FlaxMT5ForConditionalGeneration"),uua.forEach(t),gpt=r(YKe," (MT5 model)"),YKe.forEach(t),hpt=i(De),mL=n(De,"LI",{});var KKe=s(mL);u$e=n(KKe,"STRONG",{});var pua=s(u$e);upt=r(pua,"pegasus"),pua.forEach(t),ppt=r(KKe," \u2014 "),Ose=n(KKe,"A",{href:!0});var _ua=s(Ose);_pt=r(_ua,"FlaxPegasusForConditionalGeneration"),_ua.forEach(t),bpt=r(KKe," (Pegasus model)"),KKe.forEach(t),vpt=i(De),cL=n(De,"LI",{});var ZKe=s(cL);p$e=n(ZKe,"STRONG",{});var bua=s(p$e);Fpt=r(bua,"t5"),bua.forEach(t),Tpt=r(ZKe," \u2014 "),Vse=n(ZKe,"A",{href:!0});var vua=s(Vse);Mpt=r(vua,"FlaxT5ForConditionalGeneration"),vua.forEach(t),Ept=r(ZKe," (T5 model)"),ZKe.forEach(t),De.forEach(t),Cpt=i(Oi),T(fL.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),joo=i(c),Kc=n(c,"H2",{class:!0});var oao=s(Kc);gL=n(oao,"A",{id:!0,class:!0,href:!0});var Fua=s(gL);_$e=n(Fua,"SPAN",{});var Tua=s(_$e);T(WR.$$.fragment,Tua),Tua.forEach(t),Fua.forEach(t),wpt=i(oao),b$e=n(oao,"SPAN",{});var Mua=s(b$e);Apt=r(Mua,"FlaxAutoModelForSequenceClassification"),Mua.forEach(t),oao.forEach(t),Doo=i(c),Lr=n(c,"DIV",{class:!0});var Vi=s(Lr);T(UR.$$.fragment,Vi),Lpt=i(Vi),Zc=n(Vi,"P",{});var Dde=s(Zc);ypt=r(Dde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Xse=n(Dde,"A",{href:!0});var Eua=s(Xse);xpt=r(Eua,"from_pretrained()"),Eua.forEach(t),$pt=r(Dde," class method or the "),zse=n(Dde,"A",{href:!0});var Cua=s(zse);kpt=r(Cua,"from_config()"),Cua.forEach(t),Spt=r(Dde,` class
method.`),Dde.forEach(t),Rpt=i(Vi),HR=n(Vi,"P",{});var rao=s(HR);Ppt=r(rao,"This class cannot be instantiated directly using "),v$e=n(rao,"CODE",{});var wua=s(v$e);Bpt=r(wua,"__init__()"),wua.forEach(t),Ipt=r(rao," (throws an error)."),rao.forEach(t),Npt=i(Vi),ca=n(Vi,"DIV",{class:!0});var I9=s(ca);T(JR.$$.fragment,I9),qpt=i(I9),F$e=n(I9,"P",{});var Aua=s(F$e);jpt=r(Aua,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Aua.forEach(t),Dpt=i(I9),ef=n(I9,"P",{});var Gde=s(ef);Gpt=r(Gde,`Note:
Loading a model from its configuration file does `),T$e=n(Gde,"STRONG",{});var Lua=s(T$e);Opt=r(Lua,"not"),Lua.forEach(t),Vpt=r(Gde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qse=n(Gde,"A",{href:!0});var yua=s(Qse);Xpt=r(yua,"from_pretrained()"),yua.forEach(t),zpt=r(Gde," to load the model weights."),Gde.forEach(t),Qpt=i(I9),T(hL.$$.fragment,I9),I9.forEach(t),Wpt=i(Vi),tt=n(Vi,"DIV",{class:!0});var Xi=s(tt);T(YR.$$.fragment,Xi),Upt=i(Xi),M$e=n(Xi,"P",{});var xua=s(M$e);Hpt=r(xua,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),xua.forEach(t),Jpt=i(Xi),Qn=n(Xi,"P",{});var N9=s(Qn);Ypt=r(N9,"The model class to instantiate is selected based on the "),E$e=n(N9,"CODE",{});var $ua=s(E$e);Kpt=r($ua,"model_type"),$ua.forEach(t),Zpt=r(N9,` property of the config object (either
passed as an argument or loaded from `),C$e=n(N9,"CODE",{});var kua=s(C$e);e_t=r(kua,"pretrained_model_name_or_path"),kua.forEach(t),o_t=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w$e=n(N9,"CODE",{});var Sua=s(w$e);r_t=r(Sua,"pretrained_model_name_or_path"),Sua.forEach(t),t_t=r(N9,":"),N9.forEach(t),a_t=i(Xi),Se=n(Xi,"UL",{});var Ge=s(Se);uL=n(Ge,"LI",{});var eZe=s(uL);A$e=n(eZe,"STRONG",{});var Rua=s(A$e);n_t=r(Rua,"albert"),Rua.forEach(t),s_t=r(eZe," \u2014 "),Wse=n(eZe,"A",{href:!0});var Pua=s(Wse);l_t=r(Pua,"FlaxAlbertForSequenceClassification"),Pua.forEach(t),i_t=r(eZe," (ALBERT model)"),eZe.forEach(t),d_t=i(Ge),pL=n(Ge,"LI",{});var oZe=s(pL);L$e=n(oZe,"STRONG",{});var Bua=s(L$e);m_t=r(Bua,"bart"),Bua.forEach(t),c_t=r(oZe," \u2014 "),Use=n(oZe,"A",{href:!0});var Iua=s(Use);f_t=r(Iua,"FlaxBartForSequenceClassification"),Iua.forEach(t),g_t=r(oZe," (BART model)"),oZe.forEach(t),h_t=i(Ge),_L=n(Ge,"LI",{});var rZe=s(_L);y$e=n(rZe,"STRONG",{});var Nua=s(y$e);u_t=r(Nua,"bert"),Nua.forEach(t),p_t=r(rZe," \u2014 "),Hse=n(rZe,"A",{href:!0});var qua=s(Hse);__t=r(qua,"FlaxBertForSequenceClassification"),qua.forEach(t),b_t=r(rZe," (BERT model)"),rZe.forEach(t),v_t=i(Ge),bL=n(Ge,"LI",{});var tZe=s(bL);x$e=n(tZe,"STRONG",{});var jua=s(x$e);F_t=r(jua,"big_bird"),jua.forEach(t),T_t=r(tZe," \u2014 "),Jse=n(tZe,"A",{href:!0});var Dua=s(Jse);M_t=r(Dua,"FlaxBigBirdForSequenceClassification"),Dua.forEach(t),E_t=r(tZe," (BigBird model)"),tZe.forEach(t),C_t=i(Ge),vL=n(Ge,"LI",{});var aZe=s(vL);$$e=n(aZe,"STRONG",{});var Gua=s($$e);w_t=r(Gua,"distilbert"),Gua.forEach(t),A_t=r(aZe," \u2014 "),Yse=n(aZe,"A",{href:!0});var Oua=s(Yse);L_t=r(Oua,"FlaxDistilBertForSequenceClassification"),Oua.forEach(t),y_t=r(aZe," (DistilBERT model)"),aZe.forEach(t),x_t=i(Ge),FL=n(Ge,"LI",{});var nZe=s(FL);k$e=n(nZe,"STRONG",{});var Vua=s(k$e);$_t=r(Vua,"electra"),Vua.forEach(t),k_t=r(nZe," \u2014 "),Kse=n(nZe,"A",{href:!0});var Xua=s(Kse);S_t=r(Xua,"FlaxElectraForSequenceClassification"),Xua.forEach(t),R_t=r(nZe," (ELECTRA model)"),nZe.forEach(t),P_t=i(Ge),TL=n(Ge,"LI",{});var sZe=s(TL);S$e=n(sZe,"STRONG",{});var zua=s(S$e);B_t=r(zua,"mbart"),zua.forEach(t),I_t=r(sZe," \u2014 "),Zse=n(sZe,"A",{href:!0});var Qua=s(Zse);N_t=r(Qua,"FlaxMBartForSequenceClassification"),Qua.forEach(t),q_t=r(sZe," (mBART model)"),sZe.forEach(t),j_t=i(Ge),ML=n(Ge,"LI",{});var lZe=s(ML);R$e=n(lZe,"STRONG",{});var Wua=s(R$e);D_t=r(Wua,"roberta"),Wua.forEach(t),G_t=r(lZe," \u2014 "),ele=n(lZe,"A",{href:!0});var Uua=s(ele);O_t=r(Uua,"FlaxRobertaForSequenceClassification"),Uua.forEach(t),V_t=r(lZe," (RoBERTa model)"),lZe.forEach(t),X_t=i(Ge),EL=n(Ge,"LI",{});var iZe=s(EL);P$e=n(iZe,"STRONG",{});var Hua=s(P$e);z_t=r(Hua,"roformer"),Hua.forEach(t),Q_t=r(iZe," \u2014 "),ole=n(iZe,"A",{href:!0});var Jua=s(ole);W_t=r(Jua,"FlaxRoFormerForSequenceClassification"),Jua.forEach(t),U_t=r(iZe," (RoFormer model)"),iZe.forEach(t),H_t=i(Ge),CL=n(Ge,"LI",{});var dZe=s(CL);B$e=n(dZe,"STRONG",{});var Yua=s(B$e);J_t=r(Yua,"xlm-roberta"),Yua.forEach(t),Y_t=r(dZe," \u2014 "),rle=n(dZe,"A",{href:!0});var Kua=s(rle);K_t=r(Kua,"FlaxXLMRobertaForSequenceClassification"),Kua.forEach(t),Z_t=r(dZe," (XLM-RoBERTa model)"),dZe.forEach(t),Ge.forEach(t),e2t=i(Xi),T(wL.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),Goo=i(c),of=n(c,"H2",{class:!0});var tao=s(of);AL=n(tao,"A",{id:!0,class:!0,href:!0});var Zua=s(AL);I$e=n(Zua,"SPAN",{});var epa=s(I$e);T(KR.$$.fragment,epa),epa.forEach(t),Zua.forEach(t),o2t=i(tao),N$e=n(tao,"SPAN",{});var opa=s(N$e);r2t=r(opa,"FlaxAutoModelForQuestionAnswering"),opa.forEach(t),tao.forEach(t),Ooo=i(c),yr=n(c,"DIV",{class:!0});var zi=s(yr);T(ZR.$$.fragment,zi),t2t=i(zi),rf=n(zi,"P",{});var Ode=s(rf);a2t=r(Ode,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tle=n(Ode,"A",{href:!0});var rpa=s(tle);n2t=r(rpa,"from_pretrained()"),rpa.forEach(t),s2t=r(Ode," class method or the "),ale=n(Ode,"A",{href:!0});var tpa=s(ale);l2t=r(tpa,"from_config()"),tpa.forEach(t),i2t=r(Ode,` class
method.`),Ode.forEach(t),d2t=i(zi),eP=n(zi,"P",{});var aao=s(eP);m2t=r(aao,"This class cannot be instantiated directly using "),q$e=n(aao,"CODE",{});var apa=s(q$e);c2t=r(apa,"__init__()"),apa.forEach(t),f2t=r(aao," (throws an error)."),aao.forEach(t),g2t=i(zi),fa=n(zi,"DIV",{class:!0});var q9=s(fa);T(oP.$$.fragment,q9),h2t=i(q9),j$e=n(q9,"P",{});var npa=s(j$e);u2t=r(npa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),npa.forEach(t),p2t=i(q9),tf=n(q9,"P",{});var Vde=s(tf);_2t=r(Vde,`Note:
Loading a model from its configuration file does `),D$e=n(Vde,"STRONG",{});var spa=s(D$e);b2t=r(spa,"not"),spa.forEach(t),v2t=r(Vde,` load the model weights. It only affects the
model\u2019s configuration. Use `),nle=n(Vde,"A",{href:!0});var lpa=s(nle);F2t=r(lpa,"from_pretrained()"),lpa.forEach(t),T2t=r(Vde," to load the model weights."),Vde.forEach(t),M2t=i(q9),T(LL.$$.fragment,q9),q9.forEach(t),E2t=i(zi),at=n(zi,"DIV",{class:!0});var Qi=s(at);T(rP.$$.fragment,Qi),C2t=i(Qi),G$e=n(Qi,"P",{});var ipa=s(G$e);w2t=r(ipa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ipa.forEach(t),A2t=i(Qi),Wn=n(Qi,"P",{});var j9=s(Wn);L2t=r(j9,"The model class to instantiate is selected based on the "),O$e=n(j9,"CODE",{});var dpa=s(O$e);y2t=r(dpa,"model_type"),dpa.forEach(t),x2t=r(j9,` property of the config object (either
passed as an argument or loaded from `),V$e=n(j9,"CODE",{});var mpa=s(V$e);$2t=r(mpa,"pretrained_model_name_or_path"),mpa.forEach(t),k2t=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X$e=n(j9,"CODE",{});var cpa=s(X$e);S2t=r(cpa,"pretrained_model_name_or_path"),cpa.forEach(t),R2t=r(j9,":"),j9.forEach(t),P2t=i(Qi),Re=n(Qi,"UL",{});var Oe=s(Re);yL=n(Oe,"LI",{});var mZe=s(yL);z$e=n(mZe,"STRONG",{});var fpa=s(z$e);B2t=r(fpa,"albert"),fpa.forEach(t),I2t=r(mZe," \u2014 "),sle=n(mZe,"A",{href:!0});var gpa=s(sle);N2t=r(gpa,"FlaxAlbertForQuestionAnswering"),gpa.forEach(t),q2t=r(mZe," (ALBERT model)"),mZe.forEach(t),j2t=i(Oe),xL=n(Oe,"LI",{});var cZe=s(xL);Q$e=n(cZe,"STRONG",{});var hpa=s(Q$e);D2t=r(hpa,"bart"),hpa.forEach(t),G2t=r(cZe," \u2014 "),lle=n(cZe,"A",{href:!0});var upa=s(lle);O2t=r(upa,"FlaxBartForQuestionAnswering"),upa.forEach(t),V2t=r(cZe," (BART model)"),cZe.forEach(t),X2t=i(Oe),$L=n(Oe,"LI",{});var fZe=s($L);W$e=n(fZe,"STRONG",{});var ppa=s(W$e);z2t=r(ppa,"bert"),ppa.forEach(t),Q2t=r(fZe," \u2014 "),ile=n(fZe,"A",{href:!0});var _pa=s(ile);W2t=r(_pa,"FlaxBertForQuestionAnswering"),_pa.forEach(t),U2t=r(fZe," (BERT model)"),fZe.forEach(t),H2t=i(Oe),kL=n(Oe,"LI",{});var gZe=s(kL);U$e=n(gZe,"STRONG",{});var bpa=s(U$e);J2t=r(bpa,"big_bird"),bpa.forEach(t),Y2t=r(gZe," \u2014 "),dle=n(gZe,"A",{href:!0});var vpa=s(dle);K2t=r(vpa,"FlaxBigBirdForQuestionAnswering"),vpa.forEach(t),Z2t=r(gZe," (BigBird model)"),gZe.forEach(t),e1t=i(Oe),SL=n(Oe,"LI",{});var hZe=s(SL);H$e=n(hZe,"STRONG",{});var Fpa=s(H$e);o1t=r(Fpa,"distilbert"),Fpa.forEach(t),r1t=r(hZe," \u2014 "),mle=n(hZe,"A",{href:!0});var Tpa=s(mle);t1t=r(Tpa,"FlaxDistilBertForQuestionAnswering"),Tpa.forEach(t),a1t=r(hZe," (DistilBERT model)"),hZe.forEach(t),n1t=i(Oe),RL=n(Oe,"LI",{});var uZe=s(RL);J$e=n(uZe,"STRONG",{});var Mpa=s(J$e);s1t=r(Mpa,"electra"),Mpa.forEach(t),l1t=r(uZe," \u2014 "),cle=n(uZe,"A",{href:!0});var Epa=s(cle);i1t=r(Epa,"FlaxElectraForQuestionAnswering"),Epa.forEach(t),d1t=r(uZe," (ELECTRA model)"),uZe.forEach(t),m1t=i(Oe),PL=n(Oe,"LI",{});var pZe=s(PL);Y$e=n(pZe,"STRONG",{});var Cpa=s(Y$e);c1t=r(Cpa,"mbart"),Cpa.forEach(t),f1t=r(pZe," \u2014 "),fle=n(pZe,"A",{href:!0});var wpa=s(fle);g1t=r(wpa,"FlaxMBartForQuestionAnswering"),wpa.forEach(t),h1t=r(pZe," (mBART model)"),pZe.forEach(t),u1t=i(Oe),BL=n(Oe,"LI",{});var _Ze=s(BL);K$e=n(_Ze,"STRONG",{});var Apa=s(K$e);p1t=r(Apa,"roberta"),Apa.forEach(t),_1t=r(_Ze," \u2014 "),gle=n(_Ze,"A",{href:!0});var Lpa=s(gle);b1t=r(Lpa,"FlaxRobertaForQuestionAnswering"),Lpa.forEach(t),v1t=r(_Ze," (RoBERTa model)"),_Ze.forEach(t),F1t=i(Oe),IL=n(Oe,"LI",{});var bZe=s(IL);Z$e=n(bZe,"STRONG",{});var ypa=s(Z$e);T1t=r(ypa,"roformer"),ypa.forEach(t),M1t=r(bZe," \u2014 "),hle=n(bZe,"A",{href:!0});var xpa=s(hle);E1t=r(xpa,"FlaxRoFormerForQuestionAnswering"),xpa.forEach(t),C1t=r(bZe," (RoFormer model)"),bZe.forEach(t),w1t=i(Oe),NL=n(Oe,"LI",{});var vZe=s(NL);eke=n(vZe,"STRONG",{});var $pa=s(eke);A1t=r($pa,"xlm-roberta"),$pa.forEach(t),L1t=r(vZe," \u2014 "),ule=n(vZe,"A",{href:!0});var kpa=s(ule);y1t=r(kpa,"FlaxXLMRobertaForQuestionAnswering"),kpa.forEach(t),x1t=r(vZe," (XLM-RoBERTa model)"),vZe.forEach(t),Oe.forEach(t),$1t=i(Qi),T(qL.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),Voo=i(c),af=n(c,"H2",{class:!0});var nao=s(af);jL=n(nao,"A",{id:!0,class:!0,href:!0});var Spa=s(jL);oke=n(Spa,"SPAN",{});var Rpa=s(oke);T(tP.$$.fragment,Rpa),Rpa.forEach(t),Spa.forEach(t),k1t=i(nao),rke=n(nao,"SPAN",{});var Ppa=s(rke);S1t=r(Ppa,"FlaxAutoModelForTokenClassification"),Ppa.forEach(t),nao.forEach(t),Xoo=i(c),xr=n(c,"DIV",{class:!0});var Wi=s(xr);T(aP.$$.fragment,Wi),R1t=i(Wi),nf=n(Wi,"P",{});var Xde=s(nf);P1t=r(Xde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ple=n(Xde,"A",{href:!0});var Bpa=s(ple);B1t=r(Bpa,"from_pretrained()"),Bpa.forEach(t),I1t=r(Xde," class method or the "),_le=n(Xde,"A",{href:!0});var Ipa=s(_le);N1t=r(Ipa,"from_config()"),Ipa.forEach(t),q1t=r(Xde,` class
method.`),Xde.forEach(t),j1t=i(Wi),nP=n(Wi,"P",{});var sao=s(nP);D1t=r(sao,"This class cannot be instantiated directly using "),tke=n(sao,"CODE",{});var Npa=s(tke);G1t=r(Npa,"__init__()"),Npa.forEach(t),O1t=r(sao," (throws an error)."),sao.forEach(t),V1t=i(Wi),ga=n(Wi,"DIV",{class:!0});var D9=s(ga);T(sP.$$.fragment,D9),X1t=i(D9),ake=n(D9,"P",{});var qpa=s(ake);z1t=r(qpa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),qpa.forEach(t),Q1t=i(D9),sf=n(D9,"P",{});var zde=s(sf);W1t=r(zde,`Note:
Loading a model from its configuration file does `),nke=n(zde,"STRONG",{});var jpa=s(nke);U1t=r(jpa,"not"),jpa.forEach(t),H1t=r(zde,` load the model weights. It only affects the
model\u2019s configuration. Use `),ble=n(zde,"A",{href:!0});var Dpa=s(ble);J1t=r(Dpa,"from_pretrained()"),Dpa.forEach(t),Y1t=r(zde," to load the model weights."),zde.forEach(t),K1t=i(D9),T(DL.$$.fragment,D9),D9.forEach(t),Z1t=i(Wi),nt=n(Wi,"DIV",{class:!0});var Ui=s(nt);T(lP.$$.fragment,Ui),ebt=i(Ui),ske=n(Ui,"P",{});var Gpa=s(ske);obt=r(Gpa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Gpa.forEach(t),rbt=i(Ui),Un=n(Ui,"P",{});var G9=s(Un);tbt=r(G9,"The model class to instantiate is selected based on the "),lke=n(G9,"CODE",{});var Opa=s(lke);abt=r(Opa,"model_type"),Opa.forEach(t),nbt=r(G9,` property of the config object (either
passed as an argument or loaded from `),ike=n(G9,"CODE",{});var Vpa=s(ike);sbt=r(Vpa,"pretrained_model_name_or_path"),Vpa.forEach(t),lbt=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dke=n(G9,"CODE",{});var Xpa=s(dke);ibt=r(Xpa,"pretrained_model_name_or_path"),Xpa.forEach(t),dbt=r(G9,":"),G9.forEach(t),mbt=i(Ui),Xe=n(Ui,"UL",{});var Ao=s(Xe);GL=n(Ao,"LI",{});var FZe=s(GL);mke=n(FZe,"STRONG",{});var zpa=s(mke);cbt=r(zpa,"albert"),zpa.forEach(t),fbt=r(FZe," \u2014 "),vle=n(FZe,"A",{href:!0});var Qpa=s(vle);gbt=r(Qpa,"FlaxAlbertForTokenClassification"),Qpa.forEach(t),hbt=r(FZe," (ALBERT model)"),FZe.forEach(t),ubt=i(Ao),OL=n(Ao,"LI",{});var TZe=s(OL);cke=n(TZe,"STRONG",{});var Wpa=s(cke);pbt=r(Wpa,"bert"),Wpa.forEach(t),_bt=r(TZe," \u2014 "),Fle=n(TZe,"A",{href:!0});var Upa=s(Fle);bbt=r(Upa,"FlaxBertForTokenClassification"),Upa.forEach(t),vbt=r(TZe," (BERT model)"),TZe.forEach(t),Fbt=i(Ao),VL=n(Ao,"LI",{});var MZe=s(VL);fke=n(MZe,"STRONG",{});var Hpa=s(fke);Tbt=r(Hpa,"big_bird"),Hpa.forEach(t),Mbt=r(MZe," \u2014 "),Tle=n(MZe,"A",{href:!0});var Jpa=s(Tle);Ebt=r(Jpa,"FlaxBigBirdForTokenClassification"),Jpa.forEach(t),Cbt=r(MZe," (BigBird model)"),MZe.forEach(t),wbt=i(Ao),XL=n(Ao,"LI",{});var EZe=s(XL);gke=n(EZe,"STRONG",{});var Ypa=s(gke);Abt=r(Ypa,"distilbert"),Ypa.forEach(t),Lbt=r(EZe," \u2014 "),Mle=n(EZe,"A",{href:!0});var Kpa=s(Mle);ybt=r(Kpa,"FlaxDistilBertForTokenClassification"),Kpa.forEach(t),xbt=r(EZe," (DistilBERT model)"),EZe.forEach(t),$bt=i(Ao),zL=n(Ao,"LI",{});var CZe=s(zL);hke=n(CZe,"STRONG",{});var Zpa=s(hke);kbt=r(Zpa,"electra"),Zpa.forEach(t),Sbt=r(CZe," \u2014 "),Ele=n(CZe,"A",{href:!0});var e_a=s(Ele);Rbt=r(e_a,"FlaxElectraForTokenClassification"),e_a.forEach(t),Pbt=r(CZe," (ELECTRA model)"),CZe.forEach(t),Bbt=i(Ao),QL=n(Ao,"LI",{});var wZe=s(QL);uke=n(wZe,"STRONG",{});var o_a=s(uke);Ibt=r(o_a,"roberta"),o_a.forEach(t),Nbt=r(wZe," \u2014 "),Cle=n(wZe,"A",{href:!0});var r_a=s(Cle);qbt=r(r_a,"FlaxRobertaForTokenClassification"),r_a.forEach(t),jbt=r(wZe," (RoBERTa model)"),wZe.forEach(t),Dbt=i(Ao),WL=n(Ao,"LI",{});var AZe=s(WL);pke=n(AZe,"STRONG",{});var t_a=s(pke);Gbt=r(t_a,"roformer"),t_a.forEach(t),Obt=r(AZe," \u2014 "),wle=n(AZe,"A",{href:!0});var a_a=s(wle);Vbt=r(a_a,"FlaxRoFormerForTokenClassification"),a_a.forEach(t),Xbt=r(AZe," (RoFormer model)"),AZe.forEach(t),zbt=i(Ao),UL=n(Ao,"LI",{});var LZe=s(UL);_ke=n(LZe,"STRONG",{});var n_a=s(_ke);Qbt=r(n_a,"xlm-roberta"),n_a.forEach(t),Wbt=r(LZe," \u2014 "),Ale=n(LZe,"A",{href:!0});var s_a=s(Ale);Ubt=r(s_a,"FlaxXLMRobertaForTokenClassification"),s_a.forEach(t),Hbt=r(LZe," (XLM-RoBERTa model)"),LZe.forEach(t),Ao.forEach(t),Jbt=i(Ui),T(HL.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),zoo=i(c),lf=n(c,"H2",{class:!0});var lao=s(lf);JL=n(lao,"A",{id:!0,class:!0,href:!0});var l_a=s(JL);bke=n(l_a,"SPAN",{});var i_a=s(bke);T(iP.$$.fragment,i_a),i_a.forEach(t),l_a.forEach(t),Ybt=i(lao),vke=n(lao,"SPAN",{});var d_a=s(vke);Kbt=r(d_a,"FlaxAutoModelForMultipleChoice"),d_a.forEach(t),lao.forEach(t),Qoo=i(c),$r=n(c,"DIV",{class:!0});var Hi=s($r);T(dP.$$.fragment,Hi),Zbt=i(Hi),df=n(Hi,"P",{});var Qde=s(df);evt=r(Qde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Lle=n(Qde,"A",{href:!0});var m_a=s(Lle);ovt=r(m_a,"from_pretrained()"),m_a.forEach(t),rvt=r(Qde," class method or the "),yle=n(Qde,"A",{href:!0});var c_a=s(yle);tvt=r(c_a,"from_config()"),c_a.forEach(t),avt=r(Qde,` class
method.`),Qde.forEach(t),nvt=i(Hi),mP=n(Hi,"P",{});var iao=s(mP);svt=r(iao,"This class cannot be instantiated directly using "),Fke=n(iao,"CODE",{});var f_a=s(Fke);lvt=r(f_a,"__init__()"),f_a.forEach(t),ivt=r(iao," (throws an error)."),iao.forEach(t),dvt=i(Hi),ha=n(Hi,"DIV",{class:!0});var O9=s(ha);T(cP.$$.fragment,O9),mvt=i(O9),Tke=n(O9,"P",{});var g_a=s(Tke);cvt=r(g_a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),g_a.forEach(t),fvt=i(O9),mf=n(O9,"P",{});var Wde=s(mf);gvt=r(Wde,`Note:
Loading a model from its configuration file does `),Mke=n(Wde,"STRONG",{});var h_a=s(Mke);hvt=r(h_a,"not"),h_a.forEach(t),uvt=r(Wde,` load the model weights. It only affects the
model\u2019s configuration. Use `),xle=n(Wde,"A",{href:!0});var u_a=s(xle);pvt=r(u_a,"from_pretrained()"),u_a.forEach(t),_vt=r(Wde," to load the model weights."),Wde.forEach(t),bvt=i(O9),T(YL.$$.fragment,O9),O9.forEach(t),vvt=i(Hi),st=n(Hi,"DIV",{class:!0});var Ji=s(st);T(fP.$$.fragment,Ji),Fvt=i(Ji),Eke=n(Ji,"P",{});var p_a=s(Eke);Tvt=r(p_a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),p_a.forEach(t),Mvt=i(Ji),Hn=n(Ji,"P",{});var V9=s(Hn);Evt=r(V9,"The model class to instantiate is selected based on the "),Cke=n(V9,"CODE",{});var __a=s(Cke);Cvt=r(__a,"model_type"),__a.forEach(t),wvt=r(V9,` property of the config object (either
passed as an argument or loaded from `),wke=n(V9,"CODE",{});var b_a=s(wke);Avt=r(b_a,"pretrained_model_name_or_path"),b_a.forEach(t),Lvt=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ake=n(V9,"CODE",{});var v_a=s(Ake);yvt=r(v_a,"pretrained_model_name_or_path"),v_a.forEach(t),xvt=r(V9,":"),V9.forEach(t),$vt=i(Ji),ze=n(Ji,"UL",{});var Lo=s(ze);KL=n(Lo,"LI",{});var yZe=s(KL);Lke=n(yZe,"STRONG",{});var F_a=s(Lke);kvt=r(F_a,"albert"),F_a.forEach(t),Svt=r(yZe," \u2014 "),$le=n(yZe,"A",{href:!0});var T_a=s($le);Rvt=r(T_a,"FlaxAlbertForMultipleChoice"),T_a.forEach(t),Pvt=r(yZe," (ALBERT model)"),yZe.forEach(t),Bvt=i(Lo),ZL=n(Lo,"LI",{});var xZe=s(ZL);yke=n(xZe,"STRONG",{});var M_a=s(yke);Ivt=r(M_a,"bert"),M_a.forEach(t),Nvt=r(xZe," \u2014 "),kle=n(xZe,"A",{href:!0});var E_a=s(kle);qvt=r(E_a,"FlaxBertForMultipleChoice"),E_a.forEach(t),jvt=r(xZe," (BERT model)"),xZe.forEach(t),Dvt=i(Lo),ey=n(Lo,"LI",{});var $Ze=s(ey);xke=n($Ze,"STRONG",{});var C_a=s(xke);Gvt=r(C_a,"big_bird"),C_a.forEach(t),Ovt=r($Ze," \u2014 "),Sle=n($Ze,"A",{href:!0});var w_a=s(Sle);Vvt=r(w_a,"FlaxBigBirdForMultipleChoice"),w_a.forEach(t),Xvt=r($Ze," (BigBird model)"),$Ze.forEach(t),zvt=i(Lo),oy=n(Lo,"LI",{});var kZe=s(oy);$ke=n(kZe,"STRONG",{});var A_a=s($ke);Qvt=r(A_a,"distilbert"),A_a.forEach(t),Wvt=r(kZe," \u2014 "),Rle=n(kZe,"A",{href:!0});var L_a=s(Rle);Uvt=r(L_a,"FlaxDistilBertForMultipleChoice"),L_a.forEach(t),Hvt=r(kZe," (DistilBERT model)"),kZe.forEach(t),Jvt=i(Lo),ry=n(Lo,"LI",{});var SZe=s(ry);kke=n(SZe,"STRONG",{});var y_a=s(kke);Yvt=r(y_a,"electra"),y_a.forEach(t),Kvt=r(SZe," \u2014 "),Ple=n(SZe,"A",{href:!0});var x_a=s(Ple);Zvt=r(x_a,"FlaxElectraForMultipleChoice"),x_a.forEach(t),eFt=r(SZe," (ELECTRA model)"),SZe.forEach(t),oFt=i(Lo),ty=n(Lo,"LI",{});var RZe=s(ty);Ske=n(RZe,"STRONG",{});var $_a=s(Ske);rFt=r($_a,"roberta"),$_a.forEach(t),tFt=r(RZe," \u2014 "),Ble=n(RZe,"A",{href:!0});var k_a=s(Ble);aFt=r(k_a,"FlaxRobertaForMultipleChoice"),k_a.forEach(t),nFt=r(RZe," (RoBERTa model)"),RZe.forEach(t),sFt=i(Lo),ay=n(Lo,"LI",{});var PZe=s(ay);Rke=n(PZe,"STRONG",{});var S_a=s(Rke);lFt=r(S_a,"roformer"),S_a.forEach(t),iFt=r(PZe," \u2014 "),Ile=n(PZe,"A",{href:!0});var R_a=s(Ile);dFt=r(R_a,"FlaxRoFormerForMultipleChoice"),R_a.forEach(t),mFt=r(PZe," (RoFormer model)"),PZe.forEach(t),cFt=i(Lo),ny=n(Lo,"LI",{});var BZe=s(ny);Pke=n(BZe,"STRONG",{});var P_a=s(Pke);fFt=r(P_a,"xlm-roberta"),P_a.forEach(t),gFt=r(BZe," \u2014 "),Nle=n(BZe,"A",{href:!0});var B_a=s(Nle);hFt=r(B_a,"FlaxXLMRobertaForMultipleChoice"),B_a.forEach(t),uFt=r(BZe," (XLM-RoBERTa model)"),BZe.forEach(t),Lo.forEach(t),pFt=i(Ji),T(sy.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Woo=i(c),cf=n(c,"H2",{class:!0});var dao=s(cf);ly=n(dao,"A",{id:!0,class:!0,href:!0});var I_a=s(ly);Bke=n(I_a,"SPAN",{});var N_a=s(Bke);T(gP.$$.fragment,N_a),N_a.forEach(t),I_a.forEach(t),_Ft=i(dao),Ike=n(dao,"SPAN",{});var q_a=s(Ike);bFt=r(q_a,"FlaxAutoModelForNextSentencePrediction"),q_a.forEach(t),dao.forEach(t),Uoo=i(c),kr=n(c,"DIV",{class:!0});var Yi=s(kr);T(hP.$$.fragment,Yi),vFt=i(Yi),ff=n(Yi,"P",{});var Ude=s(ff);FFt=r(Ude,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),qle=n(Ude,"A",{href:!0});var j_a=s(qle);TFt=r(j_a,"from_pretrained()"),j_a.forEach(t),MFt=r(Ude," class method or the "),jle=n(Ude,"A",{href:!0});var D_a=s(jle);EFt=r(D_a,"from_config()"),D_a.forEach(t),CFt=r(Ude,` class
method.`),Ude.forEach(t),wFt=i(Yi),uP=n(Yi,"P",{});var mao=s(uP);AFt=r(mao,"This class cannot be instantiated directly using "),Nke=n(mao,"CODE",{});var G_a=s(Nke);LFt=r(G_a,"__init__()"),G_a.forEach(t),yFt=r(mao," (throws an error)."),mao.forEach(t),xFt=i(Yi),ua=n(Yi,"DIV",{class:!0});var X9=s(ua);T(pP.$$.fragment,X9),$Ft=i(X9),qke=n(X9,"P",{});var O_a=s(qke);kFt=r(O_a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),O_a.forEach(t),SFt=i(X9),gf=n(X9,"P",{});var Hde=s(gf);RFt=r(Hde,`Note:
Loading a model from its configuration file does `),jke=n(Hde,"STRONG",{});var V_a=s(jke);PFt=r(V_a,"not"),V_a.forEach(t),BFt=r(Hde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dle=n(Hde,"A",{href:!0});var X_a=s(Dle);IFt=r(X_a,"from_pretrained()"),X_a.forEach(t),NFt=r(Hde," to load the model weights."),Hde.forEach(t),qFt=i(X9),T(iy.$$.fragment,X9),X9.forEach(t),jFt=i(Yi),lt=n(Yi,"DIV",{class:!0});var Ki=s(lt);T(_P.$$.fragment,Ki),DFt=i(Ki),Dke=n(Ki,"P",{});var z_a=s(Dke);GFt=r(z_a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),z_a.forEach(t),OFt=i(Ki),Jn=n(Ki,"P",{});var z9=s(Jn);VFt=r(z9,"The model class to instantiate is selected based on the "),Gke=n(z9,"CODE",{});var Q_a=s(Gke);XFt=r(Q_a,"model_type"),Q_a.forEach(t),zFt=r(z9,` property of the config object (either
passed as an argument or loaded from `),Oke=n(z9,"CODE",{});var W_a=s(Oke);QFt=r(W_a,"pretrained_model_name_or_path"),W_a.forEach(t),WFt=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vke=n(z9,"CODE",{});var U_a=s(Vke);UFt=r(U_a,"pretrained_model_name_or_path"),U_a.forEach(t),HFt=r(z9,":"),z9.forEach(t),JFt=i(Ki),Xke=n(Ki,"UL",{});var H_a=s(Xke);dy=n(H_a,"LI",{});var IZe=s(dy);zke=n(IZe,"STRONG",{});var J_a=s(zke);YFt=r(J_a,"bert"),J_a.forEach(t),KFt=r(IZe," \u2014 "),Gle=n(IZe,"A",{href:!0});var Y_a=s(Gle);ZFt=r(Y_a,"FlaxBertForNextSentencePrediction"),Y_a.forEach(t),eTt=r(IZe," (BERT model)"),IZe.forEach(t),H_a.forEach(t),oTt=i(Ki),T(my.$$.fragment,Ki),Ki.forEach(t),Yi.forEach(t),Hoo=i(c),hf=n(c,"H2",{class:!0});var cao=s(hf);cy=n(cao,"A",{id:!0,class:!0,href:!0});var K_a=s(cy);Qke=n(K_a,"SPAN",{});var Z_a=s(Qke);T(bP.$$.fragment,Z_a),Z_a.forEach(t),K_a.forEach(t),rTt=i(cao),Wke=n(cao,"SPAN",{});var e2a=s(Wke);tTt=r(e2a,"FlaxAutoModelForImageClassification"),e2a.forEach(t),cao.forEach(t),Joo=i(c),Sr=n(c,"DIV",{class:!0});var Zi=s(Sr);T(vP.$$.fragment,Zi),aTt=i(Zi),uf=n(Zi,"P",{});var Jde=s(uf);nTt=r(Jde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ole=n(Jde,"A",{href:!0});var o2a=s(Ole);sTt=r(o2a,"from_pretrained()"),o2a.forEach(t),lTt=r(Jde," class method or the "),Vle=n(Jde,"A",{href:!0});var r2a=s(Vle);iTt=r(r2a,"from_config()"),r2a.forEach(t),dTt=r(Jde,` class
method.`),Jde.forEach(t),mTt=i(Zi),FP=n(Zi,"P",{});var fao=s(FP);cTt=r(fao,"This class cannot be instantiated directly using "),Uke=n(fao,"CODE",{});var t2a=s(Uke);fTt=r(t2a,"__init__()"),t2a.forEach(t),gTt=r(fao," (throws an error)."),fao.forEach(t),hTt=i(Zi),pa=n(Zi,"DIV",{class:!0});var Q9=s(pa);T(TP.$$.fragment,Q9),uTt=i(Q9),Hke=n(Q9,"P",{});var a2a=s(Hke);pTt=r(a2a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),a2a.forEach(t),_Tt=i(Q9),pf=n(Q9,"P",{});var Yde=s(pf);bTt=r(Yde,`Note:
Loading a model from its configuration file does `),Jke=n(Yde,"STRONG",{});var n2a=s(Jke);vTt=r(n2a,"not"),n2a.forEach(t),FTt=r(Yde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xle=n(Yde,"A",{href:!0});var s2a=s(Xle);TTt=r(s2a,"from_pretrained()"),s2a.forEach(t),MTt=r(Yde," to load the model weights."),Yde.forEach(t),ETt=i(Q9),T(fy.$$.fragment,Q9),Q9.forEach(t),CTt=i(Zi),it=n(Zi,"DIV",{class:!0});var ed=s(it);T(MP.$$.fragment,ed),wTt=i(ed),Yke=n(ed,"P",{});var l2a=s(Yke);ATt=r(l2a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),l2a.forEach(t),LTt=i(ed),Yn=n(ed,"P",{});var W9=s(Yn);yTt=r(W9,"The model class to instantiate is selected based on the "),Kke=n(W9,"CODE",{});var i2a=s(Kke);xTt=r(i2a,"model_type"),i2a.forEach(t),$Tt=r(W9,` property of the config object (either
passed as an argument or loaded from `),Zke=n(W9,"CODE",{});var d2a=s(Zke);kTt=r(d2a,"pretrained_model_name_or_path"),d2a.forEach(t),STt=r(W9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eSe=n(W9,"CODE",{});var m2a=s(eSe);RTt=r(m2a,"pretrained_model_name_or_path"),m2a.forEach(t),PTt=r(W9,":"),W9.forEach(t),BTt=i(ed),EP=n(ed,"UL",{});var gao=s(EP);gy=n(gao,"LI",{});var NZe=s(gy);oSe=n(NZe,"STRONG",{});var c2a=s(oSe);ITt=r(c2a,"beit"),c2a.forEach(t),NTt=r(NZe," \u2014 "),zle=n(NZe,"A",{href:!0});var f2a=s(zle);qTt=r(f2a,"FlaxBeitForImageClassification"),f2a.forEach(t),jTt=r(NZe," (BEiT model)"),NZe.forEach(t),DTt=i(gao),hy=n(gao,"LI",{});var qZe=s(hy);rSe=n(qZe,"STRONG",{});var g2a=s(rSe);GTt=r(g2a,"vit"),g2a.forEach(t),OTt=r(qZe," \u2014 "),Qle=n(qZe,"A",{href:!0});var h2a=s(Qle);VTt=r(h2a,"FlaxViTForImageClassification"),h2a.forEach(t),XTt=r(qZe," (ViT model)"),qZe.forEach(t),gao.forEach(t),zTt=i(ed),T(uy.$$.fragment,ed),ed.forEach(t),Zi.forEach(t),Yoo=i(c),_f=n(c,"H2",{class:!0});var hao=s(_f);py=n(hao,"A",{id:!0,class:!0,href:!0});var u2a=s(py);tSe=n(u2a,"SPAN",{});var p2a=s(tSe);T(CP.$$.fragment,p2a),p2a.forEach(t),u2a.forEach(t),QTt=i(hao),aSe=n(hao,"SPAN",{});var _2a=s(aSe);WTt=r(_2a,"FlaxAutoModelForVision2Seq"),_2a.forEach(t),hao.forEach(t),Koo=i(c),Rr=n(c,"DIV",{class:!0});var od=s(Rr);T(wP.$$.fragment,od),UTt=i(od),bf=n(od,"P",{});var Kde=s(bf);HTt=r(Kde,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Wle=n(Kde,"A",{href:!0});var b2a=s(Wle);JTt=r(b2a,"from_pretrained()"),b2a.forEach(t),YTt=r(Kde," class method or the "),Ule=n(Kde,"A",{href:!0});var v2a=s(Ule);KTt=r(v2a,"from_config()"),v2a.forEach(t),ZTt=r(Kde,` class
method.`),Kde.forEach(t),eMt=i(od),AP=n(od,"P",{});var uao=s(AP);oMt=r(uao,"This class cannot be instantiated directly using "),nSe=n(uao,"CODE",{});var F2a=s(nSe);rMt=r(F2a,"__init__()"),F2a.forEach(t),tMt=r(uao," (throws an error)."),uao.forEach(t),aMt=i(od),_a=n(od,"DIV",{class:!0});var U9=s(_a);T(LP.$$.fragment,U9),nMt=i(U9),sSe=n(U9,"P",{});var T2a=s(sSe);sMt=r(T2a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),T2a.forEach(t),lMt=i(U9),vf=n(U9,"P",{});var Zde=s(vf);iMt=r(Zde,`Note:
Loading a model from its configuration file does `),lSe=n(Zde,"STRONG",{});var M2a=s(lSe);dMt=r(M2a,"not"),M2a.forEach(t),mMt=r(Zde,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hle=n(Zde,"A",{href:!0});var E2a=s(Hle);cMt=r(E2a,"from_pretrained()"),E2a.forEach(t),fMt=r(Zde," to load the model weights."),Zde.forEach(t),gMt=i(U9),T(_y.$$.fragment,U9),U9.forEach(t),hMt=i(od),dt=n(od,"DIV",{class:!0});var rd=s(dt);T(yP.$$.fragment,rd),uMt=i(rd),iSe=n(rd,"P",{});var C2a=s(iSe);pMt=r(C2a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),C2a.forEach(t),_Mt=i(rd),Kn=n(rd,"P",{});var H9=s(Kn);bMt=r(H9,"The model class to instantiate is selected based on the "),dSe=n(H9,"CODE",{});var w2a=s(dSe);vMt=r(w2a,"model_type"),w2a.forEach(t),FMt=r(H9,` property of the config object (either
passed as an argument or loaded from `),mSe=n(H9,"CODE",{});var A2a=s(mSe);TMt=r(A2a,"pretrained_model_name_or_path"),A2a.forEach(t),MMt=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cSe=n(H9,"CODE",{});var L2a=s(cSe);EMt=r(L2a,"pretrained_model_name_or_path"),L2a.forEach(t),CMt=r(H9,":"),H9.forEach(t),wMt=i(rd),fSe=n(rd,"UL",{});var y2a=s(fSe);by=n(y2a,"LI",{});var jZe=s(by);gSe=n(jZe,"STRONG",{});var x2a=s(gSe);AMt=r(x2a,"vision-encoder-decoder"),x2a.forEach(t),LMt=r(jZe," \u2014 "),Jle=n(jZe,"A",{href:!0});var $2a=s(Jle);yMt=r($2a,"FlaxVisionEncoderDecoderModel"),$2a.forEach(t),xMt=r(jZe," (Vision Encoder decoder model)"),jZe.forEach(t),y2a.forEach(t),$Mt=i(rd),T(vy.$$.fragment,rd),rd.forEach(t),od.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(Xba)),m(f,"id","auto-classes"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#auto-classes"),m(u,"class","relative group"),m(es,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),m(rs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),m(ts,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),m(dd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(Lf,"id","extending-the-auto-classes"),m(Lf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Lf,"href","#extending-the-auto-classes"),m(md,"class","relative group"),m(xf,"id","transformers.AutoConfig"),m(xf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xf,"href","#transformers.AutoConfig"),m(cd,"class","relative group"),m(sI,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m(lI,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),m(iI,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),m(dI,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),m(mI,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),m(cI,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),m(fI,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),m(gI,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(hI,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(uI,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),m(pI,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),m(_I,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),m(bI,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),m(vI,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),m(FI,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),m(TI,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),m(MI,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),m(EI,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),m(CI,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),m(wI,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),m(AI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),m(LI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),m(yI,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),m(xI,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),m($I,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),m(kI,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),m(SI,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),m(RI,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),m(PI,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),m(BI,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),m(II,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),m(NI,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),m(qI,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),m(jI,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),m(DI,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),m(GI,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),m(OI,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),m(VI,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),m(XI,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),m(zI,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),m(QI,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),m(WI,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),m(UI,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),m(HI,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),m(JI,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(YI,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),m(KI,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),m(ZI,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),m(eN,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),m(oN,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),m(rN,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),m(tN,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(aN,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(nN,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(sN,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),m(lN,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),m(iN,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),m(dN,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),m(mN,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),m(cN,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),m(fN,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),m(gN,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),m(hN,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),m(uN,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),m(pN,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),m(_N,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),m(bN,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),m(vN,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),m(FN,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(TN,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),m(MN,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),m(EN,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),m(CN,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),m(wN,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),m(AN,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),m(LN,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),m(yN,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),m(xN,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),m($N,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),m(kN,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),m(SN,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),m(RN,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),m(PN,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),m(BN,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(IN,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(NN,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),m(qN,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),m(jN,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),m(DN,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),m(GN,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),m(ON,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),m(VN,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),m(XN,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),m(zN,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),m(QN,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),m(WN,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),m(UN,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),m(HN,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),m(JN,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(YN,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(KN,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),m(ZN,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m(eq,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),m(oq,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),m(rq,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),m(tq,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),m(aq,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),m(nq,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),m(sq,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),m(lq,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),m(iq,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(dq,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),m(mq,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),m(cq,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),m(fq,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),m(gq,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),m(hq,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),m(uq,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(pq,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),m(_q,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),m(bq,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),m(vq,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(Fq,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),m(Tq,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),m(Mq,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),m(Eq,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),m(Cq,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),m(wq,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),m(Aq,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),m(Lq,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),m(yq,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),m(xq,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),m($q,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),m(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ou,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ru,"id","transformers.AutoTokenizer"),m(ru,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ru,"href","#transformers.AutoTokenizer"),m(gd,"class","relative group"),m(kq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(Sq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(Rq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(Pq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),m(Bq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),m(Iq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),m(Nq,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(qq,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(jq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(Dq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(Gq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),m(Oq,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),m(Vq,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(Xq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),m(zq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),m(Qq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(Wq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(Uq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(Hq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(Jq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),m(Yq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),m(Kq,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(Zq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),m(ej,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(oj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),m(rj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(tj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(aj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),m(nj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),m(sj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(lj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(ij,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),m(dj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),m(mj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),m(cj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(fj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(gj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),m(hj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(uj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),m(pj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),m(_j,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(bj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(vj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(Fj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(Tj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),m(Mj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(Ej,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(Cj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(wj,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(Aj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),m(Lj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(yj,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(xj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),m($j,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(kj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(Sj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(Rj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(Pj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(Bj,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),m(Ij,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),m(Nj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(qj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(jj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(Dj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(Gj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),m(Oj,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),m(Vj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(Xj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(zj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(Qj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(Wj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(Uj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m(Hj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(Jj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(Yj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(Kj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),m(Zj,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),m(eD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),m(oD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),m(rD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),m(tD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(aD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(nD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(sD,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),m(lD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),m(iD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(dD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(mD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),m(cD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),m(fD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(gD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(hD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(uD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(pD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(_D,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),m(bD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(vD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(FD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(TD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(MD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(ED,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(CD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),m(wD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),m(AD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(LD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(yD,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),m(xD,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),m($D,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(kD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(SD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),m(RD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),m(PD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(BD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(ID,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(ND,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(qD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(jD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(DD,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),m(GD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),m(OD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(VD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(XD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(zD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),m(QD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),m(WD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),m(UD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),m(HD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(JD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),m(YD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(KD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),m(ZD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m(eG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(oG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(rG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),m(tG,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(aG,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(nG,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(sG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),m(lG,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m(iG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(dG,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(mG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(cG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(fG,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),m(gG,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),m(hG,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),m(uG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(pG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(_G,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(bG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(vG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(FG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(TG,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),m(MG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(EG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(CG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),m(wG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),m(AG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),m(LG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),m(yG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(xG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m($G,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(kG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(SG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(RG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(PG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(BG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ju,"id","transformers.AutoFeatureExtractor"),m(ju,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ju,"href","#transformers.AutoFeatureExtractor"),m(hd,"class","relative group"),m(IG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(NG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(qG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(jG,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),m(DG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(GG,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(OG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(VG,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(XG,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),m(zG,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),m(QG,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(WG,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),m(UG,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),m(HG,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),m(JG,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),m(YG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(KG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(ZG,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),m(eO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),m(oO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),m(rO,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),m(tO,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),m(aO,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),m(nO,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),m(sO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),m(lO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),m(iO,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),m(dO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(mO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(cO,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),m(fO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(gO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(hO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(uO,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(pO,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),m(_O,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),m(bO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(vO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(FO,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(TO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(MO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(EO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(CO,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($p,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kp,"id","transformers.AutoProcessor"),m(kp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(kp,"href","#transformers.AutoProcessor"),m(ud,"class","relative group"),m(wO,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(AO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(LO,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),m(yO,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),m(xO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m($O,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(kO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),m(SO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),m(RO,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),m(PO,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),m(BO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(IO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(NO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(qO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m(jO,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),m(DO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(GO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(OO,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),m(VO,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),m(XO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(zO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(QO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(WO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(r_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(t_,"id","transformers.AutoModel"),m(t_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(t_,"href","#transformers.AutoModel"),m(_d,"class","relative group"),m(UO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(HO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(JO,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(YO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),m(KO,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),m(ZO,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),m(eV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(oV,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),m(rV,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),m(tV,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(aV,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),m(nV,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),m(sV,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),m(lV,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),m(iV,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),m(dV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),m(mV,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),m(cV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),m(fV,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),m(gV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),m(hV,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),m(uV,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),m(pV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),m(_V,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),m(bV,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),m(vV,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),m(FV,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),m(TV,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),m(MV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),m(EV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),m(CV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),m(wV,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),m(AV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),m(LV,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(yV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),m(xV,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),m($V,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),m(kV,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),m(SV,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),m(RV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),m(PV,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),m(BV,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),m(IV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),m(NV,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),m(qV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),m(jV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),m(DV,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(GV,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),m(OV,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),m(VV,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),m(XV,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),m(zV,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),m(QV,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),m(WV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(UV,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),m(HV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(JV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),m(YV,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),m(KV,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),m(ZV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),m(eX,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),m(oX,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),m(rX,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),m(tX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(aX,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),m(nX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),m(sX,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),m(lX,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),m(iX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),m(dX,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),m(mX,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),m(cX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),m(fX,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),m(gX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),m(hX,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),m(uX,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),m(pX,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(_X,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),m(bX,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),m(vX,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),m(FX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),m(TX,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),m(MX,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),m(EX,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),m(CX,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),m(wX,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),m(AX,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(LX,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),m(yX,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),m(xX,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),m($X,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),m(kX,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),m(SX,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(RX,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),m(PX,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),m(BX,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),m(IX,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),m(NX,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),m(qX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(jX,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),m(DX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(GX,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),m(OX,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),m(VX,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),m(XX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),m(zX,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),m(QX,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),m(WX,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),m(UX,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),m(HX,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),m(JX,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),m(YX,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),m(KX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),m(ZX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),m(ez,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),m(oz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),m(rz,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),m(tz,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),m(az,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(nz,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),m(sz,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),m(lz,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),m(iz,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),m(dz,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),m(mz,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),m(cz,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),m(fz,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),m(gz,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),m(hz,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),m(uz,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),m(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(C1,"id","transformers.AutoModelForPreTraining"),m(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(C1,"href","#transformers.AutoModelForPreTraining"),m(Fd,"class","relative group"),m(pz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_z,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(bz,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vz,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),m(Fz,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(Tz,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),m(Mz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),m(Ez,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(Cz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(wz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(Az,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(Lz,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(yz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(xz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m($z,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),m(kz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),m(Sz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(Rz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),m(Pz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),m(Bz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(Iz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(Nz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(qz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(jz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(Dz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(Gz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(Oz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(Vz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),m(Xz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(zz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(Qz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(Wz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),m(Uz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(Hz,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(Jz,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(Yz,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),m(Kz,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(Zz,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(eQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(oQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(rQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m(tQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),m(aQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),m(nQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(sQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),m(lQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(iQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),m(dQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(mQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(cQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(fQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mb,"id","transformers.AutoModelForCausalLM"),m(Mb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Mb,"href","#transformers.AutoModelForCausalLM"),m(Ed,"class","relative group"),m(gQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(uQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),m(_Q,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),m(bQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),m(vQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),m(FQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(TQ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(MQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),m(EQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(CQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(wQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),m(AQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(LQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),m(yQ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),m(xQ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),m($Q,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(kQ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(SQ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),m(RQ,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),m(PQ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(BQ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),m(IQ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),m(NQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),m(qQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),m(jQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(DQ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),m(GQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(OQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),m(VQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(XQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(zQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m(QQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(WQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),m(UQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(HQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m(JQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(YQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(KQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),m(ZQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(eW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),m(oW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),m(rW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),m(tW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hv,"id","transformers.AutoModelForMaskedLM"),m(hv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(hv,"href","#transformers.AutoModelForMaskedLM"),m(Ad,"class","relative group"),m(aW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(nW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(sW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(iW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(dW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),m(mW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),m(cW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(fW,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(gW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(hW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(uW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(pW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(_W,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(bW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),m(vW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(FW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(TW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(MW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(EW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(CW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(wW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(AW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(LW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),m(yW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(xW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m($W,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(kW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),m(SW,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),m(RW,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(PW,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(BW,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(IW,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(NW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(qW,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(jW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(DW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(GW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(OW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(VW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(XW,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),m(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tF,"id","transformers.AutoModelForSeq2SeqLM"),m(tF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(tF,"href","#transformers.AutoModelForSeq2SeqLM"),m(xd,"class","relative group"),m(zW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(QW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(WW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(UW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(HW,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(JW,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(YW,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),m(KW,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),m(ZW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(eU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(oU,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),m(rU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(tU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),m(aU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(nU,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(sU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(lU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(iU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(dU,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),m(mU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),m(cU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(fU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(gU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(LF,"id","transformers.AutoModelForSequenceClassification"),m(LF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(LF,"href","#transformers.AutoModelForSequenceClassification"),m(Sd,"class","relative group"),m(hU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(uU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_U,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(bU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),m(vU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),m(FU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),m(TU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(MU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),m(EU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(CU,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(wU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(AU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(LU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),m(yU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(xU,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),m($U,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m(kU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(SU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),m(RU,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),m(PU,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(BU,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(IU,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(NU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(qU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(jU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(DU,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m(GU,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(OU,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m(VU,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),m(XU,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),m(zU,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(QU,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),m(WU,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),m(UU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(HU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),m(JU,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m(YU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(KU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),m(ZU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),m(eH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),m(oH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),m(rH,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),m(tH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(aH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),m(nH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(sH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(lH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(iH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(dH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(mH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(cH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(fH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),m(gH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(hH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),m(uH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),m(pH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(_H,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),m(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ST,"id","transformers.AutoModelForMultipleChoice"),m(ST,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ST,"href","#transformers.AutoModelForMultipleChoice"),m(Bd,"class","relative group"),m(bH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(FH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(TH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(MH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),m(EH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),m(CH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(wH,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(AH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(LH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),m(yH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),m(xH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m($H,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(kH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),m(SH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(RH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(PH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(BH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(IH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(NH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),m(qH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),m(jH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m(DH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(GH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),m(OH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),m(VH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m(XH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(zH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(QH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(WH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(UH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(HH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),m(JH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),m(YH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(KH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),m(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hM,"id","transformers.AutoModelForNextSentencePrediction"),m(hM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(hM,"href","#transformers.AutoModelForNextSentencePrediction"),m(qd,"class","relative group"),m(ZH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(oJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(tJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),m(aJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(nJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),m(sJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(lJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),m(iJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wM,"id","transformers.AutoModelForTokenClassification"),m(wM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(wM,"href","#transformers.AutoModelForTokenClassification"),m(Gd,"class","relative group"),m(dJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(gJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),m(hJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),m(uJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),m(pJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(_J,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),m(bJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(vJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),m(FJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(TJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),m(MJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(EJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(CJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),m(wJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),m(AJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m(LJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(yJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(xJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m($J,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(kJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(SJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(RJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),m(PJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(BJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),m(IJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),m(NJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),m(qJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m(jJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(DJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),m(GJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),m(OJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m(VJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(XJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(zJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(QJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(WJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(UJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),m(HJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),m(JJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(YJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),m(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uE,"id","transformers.AutoModelForQuestionAnswering"),m(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(uE,"href","#transformers.AutoModelForQuestionAnswering"),m(Xd,"class","relative group"),m(KJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ZJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(eY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(rY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(tY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(aY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),m(nY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(sY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(lY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(iY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(dY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),m(mY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(cY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),m(fY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(gY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(hY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),m(uY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(pY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(_Y,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(bY,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(vY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(FY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(TY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(MY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(EY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(CY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),m(wY,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(AY,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),m(LY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(yY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),m(xY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m($Y,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(kY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),m(SY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),m(RY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),m(PY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(BY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m(IY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(NY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m(qY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(jY,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m(DY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(GY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(OY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),m(VY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),m(XY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(zY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),m(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(m4,"id","transformers.AutoModelForTableQuestionAnswering"),m(m4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(m4,"href","#transformers.AutoModelForTableQuestionAnswering"),m(Wd,"class","relative group"),m(QY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(WY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(UY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(HY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(u4,"id","transformers.AutoModelForDocumentQuestionAnswering"),m(u4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(u4,"href","#transformers.AutoModelForDocumentQuestionAnswering"),m(Jd,"class","relative group"),m(JY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(YY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(KY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ZY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),m(eK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(oK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(M4,"id","transformers.AutoModelForImageClassification"),m(M4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(M4,"href","#transformers.AutoModelForImageClassification"),m(em,"class","relative group"),m(rK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(tK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(aK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),m(sK,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),m(lK,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),m(iK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),m(dK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),m(mK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(cK,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(fK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),m(gK,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),m(hK,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),m(uK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(pK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(_K,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(bK,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),m(vK,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),m(FK,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),m(TK,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(MK,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),m(EK,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),m(CK,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),m(wK,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),m(AK,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),m(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G4,"id","transformers.AutoModelForVideoClassification"),m(G4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(G4,"href","#transformers.AutoModelForVideoClassification"),m(tm,"class","relative group"),m(LK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(xK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($K,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),m(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Q4,"id","transformers.AutoModelForVision2Seq"),m(Q4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Q4,"href","#transformers.AutoModelForVision2Seq"),m(sm,"class","relative group"),m(kK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(SK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(RK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(PK,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),m(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Y4,"id","transformers.AutoModelForVisualQuestionAnswering"),m(Y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Y4,"href","#transformers.AutoModelForVisualQuestionAnswering"),m(dm,"class","relative group"),m(BK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(IK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(NK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qK,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),m(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rC,"id","transformers.AutoModelForAudioClassification"),m(rC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(rC,"href","#transformers.AutoModelForAudioClassification"),m(fm,"class","relative group"),m(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(OK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),m(VK,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(XK,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(zK,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),m(QK,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m(WK,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),m(UK,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(HK,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),m(JK,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uC,"id","transformers.AutoModelForAudioFrameClassification"),m(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(uC,"href","#transformers.AutoModelForAudioFrameClassification"),m(um,"class","relative group"),m(YK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(KK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),m(oZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),m(rZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(tZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),m(aZ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(CC,"id","transformers.AutoModelForCTC"),m(CC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(CC,"href","#transformers.AutoModelForCTC"),m(bm,"class","relative group"),m(nZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(lZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(iZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),m(dZ,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),m(mZ,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),m(cZ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),m(fZ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),m(gZ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(hZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),m(uZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(pZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),m(_Z,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),m(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qC,"id","transformers.AutoModelForSpeechSeq2Seq"),m(qC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(qC,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(Tm,"class","relative group"),m(bZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(FZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(TZ,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),m(MZ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(XC,"id","transformers.AutoModelForAudioXVector"),m(XC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(XC,"href","#transformers.AutoModelForAudioXVector"),m(Cm,"class","relative group"),m(EZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(CZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(wZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),m(LZ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),m(yZ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(xZ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),m($Z,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),m(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ZC,"id","transformers.AutoModelForMaskedImageModeling"),m(ZC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ZC,"href","#transformers.AutoModelForMaskedImageModeling"),m(Lm,"class","relative group"),m(kZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(SZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(RZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(PZ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),m(BZ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),m(IZ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),m(NZ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),m(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(l3,"id","transformers.AutoModelForObjectDetection"),m(l3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(l3,"href","#transformers.AutoModelForObjectDetection"),m($m,"class","relative group"),m(qZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(DZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GZ,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),m(OZ,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),m(VZ,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),m(XZ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),m(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(u3,"id","transformers.AutoModelForImageSegmentation"),m(u3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(u3,"href","#transformers.AutoModelForImageSegmentation"),m(Rm,"class","relative group"),m(zZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(QZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(WZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(UZ,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),m(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F3,"id","transformers.AutoModelForSemanticSegmentation"),m(F3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(F3,"href","#transformers.AutoModelForSemanticSegmentation"),m(Im,"class","relative group"),m(HZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(JZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(YZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(KZ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),m(ZZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),m(eee,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),m(oee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),m(ree,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),m(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(x3,"id","transformers.AutoModelForInstanceSegmentation"),m(x3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x3,"href","#transformers.AutoModelForInstanceSegmentation"),m(jm,"class","relative group"),m(tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(see,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),m(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(P3,"id","transformers.TFAutoModel"),m(P3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P3,"href","#transformers.TFAutoModel"),m(Om,"class","relative group"),m(lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mee,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),m(cee,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),m(fee,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),m(gee,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(hee,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),m(uee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),m(pee,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),m(_ee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),m(bee,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),m(vee,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),m(Fee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),m(Tee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),m(Mee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),m(Eee,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),m(Cee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(wee,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(Aee,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),m(Lee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),m(yee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),m(xee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m($ee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),m(kee,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),m(See,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),m(Ree,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),m(Pee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(Bee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),m(Iee,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),m(Nee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),m(qee,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),m(jee,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),m(Dee,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),m(Gee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(Oee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),m(Vee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),m(Xee,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),m(zee,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),m(Qee,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),m(Wee,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),m(Uee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),m(Hee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),m(Jee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),m(Yee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),m(Kee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),m(Zee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),m(eoe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),m(ooe,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),m(roe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),m(toe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),m(aoe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),m(noe,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),m(soe,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),m(loe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(ioe,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),m(doe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),m(moe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),m(coe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),m(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N5,"id","transformers.TFAutoModelForPreTraining"),m(N5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N5,"href","#transformers.TFAutoModelForPreTraining"),m(zm,"class","relative group"),m(foe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uoe,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(poe,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(_oe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),m(boe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(voe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Foe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Toe,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(Moe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Eoe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(Coe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(woe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Aoe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m(Loe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(yoe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(xoe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m($oe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(koe,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Soe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Roe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Poe,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),m(Boe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Ioe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(Noe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(d0,"id","transformers.TFAutoModelForCausalLM"),m(d0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(d0,"href","#transformers.TFAutoModelForCausalLM"),m(Um,"class","relative group"),m(qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Goe,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(Ooe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),m(Voe,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Xoe,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(zoe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),m(Qoe,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Woe,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),m(Uoe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(Hoe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(Joe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(Yoe,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Koe,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),m(Zoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(ere,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(A0,"id","transformers.TFAutoModelForImageClassification"),m(A0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(A0,"href","#transformers.TFAutoModelForImageClassification"),m(Ym,"class","relative group"),m(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(are,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),m(nre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),m(sre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),m(lre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),m(ire,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),m(dre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),m(mre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),m(cre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),m(fre,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),m(gre,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),m(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N0,"id","transformers.TFAutoModelForSemanticSegmentation"),m(N0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N0,"href","#transformers.TFAutoModelForSemanticSegmentation"),m(ec,"class","relative group"),m(hre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ure,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_re,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),m(bre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),m(vre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),m(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(V0,"id","transformers.TFAutoModelForMaskedLM"),m(V0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(V0,"href","#transformers.TFAutoModelForMaskedLM"),m(ac,"class","relative group"),m(Fre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Mre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ere,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m(Cre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(wre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(Are,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(Lre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m(yre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),m(xre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m($re,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(kre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Sre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(Rre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Pre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(Bre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(Ire,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Nre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(qre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(jre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(Dre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Gre,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Ore,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fw,"id","transformers.TFAutoModelForSeq2SeqLM"),m(fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fw,"href","#transformers.TFAutoModelForSeq2SeqLM"),m(lc,"class","relative group"),m(Vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(Wre,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(Ure,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(Hre,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),m(Jre,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(Yre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),m(Kre,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(Zre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(ete,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(ote,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ww,"id","transformers.TFAutoModelForSequenceClassification"),m(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ww,"href","#transformers.TFAutoModelForSequenceClassification"),m(mc,"class","relative group"),m(rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(tte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(ste,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(lte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(ite,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(dte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(mte,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(cte,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),m(fte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(gte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(hte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(ute,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(pte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(_te,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),m(bte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(vte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),m(Fte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(Tte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(Mte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(Ete,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),m(Cte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(wte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m(Ate,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(Lte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m(yte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),m(xte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m($te,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),m(kte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oA,"id","transformers.TFAutoModelForMultipleChoice"),m(oA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(oA,"href","#transformers.TFAutoModelForMultipleChoice"),m(gc,"class","relative group"),m(Ste,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m(Ite,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(Nte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(qte,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(jte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(Dte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(Gte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(Ote,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(Vte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(Xte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(zte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(Qte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(Wte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(Ute,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(Hte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(Jte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),m(Yte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(TA,"id","transformers.TFAutoModelForNextSentencePrediction"),m(TA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(TA,"href","#transformers.TFAutoModelForNextSentencePrediction"),m(pc,"class","relative group"),m(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),m(rae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),m(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AA,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(AA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(AA,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(vc,"class","relative group"),m(tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($A,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),m($A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($A,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),m(Mc,"class","relative group"),m(lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),m(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(PA,"id","transformers.TFAutoModelForTokenClassification"),m(PA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(PA,"href","#transformers.TFAutoModelForTokenClassification"),m(wc,"class","relative group"),m(cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(gae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(uae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(pae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(_ae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(bae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(vae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),m(Fae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(Tae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(Mae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m(Eae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(Cae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m(wae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),m(Aae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m(Lae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(yae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(xae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m($ae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(kae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(Sae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(Rae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),m(Pae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(a6,"id","transformers.TFAutoModelForQuestionAnswering"),m(a6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(a6,"href","#transformers.TFAutoModelForQuestionAnswering"),m(yc,"class","relative group"),m(Bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(jae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(Dae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(Gae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(Oae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(Vae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),m(Xae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(zae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(Qae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(Wae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(Uae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),m(Hae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),m(Jae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(Yae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(Kae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(Zae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(ene,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(one,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m(rne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(tne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),m(ane,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y6,"id","transformers.TFAutoModelForVision2Seq"),m(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y6,"href","#transformers.TFAutoModelForVision2Seq"),m(kc,"class","relative group"),m(nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ine,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),m(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S6,"id","transformers.TFAutoModelForSpeechSeq2Seq"),m(S6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S6,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),m(Pc,"class","relative group"),m(dne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fne,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),m(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I6,"id","transformers.FlaxAutoModel"),m(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I6,"href","#transformers.FlaxAutoModel"),m(Nc,"class","relative group"),m(gne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pne,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),m(_ne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),m(bne,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),m(vne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),m(Fne,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),m(Tne,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m(Mne,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),m(Ene,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),m(Cne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(wne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),m(Ane,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(Lne,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(yne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(xne,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),m($ne,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),m(kne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),m(Sne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),m(Rne,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),m(Pne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(Bne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(Ine,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),m(Nne,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),m(qne,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),m(jne,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),m(Dne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(Gne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),m(One,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),m(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(f7,"id","transformers.FlaxAutoModelForCausalLM"),m(f7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f7,"href","#transformers.FlaxAutoModelForCausalLM"),m(Dc,"class","relative group"),m(Vne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qne,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),m(Wne,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),m(Une,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),m(Hne,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),m(Jne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(Yne,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(Kne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(Zne,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),m(ese,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),m(ose,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),m(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(w7,"id","transformers.FlaxAutoModelForPreTraining"),m(w7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w7,"href","#transformers.FlaxAutoModelForPreTraining"),m(Vc,"class","relative group"),m(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(sse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(lse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(ise,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),m(dse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(mse,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(cse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(fse,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(gse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(hse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(use,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(pse,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(_se,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G7,"id","transformers.FlaxAutoModelForMaskedLM"),m(G7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(G7,"href","#transformers.FlaxAutoModelForMaskedLM"),m(Qc,"class","relative group"),m(bse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m(Mse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Ese,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m(Cse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),m(wse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m(Ase,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(Lse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(yse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(xse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m($se,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(eL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(eL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(Hc,"class","relative group"),m(kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pse,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Bse,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(Ise,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(Nse,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),m(qse,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(jse,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(Dse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Gse,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(Ose,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m(Vse,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gL,"id","transformers.FlaxAutoModelForSequenceClassification"),m(gL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gL,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(Kc,"class","relative group"),m(Xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wse,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(Use,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(Hse,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(Jse,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),m(Yse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(Kse,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(Zse,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(ele,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(ole,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),m(rle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),m(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AL,"id","transformers.FlaxAutoModelForQuestionAnswering"),m(AL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(AL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(of,"class","relative group"),m(tle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(lle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(ile,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(dle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),m(mle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(cle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m(fle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(gle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(hle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),m(ule,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),m(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jL,"id","transformers.FlaxAutoModelForTokenClassification"),m(jL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(jL,"href","#transformers.FlaxAutoModelForTokenClassification"),m(af,"class","relative group"),m(ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ble,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(Fle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(Tle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),m(Mle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(Ele,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m(Cle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(wle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),m(Ale,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(JL,"id","transformers.FlaxAutoModelForMultipleChoice"),m(JL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(JL,"href","#transformers.FlaxAutoModelForMultipleChoice"),m(lf,"class","relative group"),m(Lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($le,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(kle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(Sle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),m(Rle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m(Ple,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(Ble,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(Ile,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),m(Nle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),m(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ly,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(ly,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ly,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(cf,"class","relative group"),m(qle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Gle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cy,"id","transformers.FlaxAutoModelForImageClassification"),m(cy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cy,"href","#transformers.FlaxAutoModelForImageClassification"),m(hf,"class","relative group"),m(Ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zle,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(Qle,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(py,"id","transformers.FlaxAutoModelForVision2Seq"),m(py,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(py,"href","#transformers.FlaxAutoModelForVision2Seq"),m(_f,"class","relative group"),m(Wle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ule,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),m(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,yo),e(yo,td),b(c,Ef,_),b(c,pt,_),e(pt,ad),e(pt,nd),e(nd,J9),e(pt,Cf),b(c,Ve,_),b(c,He,_),e(He,sd),e(He,es),e(es,Y9),e(He,os),e(He,rs),e(rs,K9),e(He,ld),e(He,ts),e(ts,Z9),e(He,id),b(c,wf,_),M(Qa,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,eI),e(Ae,dd),e(dd,oI),e(Ae,rI),b(c,xo,_),b(c,Wa,_),e(Wa,tI),e(Wa,Af),e(Af,aI),e(Wa,pao),b(c,DZe,_),b(c,md,_),e(md,Lf),e(Lf,eme),M(ex,eme,null),e(md,_ao),e(md,ome),e(ome,bao),b(c,GZe,_),b(c,as,_),e(as,vao),e(as,rme),e(rme,Fao),e(as,Tao),e(as,tme),e(tme,Mao),e(as,Eao),b(c,OZe,_),M(ox,c,_),b(c,VZe,_),b(c,nI,_),e(nI,Cao),b(c,XZe,_),M(yf,c,_),b(c,zZe,_),b(c,cd,_),e(cd,xf),e(xf,ame),M(rx,ame,null),e(cd,wao),e(cd,nme),e(nme,Aao),b(c,QZe,_),b(c,$o,_),M(tx,$o,null),e($o,Lao),e($o,ax),e(ax,yao),e(ax,sI),e(sI,xao),e(ax,$ao),e($o,kao),e($o,nx),e(nx,Sao),e(nx,sme),e(sme,Rao),e(nx,Pao),e($o,Bao),e($o,Pr),M(sx,Pr,null),e(Pr,Iao),e(Pr,lme),e(lme,Nao),e(Pr,qao),e(Pr,fd),e(fd,jao),e(fd,ime),e(ime,Dao),e(fd,Gao),e(fd,dme),e(dme,Oao),e(fd,Vao),e(Pr,Xao),e(Pr,A),e(A,$f),e($f,mme),e(mme,zao),e($f,Qao),e($f,lI),e(lI,Wao),e($f,Uao),e(A,Hao),e(A,kf),e(kf,cme),e(cme,Jao),e(kf,Yao),e(kf,iI),e(iI,Kao),e(kf,Zao),e(A,eno),e(A,Sf),e(Sf,fme),e(fme,ono),e(Sf,rno),e(Sf,dI),e(dI,tno),e(Sf,ano),e(A,nno),e(A,Rf),e(Rf,gme),e(gme,sno),e(Rf,lno),e(Rf,mI),e(mI,ino),e(Rf,dno),e(A,mno),e(A,Pf),e(Pf,hme),e(hme,cno),e(Pf,fno),e(Pf,cI),e(cI,gno),e(Pf,hno),e(A,uno),e(A,Bf),e(Bf,ume),e(ume,pno),e(Bf,_no),e(Bf,fI),e(fI,bno),e(Bf,vno),e(A,Fno),e(A,If),e(If,pme),e(pme,Tno),e(If,Mno),e(If,gI),e(gI,Eno),e(If,Cno),e(A,wno),e(A,Nf),e(Nf,_me),e(_me,Ano),e(Nf,Lno),e(Nf,hI),e(hI,yno),e(Nf,xno),e(A,$no),e(A,qf),e(qf,bme),e(bme,kno),e(qf,Sno),e(qf,uI),e(uI,Rno),e(qf,Pno),e(A,Bno),e(A,jf),e(jf,vme),e(vme,Ino),e(jf,Nno),e(jf,pI),e(pI,qno),e(jf,jno),e(A,Dno),e(A,Df),e(Df,Fme),e(Fme,Gno),e(Df,Ono),e(Df,_I),e(_I,Vno),e(Df,Xno),e(A,zno),e(A,Gf),e(Gf,Tme),e(Tme,Qno),e(Gf,Wno),e(Gf,bI),e(bI,Uno),e(Gf,Hno),e(A,Jno),e(A,Of),e(Of,Mme),e(Mme,Yno),e(Of,Kno),e(Of,vI),e(vI,Zno),e(Of,eso),e(A,oso),e(A,Vf),e(Vf,Eme),e(Eme,rso),e(Vf,tso),e(Vf,FI),e(FI,aso),e(Vf,nso),e(A,sso),e(A,Xf),e(Xf,Cme),e(Cme,lso),e(Xf,iso),e(Xf,TI),e(TI,dso),e(Xf,mso),e(A,cso),e(A,zf),e(zf,wme),e(wme,fso),e(zf,gso),e(zf,MI),e(MI,hso),e(zf,uso),e(A,pso),e(A,Qf),e(Qf,Ame),e(Ame,_so),e(Qf,bso),e(Qf,EI),e(EI,vso),e(Qf,Fso),e(A,Tso),e(A,Wf),e(Wf,Lme),e(Lme,Mso),e(Wf,Eso),e(Wf,CI),e(CI,Cso),e(Wf,wso),e(A,Aso),e(A,Uf),e(Uf,yme),e(yme,Lso),e(Uf,yso),e(Uf,wI),e(wI,xso),e(Uf,$so),e(A,kso),e(A,Hf),e(Hf,xme),e(xme,Sso),e(Hf,Rso),e(Hf,AI),e(AI,Pso),e(Hf,Bso),e(A,Iso),e(A,Jf),e(Jf,$me),e($me,Nso),e(Jf,qso),e(Jf,LI),e(LI,jso),e(Jf,Dso),e(A,Gso),e(A,Yf),e(Yf,kme),e(kme,Oso),e(Yf,Vso),e(Yf,yI),e(yI,Xso),e(Yf,zso),e(A,Qso),e(A,Kf),e(Kf,Sme),e(Sme,Wso),e(Kf,Uso),e(Kf,xI),e(xI,Hso),e(Kf,Jso),e(A,Yso),e(A,Zf),e(Zf,Rme),e(Rme,Kso),e(Zf,Zso),e(Zf,$I),e($I,elo),e(Zf,olo),e(A,rlo),e(A,eg),e(eg,Pme),e(Pme,tlo),e(eg,alo),e(eg,kI),e(kI,nlo),e(eg,slo),e(A,llo),e(A,og),e(og,Bme),e(Bme,ilo),e(og,dlo),e(og,SI),e(SI,mlo),e(og,clo),e(A,flo),e(A,rg),e(rg,Ime),e(Ime,glo),e(rg,hlo),e(rg,RI),e(RI,ulo),e(rg,plo),e(A,_lo),e(A,tg),e(tg,Nme),e(Nme,blo),e(tg,vlo),e(tg,PI),e(PI,Flo),e(tg,Tlo),e(A,Mlo),e(A,ag),e(ag,qme),e(qme,Elo),e(ag,Clo),e(ag,BI),e(BI,wlo),e(ag,Alo),e(A,Llo),e(A,ng),e(ng,jme),e(jme,ylo),e(ng,xlo),e(ng,II),e(II,$lo),e(ng,klo),e(A,Slo),e(A,sg),e(sg,Dme),e(Dme,Rlo),e(sg,Plo),e(sg,NI),e(NI,Blo),e(sg,Ilo),e(A,Nlo),e(A,lg),e(lg,Gme),e(Gme,qlo),e(lg,jlo),e(lg,qI),e(qI,Dlo),e(lg,Glo),e(A,Olo),e(A,ig),e(ig,Ome),e(Ome,Vlo),e(ig,Xlo),e(ig,jI),e(jI,zlo),e(ig,Qlo),e(A,Wlo),e(A,dg),e(dg,Vme),e(Vme,Ulo),e(dg,Hlo),e(dg,DI),e(DI,Jlo),e(dg,Ylo),e(A,Klo),e(A,mg),e(mg,Xme),e(Xme,Zlo),e(mg,eio),e(mg,GI),e(GI,oio),e(mg,rio),e(A,tio),e(A,cg),e(cg,zme),e(zme,aio),e(cg,nio),e(cg,OI),e(OI,sio),e(cg,lio),e(A,iio),e(A,fg),e(fg,Qme),e(Qme,dio),e(fg,mio),e(fg,VI),e(VI,cio),e(fg,fio),e(A,gio),e(A,gg),e(gg,Wme),e(Wme,hio),e(gg,uio),e(gg,XI),e(XI,pio),e(gg,_io),e(A,bio),e(A,hg),e(hg,Ume),e(Ume,vio),e(hg,Fio),e(hg,zI),e(zI,Tio),e(hg,Mio),e(A,Eio),e(A,ug),e(ug,Hme),e(Hme,Cio),e(ug,wio),e(ug,QI),e(QI,Aio),e(ug,Lio),e(A,yio),e(A,pg),e(pg,Jme),e(Jme,xio),e(pg,$io),e(pg,WI),e(WI,kio),e(pg,Sio),e(A,Rio),e(A,_g),e(_g,Yme),e(Yme,Pio),e(_g,Bio),e(_g,UI),e(UI,Iio),e(_g,Nio),e(A,qio),e(A,bg),e(bg,Kme),e(Kme,jio),e(bg,Dio),e(bg,HI),e(HI,Gio),e(bg,Oio),e(A,Vio),e(A,vg),e(vg,Zme),e(Zme,Xio),e(vg,zio),e(vg,JI),e(JI,Qio),e(vg,Wio),e(A,Uio),e(A,Fg),e(Fg,ece),e(ece,Hio),e(Fg,Jio),e(Fg,YI),e(YI,Yio),e(Fg,Kio),e(A,Zio),e(A,Tg),e(Tg,oce),e(oce,edo),e(Tg,odo),e(Tg,KI),e(KI,rdo),e(Tg,tdo),e(A,ado),e(A,Mg),e(Mg,rce),e(rce,ndo),e(Mg,sdo),e(Mg,ZI),e(ZI,ldo),e(Mg,ido),e(A,ddo),e(A,Eg),e(Eg,tce),e(tce,mdo),e(Eg,cdo),e(Eg,eN),e(eN,fdo),e(Eg,gdo),e(A,hdo),e(A,Cg),e(Cg,ace),e(ace,udo),e(Cg,pdo),e(Cg,oN),e(oN,_do),e(Cg,bdo),e(A,vdo),e(A,wg),e(wg,nce),e(nce,Fdo),e(wg,Tdo),e(wg,rN),e(rN,Mdo),e(wg,Edo),e(A,Cdo),e(A,Ag),e(Ag,sce),e(sce,wdo),e(Ag,Ado),e(Ag,tN),e(tN,Ldo),e(Ag,ydo),e(A,xdo),e(A,Lg),e(Lg,lce),e(lce,$do),e(Lg,kdo),e(Lg,aN),e(aN,Sdo),e(Lg,Rdo),e(A,Pdo),e(A,yg),e(yg,ice),e(ice,Bdo),e(yg,Ido),e(yg,nN),e(nN,Ndo),e(yg,qdo),e(A,jdo),e(A,xg),e(xg,dce),e(dce,Ddo),e(xg,Gdo),e(xg,sN),e(sN,Odo),e(xg,Vdo),e(A,Xdo),e(A,$g),e($g,mce),e(mce,zdo),e($g,Qdo),e($g,lN),e(lN,Wdo),e($g,Udo),e(A,Hdo),e(A,kg),e(kg,cce),e(cce,Jdo),e(kg,Ydo),e(kg,iN),e(iN,Kdo),e(kg,Zdo),e(A,emo),e(A,Sg),e(Sg,fce),e(fce,omo),e(Sg,rmo),e(Sg,dN),e(dN,tmo),e(Sg,amo),e(A,nmo),e(A,Rg),e(Rg,gce),e(gce,smo),e(Rg,lmo),e(Rg,mN),e(mN,imo),e(Rg,dmo),e(A,mmo),e(A,Pg),e(Pg,hce),e(hce,cmo),e(Pg,fmo),e(Pg,cN),e(cN,gmo),e(Pg,hmo),e(A,umo),e(A,Bg),e(Bg,uce),e(uce,pmo),e(Bg,_mo),e(Bg,fN),e(fN,bmo),e(Bg,vmo),e(A,Fmo),e(A,Ig),e(Ig,pce),e(pce,Tmo),e(Ig,Mmo),e(Ig,gN),e(gN,Emo),e(Ig,Cmo),e(A,wmo),e(A,Ng),e(Ng,_ce),e(_ce,Amo),e(Ng,Lmo),e(Ng,hN),e(hN,ymo),e(Ng,xmo),e(A,$mo),e(A,qg),e(qg,bce),e(bce,kmo),e(qg,Smo),e(qg,uN),e(uN,Rmo),e(qg,Pmo),e(A,Bmo),e(A,jg),e(jg,vce),e(vce,Imo),e(jg,Nmo),e(jg,pN),e(pN,qmo),e(jg,jmo),e(A,Dmo),e(A,Dg),e(Dg,Fce),e(Fce,Gmo),e(Dg,Omo),e(Dg,_N),e(_N,Vmo),e(Dg,Xmo),e(A,zmo),e(A,Gg),e(Gg,Tce),e(Tce,Qmo),e(Gg,Wmo),e(Gg,bN),e(bN,Umo),e(Gg,Hmo),e(A,Jmo),e(A,Og),e(Og,Mce),e(Mce,Ymo),e(Og,Kmo),e(Og,vN),e(vN,Zmo),e(Og,eco),e(A,oco),e(A,Vg),e(Vg,Ece),e(Ece,rco),e(Vg,tco),e(Vg,FN),e(FN,aco),e(Vg,nco),e(A,sco),e(A,Xg),e(Xg,Cce),e(Cce,lco),e(Xg,ico),e(Xg,TN),e(TN,dco),e(Xg,mco),e(A,cco),e(A,zg),e(zg,wce),e(wce,fco),e(zg,gco),e(zg,MN),e(MN,hco),e(zg,uco),e(A,pco),e(A,Qg),e(Qg,Ace),e(Ace,_co),e(Qg,bco),e(Qg,EN),e(EN,vco),e(Qg,Fco),e(A,Tco),e(A,Wg),e(Wg,Lce),e(Lce,Mco),e(Wg,Eco),e(Wg,CN),e(CN,Cco),e(Wg,wco),e(A,Aco),e(A,Ug),e(Ug,yce),e(yce,Lco),e(Ug,yco),e(Ug,wN),e(wN,xco),e(Ug,$co),e(A,kco),e(A,Hg),e(Hg,xce),e(xce,Sco),e(Hg,Rco),e(Hg,AN),e(AN,Pco),e(Hg,Bco),e(A,Ico),e(A,Jg),e(Jg,$ce),e($ce,Nco),e(Jg,qco),e(Jg,LN),e(LN,jco),e(Jg,Dco),e(A,Gco),e(A,Yg),e(Yg,kce),e(kce,Oco),e(Yg,Vco),e(Yg,yN),e(yN,Xco),e(Yg,zco),e(A,Qco),e(A,Kg),e(Kg,Sce),e(Sce,Wco),e(Kg,Uco),e(Kg,xN),e(xN,Hco),e(Kg,Jco),e(A,Yco),e(A,Zg),e(Zg,Rce),e(Rce,Kco),e(Zg,Zco),e(Zg,$N),e($N,efo),e(Zg,ofo),e(A,rfo),e(A,eh),e(eh,Pce),e(Pce,tfo),e(eh,afo),e(eh,kN),e(kN,nfo),e(eh,sfo),e(A,lfo),e(A,oh),e(oh,Bce),e(Bce,ifo),e(oh,dfo),e(oh,SN),e(SN,mfo),e(oh,cfo),e(A,ffo),e(A,rh),e(rh,Ice),e(Ice,gfo),e(rh,hfo),e(rh,RN),e(RN,ufo),e(rh,pfo),e(A,_fo),e(A,th),e(th,Nce),e(Nce,bfo),e(th,vfo),e(th,PN),e(PN,Ffo),e(th,Tfo),e(A,Mfo),e(A,ah),e(ah,qce),e(qce,Efo),e(ah,Cfo),e(ah,BN),e(BN,wfo),e(ah,Afo),e(A,Lfo),e(A,nh),e(nh,jce),e(jce,yfo),e(nh,xfo),e(nh,IN),e(IN,$fo),e(nh,kfo),e(A,Sfo),e(A,sh),e(sh,Dce),e(Dce,Rfo),e(sh,Pfo),e(sh,NN),e(NN,Bfo),e(sh,Ifo),e(A,Nfo),e(A,lh),e(lh,Gce),e(Gce,qfo),e(lh,jfo),e(lh,qN),e(qN,Dfo),e(lh,Gfo),e(A,Ofo),e(A,ih),e(ih,Oce),e(Oce,Vfo),e(ih,Xfo),e(ih,jN),e(jN,zfo),e(ih,Qfo),e(A,Wfo),e(A,dh),e(dh,Vce),e(Vce,Ufo),e(dh,Hfo),e(dh,DN),e(DN,Jfo),e(dh,Yfo),e(A,Kfo),e(A,mh),e(mh,Xce),e(Xce,Zfo),e(mh,ego),e(mh,GN),e(GN,ogo),e(mh,rgo),e(A,tgo),e(A,ch),e(ch,zce),e(zce,ago),e(ch,ngo),e(ch,ON),e(ON,sgo),e(ch,lgo),e(A,igo),e(A,fh),e(fh,Qce),e(Qce,dgo),e(fh,mgo),e(fh,VN),e(VN,cgo),e(fh,fgo),e(A,ggo),e(A,gh),e(gh,Wce),e(Wce,hgo),e(gh,ugo),e(gh,XN),e(XN,pgo),e(gh,_go),e(A,bgo),e(A,hh),e(hh,Uce),e(Uce,vgo),e(hh,Fgo),e(hh,zN),e(zN,Tgo),e(hh,Mgo),e(A,Ego),e(A,uh),e(uh,Hce),e(Hce,Cgo),e(uh,wgo),e(uh,QN),e(QN,Ago),e(uh,Lgo),e(A,ygo),e(A,ph),e(ph,Jce),e(Jce,xgo),e(ph,$go),e(ph,WN),e(WN,kgo),e(ph,Sgo),e(A,Rgo),e(A,_h),e(_h,Yce),e(Yce,Pgo),e(_h,Bgo),e(_h,UN),e(UN,Igo),e(_h,Ngo),e(A,qgo),e(A,bh),e(bh,Kce),e(Kce,jgo),e(bh,Dgo),e(bh,HN),e(HN,Ggo),e(bh,Ogo),e(A,Vgo),e(A,vh),e(vh,Zce),e(Zce,Xgo),e(vh,zgo),e(vh,JN),e(JN,Qgo),e(vh,Wgo),e(A,Ugo),e(A,Fh),e(Fh,efe),e(efe,Hgo),e(Fh,Jgo),e(Fh,YN),e(YN,Ygo),e(Fh,Kgo),e(A,Zgo),e(A,Th),e(Th,ofe),e(ofe,eho),e(Th,oho),e(Th,KN),e(KN,rho),e(Th,tho),e(A,aho),e(A,Mh),e(Mh,rfe),e(rfe,nho),e(Mh,sho),e(Mh,ZN),e(ZN,lho),e(Mh,iho),e(A,dho),e(A,Eh),e(Eh,tfe),e(tfe,mho),e(Eh,cho),e(Eh,eq),e(eq,fho),e(Eh,gho),e(A,hho),e(A,Ch),e(Ch,afe),e(afe,uho),e(Ch,pho),e(Ch,oq),e(oq,_ho),e(Ch,bho),e(A,vho),e(A,wh),e(wh,nfe),e(nfe,Fho),e(wh,Tho),e(wh,rq),e(rq,Mho),e(wh,Eho),e(A,Cho),e(A,Ah),e(Ah,sfe),e(sfe,who),e(Ah,Aho),e(Ah,tq),e(tq,Lho),e(Ah,yho),e(A,xho),e(A,Lh),e(Lh,lfe),e(lfe,$ho),e(Lh,kho),e(Lh,aq),e(aq,Sho),e(Lh,Rho),e(A,Pho),e(A,yh),e(yh,ife),e(ife,Bho),e(yh,Iho),e(yh,nq),e(nq,Nho),e(yh,qho),e(A,jho),e(A,xh),e(xh,dfe),e(dfe,Dho),e(xh,Gho),e(xh,sq),e(sq,Oho),e(xh,Vho),e(A,Xho),e(A,$h),e($h,mfe),e(mfe,zho),e($h,Qho),e($h,lq),e(lq,Who),e($h,Uho),e(A,Hho),e(A,kh),e(kh,cfe),e(cfe,Jho),e(kh,Yho),e(kh,iq),e(iq,Kho),e(kh,Zho),e(A,euo),e(A,Sh),e(Sh,ffe),e(ffe,ouo),e(Sh,ruo),e(Sh,dq),e(dq,tuo),e(Sh,auo),e(A,nuo),e(A,Rh),e(Rh,gfe),e(gfe,suo),e(Rh,luo),e(Rh,mq),e(mq,iuo),e(Rh,duo),e(A,muo),e(A,Ph),e(Ph,hfe),e(hfe,cuo),e(Ph,fuo),e(Ph,cq),e(cq,guo),e(Ph,huo),e(A,uuo),e(A,Bh),e(Bh,ufe),e(ufe,puo),e(Bh,_uo),e(Bh,fq),e(fq,buo),e(Bh,vuo),e(A,Fuo),e(A,Ih),e(Ih,pfe),e(pfe,Tuo),e(Ih,Muo),e(Ih,gq),e(gq,Euo),e(Ih,Cuo),e(A,wuo),e(A,Nh),e(Nh,_fe),e(_fe,Auo),e(Nh,Luo),e(Nh,hq),e(hq,yuo),e(Nh,xuo),e(A,$uo),e(A,qh),e(qh,bfe),e(bfe,kuo),e(qh,Suo),e(qh,uq),e(uq,Ruo),e(qh,Puo),e(A,Buo),e(A,jh),e(jh,vfe),e(vfe,Iuo),e(jh,Nuo),e(jh,pq),e(pq,quo),e(jh,juo),e(A,Duo),e(A,Dh),e(Dh,Ffe),e(Ffe,Guo),e(Dh,Ouo),e(Dh,_q),e(_q,Vuo),e(Dh,Xuo),e(A,zuo),e(A,Gh),e(Gh,Tfe),e(Tfe,Quo),e(Gh,Wuo),e(Gh,bq),e(bq,Uuo),e(Gh,Huo),e(A,Juo),e(A,Oh),e(Oh,Mfe),e(Mfe,Yuo),e(Oh,Kuo),e(Oh,vq),e(vq,Zuo),e(Oh,epo),e(A,opo),e(A,Vh),e(Vh,Efe),e(Efe,rpo),e(Vh,tpo),e(Vh,Fq),e(Fq,apo),e(Vh,npo),e(A,spo),e(A,Xh),e(Xh,Cfe),e(Cfe,lpo),e(Xh,ipo),e(Xh,Tq),e(Tq,dpo),e(Xh,mpo),e(A,cpo),e(A,zh),e(zh,wfe),e(wfe,fpo),e(zh,gpo),e(zh,Mq),e(Mq,hpo),e(zh,upo),e(A,ppo),e(A,Qh),e(Qh,Afe),e(Afe,_po),e(Qh,bpo),e(Qh,Eq),e(Eq,vpo),e(Qh,Fpo),e(A,Tpo),e(A,Wh),e(Wh,Lfe),e(Lfe,Mpo),e(Wh,Epo),e(Wh,Cq),e(Cq,Cpo),e(Wh,wpo),e(A,Apo),e(A,Uh),e(Uh,yfe),e(yfe,Lpo),e(Uh,ypo),e(Uh,wq),e(wq,xpo),e(Uh,$po),e(A,kpo),e(A,Hh),e(Hh,xfe),e(xfe,Spo),e(Hh,Rpo),e(Hh,Aq),e(Aq,Ppo),e(Hh,Bpo),e(A,Ipo),e(A,Jh),e(Jh,$fe),e($fe,Npo),e(Jh,qpo),e(Jh,Lq),e(Lq,jpo),e(Jh,Dpo),e(A,Gpo),e(A,Yh),e(Yh,kfe),e(kfe,Opo),e(Yh,Vpo),e(Yh,yq),e(yq,Xpo),e(Yh,zpo),e(A,Qpo),e(A,Kh),e(Kh,Sfe),e(Sfe,Wpo),e(Kh,Upo),e(Kh,xq),e(xq,Hpo),e(Kh,Jpo),e(A,Ypo),e(A,Zh),e(Zh,Rfe),e(Rfe,Kpo),e(Zh,Zpo),e(Zh,$q),e($q,e_o),e(Zh,o_o),e(Pr,r_o),M(eu,Pr,null),e($o,t_o),e($o,ou),M(lx,ou,null),e(ou,a_o),e(ou,Pfe),e(Pfe,n_o),b(c,WZe,_),b(c,gd,_),e(gd,ru),e(ru,Bfe),M(ix,Bfe,null),e(gd,s_o),e(gd,Ife),e(Ife,l_o),b(c,UZe,_),b(c,ko,_),M(dx,ko,null),e(ko,i_o),e(ko,mx),e(mx,d_o),e(mx,kq),e(kq,m_o),e(mx,c_o),e(ko,f_o),e(ko,cx),e(cx,g_o),e(cx,Nfe),e(Nfe,h_o),e(cx,u_o),e(ko,p_o),e(ko,Br),M(fx,Br,null),e(Br,__o),e(Br,qfe),e(qfe,b_o),e(Br,v_o),e(Br,Ua),e(Ua,F_o),e(Ua,jfe),e(jfe,T_o),e(Ua,M_o),e(Ua,Dfe),e(Dfe,E_o),e(Ua,C_o),e(Ua,Gfe),e(Gfe,w_o),e(Ua,A_o),e(Br,L_o),e(Br,k),e(k,ns),e(ns,Ofe),e(Ofe,y_o),e(ns,x_o),e(ns,Sq),e(Sq,$_o),e(ns,k_o),e(ns,Rq),e(Rq,S_o),e(ns,R_o),e(k,P_o),e(k,ss),e(ss,Vfe),e(Vfe,B_o),e(ss,I_o),e(ss,Pq),e(Pq,N_o),e(ss,q_o),e(ss,Bq),e(Bq,j_o),e(ss,D_o),e(k,G_o),e(k,ls),e(ls,Xfe),e(Xfe,O_o),e(ls,V_o),e(ls,Iq),e(Iq,X_o),e(ls,z_o),e(ls,Nq),e(Nq,Q_o),e(ls,W_o),e(k,U_o),e(k,tu),e(tu,zfe),e(zfe,H_o),e(tu,J_o),e(tu,qq),e(qq,Y_o),e(tu,K_o),e(k,Z_o),e(k,is),e(is,Qfe),e(Qfe,e2o),e(is,o2o),e(is,jq),e(jq,r2o),e(is,t2o),e(is,Dq),e(Dq,a2o),e(is,n2o),e(k,s2o),e(k,au),e(au,Wfe),e(Wfe,l2o),e(au,i2o),e(au,Gq),e(Gq,d2o),e(au,m2o),e(k,c2o),e(k,nu),e(nu,Ufe),e(Ufe,f2o),e(nu,g2o),e(nu,Oq),e(Oq,h2o),e(nu,u2o),e(k,p2o),e(k,su),e(su,Hfe),e(Hfe,_2o),e(su,b2o),e(su,Vq),e(Vq,v2o),e(su,F2o),e(k,T2o),e(k,ds),e(ds,Jfe),e(Jfe,M2o),e(ds,E2o),e(ds,Xq),e(Xq,C2o),e(ds,w2o),e(ds,zq),e(zq,A2o),e(ds,L2o),e(k,y2o),e(k,ms),e(ms,Yfe),e(Yfe,x2o),e(ms,$2o),e(ms,Qq),e(Qq,k2o),e(ms,S2o),e(ms,Wq),e(Wq,R2o),e(ms,P2o),e(k,B2o),e(k,cs),e(cs,Kfe),e(Kfe,I2o),e(cs,N2o),e(cs,Uq),e(Uq,q2o),e(cs,j2o),e(cs,Hq),e(Hq,D2o),e(cs,G2o),e(k,O2o),e(k,lu),e(lu,Zfe),e(Zfe,V2o),e(lu,X2o),e(lu,Jq),e(Jq,z2o),e(lu,Q2o),e(k,W2o),e(k,iu),e(iu,ege),e(ege,U2o),e(iu,H2o),e(iu,Yq),e(Yq,J2o),e(iu,Y2o),e(k,K2o),e(k,du),e(du,oge),e(oge,Z2o),e(du,e1o),e(du,Kq),e(Kq,o1o),e(du,r1o),e(k,t1o),e(k,fs),e(fs,rge),e(rge,a1o),e(fs,n1o),e(fs,Zq),e(Zq,s1o),e(fs,l1o),e(fs,ej),e(ej,i1o),e(fs,d1o),e(k,m1o),e(k,mu),e(mu,tge),e(tge,c1o),e(mu,f1o),e(mu,oj),e(oj,g1o),e(mu,h1o),e(k,u1o),e(k,gs),e(gs,age),e(age,p1o),e(gs,_1o),e(gs,rj),e(rj,b1o),e(gs,v1o),e(gs,tj),e(tj,F1o),e(gs,T1o),e(k,M1o),e(k,hs),e(hs,nge),e(nge,E1o),e(hs,C1o),e(hs,aj),e(aj,w1o),e(hs,A1o),e(hs,nj),e(nj,L1o),e(hs,y1o),e(k,x1o),e(k,us),e(us,sge),e(sge,$1o),e(us,k1o),e(us,sj),e(sj,S1o),e(us,R1o),e(us,lj),e(lj,P1o),e(us,B1o),e(k,I1o),e(k,ps),e(ps,lge),e(lge,N1o),e(ps,q1o),e(ps,ij),e(ij,j1o),e(ps,D1o),e(ps,dj),e(dj,G1o),e(ps,O1o),e(k,V1o),e(k,cu),e(cu,ige),e(ige,X1o),e(cu,z1o),e(cu,mj),e(mj,Q1o),e(cu,W1o),e(k,U1o),e(k,_s),e(_s,dge),e(dge,H1o),e(_s,J1o),e(_s,cj),e(cj,Y1o),e(_s,K1o),e(_s,fj),e(fj,Z1o),e(_s,ebo),e(k,obo),e(k,bs),e(bs,mge),e(mge,rbo),e(bs,tbo),e(bs,gj),e(gj,abo),e(bs,nbo),e(bs,hj),e(hj,sbo),e(bs,lbo),e(k,ibo),e(k,vs),e(vs,cge),e(cge,dbo),e(vs,mbo),e(vs,uj),e(uj,cbo),e(vs,fbo),e(vs,pj),e(pj,gbo),e(vs,hbo),e(k,ubo),e(k,Fs),e(Fs,fge),e(fge,pbo),e(Fs,_bo),e(Fs,_j),e(_j,bbo),e(Fs,vbo),e(Fs,bj),e(bj,Fbo),e(Fs,Tbo),e(k,Mbo),e(k,Ts),e(Ts,gge),e(gge,Ebo),e(Ts,Cbo),e(Ts,vj),e(vj,wbo),e(Ts,Abo),e(Ts,Fj),e(Fj,Lbo),e(Ts,ybo),e(k,xbo),e(k,Ms),e(Ms,hge),e(hge,$bo),e(Ms,kbo),e(Ms,Tj),e(Tj,Sbo),e(Ms,Rbo),e(Ms,Mj),e(Mj,Pbo),e(Ms,Bbo),e(k,Ibo),e(k,Es),e(Es,uge),e(uge,Nbo),e(Es,qbo),e(Es,Ej),e(Ej,jbo),e(Es,Dbo),e(Es,Cj),e(Cj,Gbo),e(Es,Obo),e(k,Vbo),e(k,fu),e(fu,pge),e(pge,Xbo),e(fu,zbo),e(fu,wj),e(wj,Qbo),e(fu,Wbo),e(k,Ubo),e(k,Cs),e(Cs,_ge),e(_ge,Hbo),e(Cs,Jbo),e(Cs,Aj),e(Aj,Ybo),e(Cs,Kbo),e(Cs,Lj),e(Lj,Zbo),e(Cs,evo),e(k,ovo),e(k,gu),e(gu,bge),e(bge,rvo),e(gu,tvo),e(gu,yj),e(yj,avo),e(gu,nvo),e(k,svo),e(k,ws),e(ws,vge),e(vge,lvo),e(ws,ivo),e(ws,xj),e(xj,dvo),e(ws,mvo),e(ws,$j),e($j,cvo),e(ws,fvo),e(k,gvo),e(k,As),e(As,Fge),e(Fge,hvo),e(As,uvo),e(As,kj),e(kj,pvo),e(As,_vo),e(As,Sj),e(Sj,bvo),e(As,vvo),e(k,Fvo),e(k,Ls),e(Ls,Tge),e(Tge,Tvo),e(Ls,Mvo),e(Ls,Rj),e(Rj,Evo),e(Ls,Cvo),e(Ls,Pj),e(Pj,wvo),e(Ls,Avo),e(k,Lvo),e(k,hu),e(hu,Mge),e(Mge,yvo),e(hu,xvo),e(hu,Bj),e(Bj,$vo),e(hu,kvo),e(k,Svo),e(k,uu),e(uu,Ege),e(Ege,Rvo),e(uu,Pvo),e(uu,Ij),e(Ij,Bvo),e(uu,Ivo),e(k,Nvo),e(k,ys),e(ys,Cge),e(Cge,qvo),e(ys,jvo),e(ys,Nj),e(Nj,Dvo),e(ys,Gvo),e(ys,qj),e(qj,Ovo),e(ys,Vvo),e(k,Xvo),e(k,xs),e(xs,wge),e(wge,zvo),e(xs,Qvo),e(xs,jj),e(jj,Wvo),e(xs,Uvo),e(xs,Dj),e(Dj,Hvo),e(xs,Jvo),e(k,Yvo),e(k,$s),e($s,Age),e(Age,Kvo),e($s,Zvo),e($s,Gj),e(Gj,eFo),e($s,oFo),e($s,Oj),e(Oj,rFo),e($s,tFo),e(k,aFo),e(k,pu),e(pu,Lge),e(Lge,nFo),e(pu,sFo),e(pu,Vj),e(Vj,lFo),e(pu,iFo),e(k,dFo),e(k,ks),e(ks,yge),e(yge,mFo),e(ks,cFo),e(ks,Xj),e(Xj,fFo),e(ks,gFo),e(ks,zj),e(zj,hFo),e(ks,uFo),e(k,pFo),e(k,Ss),e(Ss,xge),e(xge,_Fo),e(Ss,bFo),e(Ss,Qj),e(Qj,vFo),e(Ss,FFo),e(Ss,Wj),e(Wj,TFo),e(Ss,MFo),e(k,EFo),e(k,Rs),e(Rs,$ge),e($ge,CFo),e(Rs,wFo),e(Rs,Uj),e(Uj,AFo),e(Rs,LFo),e(Rs,Hj),e(Hj,yFo),e(Rs,xFo),e(k,$Fo),e(k,Ps),e(Ps,kge),e(kge,kFo),e(Ps,SFo),e(Ps,Jj),e(Jj,RFo),e(Ps,PFo),e(Ps,Yj),e(Yj,BFo),e(Ps,IFo),e(k,NFo),e(k,Bs),e(Bs,Sge),e(Sge,qFo),e(Bs,jFo),e(Bs,Kj),e(Kj,DFo),e(Bs,GFo),e(Bs,Zj),e(Zj,OFo),e(Bs,VFo),e(k,XFo),e(k,Is),e(Is,Rge),e(Rge,zFo),e(Is,QFo),e(Is,eD),e(eD,WFo),e(Is,UFo),e(Is,oD),e(oD,HFo),e(Is,JFo),e(k,YFo),e(k,Ns),e(Ns,Pge),e(Pge,KFo),e(Ns,ZFo),e(Ns,rD),e(rD,eTo),e(Ns,oTo),e(Ns,tD),e(tD,rTo),e(Ns,tTo),e(k,aTo),e(k,qs),e(qs,Bge),e(Bge,nTo),e(qs,sTo),e(qs,aD),e(aD,lTo),e(qs,iTo),e(qs,nD),e(nD,dTo),e(qs,mTo),e(k,cTo),e(k,_u),e(_u,Ige),e(Ige,fTo),e(_u,gTo),e(_u,sD),e(sD,hTo),e(_u,uTo),e(k,pTo),e(k,js),e(js,Nge),e(Nge,_To),e(js,bTo),e(js,lD),e(lD,vTo),e(js,FTo),e(js,iD),e(iD,TTo),e(js,MTo),e(k,ETo),e(k,bu),e(bu,qge),e(qge,CTo),e(bu,wTo),e(bu,dD),e(dD,ATo),e(bu,LTo),e(k,yTo),e(k,vu),e(vu,jge),e(jge,xTo),e(vu,$To),e(vu,mD),e(mD,kTo),e(vu,STo),e(k,RTo),e(k,Ds),e(Ds,Dge),e(Dge,PTo),e(Ds,BTo),e(Ds,cD),e(cD,ITo),e(Ds,NTo),e(Ds,fD),e(fD,qTo),e(Ds,jTo),e(k,DTo),e(k,Gs),e(Gs,Gge),e(Gge,GTo),e(Gs,OTo),e(Gs,gD),e(gD,VTo),e(Gs,XTo),e(Gs,hD),e(hD,zTo),e(Gs,QTo),e(k,WTo),e(k,Os),e(Os,Oge),e(Oge,UTo),e(Os,HTo),e(Os,uD),e(uD,JTo),e(Os,YTo),e(Os,pD),e(pD,KTo),e(Os,ZTo),e(k,eMo),e(k,Fu),e(Fu,Vge),e(Vge,oMo),e(Fu,rMo),e(Fu,_D),e(_D,tMo),e(Fu,aMo),e(k,nMo),e(k,Vs),e(Vs,Xge),e(Xge,sMo),e(Vs,lMo),e(Vs,bD),e(bD,iMo),e(Vs,dMo),e(Vs,vD),e(vD,mMo),e(Vs,cMo),e(k,fMo),e(k,Xs),e(Xs,zge),e(zge,gMo),e(Xs,hMo),e(Xs,FD),e(FD,uMo),e(Xs,pMo),e(Xs,TD),e(TD,_Mo),e(Xs,bMo),e(k,vMo),e(k,zs),e(zs,Qge),e(Qge,FMo),e(zs,TMo),e(zs,MD),e(MD,MMo),e(zs,EMo),e(zs,ED),e(ED,CMo),e(zs,wMo),e(k,AMo),e(k,Qs),e(Qs,Wge),e(Wge,LMo),e(Qs,yMo),e(Qs,CD),e(CD,xMo),e(Qs,$Mo),e(Qs,wD),e(wD,kMo),e(Qs,SMo),e(k,RMo),e(k,Ws),e(Ws,Uge),e(Uge,PMo),e(Ws,BMo),e(Ws,AD),e(AD,IMo),e(Ws,NMo),e(Ws,LD),e(LD,qMo),e(Ws,jMo),e(k,DMo),e(k,Us),e(Us,Hge),e(Hge,GMo),e(Us,OMo),e(Us,yD),e(yD,VMo),e(Us,XMo),e(Us,xD),e(xD,zMo),e(Us,QMo),e(k,WMo),e(k,Hs),e(Hs,Jge),e(Jge,UMo),e(Hs,HMo),e(Hs,$D),e($D,JMo),e(Hs,YMo),e(Hs,kD),e(kD,KMo),e(Hs,ZMo),e(k,eEo),e(k,Js),e(Js,Yge),e(Yge,oEo),e(Js,rEo),e(Js,SD),e(SD,tEo),e(Js,aEo),e(Js,RD),e(RD,nEo),e(Js,sEo),e(k,lEo),e(k,Tu),e(Tu,Kge),e(Kge,iEo),e(Tu,dEo),e(Tu,PD),e(PD,mEo),e(Tu,cEo),e(k,fEo),e(k,Ys),e(Ys,Zge),e(Zge,gEo),e(Ys,hEo),e(Ys,BD),e(BD,uEo),e(Ys,pEo),e(Ys,ID),e(ID,_Eo),e(Ys,bEo),e(k,vEo),e(k,Ks),e(Ks,ehe),e(ehe,FEo),e(Ks,TEo),e(Ks,ND),e(ND,MEo),e(Ks,EEo),e(Ks,qD),e(qD,CEo),e(Ks,wEo),e(k,AEo),e(k,Mu),e(Mu,ohe),e(ohe,LEo),e(Mu,yEo),e(Mu,jD),e(jD,xEo),e(Mu,$Eo),e(k,kEo),e(k,Eu),e(Eu,rhe),e(rhe,SEo),e(Eu,REo),e(Eu,DD),e(DD,PEo),e(Eu,BEo),e(k,IEo),e(k,Cu),e(Cu,the),e(the,NEo),e(Cu,qEo),e(Cu,GD),e(GD,jEo),e(Cu,DEo),e(k,GEo),e(k,wu),e(wu,ahe),e(ahe,OEo),e(wu,VEo),e(wu,OD),e(OD,XEo),e(wu,zEo),e(k,QEo),e(k,Zs),e(Zs,nhe),e(nhe,WEo),e(Zs,UEo),e(Zs,VD),e(VD,HEo),e(Zs,JEo),e(Zs,XD),e(XD,YEo),e(Zs,KEo),e(k,ZEo),e(k,Au),e(Au,she),e(she,e4o),e(Au,o4o),e(Au,zD),e(zD,r4o),e(Au,t4o),e(k,a4o),e(k,el),e(el,lhe),e(lhe,n4o),e(el,s4o),e(el,QD),e(QD,l4o),e(el,i4o),e(el,WD),e(WD,d4o),e(el,m4o),e(k,c4o),e(k,ol),e(ol,ihe),e(ihe,f4o),e(ol,g4o),e(ol,UD),e(UD,h4o),e(ol,u4o),e(ol,HD),e(HD,p4o),e(ol,_4o),e(k,b4o),e(k,rl),e(rl,dhe),e(dhe,v4o),e(rl,F4o),e(rl,JD),e(JD,T4o),e(rl,M4o),e(rl,YD),e(YD,E4o),e(rl,C4o),e(k,w4o),e(k,tl),e(tl,mhe),e(mhe,A4o),e(tl,L4o),e(tl,KD),e(KD,y4o),e(tl,x4o),e(tl,ZD),e(ZD,$4o),e(tl,k4o),e(k,S4o),e(k,al),e(al,che),e(che,R4o),e(al,P4o),e(al,eG),e(eG,B4o),e(al,I4o),e(al,oG),e(oG,N4o),e(al,q4o),e(k,j4o),e(k,nl),e(nl,fhe),e(fhe,D4o),e(nl,G4o),e(nl,rG),e(rG,O4o),e(nl,V4o),e(nl,tG),e(tG,X4o),e(nl,z4o),e(k,Q4o),e(k,Lu),e(Lu,ghe),e(ghe,W4o),e(Lu,U4o),e(Lu,aG),e(aG,H4o),e(Lu,J4o),e(k,Y4o),e(k,yu),e(yu,hhe),e(hhe,K4o),e(yu,Z4o),e(yu,nG),e(nG,eCo),e(yu,oCo),e(k,rCo),e(k,sl),e(sl,uhe),e(uhe,tCo),e(sl,aCo),e(sl,sG),e(sG,nCo),e(sl,sCo),e(sl,lG),e(lG,lCo),e(sl,iCo),e(k,dCo),e(k,ll),e(ll,phe),e(phe,mCo),e(ll,cCo),e(ll,iG),e(iG,fCo),e(ll,gCo),e(ll,dG),e(dG,hCo),e(ll,uCo),e(k,pCo),e(k,il),e(il,_he),e(_he,_Co),e(il,bCo),e(il,mG),e(mG,vCo),e(il,FCo),e(il,cG),e(cG,TCo),e(il,MCo),e(k,ECo),e(k,xu),e(xu,bhe),e(bhe,CCo),e(xu,wCo),e(xu,fG),e(fG,ACo),e(xu,LCo),e(k,yCo),e(k,$u),e($u,vhe),e(vhe,xCo),e($u,$Co),e($u,gG),e(gG,kCo),e($u,SCo),e(k,RCo),e(k,ku),e(ku,Fhe),e(Fhe,PCo),e(ku,BCo),e(ku,hG),e(hG,ICo),e(ku,NCo),e(k,qCo),e(k,dl),e(dl,The),e(The,jCo),e(dl,DCo),e(dl,uG),e(uG,GCo),e(dl,OCo),e(dl,pG),e(pG,VCo),e(dl,XCo),e(k,zCo),e(k,ml),e(ml,Mhe),e(Mhe,QCo),e(ml,WCo),e(ml,_G),e(_G,UCo),e(ml,HCo),e(ml,bG),e(bG,JCo),e(ml,YCo),e(k,KCo),e(k,Su),e(Su,Ehe),e(Ehe,ZCo),e(Su,e3o),e(Su,vG),e(vG,o3o),e(Su,r3o),e(k,t3o),e(k,Ru),e(Ru,Che),e(Che,a3o),e(Ru,n3o),e(Ru,FG),e(FG,s3o),e(Ru,l3o),e(k,i3o),e(k,Pu),e(Pu,whe),e(whe,d3o),e(Pu,m3o),e(Pu,TG),e(TG,c3o),e(Pu,f3o),e(k,g3o),e(k,cl),e(cl,Ahe),e(Ahe,h3o),e(cl,u3o),e(cl,MG),e(MG,p3o),e(cl,_3o),e(cl,EG),e(EG,b3o),e(cl,v3o),e(k,F3o),e(k,fl),e(fl,Lhe),e(Lhe,T3o),e(fl,M3o),e(fl,CG),e(CG,E3o),e(fl,C3o),e(fl,wG),e(wG,w3o),e(fl,A3o),e(k,L3o),e(k,Bu),e(Bu,yhe),e(yhe,y3o),e(Bu,x3o),e(Bu,AG),e(AG,$3o),e(Bu,k3o),e(k,S3o),e(k,Iu),e(Iu,xhe),e(xhe,R3o),e(Iu,P3o),e(Iu,LG),e(LG,B3o),e(Iu,I3o),e(k,N3o),e(k,gl),e(gl,$he),e($he,q3o),e(gl,j3o),e(gl,yG),e(yG,D3o),e(gl,G3o),e(gl,xG),e(xG,O3o),e(gl,V3o),e(k,X3o),e(k,hl),e(hl,khe),e(khe,z3o),e(hl,Q3o),e(hl,$G),e($G,W3o),e(hl,U3o),e(hl,kG),e(kG,H3o),e(hl,J3o),e(k,Y3o),e(k,ul),e(ul,She),e(She,K3o),e(ul,Z3o),e(ul,SG),e(SG,e5o),e(ul,o5o),e(ul,RG),e(RG,r5o),e(ul,t5o),e(k,a5o),e(k,pl),e(pl,Rhe),e(Rhe,n5o),e(pl,s5o),e(pl,PG),e(PG,l5o),e(pl,i5o),e(pl,BG),e(BG,d5o),e(pl,m5o),e(Br,c5o),M(Nu,Br,null),e(ko,f5o),e(ko,qu),M(gx,qu,null),e(qu,g5o),e(qu,Phe),e(Phe,h5o),b(c,HZe,_),b(c,hd,_),e(hd,ju),e(ju,Bhe),M(hx,Bhe,null),e(hd,u5o),e(hd,Ihe),e(Ihe,p5o),b(c,JZe,_),b(c,So,_),M(ux,So,null),e(So,_5o),e(So,px),e(px,b5o),e(px,IG),e(IG,v5o),e(px,F5o),e(So,T5o),e(So,_x),e(_x,M5o),e(_x,Nhe),e(Nhe,E5o),e(_x,C5o),e(So,w5o),e(So,Ye),M(bx,Ye,null),e(Ye,A5o),e(Ye,qhe),e(qhe,L5o),e(Ye,y5o),e(Ye,Ha),e(Ha,x5o),e(Ha,jhe),e(jhe,$5o),e(Ha,k5o),e(Ha,Dhe),e(Dhe,S5o),e(Ha,R5o),e(Ha,Ghe),e(Ghe,P5o),e(Ha,B5o),e(Ye,I5o),e(Ye,z),e(z,Du),e(Du,Ohe),e(Ohe,N5o),e(Du,q5o),e(Du,NG),e(NG,j5o),e(Du,D5o),e(z,G5o),e(z,Gu),e(Gu,Vhe),e(Vhe,O5o),e(Gu,V5o),e(Gu,qG),e(qG,X5o),e(Gu,z5o),e(z,Q5o),e(z,Ou),e(Ou,Xhe),e(Xhe,W5o),e(Ou,U5o),e(Ou,jG),e(jG,H5o),e(Ou,J5o),e(z,Y5o),e(z,Vu),e(Vu,zhe),e(zhe,K5o),e(Vu,Z5o),e(Vu,DG),e(DG,e0o),e(Vu,o0o),e(z,r0o),e(z,Xu),e(Xu,Qhe),e(Qhe,t0o),e(Xu,a0o),e(Xu,GG),e(GG,n0o),e(Xu,s0o),e(z,l0o),e(z,zu),e(zu,Whe),e(Whe,i0o),e(zu,d0o),e(zu,OG),e(OG,m0o),e(zu,c0o),e(z,f0o),e(z,Qu),e(Qu,Uhe),e(Uhe,g0o),e(Qu,h0o),e(Qu,VG),e(VG,u0o),e(Qu,p0o),e(z,_0o),e(z,Wu),e(Wu,Hhe),e(Hhe,b0o),e(Wu,v0o),e(Wu,XG),e(XG,F0o),e(Wu,T0o),e(z,M0o),e(z,Uu),e(Uu,Jhe),e(Jhe,E0o),e(Uu,C0o),e(Uu,zG),e(zG,w0o),e(Uu,A0o),e(z,L0o),e(z,Hu),e(Hu,Yhe),e(Yhe,y0o),e(Hu,x0o),e(Hu,QG),e(QG,$0o),e(Hu,k0o),e(z,S0o),e(z,Ju),e(Ju,Khe),e(Khe,R0o),e(Ju,P0o),e(Ju,WG),e(WG,B0o),e(Ju,I0o),e(z,N0o),e(z,Yu),e(Yu,Zhe),e(Zhe,q0o),e(Yu,j0o),e(Yu,UG),e(UG,D0o),e(Yu,G0o),e(z,O0o),e(z,Ku),e(Ku,eue),e(eue,V0o),e(Ku,X0o),e(Ku,HG),e(HG,z0o),e(Ku,Q0o),e(z,W0o),e(z,Zu),e(Zu,oue),e(oue,U0o),e(Zu,H0o),e(Zu,JG),e(JG,J0o),e(Zu,Y0o),e(z,K0o),e(z,ep),e(ep,rue),e(rue,Z0o),e(ep,ewo),e(ep,YG),e(YG,owo),e(ep,rwo),e(z,two),e(z,op),e(op,tue),e(tue,awo),e(op,nwo),e(op,KG),e(KG,swo),e(op,lwo),e(z,iwo),e(z,rp),e(rp,aue),e(aue,dwo),e(rp,mwo),e(rp,ZG),e(ZG,cwo),e(rp,fwo),e(z,gwo),e(z,tp),e(tp,nue),e(nue,hwo),e(tp,uwo),e(tp,eO),e(eO,pwo),e(tp,_wo),e(z,bwo),e(z,ap),e(ap,sue),e(sue,vwo),e(ap,Fwo),e(ap,oO),e(oO,Two),e(ap,Mwo),e(z,Ewo),e(z,np),e(np,lue),e(lue,Cwo),e(np,wwo),e(np,rO),e(rO,Awo),e(np,Lwo),e(z,ywo),e(z,sp),e(sp,iue),e(iue,xwo),e(sp,$wo),e(sp,tO),e(tO,kwo),e(sp,Swo),e(z,Rwo),e(z,lp),e(lp,due),e(due,Pwo),e(lp,Bwo),e(lp,aO),e(aO,Iwo),e(lp,Nwo),e(z,qwo),e(z,ip),e(ip,mue),e(mue,jwo),e(ip,Dwo),e(ip,nO),e(nO,Gwo),e(ip,Owo),e(z,Vwo),e(z,dp),e(dp,cue),e(cue,Xwo),e(dp,zwo),e(dp,sO),e(sO,Qwo),e(dp,Wwo),e(z,Uwo),e(z,mp),e(mp,fue),e(fue,Hwo),e(mp,Jwo),e(mp,lO),e(lO,Ywo),e(mp,Kwo),e(z,Zwo),e(z,cp),e(cp,gue),e(gue,eAo),e(cp,oAo),e(cp,iO),e(iO,rAo),e(cp,tAo),e(z,aAo),e(z,fp),e(fp,hue),e(hue,nAo),e(fp,sAo),e(fp,dO),e(dO,lAo),e(fp,iAo),e(z,dAo),e(z,gp),e(gp,uue),e(uue,mAo),e(gp,cAo),e(gp,mO),e(mO,fAo),e(gp,gAo),e(z,hAo),e(z,hp),e(hp,pue),e(pue,uAo),e(hp,pAo),e(hp,cO),e(cO,_Ao),e(hp,bAo),e(z,vAo),e(z,up),e(up,_ue),e(_ue,FAo),e(up,TAo),e(up,fO),e(fO,MAo),e(up,EAo),e(z,CAo),e(z,pp),e(pp,bue),e(bue,wAo),e(pp,AAo),e(pp,gO),e(gO,LAo),e(pp,yAo),e(z,xAo),e(z,_p),e(_p,vue),e(vue,$Ao),e(_p,kAo),e(_p,hO),e(hO,SAo),e(_p,RAo),e(z,PAo),e(z,bp),e(bp,Fue),e(Fue,BAo),e(bp,IAo),e(bp,uO),e(uO,NAo),e(bp,qAo),e(z,jAo),e(z,vp),e(vp,Tue),e(Tue,DAo),e(vp,GAo),e(vp,pO),e(pO,OAo),e(vp,VAo),e(z,XAo),e(z,Fp),e(Fp,Mue),e(Mue,zAo),e(Fp,QAo),e(Fp,_O),e(_O,WAo),e(Fp,UAo),e(z,HAo),e(z,Tp),e(Tp,Eue),e(Eue,JAo),e(Tp,YAo),e(Tp,bO),e(bO,KAo),e(Tp,ZAo),e(z,e6o),e(z,Mp),e(Mp,Cue),e(Cue,o6o),e(Mp,r6o),e(Mp,vO),e(vO,t6o),e(Mp,a6o),e(z,n6o),e(z,Ep),e(Ep,wue),e(wue,s6o),e(Ep,l6o),e(Ep,FO),e(FO,i6o),e(Ep,d6o),e(z,m6o),e(z,Cp),e(Cp,Aue),e(Aue,c6o),e(Cp,f6o),e(Cp,TO),e(TO,g6o),e(Cp,h6o),e(z,u6o),e(z,wp),e(wp,Lue),e(Lue,p6o),e(wp,_6o),e(wp,MO),e(MO,b6o),e(wp,v6o),e(z,F6o),e(z,Ap),e(Ap,yue),e(yue,T6o),e(Ap,M6o),e(Ap,EO),e(EO,E6o),e(Ap,C6o),e(z,w6o),e(z,Lp),e(Lp,xue),e(xue,A6o),e(Lp,L6o),e(Lp,CO),e(CO,y6o),e(Lp,x6o),e(Ye,$6o),M(yp,Ye,null),e(Ye,k6o),M(xp,Ye,null),e(So,S6o),e(So,$p),M(vx,$p,null),e($p,R6o),e($p,$ue),e($ue,P6o),b(c,YZe,_),b(c,ud,_),e(ud,kp),e(kp,kue),M(Fx,kue,null),e(ud,B6o),e(ud,Sue),e(Sue,I6o),b(c,KZe,_),b(c,Ro,_),M(Tx,Ro,null),e(Ro,N6o),e(Ro,Mx),e(Mx,q6o),e(Mx,wO),e(wO,j6o),e(Mx,D6o),e(Ro,G6o),e(Ro,Ex),e(Ex,O6o),e(Ex,Rue),e(Rue,V6o),e(Ex,X6o),e(Ro,z6o),e(Ro,Ke),M(Cx,Ke,null),e(Ke,Q6o),e(Ke,Pue),e(Pue,W6o),e(Ke,U6o),e(Ke,pd),e(pd,H6o),e(pd,Bue),e(Bue,J6o),e(pd,Y6o),e(pd,Iue),e(Iue,K6o),e(pd,Z6o),e(Ke,e7o),e(Ke,le),e(le,Sp),e(Sp,Nue),e(Nue,o7o),e(Sp,r7o),e(Sp,AO),e(AO,t7o),e(Sp,a7o),e(le,n7o),e(le,Rp),e(Rp,que),e(que,s7o),e(Rp,l7o),e(Rp,LO),e(LO,i7o),e(Rp,d7o),e(le,m7o),e(le,Pp),e(Pp,jue),e(jue,c7o),e(Pp,f7o),e(Pp,yO),e(yO,g7o),e(Pp,h7o),e(le,u7o),e(le,Bp),e(Bp,Due),e(Due,p7o),e(Bp,_7o),e(Bp,xO),e(xO,b7o),e(Bp,v7o),e(le,F7o),e(le,Ip),e(Ip,Gue),e(Gue,T7o),e(Ip,M7o),e(Ip,$O),e($O,E7o),e(Ip,C7o),e(le,w7o),e(le,Np),e(Np,Oue),e(Oue,A7o),e(Np,L7o),e(Np,kO),e(kO,y7o),e(Np,x7o),e(le,$7o),e(le,qp),e(qp,Vue),e(Vue,k7o),e(qp,S7o),e(qp,SO),e(SO,R7o),e(qp,P7o),e(le,B7o),e(le,jp),e(jp,Xue),e(Xue,I7o),e(jp,N7o),e(jp,RO),e(RO,q7o),e(jp,j7o),e(le,D7o),e(le,Dp),e(Dp,zue),e(zue,G7o),e(Dp,O7o),e(Dp,PO),e(PO,V7o),e(Dp,X7o),e(le,z7o),e(le,Gp),e(Gp,Que),e(Que,Q7o),e(Gp,W7o),e(Gp,BO),e(BO,U7o),e(Gp,H7o),e(le,J7o),e(le,Op),e(Op,Wue),e(Wue,Y7o),e(Op,K7o),e(Op,IO),e(IO,Z7o),e(Op,eLo),e(le,oLo),e(le,Vp),e(Vp,Uue),e(Uue,rLo),e(Vp,tLo),e(Vp,NO),e(NO,aLo),e(Vp,nLo),e(le,sLo),e(le,Xp),e(Xp,Hue),e(Hue,lLo),e(Xp,iLo),e(Xp,qO),e(qO,dLo),e(Xp,mLo),e(le,cLo),e(le,zp),e(zp,Jue),e(Jue,fLo),e(zp,gLo),e(zp,jO),e(jO,hLo),e(zp,uLo),e(le,pLo),e(le,Qp),e(Qp,Yue),e(Yue,_Lo),e(Qp,bLo),e(Qp,DO),e(DO,vLo),e(Qp,FLo),e(le,TLo),e(le,Wp),e(Wp,Kue),e(Kue,MLo),e(Wp,ELo),e(Wp,GO),e(GO,CLo),e(Wp,wLo),e(le,ALo),e(le,Up),e(Up,Zue),e(Zue,LLo),e(Up,yLo),e(Up,OO),e(OO,xLo),e(Up,$Lo),e(le,kLo),e(le,Hp),e(Hp,epe),e(epe,SLo),e(Hp,RLo),e(Hp,VO),e(VO,PLo),e(Hp,BLo),e(le,ILo),e(le,Jp),e(Jp,ope),e(ope,NLo),e(Jp,qLo),e(Jp,XO),e(XO,jLo),e(Jp,DLo),e(le,GLo),e(le,Yp),e(Yp,rpe),e(rpe,OLo),e(Yp,VLo),e(Yp,zO),e(zO,XLo),e(Yp,zLo),e(le,QLo),e(le,Kp),e(Kp,tpe),e(tpe,WLo),e(Kp,ULo),e(Kp,QO),e(QO,HLo),e(Kp,JLo),e(le,YLo),e(le,Zp),e(Zp,ape),e(ape,KLo),e(Zp,ZLo),e(Zp,WO),e(WO,eyo),e(Zp,oyo),e(Ke,ryo),M(e_,Ke,null),e(Ke,tyo),M(o_,Ke,null),e(Ro,ayo),e(Ro,r_),M(wx,r_,null),e(r_,nyo),e(r_,npe),e(npe,syo),b(c,ZZe,_),b(c,_d,_),e(_d,t_),e(t_,spe),M(Ax,spe,null),e(_d,lyo),e(_d,lpe),e(lpe,iyo),b(c,eeo,_),b(c,Po,_),M(Lx,Po,null),e(Po,dyo),e(Po,bd),e(bd,myo),e(bd,UO),e(UO,cyo),e(bd,fyo),e(bd,HO),e(HO,gyo),e(bd,hyo),e(Po,uyo),e(Po,yx),e(yx,pyo),e(yx,ipe),e(ipe,_yo),e(yx,byo),e(Po,vyo),e(Po,_t),M(xx,_t,null),e(_t,Fyo),e(_t,dpe),e(dpe,Tyo),e(_t,Myo),e(_t,vd),e(vd,Eyo),e(vd,mpe),e(mpe,Cyo),e(vd,wyo),e(vd,JO),e(JO,Ayo),e(vd,Lyo),e(_t,yyo),M(a_,_t,null),e(Po,xyo),e(Po,Ze),M($x,Ze,null),e(Ze,$yo),e(Ze,cpe),e(cpe,kyo),e(Ze,Syo),e(Ze,Ja),e(Ja,Ryo),e(Ja,fpe),e(fpe,Pyo),e(Ja,Byo),e(Ja,gpe),e(gpe,Iyo),e(Ja,Nyo),e(Ja,hpe),e(hpe,qyo),e(Ja,jyo),e(Ze,Dyo),e(Ze,y),e(y,n_),e(n_,upe),e(upe,Gyo),e(n_,Oyo),e(n_,YO),e(YO,Vyo),e(n_,Xyo),e(y,zyo),e(y,s_),e(s_,ppe),e(ppe,Qyo),e(s_,Wyo),e(s_,KO),e(KO,Uyo),e(s_,Hyo),e(y,Jyo),e(y,l_),e(l_,_pe),e(_pe,Yyo),e(l_,Kyo),e(l_,ZO),e(ZO,Zyo),e(l_,e8o),e(y,o8o),e(y,i_),e(i_,bpe),e(bpe,r8o),e(i_,t8o),e(i_,eV),e(eV,a8o),e(i_,n8o),e(y,s8o),e(y,d_),e(d_,vpe),e(vpe,l8o),e(d_,i8o),e(d_,oV),e(oV,d8o),e(d_,m8o),e(y,c8o),e(y,m_),e(m_,Fpe),e(Fpe,f8o),e(m_,g8o),e(m_,rV),e(rV,h8o),e(m_,u8o),e(y,p8o),e(y,c_),e(c_,Tpe),e(Tpe,_8o),e(c_,b8o),e(c_,tV),e(tV,v8o),e(c_,F8o),e(y,T8o),e(y,f_),e(f_,Mpe),e(Mpe,M8o),e(f_,E8o),e(f_,aV),e(aV,C8o),e(f_,w8o),e(y,A8o),e(y,g_),e(g_,Epe),e(Epe,L8o),e(g_,y8o),e(g_,nV),e(nV,x8o),e(g_,$8o),e(y,k8o),e(y,h_),e(h_,Cpe),e(Cpe,S8o),e(h_,R8o),e(h_,sV),e(sV,P8o),e(h_,B8o),e(y,I8o),e(y,u_),e(u_,wpe),e(wpe,N8o),e(u_,q8o),e(u_,lV),e(lV,j8o),e(u_,D8o),e(y,G8o),e(y,p_),e(p_,Ape),e(Ape,O8o),e(p_,V8o),e(p_,iV),e(iV,X8o),e(p_,z8o),e(y,Q8o),e(y,__),e(__,Lpe),e(Lpe,W8o),e(__,U8o),e(__,dV),e(dV,H8o),e(__,J8o),e(y,Y8o),e(y,b_),e(b_,ype),e(ype,K8o),e(b_,Z8o),e(b_,mV),e(mV,e9o),e(b_,o9o),e(y,r9o),e(y,v_),e(v_,xpe),e(xpe,t9o),e(v_,a9o),e(v_,cV),e(cV,n9o),e(v_,s9o),e(y,l9o),e(y,F_),e(F_,$pe),e($pe,i9o),e(F_,d9o),e(F_,fV),e(fV,m9o),e(F_,c9o),e(y,f9o),e(y,T_),e(T_,kpe),e(kpe,g9o),e(T_,h9o),e(T_,gV),e(gV,u9o),e(T_,p9o),e(y,_9o),e(y,M_),e(M_,Spe),e(Spe,b9o),e(M_,v9o),e(M_,hV),e(hV,F9o),e(M_,T9o),e(y,M9o),e(y,E_),e(E_,Rpe),e(Rpe,E9o),e(E_,C9o),e(E_,uV),e(uV,w9o),e(E_,A9o),e(y,L9o),e(y,C_),e(C_,Ppe),e(Ppe,y9o),e(C_,x9o),e(C_,pV),e(pV,$9o),e(C_,k9o),e(y,S9o),e(y,w_),e(w_,Bpe),e(Bpe,R9o),e(w_,P9o),e(w_,_V),e(_V,B9o),e(w_,I9o),e(y,N9o),e(y,A_),e(A_,Ipe),e(Ipe,q9o),e(A_,j9o),e(A_,bV),e(bV,D9o),e(A_,G9o),e(y,O9o),e(y,L_),e(L_,Npe),e(Npe,V9o),e(L_,X9o),e(L_,vV),e(vV,z9o),e(L_,Q9o),e(y,W9o),e(y,y_),e(y_,qpe),e(qpe,U9o),e(y_,H9o),e(y_,FV),e(FV,J9o),e(y_,Y9o),e(y,K9o),e(y,x_),e(x_,jpe),e(jpe,Z9o),e(x_,exo),e(x_,TV),e(TV,oxo),e(x_,rxo),e(y,txo),e(y,$_),e($_,Dpe),e(Dpe,axo),e($_,nxo),e($_,MV),e(MV,sxo),e($_,lxo),e(y,ixo),e(y,k_),e(k_,Gpe),e(Gpe,dxo),e(k_,mxo),e(k_,EV),e(EV,cxo),e(k_,fxo),e(y,gxo),e(y,S_),e(S_,Ope),e(Ope,hxo),e(S_,uxo),e(S_,CV),e(CV,pxo),e(S_,_xo),e(y,bxo),e(y,R_),e(R_,Vpe),e(Vpe,vxo),e(R_,Fxo),e(R_,wV),e(wV,Txo),e(R_,Mxo),e(y,Exo),e(y,P_),e(P_,Xpe),e(Xpe,Cxo),e(P_,wxo),e(P_,AV),e(AV,Axo),e(P_,Lxo),e(y,yxo),e(y,B_),e(B_,zpe),e(zpe,xxo),e(B_,$xo),e(B_,LV),e(LV,kxo),e(B_,Sxo),e(y,Rxo),e(y,I_),e(I_,Qpe),e(Qpe,Pxo),e(I_,Bxo),e(I_,yV),e(yV,Ixo),e(I_,Nxo),e(y,qxo),e(y,N_),e(N_,Wpe),e(Wpe,jxo),e(N_,Dxo),e(N_,xV),e(xV,Gxo),e(N_,Oxo),e(y,Vxo),e(y,q_),e(q_,Upe),e(Upe,Xxo),e(q_,zxo),e(q_,$V),e($V,Qxo),e(q_,Wxo),e(y,Uxo),e(y,j_),e(j_,Hpe),e(Hpe,Hxo),e(j_,Jxo),e(j_,kV),e(kV,Yxo),e(j_,Kxo),e(y,Zxo),e(y,D_),e(D_,Jpe),e(Jpe,e$o),e(D_,o$o),e(D_,SV),e(SV,r$o),e(D_,t$o),e(y,a$o),e(y,G_),e(G_,Ype),e(Ype,n$o),e(G_,s$o),e(G_,RV),e(RV,l$o),e(G_,i$o),e(y,d$o),e(y,O_),e(O_,Kpe),e(Kpe,m$o),e(O_,c$o),e(O_,PV),e(PV,f$o),e(O_,g$o),e(y,h$o),e(y,V_),e(V_,Zpe),e(Zpe,u$o),e(V_,p$o),e(V_,BV),e(BV,_$o),e(V_,b$o),e(y,v$o),e(y,_l),e(_l,e_e),e(e_e,F$o),e(_l,T$o),e(_l,IV),e(IV,M$o),e(_l,E$o),e(_l,NV),e(NV,C$o),e(_l,w$o),e(y,A$o),e(y,X_),e(X_,o_e),e(o_e,L$o),e(X_,y$o),e(X_,qV),e(qV,x$o),e(X_,$$o),e(y,k$o),e(y,z_),e(z_,r_e),e(r_e,S$o),e(z_,R$o),e(z_,jV),e(jV,P$o),e(z_,B$o),e(y,I$o),e(y,Q_),e(Q_,t_e),e(t_e,N$o),e(Q_,q$o),e(Q_,DV),e(DV,j$o),e(Q_,D$o),e(y,G$o),e(y,W_),e(W_,a_e),e(a_e,O$o),e(W_,V$o),e(W_,GV),e(GV,X$o),e(W_,z$o),e(y,Q$o),e(y,U_),e(U_,n_e),e(n_e,W$o),e(U_,U$o),e(U_,OV),e(OV,H$o),e(U_,J$o),e(y,Y$o),e(y,H_),e(H_,s_e),e(s_e,K$o),e(H_,Z$o),e(H_,VV),e(VV,eko),e(H_,oko),e(y,rko),e(y,J_),e(J_,l_e),e(l_e,tko),e(J_,ako),e(J_,XV),e(XV,nko),e(J_,sko),e(y,lko),e(y,Y_),e(Y_,i_e),e(i_e,iko),e(Y_,dko),e(Y_,zV),e(zV,mko),e(Y_,cko),e(y,fko),e(y,K_),e(K_,d_e),e(d_e,gko),e(K_,hko),e(K_,QV),e(QV,uko),e(K_,pko),e(y,_ko),e(y,Z_),e(Z_,m_e),e(m_e,bko),e(Z_,vko),e(Z_,WV),e(WV,Fko),e(Z_,Tko),e(y,Mko),e(y,e2),e(e2,c_e),e(c_e,Eko),e(e2,Cko),e(e2,UV),e(UV,wko),e(e2,Ako),e(y,Lko),e(y,o2),e(o2,f_e),e(f_e,yko),e(o2,xko),e(o2,HV),e(HV,$ko),e(o2,kko),e(y,Sko),e(y,r2),e(r2,g_e),e(g_e,Rko),e(r2,Pko),e(r2,JV),e(JV,Bko),e(r2,Iko),e(y,Nko),e(y,t2),e(t2,h_e),e(h_e,qko),e(t2,jko),e(t2,YV),e(YV,Dko),e(t2,Gko),e(y,Oko),e(y,a2),e(a2,u_e),e(u_e,Vko),e(a2,Xko),e(a2,KV),e(KV,zko),e(a2,Qko),e(y,Wko),e(y,n2),e(n2,p_e),e(p_e,Uko),e(n2,Hko),e(n2,ZV),e(ZV,Jko),e(n2,Yko),e(y,Kko),e(y,s2),e(s2,__e),e(__e,Zko),e(s2,eSo),e(s2,eX),e(eX,oSo),e(s2,rSo),e(y,tSo),e(y,l2),e(l2,b_e),e(b_e,aSo),e(l2,nSo),e(l2,oX),e(oX,sSo),e(l2,lSo),e(y,iSo),e(y,i2),e(i2,v_e),e(v_e,dSo),e(i2,mSo),e(i2,rX),e(rX,cSo),e(i2,fSo),e(y,gSo),e(y,d2),e(d2,F_e),e(F_e,hSo),e(d2,uSo),e(d2,tX),e(tX,pSo),e(d2,_So),e(y,bSo),e(y,m2),e(m2,T_e),e(T_e,vSo),e(m2,FSo),e(m2,aX),e(aX,TSo),e(m2,MSo),e(y,ESo),e(y,c2),e(c2,M_e),e(M_e,CSo),e(c2,wSo),e(c2,nX),e(nX,ASo),e(c2,LSo),e(y,ySo),e(y,f2),e(f2,E_e),e(E_e,xSo),e(f2,$So),e(f2,sX),e(sX,kSo),e(f2,SSo),e(y,RSo),e(y,g2),e(g2,C_e),e(C_e,PSo),e(g2,BSo),e(g2,lX),e(lX,ISo),e(g2,NSo),e(y,qSo),e(y,h2),e(h2,w_e),e(w_e,jSo),e(h2,DSo),e(h2,iX),e(iX,GSo),e(h2,OSo),e(y,VSo),e(y,u2),e(u2,A_e),e(A_e,XSo),e(u2,zSo),e(u2,dX),e(dX,QSo),e(u2,WSo),e(y,USo),e(y,p2),e(p2,L_e),e(L_e,HSo),e(p2,JSo),e(p2,mX),e(mX,YSo),e(p2,KSo),e(y,ZSo),e(y,_2),e(_2,y_e),e(y_e,eRo),e(_2,oRo),e(_2,cX),e(cX,rRo),e(_2,tRo),e(y,aRo),e(y,b2),e(b2,x_e),e(x_e,nRo),e(b2,sRo),e(b2,fX),e(fX,lRo),e(b2,iRo),e(y,dRo),e(y,v2),e(v2,$_e),e($_e,mRo),e(v2,cRo),e(v2,gX),e(gX,fRo),e(v2,gRo),e(y,hRo),e(y,F2),e(F2,k_e),e(k_e,uRo),e(F2,pRo),e(F2,hX),e(hX,_Ro),e(F2,bRo),e(y,vRo),e(y,T2),e(T2,S_e),e(S_e,FRo),e(T2,TRo),e(T2,uX),e(uX,MRo),e(T2,ERo),e(y,CRo),e(y,M2),e(M2,R_e),e(R_e,wRo),e(M2,ARo),e(M2,pX),e(pX,LRo),e(M2,yRo),e(y,xRo),e(y,E2),e(E2,P_e),e(P_e,$Ro),e(E2,kRo),e(E2,_X),e(_X,SRo),e(E2,RRo),e(y,PRo),e(y,C2),e(C2,B_e),e(B_e,BRo),e(C2,IRo),e(C2,bX),e(bX,NRo),e(C2,qRo),e(y,jRo),e(y,w2),e(w2,I_e),e(I_e,DRo),e(w2,GRo),e(w2,vX),e(vX,ORo),e(w2,VRo),e(y,XRo),e(y,A2),e(A2,N_e),e(N_e,zRo),e(A2,QRo),e(A2,FX),e(FX,WRo),e(A2,URo),e(y,HRo),e(y,L2),e(L2,q_e),e(q_e,JRo),e(L2,YRo),e(L2,TX),e(TX,KRo),e(L2,ZRo),e(y,ePo),e(y,y2),e(y2,j_e),e(j_e,oPo),e(y2,rPo),e(y2,MX),e(MX,tPo),e(y2,aPo),e(y,nPo),e(y,x2),e(x2,D_e),e(D_e,sPo),e(x2,lPo),e(x2,EX),e(EX,iPo),e(x2,dPo),e(y,mPo),e(y,$2),e($2,G_e),e(G_e,cPo),e($2,fPo),e($2,CX),e(CX,gPo),e($2,hPo),e(y,uPo),e(y,k2),e(k2,O_e),e(O_e,pPo),e(k2,_Po),e(k2,wX),e(wX,bPo),e(k2,vPo),e(y,FPo),e(y,S2),e(S2,V_e),e(V_e,TPo),e(S2,MPo),e(S2,AX),e(AX,EPo),e(S2,CPo),e(y,wPo),e(y,R2),e(R2,X_e),e(X_e,APo),e(R2,LPo),e(R2,LX),e(LX,yPo),e(R2,xPo),e(y,$Po),e(y,P2),e(P2,z_e),e(z_e,kPo),e(P2,SPo),e(P2,yX),e(yX,RPo),e(P2,PPo),e(y,BPo),e(y,B2),e(B2,Q_e),e(Q_e,IPo),e(B2,NPo),e(B2,xX),e(xX,qPo),e(B2,jPo),e(y,DPo),e(y,I2),e(I2,W_e),e(W_e,GPo),e(I2,OPo),e(I2,$X),e($X,VPo),e(I2,XPo),e(y,zPo),e(y,N2),e(N2,U_e),e(U_e,QPo),e(N2,WPo),e(N2,kX),e(kX,UPo),e(N2,HPo),e(y,JPo),e(y,q2),e(q2,H_e),e(H_e,YPo),e(q2,KPo),e(q2,SX),e(SX,ZPo),e(q2,eBo),e(y,oBo),e(y,j2),e(j2,J_e),e(J_e,rBo),e(j2,tBo),e(j2,RX),e(RX,aBo),e(j2,nBo),e(y,sBo),e(y,D2),e(D2,Y_e),e(Y_e,lBo),e(D2,iBo),e(D2,PX),e(PX,dBo),e(D2,mBo),e(y,cBo),e(y,G2),e(G2,K_e),e(K_e,fBo),e(G2,gBo),e(G2,BX),e(BX,hBo),e(G2,uBo),e(y,pBo),e(y,O2),e(O2,Z_e),e(Z_e,_Bo),e(O2,bBo),e(O2,IX),e(IX,vBo),e(O2,FBo),e(y,TBo),e(y,V2),e(V2,e2e),e(e2e,MBo),e(V2,EBo),e(V2,NX),e(NX,CBo),e(V2,wBo),e(y,ABo),e(y,X2),e(X2,o2e),e(o2e,LBo),e(X2,yBo),e(X2,qX),e(qX,xBo),e(X2,$Bo),e(y,kBo),e(y,z2),e(z2,r2e),e(r2e,SBo),e(z2,RBo),e(z2,jX),e(jX,PBo),e(z2,BBo),e(y,IBo),e(y,Q2),e(Q2,t2e),e(t2e,NBo),e(Q2,qBo),e(Q2,DX),e(DX,jBo),e(Q2,DBo),e(y,GBo),e(y,W2),e(W2,a2e),e(a2e,OBo),e(W2,VBo),e(W2,GX),e(GX,XBo),e(W2,zBo),e(y,QBo),e(y,U2),e(U2,n2e),e(n2e,WBo),e(U2,UBo),e(U2,OX),e(OX,HBo),e(U2,JBo),e(y,YBo),e(y,H2),e(H2,s2e),e(s2e,KBo),e(H2,ZBo),e(H2,VX),e(VX,eIo),e(H2,oIo),e(y,rIo),e(y,J2),e(J2,l2e),e(l2e,tIo),e(J2,aIo),e(J2,XX),e(XX,nIo),e(J2,sIo),e(y,lIo),e(y,Y2),e(Y2,i2e),e(i2e,iIo),e(Y2,dIo),e(Y2,zX),e(zX,mIo),e(Y2,cIo),e(y,fIo),e(y,K2),e(K2,d2e),e(d2e,gIo),e(K2,hIo),e(K2,QX),e(QX,uIo),e(K2,pIo),e(y,_Io),e(y,Z2),e(Z2,m2e),e(m2e,bIo),e(Z2,vIo),e(Z2,WX),e(WX,FIo),e(Z2,TIo),e(y,MIo),e(y,e1),e(e1,c2e),e(c2e,EIo),e(e1,CIo),e(e1,UX),e(UX,wIo),e(e1,AIo),e(y,LIo),e(y,o1),e(o1,f2e),e(f2e,yIo),e(o1,xIo),e(o1,HX),e(HX,$Io),e(o1,kIo),e(y,SIo),e(y,r1),e(r1,g2e),e(g2e,RIo),e(r1,PIo),e(r1,JX),e(JX,BIo),e(r1,IIo),e(y,NIo),e(y,t1),e(t1,h2e),e(h2e,qIo),e(t1,jIo),e(t1,YX),e(YX,DIo),e(t1,GIo),e(y,OIo),e(y,a1),e(a1,u2e),e(u2e,VIo),e(a1,XIo),e(a1,KX),e(KX,zIo),e(a1,QIo),e(y,WIo),e(y,n1),e(n1,p2e),e(p2e,UIo),e(n1,HIo),e(n1,ZX),e(ZX,JIo),e(n1,YIo),e(y,KIo),e(y,s1),e(s1,_2e),e(_2e,ZIo),e(s1,eNo),e(s1,ez),e(ez,oNo),e(s1,rNo),e(y,tNo),e(y,l1),e(l1,b2e),e(b2e,aNo),e(l1,nNo),e(l1,oz),e(oz,sNo),e(l1,lNo),e(y,iNo),e(y,i1),e(i1,v2e),e(v2e,dNo),e(i1,mNo),e(i1,rz),e(rz,cNo),e(i1,fNo),e(y,gNo),e(y,d1),e(d1,F2e),e(F2e,hNo),e(d1,uNo),e(d1,tz),e(tz,pNo),e(d1,_No),e(y,bNo),e(y,m1),e(m1,T2e),e(T2e,vNo),e(m1,FNo),e(m1,az),e(az,TNo),e(m1,MNo),e(y,ENo),e(y,c1),e(c1,M2e),e(M2e,CNo),e(c1,wNo),e(c1,nz),e(nz,ANo),e(c1,LNo),e(y,yNo),e(y,f1),e(f1,E2e),e(E2e,xNo),e(f1,$No),e(f1,sz),e(sz,kNo),e(f1,SNo),e(y,RNo),e(y,g1),e(g1,C2e),e(C2e,PNo),e(g1,BNo),e(g1,lz),e(lz,INo),e(g1,NNo),e(y,qNo),e(y,h1),e(h1,w2e),e(w2e,jNo),e(h1,DNo),e(h1,iz),e(iz,GNo),e(h1,ONo),e(y,VNo),e(y,u1),e(u1,A2e),e(A2e,XNo),e(u1,zNo),e(u1,dz),e(dz,QNo),e(u1,WNo),e(y,UNo),e(y,p1),e(p1,L2e),e(L2e,HNo),e(p1,JNo),e(p1,mz),e(mz,YNo),e(p1,KNo),e(y,ZNo),e(y,_1),e(_1,y2e),e(y2e,eqo),e(_1,oqo),e(_1,cz),e(cz,rqo),e(_1,tqo),e(y,aqo),e(y,b1),e(b1,x2e),e(x2e,nqo),e(b1,sqo),e(b1,fz),e(fz,lqo),e(b1,iqo),e(y,dqo),e(y,v1),e(v1,$2e),e($2e,mqo),e(v1,cqo),e(v1,gz),e(gz,fqo),e(v1,gqo),e(y,hqo),e(y,F1),e(F1,k2e),e(k2e,uqo),e(F1,pqo),e(F1,hz),e(hz,_qo),e(F1,bqo),e(y,vqo),e(y,T1),e(T1,S2e),e(S2e,Fqo),e(T1,Tqo),e(T1,uz),e(uz,Mqo),e(T1,Eqo),e(Ze,Cqo),e(Ze,M1),e(M1,wqo),e(M1,R2e),e(R2e,Aqo),e(M1,Lqo),e(M1,P2e),e(P2e,yqo),e(Ze,xqo),M(E1,Ze,null),b(c,oeo,_),b(c,Fd,_),e(Fd,C1),e(C1,B2e),M(kx,B2e,null),e(Fd,$qo),e(Fd,I2e),e(I2e,kqo),b(c,reo,_),b(c,Bo,_),M(Sx,Bo,null),e(Bo,Sqo),e(Bo,Td),e(Td,Rqo),e(Td,pz),e(pz,Pqo),e(Td,Bqo),e(Td,_z),e(_z,Iqo),e(Td,Nqo),e(Bo,qqo),e(Bo,Rx),e(Rx,jqo),e(Rx,N2e),e(N2e,Dqo),e(Rx,Gqo),e(Bo,Oqo),e(Bo,bt),M(Px,bt,null),e(bt,Vqo),e(bt,q2e),e(q2e,Xqo),e(bt,zqo),e(bt,Md),e(Md,Qqo),e(Md,j2e),e(j2e,Wqo),e(Md,Uqo),e(Md,bz),e(bz,Hqo),e(Md,Jqo),e(bt,Yqo),M(w1,bt,null),e(Bo,Kqo),e(Bo,eo),M(Bx,eo,null),e(eo,Zqo),e(eo,D2e),e(D2e,ejo),e(eo,ojo),e(eo,Ya),e(Ya,rjo),e(Ya,G2e),e(G2e,tjo),e(Ya,ajo),e(Ya,O2e),e(O2e,njo),e(Ya,sjo),e(Ya,V2e),e(V2e,ljo),e(Ya,ijo),e(eo,djo),e(eo,G),e(G,A1),e(A1,X2e),e(X2e,mjo),e(A1,cjo),e(A1,vz),e(vz,fjo),e(A1,gjo),e(G,hjo),e(G,L1),e(L1,z2e),e(z2e,ujo),e(L1,pjo),e(L1,Fz),e(Fz,_jo),e(L1,bjo),e(G,vjo),e(G,y1),e(y1,Q2e),e(Q2e,Fjo),e(y1,Tjo),e(y1,Tz),e(Tz,Mjo),e(y1,Ejo),e(G,Cjo),e(G,x1),e(x1,W2e),e(W2e,wjo),e(x1,Ajo),e(x1,Mz),e(Mz,Ljo),e(x1,yjo),e(G,xjo),e(G,$1),e($1,U2e),e(U2e,$jo),e($1,kjo),e($1,Ez),e(Ez,Sjo),e($1,Rjo),e(G,Pjo),e(G,k1),e(k1,H2e),e(H2e,Bjo),e(k1,Ijo),e(k1,Cz),e(Cz,Njo),e(k1,qjo),e(G,jjo),e(G,S1),e(S1,J2e),e(J2e,Djo),e(S1,Gjo),e(S1,wz),e(wz,Ojo),e(S1,Vjo),e(G,Xjo),e(G,R1),e(R1,Y2e),e(Y2e,zjo),e(R1,Qjo),e(R1,Az),e(Az,Wjo),e(R1,Ujo),e(G,Hjo),e(G,P1),e(P1,K2e),e(K2e,Jjo),e(P1,Yjo),e(P1,Lz),e(Lz,Kjo),e(P1,Zjo),e(G,eDo),e(G,B1),e(B1,Z2e),e(Z2e,oDo),e(B1,rDo),e(B1,yz),e(yz,tDo),e(B1,aDo),e(G,nDo),e(G,I1),e(I1,e1e),e(e1e,sDo),e(I1,lDo),e(I1,xz),e(xz,iDo),e(I1,dDo),e(G,mDo),e(G,N1),e(N1,o1e),e(o1e,cDo),e(N1,fDo),e(N1,$z),e($z,gDo),e(N1,hDo),e(G,uDo),e(G,q1),e(q1,r1e),e(r1e,pDo),e(q1,_Do),e(q1,kz),e(kz,bDo),e(q1,vDo),e(G,FDo),e(G,j1),e(j1,t1e),e(t1e,TDo),e(j1,MDo),e(j1,Sz),e(Sz,EDo),e(j1,CDo),e(G,wDo),e(G,D1),e(D1,a1e),e(a1e,ADo),e(D1,LDo),e(D1,Rz),e(Rz,yDo),e(D1,xDo),e(G,$Do),e(G,G1),e(G1,n1e),e(n1e,kDo),e(G1,SDo),e(G1,Pz),e(Pz,RDo),e(G1,PDo),e(G,BDo),e(G,O1),e(O1,s1e),e(s1e,IDo),e(O1,NDo),e(O1,Bz),e(Bz,qDo),e(O1,jDo),e(G,DDo),e(G,V1),e(V1,l1e),e(l1e,GDo),e(V1,ODo),e(V1,Iz),e(Iz,VDo),e(V1,XDo),e(G,zDo),e(G,X1),e(X1,i1e),e(i1e,QDo),e(X1,WDo),e(X1,Nz),e(Nz,UDo),e(X1,HDo),e(G,JDo),e(G,z1),e(z1,d1e),e(d1e,YDo),e(z1,KDo),e(z1,qz),e(qz,ZDo),e(z1,eGo),e(G,oGo),e(G,Q1),e(Q1,m1e),e(m1e,rGo),e(Q1,tGo),e(Q1,jz),e(jz,aGo),e(Q1,nGo),e(G,sGo),e(G,W1),e(W1,c1e),e(c1e,lGo),e(W1,iGo),e(W1,Dz),e(Dz,dGo),e(W1,mGo),e(G,cGo),e(G,U1),e(U1,f1e),e(f1e,fGo),e(U1,gGo),e(U1,Gz),e(Gz,hGo),e(U1,uGo),e(G,pGo),e(G,H1),e(H1,g1e),e(g1e,_Go),e(H1,bGo),e(H1,Oz),e(Oz,vGo),e(H1,FGo),e(G,TGo),e(G,J1),e(J1,h1e),e(h1e,MGo),e(J1,EGo),e(J1,Vz),e(Vz,CGo),e(J1,wGo),e(G,AGo),e(G,Y1),e(Y1,u1e),e(u1e,LGo),e(Y1,yGo),e(Y1,Xz),e(Xz,xGo),e(Y1,$Go),e(G,kGo),e(G,K1),e(K1,p1e),e(p1e,SGo),e(K1,RGo),e(K1,zz),e(zz,PGo),e(K1,BGo),e(G,IGo),e(G,Z1),e(Z1,_1e),e(_1e,NGo),e(Z1,qGo),e(Z1,Qz),e(Qz,jGo),e(Z1,DGo),e(G,GGo),e(G,eb),e(eb,b1e),e(b1e,OGo),e(eb,VGo),e(eb,Wz),e(Wz,XGo),e(eb,zGo),e(G,QGo),e(G,ob),e(ob,v1e),e(v1e,WGo),e(ob,UGo),e(ob,Uz),e(Uz,HGo),e(ob,JGo),e(G,YGo),e(G,rb),e(rb,F1e),e(F1e,KGo),e(rb,ZGo),e(rb,Hz),e(Hz,eOo),e(rb,oOo),e(G,rOo),e(G,tb),e(tb,T1e),e(T1e,tOo),e(tb,aOo),e(tb,Jz),e(Jz,nOo),e(tb,sOo),e(G,lOo),e(G,ab),e(ab,M1e),e(M1e,iOo),e(ab,dOo),e(ab,Yz),e(Yz,mOo),e(ab,cOo),e(G,fOo),e(G,nb),e(nb,E1e),e(E1e,gOo),e(nb,hOo),e(nb,Kz),e(Kz,uOo),e(nb,pOo),e(G,_Oo),e(G,sb),e(sb,C1e),e(C1e,bOo),e(sb,vOo),e(sb,Zz),e(Zz,FOo),e(sb,TOo),e(G,MOo),e(G,lb),e(lb,w1e),e(w1e,EOo),e(lb,COo),e(lb,eQ),e(eQ,wOo),e(lb,AOo),e(G,LOo),e(G,ib),e(ib,A1e),e(A1e,yOo),e(ib,xOo),e(ib,oQ),e(oQ,$Oo),e(ib,kOo),e(G,SOo),e(G,db),e(db,L1e),e(L1e,ROo),e(db,POo),e(db,rQ),e(rQ,BOo),e(db,IOo),e(G,NOo),e(G,mb),e(mb,y1e),e(y1e,qOo),e(mb,jOo),e(mb,tQ),e(tQ,DOo),e(mb,GOo),e(G,OOo),e(G,cb),e(cb,x1e),e(x1e,VOo),e(cb,XOo),e(cb,aQ),e(aQ,zOo),e(cb,QOo),e(G,WOo),e(G,fb),e(fb,$1e),e($1e,UOo),e(fb,HOo),e(fb,nQ),e(nQ,JOo),e(fb,YOo),e(G,KOo),e(G,gb),e(gb,k1e),e(k1e,ZOo),e(gb,eVo),e(gb,sQ),e(sQ,oVo),e(gb,rVo),e(G,tVo),e(G,hb),e(hb,S1e),e(S1e,aVo),e(hb,nVo),e(hb,lQ),e(lQ,sVo),e(hb,lVo),e(G,iVo),e(G,ub),e(ub,R1e),e(R1e,dVo),e(ub,mVo),e(ub,iQ),e(iQ,cVo),e(ub,fVo),e(G,gVo),e(G,pb),e(pb,P1e),e(P1e,hVo),e(pb,uVo),e(pb,dQ),e(dQ,pVo),e(pb,_Vo),e(G,bVo),e(G,_b),e(_b,B1e),e(B1e,vVo),e(_b,FVo),e(_b,mQ),e(mQ,TVo),e(_b,MVo),e(G,EVo),e(G,bb),e(bb,I1e),e(I1e,CVo),e(bb,wVo),e(bb,cQ),e(cQ,AVo),e(bb,LVo),e(G,yVo),e(G,vb),e(vb,N1e),e(N1e,xVo),e(vb,$Vo),e(vb,fQ),e(fQ,kVo),e(vb,SVo),e(eo,RVo),e(eo,Fb),e(Fb,PVo),e(Fb,q1e),e(q1e,BVo),e(Fb,IVo),e(Fb,j1e),e(j1e,NVo),e(eo,qVo),M(Tb,eo,null),b(c,teo,_),b(c,Ed,_),e(Ed,Mb),e(Mb,D1e),M(Ix,D1e,null),e(Ed,jVo),e(Ed,G1e),e(G1e,DVo),b(c,aeo,_),b(c,Io,_),M(Nx,Io,null),e(Io,GVo),e(Io,Cd),e(Cd,OVo),e(Cd,gQ),e(gQ,VVo),e(Cd,XVo),e(Cd,hQ),e(hQ,zVo),e(Cd,QVo),e(Io,WVo),e(Io,qx),e(qx,UVo),e(qx,O1e),e(O1e,HVo),e(qx,JVo),e(Io,YVo),e(Io,vt),M(jx,vt,null),e(vt,KVo),e(vt,V1e),e(V1e,ZVo),e(vt,eXo),e(vt,wd),e(wd,oXo),e(wd,X1e),e(X1e,rXo),e(wd,tXo),e(wd,uQ),e(uQ,aXo),e(wd,nXo),e(vt,sXo),M(Eb,vt,null),e(Io,lXo),e(Io,oo),M(Dx,oo,null),e(oo,iXo),e(oo,z1e),e(z1e,dXo),e(oo,mXo),e(oo,Ka),e(Ka,cXo),e(Ka,Q1e),e(Q1e,fXo),e(Ka,gXo),e(Ka,W1e),e(W1e,hXo),e(Ka,uXo),e(Ka,U1e),e(U1e,pXo),e(Ka,_Xo),e(oo,bXo),e(oo,Q),e(Q,Cb),e(Cb,H1e),e(H1e,vXo),e(Cb,FXo),e(Cb,pQ),e(pQ,TXo),e(Cb,MXo),e(Q,EXo),e(Q,wb),e(wb,J1e),e(J1e,CXo),e(wb,wXo),e(wb,_Q),e(_Q,AXo),e(wb,LXo),e(Q,yXo),e(Q,Ab),e(Ab,Y1e),e(Y1e,xXo),e(Ab,$Xo),e(Ab,bQ),e(bQ,kXo),e(Ab,SXo),e(Q,RXo),e(Q,Lb),e(Lb,K1e),e(K1e,PXo),e(Lb,BXo),e(Lb,vQ),e(vQ,IXo),e(Lb,NXo),e(Q,qXo),e(Q,yb),e(yb,Z1e),e(Z1e,jXo),e(yb,DXo),e(yb,FQ),e(FQ,GXo),e(yb,OXo),e(Q,VXo),e(Q,xb),e(xb,ebe),e(ebe,XXo),e(xb,zXo),e(xb,TQ),e(TQ,QXo),e(xb,WXo),e(Q,UXo),e(Q,$b),e($b,obe),e(obe,HXo),e($b,JXo),e($b,MQ),e(MQ,YXo),e($b,KXo),e(Q,ZXo),e(Q,kb),e(kb,rbe),e(rbe,ezo),e(kb,ozo),e(kb,EQ),e(EQ,rzo),e(kb,tzo),e(Q,azo),e(Q,Sb),e(Sb,tbe),e(tbe,nzo),e(Sb,szo),e(Sb,CQ),e(CQ,lzo),e(Sb,izo),e(Q,dzo),e(Q,Rb),e(Rb,abe),e(abe,mzo),e(Rb,czo),e(Rb,wQ),e(wQ,fzo),e(Rb,gzo),e(Q,hzo),e(Q,Pb),e(Pb,nbe),e(nbe,uzo),e(Pb,pzo),e(Pb,AQ),e(AQ,_zo),e(Pb,bzo),e(Q,vzo),e(Q,Bb),e(Bb,sbe),e(sbe,Fzo),e(Bb,Tzo),e(Bb,LQ),e(LQ,Mzo),e(Bb,Ezo),e(Q,Czo),e(Q,Ib),e(Ib,lbe),e(lbe,wzo),e(Ib,Azo),e(Ib,yQ),e(yQ,Lzo),e(Ib,yzo),e(Q,xzo),e(Q,Nb),e(Nb,ibe),e(ibe,$zo),e(Nb,kzo),e(Nb,xQ),e(xQ,Szo),e(Nb,Rzo),e(Q,Pzo),e(Q,qb),e(qb,dbe),e(dbe,Bzo),e(qb,Izo),e(qb,$Q),e($Q,Nzo),e(qb,qzo),e(Q,jzo),e(Q,jb),e(jb,mbe),e(mbe,Dzo),e(jb,Gzo),e(jb,kQ),e(kQ,Ozo),e(jb,Vzo),e(Q,Xzo),e(Q,Db),e(Db,cbe),e(cbe,zzo),e(Db,Qzo),e(Db,SQ),e(SQ,Wzo),e(Db,Uzo),e(Q,Hzo),e(Q,Gb),e(Gb,fbe),e(fbe,Jzo),e(Gb,Yzo),e(Gb,RQ),e(RQ,Kzo),e(Gb,Zzo),e(Q,eQo),e(Q,Ob),e(Ob,gbe),e(gbe,oQo),e(Ob,rQo),e(Ob,PQ),e(PQ,tQo),e(Ob,aQo),e(Q,nQo),e(Q,Vb),e(Vb,hbe),e(hbe,sQo),e(Vb,lQo),e(Vb,BQ),e(BQ,iQo),e(Vb,dQo),e(Q,mQo),e(Q,Xb),e(Xb,ube),e(ube,cQo),e(Xb,fQo),e(Xb,IQ),e(IQ,gQo),e(Xb,hQo),e(Q,uQo),e(Q,zb),e(zb,pbe),e(pbe,pQo),e(zb,_Qo),e(zb,NQ),e(NQ,bQo),e(zb,vQo),e(Q,FQo),e(Q,Qb),e(Qb,_be),e(_be,TQo),e(Qb,MQo),e(Qb,qQ),e(qQ,EQo),e(Qb,CQo),e(Q,wQo),e(Q,Wb),e(Wb,bbe),e(bbe,AQo),e(Wb,LQo),e(Wb,jQ),e(jQ,yQo),e(Wb,xQo),e(Q,$Qo),e(Q,Ub),e(Ub,vbe),e(vbe,kQo),e(Ub,SQo),e(Ub,DQ),e(DQ,RQo),e(Ub,PQo),e(Q,BQo),e(Q,Hb),e(Hb,Fbe),e(Fbe,IQo),e(Hb,NQo),e(Hb,GQ),e(GQ,qQo),e(Hb,jQo),e(Q,DQo),e(Q,Jb),e(Jb,Tbe),e(Tbe,GQo),e(Jb,OQo),e(Jb,OQ),e(OQ,VQo),e(Jb,XQo),e(Q,zQo),e(Q,Yb),e(Yb,Mbe),e(Mbe,QQo),e(Yb,WQo),e(Yb,VQ),e(VQ,UQo),e(Yb,HQo),e(Q,JQo),e(Q,Kb),e(Kb,Ebe),e(Ebe,YQo),e(Kb,KQo),e(Kb,XQ),e(XQ,ZQo),e(Kb,eWo),e(Q,oWo),e(Q,Zb),e(Zb,Cbe),e(Cbe,rWo),e(Zb,tWo),e(Zb,zQ),e(zQ,aWo),e(Zb,nWo),e(Q,sWo),e(Q,ev),e(ev,wbe),e(wbe,lWo),e(ev,iWo),e(ev,QQ),e(QQ,dWo),e(ev,mWo),e(Q,cWo),e(Q,ov),e(ov,Abe),e(Abe,fWo),e(ov,gWo),e(ov,WQ),e(WQ,hWo),e(ov,uWo),e(Q,pWo),e(Q,rv),e(rv,Lbe),e(Lbe,_Wo),e(rv,bWo),e(rv,UQ),e(UQ,vWo),e(rv,FWo),e(Q,TWo),e(Q,tv),e(tv,ybe),e(ybe,MWo),e(tv,EWo),e(tv,HQ),e(HQ,CWo),e(tv,wWo),e(Q,AWo),e(Q,av),e(av,xbe),e(xbe,LWo),e(av,yWo),e(av,JQ),e(JQ,xWo),e(av,$Wo),e(Q,kWo),e(Q,nv),e(nv,$be),e($be,SWo),e(nv,RWo),e(nv,YQ),e(YQ,PWo),e(nv,BWo),e(Q,IWo),e(Q,sv),e(sv,kbe),e(kbe,NWo),e(sv,qWo),e(sv,KQ),e(KQ,jWo),e(sv,DWo),e(Q,GWo),e(Q,lv),e(lv,Sbe),e(Sbe,OWo),e(lv,VWo),e(lv,ZQ),e(ZQ,XWo),e(lv,zWo),e(Q,QWo),e(Q,iv),e(iv,Rbe),e(Rbe,WWo),e(iv,UWo),e(iv,eW),e(eW,HWo),e(iv,JWo),e(Q,YWo),e(Q,dv),e(dv,Pbe),e(Pbe,KWo),e(dv,ZWo),e(dv,oW),e(oW,eUo),e(dv,oUo),e(Q,rUo),e(Q,mv),e(mv,Bbe),e(Bbe,tUo),e(mv,aUo),e(mv,rW),e(rW,nUo),e(mv,sUo),e(Q,lUo),e(Q,cv),e(cv,Ibe),e(Ibe,iUo),e(cv,dUo),e(cv,tW),e(tW,mUo),e(cv,cUo),e(oo,fUo),e(oo,fv),e(fv,gUo),e(fv,Nbe),e(Nbe,hUo),e(fv,uUo),e(fv,qbe),e(qbe,pUo),e(oo,_Uo),M(gv,oo,null),b(c,neo,_),b(c,Ad,_),e(Ad,hv),e(hv,jbe),M(Gx,jbe,null),e(Ad,bUo),e(Ad,Dbe),e(Dbe,vUo),b(c,seo,_),b(c,No,_),M(Ox,No,null),e(No,FUo),e(No,Ld),e(Ld,TUo),e(Ld,aW),e(aW,MUo),e(Ld,EUo),e(Ld,nW),e(nW,CUo),e(Ld,wUo),e(No,AUo),e(No,Vx),e(Vx,LUo),e(Vx,Gbe),e(Gbe,yUo),e(Vx,xUo),e(No,$Uo),e(No,Ft),M(Xx,Ft,null),e(Ft,kUo),e(Ft,Obe),e(Obe,SUo),e(Ft,RUo),e(Ft,yd),e(yd,PUo),e(yd,Vbe),e(Vbe,BUo),e(yd,IUo),e(yd,sW),e(sW,NUo),e(yd,qUo),e(Ft,jUo),M(uv,Ft,null),e(No,DUo),e(No,ro),M(zx,ro,null),e(ro,GUo),e(ro,Xbe),e(Xbe,OUo),e(ro,VUo),e(ro,Za),e(Za,XUo),e(Za,zbe),e(zbe,zUo),e(Za,QUo),e(Za,Qbe),e(Qbe,WUo),e(Za,UUo),e(Za,Wbe),e(Wbe,HUo),e(Za,JUo),e(ro,YUo),e(ro,J),e(J,pv),e(pv,Ube),e(Ube,KUo),e(pv,ZUo),e(pv,lW),e(lW,eHo),e(pv,oHo),e(J,rHo),e(J,_v),e(_v,Hbe),e(Hbe,tHo),e(_v,aHo),e(_v,iW),e(iW,nHo),e(_v,sHo),e(J,lHo),e(J,bv),e(bv,Jbe),e(Jbe,iHo),e(bv,dHo),e(bv,dW),e(dW,mHo),e(bv,cHo),e(J,fHo),e(J,vv),e(vv,Ybe),e(Ybe,gHo),e(vv,hHo),e(vv,mW),e(mW,uHo),e(vv,pHo),e(J,_Ho),e(J,Fv),e(Fv,Kbe),e(Kbe,bHo),e(Fv,vHo),e(Fv,cW),e(cW,FHo),e(Fv,THo),e(J,MHo),e(J,Tv),e(Tv,Zbe),e(Zbe,EHo),e(Tv,CHo),e(Tv,fW),e(fW,wHo),e(Tv,AHo),e(J,LHo),e(J,Mv),e(Mv,eve),e(eve,yHo),e(Mv,xHo),e(Mv,gW),e(gW,$Ho),e(Mv,kHo),e(J,SHo),e(J,Ev),e(Ev,ove),e(ove,RHo),e(Ev,PHo),e(Ev,hW),e(hW,BHo),e(Ev,IHo),e(J,NHo),e(J,Cv),e(Cv,rve),e(rve,qHo),e(Cv,jHo),e(Cv,uW),e(uW,DHo),e(Cv,GHo),e(J,OHo),e(J,wv),e(wv,tve),e(tve,VHo),e(wv,XHo),e(wv,pW),e(pW,zHo),e(wv,QHo),e(J,WHo),e(J,Av),e(Av,ave),e(ave,UHo),e(Av,HHo),e(Av,_W),e(_W,JHo),e(Av,YHo),e(J,KHo),e(J,Lv),e(Lv,nve),e(nve,ZHo),e(Lv,eJo),e(Lv,bW),e(bW,oJo),e(Lv,rJo),e(J,tJo),e(J,yv),e(yv,sve),e(sve,aJo),e(yv,nJo),e(yv,vW),e(vW,sJo),e(yv,lJo),e(J,iJo),e(J,xv),e(xv,lve),e(lve,dJo),e(xv,mJo),e(xv,FW),e(FW,cJo),e(xv,fJo),e(J,gJo),e(J,$v),e($v,ive),e(ive,hJo),e($v,uJo),e($v,TW),e(TW,pJo),e($v,_Jo),e(J,bJo),e(J,kv),e(kv,dve),e(dve,vJo),e(kv,FJo),e(kv,MW),e(MW,TJo),e(kv,MJo),e(J,EJo),e(J,Sv),e(Sv,mve),e(mve,CJo),e(Sv,wJo),e(Sv,EW),e(EW,AJo),e(Sv,LJo),e(J,yJo),e(J,Rv),e(Rv,cve),e(cve,xJo),e(Rv,$Jo),e(Rv,CW),e(CW,kJo),e(Rv,SJo),e(J,RJo),e(J,Pv),e(Pv,fve),e(fve,PJo),e(Pv,BJo),e(Pv,wW),e(wW,IJo),e(Pv,NJo),e(J,qJo),e(J,Bv),e(Bv,gve),e(gve,jJo),e(Bv,DJo),e(Bv,AW),e(AW,GJo),e(Bv,OJo),e(J,VJo),e(J,Iv),e(Iv,hve),e(hve,XJo),e(Iv,zJo),e(Iv,LW),e(LW,QJo),e(Iv,WJo),e(J,UJo),e(J,Nv),e(Nv,uve),e(uve,HJo),e(Nv,JJo),e(Nv,yW),e(yW,YJo),e(Nv,KJo),e(J,ZJo),e(J,qv),e(qv,pve),e(pve,eYo),e(qv,oYo),e(qv,xW),e(xW,rYo),e(qv,tYo),e(J,aYo),e(J,jv),e(jv,_ve),e(_ve,nYo),e(jv,sYo),e(jv,$W),e($W,lYo),e(jv,iYo),e(J,dYo),e(J,Dv),e(Dv,bve),e(bve,mYo),e(Dv,cYo),e(Dv,kW),e(kW,fYo),e(Dv,gYo),e(J,hYo),e(J,Gv),e(Gv,vve),e(vve,uYo),e(Gv,pYo),e(Gv,SW),e(SW,_Yo),e(Gv,bYo),e(J,vYo),e(J,Ov),e(Ov,Fve),e(Fve,FYo),e(Ov,TYo),e(Ov,RW),e(RW,MYo),e(Ov,EYo),e(J,CYo),e(J,Vv),e(Vv,Tve),e(Tve,wYo),e(Vv,AYo),e(Vv,PW),e(PW,LYo),e(Vv,yYo),e(J,xYo),e(J,Xv),e(Xv,Mve),e(Mve,$Yo),e(Xv,kYo),e(Xv,BW),e(BW,SYo),e(Xv,RYo),e(J,PYo),e(J,zv),e(zv,Eve),e(Eve,BYo),e(zv,IYo),e(zv,IW),e(IW,NYo),e(zv,qYo),e(J,jYo),e(J,Qv),e(Qv,Cve),e(Cve,DYo),e(Qv,GYo),e(Qv,NW),e(NW,OYo),e(Qv,VYo),e(J,XYo),e(J,Wv),e(Wv,wve),e(wve,zYo),e(Wv,QYo),e(Wv,qW),e(qW,WYo),e(Wv,UYo),e(J,HYo),e(J,Uv),e(Uv,Ave),e(Ave,JYo),e(Uv,YYo),e(Uv,jW),e(jW,KYo),e(Uv,ZYo),e(J,eKo),e(J,Hv),e(Hv,Lve),e(Lve,oKo),e(Hv,rKo),e(Hv,DW),e(DW,tKo),e(Hv,aKo),e(J,nKo),e(J,Jv),e(Jv,yve),e(yve,sKo),e(Jv,lKo),e(Jv,xve),e(xve,iKo),e(Jv,dKo),e(J,mKo),e(J,Yv),e(Yv,$ve),e($ve,cKo),e(Yv,fKo),e(Yv,GW),e(GW,gKo),e(Yv,hKo),e(J,uKo),e(J,Kv),e(Kv,kve),e(kve,pKo),e(Kv,_Ko),e(Kv,OW),e(OW,bKo),e(Kv,vKo),e(J,FKo),e(J,Zv),e(Zv,Sve),e(Sve,TKo),e(Zv,MKo),e(Zv,VW),e(VW,EKo),e(Zv,CKo),e(J,wKo),e(J,eF),e(eF,Rve),e(Rve,AKo),e(eF,LKo),e(eF,XW),e(XW,yKo),e(eF,xKo),e(ro,$Ko),e(ro,oF),e(oF,kKo),e(oF,Pve),e(Pve,SKo),e(oF,RKo),e(oF,Bve),e(Bve,PKo),e(ro,BKo),M(rF,ro,null),b(c,leo,_),b(c,xd,_),e(xd,tF),e(tF,Ive),M(Qx,Ive,null),e(xd,IKo),e(xd,Nve),e(Nve,NKo),b(c,ieo,_),b(c,qo,_),M(Wx,qo,null),e(qo,qKo),e(qo,$d),e($d,jKo),e($d,zW),e(zW,DKo),e($d,GKo),e($d,QW),e(QW,OKo),e($d,VKo),e(qo,XKo),e(qo,Ux),e(Ux,zKo),e(Ux,qve),e(qve,QKo),e(Ux,WKo),e(qo,UKo),e(qo,Tt),M(Hx,Tt,null),e(Tt,HKo),e(Tt,jve),e(jve,JKo),e(Tt,YKo),e(Tt,kd),e(kd,KKo),e(kd,Dve),e(Dve,ZKo),e(kd,eZo),e(kd,WW),e(WW,oZo),e(kd,rZo),e(Tt,tZo),M(aF,Tt,null),e(qo,aZo),e(qo,to),M(Jx,to,null),e(to,nZo),e(to,Gve),e(Gve,sZo),e(to,lZo),e(to,en),e(en,iZo),e(en,Ove),e(Ove,dZo),e(en,mZo),e(en,Vve),e(Vve,cZo),e(en,fZo),e(en,Xve),e(Xve,gZo),e(en,hZo),e(to,uZo),e(to,fe),e(fe,nF),e(nF,zve),e(zve,pZo),e(nF,_Zo),e(nF,UW),e(UW,bZo),e(nF,vZo),e(fe,FZo),e(fe,sF),e(sF,Qve),e(Qve,TZo),e(sF,MZo),e(sF,HW),e(HW,EZo),e(sF,CZo),e(fe,wZo),e(fe,lF),e(lF,Wve),e(Wve,AZo),e(lF,LZo),e(lF,JW),e(JW,yZo),e(lF,xZo),e(fe,$Zo),e(fe,iF),e(iF,Uve),e(Uve,kZo),e(iF,SZo),e(iF,YW),e(YW,RZo),e(iF,PZo),e(fe,BZo),e(fe,dF),e(dF,Hve),e(Hve,IZo),e(dF,NZo),e(dF,KW),e(KW,qZo),e(dF,jZo),e(fe,DZo),e(fe,mF),e(mF,Jve),e(Jve,GZo),e(mF,OZo),e(mF,ZW),e(ZW,VZo),e(mF,XZo),e(fe,zZo),e(fe,cF),e(cF,Yve),e(Yve,QZo),e(cF,WZo),e(cF,eU),e(eU,UZo),e(cF,HZo),e(fe,JZo),e(fe,fF),e(fF,Kve),e(Kve,YZo),e(fF,KZo),e(fF,oU),e(oU,ZZo),e(fF,eer),e(fe,oer),e(fe,gF),e(gF,Zve),e(Zve,rer),e(gF,ter),e(gF,rU),e(rU,aer),e(gF,ner),e(fe,ser),e(fe,hF),e(hF,eFe),e(eFe,ler),e(hF,ier),e(hF,tU),e(tU,der),e(hF,mer),e(fe,cer),e(fe,uF),e(uF,oFe),e(oFe,fer),e(uF,ger),e(uF,aU),e(aU,her),e(uF,uer),e(fe,per),e(fe,pF),e(pF,rFe),e(rFe,_er),e(pF,ber),e(pF,nU),e(nU,ver),e(pF,Fer),e(fe,Ter),e(fe,_F),e(_F,tFe),e(tFe,Mer),e(_F,Eer),e(_F,sU),e(sU,Cer),e(_F,wer),e(fe,Aer),e(fe,bF),e(bF,aFe),e(aFe,Ler),e(bF,yer),e(bF,lU),e(lU,xer),e(bF,$er),e(fe,ker),e(fe,vF),e(vF,nFe),e(nFe,Ser),e(vF,Rer),e(vF,iU),e(iU,Per),e(vF,Ber),e(fe,Ier),e(fe,FF),e(FF,sFe),e(sFe,Ner),e(FF,qer),e(FF,dU),e(dU,jer),e(FF,Der),e(fe,Ger),e(fe,TF),e(TF,lFe),e(lFe,Oer),e(TF,Ver),e(TF,mU),e(mU,Xer),e(TF,zer),e(fe,Qer),e(fe,MF),e(MF,iFe),e(iFe,Wer),e(MF,Uer),e(MF,cU),e(cU,Her),e(MF,Jer),e(fe,Yer),e(fe,EF),e(EF,dFe),e(dFe,Ker),e(EF,Zer),e(EF,fU),e(fU,eor),e(EF,oor),e(fe,ror),e(fe,CF),e(CF,mFe),e(mFe,tor),e(CF,aor),e(CF,gU),e(gU,nor),e(CF,sor),e(to,lor),e(to,wF),e(wF,ior),e(wF,cFe),e(cFe,dor),e(wF,mor),e(wF,fFe),e(fFe,cor),e(to,gor),M(AF,to,null),b(c,deo,_),b(c,Sd,_),e(Sd,LF),e(LF,gFe),M(Yx,gFe,null),e(Sd,hor),e(Sd,hFe),e(hFe,uor),b(c,meo,_),b(c,jo,_),M(Kx,jo,null),e(jo,por),e(jo,Rd),e(Rd,_or),e(Rd,hU),e(hU,bor),e(Rd,vor),e(Rd,uU),e(uU,For),e(Rd,Tor),e(jo,Mor),e(jo,Zx),e(Zx,Eor),e(Zx,uFe),e(uFe,Cor),e(Zx,wor),e(jo,Aor),e(jo,Mt),M(e$,Mt,null),e(Mt,Lor),e(Mt,pFe),e(pFe,yor),e(Mt,xor),e(Mt,Pd),e(Pd,$or),e(Pd,_Fe),e(_Fe,kor),e(Pd,Sor),e(Pd,pU),e(pU,Ror),e(Pd,Por),e(Mt,Bor),M(yF,Mt,null),e(jo,Ior),e(jo,ao),M(o$,ao,null),e(ao,Nor),e(ao,bFe),e(bFe,qor),e(ao,jor),e(ao,on),e(on,Dor),e(on,vFe),e(vFe,Gor),e(on,Oor),e(on,FFe),e(FFe,Vor),e(on,Xor),e(on,TFe),e(TFe,zor),e(on,Qor),e(ao,Wor),e(ao,B),e(B,xF),e(xF,MFe),e(MFe,Uor),e(xF,Hor),e(xF,_U),e(_U,Jor),e(xF,Yor),e(B,Kor),e(B,$F),e($F,EFe),e(EFe,Zor),e($F,err),e($F,bU),e(bU,orr),e($F,rrr),e(B,trr),e(B,kF),e(kF,CFe),e(CFe,arr),e(kF,nrr),e(kF,vU),e(vU,srr),e(kF,lrr),e(B,irr),e(B,SF),e(SF,wFe),e(wFe,drr),e(SF,mrr),e(SF,FU),e(FU,crr),e(SF,frr),e(B,grr),e(B,RF),e(RF,AFe),e(AFe,hrr),e(RF,urr),e(RF,TU),e(TU,prr),e(RF,_rr),e(B,brr),e(B,PF),e(PF,LFe),e(LFe,vrr),e(PF,Frr),e(PF,MU),e(MU,Trr),e(PF,Mrr),e(B,Err),e(B,BF),e(BF,yFe),e(yFe,Crr),e(BF,wrr),e(BF,EU),e(EU,Arr),e(BF,Lrr),e(B,yrr),e(B,IF),e(IF,xFe),e(xFe,xrr),e(IF,$rr),e(IF,CU),e(CU,krr),e(IF,Srr),e(B,Rrr),e(B,NF),e(NF,$Fe),e($Fe,Prr),e(NF,Brr),e(NF,wU),e(wU,Irr),e(NF,Nrr),e(B,qrr),e(B,qF),e(qF,kFe),e(kFe,jrr),e(qF,Drr),e(qF,AU),e(AU,Grr),e(qF,Orr),e(B,Vrr),e(B,jF),e(jF,SFe),e(SFe,Xrr),e(jF,zrr),e(jF,LU),e(LU,Qrr),e(jF,Wrr),e(B,Urr),e(B,DF),e(DF,RFe),e(RFe,Hrr),e(DF,Jrr),e(DF,yU),e(yU,Yrr),e(DF,Krr),e(B,Zrr),e(B,GF),e(GF,PFe),e(PFe,etr),e(GF,otr),e(GF,xU),e(xU,rtr),e(GF,ttr),e(B,atr),e(B,OF),e(OF,BFe),e(BFe,ntr),e(OF,str),e(OF,$U),e($U,ltr),e(OF,itr),e(B,dtr),e(B,VF),e(VF,IFe),e(IFe,mtr),e(VF,ctr),e(VF,kU),e(kU,ftr),e(VF,gtr),e(B,htr),e(B,XF),e(XF,NFe),e(NFe,utr),e(XF,ptr),e(XF,SU),e(SU,_tr),e(XF,btr),e(B,vtr),e(B,zF),e(zF,qFe),e(qFe,Ftr),e(zF,Ttr),e(zF,RU),e(RU,Mtr),e(zF,Etr),e(B,Ctr),e(B,QF),e(QF,jFe),e(jFe,wtr),e(QF,Atr),e(QF,PU),e(PU,Ltr),e(QF,ytr),e(B,xtr),e(B,WF),e(WF,DFe),e(DFe,$tr),e(WF,ktr),e(WF,BU),e(BU,Str),e(WF,Rtr),e(B,Ptr),e(B,UF),e(UF,GFe),e(GFe,Btr),e(UF,Itr),e(UF,IU),e(IU,Ntr),e(UF,qtr),e(B,jtr),e(B,HF),e(HF,OFe),e(OFe,Dtr),e(HF,Gtr),e(HF,NU),e(NU,Otr),e(HF,Vtr),e(B,Xtr),e(B,JF),e(JF,VFe),e(VFe,ztr),e(JF,Qtr),e(JF,qU),e(qU,Wtr),e(JF,Utr),e(B,Htr),e(B,YF),e(YF,XFe),e(XFe,Jtr),e(YF,Ytr),e(YF,jU),e(jU,Ktr),e(YF,Ztr),e(B,ear),e(B,KF),e(KF,zFe),e(zFe,oar),e(KF,rar),e(KF,DU),e(DU,tar),e(KF,aar),e(B,nar),e(B,ZF),e(ZF,QFe),e(QFe,sar),e(ZF,lar),e(ZF,GU),e(GU,iar),e(ZF,dar),e(B,mar),e(B,eT),e(eT,WFe),e(WFe,car),e(eT,far),e(eT,OU),e(OU,gar),e(eT,har),e(B,uar),e(B,oT),e(oT,UFe),e(UFe,par),e(oT,_ar),e(oT,VU),e(VU,bar),e(oT,Far),e(B,Tar),e(B,rT),e(rT,HFe),e(HFe,Mar),e(rT,Ear),e(rT,XU),e(XU,Car),e(rT,war),e(B,Aar),e(B,tT),e(tT,JFe),e(JFe,Lar),e(tT,yar),e(tT,zU),e(zU,xar),e(tT,$ar),e(B,kar),e(B,aT),e(aT,YFe),e(YFe,Sar),e(aT,Rar),e(aT,QU),e(QU,Par),e(aT,Bar),e(B,Iar),e(B,nT),e(nT,KFe),e(KFe,Nar),e(nT,qar),e(nT,WU),e(WU,jar),e(nT,Dar),e(B,Gar),e(B,sT),e(sT,ZFe),e(ZFe,Oar),e(sT,Var),e(sT,UU),e(UU,Xar),e(sT,zar),e(B,Qar),e(B,lT),e(lT,eTe),e(eTe,War),e(lT,Uar),e(lT,HU),e(HU,Har),e(lT,Jar),e(B,Yar),e(B,iT),e(iT,oTe),e(oTe,Kar),e(iT,Zar),e(iT,JU),e(JU,enr),e(iT,onr),e(B,rnr),e(B,dT),e(dT,rTe),e(rTe,tnr),e(dT,anr),e(dT,YU),e(YU,nnr),e(dT,snr),e(B,lnr),e(B,mT),e(mT,tTe),e(tTe,inr),e(mT,dnr),e(mT,KU),e(KU,mnr),e(mT,cnr),e(B,fnr),e(B,cT),e(cT,aTe),e(aTe,gnr),e(cT,hnr),e(cT,ZU),e(ZU,unr),e(cT,pnr),e(B,_nr),e(B,fT),e(fT,nTe),e(nTe,bnr),e(fT,vnr),e(fT,eH),e(eH,Fnr),e(fT,Tnr),e(B,Mnr),e(B,gT),e(gT,sTe),e(sTe,Enr),e(gT,Cnr),e(gT,oH),e(oH,wnr),e(gT,Anr),e(B,Lnr),e(B,hT),e(hT,lTe),e(lTe,ynr),e(hT,xnr),e(hT,rH),e(rH,$nr),e(hT,knr),e(B,Snr),e(B,uT),e(uT,iTe),e(iTe,Rnr),e(uT,Pnr),e(uT,tH),e(tH,Bnr),e(uT,Inr),e(B,Nnr),e(B,pT),e(pT,dTe),e(dTe,qnr),e(pT,jnr),e(pT,aH),e(aH,Dnr),e(pT,Gnr),e(B,Onr),e(B,_T),e(_T,mTe),e(mTe,Vnr),e(_T,Xnr),e(_T,nH),e(nH,znr),e(_T,Qnr),e(B,Wnr),e(B,bT),e(bT,cTe),e(cTe,Unr),e(bT,Hnr),e(bT,sH),e(sH,Jnr),e(bT,Ynr),e(B,Knr),e(B,vT),e(vT,fTe),e(fTe,Znr),e(vT,esr),e(vT,lH),e(lH,osr),e(vT,rsr),e(B,tsr),e(B,FT),e(FT,gTe),e(gTe,asr),e(FT,nsr),e(FT,iH),e(iH,ssr),e(FT,lsr),e(B,isr),e(B,TT),e(TT,hTe),e(hTe,dsr),e(TT,msr),e(TT,dH),e(dH,csr),e(TT,fsr),e(B,gsr),e(B,MT),e(MT,uTe),e(uTe,hsr),e(MT,usr),e(MT,mH),e(mH,psr),e(MT,_sr),e(B,bsr),e(B,ET),e(ET,pTe),e(pTe,vsr),e(ET,Fsr),e(ET,cH),e(cH,Tsr),e(ET,Msr),e(B,Esr),e(B,CT),e(CT,_Te),e(_Te,Csr),e(CT,wsr),e(CT,fH),e(fH,Asr),e(CT,Lsr),e(B,ysr),e(B,wT),e(wT,bTe),e(bTe,xsr),e(wT,$sr),e(wT,gH),e(gH,ksr),e(wT,Ssr),e(B,Rsr),e(B,AT),e(AT,vTe),e(vTe,Psr),e(AT,Bsr),e(AT,hH),e(hH,Isr),e(AT,Nsr),e(B,qsr),e(B,LT),e(LT,FTe),e(FTe,jsr),e(LT,Dsr),e(LT,uH),e(uH,Gsr),e(LT,Osr),e(B,Vsr),e(B,yT),e(yT,TTe),e(TTe,Xsr),e(yT,zsr),e(yT,pH),e(pH,Qsr),e(yT,Wsr),e(B,Usr),e(B,xT),e(xT,MTe),e(MTe,Hsr),e(xT,Jsr),e(xT,_H),e(_H,Ysr),e(xT,Ksr),e(ao,Zsr),e(ao,$T),e($T,elr),e($T,ETe),e(ETe,olr),e($T,rlr),e($T,CTe),e(CTe,tlr),e(ao,alr),M(kT,ao,null),b(c,ceo,_),b(c,Bd,_),e(Bd,ST),e(ST,wTe),M(r$,wTe,null),e(Bd,nlr),e(Bd,ATe),e(ATe,slr),b(c,feo,_),b(c,Do,_),M(t$,Do,null),e(Do,llr),e(Do,Id),e(Id,ilr),e(Id,bH),e(bH,dlr),e(Id,mlr),e(Id,vH),e(vH,clr),e(Id,flr),e(Do,glr),e(Do,a$),e(a$,hlr),e(a$,LTe),e(LTe,ulr),e(a$,plr),e(Do,_lr),e(Do,Et),M(n$,Et,null),e(Et,blr),e(Et,yTe),e(yTe,vlr),e(Et,Flr),e(Et,Nd),e(Nd,Tlr),e(Nd,xTe),e(xTe,Mlr),e(Nd,Elr),e(Nd,FH),e(FH,Clr),e(Nd,wlr),e(Et,Alr),M(RT,Et,null),e(Do,Llr),e(Do,no),M(s$,no,null),e(no,ylr),e(no,$Te),e($Te,xlr),e(no,$lr),e(no,rn),e(rn,klr),e(rn,kTe),e(kTe,Slr),e(rn,Rlr),e(rn,STe),e(STe,Plr),e(rn,Blr),e(rn,RTe),e(RTe,Ilr),e(rn,Nlr),e(no,qlr),e(no,Z),e(Z,PT),e(PT,PTe),e(PTe,jlr),e(PT,Dlr),e(PT,TH),e(TH,Glr),e(PT,Olr),e(Z,Vlr),e(Z,BT),e(BT,BTe),e(BTe,Xlr),e(BT,zlr),e(BT,MH),e(MH,Qlr),e(BT,Wlr),e(Z,Ulr),e(Z,IT),e(IT,ITe),e(ITe,Hlr),e(IT,Jlr),e(IT,EH),e(EH,Ylr),e(IT,Klr),e(Z,Zlr),e(Z,NT),e(NT,NTe),e(NTe,eir),e(NT,oir),e(NT,CH),e(CH,rir),e(NT,tir),e(Z,air),e(Z,qT),e(qT,qTe),e(qTe,nir),e(qT,sir),e(qT,wH),e(wH,lir),e(qT,iir),e(Z,dir),e(Z,jT),e(jT,jTe),e(jTe,mir),e(jT,cir),e(jT,AH),e(AH,fir),e(jT,gir),e(Z,hir),e(Z,DT),e(DT,DTe),e(DTe,uir),e(DT,pir),e(DT,LH),e(LH,_ir),e(DT,bir),e(Z,vir),e(Z,GT),e(GT,GTe),e(GTe,Fir),e(GT,Tir),e(GT,yH),e(yH,Mir),e(GT,Eir),e(Z,Cir),e(Z,OT),e(OT,OTe),e(OTe,wir),e(OT,Air),e(OT,xH),e(xH,Lir),e(OT,yir),e(Z,xir),e(Z,VT),e(VT,VTe),e(VTe,$ir),e(VT,kir),e(VT,$H),e($H,Sir),e(VT,Rir),e(Z,Pir),e(Z,XT),e(XT,XTe),e(XTe,Bir),e(XT,Iir),e(XT,kH),e(kH,Nir),e(XT,qir),e(Z,jir),e(Z,zT),e(zT,zTe),e(zTe,Dir),e(zT,Gir),e(zT,SH),e(SH,Oir),e(zT,Vir),e(Z,Xir),e(Z,QT),e(QT,QTe),e(QTe,zir),e(QT,Qir),e(QT,RH),e(RH,Wir),e(QT,Uir),e(Z,Hir),e(Z,WT),e(WT,WTe),e(WTe,Jir),e(WT,Yir),e(WT,PH),e(PH,Kir),e(WT,Zir),e(Z,edr),e(Z,UT),e(UT,UTe),e(UTe,odr),e(UT,rdr),e(UT,BH),e(BH,tdr),e(UT,adr),e(Z,ndr),e(Z,HT),e(HT,HTe),e(HTe,sdr),e(HT,ldr),e(HT,IH),e(IH,idr),e(HT,ddr),e(Z,mdr),e(Z,JT),e(JT,JTe),e(JTe,cdr),e(JT,fdr),e(JT,NH),e(NH,gdr),e(JT,hdr),e(Z,udr),e(Z,YT),e(YT,YTe),e(YTe,pdr),e(YT,_dr),e(YT,qH),e(qH,bdr),e(YT,vdr),e(Z,Fdr),e(Z,KT),e(KT,KTe),e(KTe,Tdr),e(KT,Mdr),e(KT,jH),e(jH,Edr),e(KT,Cdr),e(Z,wdr),e(Z,ZT),e(ZT,ZTe),e(ZTe,Adr),e(ZT,Ldr),e(ZT,DH),e(DH,ydr),e(ZT,xdr),e(Z,$dr),e(Z,eM),e(eM,eMe),e(eMe,kdr),e(eM,Sdr),e(eM,GH),e(GH,Rdr),e(eM,Pdr),e(Z,Bdr),e(Z,oM),e(oM,oMe),e(oMe,Idr),e(oM,Ndr),e(oM,OH),e(OH,qdr),e(oM,jdr),e(Z,Ddr),e(Z,rM),e(rM,rMe),e(rMe,Gdr),e(rM,Odr),e(rM,VH),e(VH,Vdr),e(rM,Xdr),e(Z,zdr),e(Z,tM),e(tM,tMe),e(tMe,Qdr),e(tM,Wdr),e(tM,XH),e(XH,Udr),e(tM,Hdr),e(Z,Jdr),e(Z,aM),e(aM,aMe),e(aMe,Ydr),e(aM,Kdr),e(aM,zH),e(zH,Zdr),e(aM,emr),e(Z,omr),e(Z,nM),e(nM,nMe),e(nMe,rmr),e(nM,tmr),e(nM,QH),e(QH,amr),e(nM,nmr),e(Z,smr),e(Z,sM),e(sM,sMe),e(sMe,lmr),e(sM,imr),e(sM,WH),e(WH,dmr),e(sM,mmr),e(Z,cmr),e(Z,lM),e(lM,lMe),e(lMe,fmr),e(lM,gmr),e(lM,UH),e(UH,hmr),e(lM,umr),e(Z,pmr),e(Z,iM),e(iM,iMe),e(iMe,_mr),e(iM,bmr),e(iM,HH),e(HH,vmr),e(iM,Fmr),e(Z,Tmr),e(Z,dM),e(dM,dMe),e(dMe,Mmr),e(dM,Emr),e(dM,JH),e(JH,Cmr),e(dM,wmr),e(Z,Amr),e(Z,mM),e(mM,mMe),e(mMe,Lmr),e(mM,ymr),e(mM,YH),e(YH,xmr),e(mM,$mr),e(Z,kmr),e(Z,cM),e(cM,cMe),e(cMe,Smr),e(cM,Rmr),e(cM,KH),e(KH,Pmr),e(cM,Bmr),e(no,Imr),e(no,fM),e(fM,Nmr),e(fM,fMe),e(fMe,qmr),e(fM,jmr),e(fM,gMe),e(gMe,Dmr),e(no,Gmr),M(gM,no,null),b(c,geo,_),b(c,qd,_),e(qd,hM),e(hM,hMe),M(l$,hMe,null),e(qd,Omr),e(qd,uMe),e(uMe,Vmr),b(c,heo,_),b(c,Go,_),M(i$,Go,null),e(Go,Xmr),e(Go,jd),e(jd,zmr),e(jd,ZH),e(ZH,Qmr),e(jd,Wmr),e(jd,eJ),e(eJ,Umr),e(jd,Hmr),e(Go,Jmr),e(Go,d$),e(d$,Ymr),e(d$,pMe),e(pMe,Kmr),e(d$,Zmr),e(Go,ecr),e(Go,Ct),M(m$,Ct,null),e(Ct,ocr),e(Ct,_Me),e(_Me,rcr),e(Ct,tcr),e(Ct,Dd),e(Dd,acr),e(Dd,bMe),e(bMe,ncr),e(Dd,scr),e(Dd,oJ),e(oJ,lcr),e(Dd,icr),e(Ct,dcr),M(uM,Ct,null),e(Go,mcr),e(Go,so),M(c$,so,null),e(so,ccr),e(so,vMe),e(vMe,fcr),e(so,gcr),e(so,tn),e(tn,hcr),e(tn,FMe),e(FMe,ucr),e(tn,pcr),e(tn,TMe),e(TMe,_cr),e(tn,bcr),e(tn,MMe),e(MMe,vcr),e(tn,Fcr),e(so,Tcr),e(so,Ue),e(Ue,pM),e(pM,EMe),e(EMe,Mcr),e(pM,Ecr),e(pM,rJ),e(rJ,Ccr),e(pM,wcr),e(Ue,Acr),e(Ue,_M),e(_M,CMe),e(CMe,Lcr),e(_M,ycr),e(_M,tJ),e(tJ,xcr),e(_M,$cr),e(Ue,kcr),e(Ue,bM),e(bM,wMe),e(wMe,Scr),e(bM,Rcr),e(bM,aJ),e(aJ,Pcr),e(bM,Bcr),e(Ue,Icr),e(Ue,vM),e(vM,AMe),e(AMe,Ncr),e(vM,qcr),e(vM,nJ),e(nJ,jcr),e(vM,Dcr),e(Ue,Gcr),e(Ue,FM),e(FM,LMe),e(LMe,Ocr),e(FM,Vcr),e(FM,sJ),e(sJ,Xcr),e(FM,zcr),e(Ue,Qcr),e(Ue,TM),e(TM,yMe),e(yMe,Wcr),e(TM,Ucr),e(TM,lJ),e(lJ,Hcr),e(TM,Jcr),e(Ue,Ycr),e(Ue,MM),e(MM,xMe),e(xMe,Kcr),e(MM,Zcr),e(MM,iJ),e(iJ,efr),e(MM,ofr),e(so,rfr),e(so,EM),e(EM,tfr),e(EM,$Me),e($Me,afr),e(EM,nfr),e(EM,kMe),e(kMe,sfr),e(so,lfr),M(CM,so,null),b(c,ueo,_),b(c,Gd,_),e(Gd,wM),e(wM,SMe),M(f$,SMe,null),e(Gd,ifr),e(Gd,RMe),e(RMe,dfr),b(c,peo,_),b(c,Oo,_),M(g$,Oo,null),e(Oo,mfr),e(Oo,Od),e(Od,cfr),e(Od,dJ),e(dJ,ffr),e(Od,gfr),e(Od,mJ),e(mJ,hfr),e(Od,ufr),e(Oo,pfr),e(Oo,h$),e(h$,_fr),e(h$,PMe),e(PMe,bfr),e(h$,vfr),e(Oo,Ffr),e(Oo,wt),M(u$,wt,null),e(wt,Tfr),e(wt,BMe),e(BMe,Mfr),e(wt,Efr),e(wt,Vd),e(Vd,Cfr),e(Vd,IMe),e(IMe,wfr),e(Vd,Afr),e(Vd,cJ),e(cJ,Lfr),e(Vd,yfr),e(wt,xfr),M(AM,wt,null),e(Oo,$fr),e(Oo,lo),M(p$,lo,null),e(lo,kfr),e(lo,NMe),e(NMe,Sfr),e(lo,Rfr),e(lo,an),e(an,Pfr),e(an,qMe),e(qMe,Bfr),e(an,Ifr),e(an,jMe),e(jMe,Nfr),e(an,qfr),e(an,DMe),e(DMe,jfr),e(an,Dfr),e(lo,Gfr),e(lo,H),e(H,LM),e(LM,GMe),e(GMe,Ofr),e(LM,Vfr),e(LM,fJ),e(fJ,Xfr),e(LM,zfr),e(H,Qfr),e(H,yM),e(yM,OMe),e(OMe,Wfr),e(yM,Ufr),e(yM,gJ),e(gJ,Hfr),e(yM,Jfr),e(H,Yfr),e(H,xM),e(xM,VMe),e(VMe,Kfr),e(xM,Zfr),e(xM,hJ),e(hJ,egr),e(xM,ogr),e(H,rgr),e(H,$M),e($M,XMe),e(XMe,tgr),e($M,agr),e($M,uJ),e(uJ,ngr),e($M,sgr),e(H,lgr),e(H,kM),e(kM,zMe),e(zMe,igr),e(kM,dgr),e(kM,pJ),e(pJ,mgr),e(kM,cgr),e(H,fgr),e(H,SM),e(SM,QMe),e(QMe,ggr),e(SM,hgr),e(SM,_J),e(_J,ugr),e(SM,pgr),e(H,_gr),e(H,RM),e(RM,WMe),e(WMe,bgr),e(RM,vgr),e(RM,bJ),e(bJ,Fgr),e(RM,Tgr),e(H,Mgr),e(H,PM),e(PM,UMe),e(UMe,Egr),e(PM,Cgr),e(PM,vJ),e(vJ,wgr),e(PM,Agr),e(H,Lgr),e(H,BM),e(BM,HMe),e(HMe,ygr),e(BM,xgr),e(BM,FJ),e(FJ,$gr),e(BM,kgr),e(H,Sgr),e(H,IM),e(IM,JMe),e(JMe,Rgr),e(IM,Pgr),e(IM,TJ),e(TJ,Bgr),e(IM,Igr),e(H,Ngr),e(H,NM),e(NM,YMe),e(YMe,qgr),e(NM,jgr),e(NM,MJ),e(MJ,Dgr),e(NM,Ggr),e(H,Ogr),e(H,qM),e(qM,KMe),e(KMe,Vgr),e(qM,Xgr),e(qM,EJ),e(EJ,zgr),e(qM,Qgr),e(H,Wgr),e(H,jM),e(jM,ZMe),e(ZMe,Ugr),e(jM,Hgr),e(jM,CJ),e(CJ,Jgr),e(jM,Ygr),e(H,Kgr),e(H,DM),e(DM,eEe),e(eEe,Zgr),e(DM,ehr),e(DM,wJ),e(wJ,ohr),e(DM,rhr),e(H,thr),e(H,GM),e(GM,oEe),e(oEe,ahr),e(GM,nhr),e(GM,AJ),e(AJ,shr),e(GM,lhr),e(H,ihr),e(H,OM),e(OM,rEe),e(rEe,dhr),e(OM,mhr),e(OM,LJ),e(LJ,chr),e(OM,fhr),e(H,ghr),e(H,VM),e(VM,tEe),e(tEe,hhr),e(VM,uhr),e(VM,yJ),e(yJ,phr),e(VM,_hr),e(H,bhr),e(H,XM),e(XM,aEe),e(aEe,vhr),e(XM,Fhr),e(XM,xJ),e(xJ,Thr),e(XM,Mhr),e(H,Ehr),e(H,zM),e(zM,nEe),e(nEe,Chr),e(zM,whr),e(zM,$J),e($J,Ahr),e(zM,Lhr),e(H,yhr),e(H,QM),e(QM,sEe),e(sEe,xhr),e(QM,$hr),e(QM,kJ),e(kJ,khr),e(QM,Shr),e(H,Rhr),e(H,WM),e(WM,lEe),e(lEe,Phr),e(WM,Bhr),e(WM,SJ),e(SJ,Ihr),e(WM,Nhr),e(H,qhr),e(H,UM),e(UM,iEe),e(iEe,jhr),e(UM,Dhr),e(UM,RJ),e(RJ,Ghr),e(UM,Ohr),e(H,Vhr),e(H,HM),e(HM,dEe),e(dEe,Xhr),e(HM,zhr),e(HM,PJ),e(PJ,Qhr),e(HM,Whr),e(H,Uhr),e(H,JM),e(JM,mEe),e(mEe,Hhr),e(JM,Jhr),e(JM,BJ),e(BJ,Yhr),e(JM,Khr),e(H,Zhr),e(H,YM),e(YM,cEe),e(cEe,eur),e(YM,our),e(YM,IJ),e(IJ,rur),e(YM,tur),e(H,aur),e(H,KM),e(KM,fEe),e(fEe,nur),e(KM,sur),e(KM,NJ),e(NJ,lur),e(KM,iur),e(H,dur),e(H,ZM),e(ZM,gEe),e(gEe,mur),e(ZM,cur),e(ZM,qJ),e(qJ,fur),e(ZM,gur),e(H,hur),e(H,eE),e(eE,hEe),e(hEe,uur),e(eE,pur),e(eE,jJ),e(jJ,_ur),e(eE,bur),e(H,vur),e(H,oE),e(oE,uEe),e(uEe,Fur),e(oE,Tur),e(oE,DJ),e(DJ,Mur),e(oE,Eur),e(H,Cur),e(H,rE),e(rE,pEe),e(pEe,wur),e(rE,Aur),e(rE,GJ),e(GJ,Lur),e(rE,yur),e(H,xur),e(H,tE),e(tE,_Ee),e(_Ee,$ur),e(tE,kur),e(tE,OJ),e(OJ,Sur),e(tE,Rur),e(H,Pur),e(H,aE),e(aE,bEe),e(bEe,Bur),e(aE,Iur),e(aE,VJ),e(VJ,Nur),e(aE,qur),e(H,jur),e(H,nE),e(nE,vEe),e(vEe,Dur),e(nE,Gur),e(nE,XJ),e(XJ,Our),e(nE,Vur),e(H,Xur),e(H,sE),e(sE,FEe),e(FEe,zur),e(sE,Qur),e(sE,zJ),e(zJ,Wur),e(sE,Uur),e(H,Hur),e(H,lE),e(lE,TEe),e(TEe,Jur),e(lE,Yur),e(lE,QJ),e(QJ,Kur),e(lE,Zur),e(H,epr),e(H,iE),e(iE,MEe),e(MEe,opr),e(iE,rpr),e(iE,WJ),e(WJ,tpr),e(iE,apr),e(H,npr),e(H,dE),e(dE,EEe),e(EEe,spr),e(dE,lpr),e(dE,UJ),e(UJ,ipr),e(dE,dpr),e(H,mpr),e(H,mE),e(mE,CEe),e(CEe,cpr),e(mE,fpr),e(mE,HJ),e(HJ,gpr),e(mE,hpr),e(H,upr),e(H,cE),e(cE,wEe),e(wEe,ppr),e(cE,_pr),e(cE,JJ),e(JJ,bpr),e(cE,vpr),e(H,Fpr),e(H,fE),e(fE,AEe),e(AEe,Tpr),e(fE,Mpr),e(fE,YJ),e(YJ,Epr),e(fE,Cpr),e(lo,wpr),e(lo,gE),e(gE,Apr),e(gE,LEe),e(LEe,Lpr),e(gE,ypr),e(gE,yEe),e(yEe,xpr),e(lo,$pr),M(hE,lo,null),b(c,_eo,_),b(c,Xd,_),e(Xd,uE),e(uE,xEe),M(_$,xEe,null),e(Xd,kpr),e(Xd,$Ee),e($Ee,Spr),b(c,beo,_),b(c,Vo,_),M(b$,Vo,null),e(Vo,Rpr),e(Vo,zd),e(zd,Ppr),e(zd,KJ),e(KJ,Bpr),e(zd,Ipr),e(zd,ZJ),e(ZJ,Npr),e(zd,qpr),e(Vo,jpr),e(Vo,v$),e(v$,Dpr),e(v$,kEe),e(kEe,Gpr),e(v$,Opr),e(Vo,Vpr),e(Vo,At),M(F$,At,null),e(At,Xpr),e(At,SEe),e(SEe,zpr),e(At,Qpr),e(At,Qd),e(Qd,Wpr),e(Qd,REe),e(REe,Upr),e(Qd,Hpr),e(Qd,eY),e(eY,Jpr),e(Qd,Ypr),e(At,Kpr),M(pE,At,null),e(Vo,Zpr),e(Vo,io),M(T$,io,null),e(io,e_r),e(io,PEe),e(PEe,o_r),e(io,r_r),e(io,nn),e(nn,t_r),e(nn,BEe),e(BEe,a_r),e(nn,n_r),e(nn,IEe),e(IEe,s_r),e(nn,l_r),e(nn,NEe),e(NEe,i_r),e(nn,d_r),e(io,m_r),e(io,V),e(V,_E),e(_E,qEe),e(qEe,c_r),e(_E,f_r),e(_E,oY),e(oY,g_r),e(_E,h_r),e(V,u_r),e(V,bE),e(bE,jEe),e(jEe,p_r),e(bE,__r),e(bE,rY),e(rY,b_r),e(bE,v_r),e(V,F_r),e(V,vE),e(vE,DEe),e(DEe,T_r),e(vE,M_r),e(vE,tY),e(tY,E_r),e(vE,C_r),e(V,w_r),e(V,FE),e(FE,GEe),e(GEe,A_r),e(FE,L_r),e(FE,aY),e(aY,y_r),e(FE,x_r),e(V,$_r),e(V,TE),e(TE,OEe),e(OEe,k_r),e(TE,S_r),e(TE,nY),e(nY,R_r),e(TE,P_r),e(V,B_r),e(V,ME),e(ME,VEe),e(VEe,I_r),e(ME,N_r),e(ME,sY),e(sY,q_r),e(ME,j_r),e(V,D_r),e(V,EE),e(EE,XEe),e(XEe,G_r),e(EE,O_r),e(EE,lY),e(lY,V_r),e(EE,X_r),e(V,z_r),e(V,CE),e(CE,zEe),e(zEe,Q_r),e(CE,W_r),e(CE,iY),e(iY,U_r),e(CE,H_r),e(V,J_r),e(V,wE),e(wE,QEe),e(QEe,Y_r),e(wE,K_r),e(wE,dY),e(dY,Z_r),e(wE,e2r),e(V,o2r),e(V,AE),e(AE,WEe),e(WEe,r2r),e(AE,t2r),e(AE,mY),e(mY,a2r),e(AE,n2r),e(V,s2r),e(V,LE),e(LE,UEe),e(UEe,l2r),e(LE,i2r),e(LE,cY),e(cY,d2r),e(LE,m2r),e(V,c2r),e(V,yE),e(yE,HEe),e(HEe,f2r),e(yE,g2r),e(yE,fY),e(fY,h2r),e(yE,u2r),e(V,p2r),e(V,xE),e(xE,JEe),e(JEe,_2r),e(xE,b2r),e(xE,gY),e(gY,v2r),e(xE,F2r),e(V,T2r),e(V,$E),e($E,YEe),e(YEe,M2r),e($E,E2r),e($E,hY),e(hY,C2r),e($E,w2r),e(V,A2r),e(V,kE),e(kE,KEe),e(KEe,L2r),e(kE,y2r),e(kE,uY),e(uY,x2r),e(kE,$2r),e(V,k2r),e(V,SE),e(SE,ZEe),e(ZEe,S2r),e(SE,R2r),e(SE,pY),e(pY,P2r),e(SE,B2r),e(V,I2r),e(V,RE),e(RE,e4e),e(e4e,N2r),e(RE,q2r),e(RE,_Y),e(_Y,j2r),e(RE,D2r),e(V,G2r),e(V,PE),e(PE,o4e),e(o4e,O2r),e(PE,V2r),e(PE,bY),e(bY,X2r),e(PE,z2r),e(V,Q2r),e(V,BE),e(BE,r4e),e(r4e,W2r),e(BE,U2r),e(BE,vY),e(vY,H2r),e(BE,J2r),e(V,Y2r),e(V,IE),e(IE,t4e),e(t4e,K2r),e(IE,Z2r),e(IE,FY),e(FY,e1r),e(IE,o1r),e(V,r1r),e(V,NE),e(NE,a4e),e(a4e,t1r),e(NE,a1r),e(NE,TY),e(TY,n1r),e(NE,s1r),e(V,l1r),e(V,qE),e(qE,n4e),e(n4e,i1r),e(qE,d1r),e(qE,MY),e(MY,m1r),e(qE,c1r),e(V,f1r),e(V,jE),e(jE,s4e),e(s4e,g1r),e(jE,h1r),e(jE,EY),e(EY,u1r),e(jE,p1r),e(V,_1r),e(V,DE),e(DE,l4e),e(l4e,b1r),e(DE,v1r),e(DE,CY),e(CY,F1r),e(DE,T1r),e(V,M1r),e(V,GE),e(GE,i4e),e(i4e,E1r),e(GE,C1r),e(GE,wY),e(wY,w1r),e(GE,A1r),e(V,L1r),e(V,OE),e(OE,d4e),e(d4e,y1r),e(OE,x1r),e(OE,AY),e(AY,$1r),e(OE,k1r),e(V,S1r),e(V,VE),e(VE,m4e),e(m4e,R1r),e(VE,P1r),e(VE,LY),e(LY,B1r),e(VE,I1r),e(V,N1r),e(V,XE),e(XE,c4e),e(c4e,q1r),e(XE,j1r),e(XE,yY),e(yY,D1r),e(XE,G1r),e(V,O1r),e(V,zE),e(zE,f4e),e(f4e,V1r),e(zE,X1r),e(zE,xY),e(xY,z1r),e(zE,Q1r),e(V,W1r),e(V,QE),e(QE,g4e),e(g4e,U1r),e(QE,H1r),e(QE,$Y),e($Y,J1r),e(QE,Y1r),e(V,K1r),e(V,WE),e(WE,h4e),e(h4e,Z1r),e(WE,ebr),e(WE,kY),e(kY,obr),e(WE,rbr),e(V,tbr),e(V,UE),e(UE,u4e),e(u4e,abr),e(UE,nbr),e(UE,SY),e(SY,sbr),e(UE,lbr),e(V,ibr),e(V,HE),e(HE,p4e),e(p4e,dbr),e(HE,mbr),e(HE,RY),e(RY,cbr),e(HE,fbr),e(V,gbr),e(V,JE),e(JE,_4e),e(_4e,hbr),e(JE,ubr),e(JE,PY),e(PY,pbr),e(JE,_br),e(V,bbr),e(V,YE),e(YE,b4e),e(b4e,vbr),e(YE,Fbr),e(YE,BY),e(BY,Tbr),e(YE,Mbr),e(V,Ebr),e(V,KE),e(KE,v4e),e(v4e,Cbr),e(KE,wbr),e(KE,IY),e(IY,Abr),e(KE,Lbr),e(V,ybr),e(V,ZE),e(ZE,F4e),e(F4e,xbr),e(ZE,$br),e(ZE,NY),e(NY,kbr),e(ZE,Sbr),e(V,Rbr),e(V,e4),e(e4,T4e),e(T4e,Pbr),e(e4,Bbr),e(e4,qY),e(qY,Ibr),e(e4,Nbr),e(V,qbr),e(V,o4),e(o4,M4e),e(M4e,jbr),e(o4,Dbr),e(o4,jY),e(jY,Gbr),e(o4,Obr),e(V,Vbr),e(V,r4),e(r4,E4e),e(E4e,Xbr),e(r4,zbr),e(r4,DY),e(DY,Qbr),e(r4,Wbr),e(V,Ubr),e(V,t4),e(t4,C4e),e(C4e,Hbr),e(t4,Jbr),e(t4,GY),e(GY,Ybr),e(t4,Kbr),e(V,Zbr),e(V,a4),e(a4,w4e),e(w4e,evr),e(a4,ovr),e(a4,OY),e(OY,rvr),e(a4,tvr),e(V,avr),e(V,n4),e(n4,A4e),e(A4e,nvr),e(n4,svr),e(n4,VY),e(VY,lvr),e(n4,ivr),e(V,dvr),e(V,s4),e(s4,L4e),e(L4e,mvr),e(s4,cvr),e(s4,XY),e(XY,fvr),e(s4,gvr),e(V,hvr),e(V,l4),e(l4,y4e),e(y4e,uvr),e(l4,pvr),e(l4,zY),e(zY,_vr),e(l4,bvr),e(io,vvr),e(io,i4),e(i4,Fvr),e(i4,x4e),e(x4e,Tvr),e(i4,Mvr),e(i4,$4e),e($4e,Evr),e(io,Cvr),M(d4,io,null),b(c,veo,_),b(c,Wd,_),e(Wd,m4),e(m4,k4e),M(M$,k4e,null),e(Wd,wvr),e(Wd,S4e),e(S4e,Avr),b(c,Feo,_),b(c,Xo,_),M(E$,Xo,null),e(Xo,Lvr),e(Xo,Ud),e(Ud,yvr),e(Ud,QY),e(QY,xvr),e(Ud,$vr),e(Ud,WY),e(WY,kvr),e(Ud,Svr),e(Xo,Rvr),e(Xo,C$),e(C$,Pvr),e(C$,R4e),e(R4e,Bvr),e(C$,Ivr),e(Xo,Nvr),e(Xo,Lt),M(w$,Lt,null),e(Lt,qvr),e(Lt,P4e),e(P4e,jvr),e(Lt,Dvr),e(Lt,Hd),e(Hd,Gvr),e(Hd,B4e),e(B4e,Ovr),e(Hd,Vvr),e(Hd,UY),e(UY,Xvr),e(Hd,zvr),e(Lt,Qvr),M(c4,Lt,null),e(Xo,Wvr),e(Xo,mo),M(A$,mo,null),e(mo,Uvr),e(mo,I4e),e(I4e,Hvr),e(mo,Jvr),e(mo,sn),e(sn,Yvr),e(sn,N4e),e(N4e,Kvr),e(sn,Zvr),e(sn,q4e),e(q4e,eFr),e(sn,oFr),e(sn,j4e),e(j4e,rFr),e(sn,tFr),e(mo,aFr),e(mo,D4e),e(D4e,f4),e(f4,G4e),e(G4e,nFr),e(f4,sFr),e(f4,HY),e(HY,lFr),e(f4,iFr),e(mo,dFr),e(mo,g4),e(g4,mFr),e(g4,O4e),e(O4e,cFr),e(g4,fFr),e(g4,V4e),e(V4e,gFr),e(mo,hFr),M(h4,mo,null),b(c,Teo,_),b(c,Jd,_),e(Jd,u4),e(u4,X4e),M(L$,X4e,null),e(Jd,uFr),e(Jd,z4e),e(z4e,pFr),b(c,Meo,_),b(c,zo,_),M(y$,zo,null),e(zo,_Fr),e(zo,Yd),e(Yd,bFr),e(Yd,JY),e(JY,vFr),e(Yd,FFr),e(Yd,YY),e(YY,TFr),e(Yd,MFr),e(zo,EFr),e(zo,x$),e(x$,CFr),e(x$,Q4e),e(Q4e,wFr),e(x$,AFr),e(zo,LFr),e(zo,yt),M($$,yt,null),e(yt,yFr),e(yt,W4e),e(W4e,xFr),e(yt,$Fr),e(yt,Kd),e(Kd,kFr),e(Kd,U4e),e(U4e,SFr),e(Kd,RFr),e(Kd,KY),e(KY,PFr),e(Kd,BFr),e(yt,IFr),M(p4,yt,null),e(zo,NFr),e(zo,co),M(k$,co,null),e(co,qFr),e(co,H4e),e(H4e,jFr),e(co,DFr),e(co,ln),e(ln,GFr),e(ln,J4e),e(J4e,OFr),e(ln,VFr),e(ln,Y4e),e(Y4e,XFr),e(ln,zFr),e(ln,K4e),e(K4e,QFr),e(ln,WFr),e(co,UFr),e(co,Zd),e(Zd,_4),e(_4,Z4e),e(Z4e,HFr),e(_4,JFr),e(_4,ZY),e(ZY,YFr),e(_4,KFr),e(Zd,ZFr),e(Zd,b4),e(b4,eCe),e(eCe,eTr),e(b4,oTr),e(b4,eK),e(eK,rTr),e(b4,tTr),e(Zd,aTr),e(Zd,v4),e(v4,oCe),e(oCe,nTr),e(v4,sTr),e(v4,oK),e(oK,lTr),e(v4,iTr),e(co,dTr),e(co,F4),e(F4,mTr),e(F4,rCe),e(rCe,cTr),e(F4,fTr),e(F4,tCe),e(tCe,gTr),e(co,hTr),M(T4,co,null),b(c,Eeo,_),b(c,em,_),e(em,M4),e(M4,aCe),M(S$,aCe,null),e(em,uTr),e(em,nCe),e(nCe,pTr),b(c,Ceo,_),b(c,Qo,_),M(R$,Qo,null),e(Qo,_Tr),e(Qo,om),e(om,bTr),e(om,rK),e(rK,vTr),e(om,FTr),e(om,tK),e(tK,TTr),e(om,MTr),e(Qo,ETr),e(Qo,P$),e(P$,CTr),e(P$,sCe),e(sCe,wTr),e(P$,ATr),e(Qo,LTr),e(Qo,xt),M(B$,xt,null),e(xt,yTr),e(xt,lCe),e(lCe,xTr),e(xt,$Tr),e(xt,rm),e(rm,kTr),e(rm,iCe),e(iCe,STr),e(rm,RTr),e(rm,aK),e(aK,PTr),e(rm,BTr),e(xt,ITr),M(E4,xt,null),e(Qo,NTr),e(Qo,fo),M(I$,fo,null),e(fo,qTr),e(fo,dCe),e(dCe,jTr),e(fo,DTr),e(fo,dn),e(dn,GTr),e(dn,mCe),e(mCe,OTr),e(dn,VTr),e(dn,cCe),e(cCe,XTr),e(dn,zTr),e(dn,fCe),e(fCe,QTr),e(dn,WTr),e(fo,UTr),e(fo,be),e(be,C4),e(C4,gCe),e(gCe,HTr),e(C4,JTr),e(C4,nK),e(nK,YTr),e(C4,KTr),e(be,ZTr),e(be,w4),e(w4,hCe),e(hCe,eMr),e(w4,oMr),e(w4,sK),e(sK,rMr),e(w4,tMr),e(be,aMr),e(be,A4),e(A4,uCe),e(uCe,nMr),e(A4,sMr),e(A4,lK),e(lK,lMr),e(A4,iMr),e(be,dMr),e(be,L4),e(L4,pCe),e(pCe,mMr),e(L4,cMr),e(L4,iK),e(iK,fMr),e(L4,gMr),e(be,hMr),e(be,bl),e(bl,_Ce),e(_Ce,uMr),e(bl,pMr),e(bl,dK),e(dK,_Mr),e(bl,bMr),e(bl,mK),e(mK,vMr),e(bl,FMr),e(be,TMr),e(be,y4),e(y4,bCe),e(bCe,MMr),e(y4,EMr),e(y4,cK),e(cK,CMr),e(y4,wMr),e(be,AMr),e(be,vl),e(vl,vCe),e(vCe,LMr),e(vl,yMr),e(vl,fK),e(fK,xMr),e(vl,$Mr),e(vl,gK),e(gK,kMr),e(vl,SMr),e(be,RMr),e(be,x4),e(x4,FCe),e(FCe,PMr),e(x4,BMr),e(x4,hK),e(hK,IMr),e(x4,NMr),e(be,qMr),e(be,$t),e($t,TCe),e(TCe,jMr),e($t,DMr),e($t,uK),e(uK,GMr),e($t,OMr),e($t,pK),e(pK,VMr),e($t,XMr),e($t,_K),e(_K,zMr),e($t,QMr),e(be,WMr),e(be,$4),e($4,MCe),e(MCe,UMr),e($4,HMr),e($4,bK),e(bK,JMr),e($4,YMr),e(be,KMr),e(be,k4),e(k4,ECe),e(ECe,ZMr),e(k4,eEr),e(k4,vK),e(vK,oEr),e(k4,rEr),e(be,tEr),e(be,S4),e(S4,CCe),e(CCe,aEr),e(S4,nEr),e(S4,FK),e(FK,sEr),e(S4,lEr),e(be,iEr),e(be,R4),e(R4,wCe),e(wCe,dEr),e(R4,mEr),e(R4,TK),e(TK,cEr),e(R4,fEr),e(be,gEr),e(be,P4),e(P4,ACe),e(ACe,hEr),e(P4,uEr),e(P4,MK),e(MK,pEr),e(P4,_Er),e(be,bEr),e(be,B4),e(B4,LCe),e(LCe,vEr),e(B4,FEr),e(B4,EK),e(EK,TEr),e(B4,MEr),e(be,EEr),e(be,I4),e(I4,yCe),e(yCe,CEr),e(I4,wEr),e(I4,CK),e(CK,AEr),e(I4,LEr),e(be,yEr),e(be,N4),e(N4,xCe),e(xCe,xEr),e(N4,$Er),e(N4,wK),e(wK,kEr),e(N4,SEr),e(be,REr),e(be,q4),e(q4,$Ce),e($Ce,PEr),e(q4,BEr),e(q4,AK),e(AK,IEr),e(q4,NEr),e(fo,qEr),e(fo,j4),e(j4,jEr),e(j4,kCe),e(kCe,DEr),e(j4,GEr),e(j4,SCe),e(SCe,OEr),e(fo,VEr),M(D4,fo,null),b(c,weo,_),b(c,tm,_),e(tm,G4),e(G4,RCe),M(N$,RCe,null),e(tm,XEr),e(tm,PCe),e(PCe,zEr),b(c,Aeo,_),b(c,Wo,_),M(q$,Wo,null),e(Wo,QEr),e(Wo,am),e(am,WEr),e(am,LK),e(LK,UEr),e(am,HEr),e(am,yK),e(yK,JEr),e(am,YEr),e(Wo,KEr),e(Wo,j$),e(j$,ZEr),e(j$,BCe),e(BCe,e4r),e(j$,o4r),e(Wo,r4r),e(Wo,kt),M(D$,kt,null),e(kt,t4r),e(kt,ICe),e(ICe,a4r),e(kt,n4r),e(kt,nm),e(nm,s4r),e(nm,NCe),e(NCe,l4r),e(nm,i4r),e(nm,xK),e(xK,d4r),e(nm,m4r),e(kt,c4r),M(O4,kt,null),e(Wo,f4r),e(Wo,go),M(G$,go,null),e(go,g4r),e(go,qCe),e(qCe,h4r),e(go,u4r),e(go,mn),e(mn,p4r),e(mn,jCe),e(jCe,_4r),e(mn,b4r),e(mn,DCe),e(DCe,v4r),e(mn,F4r),e(mn,GCe),e(GCe,T4r),e(mn,M4r),e(go,E4r),e(go,OCe),e(OCe,V4),e(V4,VCe),e(VCe,C4r),e(V4,w4r),e(V4,$K),e($K,A4r),e(V4,L4r),e(go,y4r),e(go,X4),e(X4,x4r),e(X4,XCe),e(XCe,$4r),e(X4,k4r),e(X4,zCe),e(zCe,S4r),e(go,R4r),M(z4,go,null),b(c,Leo,_),b(c,sm,_),e(sm,Q4),e(Q4,QCe),M(O$,QCe,null),e(sm,P4r),e(sm,WCe),e(WCe,B4r),b(c,yeo,_),b(c,Uo,_),M(V$,Uo,null),e(Uo,I4r),e(Uo,lm),e(lm,N4r),e(lm,kK),e(kK,q4r),e(lm,j4r),e(lm,SK),e(SK,D4r),e(lm,G4r),e(Uo,O4r),e(Uo,X$),e(X$,V4r),e(X$,UCe),e(UCe,X4r),e(X$,z4r),e(Uo,Q4r),e(Uo,St),M(z$,St,null),e(St,W4r),e(St,HCe),e(HCe,U4r),e(St,H4r),e(St,im),e(im,J4r),e(im,JCe),e(JCe,Y4r),e(im,K4r),e(im,RK),e(RK,Z4r),e(im,eCr),e(St,oCr),M(W4,St,null),e(Uo,rCr),e(Uo,ho),M(Q$,ho,null),e(ho,tCr),e(ho,YCe),e(YCe,aCr),e(ho,nCr),e(ho,cn),e(cn,sCr),e(cn,KCe),e(KCe,lCr),e(cn,iCr),e(cn,ZCe),e(ZCe,dCr),e(cn,mCr),e(cn,e3e),e(e3e,cCr),e(cn,fCr),e(ho,gCr),e(ho,o3e),e(o3e,U4),e(U4,r3e),e(r3e,hCr),e(U4,uCr),e(U4,PK),e(PK,pCr),e(U4,_Cr),e(ho,bCr),e(ho,H4),e(H4,vCr),e(H4,t3e),e(t3e,FCr),e(H4,TCr),e(H4,a3e),e(a3e,MCr),e(ho,ECr),M(J4,ho,null),b(c,xeo,_),b(c,dm,_),e(dm,Y4),e(Y4,n3e),M(W$,n3e,null),e(dm,CCr),e(dm,s3e),e(s3e,wCr),b(c,$eo,_),b(c,Ho,_),M(U$,Ho,null),e(Ho,ACr),e(Ho,mm),e(mm,LCr),e(mm,BK),e(BK,yCr),e(mm,xCr),e(mm,IK),e(IK,$Cr),e(mm,kCr),e(Ho,SCr),e(Ho,H$),e(H$,RCr),e(H$,l3e),e(l3e,PCr),e(H$,BCr),e(Ho,ICr),e(Ho,Rt),M(J$,Rt,null),e(Rt,NCr),e(Rt,i3e),e(i3e,qCr),e(Rt,jCr),e(Rt,cm),e(cm,DCr),e(cm,d3e),e(d3e,GCr),e(cm,OCr),e(cm,NK),e(NK,VCr),e(cm,XCr),e(Rt,zCr),M(K4,Rt,null),e(Ho,QCr),e(Ho,uo),M(Y$,uo,null),e(uo,WCr),e(uo,m3e),e(m3e,UCr),e(uo,HCr),e(uo,fn),e(fn,JCr),e(fn,c3e),e(c3e,YCr),e(fn,KCr),e(fn,f3e),e(f3e,ZCr),e(fn,e3r),e(fn,g3e),e(g3e,o3r),e(fn,r3r),e(uo,t3r),e(uo,h3e),e(h3e,Z4),e(Z4,u3e),e(u3e,a3r),e(Z4,n3r),e(Z4,qK),e(qK,s3r),e(Z4,l3r),e(uo,i3r),e(uo,eC),e(eC,d3r),e(eC,p3e),e(p3e,m3r),e(eC,c3r),e(eC,_3e),e(_3e,f3r),e(uo,g3r),M(oC,uo,null),b(c,keo,_),b(c,fm,_),e(fm,rC),e(rC,b3e),M(K$,b3e,null),e(fm,h3r),e(fm,v3e),e(v3e,u3r),b(c,Seo,_),b(c,Jo,_),M(Z$,Jo,null),e(Jo,p3r),e(Jo,gm),e(gm,_3r),e(gm,jK),e(jK,b3r),e(gm,v3r),e(gm,DK),e(DK,F3r),e(gm,T3r),e(Jo,M3r),e(Jo,ek),e(ek,E3r),e(ek,F3e),e(F3e,C3r),e(ek,w3r),e(Jo,A3r),e(Jo,Pt),M(ok,Pt,null),e(Pt,L3r),e(Pt,T3e),e(T3e,y3r),e(Pt,x3r),e(Pt,hm),e(hm,$3r),e(hm,M3e),e(M3e,k3r),e(hm,S3r),e(hm,GK),e(GK,R3r),e(hm,P3r),e(Pt,B3r),M(tC,Pt,null),e(Jo,I3r),e(Jo,po),M(rk,po,null),e(po,N3r),e(po,E3e),e(E3e,q3r),e(po,j3r),e(po,gn),e(gn,D3r),e(gn,C3e),e(C3e,G3r),e(gn,O3r),e(gn,w3e),e(w3e,V3r),e(gn,X3r),e(gn,A3e),e(A3e,z3r),e(gn,Q3r),e(po,W3r),e(po,Pe),e(Pe,aC),e(aC,L3e),e(L3e,U3r),e(aC,H3r),e(aC,OK),e(OK,J3r),e(aC,Y3r),e(Pe,K3r),e(Pe,nC),e(nC,y3e),e(y3e,Z3r),e(nC,e5r),e(nC,VK),e(VK,o5r),e(nC,r5r),e(Pe,t5r),e(Pe,sC),e(sC,x3e),e(x3e,a5r),e(sC,n5r),e(sC,XK),e(XK,s5r),e(sC,l5r),e(Pe,i5r),e(Pe,lC),e(lC,$3e),e($3e,d5r),e(lC,m5r),e(lC,zK),e(zK,c5r),e(lC,f5r),e(Pe,g5r),e(Pe,iC),e(iC,k3e),e(k3e,h5r),e(iC,u5r),e(iC,QK),e(QK,p5r),e(iC,_5r),e(Pe,b5r),e(Pe,dC),e(dC,S3e),e(S3e,v5r),e(dC,F5r),e(dC,WK),e(WK,T5r),e(dC,M5r),e(Pe,E5r),e(Pe,mC),e(mC,R3e),e(R3e,C5r),e(mC,w5r),e(mC,UK),e(UK,A5r),e(mC,L5r),e(Pe,y5r),e(Pe,cC),e(cC,P3e),e(P3e,x5r),e(cC,$5r),e(cC,HK),e(HK,k5r),e(cC,S5r),e(Pe,R5r),e(Pe,fC),e(fC,B3e),e(B3e,P5r),e(fC,B5r),e(fC,JK),e(JK,I5r),e(fC,N5r),e(po,q5r),e(po,gC),e(gC,j5r),e(gC,I3e),e(I3e,D5r),e(gC,G5r),e(gC,N3e),e(N3e,O5r),e(po,V5r),M(hC,po,null),b(c,Reo,_),b(c,um,_),e(um,uC),e(uC,q3e),M(tk,q3e,null),e(um,X5r),e(um,j3e),e(j3e,z5r),b(c,Peo,_),b(c,Yo,_),M(ak,Yo,null),e(Yo,Q5r),e(Yo,pm),e(pm,W5r),e(pm,YK),e(YK,U5r),e(pm,H5r),e(pm,KK),e(KK,J5r),e(pm,Y5r),e(Yo,K5r),e(Yo,nk),e(nk,Z5r),e(nk,D3e),e(D3e,e0r),e(nk,o0r),e(Yo,r0r),e(Yo,Bt),M(sk,Bt,null),e(Bt,t0r),e(Bt,G3e),e(G3e,a0r),e(Bt,n0r),e(Bt,_m),e(_m,s0r),e(_m,O3e),e(O3e,l0r),e(_m,i0r),e(_m,ZK),e(ZK,d0r),e(_m,m0r),e(Bt,c0r),M(pC,Bt,null),e(Yo,f0r),e(Yo,_o),M(lk,_o,null),e(_o,g0r),e(_o,V3e),e(V3e,h0r),e(_o,u0r),e(_o,hn),e(hn,p0r),e(hn,X3e),e(X3e,_0r),e(hn,b0r),e(hn,z3e),e(z3e,v0r),e(hn,F0r),e(hn,Q3e),e(Q3e,T0r),e(hn,M0r),e(_o,E0r),e(_o,ct),e(ct,_C),e(_C,W3e),e(W3e,C0r),e(_C,w0r),e(_C,eZ),e(eZ,A0r),e(_C,L0r),e(ct,y0r),e(ct,bC),e(bC,U3e),e(U3e,x0r),e(bC,$0r),e(bC,oZ),e(oZ,k0r),e(bC,S0r),e(ct,R0r),e(ct,vC),e(vC,H3e),e(H3e,P0r),e(vC,B0r),e(vC,rZ),e(rZ,I0r),e(vC,N0r),e(ct,q0r),e(ct,FC),e(FC,J3e),e(J3e,j0r),e(FC,D0r),e(FC,tZ),e(tZ,G0r),e(FC,O0r),e(ct,V0r),e(ct,TC),e(TC,Y3e),e(Y3e,X0r),e(TC,z0r),e(TC,aZ),e(aZ,Q0r),e(TC,W0r),e(_o,U0r),e(_o,MC),e(MC,H0r),e(MC,K3e),e(K3e,J0r),e(MC,Y0r),e(MC,Z3e),e(Z3e,K0r),e(_o,Z0r),M(EC,_o,null),b(c,Beo,_),b(c,bm,_),e(bm,CC),e(CC,e5e),M(ik,e5e,null),e(bm,ewr),e(bm,o5e),e(o5e,owr),b(c,Ieo,_),b(c,Ko,_),M(dk,Ko,null),e(Ko,rwr),e(Ko,vm),e(vm,twr),e(vm,nZ),e(nZ,awr),e(vm,nwr),e(vm,sZ),e(sZ,swr),e(vm,lwr),e(Ko,iwr),e(Ko,mk),e(mk,dwr),e(mk,r5e),e(r5e,mwr),e(mk,cwr),e(Ko,fwr),e(Ko,It),M(ck,It,null),e(It,gwr),e(It,t5e),e(t5e,hwr),e(It,uwr),e(It,Fm),e(Fm,pwr),e(Fm,a5e),e(a5e,_wr),e(Fm,bwr),e(Fm,lZ),e(lZ,vwr),e(Fm,Fwr),e(It,Twr),M(wC,It,null),e(Ko,Mwr),e(Ko,bo),M(fk,bo,null),e(bo,Ewr),e(bo,n5e),e(n5e,Cwr),e(bo,wwr),e(bo,un),e(un,Awr),e(un,s5e),e(s5e,Lwr),e(un,ywr),e(un,l5e),e(l5e,xwr),e(un,$wr),e(un,i5e),e(i5e,kwr),e(un,Swr),e(bo,Rwr),e(bo,Le),e(Le,AC),e(AC,d5e),e(d5e,Pwr),e(AC,Bwr),e(AC,iZ),e(iZ,Iwr),e(AC,Nwr),e(Le,qwr),e(Le,LC),e(LC,m5e),e(m5e,jwr),e(LC,Dwr),e(LC,dZ),e(dZ,Gwr),e(LC,Owr),e(Le,Vwr),e(Le,yC),e(yC,c5e),e(c5e,Xwr),e(yC,zwr),e(yC,mZ),e(mZ,Qwr),e(yC,Wwr),e(Le,Uwr),e(Le,xC),e(xC,f5e),e(f5e,Hwr),e(xC,Jwr),e(xC,cZ),e(cZ,Ywr),e(xC,Kwr),e(Le,Zwr),e(Le,$C),e($C,g5e),e(g5e,eAr),e($C,oAr),e($C,fZ),e(fZ,rAr),e($C,tAr),e(Le,aAr),e(Le,kC),e(kC,h5e),e(h5e,nAr),e(kC,sAr),e(kC,gZ),e(gZ,lAr),e(kC,iAr),e(Le,dAr),e(Le,SC),e(SC,u5e),e(u5e,mAr),e(SC,cAr),e(SC,hZ),e(hZ,fAr),e(SC,gAr),e(Le,hAr),e(Le,RC),e(RC,p5e),e(p5e,uAr),e(RC,pAr),e(RC,uZ),e(uZ,_Ar),e(RC,bAr),e(Le,vAr),e(Le,PC),e(PC,_5e),e(_5e,FAr),e(PC,TAr),e(PC,pZ),e(pZ,MAr),e(PC,EAr),e(Le,CAr),e(Le,BC),e(BC,b5e),e(b5e,wAr),e(BC,AAr),e(BC,_Z),e(_Z,LAr),e(BC,yAr),e(bo,xAr),e(bo,IC),e(IC,$Ar),e(IC,v5e),e(v5e,kAr),e(IC,SAr),e(IC,F5e),e(F5e,RAr),e(bo,PAr),M(NC,bo,null),b(c,Neo,_),b(c,Tm,_),e(Tm,qC),e(qC,T5e),M(gk,T5e,null),e(Tm,BAr),e(Tm,M5e),e(M5e,IAr),b(c,qeo,_),b(c,Zo,_),M(hk,Zo,null),e(Zo,NAr),e(Zo,Mm),e(Mm,qAr),e(Mm,bZ),e(bZ,jAr),e(Mm,DAr),e(Mm,vZ),e(vZ,GAr),e(Mm,OAr),e(Zo,VAr),e(Zo,uk),e(uk,XAr),e(uk,E5e),e(E5e,zAr),e(uk,QAr),e(Zo,WAr),e(Zo,Nt),M(pk,Nt,null),e(Nt,UAr),e(Nt,C5e),e(C5e,HAr),e(Nt,JAr),e(Nt,Em),e(Em,YAr),e(Em,w5e),e(w5e,KAr),e(Em,ZAr),e(Em,FZ),e(FZ,e6r),e(Em,o6r),e(Nt,r6r),M(jC,Nt,null),e(Zo,t6r),e(Zo,vo),M(_k,vo,null),e(vo,a6r),e(vo,A5e),e(A5e,n6r),e(vo,s6r),e(vo,pn),e(pn,l6r),e(pn,L5e),e(L5e,i6r),e(pn,d6r),e(pn,y5e),e(y5e,m6r),e(pn,c6r),e(pn,x5e),e(x5e,f6r),e(pn,g6r),e(vo,h6r),e(vo,bk),e(bk,DC),e(DC,$5e),e($5e,u6r),e(DC,p6r),e(DC,TZ),e(TZ,_6r),e(DC,b6r),e(bk,v6r),e(bk,GC),e(GC,k5e),e(k5e,F6r),e(GC,T6r),e(GC,MZ),e(MZ,M6r),e(GC,E6r),e(vo,C6r),e(vo,OC),e(OC,w6r),e(OC,S5e),e(S5e,A6r),e(OC,L6r),e(OC,R5e),e(R5e,y6r),e(vo,x6r),M(VC,vo,null),b(c,jeo,_),b(c,Cm,_),e(Cm,XC),e(XC,P5e),M(vk,P5e,null),e(Cm,$6r),e(Cm,B5e),e(B5e,k6r),b(c,Deo,_),b(c,er,_),M(Fk,er,null),e(er,S6r),e(er,wm),e(wm,R6r),e(wm,EZ),e(EZ,P6r),e(wm,B6r),e(wm,CZ),e(CZ,I6r),e(wm,N6r),e(er,q6r),e(er,Tk),e(Tk,j6r),e(Tk,I5e),e(I5e,D6r),e(Tk,G6r),e(er,O6r),e(er,qt),M(Mk,qt,null),e(qt,V6r),e(qt,N5e),e(N5e,X6r),e(qt,z6r),e(qt,Am),e(Am,Q6r),e(Am,q5e),e(q5e,W6r),e(Am,U6r),e(Am,wZ),e(wZ,H6r),e(Am,J6r),e(qt,Y6r),M(zC,qt,null),e(er,K6r),e(er,Fo),M(Ek,Fo,null),e(Fo,Z6r),e(Fo,j5e),e(j5e,e7r),e(Fo,o7r),e(Fo,_n),e(_n,r7r),e(_n,D5e),e(D5e,t7r),e(_n,a7r),e(_n,G5e),e(G5e,n7r),e(_n,s7r),e(_n,O5e),e(O5e,l7r),e(_n,i7r),e(Fo,d7r),e(Fo,ft),e(ft,QC),e(QC,V5e),e(V5e,m7r),e(QC,c7r),e(QC,AZ),e(AZ,f7r),e(QC,g7r),e(ft,h7r),e(ft,WC),e(WC,X5e),e(X5e,u7r),e(WC,p7r),e(WC,LZ),e(LZ,_7r),e(WC,b7r),e(ft,v7r),e(ft,UC),e(UC,z5e),e(z5e,F7r),e(UC,T7r),e(UC,yZ),e(yZ,M7r),e(UC,E7r),e(ft,C7r),e(ft,HC),e(HC,Q5e),e(Q5e,w7r),e(HC,A7r),e(HC,xZ),e(xZ,L7r),e(HC,y7r),e(ft,x7r),e(ft,JC),e(JC,W5e),e(W5e,$7r),e(JC,k7r),e(JC,$Z),e($Z,S7r),e(JC,R7r),e(Fo,P7r),e(Fo,YC),e(YC,B7r),e(YC,U5e),e(U5e,I7r),e(YC,N7r),e(YC,H5e),e(H5e,q7r),e(Fo,j7r),M(KC,Fo,null),b(c,Geo,_),b(c,Lm,_),e(Lm,ZC),e(ZC,J5e),M(Ck,J5e,null),e(Lm,D7r),e(Lm,Y5e),e(Y5e,G7r),b(c,Oeo,_),b(c,or,_),M(wk,or,null),e(or,O7r),e(or,ym),e(ym,V7r),e(ym,kZ),e(kZ,X7r),e(ym,z7r),e(ym,SZ),e(SZ,Q7r),e(ym,W7r),e(or,U7r),e(or,Ak),e(Ak,H7r),e(Ak,K5e),e(K5e,J7r),e(Ak,Y7r),e(or,K7r),e(or,jt),M(Lk,jt,null),e(jt,Z7r),e(jt,Z5e),e(Z5e,eLr),e(jt,oLr),e(jt,xm),e(xm,rLr),e(xm,e0e),e(e0e,tLr),e(xm,aLr),e(xm,RZ),e(RZ,nLr),e(xm,sLr),e(jt,lLr),M(e3,jt,null),e(or,iLr),e(or,To),M(yk,To,null),e(To,dLr),e(To,o0e),e(o0e,mLr),e(To,cLr),e(To,bn),e(bn,fLr),e(bn,r0e),e(r0e,gLr),e(bn,hLr),e(bn,t0e),e(t0e,uLr),e(bn,pLr),e(bn,a0e),e(a0e,_Lr),e(bn,bLr),e(To,vLr),e(To,vn),e(vn,o3),e(o3,n0e),e(n0e,FLr),e(o3,TLr),e(o3,PZ),e(PZ,MLr),e(o3,ELr),e(vn,CLr),e(vn,r3),e(r3,s0e),e(s0e,wLr),e(r3,ALr),e(r3,BZ),e(BZ,LLr),e(r3,yLr),e(vn,xLr),e(vn,t3),e(t3,l0e),e(l0e,$Lr),e(t3,kLr),e(t3,IZ),e(IZ,SLr),e(t3,RLr),e(vn,PLr),e(vn,a3),e(a3,i0e),e(i0e,BLr),e(a3,ILr),e(a3,NZ),e(NZ,NLr),e(a3,qLr),e(To,jLr),e(To,n3),e(n3,DLr),e(n3,d0e),e(d0e,GLr),e(n3,OLr),e(n3,m0e),e(m0e,VLr),e(To,XLr),M(s3,To,null),b(c,Veo,_),b(c,$m,_),e($m,l3),e(l3,c0e),M(xk,c0e,null),e($m,zLr),e($m,f0e),e(f0e,QLr),b(c,Xeo,_),b(c,rr,_),M($k,rr,null),e(rr,WLr),e(rr,km),e(km,ULr),e(km,qZ),e(qZ,HLr),e(km,JLr),e(km,jZ),e(jZ,YLr),e(km,KLr),e(rr,ZLr),e(rr,kk),e(kk,eyr),e(kk,g0e),e(g0e,oyr),e(kk,ryr),e(rr,tyr),e(rr,Dt),M(Sk,Dt,null),e(Dt,ayr),e(Dt,h0e),e(h0e,nyr),e(Dt,syr),e(Dt,Sm),e(Sm,lyr),e(Sm,u0e),e(u0e,iyr),e(Sm,dyr),e(Sm,DZ),e(DZ,myr),e(Sm,cyr),e(Dt,fyr),M(i3,Dt,null),e(rr,gyr),e(rr,Mo),M(Rk,Mo,null),e(Mo,hyr),e(Mo,p0e),e(p0e,uyr),e(Mo,pyr),e(Mo,Fn),e(Fn,_yr),e(Fn,_0e),e(_0e,byr),e(Fn,vyr),e(Fn,b0e),e(b0e,Fyr),e(Fn,Tyr),e(Fn,v0e),e(v0e,Myr),e(Fn,Eyr),e(Mo,Cyr),e(Mo,Tn),e(Tn,d3),e(d3,F0e),e(F0e,wyr),e(d3,Ayr),e(d3,GZ),e(GZ,Lyr),e(d3,yyr),e(Tn,xyr),e(Tn,m3),e(m3,T0e),e(T0e,$yr),e(m3,kyr),e(m3,OZ),e(OZ,Syr),e(m3,Ryr),e(Tn,Pyr),e(Tn,c3),e(c3,M0e),e(M0e,Byr),e(c3,Iyr),e(c3,VZ),e(VZ,Nyr),e(c3,qyr),e(Tn,jyr),e(Tn,f3),e(f3,E0e),e(E0e,Dyr),e(f3,Gyr),e(f3,XZ),e(XZ,Oyr),e(f3,Vyr),e(Mo,Xyr),e(Mo,g3),e(g3,zyr),e(g3,C0e),e(C0e,Qyr),e(g3,Wyr),e(g3,w0e),e(w0e,Uyr),e(Mo,Hyr),M(h3,Mo,null),b(c,zeo,_),b(c,Rm,_),e(Rm,u3),e(u3,A0e),M(Pk,A0e,null),e(Rm,Jyr),e(Rm,L0e),e(L0e,Yyr),b(c,Qeo,_),b(c,tr,_),M(Bk,tr,null),e(tr,Kyr),e(tr,Pm),e(Pm,Zyr),e(Pm,zZ),e(zZ,e8r),e(Pm,o8r),e(Pm,QZ),e(QZ,r8r),e(Pm,t8r),e(tr,a8r),e(tr,Ik),e(Ik,n8r),e(Ik,y0e),e(y0e,s8r),e(Ik,l8r),e(tr,i8r),e(tr,Gt),M(Nk,Gt,null),e(Gt,d8r),e(Gt,x0e),e(x0e,m8r),e(Gt,c8r),e(Gt,Bm),e(Bm,f8r),e(Bm,$0e),e($0e,g8r),e(Bm,h8r),e(Bm,WZ),e(WZ,u8r),e(Bm,p8r),e(Gt,_8r),M(p3,Gt,null),e(tr,b8r),e(tr,Eo),M(qk,Eo,null),e(Eo,v8r),e(Eo,k0e),e(k0e,F8r),e(Eo,T8r),e(Eo,Mn),e(Mn,M8r),e(Mn,S0e),e(S0e,E8r),e(Mn,C8r),e(Mn,R0e),e(R0e,w8r),e(Mn,A8r),e(Mn,P0e),e(P0e,L8r),e(Mn,y8r),e(Eo,x8r),e(Eo,B0e),e(B0e,_3),e(_3,I0e),e(I0e,$8r),e(_3,k8r),e(_3,UZ),e(UZ,S8r),e(_3,R8r),e(Eo,P8r),e(Eo,b3),e(b3,B8r),e(b3,N0e),e(N0e,I8r),e(b3,N8r),e(b3,q0e),e(q0e,q8r),e(Eo,j8r),M(v3,Eo,null),b(c,Weo,_),b(c,Im,_),e(Im,F3),e(F3,j0e),M(jk,j0e,null),e(Im,D8r),e(Im,D0e),e(D0e,G8r),b(c,Ueo,_),b(c,ar,_),M(Dk,ar,null),e(ar,O8r),e(ar,Nm),e(Nm,V8r),e(Nm,HZ),e(HZ,X8r),e(Nm,z8r),e(Nm,JZ),e(JZ,Q8r),e(Nm,W8r),e(ar,U8r),e(ar,Gk),e(Gk,H8r),e(Gk,G0e),e(G0e,J8r),e(Gk,Y8r),e(ar,K8r),e(ar,Ot),M(Ok,Ot,null),e(Ot,Z8r),e(Ot,O0e),e(O0e,e9r),e(Ot,o9r),e(Ot,qm),e(qm,r9r),e(qm,V0e),e(V0e,t9r),e(qm,a9r),e(qm,YZ),e(YZ,n9r),e(qm,s9r),e(Ot,l9r),M(T3,Ot,null),e(ar,i9r),e(ar,Co),M(Vk,Co,null),e(Co,d9r),e(Co,X0e),e(X0e,m9r),e(Co,c9r),e(Co,En),e(En,f9r),e(En,z0e),e(z0e,g9r),e(En,h9r),e(En,Q0e),e(Q0e,u9r),e(En,p9r),e(En,W0e),e(W0e,_9r),e(En,b9r),e(Co,v9r),e(Co,gt),e(gt,M3),e(M3,U0e),e(U0e,F9r),e(M3,T9r),e(M3,KZ),e(KZ,M9r),e(M3,E9r),e(gt,C9r),e(gt,E3),e(E3,H0e),e(H0e,w9r),e(E3,A9r),e(E3,ZZ),e(ZZ,L9r),e(E3,y9r),e(gt,x9r),e(gt,C3),e(C3,J0e),e(J0e,$9r),e(C3,k9r),e(C3,eee),e(eee,S9r),e(C3,R9r),e(gt,P9r),e(gt,w3),e(w3,Y0e),e(Y0e,B9r),e(w3,I9r),e(w3,oee),e(oee,N9r),e(w3,q9r),e(gt,j9r),e(gt,A3),e(A3,K0e),e(K0e,D9r),e(A3,G9r),e(A3,ree),e(ree,O9r),e(A3,V9r),e(Co,X9r),e(Co,L3),e(L3,z9r),e(L3,Z0e),e(Z0e,Q9r),e(L3,W9r),e(L3,ewe),e(ewe,U9r),e(Co,H9r),M(y3,Co,null),b(c,Heo,_),b(c,jm,_),e(jm,x3),e(x3,owe),M(Xk,owe,null),e(jm,J9r),e(jm,rwe),e(rwe,Y9r),b(c,Jeo,_),b(c,nr,_),M(zk,nr,null),e(nr,K9r),e(nr,Dm),e(Dm,Z9r),e(Dm,tee),e(tee,exr),e(Dm,oxr),e(Dm,aee),e(aee,rxr),e(Dm,txr),e(nr,axr),e(nr,Qk),e(Qk,nxr),e(Qk,twe),e(twe,sxr),e(Qk,lxr),e(nr,ixr),e(nr,Vt),M(Wk,Vt,null),e(Vt,dxr),e(Vt,awe),e(awe,mxr),e(Vt,cxr),e(Vt,Gm),e(Gm,fxr),e(Gm,nwe),e(nwe,gxr),e(Gm,hxr),e(Gm,nee),e(nee,uxr),e(Gm,pxr),e(Vt,_xr),M($3,Vt,null),e(nr,bxr),e(nr,wo),M(Uk,wo,null),e(wo,vxr),e(wo,swe),e(swe,Fxr),e(wo,Txr),e(wo,Cn),e(Cn,Mxr),e(Cn,lwe),e(lwe,Exr),e(Cn,Cxr),e(Cn,iwe),e(iwe,wxr),e(Cn,Axr),e(Cn,dwe),e(dwe,Lxr),e(Cn,yxr),e(wo,xxr),e(wo,mwe),e(mwe,k3),e(k3,cwe),e(cwe,$xr),e(k3,kxr),e(k3,see),e(see,Sxr),e(k3,Rxr),e(wo,Pxr),e(wo,S3),e(S3,Bxr),e(S3,fwe),e(fwe,Ixr),e(S3,Nxr),e(S3,gwe),e(gwe,qxr),e(wo,jxr),M(R3,wo,null),b(c,Yeo,_),b(c,Om,_),e(Om,P3),e(P3,hwe),M(Hk,hwe,null),e(Om,Dxr),e(Om,uwe),e(uwe,Gxr),b(c,Keo,_),b(c,sr,_),M(Jk,sr,null),e(sr,Oxr),e(sr,Vm),e(Vm,Vxr),e(Vm,lee),e(lee,Xxr),e(Vm,zxr),e(Vm,iee),e(iee,Qxr),e(Vm,Wxr),e(sr,Uxr),e(sr,Yk),e(Yk,Hxr),e(Yk,pwe),e(pwe,Jxr),e(Yk,Yxr),e(sr,Kxr),e(sr,Xt),M(Kk,Xt,null),e(Xt,Zxr),e(Xt,_we),e(_we,e$r),e(Xt,o$r),e(Xt,Xm),e(Xm,r$r),e(Xm,bwe),e(bwe,t$r),e(Xm,a$r),e(Xm,dee),e(dee,n$r),e(Xm,s$r),e(Xt,l$r),M(B3,Xt,null),e(sr,i$r),e(sr,Ir),M(Zk,Ir,null),e(Ir,d$r),e(Ir,vwe),e(vwe,m$r),e(Ir,c$r),e(Ir,wn),e(wn,f$r),e(wn,Fwe),e(Fwe,g$r),e(wn,h$r),e(wn,Twe),e(Twe,u$r),e(wn,p$r),e(wn,Mwe),e(Mwe,_$r),e(wn,b$r),e(Ir,v$r),e(Ir,I),e(I,I3),e(I3,Ewe),e(Ewe,F$r),e(I3,T$r),e(I3,mee),e(mee,M$r),e(I3,E$r),e(I,C$r),e(I,N3),e(N3,Cwe),e(Cwe,w$r),e(N3,A$r),e(N3,cee),e(cee,L$r),e(N3,y$r),e(I,x$r),e(I,q3),e(q3,wwe),e(wwe,$$r),e(q3,k$r),e(q3,fee),e(fee,S$r),e(q3,R$r),e(I,P$r),e(I,j3),e(j3,Awe),e(Awe,B$r),e(j3,I$r),e(j3,gee),e(gee,N$r),e(j3,q$r),e(I,j$r),e(I,D3),e(D3,Lwe),e(Lwe,D$r),e(D3,G$r),e(D3,hee),e(hee,O$r),e(D3,V$r),e(I,X$r),e(I,G3),e(G3,ywe),e(ywe,z$r),e(G3,Q$r),e(G3,uee),e(uee,W$r),e(G3,U$r),e(I,H$r),e(I,O3),e(O3,xwe),e(xwe,J$r),e(O3,Y$r),e(O3,pee),e(pee,K$r),e(O3,Z$r),e(I,ekr),e(I,V3),e(V3,$we),e($we,okr),e(V3,rkr),e(V3,_ee),e(_ee,tkr),e(V3,akr),e(I,nkr),e(I,X3),e(X3,kwe),e(kwe,skr),e(X3,lkr),e(X3,bee),e(bee,ikr),e(X3,dkr),e(I,mkr),e(I,z3),e(z3,Swe),e(Swe,ckr),e(z3,fkr),e(z3,vee),e(vee,gkr),e(z3,hkr),e(I,ukr),e(I,Q3),e(Q3,Rwe),e(Rwe,pkr),e(Q3,_kr),e(Q3,Fee),e(Fee,bkr),e(Q3,vkr),e(I,Fkr),e(I,W3),e(W3,Pwe),e(Pwe,Tkr),e(W3,Mkr),e(W3,Tee),e(Tee,Ekr),e(W3,Ckr),e(I,wkr),e(I,U3),e(U3,Bwe),e(Bwe,Akr),e(U3,Lkr),e(U3,Mee),e(Mee,ykr),e(U3,xkr),e(I,$kr),e(I,H3),e(H3,Iwe),e(Iwe,kkr),e(H3,Skr),e(H3,Eee),e(Eee,Rkr),e(H3,Pkr),e(I,Bkr),e(I,J3),e(J3,Nwe),e(Nwe,Ikr),e(J3,Nkr),e(J3,Cee),e(Cee,qkr),e(J3,jkr),e(I,Dkr),e(I,Y3),e(Y3,qwe),e(qwe,Gkr),e(Y3,Okr),e(Y3,wee),e(wee,Vkr),e(Y3,Xkr),e(I,zkr),e(I,K3),e(K3,jwe),e(jwe,Qkr),e(K3,Wkr),e(K3,Aee),e(Aee,Ukr),e(K3,Hkr),e(I,Jkr),e(I,Z3),e(Z3,Dwe),e(Dwe,Ykr),e(Z3,Kkr),e(Z3,Lee),e(Lee,Zkr),e(Z3,eSr),e(I,oSr),e(I,Fl),e(Fl,Gwe),e(Gwe,rSr),e(Fl,tSr),e(Fl,yee),e(yee,aSr),e(Fl,nSr),e(Fl,xee),e(xee,sSr),e(Fl,lSr),e(I,iSr),e(I,e5),e(e5,Owe),e(Owe,dSr),e(e5,mSr),e(e5,$ee),e($ee,cSr),e(e5,fSr),e(I,gSr),e(I,o5),e(o5,Vwe),e(Vwe,hSr),e(o5,uSr),e(o5,kee),e(kee,pSr),e(o5,_Sr),e(I,bSr),e(I,r5),e(r5,Xwe),e(Xwe,vSr),e(r5,FSr),e(r5,See),e(See,TSr),e(r5,MSr),e(I,ESr),e(I,t5),e(t5,zwe),e(zwe,CSr),e(t5,wSr),e(t5,Ree),e(Ree,ASr),e(t5,LSr),e(I,ySr),e(I,a5),e(a5,Qwe),e(Qwe,xSr),e(a5,$Sr),e(a5,Pee),e(Pee,kSr),e(a5,SSr),e(I,RSr),e(I,n5),e(n5,Wwe),e(Wwe,PSr),e(n5,BSr),e(n5,Bee),e(Bee,ISr),e(n5,NSr),e(I,qSr),e(I,s5),e(s5,Uwe),e(Uwe,jSr),e(s5,DSr),e(s5,Iee),e(Iee,GSr),e(s5,OSr),e(I,VSr),e(I,l5),e(l5,Hwe),e(Hwe,XSr),e(l5,zSr),e(l5,Nee),e(Nee,QSr),e(l5,WSr),e(I,USr),e(I,i5),e(i5,Jwe),e(Jwe,HSr),e(i5,JSr),e(i5,qee),e(qee,YSr),e(i5,KSr),e(I,ZSr),e(I,d5),e(d5,Ywe),e(Ywe,eRr),e(d5,oRr),e(d5,jee),e(jee,rRr),e(d5,tRr),e(I,aRr),e(I,m5),e(m5,Kwe),e(Kwe,nRr),e(m5,sRr),e(m5,Dee),e(Dee,lRr),e(m5,iRr),e(I,dRr),e(I,c5),e(c5,Zwe),e(Zwe,mRr),e(c5,cRr),e(c5,Gee),e(Gee,fRr),e(c5,gRr),e(I,hRr),e(I,f5),e(f5,eAe),e(eAe,uRr),e(f5,pRr),e(f5,Oee),e(Oee,_Rr),e(f5,bRr),e(I,vRr),e(I,g5),e(g5,oAe),e(oAe,FRr),e(g5,TRr),e(g5,Vee),e(Vee,MRr),e(g5,ERr),e(I,CRr),e(I,h5),e(h5,rAe),e(rAe,wRr),e(h5,ARr),e(h5,Xee),e(Xee,LRr),e(h5,yRr),e(I,xRr),e(I,u5),e(u5,tAe),e(tAe,$Rr),e(u5,kRr),e(u5,zee),e(zee,SRr),e(u5,RRr),e(I,PRr),e(I,p5),e(p5,aAe),e(aAe,BRr),e(p5,IRr),e(p5,Qee),e(Qee,NRr),e(p5,qRr),e(I,jRr),e(I,_5),e(_5,nAe),e(nAe,DRr),e(_5,GRr),e(_5,Wee),e(Wee,ORr),e(_5,VRr),e(I,XRr),e(I,b5),e(b5,sAe),e(sAe,zRr),e(b5,QRr),e(b5,Uee),e(Uee,WRr),e(b5,URr),e(I,HRr),e(I,v5),e(v5,lAe),e(lAe,JRr),e(v5,YRr),e(v5,Hee),e(Hee,KRr),e(v5,ZRr),e(I,ePr),e(I,F5),e(F5,iAe),e(iAe,oPr),e(F5,rPr),e(F5,Jee),e(Jee,tPr),e(F5,aPr),e(I,nPr),e(I,T5),e(T5,dAe),e(dAe,sPr),e(T5,lPr),e(T5,Yee),e(Yee,iPr),e(T5,dPr),e(I,mPr),e(I,M5),e(M5,mAe),e(mAe,cPr),e(M5,fPr),e(M5,Kee),e(Kee,gPr),e(M5,hPr),e(I,uPr),e(I,E5),e(E5,cAe),e(cAe,pPr),e(E5,_Pr),e(E5,Zee),e(Zee,bPr),e(E5,vPr),e(I,FPr),e(I,C5),e(C5,fAe),e(fAe,TPr),e(C5,MPr),e(C5,eoe),e(eoe,EPr),e(C5,CPr),e(I,wPr),e(I,w5),e(w5,gAe),e(gAe,APr),e(w5,LPr),e(w5,ooe),e(ooe,yPr),e(w5,xPr),e(I,$Pr),e(I,A5),e(A5,hAe),e(hAe,kPr),e(A5,SPr),e(A5,roe),e(roe,RPr),e(A5,PPr),e(I,BPr),e(I,L5),e(L5,uAe),e(uAe,IPr),e(L5,NPr),e(L5,toe),e(toe,qPr),e(L5,jPr),e(I,DPr),e(I,y5),e(y5,pAe),e(pAe,GPr),e(y5,OPr),e(y5,aoe),e(aoe,VPr),e(y5,XPr),e(I,zPr),e(I,x5),e(x5,_Ae),e(_Ae,QPr),e(x5,WPr),e(x5,noe),e(noe,UPr),e(x5,HPr),e(I,JPr),e(I,$5),e($5,bAe),e(bAe,YPr),e($5,KPr),e($5,soe),e(soe,ZPr),e($5,eBr),e(I,oBr),e(I,k5),e(k5,vAe),e(vAe,rBr),e(k5,tBr),e(k5,loe),e(loe,aBr),e(k5,nBr),e(I,sBr),e(I,S5),e(S5,FAe),e(FAe,lBr),e(S5,iBr),e(S5,ioe),e(ioe,dBr),e(S5,mBr),e(I,cBr),e(I,R5),e(R5,TAe),e(TAe,fBr),e(R5,gBr),e(R5,doe),e(doe,hBr),e(R5,uBr),e(I,pBr),e(I,P5),e(P5,MAe),e(MAe,_Br),e(P5,bBr),e(P5,moe),e(moe,vBr),e(P5,FBr),e(I,TBr),e(I,B5),e(B5,EAe),e(EAe,MBr),e(B5,EBr),e(B5,coe),e(coe,CBr),e(B5,wBr),e(Ir,ABr),M(I5,Ir,null),b(c,Zeo,_),b(c,zm,_),e(zm,N5),e(N5,CAe),M(eS,CAe,null),e(zm,LBr),e(zm,wAe),e(wAe,yBr),b(c,eoo,_),b(c,lr,_),M(oS,lr,null),e(lr,xBr),e(lr,Qm),e(Qm,$Br),e(Qm,foe),e(foe,kBr),e(Qm,SBr),e(Qm,goe),e(goe,RBr),e(Qm,PBr),e(lr,BBr),e(lr,rS),e(rS,IBr),e(rS,AAe),e(AAe,NBr),e(rS,qBr),e(lr,jBr),e(lr,zt),M(tS,zt,null),e(zt,DBr),e(zt,LAe),e(LAe,GBr),e(zt,OBr),e(zt,Wm),e(Wm,VBr),e(Wm,yAe),e(yAe,XBr),e(Wm,zBr),e(Wm,hoe),e(hoe,QBr),e(Wm,WBr),e(zt,UBr),M(q5,zt,null),e(lr,HBr),e(lr,Nr),M(aS,Nr,null),e(Nr,JBr),e(Nr,xAe),e(xAe,YBr),e(Nr,KBr),e(Nr,An),e(An,ZBr),e(An,$Ae),e($Ae,eIr),e(An,oIr),e(An,kAe),e(kAe,rIr),e(An,tIr),e(An,SAe),e(SAe,aIr),e(An,nIr),e(Nr,sIr),e(Nr,se),e(se,j5),e(j5,RAe),e(RAe,lIr),e(j5,iIr),e(j5,uoe),e(uoe,dIr),e(j5,mIr),e(se,cIr),e(se,D5),e(D5,PAe),e(PAe,fIr),e(D5,gIr),e(D5,poe),e(poe,hIr),e(D5,uIr),e(se,pIr),e(se,G5),e(G5,BAe),e(BAe,_Ir),e(G5,bIr),e(G5,_oe),e(_oe,vIr),e(G5,FIr),e(se,TIr),e(se,O5),e(O5,IAe),e(IAe,MIr),e(O5,EIr),e(O5,boe),e(boe,CIr),e(O5,wIr),e(se,AIr),e(se,V5),e(V5,NAe),e(NAe,LIr),e(V5,yIr),e(V5,voe),e(voe,xIr),e(V5,$Ir),e(se,kIr),e(se,X5),e(X5,qAe),e(qAe,SIr),e(X5,RIr),e(X5,Foe),e(Foe,PIr),e(X5,BIr),e(se,IIr),e(se,z5),e(z5,jAe),e(jAe,NIr),e(z5,qIr),e(z5,Toe),e(Toe,jIr),e(z5,DIr),e(se,GIr),e(se,Q5),e(Q5,DAe),e(DAe,OIr),e(Q5,VIr),e(Q5,Moe),e(Moe,XIr),e(Q5,zIr),e(se,QIr),e(se,W5),e(W5,GAe),e(GAe,WIr),e(W5,UIr),e(W5,Eoe),e(Eoe,HIr),e(W5,JIr),e(se,YIr),e(se,U5),e(U5,OAe),e(OAe,KIr),e(U5,ZIr),e(U5,Coe),e(Coe,eNr),e(U5,oNr),e(se,rNr),e(se,H5),e(H5,VAe),e(VAe,tNr),e(H5,aNr),e(H5,woe),e(woe,nNr),e(H5,sNr),e(se,lNr),e(se,J5),e(J5,XAe),e(XAe,iNr),e(J5,dNr),e(J5,Aoe),e(Aoe,mNr),e(J5,cNr),e(se,fNr),e(se,Y5),e(Y5,zAe),e(zAe,gNr),e(Y5,hNr),e(Y5,Loe),e(Loe,uNr),e(Y5,pNr),e(se,_Nr),e(se,K5),e(K5,QAe),e(QAe,bNr),e(K5,vNr),e(K5,yoe),e(yoe,FNr),e(K5,TNr),e(se,MNr),e(se,Z5),e(Z5,WAe),e(WAe,ENr),e(Z5,CNr),e(Z5,xoe),e(xoe,wNr),e(Z5,ANr),e(se,LNr),e(se,e0),e(e0,UAe),e(UAe,yNr),e(e0,xNr),e(e0,$oe),e($oe,$Nr),e(e0,kNr),e(se,SNr),e(se,o0),e(o0,HAe),e(HAe,RNr),e(o0,PNr),e(o0,koe),e(koe,BNr),e(o0,INr),e(se,NNr),e(se,r0),e(r0,JAe),e(JAe,qNr),e(r0,jNr),e(r0,Soe),e(Soe,DNr),e(r0,GNr),e(se,ONr),e(se,t0),e(t0,YAe),e(YAe,VNr),e(t0,XNr),e(t0,Roe),e(Roe,zNr),e(t0,QNr),e(se,WNr),e(se,a0),e(a0,KAe),e(KAe,UNr),e(a0,HNr),e(a0,Poe),e(Poe,JNr),e(a0,YNr),e(se,KNr),e(se,n0),e(n0,ZAe),e(ZAe,ZNr),e(n0,eqr),e(n0,Boe),e(Boe,oqr),e(n0,rqr),e(se,tqr),e(se,s0),e(s0,e6e),e(e6e,aqr),e(s0,nqr),e(s0,Ioe),e(Ioe,sqr),e(s0,lqr),e(se,iqr),e(se,l0),e(l0,o6e),e(o6e,dqr),e(l0,mqr),e(l0,Noe),e(Noe,cqr),e(l0,fqr),e(Nr,gqr),M(i0,Nr,null),b(c,ooo,_),b(c,Um,_),e(Um,d0),e(d0,r6e),M(nS,r6e,null),e(Um,hqr),e(Um,t6e),e(t6e,uqr),b(c,roo,_),b(c,ir,_),M(sS,ir,null),e(ir,pqr),e(ir,Hm),e(Hm,_qr),e(Hm,qoe),e(qoe,bqr),e(Hm,vqr),e(Hm,joe),e(joe,Fqr),e(Hm,Tqr),e(ir,Mqr),e(ir,lS),e(lS,Eqr),e(lS,a6e),e(a6e,Cqr),e(lS,wqr),e(ir,Aqr),e(ir,Qt),M(iS,Qt,null),e(Qt,Lqr),e(Qt,n6e),e(n6e,yqr),e(Qt,xqr),e(Qt,Jm),e(Jm,$qr),e(Jm,s6e),e(s6e,kqr),e(Jm,Sqr),e(Jm,Doe),e(Doe,Rqr),e(Jm,Pqr),e(Qt,Bqr),M(m0,Qt,null),e(ir,Iqr),e(ir,qr),M(dS,qr,null),e(qr,Nqr),e(qr,l6e),e(l6e,qqr),e(qr,jqr),e(qr,Ln),e(Ln,Dqr),e(Ln,i6e),e(i6e,Gqr),e(Ln,Oqr),e(Ln,d6e),e(d6e,Vqr),e(Ln,Xqr),e(Ln,m6e),e(m6e,zqr),e(Ln,Qqr),e(qr,Wqr),e(qr,Me),e(Me,c0),e(c0,c6e),e(c6e,Uqr),e(c0,Hqr),e(c0,Goe),e(Goe,Jqr),e(c0,Yqr),e(Me,Kqr),e(Me,f0),e(f0,f6e),e(f6e,Zqr),e(f0,ejr),e(f0,Ooe),e(Ooe,ojr),e(f0,rjr),e(Me,tjr),e(Me,g0),e(g0,g6e),e(g6e,ajr),e(g0,njr),e(g0,Voe),e(Voe,sjr),e(g0,ljr),e(Me,ijr),e(Me,h0),e(h0,h6e),e(h6e,djr),e(h0,mjr),e(h0,Xoe),e(Xoe,cjr),e(h0,fjr),e(Me,gjr),e(Me,u0),e(u0,u6e),e(u6e,hjr),e(u0,ujr),e(u0,zoe),e(zoe,pjr),e(u0,_jr),e(Me,bjr),e(Me,p0),e(p0,p6e),e(p6e,vjr),e(p0,Fjr),e(p0,Qoe),e(Qoe,Tjr),e(p0,Mjr),e(Me,Ejr),e(Me,_0),e(_0,_6e),e(_6e,Cjr),e(_0,wjr),e(_0,Woe),e(Woe,Ajr),e(_0,Ljr),e(Me,yjr),e(Me,b0),e(b0,b6e),e(b6e,xjr),e(b0,$jr),e(b0,Uoe),e(Uoe,kjr),e(b0,Sjr),e(Me,Rjr),e(Me,v0),e(v0,v6e),e(v6e,Pjr),e(v0,Bjr),e(v0,Hoe),e(Hoe,Ijr),e(v0,Njr),e(Me,qjr),e(Me,F0),e(F0,F6e),e(F6e,jjr),e(F0,Djr),e(F0,Joe),e(Joe,Gjr),e(F0,Ojr),e(Me,Vjr),e(Me,T0),e(T0,T6e),e(T6e,Xjr),e(T0,zjr),e(T0,Yoe),e(Yoe,Qjr),e(T0,Wjr),e(Me,Ujr),e(Me,M0),e(M0,M6e),e(M6e,Hjr),e(M0,Jjr),e(M0,Koe),e(Koe,Yjr),e(M0,Kjr),e(Me,Zjr),e(Me,E0),e(E0,E6e),e(E6e,eDr),e(E0,oDr),e(E0,Zoe),e(Zoe,rDr),e(E0,tDr),e(Me,aDr),e(Me,C0),e(C0,C6e),e(C6e,nDr),e(C0,sDr),e(C0,ere),e(ere,lDr),e(C0,iDr),e(qr,dDr),M(w0,qr,null),b(c,too,_),b(c,Ym,_),e(Ym,A0),e(A0,w6e),M(mS,w6e,null),e(Ym,mDr),e(Ym,A6e),e(A6e,cDr),b(c,aoo,_),b(c,dr,_),M(cS,dr,null),e(dr,fDr),e(dr,Km),e(Km,gDr),e(Km,ore),e(ore,hDr),e(Km,uDr),e(Km,rre),e(rre,pDr),e(Km,_Dr),e(dr,bDr),e(dr,fS),e(fS,vDr),e(fS,L6e),e(L6e,FDr),e(fS,TDr),e(dr,MDr),e(dr,Wt),M(gS,Wt,null),e(Wt,EDr),e(Wt,y6e),e(y6e,CDr),e(Wt,wDr),e(Wt,Zm),e(Zm,ADr),e(Zm,x6e),e(x6e,LDr),e(Zm,yDr),e(Zm,tre),e(tre,xDr),e(Zm,$Dr),e(Wt,kDr),M(L0,Wt,null),e(dr,SDr),e(dr,jr),M(hS,jr,null),e(jr,RDr),e(jr,$6e),e($6e,PDr),e(jr,BDr),e(jr,yn),e(yn,IDr),e(yn,k6e),e(k6e,NDr),e(yn,qDr),e(yn,S6e),e(S6e,jDr),e(yn,DDr),e(yn,R6e),e(R6e,GDr),e(yn,ODr),e(jr,VDr),e(jr,Be),e(Be,y0),e(y0,P6e),e(P6e,XDr),e(y0,zDr),e(y0,are),e(are,QDr),e(y0,WDr),e(Be,UDr),e(Be,x0),e(x0,B6e),e(B6e,HDr),e(x0,JDr),e(x0,nre),e(nre,YDr),e(x0,KDr),e(Be,ZDr),e(Be,Tl),e(Tl,I6e),e(I6e,eGr),e(Tl,oGr),e(Tl,sre),e(sre,rGr),e(Tl,tGr),e(Tl,lre),e(lre,aGr),e(Tl,nGr),e(Be,sGr),e(Be,$0),e($0,N6e),e(N6e,lGr),e($0,iGr),e($0,ire),e(ire,dGr),e($0,mGr),e(Be,cGr),e(Be,k0),e(k0,q6e),e(q6e,fGr),e(k0,gGr),e(k0,dre),e(dre,hGr),e(k0,uGr),e(Be,pGr),e(Be,S0),e(S0,j6e),e(j6e,_Gr),e(S0,bGr),e(S0,mre),e(mre,vGr),e(S0,FGr),e(Be,TGr),e(Be,R0),e(R0,D6e),e(D6e,MGr),e(R0,EGr),e(R0,cre),e(cre,CGr),e(R0,wGr),e(Be,AGr),e(Be,P0),e(P0,G6e),e(G6e,LGr),e(P0,yGr),e(P0,fre),e(fre,xGr),e(P0,$Gr),e(Be,kGr),e(Be,B0),e(B0,O6e),e(O6e,SGr),e(B0,RGr),e(B0,gre),e(gre,PGr),e(B0,BGr),e(jr,IGr),M(I0,jr,null),b(c,noo,_),b(c,ec,_),e(ec,N0),e(N0,V6e),M(uS,V6e,null),e(ec,NGr),e(ec,X6e),e(X6e,qGr),b(c,soo,_),b(c,mr,_),M(pS,mr,null),e(mr,jGr),e(mr,oc),e(oc,DGr),e(oc,hre),e(hre,GGr),e(oc,OGr),e(oc,ure),e(ure,VGr),e(oc,XGr),e(mr,zGr),e(mr,_S),e(_S,QGr),e(_S,z6e),e(z6e,WGr),e(_S,UGr),e(mr,HGr),e(mr,Ut),M(bS,Ut,null),e(Ut,JGr),e(Ut,Q6e),e(Q6e,YGr),e(Ut,KGr),e(Ut,rc),e(rc,ZGr),e(rc,W6e),e(W6e,eOr),e(rc,oOr),e(rc,pre),e(pre,rOr),e(rc,tOr),e(Ut,aOr),M(q0,Ut,null),e(mr,nOr),e(mr,Dr),M(vS,Dr,null),e(Dr,sOr),e(Dr,U6e),e(U6e,lOr),e(Dr,iOr),e(Dr,xn),e(xn,dOr),e(xn,H6e),e(H6e,mOr),e(xn,cOr),e(xn,J6e),e(J6e,fOr),e(xn,gOr),e(xn,Y6e),e(Y6e,hOr),e(xn,uOr),e(Dr,pOr),e(Dr,tc),e(tc,j0),e(j0,K6e),e(K6e,_Or),e(j0,bOr),e(j0,_re),e(_re,vOr),e(j0,FOr),e(tc,TOr),e(tc,D0),e(D0,Z6e),e(Z6e,MOr),e(D0,EOr),e(D0,bre),e(bre,COr),e(D0,wOr),e(tc,AOr),e(tc,G0),e(G0,e7e),e(e7e,LOr),e(G0,yOr),e(G0,vre),e(vre,xOr),e(G0,$Or),e(Dr,kOr),M(O0,Dr,null),b(c,loo,_),b(c,ac,_),e(ac,V0),e(V0,o7e),M(FS,o7e,null),e(ac,SOr),e(ac,r7e),e(r7e,ROr),b(c,ioo,_),b(c,cr,_),M(TS,cr,null),e(cr,POr),e(cr,nc),e(nc,BOr),e(nc,Fre),e(Fre,IOr),e(nc,NOr),e(nc,Tre),e(Tre,qOr),e(nc,jOr),e(cr,DOr),e(cr,MS),e(MS,GOr),e(MS,t7e),e(t7e,OOr),e(MS,VOr),e(cr,XOr),e(cr,Ht),M(ES,Ht,null),e(Ht,zOr),e(Ht,a7e),e(a7e,QOr),e(Ht,WOr),e(Ht,sc),e(sc,UOr),e(sc,n7e),e(n7e,HOr),e(sc,JOr),e(sc,Mre),e(Mre,YOr),e(sc,KOr),e(Ht,ZOr),M(X0,Ht,null),e(cr,eVr),e(cr,Gr),M(CS,Gr,null),e(Gr,oVr),e(Gr,s7e),e(s7e,rVr),e(Gr,tVr),e(Gr,$n),e($n,aVr),e($n,l7e),e(l7e,nVr),e($n,sVr),e($n,i7e),e(i7e,lVr),e($n,iVr),e($n,d7e),e(d7e,dVr),e($n,mVr),e(Gr,cVr),e(Gr,ge),e(ge,z0),e(z0,m7e),e(m7e,fVr),e(z0,gVr),e(z0,Ere),e(Ere,hVr),e(z0,uVr),e(ge,pVr),e(ge,Q0),e(Q0,c7e),e(c7e,_Vr),e(Q0,bVr),e(Q0,Cre),e(Cre,vVr),e(Q0,FVr),e(ge,TVr),e(ge,W0),e(W0,f7e),e(f7e,MVr),e(W0,EVr),e(W0,wre),e(wre,CVr),e(W0,wVr),e(ge,AVr),e(ge,U0),e(U0,g7e),e(g7e,LVr),e(U0,yVr),e(U0,Are),e(Are,xVr),e(U0,$Vr),e(ge,kVr),e(ge,H0),e(H0,h7e),e(h7e,SVr),e(H0,RVr),e(H0,Lre),e(Lre,PVr),e(H0,BVr),e(ge,IVr),e(ge,J0),e(J0,u7e),e(u7e,NVr),e(J0,qVr),e(J0,yre),e(yre,jVr),e(J0,DVr),e(ge,GVr),e(ge,Y0),e(Y0,p7e),e(p7e,OVr),e(Y0,VVr),e(Y0,xre),e(xre,XVr),e(Y0,zVr),e(ge,QVr),e(ge,K0),e(K0,_7e),e(_7e,WVr),e(K0,UVr),e(K0,$re),e($re,HVr),e(K0,JVr),e(ge,YVr),e(ge,Z0),e(Z0,b7e),e(b7e,KVr),e(Z0,ZVr),e(Z0,kre),e(kre,eXr),e(Z0,oXr),e(ge,rXr),e(ge,ew),e(ew,v7e),e(v7e,tXr),e(ew,aXr),e(ew,Sre),e(Sre,nXr),e(ew,sXr),e(ge,lXr),e(ge,ow),e(ow,F7e),e(F7e,iXr),e(ow,dXr),e(ow,Rre),e(Rre,mXr),e(ow,cXr),e(ge,fXr),e(ge,rw),e(rw,T7e),e(T7e,gXr),e(rw,hXr),e(rw,Pre),e(Pre,uXr),e(rw,pXr),e(ge,_Xr),e(ge,tw),e(tw,M7e),e(M7e,bXr),e(tw,vXr),e(tw,Bre),e(Bre,FXr),e(tw,TXr),e(ge,MXr),e(ge,aw),e(aw,E7e),e(E7e,EXr),e(aw,CXr),e(aw,Ire),e(Ire,wXr),e(aw,AXr),e(ge,LXr),e(ge,nw),e(nw,C7e),e(C7e,yXr),e(nw,xXr),e(nw,Nre),e(Nre,$Xr),e(nw,kXr),e(ge,SXr),e(ge,sw),e(sw,w7e),e(w7e,RXr),e(sw,PXr),e(sw,qre),e(qre,BXr),e(sw,IXr),e(ge,NXr),e(ge,lw),e(lw,A7e),e(A7e,qXr),e(lw,jXr),e(lw,jre),e(jre,DXr),e(lw,GXr),e(ge,OXr),e(ge,iw),e(iw,L7e),e(L7e,VXr),e(iw,XXr),e(iw,Dre),e(Dre,zXr),e(iw,QXr),e(ge,WXr),e(ge,dw),e(dw,y7e),e(y7e,UXr),e(dw,HXr),e(dw,Gre),e(Gre,JXr),e(dw,YXr),e(ge,KXr),e(ge,mw),e(mw,x7e),e(x7e,ZXr),e(mw,ezr),e(mw,Ore),e(Ore,ozr),e(mw,rzr),e(Gr,tzr),M(cw,Gr,null),b(c,doo,_),b(c,lc,_),e(lc,fw),e(fw,$7e),M(wS,$7e,null),e(lc,azr),e(lc,k7e),e(k7e,nzr),b(c,moo,_),b(c,fr,_),M(AS,fr,null),e(fr,szr),e(fr,ic),e(ic,lzr),e(ic,Vre),e(Vre,izr),e(ic,dzr),e(ic,Xre),e(Xre,mzr),e(ic,czr),e(fr,fzr),e(fr,LS),e(LS,gzr),e(LS,S7e),e(S7e,hzr),e(LS,uzr),e(fr,pzr),e(fr,Jt),M(yS,Jt,null),e(Jt,_zr),e(Jt,R7e),e(R7e,bzr),e(Jt,vzr),e(Jt,dc),e(dc,Fzr),e(dc,P7e),e(P7e,Tzr),e(dc,Mzr),e(dc,zre),e(zre,Ezr),e(dc,Czr),e(Jt,wzr),M(gw,Jt,null),e(fr,Azr),e(fr,Or),M(xS,Or,null),e(Or,Lzr),e(Or,B7e),e(B7e,yzr),e(Or,xzr),e(Or,kn),e(kn,$zr),e(kn,I7e),e(I7e,kzr),e(kn,Szr),e(kn,N7e),e(N7e,Rzr),e(kn,Pzr),e(kn,q7e),e(q7e,Bzr),e(kn,Izr),e(Or,Nzr),e(Or,ye),e(ye,hw),e(hw,j7e),e(j7e,qzr),e(hw,jzr),e(hw,Qre),e(Qre,Dzr),e(hw,Gzr),e(ye,Ozr),e(ye,uw),e(uw,D7e),e(D7e,Vzr),e(uw,Xzr),e(uw,Wre),e(Wre,zzr),e(uw,Qzr),e(ye,Wzr),e(ye,pw),e(pw,G7e),e(G7e,Uzr),e(pw,Hzr),e(pw,Ure),e(Ure,Jzr),e(pw,Yzr),e(ye,Kzr),e(ye,_w),e(_w,O7e),e(O7e,Zzr),e(_w,eQr),e(_w,Hre),e(Hre,oQr),e(_w,rQr),e(ye,tQr),e(ye,bw),e(bw,V7e),e(V7e,aQr),e(bw,nQr),e(bw,Jre),e(Jre,sQr),e(bw,lQr),e(ye,iQr),e(ye,vw),e(vw,X7e),e(X7e,dQr),e(vw,mQr),e(vw,Yre),e(Yre,cQr),e(vw,fQr),e(ye,gQr),e(ye,Fw),e(Fw,z7e),e(z7e,hQr),e(Fw,uQr),e(Fw,Kre),e(Kre,pQr),e(Fw,_Qr),e(ye,bQr),e(ye,Tw),e(Tw,Q7e),e(Q7e,vQr),e(Tw,FQr),e(Tw,Zre),e(Zre,TQr),e(Tw,MQr),e(ye,EQr),e(ye,Mw),e(Mw,W7e),e(W7e,CQr),e(Mw,wQr),e(Mw,ete),e(ete,AQr),e(Mw,LQr),e(ye,yQr),e(ye,Ew),e(Ew,U7e),e(U7e,xQr),e(Ew,$Qr),e(Ew,ote),e(ote,kQr),e(Ew,SQr),e(Or,RQr),M(Cw,Or,null),b(c,coo,_),b(c,mc,_),e(mc,ww),e(ww,H7e),M($S,H7e,null),e(mc,PQr),e(mc,J7e),e(J7e,BQr),b(c,foo,_),b(c,gr,_),M(kS,gr,null),e(gr,IQr),e(gr,cc),e(cc,NQr),e(cc,rte),e(rte,qQr),e(cc,jQr),e(cc,tte),e(tte,DQr),e(cc,GQr),e(gr,OQr),e(gr,SS),e(SS,VQr),e(SS,Y7e),e(Y7e,XQr),e(SS,zQr),e(gr,QQr),e(gr,Yt),M(RS,Yt,null),e(Yt,WQr),e(Yt,K7e),e(K7e,UQr),e(Yt,HQr),e(Yt,fc),e(fc,JQr),e(fc,Z7e),e(Z7e,YQr),e(fc,KQr),e(fc,ate),e(ate,ZQr),e(fc,eWr),e(Yt,oWr),M(Aw,Yt,null),e(gr,rWr),e(gr,Vr),M(PS,Vr,null),e(Vr,tWr),e(Vr,eLe),e(eLe,aWr),e(Vr,nWr),e(Vr,Sn),e(Sn,sWr),e(Sn,oLe),e(oLe,lWr),e(Sn,iWr),e(Sn,rLe),e(rLe,dWr),e(Sn,mWr),e(Sn,tLe),e(tLe,cWr),e(Sn,fWr),e(Vr,gWr),e(Vr,re),e(re,Lw),e(Lw,aLe),e(aLe,hWr),e(Lw,uWr),e(Lw,nte),e(nte,pWr),e(Lw,_Wr),e(re,bWr),e(re,yw),e(yw,nLe),e(nLe,vWr),e(yw,FWr),e(yw,ste),e(ste,TWr),e(yw,MWr),e(re,EWr),e(re,xw),e(xw,sLe),e(sLe,CWr),e(xw,wWr),e(xw,lte),e(lte,AWr),e(xw,LWr),e(re,yWr),e(re,$w),e($w,lLe),e(lLe,xWr),e($w,$Wr),e($w,ite),e(ite,kWr),e($w,SWr),e(re,RWr),e(re,kw),e(kw,iLe),e(iLe,PWr),e(kw,BWr),e(kw,dte),e(dte,IWr),e(kw,NWr),e(re,qWr),e(re,Sw),e(Sw,dLe),e(dLe,jWr),e(Sw,DWr),e(Sw,mte),e(mte,GWr),e(Sw,OWr),e(re,VWr),e(re,Rw),e(Rw,mLe),e(mLe,XWr),e(Rw,zWr),e(Rw,cte),e(cte,QWr),e(Rw,WWr),e(re,UWr),e(re,Pw),e(Pw,cLe),e(cLe,HWr),e(Pw,JWr),e(Pw,fte),e(fte,YWr),e(Pw,KWr),e(re,ZWr),e(re,Bw),e(Bw,fLe),e(fLe,eUr),e(Bw,oUr),e(Bw,gte),e(gte,rUr),e(Bw,tUr),e(re,aUr),e(re,Iw),e(Iw,gLe),e(gLe,nUr),e(Iw,sUr),e(Iw,hte),e(hte,lUr),e(Iw,iUr),e(re,dUr),e(re,Nw),e(Nw,hLe),e(hLe,mUr),e(Nw,cUr),e(Nw,ute),e(ute,fUr),e(Nw,gUr),e(re,hUr),e(re,qw),e(qw,uLe),e(uLe,uUr),e(qw,pUr),e(qw,pte),e(pte,_Ur),e(qw,bUr),e(re,vUr),e(re,jw),e(jw,pLe),e(pLe,FUr),e(jw,TUr),e(jw,_te),e(_te,MUr),e(jw,EUr),e(re,CUr),e(re,Dw),e(Dw,_Le),e(_Le,wUr),e(Dw,AUr),e(Dw,bte),e(bte,LUr),e(Dw,yUr),e(re,xUr),e(re,Gw),e(Gw,bLe),e(bLe,$Ur),e(Gw,kUr),e(Gw,vte),e(vte,SUr),e(Gw,RUr),e(re,PUr),e(re,Ow),e(Ow,vLe),e(vLe,BUr),e(Ow,IUr),e(Ow,Fte),e(Fte,NUr),e(Ow,qUr),e(re,jUr),e(re,Vw),e(Vw,FLe),e(FLe,DUr),e(Vw,GUr),e(Vw,Tte),e(Tte,OUr),e(Vw,VUr),e(re,XUr),e(re,Xw),e(Xw,TLe),e(TLe,zUr),e(Xw,QUr),e(Xw,Mte),e(Mte,WUr),e(Xw,UUr),e(re,HUr),e(re,zw),e(zw,MLe),e(MLe,JUr),e(zw,YUr),e(zw,Ete),e(Ete,KUr),e(zw,ZUr),e(re,eHr),e(re,Qw),e(Qw,ELe),e(ELe,oHr),e(Qw,rHr),e(Qw,Cte),e(Cte,tHr),e(Qw,aHr),e(re,nHr),e(re,Ww),e(Ww,CLe),e(CLe,sHr),e(Ww,lHr),e(Ww,wte),e(wte,iHr),e(Ww,dHr),e(re,mHr),e(re,Uw),e(Uw,wLe),e(wLe,cHr),e(Uw,fHr),e(Uw,Ate),e(Ate,gHr),e(Uw,hHr),e(re,uHr),e(re,Hw),e(Hw,ALe),e(ALe,pHr),e(Hw,_Hr),e(Hw,Lte),e(Lte,bHr),e(Hw,vHr),e(re,FHr),e(re,Jw),e(Jw,LLe),e(LLe,THr),e(Jw,MHr),e(Jw,yte),e(yte,EHr),e(Jw,CHr),e(re,wHr),e(re,Yw),e(Yw,yLe),e(yLe,AHr),e(Yw,LHr),e(Yw,xte),e(xte,yHr),e(Yw,xHr),e(re,$Hr),e(re,Kw),e(Kw,xLe),e(xLe,kHr),e(Kw,SHr),e(Kw,$te),e($te,RHr),e(Kw,PHr),e(re,BHr),e(re,Zw),e(Zw,$Le),e($Le,IHr),e(Zw,NHr),e(Zw,kte),e(kte,qHr),e(Zw,jHr),e(Vr,DHr),M(eA,Vr,null),b(c,goo,_),b(c,gc,_),e(gc,oA),e(oA,kLe),M(BS,kLe,null),e(gc,GHr),e(gc,SLe),e(SLe,OHr),b(c,hoo,_),b(c,hr,_),M(IS,hr,null),e(hr,VHr),e(hr,hc),e(hc,XHr),e(hc,Ste),e(Ste,zHr),e(hc,QHr),e(hc,Rte),e(Rte,WHr),e(hc,UHr),e(hr,HHr),e(hr,NS),e(NS,JHr),e(NS,RLe),e(RLe,YHr),e(NS,KHr),e(hr,ZHr),e(hr,Kt),M(qS,Kt,null),e(Kt,eJr),e(Kt,PLe),e(PLe,oJr),e(Kt,rJr),e(Kt,uc),e(uc,tJr),e(uc,BLe),e(BLe,aJr),e(uc,nJr),e(uc,Pte),e(Pte,sJr),e(uc,lJr),e(Kt,iJr),M(rA,Kt,null),e(hr,dJr),e(hr,Xr),M(jS,Xr,null),e(Xr,mJr),e(Xr,ILe),e(ILe,cJr),e(Xr,fJr),e(Xr,Rn),e(Rn,gJr),e(Rn,NLe),e(NLe,hJr),e(Rn,uJr),e(Rn,qLe),e(qLe,pJr),e(Rn,_Jr),e(Rn,jLe),e(jLe,bJr),e(Rn,vJr),e(Xr,FJr),e(Xr,ve),e(ve,tA),e(tA,DLe),e(DLe,TJr),e(tA,MJr),e(tA,Bte),e(Bte,EJr),e(tA,CJr),e(ve,wJr),e(ve,aA),e(aA,GLe),e(GLe,AJr),e(aA,LJr),e(aA,Ite),e(Ite,yJr),e(aA,xJr),e(ve,$Jr),e(ve,nA),e(nA,OLe),e(OLe,kJr),e(nA,SJr),e(nA,Nte),e(Nte,RJr),e(nA,PJr),e(ve,BJr),e(ve,sA),e(sA,VLe),e(VLe,IJr),e(sA,NJr),e(sA,qte),e(qte,qJr),e(sA,jJr),e(ve,DJr),e(ve,lA),e(lA,XLe),e(XLe,GJr),e(lA,OJr),e(lA,jte),e(jte,VJr),e(lA,XJr),e(ve,zJr),e(ve,iA),e(iA,zLe),e(zLe,QJr),e(iA,WJr),e(iA,Dte),e(Dte,UJr),e(iA,HJr),e(ve,JJr),e(ve,dA),e(dA,QLe),e(QLe,YJr),e(dA,KJr),e(dA,Gte),e(Gte,ZJr),e(dA,eYr),e(ve,oYr),e(ve,mA),e(mA,WLe),e(WLe,rYr),e(mA,tYr),e(mA,Ote),e(Ote,aYr),e(mA,nYr),e(ve,sYr),e(ve,cA),e(cA,ULe),e(ULe,lYr),e(cA,iYr),e(cA,Vte),e(Vte,dYr),e(cA,mYr),e(ve,cYr),e(ve,fA),e(fA,HLe),e(HLe,fYr),e(fA,gYr),e(fA,Xte),e(Xte,hYr),e(fA,uYr),e(ve,pYr),e(ve,gA),e(gA,JLe),e(JLe,_Yr),e(gA,bYr),e(gA,zte),e(zte,vYr),e(gA,FYr),e(ve,TYr),e(ve,hA),e(hA,YLe),e(YLe,MYr),e(hA,EYr),e(hA,Qte),e(Qte,CYr),e(hA,wYr),e(ve,AYr),e(ve,uA),e(uA,KLe),e(KLe,LYr),e(uA,yYr),e(uA,Wte),e(Wte,xYr),e(uA,$Yr),e(ve,kYr),e(ve,pA),e(pA,ZLe),e(ZLe,SYr),e(pA,RYr),e(pA,Ute),e(Ute,PYr),e(pA,BYr),e(ve,IYr),e(ve,_A),e(_A,eye),e(eye,NYr),e(_A,qYr),e(_A,Hte),e(Hte,jYr),e(_A,DYr),e(ve,GYr),e(ve,bA),e(bA,oye),e(oye,OYr),e(bA,VYr),e(bA,Jte),e(Jte,XYr),e(bA,zYr),e(ve,QYr),e(ve,vA),e(vA,rye),e(rye,WYr),e(vA,UYr),e(vA,Yte),e(Yte,HYr),e(vA,JYr),e(Xr,YYr),M(FA,Xr,null),b(c,uoo,_),b(c,pc,_),e(pc,TA),e(TA,tye),M(DS,tye,null),e(pc,KYr),e(pc,aye),e(aye,ZYr),b(c,poo,_),b(c,ur,_),M(GS,ur,null),e(ur,eKr),e(ur,_c),e(_c,oKr),e(_c,Kte),e(Kte,rKr),e(_c,tKr),e(_c,Zte),e(Zte,aKr),e(_c,nKr),e(ur,sKr),e(ur,OS),e(OS,lKr),e(OS,nye),e(nye,iKr),e(OS,dKr),e(ur,mKr),e(ur,Zt),M(VS,Zt,null),e(Zt,cKr),e(Zt,sye),e(sye,fKr),e(Zt,gKr),e(Zt,bc),e(bc,hKr),e(bc,lye),e(lye,uKr),e(bc,pKr),e(bc,eae),e(eae,_Kr),e(bc,bKr),e(Zt,vKr),M(MA,Zt,null),e(ur,FKr),e(ur,zr),M(XS,zr,null),e(zr,TKr),e(zr,iye),e(iye,MKr),e(zr,EKr),e(zr,Pn),e(Pn,CKr),e(Pn,dye),e(dye,wKr),e(Pn,AKr),e(Pn,mye),e(mye,LKr),e(Pn,yKr),e(Pn,cye),e(cye,xKr),e(Pn,$Kr),e(zr,kKr),e(zr,zS),e(zS,EA),e(EA,fye),e(fye,SKr),e(EA,RKr),e(EA,oae),e(oae,PKr),e(EA,BKr),e(zS,IKr),e(zS,CA),e(CA,gye),e(gye,NKr),e(CA,qKr),e(CA,rae),e(rae,jKr),e(CA,DKr),e(zr,GKr),M(wA,zr,null),b(c,_oo,_),b(c,vc,_),e(vc,AA),e(AA,hye),M(QS,hye,null),e(vc,OKr),e(vc,uye),e(uye,VKr),b(c,boo,_),b(c,pr,_),M(WS,pr,null),e(pr,XKr),e(pr,Fc),e(Fc,zKr),e(Fc,tae),e(tae,QKr),e(Fc,WKr),e(Fc,aae),e(aae,UKr),e(Fc,HKr),e(pr,JKr),e(pr,US),e(US,YKr),e(US,pye),e(pye,KKr),e(US,ZKr),e(pr,eZr),e(pr,ea),M(HS,ea,null),e(ea,oZr),e(ea,_ye),e(_ye,rZr),e(ea,tZr),e(ea,Tc),e(Tc,aZr),e(Tc,bye),e(bye,nZr),e(Tc,sZr),e(Tc,nae),e(nae,lZr),e(Tc,iZr),e(ea,dZr),M(LA,ea,null),e(pr,mZr),e(pr,Qr),M(JS,Qr,null),e(Qr,cZr),e(Qr,vye),e(vye,fZr),e(Qr,gZr),e(Qr,Bn),e(Bn,hZr),e(Bn,Fye),e(Fye,uZr),e(Bn,pZr),e(Bn,Tye),e(Tye,_Zr),e(Bn,bZr),e(Bn,Mye),e(Mye,vZr),e(Bn,FZr),e(Qr,TZr),e(Qr,Eye),e(Eye,yA),e(yA,Cye),e(Cye,MZr),e(yA,EZr),e(yA,sae),e(sae,CZr),e(yA,wZr),e(Qr,AZr),M(xA,Qr,null),b(c,voo,_),b(c,Mc,_),e(Mc,$A),e($A,wye),M(YS,wye,null),e(Mc,LZr),e(Mc,Aye),e(Aye,yZr),b(c,Foo,_),b(c,_r,_),M(KS,_r,null),e(_r,xZr),e(_r,Ec),e(Ec,$Zr),e(Ec,lae),e(lae,kZr),e(Ec,SZr),e(Ec,iae),e(iae,RZr),e(Ec,PZr),e(_r,BZr),e(_r,ZS),e(ZS,IZr),e(ZS,Lye),e(Lye,NZr),e(ZS,qZr),e(_r,jZr),e(_r,oa),M(eR,oa,null),e(oa,DZr),e(oa,yye),e(yye,GZr),e(oa,OZr),e(oa,Cc),e(Cc,VZr),e(Cc,xye),e(xye,XZr),e(Cc,zZr),e(Cc,dae),e(dae,QZr),e(Cc,WZr),e(oa,UZr),M(kA,oa,null),e(_r,HZr),e(_r,Wr),M(oR,Wr,null),e(Wr,JZr),e(Wr,$ye),e($ye,YZr),e(Wr,KZr),e(Wr,In),e(In,ZZr),e(In,kye),e(kye,eet),e(In,oet),e(In,Sye),e(Sye,ret),e(In,tet),e(In,Rye),e(Rye,aet),e(In,net),e(Wr,set),e(Wr,Pye),e(Pye,SA),e(SA,Bye),e(Bye,iet),e(SA,det),e(SA,mae),e(mae,met),e(SA,cet),e(Wr,fet),M(RA,Wr,null),b(c,Too,_),b(c,wc,_),e(wc,PA),e(PA,Iye),M(rR,Iye,null),e(wc,get),e(wc,Nye),e(Nye,het),b(c,Moo,_),b(c,br,_),M(tR,br,null),e(br,uet),e(br,Ac),e(Ac,pet),e(Ac,cae),e(cae,_et),e(Ac,bet),e(Ac,fae),e(fae,vet),e(Ac,Fet),e(br,Tet),e(br,aR),e(aR,Met),e(aR,qye),e(qye,Eet),e(aR,Cet),e(br,wet),e(br,ra),M(nR,ra,null),e(ra,Aet),e(ra,jye),e(jye,Let),e(ra,yet),e(ra,Lc),e(Lc,xet),e(Lc,Dye),e(Dye,$et),e(Lc,ket),e(Lc,gae),e(gae,Set),e(Lc,Ret),e(ra,Pet),M(BA,ra,null),e(br,Bet),e(br,Ur),M(sR,Ur,null),e(Ur,Iet),e(Ur,Gye),e(Gye,Net),e(Ur,qet),e(Ur,Nn),e(Nn,jet),e(Nn,Oye),e(Oye,Det),e(Nn,Get),e(Nn,Vye),e(Vye,Oet),e(Nn,Vet),e(Nn,Xye),e(Xye,Xet),e(Nn,zet),e(Ur,Qet),e(Ur,de),e(de,IA),e(IA,zye),e(zye,Wet),e(IA,Uet),e(IA,hae),e(hae,Het),e(IA,Jet),e(de,Yet),e(de,NA),e(NA,Qye),e(Qye,Ket),e(NA,Zet),e(NA,uae),e(uae,eot),e(NA,oot),e(de,rot),e(de,qA),e(qA,Wye),e(Wye,tot),e(qA,aot),e(qA,pae),e(pae,not),e(qA,sot),e(de,lot),e(de,jA),e(jA,Uye),e(Uye,iot),e(jA,dot),e(jA,_ae),e(_ae,mot),e(jA,cot),e(de,fot),e(de,DA),e(DA,Hye),e(Hye,got),e(DA,hot),e(DA,bae),e(bae,uot),e(DA,pot),e(de,_ot),e(de,GA),e(GA,Jye),e(Jye,bot),e(GA,vot),e(GA,vae),e(vae,Fot),e(GA,Tot),e(de,Mot),e(de,OA),e(OA,Yye),e(Yye,Eot),e(OA,Cot),e(OA,Fae),e(Fae,wot),e(OA,Aot),e(de,Lot),e(de,VA),e(VA,Kye),e(Kye,yot),e(VA,xot),e(VA,Tae),e(Tae,$ot),e(VA,kot),e(de,Sot),e(de,XA),e(XA,Zye),e(Zye,Rot),e(XA,Pot),e(XA,Mae),e(Mae,Bot),e(XA,Iot),e(de,Not),e(de,zA),e(zA,e8e),e(e8e,qot),e(zA,jot),e(zA,Eae),e(Eae,Dot),e(zA,Got),e(de,Oot),e(de,QA),e(QA,o8e),e(o8e,Vot),e(QA,Xot),e(QA,Cae),e(Cae,zot),e(QA,Qot),e(de,Wot),e(de,WA),e(WA,r8e),e(r8e,Uot),e(WA,Hot),e(WA,wae),e(wae,Jot),e(WA,Yot),e(de,Kot),e(de,UA),e(UA,t8e),e(t8e,Zot),e(UA,ert),e(UA,Aae),e(Aae,ort),e(UA,rrt),e(de,trt),e(de,HA),e(HA,a8e),e(a8e,art),e(HA,nrt),e(HA,Lae),e(Lae,srt),e(HA,lrt),e(de,irt),e(de,JA),e(JA,n8e),e(n8e,drt),e(JA,mrt),e(JA,yae),e(yae,crt),e(JA,frt),e(de,grt),e(de,YA),e(YA,s8e),e(s8e,hrt),e(YA,urt),e(YA,xae),e(xae,prt),e(YA,_rt),e(de,brt),e(de,KA),e(KA,l8e),e(l8e,vrt),e(KA,Frt),e(KA,$ae),e($ae,Trt),e(KA,Mrt),e(de,Ert),e(de,ZA),e(ZA,i8e),e(i8e,Crt),e(ZA,wrt),e(ZA,kae),e(kae,Art),e(ZA,Lrt),e(de,yrt),e(de,e6),e(e6,d8e),e(d8e,xrt),e(e6,$rt),e(e6,Sae),e(Sae,krt),e(e6,Srt),e(de,Rrt),e(de,o6),e(o6,m8e),e(m8e,Prt),e(o6,Brt),e(o6,Rae),e(Rae,Irt),e(o6,Nrt),e(de,qrt),e(de,r6),e(r6,c8e),e(c8e,jrt),e(r6,Drt),e(r6,Pae),e(Pae,Grt),e(r6,Ort),e(Ur,Vrt),M(t6,Ur,null),b(c,Eoo,_),b(c,yc,_),e(yc,a6),e(a6,f8e),M(lR,f8e,null),e(yc,Xrt),e(yc,g8e),e(g8e,zrt),b(c,Coo,_),b(c,vr,_),M(iR,vr,null),e(vr,Qrt),e(vr,xc),e(xc,Wrt),e(xc,Bae),e(Bae,Urt),e(xc,Hrt),e(xc,Iae),e(Iae,Jrt),e(xc,Yrt),e(vr,Krt),e(vr,dR),e(dR,Zrt),e(dR,h8e),e(h8e,ett),e(dR,ott),e(vr,rtt),e(vr,ta),M(mR,ta,null),e(ta,ttt),e(ta,u8e),e(u8e,att),e(ta,ntt),e(ta,$c),e($c,stt),e($c,p8e),e(p8e,ltt),e($c,itt),e($c,Nae),e(Nae,dtt),e($c,mtt),e(ta,ctt),M(n6,ta,null),e(vr,ftt),e(vr,Hr),M(cR,Hr,null),e(Hr,gtt),e(Hr,_8e),e(_8e,htt),e(Hr,utt),e(Hr,qn),e(qn,ptt),e(qn,b8e),e(b8e,_tt),e(qn,btt),e(qn,v8e),e(v8e,vtt),e(qn,Ftt),e(qn,F8e),e(F8e,Ttt),e(qn,Mtt),e(Hr,Ett),e(Hr,me),e(me,s6),e(s6,T8e),e(T8e,Ctt),e(s6,wtt),e(s6,qae),e(qae,Att),e(s6,Ltt),e(me,ytt),e(me,l6),e(l6,M8e),e(M8e,xtt),e(l6,$tt),e(l6,jae),e(jae,ktt),e(l6,Stt),e(me,Rtt),e(me,i6),e(i6,E8e),e(E8e,Ptt),e(i6,Btt),e(i6,Dae),e(Dae,Itt),e(i6,Ntt),e(me,qtt),e(me,d6),e(d6,C8e),e(C8e,jtt),e(d6,Dtt),e(d6,Gae),e(Gae,Gtt),e(d6,Ott),e(me,Vtt),e(me,m6),e(m6,w8e),e(w8e,Xtt),e(m6,ztt),e(m6,Oae),e(Oae,Qtt),e(m6,Wtt),e(me,Utt),e(me,c6),e(c6,A8e),e(A8e,Htt),e(c6,Jtt),e(c6,Vae),e(Vae,Ytt),e(c6,Ktt),e(me,Ztt),e(me,f6),e(f6,L8e),e(L8e,eat),e(f6,oat),e(f6,Xae),e(Xae,rat),e(f6,tat),e(me,aat),e(me,g6),e(g6,y8e),e(y8e,nat),e(g6,sat),e(g6,zae),e(zae,lat),e(g6,iat),e(me,dat),e(me,h6),e(h6,x8e),e(x8e,mat),e(h6,cat),e(h6,Qae),e(Qae,fat),e(h6,gat),e(me,hat),e(me,u6),e(u6,$8e),e($8e,uat),e(u6,pat),e(u6,Wae),e(Wae,_at),e(u6,bat),e(me,vat),e(me,p6),e(p6,k8e),e(k8e,Fat),e(p6,Tat),e(p6,Uae),e(Uae,Mat),e(p6,Eat),e(me,Cat),e(me,_6),e(_6,S8e),e(S8e,wat),e(_6,Aat),e(_6,Hae),e(Hae,Lat),e(_6,yat),e(me,xat),e(me,b6),e(b6,R8e),e(R8e,$at),e(b6,kat),e(b6,Jae),e(Jae,Sat),e(b6,Rat),e(me,Pat),e(me,v6),e(v6,P8e),e(P8e,Bat),e(v6,Iat),e(v6,Yae),e(Yae,Nat),e(v6,qat),e(me,jat),e(me,F6),e(F6,B8e),e(B8e,Dat),e(F6,Gat),e(F6,Kae),e(Kae,Oat),e(F6,Vat),e(me,Xat),e(me,T6),e(T6,I8e),e(I8e,zat),e(T6,Qat),e(T6,Zae),e(Zae,Wat),e(T6,Uat),e(me,Hat),e(me,M6),e(M6,N8e),e(N8e,Jat),e(M6,Yat),e(M6,ene),e(ene,Kat),e(M6,Zat),e(me,ent),e(me,E6),e(E6,q8e),e(q8e,ont),e(E6,rnt),e(E6,one),e(one,tnt),e(E6,ant),e(me,nnt),e(me,C6),e(C6,j8e),e(j8e,snt),e(C6,lnt),e(C6,rne),e(rne,int),e(C6,dnt),e(me,mnt),e(me,w6),e(w6,D8e),e(D8e,cnt),e(w6,fnt),e(w6,tne),e(tne,gnt),e(w6,hnt),e(me,unt),e(me,A6),e(A6,G8e),e(G8e,pnt),e(A6,_nt),e(A6,ane),e(ane,bnt),e(A6,vnt),e(Hr,Fnt),M(L6,Hr,null),b(c,woo,_),b(c,kc,_),e(kc,y6),e(y6,O8e),M(fR,O8e,null),e(kc,Tnt),e(kc,V8e),e(V8e,Mnt),b(c,Aoo,_),b(c,Fr,_),M(gR,Fr,null),e(Fr,Ent),e(Fr,Sc),e(Sc,Cnt),e(Sc,nne),e(nne,wnt),e(Sc,Ant),e(Sc,sne),e(sne,Lnt),e(Sc,ynt),e(Fr,xnt),e(Fr,hR),e(hR,$nt),e(hR,X8e),e(X8e,knt),e(hR,Snt),e(Fr,Rnt),e(Fr,aa),M(uR,aa,null),e(aa,Pnt),e(aa,z8e),e(z8e,Bnt),e(aa,Int),e(aa,Rc),e(Rc,Nnt),e(Rc,Q8e),e(Q8e,qnt),e(Rc,jnt),e(Rc,lne),e(lne,Dnt),e(Rc,Gnt),e(aa,Ont),M(x6,aa,null),e(Fr,Vnt),e(Fr,Jr),M(pR,Jr,null),e(Jr,Xnt),e(Jr,W8e),e(W8e,znt),e(Jr,Qnt),e(Jr,jn),e(jn,Wnt),e(jn,U8e),e(U8e,Unt),e(jn,Hnt),e(jn,H8e),e(H8e,Jnt),e(jn,Ynt),e(jn,J8e),e(J8e,Knt),e(jn,Znt),e(Jr,est),e(Jr,Y8e),e(Y8e,$6),e($6,K8e),e(K8e,ost),e($6,rst),e($6,ine),e(ine,tst),e($6,ast),e(Jr,nst),M(k6,Jr,null),b(c,Loo,_),b(c,Pc,_),e(Pc,S6),e(S6,Z8e),M(_R,Z8e,null),e(Pc,sst),e(Pc,e9e),e(e9e,lst),b(c,yoo,_),b(c,Tr,_),M(bR,Tr,null),e(Tr,ist),e(Tr,Bc),e(Bc,dst),e(Bc,dne),e(dne,mst),e(Bc,cst),e(Bc,mne),e(mne,fst),e(Bc,gst),e(Tr,hst),e(Tr,vR),e(vR,ust),e(vR,o9e),e(o9e,pst),e(vR,_st),e(Tr,bst),e(Tr,na),M(FR,na,null),e(na,vst),e(na,r9e),e(r9e,Fst),e(na,Tst),e(na,Ic),e(Ic,Mst),e(Ic,t9e),e(t9e,Est),e(Ic,Cst),e(Ic,cne),e(cne,wst),e(Ic,Ast),e(na,Lst),M(R6,na,null),e(Tr,yst),e(Tr,Yr),M(TR,Yr,null),e(Yr,xst),e(Yr,a9e),e(a9e,$st),e(Yr,kst),e(Yr,Dn),e(Dn,Sst),e(Dn,n9e),e(n9e,Rst),e(Dn,Pst),e(Dn,s9e),e(s9e,Bst),e(Dn,Ist),e(Dn,l9e),e(l9e,Nst),e(Dn,qst),e(Yr,jst),e(Yr,i9e),e(i9e,P6),e(P6,d9e),e(d9e,Dst),e(P6,Gst),e(P6,fne),e(fne,Ost),e(P6,Vst),e(Yr,Xst),M(B6,Yr,null),b(c,xoo,_),b(c,Nc,_),e(Nc,I6),e(I6,m9e),M(MR,m9e,null),e(Nc,zst),e(Nc,c9e),e(c9e,Qst),b(c,$oo,_),b(c,Mr,_),M(ER,Mr,null),e(Mr,Wst),e(Mr,qc),e(qc,Ust),e(qc,gne),e(gne,Hst),e(qc,Jst),e(qc,hne),e(hne,Yst),e(qc,Kst),e(Mr,Zst),e(Mr,CR),e(CR,elt),e(CR,f9e),e(f9e,olt),e(CR,rlt),e(Mr,tlt),e(Mr,sa),M(wR,sa,null),e(sa,alt),e(sa,g9e),e(g9e,nlt),e(sa,slt),e(sa,jc),e(jc,llt),e(jc,h9e),e(h9e,ilt),e(jc,dlt),e(jc,une),e(une,mlt),e(jc,clt),e(sa,flt),M(N6,sa,null),e(Mr,glt),e(Mr,Kr),M(AR,Kr,null),e(Kr,hlt),e(Kr,u9e),e(u9e,ult),e(Kr,plt),e(Kr,Gn),e(Gn,_lt),e(Gn,p9e),e(p9e,blt),e(Gn,vlt),e(Gn,_9e),e(_9e,Flt),e(Gn,Tlt),e(Gn,b9e),e(b9e,Mlt),e(Gn,Elt),e(Kr,Clt),e(Kr,te),e(te,q6),e(q6,v9e),e(v9e,wlt),e(q6,Alt),e(q6,pne),e(pne,Llt),e(q6,ylt),e(te,xlt),e(te,j6),e(j6,F9e),e(F9e,$lt),e(j6,klt),e(j6,_ne),e(_ne,Slt),e(j6,Rlt),e(te,Plt),e(te,D6),e(D6,T9e),e(T9e,Blt),e(D6,Ilt),e(D6,bne),e(bne,Nlt),e(D6,qlt),e(te,jlt),e(te,G6),e(G6,M9e),e(M9e,Dlt),e(G6,Glt),e(G6,vne),e(vne,Olt),e(G6,Vlt),e(te,Xlt),e(te,O6),e(O6,E9e),e(E9e,zlt),e(O6,Qlt),e(O6,Fne),e(Fne,Wlt),e(O6,Ult),e(te,Hlt),e(te,V6),e(V6,C9e),e(C9e,Jlt),e(V6,Ylt),e(V6,Tne),e(Tne,Klt),e(V6,Zlt),e(te,eit),e(te,X6),e(X6,w9e),e(w9e,oit),e(X6,rit),e(X6,Mne),e(Mne,tit),e(X6,ait),e(te,nit),e(te,z6),e(z6,A9e),e(A9e,sit),e(z6,lit),e(z6,Ene),e(Ene,iit),e(z6,dit),e(te,mit),e(te,Q6),e(Q6,L9e),e(L9e,cit),e(Q6,fit),e(Q6,Cne),e(Cne,git),e(Q6,hit),e(te,uit),e(te,W6),e(W6,y9e),e(y9e,pit),e(W6,_it),e(W6,wne),e(wne,bit),e(W6,vit),e(te,Fit),e(te,U6),e(U6,x9e),e(x9e,Tit),e(U6,Mit),e(U6,Ane),e(Ane,Eit),e(U6,Cit),e(te,wit),e(te,H6),e(H6,$9e),e($9e,Ait),e(H6,Lit),e(H6,Lne),e(Lne,yit),e(H6,xit),e(te,$it),e(te,J6),e(J6,k9e),e(k9e,kit),e(J6,Sit),e(J6,yne),e(yne,Rit),e(J6,Pit),e(te,Bit),e(te,Y6),e(Y6,S9e),e(S9e,Iit),e(Y6,Nit),e(Y6,xne),e(xne,qit),e(Y6,jit),e(te,Dit),e(te,K6),e(K6,R9e),e(R9e,Git),e(K6,Oit),e(K6,$ne),e($ne,Vit),e(K6,Xit),e(te,zit),e(te,Z6),e(Z6,P9e),e(P9e,Qit),e(Z6,Wit),e(Z6,kne),e(kne,Uit),e(Z6,Hit),e(te,Jit),e(te,e7),e(e7,B9e),e(B9e,Yit),e(e7,Kit),e(e7,Sne),e(Sne,Zit),e(e7,edt),e(te,odt),e(te,o7),e(o7,I9e),e(I9e,rdt),e(o7,tdt),e(o7,Rne),e(Rne,adt),e(o7,ndt),e(te,sdt),e(te,r7),e(r7,N9e),e(N9e,ldt),e(r7,idt),e(r7,Pne),e(Pne,ddt),e(r7,mdt),e(te,cdt),e(te,t7),e(t7,q9e),e(q9e,fdt),e(t7,gdt),e(t7,Bne),e(Bne,hdt),e(t7,udt),e(te,pdt),e(te,a7),e(a7,j9e),e(j9e,_dt),e(a7,bdt),e(a7,Ine),e(Ine,vdt),e(a7,Fdt),e(te,Tdt),e(te,n7),e(n7,D9e),e(D9e,Mdt),e(n7,Edt),e(n7,Nne),e(Nne,Cdt),e(n7,wdt),e(te,Adt),e(te,s7),e(s7,G9e),e(G9e,Ldt),e(s7,ydt),e(s7,qne),e(qne,xdt),e(s7,$dt),e(te,kdt),e(te,l7),e(l7,O9e),e(O9e,Sdt),e(l7,Rdt),e(l7,jne),e(jne,Pdt),e(l7,Bdt),e(te,Idt),e(te,i7),e(i7,V9e),e(V9e,Ndt),e(i7,qdt),e(i7,Dne),e(Dne,jdt),e(i7,Ddt),e(te,Gdt),e(te,d7),e(d7,X9e),e(X9e,Odt),e(d7,Vdt),e(d7,Gne),e(Gne,Xdt),e(d7,zdt),e(te,Qdt),e(te,m7),e(m7,z9e),e(z9e,Wdt),e(m7,Udt),e(m7,One),e(One,Hdt),e(m7,Jdt),e(Kr,Ydt),M(c7,Kr,null),b(c,koo,_),b(c,Dc,_),e(Dc,f7),e(f7,Q9e),M(LR,Q9e,null),e(Dc,Kdt),e(Dc,W9e),e(W9e,Zdt),b(c,Soo,_),b(c,Er,_),M(yR,Er,null),e(Er,emt),e(Er,Gc),e(Gc,omt),e(Gc,Vne),e(Vne,rmt),e(Gc,tmt),e(Gc,Xne),e(Xne,amt),e(Gc,nmt),e(Er,smt),e(Er,xR),e(xR,lmt),e(xR,U9e),e(U9e,imt),e(xR,dmt),e(Er,mmt),e(Er,la),M($R,la,null),e(la,cmt),e(la,H9e),e(H9e,fmt),e(la,gmt),e(la,Oc),e(Oc,hmt),e(Oc,J9e),e(J9e,umt),e(Oc,pmt),e(Oc,zne),e(zne,_mt),e(Oc,bmt),e(la,vmt),M(g7,la,null),e(Er,Fmt),e(Er,Zr),M(kR,Zr,null),e(Zr,Tmt),e(Zr,Y9e),e(Y9e,Mmt),e(Zr,Emt),e(Zr,On),e(On,Cmt),e(On,K9e),e(K9e,wmt),e(On,Amt),e(On,Z9e),e(Z9e,Lmt),e(On,ymt),e(On,exe),e(exe,xmt),e(On,$mt),e(Zr,kmt),e(Zr,xe),e(xe,h7),e(h7,oxe),e(oxe,Smt),e(h7,Rmt),e(h7,Qne),e(Qne,Pmt),e(h7,Bmt),e(xe,Imt),e(xe,u7),e(u7,rxe),e(rxe,Nmt),e(u7,qmt),e(u7,Wne),e(Wne,jmt),e(u7,Dmt),e(xe,Gmt),e(xe,p7),e(p7,txe),e(txe,Omt),e(p7,Vmt),e(p7,Une),e(Une,Xmt),e(p7,zmt),e(xe,Qmt),e(xe,_7),e(_7,axe),e(axe,Wmt),e(_7,Umt),e(_7,Hne),e(Hne,Hmt),e(_7,Jmt),e(xe,Ymt),e(xe,b7),e(b7,nxe),e(nxe,Kmt),e(b7,Zmt),e(b7,Jne),e(Jne,ect),e(b7,oct),e(xe,rct),e(xe,v7),e(v7,sxe),e(sxe,tct),e(v7,act),e(v7,Yne),e(Yne,nct),e(v7,sct),e(xe,lct),e(xe,F7),e(F7,lxe),e(lxe,ict),e(F7,dct),e(F7,Kne),e(Kne,mct),e(F7,cct),e(xe,fct),e(xe,T7),e(T7,ixe),e(ixe,gct),e(T7,hct),e(T7,Zne),e(Zne,uct),e(T7,pct),e(xe,_ct),e(xe,M7),e(M7,dxe),e(dxe,bct),e(M7,vct),e(M7,ese),e(ese,Fct),e(M7,Tct),e(xe,Mct),e(xe,E7),e(E7,mxe),e(mxe,Ect),e(E7,Cct),e(E7,ose),e(ose,wct),e(E7,Act),e(Zr,Lct),M(C7,Zr,null),b(c,Roo,_),b(c,Vc,_),e(Vc,w7),e(w7,cxe),M(SR,cxe,null),e(Vc,yct),e(Vc,fxe),e(fxe,xct),b(c,Poo,_),b(c,Cr,_),M(RR,Cr,null),e(Cr,$ct),e(Cr,Xc),e(Xc,kct),e(Xc,rse),e(rse,Sct),e(Xc,Rct),e(Xc,tse),e(tse,Pct),e(Xc,Bct),e(Cr,Ict),e(Cr,PR),e(PR,Nct),e(PR,gxe),e(gxe,qct),e(PR,jct),e(Cr,Dct),e(Cr,ia),M(BR,ia,null),e(ia,Gct),e(ia,hxe),e(hxe,Oct),e(ia,Vct),e(ia,zc),e(zc,Xct),e(zc,uxe),e(uxe,zct),e(zc,Qct),e(zc,ase),e(ase,Wct),e(zc,Uct),e(ia,Hct),M(A7,ia,null),e(Cr,Jct),e(Cr,et),M(IR,et,null),e(et,Yct),e(et,pxe),e(pxe,Kct),e(et,Zct),e(et,Vn),e(Vn,eft),e(Vn,_xe),e(_xe,oft),e(Vn,rft),e(Vn,bxe),e(bxe,tft),e(Vn,aft),e(Vn,vxe),e(vxe,nft),e(Vn,sft),e(et,lft),e(et,Ee),e(Ee,L7),e(L7,Fxe),e(Fxe,ift),e(L7,dft),e(L7,nse),e(nse,mft),e(L7,cft),e(Ee,fft),e(Ee,y7),e(y7,Txe),e(Txe,gft),e(y7,hft),e(y7,sse),e(sse,uft),e(y7,pft),e(Ee,_ft),e(Ee,x7),e(x7,Mxe),e(Mxe,bft),e(x7,vft),e(x7,lse),e(lse,Fft),e(x7,Tft),e(Ee,Mft),e(Ee,$7),e($7,Exe),e(Exe,Eft),e($7,Cft),e($7,ise),e(ise,wft),e($7,Aft),e(Ee,Lft),e(Ee,k7),e(k7,Cxe),e(Cxe,yft),e(k7,xft),e(k7,dse),e(dse,$ft),e(k7,kft),e(Ee,Sft),e(Ee,S7),e(S7,wxe),e(wxe,Rft),e(S7,Pft),e(S7,mse),e(mse,Bft),e(S7,Ift),e(Ee,Nft),e(Ee,R7),e(R7,Axe),e(Axe,qft),e(R7,jft),e(R7,cse),e(cse,Dft),e(R7,Gft),e(Ee,Oft),e(Ee,P7),e(P7,Lxe),e(Lxe,Vft),e(P7,Xft),e(P7,fse),e(fse,zft),e(P7,Qft),e(Ee,Wft),e(Ee,B7),e(B7,yxe),e(yxe,Uft),e(B7,Hft),e(B7,gse),e(gse,Jft),e(B7,Yft),e(Ee,Kft),e(Ee,I7),e(I7,xxe),e(xxe,Zft),e(I7,egt),e(I7,hse),e(hse,ogt),e(I7,rgt),e(Ee,tgt),e(Ee,N7),e(N7,$xe),e($xe,agt),e(N7,ngt),e(N7,use),e(use,sgt),e(N7,lgt),e(Ee,igt),e(Ee,q7),e(q7,kxe),e(kxe,dgt),e(q7,mgt),e(q7,pse),e(pse,cgt),e(q7,fgt),e(Ee,ggt),e(Ee,j7),e(j7,Sxe),e(Sxe,hgt),e(j7,ugt),e(j7,_se),e(_se,pgt),e(j7,_gt),e(et,bgt),M(D7,et,null),b(c,Boo,_),b(c,Qc,_),e(Qc,G7),e(G7,Rxe),M(NR,Rxe,null),e(Qc,vgt),e(Qc,Pxe),e(Pxe,Fgt),b(c,Ioo,_),b(c,wr,_),M(qR,wr,null),e(wr,Tgt),e(wr,Wc),e(Wc,Mgt),e(Wc,bse),e(bse,Egt),e(Wc,Cgt),e(Wc,vse),e(vse,wgt),e(Wc,Agt),e(wr,Lgt),e(wr,jR),e(jR,ygt),e(jR,Bxe),e(Bxe,xgt),e(jR,$gt),e(wr,kgt),e(wr,da),M(DR,da,null),e(da,Sgt),e(da,Ixe),e(Ixe,Rgt),e(da,Pgt),e(da,Uc),e(Uc,Bgt),e(Uc,Nxe),e(Nxe,Igt),e(Uc,Ngt),e(Uc,Fse),e(Fse,qgt),e(Uc,jgt),e(da,Dgt),M(O7,da,null),e(wr,Ggt),e(wr,ot),M(GR,ot,null),e(ot,Ogt),e(ot,qxe),e(qxe,Vgt),e(ot,Xgt),e(ot,Xn),e(Xn,zgt),e(Xn,jxe),e(jxe,Qgt),e(Xn,Wgt),e(Xn,Dxe),e(Dxe,Ugt),e(Xn,Hgt),e(Xn,Gxe),e(Gxe,Jgt),e(Xn,Ygt),e(ot,Kgt),e(ot,$e),e($e,V7),e(V7,Oxe),e(Oxe,Zgt),e(V7,eht),e(V7,Tse),e(Tse,oht),e(V7,rht),e($e,tht),e($e,X7),e(X7,Vxe),e(Vxe,aht),e(X7,nht),e(X7,Mse),e(Mse,sht),e(X7,lht),e($e,iht),e($e,z7),e(z7,Xxe),e(Xxe,dht),e(z7,mht),e(z7,Ese),e(Ese,cht),e(z7,fht),e($e,ght),e($e,Q7),e(Q7,zxe),e(zxe,hht),e(Q7,uht),e(Q7,Cse),e(Cse,pht),e(Q7,_ht),e($e,bht),e($e,W7),e(W7,Qxe),e(Qxe,vht),e(W7,Fht),e(W7,wse),e(wse,Tht),e(W7,Mht),e($e,Eht),e($e,U7),e(U7,Wxe),e(Wxe,Cht),e(U7,wht),e(U7,Ase),e(Ase,Aht),e(U7,Lht),e($e,yht),e($e,H7),e(H7,Uxe),e(Uxe,xht),e(H7,$ht),e(H7,Lse),e(Lse,kht),e(H7,Sht),e($e,Rht),e($e,J7),e(J7,Hxe),e(Hxe,Pht),e(J7,Bht),e(J7,yse),e(yse,Iht),e(J7,Nht),e($e,qht),e($e,Y7),e(Y7,Jxe),e(Jxe,jht),e(Y7,Dht),e(Y7,xse),e(xse,Ght),e(Y7,Oht),e($e,Vht),e($e,K7),e(K7,Yxe),e(Yxe,Xht),e(K7,zht),e(K7,$se),e($se,Qht),e(K7,Wht),e(ot,Uht),M(Z7,ot,null),b(c,Noo,_),b(c,Hc,_),e(Hc,eL),e(eL,Kxe),M(OR,Kxe,null),e(Hc,Hht),e(Hc,Zxe),e(Zxe,Jht),b(c,qoo,_),b(c,Ar,_),M(VR,Ar,null),e(Ar,Yht),e(Ar,Jc),e(Jc,Kht),e(Jc,kse),e(kse,Zht),e(Jc,eut),e(Jc,Sse),e(Sse,out),e(Jc,rut),e(Ar,tut),e(Ar,XR),e(XR,aut),e(XR,e$e),e(e$e,nut),e(XR,sut),e(Ar,lut),e(Ar,ma),M(zR,ma,null),e(ma,iut),e(ma,o$e),e(o$e,dut),e(ma,mut),e(ma,Yc),e(Yc,cut),e(Yc,r$e),e(r$e,fut),e(Yc,gut),e(Yc,Rse),e(Rse,hut),e(Yc,uut),e(ma,put),M(oL,ma,null),e(Ar,_ut),e(Ar,rt),M(QR,rt,null),e(rt,but),e(rt,t$e),e(t$e,vut),e(rt,Fut),e(rt,zn),e(zn,Tut),e(zn,a$e),e(a$e,Mut),e(zn,Eut),e(zn,n$e),e(n$e,Cut),e(zn,wut),e(zn,s$e),e(s$e,Aut),e(zn,Lut),e(rt,yut),e(rt,ke),e(ke,rL),e(rL,l$e),e(l$e,xut),e(rL,$ut),e(rL,Pse),e(Pse,kut),e(rL,Sut),e(ke,Rut),e(ke,tL),e(tL,i$e),e(i$e,Put),e(tL,But),e(tL,Bse),e(Bse,Iut),e(tL,Nut),e(ke,qut),e(ke,aL),e(aL,d$e),e(d$e,jut),e(aL,Dut),e(aL,Ise),e(Ise,Gut),e(aL,Out),e(ke,Vut),e(ke,nL),e(nL,m$e),e(m$e,Xut),e(nL,zut),e(nL,Nse),e(Nse,Qut),e(nL,Wut),e(ke,Uut),e(ke,sL),e(sL,c$e),e(c$e,Hut),e(sL,Jut),e(sL,qse),e(qse,Yut),e(sL,Kut),e(ke,Zut),e(ke,lL),e(lL,f$e),e(f$e,ept),e(lL,opt),e(lL,jse),e(jse,rpt),e(lL,tpt),e(ke,apt),e(ke,iL),e(iL,g$e),e(g$e,npt),e(iL,spt),e(iL,Dse),e(Dse,lpt),e(iL,ipt),e(ke,dpt),e(ke,dL),e(dL,h$e),e(h$e,mpt),e(dL,cpt),e(dL,Gse),e(Gse,fpt),e(dL,gpt),e(ke,hpt),e(ke,mL),e(mL,u$e),e(u$e,upt),e(mL,ppt),e(mL,Ose),e(Ose,_pt),e(mL,bpt),e(ke,vpt),e(ke,cL),e(cL,p$e),e(p$e,Fpt),e(cL,Tpt),e(cL,Vse),e(Vse,Mpt),e(cL,Ept),e(rt,Cpt),M(fL,rt,null),b(c,joo,_),b(c,Kc,_),e(Kc,gL),e(gL,_$e),M(WR,_$e,null),e(Kc,wpt),e(Kc,b$e),e(b$e,Apt),b(c,Doo,_),b(c,Lr,_),M(UR,Lr,null),e(Lr,Lpt),e(Lr,Zc),e(Zc,ypt),e(Zc,Xse),e(Xse,xpt),e(Zc,$pt),e(Zc,zse),e(zse,kpt),e(Zc,Spt),e(Lr,Rpt),e(Lr,HR),e(HR,Ppt),e(HR,v$e),e(v$e,Bpt),e(HR,Ipt),e(Lr,Npt),e(Lr,ca),M(JR,ca,null),e(ca,qpt),e(ca,F$e),e(F$e,jpt),e(ca,Dpt),e(ca,ef),e(ef,Gpt),e(ef,T$e),e(T$e,Opt),e(ef,Vpt),e(ef,Qse),e(Qse,Xpt),e(ef,zpt),e(ca,Qpt),M(hL,ca,null),e(Lr,Wpt),e(Lr,tt),M(YR,tt,null),e(tt,Upt),e(tt,M$e),e(M$e,Hpt),e(tt,Jpt),e(tt,Qn),e(Qn,Ypt),e(Qn,E$e),e(E$e,Kpt),e(Qn,Zpt),e(Qn,C$e),e(C$e,e_t),e(Qn,o_t),e(Qn,w$e),e(w$e,r_t),e(Qn,t_t),e(tt,a_t),e(tt,Se),e(Se,uL),e(uL,A$e),e(A$e,n_t),e(uL,s_t),e(uL,Wse),e(Wse,l_t),e(uL,i_t),e(Se,d_t),e(Se,pL),e(pL,L$e),e(L$e,m_t),e(pL,c_t),e(pL,Use),e(Use,f_t),e(pL,g_t),e(Se,h_t),e(Se,_L),e(_L,y$e),e(y$e,u_t),e(_L,p_t),e(_L,Hse),e(Hse,__t),e(_L,b_t),e(Se,v_t),e(Se,bL),e(bL,x$e),e(x$e,F_t),e(bL,T_t),e(bL,Jse),e(Jse,M_t),e(bL,E_t),e(Se,C_t),e(Se,vL),e(vL,$$e),e($$e,w_t),e(vL,A_t),e(vL,Yse),e(Yse,L_t),e(vL,y_t),e(Se,x_t),e(Se,FL),e(FL,k$e),e(k$e,$_t),e(FL,k_t),e(FL,Kse),e(Kse,S_t),e(FL,R_t),e(Se,P_t),e(Se,TL),e(TL,S$e),e(S$e,B_t),e(TL,I_t),e(TL,Zse),e(Zse,N_t),e(TL,q_t),e(Se,j_t),e(Se,ML),e(ML,R$e),e(R$e,D_t),e(ML,G_t),e(ML,ele),e(ele,O_t),e(ML,V_t),e(Se,X_t),e(Se,EL),e(EL,P$e),e(P$e,z_t),e(EL,Q_t),e(EL,ole),e(ole,W_t),e(EL,U_t),e(Se,H_t),e(Se,CL),e(CL,B$e),e(B$e,J_t),e(CL,Y_t),e(CL,rle),e(rle,K_t),e(CL,Z_t),e(tt,e2t),M(wL,tt,null),b(c,Goo,_),b(c,of,_),e(of,AL),e(AL,I$e),M(KR,I$e,null),e(of,o2t),e(of,N$e),e(N$e,r2t),b(c,Ooo,_),b(c,yr,_),M(ZR,yr,null),e(yr,t2t),e(yr,rf),e(rf,a2t),e(rf,tle),e(tle,n2t),e(rf,s2t),e(rf,ale),e(ale,l2t),e(rf,i2t),e(yr,d2t),e(yr,eP),e(eP,m2t),e(eP,q$e),e(q$e,c2t),e(eP,f2t),e(yr,g2t),e(yr,fa),M(oP,fa,null),e(fa,h2t),e(fa,j$e),e(j$e,u2t),e(fa,p2t),e(fa,tf),e(tf,_2t),e(tf,D$e),e(D$e,b2t),e(tf,v2t),e(tf,nle),e(nle,F2t),e(tf,T2t),e(fa,M2t),M(LL,fa,null),e(yr,E2t),e(yr,at),M(rP,at,null),e(at,C2t),e(at,G$e),e(G$e,w2t),e(at,A2t),e(at,Wn),e(Wn,L2t),e(Wn,O$e),e(O$e,y2t),e(Wn,x2t),e(Wn,V$e),e(V$e,$2t),e(Wn,k2t),e(Wn,X$e),e(X$e,S2t),e(Wn,R2t),e(at,P2t),e(at,Re),e(Re,yL),e(yL,z$e),e(z$e,B2t),e(yL,I2t),e(yL,sle),e(sle,N2t),e(yL,q2t),e(Re,j2t),e(Re,xL),e(xL,Q$e),e(Q$e,D2t),e(xL,G2t),e(xL,lle),e(lle,O2t),e(xL,V2t),e(Re,X2t),e(Re,$L),e($L,W$e),e(W$e,z2t),e($L,Q2t),e($L,ile),e(ile,W2t),e($L,U2t),e(Re,H2t),e(Re,kL),e(kL,U$e),e(U$e,J2t),e(kL,Y2t),e(kL,dle),e(dle,K2t),e(kL,Z2t),e(Re,e1t),e(Re,SL),e(SL,H$e),e(H$e,o1t),e(SL,r1t),e(SL,mle),e(mle,t1t),e(SL,a1t),e(Re,n1t),e(Re,RL),e(RL,J$e),e(J$e,s1t),e(RL,l1t),e(RL,cle),e(cle,i1t),e(RL,d1t),e(Re,m1t),e(Re,PL),e(PL,Y$e),e(Y$e,c1t),e(PL,f1t),e(PL,fle),e(fle,g1t),e(PL,h1t),e(Re,u1t),e(Re,BL),e(BL,K$e),e(K$e,p1t),e(BL,_1t),e(BL,gle),e(gle,b1t),e(BL,v1t),e(Re,F1t),e(Re,IL),e(IL,Z$e),e(Z$e,T1t),e(IL,M1t),e(IL,hle),e(hle,E1t),e(IL,C1t),e(Re,w1t),e(Re,NL),e(NL,eke),e(eke,A1t),e(NL,L1t),e(NL,ule),e(ule,y1t),e(NL,x1t),e(at,$1t),M(qL,at,null),b(c,Voo,_),b(c,af,_),e(af,jL),e(jL,oke),M(tP,oke,null),e(af,k1t),e(af,rke),e(rke,S1t),b(c,Xoo,_),b(c,xr,_),M(aP,xr,null),e(xr,R1t),e(xr,nf),e(nf,P1t),e(nf,ple),e(ple,B1t),e(nf,I1t),e(nf,_le),e(_le,N1t),e(nf,q1t),e(xr,j1t),e(xr,nP),e(nP,D1t),e(nP,tke),e(tke,G1t),e(nP,O1t),e(xr,V1t),e(xr,ga),M(sP,ga,null),e(ga,X1t),e(ga,ake),e(ake,z1t),e(ga,Q1t),e(ga,sf),e(sf,W1t),e(sf,nke),e(nke,U1t),e(sf,H1t),e(sf,ble),e(ble,J1t),e(sf,Y1t),e(ga,K1t),M(DL,ga,null),e(xr,Z1t),e(xr,nt),M(lP,nt,null),e(nt,ebt),e(nt,ske),e(ske,obt),e(nt,rbt),e(nt,Un),e(Un,tbt),e(Un,lke),e(lke,abt),e(Un,nbt),e(Un,ike),e(ike,sbt),e(Un,lbt),e(Un,dke),e(dke,ibt),e(Un,dbt),e(nt,mbt),e(nt,Xe),e(Xe,GL),e(GL,mke),e(mke,cbt),e(GL,fbt),e(GL,vle),e(vle,gbt),e(GL,hbt),e(Xe,ubt),e(Xe,OL),e(OL,cke),e(cke,pbt),e(OL,_bt),e(OL,Fle),e(Fle,bbt),e(OL,vbt),e(Xe,Fbt),e(Xe,VL),e(VL,fke),e(fke,Tbt),e(VL,Mbt),e(VL,Tle),e(Tle,Ebt),e(VL,Cbt),e(Xe,wbt),e(Xe,XL),e(XL,gke),e(gke,Abt),e(XL,Lbt),e(XL,Mle),e(Mle,ybt),e(XL,xbt),e(Xe,$bt),e(Xe,zL),e(zL,hke),e(hke,kbt),e(zL,Sbt),e(zL,Ele),e(Ele,Rbt),e(zL,Pbt),e(Xe,Bbt),e(Xe,QL),e(QL,uke),e(uke,Ibt),e(QL,Nbt),e(QL,Cle),e(Cle,qbt),e(QL,jbt),e(Xe,Dbt),e(Xe,WL),e(WL,pke),e(pke,Gbt),e(WL,Obt),e(WL,wle),e(wle,Vbt),e(WL,Xbt),e(Xe,zbt),e(Xe,UL),e(UL,_ke),e(_ke,Qbt),e(UL,Wbt),e(UL,Ale),e(Ale,Ubt),e(UL,Hbt),e(nt,Jbt),M(HL,nt,null),b(c,zoo,_),b(c,lf,_),e(lf,JL),e(JL,bke),M(iP,bke,null),e(lf,Ybt),e(lf,vke),e(vke,Kbt),b(c,Qoo,_),b(c,$r,_),M(dP,$r,null),e($r,Zbt),e($r,df),e(df,evt),e(df,Lle),e(Lle,ovt),e(df,rvt),e(df,yle),e(yle,tvt),e(df,avt),e($r,nvt),e($r,mP),e(mP,svt),e(mP,Fke),e(Fke,lvt),e(mP,ivt),e($r,dvt),e($r,ha),M(cP,ha,null),e(ha,mvt),e(ha,Tke),e(Tke,cvt),e(ha,fvt),e(ha,mf),e(mf,gvt),e(mf,Mke),e(Mke,hvt),e(mf,uvt),e(mf,xle),e(xle,pvt),e(mf,_vt),e(ha,bvt),M(YL,ha,null),e($r,vvt),e($r,st),M(fP,st,null),e(st,Fvt),e(st,Eke),e(Eke,Tvt),e(st,Mvt),e(st,Hn),e(Hn,Evt),e(Hn,Cke),e(Cke,Cvt),e(Hn,wvt),e(Hn,wke),e(wke,Avt),e(Hn,Lvt),e(Hn,Ake),e(Ake,yvt),e(Hn,xvt),e(st,$vt),e(st,ze),e(ze,KL),e(KL,Lke),e(Lke,kvt),e(KL,Svt),e(KL,$le),e($le,Rvt),e(KL,Pvt),e(ze,Bvt),e(ze,ZL),e(ZL,yke),e(yke,Ivt),e(ZL,Nvt),e(ZL,kle),e(kle,qvt),e(ZL,jvt),e(ze,Dvt),e(ze,ey),e(ey,xke),e(xke,Gvt),e(ey,Ovt),e(ey,Sle),e(Sle,Vvt),e(ey,Xvt),e(ze,zvt),e(ze,oy),e(oy,$ke),e($ke,Qvt),e(oy,Wvt),e(oy,Rle),e(Rle,Uvt),e(oy,Hvt),e(ze,Jvt),e(ze,ry),e(ry,kke),e(kke,Yvt),e(ry,Kvt),e(ry,Ple),e(Ple,Zvt),e(ry,eFt),e(ze,oFt),e(ze,ty),e(ty,Ske),e(Ske,rFt),e(ty,tFt),e(ty,Ble),e(Ble,aFt),e(ty,nFt),e(ze,sFt),e(ze,ay),e(ay,Rke),e(Rke,lFt),e(ay,iFt),e(ay,Ile),e(Ile,dFt),e(ay,mFt),e(ze,cFt),e(ze,ny),e(ny,Pke),e(Pke,fFt),e(ny,gFt),e(ny,Nle),e(Nle,hFt),e(ny,uFt),e(st,pFt),M(sy,st,null),b(c,Woo,_),b(c,cf,_),e(cf,ly),e(ly,Bke),M(gP,Bke,null),e(cf,_Ft),e(cf,Ike),e(Ike,bFt),b(c,Uoo,_),b(c,kr,_),M(hP,kr,null),e(kr,vFt),e(kr,ff),e(ff,FFt),e(ff,qle),e(qle,TFt),e(ff,MFt),e(ff,jle),e(jle,EFt),e(ff,CFt),e(kr,wFt),e(kr,uP),e(uP,AFt),e(uP,Nke),e(Nke,LFt),e(uP,yFt),e(kr,xFt),e(kr,ua),M(pP,ua,null),e(ua,$Ft),e(ua,qke),e(qke,kFt),e(ua,SFt),e(ua,gf),e(gf,RFt),e(gf,jke),e(jke,PFt),e(gf,BFt),e(gf,Dle),e(Dle,IFt),e(gf,NFt),e(ua,qFt),M(iy,ua,null),e(kr,jFt),e(kr,lt),M(_P,lt,null),e(lt,DFt),e(lt,Dke),e(Dke,GFt),e(lt,OFt),e(lt,Jn),e(Jn,VFt),e(Jn,Gke),e(Gke,XFt),e(Jn,zFt),e(Jn,Oke),e(Oke,QFt),e(Jn,WFt),e(Jn,Vke),e(Vke,UFt),e(Jn,HFt),e(lt,JFt),e(lt,Xke),e(Xke,dy),e(dy,zke),e(zke,YFt),e(dy,KFt),e(dy,Gle),e(Gle,ZFt),e(dy,eTt),e(lt,oTt),M(my,lt,null),b(c,Hoo,_),b(c,hf,_),e(hf,cy),e(cy,Qke),M(bP,Qke,null),e(hf,rTt),e(hf,Wke),e(Wke,tTt),b(c,Joo,_),b(c,Sr,_),M(vP,Sr,null),e(Sr,aTt),e(Sr,uf),e(uf,nTt),e(uf,Ole),e(Ole,sTt),e(uf,lTt),e(uf,Vle),e(Vle,iTt),e(uf,dTt),e(Sr,mTt),e(Sr,FP),e(FP,cTt),e(FP,Uke),e(Uke,fTt),e(FP,gTt),e(Sr,hTt),e(Sr,pa),M(TP,pa,null),e(pa,uTt),e(pa,Hke),e(Hke,pTt),e(pa,_Tt),e(pa,pf),e(pf,bTt),e(pf,Jke),e(Jke,vTt),e(pf,FTt),e(pf,Xle),e(Xle,TTt),e(pf,MTt),e(pa,ETt),M(fy,pa,null),e(Sr,CTt),e(Sr,it),M(MP,it,null),e(it,wTt),e(it,Yke),e(Yke,ATt),e(it,LTt),e(it,Yn),e(Yn,yTt),e(Yn,Kke),e(Kke,xTt),e(Yn,$Tt),e(Yn,Zke),e(Zke,kTt),e(Yn,STt),e(Yn,eSe),e(eSe,RTt),e(Yn,PTt),e(it,BTt),e(it,EP),e(EP,gy),e(gy,oSe),e(oSe,ITt),e(gy,NTt),e(gy,zle),e(zle,qTt),e(gy,jTt),e(EP,DTt),e(EP,hy),e(hy,rSe),e(rSe,GTt),e(hy,OTt),e(hy,Qle),e(Qle,VTt),e(hy,XTt),e(it,zTt),M(uy,it,null),b(c,Yoo,_),b(c,_f,_),e(_f,py),e(py,tSe),M(CP,tSe,null),e(_f,QTt),e(_f,aSe),e(aSe,WTt),b(c,Koo,_),b(c,Rr,_),M(wP,Rr,null),e(Rr,UTt),e(Rr,bf),e(bf,HTt),e(bf,Wle),e(Wle,JTt),e(bf,YTt),e(bf,Ule),e(Ule,KTt),e(bf,ZTt),e(Rr,eMt),e(Rr,AP),e(AP,oMt),e(AP,nSe),e(nSe,rMt),e(AP,tMt),e(Rr,aMt),e(Rr,_a),M(LP,_a,null),e(_a,nMt),e(_a,sSe),e(sSe,sMt),e(_a,lMt),e(_a,vf),e(vf,iMt),e(vf,lSe),e(lSe,dMt),e(vf,mMt),e(vf,Hle),e(Hle,cMt),e(vf,fMt),e(_a,gMt),M(_y,_a,null),e(Rr,hMt),e(Rr,dt),M(yP,dt,null),e(dt,uMt),e(dt,iSe),e(iSe,pMt),e(dt,_Mt),e(dt,Kn),e(Kn,bMt),e(Kn,dSe),e(dSe,vMt),e(Kn,FMt),e(Kn,mSe),e(mSe,TMt),e(Kn,MMt),e(Kn,cSe),e(cSe,EMt),e(Kn,CMt),e(dt,wMt),e(dt,fSe),e(fSe,by),e(by,gSe),e(gSe,AMt),e(by,LMt),e(by,Jle),e(Jle,yMt),e(by,xMt),e(dt,$Mt),M(vy,dt,null),Zoo=!0},p(c,[_]){const xP={};_&2&&(xP.$$scope={dirty:_,ctx:c}),yf.$set(xP);const hSe={};_&2&&(hSe.$$scope={dirty:_,ctx:c}),eu.$set(hSe);const uSe={};_&2&&(uSe.$$scope={dirty:_,ctx:c}),Nu.$set(uSe);const pSe={};_&2&&(pSe.$$scope={dirty:_,ctx:c}),yp.$set(pSe);const $P={};_&2&&($P.$$scope={dirty:_,ctx:c}),xp.$set($P);const _Se={};_&2&&(_Se.$$scope={dirty:_,ctx:c}),e_.$set(_Se);const Zn={};_&2&&(Zn.$$scope={dirty:_,ctx:c}),o_.$set(Zn);const bSe={};_&2&&(bSe.$$scope={dirty:_,ctx:c}),a_.$set(bSe);const vSe={};_&2&&(vSe.$$scope={dirty:_,ctx:c}),E1.$set(vSe);const FSe={};_&2&&(FSe.$$scope={dirty:_,ctx:c}),w1.$set(FSe);const kP={};_&2&&(kP.$$scope={dirty:_,ctx:c}),Tb.$set(kP);const TSe={};_&2&&(TSe.$$scope={dirty:_,ctx:c}),Eb.$set(TSe);const SP={};_&2&&(SP.$$scope={dirty:_,ctx:c}),gv.$set(SP);const MSe={};_&2&&(MSe.$$scope={dirty:_,ctx:c}),uv.$set(MSe);const RP={};_&2&&(RP.$$scope={dirty:_,ctx:c}),rF.$set(RP);const ESe={};_&2&&(ESe.$$scope={dirty:_,ctx:c}),aF.$set(ESe);const CSe={};_&2&&(CSe.$$scope={dirty:_,ctx:c}),AF.$set(CSe);const wSe={};_&2&&(wSe.$$scope={dirty:_,ctx:c}),yF.$set(wSe);const Ff={};_&2&&(Ff.$$scope={dirty:_,ctx:c}),kT.$set(Ff);const ASe={};_&2&&(ASe.$$scope={dirty:_,ctx:c}),RT.$set(ASe);const LSe={};_&2&&(LSe.$$scope={dirty:_,ctx:c}),gM.$set(LSe);const ySe={};_&2&&(ySe.$$scope={dirty:_,ctx:c}),uM.$set(ySe);const PP={};_&2&&(PP.$$scope={dirty:_,ctx:c}),CM.$set(PP);const xSe={};_&2&&(xSe.$$scope={dirty:_,ctx:c}),AM.$set(xSe);const $Se={};_&2&&($Se.$$scope={dirty:_,ctx:c}),hE.$set($Se);const kSe={};_&2&&(kSe.$$scope={dirty:_,ctx:c}),pE.$set(kSe);const ht={};_&2&&(ht.$$scope={dirty:_,ctx:c}),d4.$set(ht);const BP={};_&2&&(BP.$$scope={dirty:_,ctx:c}),c4.$set(BP);const SSe={};_&2&&(SSe.$$scope={dirty:_,ctx:c}),h4.$set(SSe);const IP={};_&2&&(IP.$$scope={dirty:_,ctx:c}),p4.$set(IP);const RSe={};_&2&&(RSe.$$scope={dirty:_,ctx:c}),T4.$set(RSe);const ut={};_&2&&(ut.$$scope={dirty:_,ctx:c}),E4.$set(ut);const PSe={};_&2&&(PSe.$$scope={dirty:_,ctx:c}),D4.$set(PSe);const Tf={};_&2&&(Tf.$$scope={dirty:_,ctx:c}),O4.$set(Tf);const BSe={};_&2&&(BSe.$$scope={dirty:_,ctx:c}),z4.$set(BSe);const ISe={};_&2&&(ISe.$$scope={dirty:_,ctx:c}),W4.$set(ISe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),J4.$set(L);const Fy={};_&2&&(Fy.$$scope={dirty:_,ctx:c}),K4.$set(Fy);const NSe={};_&2&&(NSe.$$scope={dirty:_,ctx:c}),oC.$set(NSe);const qSe={};_&2&&(qSe.$$scope={dirty:_,ctx:c}),tC.$set(qSe);const Ty={};_&2&&(Ty.$$scope={dirty:_,ctx:c}),hC.$set(Ty);const jSe={};_&2&&(jSe.$$scope={dirty:_,ctx:c}),pC.$set(jSe);const DSe={};_&2&&(DSe.$$scope={dirty:_,ctx:c}),EC.$set(DSe);const My={};_&2&&(My.$$scope={dirty:_,ctx:c}),wC.$set(My);const GSe={};_&2&&(GSe.$$scope={dirty:_,ctx:c}),NC.$set(GSe);const OSe={};_&2&&(OSe.$$scope={dirty:_,ctx:c}),jC.$set(OSe);const Ey={};_&2&&(Ey.$$scope={dirty:_,ctx:c}),VC.$set(Ey);const VSe={};_&2&&(VSe.$$scope={dirty:_,ctx:c}),zC.$set(VSe);const XSe={};_&2&&(XSe.$$scope={dirty:_,ctx:c}),KC.$set(XSe);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:c}),e3.$set(Cy);const zSe={};_&2&&(zSe.$$scope={dirty:_,ctx:c}),s3.$set(zSe);const QSe={};_&2&&(QSe.$$scope={dirty:_,ctx:c}),i3.$set(QSe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:c}),h3.$set(wy);const WSe={};_&2&&(WSe.$$scope={dirty:_,ctx:c}),p3.$set(WSe);const USe={};_&2&&(USe.$$scope={dirty:_,ctx:c}),v3.$set(USe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:c}),T3.$set(Ay);const HSe={};_&2&&(HSe.$$scope={dirty:_,ctx:c}),y3.$set(HSe);const JSe={};_&2&&(JSe.$$scope={dirty:_,ctx:c}),$3.$set(JSe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:c}),R3.$set(Ly);const YSe={};_&2&&(YSe.$$scope={dirty:_,ctx:c}),B3.$set(YSe);const KSe={};_&2&&(KSe.$$scope={dirty:_,ctx:c}),I5.$set(KSe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:c}),q5.$set(yy);const ZSe={};_&2&&(ZSe.$$scope={dirty:_,ctx:c}),i0.$set(ZSe);const eRe={};_&2&&(eRe.$$scope={dirty:_,ctx:c}),m0.$set(eRe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),w0.$set(xy);const oRe={};_&2&&(oRe.$$scope={dirty:_,ctx:c}),L0.$set(oRe);const rRe={};_&2&&(rRe.$$scope={dirty:_,ctx:c}),I0.$set(rRe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),q0.$set($y);const tRe={};_&2&&(tRe.$$scope={dirty:_,ctx:c}),O0.$set(tRe);const aRe={};_&2&&(aRe.$$scope={dirty:_,ctx:c}),X0.$set(aRe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),cw.$set(ky);const nRe={};_&2&&(nRe.$$scope={dirty:_,ctx:c}),gw.$set(nRe);const sRe={};_&2&&(sRe.$$scope={dirty:_,ctx:c}),Cw.$set(sRe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),Aw.$set(Sy);const lRe={};_&2&&(lRe.$$scope={dirty:_,ctx:c}),eA.$set(lRe);const iRe={};_&2&&(iRe.$$scope={dirty:_,ctx:c}),rA.$set(iRe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),FA.$set(Ry);const dRe={};_&2&&(dRe.$$scope={dirty:_,ctx:c}),MA.$set(dRe);const mRe={};_&2&&(mRe.$$scope={dirty:_,ctx:c}),wA.$set(mRe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),LA.$set(Py);const cRe={};_&2&&(cRe.$$scope={dirty:_,ctx:c}),xA.$set(cRe);const fRe={};_&2&&(fRe.$$scope={dirty:_,ctx:c}),kA.$set(fRe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),RA.$set(By);const gRe={};_&2&&(gRe.$$scope={dirty:_,ctx:c}),BA.$set(gRe);const hRe={};_&2&&(hRe.$$scope={dirty:_,ctx:c}),t6.$set(hRe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),n6.$set(Iy);const uRe={};_&2&&(uRe.$$scope={dirty:_,ctx:c}),L6.$set(uRe);const pRe={};_&2&&(pRe.$$scope={dirty:_,ctx:c}),x6.$set(pRe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),k6.$set(Ny);const _Re={};_&2&&(_Re.$$scope={dirty:_,ctx:c}),R6.$set(_Re);const bRe={};_&2&&(bRe.$$scope={dirty:_,ctx:c}),B6.$set(bRe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),N6.$set(qy);const vRe={};_&2&&(vRe.$$scope={dirty:_,ctx:c}),c7.$set(vRe);const FRe={};_&2&&(FRe.$$scope={dirty:_,ctx:c}),g7.$set(FRe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),C7.$set(jy);const TRe={};_&2&&(TRe.$$scope={dirty:_,ctx:c}),A7.$set(TRe);const MRe={};_&2&&(MRe.$$scope={dirty:_,ctx:c}),D7.$set(MRe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),O7.$set(Dy);const ERe={};_&2&&(ERe.$$scope={dirty:_,ctx:c}),Z7.$set(ERe);const CRe={};_&2&&(CRe.$$scope={dirty:_,ctx:c}),oL.$set(CRe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),fL.$set(Gy);const wRe={};_&2&&(wRe.$$scope={dirty:_,ctx:c}),hL.$set(wRe);const ARe={};_&2&&(ARe.$$scope={dirty:_,ctx:c}),wL.$set(ARe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),LL.$set(Oy);const LRe={};_&2&&(LRe.$$scope={dirty:_,ctx:c}),qL.$set(LRe);const yRe={};_&2&&(yRe.$$scope={dirty:_,ctx:c}),DL.$set(yRe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),HL.$set(Vy);const xRe={};_&2&&(xRe.$$scope={dirty:_,ctx:c}),YL.$set(xRe);const $Re={};_&2&&($Re.$$scope={dirty:_,ctx:c}),sy.$set($Re);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),iy.$set(Xy);const kRe={};_&2&&(kRe.$$scope={dirty:_,ctx:c}),my.$set(kRe);const SRe={};_&2&&(SRe.$$scope={dirty:_,ctx:c}),fy.$set(SRe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),uy.$set(zy);const RRe={};_&2&&(RRe.$$scope={dirty:_,ctx:c}),_y.$set(RRe);const PRe={};_&2&&(PRe.$$scope={dirty:_,ctx:c}),vy.$set(PRe)},i(c){Zoo||(E(d.$$.fragment,c),E(Qa.$$.fragment,c),E(ex.$$.fragment,c),E(ox.$$.fragment,c),E(yf.$$.fragment,c),E(rx.$$.fragment,c),E(tx.$$.fragment,c),E(sx.$$.fragment,c),E(eu.$$.fragment,c),E(lx.$$.fragment,c),E(ix.$$.fragment,c),E(dx.$$.fragment,c),E(fx.$$.fragment,c),E(Nu.$$.fragment,c),E(gx.$$.fragment,c),E(hx.$$.fragment,c),E(ux.$$.fragment,c),E(bx.$$.fragment,c),E(yp.$$.fragment,c),E(xp.$$.fragment,c),E(vx.$$.fragment,c),E(Fx.$$.fragment,c),E(Tx.$$.fragment,c),E(Cx.$$.fragment,c),E(e_.$$.fragment,c),E(o_.$$.fragment,c),E(wx.$$.fragment,c),E(Ax.$$.fragment,c),E(Lx.$$.fragment,c),E(xx.$$.fragment,c),E(a_.$$.fragment,c),E($x.$$.fragment,c),E(E1.$$.fragment,c),E(kx.$$.fragment,c),E(Sx.$$.fragment,c),E(Px.$$.fragment,c),E(w1.$$.fragment,c),E(Bx.$$.fragment,c),E(Tb.$$.fragment,c),E(Ix.$$.fragment,c),E(Nx.$$.fragment,c),E(jx.$$.fragment,c),E(Eb.$$.fragment,c),E(Dx.$$.fragment,c),E(gv.$$.fragment,c),E(Gx.$$.fragment,c),E(Ox.$$.fragment,c),E(Xx.$$.fragment,c),E(uv.$$.fragment,c),E(zx.$$.fragment,c),E(rF.$$.fragment,c),E(Qx.$$.fragment,c),E(Wx.$$.fragment,c),E(Hx.$$.fragment,c),E(aF.$$.fragment,c),E(Jx.$$.fragment,c),E(AF.$$.fragment,c),E(Yx.$$.fragment,c),E(Kx.$$.fragment,c),E(e$.$$.fragment,c),E(yF.$$.fragment,c),E(o$.$$.fragment,c),E(kT.$$.fragment,c),E(r$.$$.fragment,c),E(t$.$$.fragment,c),E(n$.$$.fragment,c),E(RT.$$.fragment,c),E(s$.$$.fragment,c),E(gM.$$.fragment,c),E(l$.$$.fragment,c),E(i$.$$.fragment,c),E(m$.$$.fragment,c),E(uM.$$.fragment,c),E(c$.$$.fragment,c),E(CM.$$.fragment,c),E(f$.$$.fragment,c),E(g$.$$.fragment,c),E(u$.$$.fragment,c),E(AM.$$.fragment,c),E(p$.$$.fragment,c),E(hE.$$.fragment,c),E(_$.$$.fragment,c),E(b$.$$.fragment,c),E(F$.$$.fragment,c),E(pE.$$.fragment,c),E(T$.$$.fragment,c),E(d4.$$.fragment,c),E(M$.$$.fragment,c),E(E$.$$.fragment,c),E(w$.$$.fragment,c),E(c4.$$.fragment,c),E(A$.$$.fragment,c),E(h4.$$.fragment,c),E(L$.$$.fragment,c),E(y$.$$.fragment,c),E($$.$$.fragment,c),E(p4.$$.fragment,c),E(k$.$$.fragment,c),E(T4.$$.fragment,c),E(S$.$$.fragment,c),E(R$.$$.fragment,c),E(B$.$$.fragment,c),E(E4.$$.fragment,c),E(I$.$$.fragment,c),E(D4.$$.fragment,c),E(N$.$$.fragment,c),E(q$.$$.fragment,c),E(D$.$$.fragment,c),E(O4.$$.fragment,c),E(G$.$$.fragment,c),E(z4.$$.fragment,c),E(O$.$$.fragment,c),E(V$.$$.fragment,c),E(z$.$$.fragment,c),E(W4.$$.fragment,c),E(Q$.$$.fragment,c),E(J4.$$.fragment,c),E(W$.$$.fragment,c),E(U$.$$.fragment,c),E(J$.$$.fragment,c),E(K4.$$.fragment,c),E(Y$.$$.fragment,c),E(oC.$$.fragment,c),E(K$.$$.fragment,c),E(Z$.$$.fragment,c),E(ok.$$.fragment,c),E(tC.$$.fragment,c),E(rk.$$.fragment,c),E(hC.$$.fragment,c),E(tk.$$.fragment,c),E(ak.$$.fragment,c),E(sk.$$.fragment,c),E(pC.$$.fragment,c),E(lk.$$.fragment,c),E(EC.$$.fragment,c),E(ik.$$.fragment,c),E(dk.$$.fragment,c),E(ck.$$.fragment,c),E(wC.$$.fragment,c),E(fk.$$.fragment,c),E(NC.$$.fragment,c),E(gk.$$.fragment,c),E(hk.$$.fragment,c),E(pk.$$.fragment,c),E(jC.$$.fragment,c),E(_k.$$.fragment,c),E(VC.$$.fragment,c),E(vk.$$.fragment,c),E(Fk.$$.fragment,c),E(Mk.$$.fragment,c),E(zC.$$.fragment,c),E(Ek.$$.fragment,c),E(KC.$$.fragment,c),E(Ck.$$.fragment,c),E(wk.$$.fragment,c),E(Lk.$$.fragment,c),E(e3.$$.fragment,c),E(yk.$$.fragment,c),E(s3.$$.fragment,c),E(xk.$$.fragment,c),E($k.$$.fragment,c),E(Sk.$$.fragment,c),E(i3.$$.fragment,c),E(Rk.$$.fragment,c),E(h3.$$.fragment,c),E(Pk.$$.fragment,c),E(Bk.$$.fragment,c),E(Nk.$$.fragment,c),E(p3.$$.fragment,c),E(qk.$$.fragment,c),E(v3.$$.fragment,c),E(jk.$$.fragment,c),E(Dk.$$.fragment,c),E(Ok.$$.fragment,c),E(T3.$$.fragment,c),E(Vk.$$.fragment,c),E(y3.$$.fragment,c),E(Xk.$$.fragment,c),E(zk.$$.fragment,c),E(Wk.$$.fragment,c),E($3.$$.fragment,c),E(Uk.$$.fragment,c),E(R3.$$.fragment,c),E(Hk.$$.fragment,c),E(Jk.$$.fragment,c),E(Kk.$$.fragment,c),E(B3.$$.fragment,c),E(Zk.$$.fragment,c),E(I5.$$.fragment,c),E(eS.$$.fragment,c),E(oS.$$.fragment,c),E(tS.$$.fragment,c),E(q5.$$.fragment,c),E(aS.$$.fragment,c),E(i0.$$.fragment,c),E(nS.$$.fragment,c),E(sS.$$.fragment,c),E(iS.$$.fragment,c),E(m0.$$.fragment,c),E(dS.$$.fragment,c),E(w0.$$.fragment,c),E(mS.$$.fragment,c),E(cS.$$.fragment,c),E(gS.$$.fragment,c),E(L0.$$.fragment,c),E(hS.$$.fragment,c),E(I0.$$.fragment,c),E(uS.$$.fragment,c),E(pS.$$.fragment,c),E(bS.$$.fragment,c),E(q0.$$.fragment,c),E(vS.$$.fragment,c),E(O0.$$.fragment,c),E(FS.$$.fragment,c),E(TS.$$.fragment,c),E(ES.$$.fragment,c),E(X0.$$.fragment,c),E(CS.$$.fragment,c),E(cw.$$.fragment,c),E(wS.$$.fragment,c),E(AS.$$.fragment,c),E(yS.$$.fragment,c),E(gw.$$.fragment,c),E(xS.$$.fragment,c),E(Cw.$$.fragment,c),E($S.$$.fragment,c),E(kS.$$.fragment,c),E(RS.$$.fragment,c),E(Aw.$$.fragment,c),E(PS.$$.fragment,c),E(eA.$$.fragment,c),E(BS.$$.fragment,c),E(IS.$$.fragment,c),E(qS.$$.fragment,c),E(rA.$$.fragment,c),E(jS.$$.fragment,c),E(FA.$$.fragment,c),E(DS.$$.fragment,c),E(GS.$$.fragment,c),E(VS.$$.fragment,c),E(MA.$$.fragment,c),E(XS.$$.fragment,c),E(wA.$$.fragment,c),E(QS.$$.fragment,c),E(WS.$$.fragment,c),E(HS.$$.fragment,c),E(LA.$$.fragment,c),E(JS.$$.fragment,c),E(xA.$$.fragment,c),E(YS.$$.fragment,c),E(KS.$$.fragment,c),E(eR.$$.fragment,c),E(kA.$$.fragment,c),E(oR.$$.fragment,c),E(RA.$$.fragment,c),E(rR.$$.fragment,c),E(tR.$$.fragment,c),E(nR.$$.fragment,c),E(BA.$$.fragment,c),E(sR.$$.fragment,c),E(t6.$$.fragment,c),E(lR.$$.fragment,c),E(iR.$$.fragment,c),E(mR.$$.fragment,c),E(n6.$$.fragment,c),E(cR.$$.fragment,c),E(L6.$$.fragment,c),E(fR.$$.fragment,c),E(gR.$$.fragment,c),E(uR.$$.fragment,c),E(x6.$$.fragment,c),E(pR.$$.fragment,c),E(k6.$$.fragment,c),E(_R.$$.fragment,c),E(bR.$$.fragment,c),E(FR.$$.fragment,c),E(R6.$$.fragment,c),E(TR.$$.fragment,c),E(B6.$$.fragment,c),E(MR.$$.fragment,c),E(ER.$$.fragment,c),E(wR.$$.fragment,c),E(N6.$$.fragment,c),E(AR.$$.fragment,c),E(c7.$$.fragment,c),E(LR.$$.fragment,c),E(yR.$$.fragment,c),E($R.$$.fragment,c),E(g7.$$.fragment,c),E(kR.$$.fragment,c),E(C7.$$.fragment,c),E(SR.$$.fragment,c),E(RR.$$.fragment,c),E(BR.$$.fragment,c),E(A7.$$.fragment,c),E(IR.$$.fragment,c),E(D7.$$.fragment,c),E(NR.$$.fragment,c),E(qR.$$.fragment,c),E(DR.$$.fragment,c),E(O7.$$.fragment,c),E(GR.$$.fragment,c),E(Z7.$$.fragment,c),E(OR.$$.fragment,c),E(VR.$$.fragment,c),E(zR.$$.fragment,c),E(oL.$$.fragment,c),E(QR.$$.fragment,c),E(fL.$$.fragment,c),E(WR.$$.fragment,c),E(UR.$$.fragment,c),E(JR.$$.fragment,c),E(hL.$$.fragment,c),E(YR.$$.fragment,c),E(wL.$$.fragment,c),E(KR.$$.fragment,c),E(ZR.$$.fragment,c),E(oP.$$.fragment,c),E(LL.$$.fragment,c),E(rP.$$.fragment,c),E(qL.$$.fragment,c),E(tP.$$.fragment,c),E(aP.$$.fragment,c),E(sP.$$.fragment,c),E(DL.$$.fragment,c),E(lP.$$.fragment,c),E(HL.$$.fragment,c),E(iP.$$.fragment,c),E(dP.$$.fragment,c),E(cP.$$.fragment,c),E(YL.$$.fragment,c),E(fP.$$.fragment,c),E(sy.$$.fragment,c),E(gP.$$.fragment,c),E(hP.$$.fragment,c),E(pP.$$.fragment,c),E(iy.$$.fragment,c),E(_P.$$.fragment,c),E(my.$$.fragment,c),E(bP.$$.fragment,c),E(vP.$$.fragment,c),E(TP.$$.fragment,c),E(fy.$$.fragment,c),E(MP.$$.fragment,c),E(uy.$$.fragment,c),E(CP.$$.fragment,c),E(wP.$$.fragment,c),E(LP.$$.fragment,c),E(_y.$$.fragment,c),E(yP.$$.fragment,c),E(vy.$$.fragment,c),Zoo=!0)},o(c){C(d.$$.fragment,c),C(Qa.$$.fragment,c),C(ex.$$.fragment,c),C(ox.$$.fragment,c),C(yf.$$.fragment,c),C(rx.$$.fragment,c),C(tx.$$.fragment,c),C(sx.$$.fragment,c),C(eu.$$.fragment,c),C(lx.$$.fragment,c),C(ix.$$.fragment,c),C(dx.$$.fragment,c),C(fx.$$.fragment,c),C(Nu.$$.fragment,c),C(gx.$$.fragment,c),C(hx.$$.fragment,c),C(ux.$$.fragment,c),C(bx.$$.fragment,c),C(yp.$$.fragment,c),C(xp.$$.fragment,c),C(vx.$$.fragment,c),C(Fx.$$.fragment,c),C(Tx.$$.fragment,c),C(Cx.$$.fragment,c),C(e_.$$.fragment,c),C(o_.$$.fragment,c),C(wx.$$.fragment,c),C(Ax.$$.fragment,c),C(Lx.$$.fragment,c),C(xx.$$.fragment,c),C(a_.$$.fragment,c),C($x.$$.fragment,c),C(E1.$$.fragment,c),C(kx.$$.fragment,c),C(Sx.$$.fragment,c),C(Px.$$.fragment,c),C(w1.$$.fragment,c),C(Bx.$$.fragment,c),C(Tb.$$.fragment,c),C(Ix.$$.fragment,c),C(Nx.$$.fragment,c),C(jx.$$.fragment,c),C(Eb.$$.fragment,c),C(Dx.$$.fragment,c),C(gv.$$.fragment,c),C(Gx.$$.fragment,c),C(Ox.$$.fragment,c),C(Xx.$$.fragment,c),C(uv.$$.fragment,c),C(zx.$$.fragment,c),C(rF.$$.fragment,c),C(Qx.$$.fragment,c),C(Wx.$$.fragment,c),C(Hx.$$.fragment,c),C(aF.$$.fragment,c),C(Jx.$$.fragment,c),C(AF.$$.fragment,c),C(Yx.$$.fragment,c),C(Kx.$$.fragment,c),C(e$.$$.fragment,c),C(yF.$$.fragment,c),C(o$.$$.fragment,c),C(kT.$$.fragment,c),C(r$.$$.fragment,c),C(t$.$$.fragment,c),C(n$.$$.fragment,c),C(RT.$$.fragment,c),C(s$.$$.fragment,c),C(gM.$$.fragment,c),C(l$.$$.fragment,c),C(i$.$$.fragment,c),C(m$.$$.fragment,c),C(uM.$$.fragment,c),C(c$.$$.fragment,c),C(CM.$$.fragment,c),C(f$.$$.fragment,c),C(g$.$$.fragment,c),C(u$.$$.fragment,c),C(AM.$$.fragment,c),C(p$.$$.fragment,c),C(hE.$$.fragment,c),C(_$.$$.fragment,c),C(b$.$$.fragment,c),C(F$.$$.fragment,c),C(pE.$$.fragment,c),C(T$.$$.fragment,c),C(d4.$$.fragment,c),C(M$.$$.fragment,c),C(E$.$$.fragment,c),C(w$.$$.fragment,c),C(c4.$$.fragment,c),C(A$.$$.fragment,c),C(h4.$$.fragment,c),C(L$.$$.fragment,c),C(y$.$$.fragment,c),C($$.$$.fragment,c),C(p4.$$.fragment,c),C(k$.$$.fragment,c),C(T4.$$.fragment,c),C(S$.$$.fragment,c),C(R$.$$.fragment,c),C(B$.$$.fragment,c),C(E4.$$.fragment,c),C(I$.$$.fragment,c),C(D4.$$.fragment,c),C(N$.$$.fragment,c),C(q$.$$.fragment,c),C(D$.$$.fragment,c),C(O4.$$.fragment,c),C(G$.$$.fragment,c),C(z4.$$.fragment,c),C(O$.$$.fragment,c),C(V$.$$.fragment,c),C(z$.$$.fragment,c),C(W4.$$.fragment,c),C(Q$.$$.fragment,c),C(J4.$$.fragment,c),C(W$.$$.fragment,c),C(U$.$$.fragment,c),C(J$.$$.fragment,c),C(K4.$$.fragment,c),C(Y$.$$.fragment,c),C(oC.$$.fragment,c),C(K$.$$.fragment,c),C(Z$.$$.fragment,c),C(ok.$$.fragment,c),C(tC.$$.fragment,c),C(rk.$$.fragment,c),C(hC.$$.fragment,c),C(tk.$$.fragment,c),C(ak.$$.fragment,c),C(sk.$$.fragment,c),C(pC.$$.fragment,c),C(lk.$$.fragment,c),C(EC.$$.fragment,c),C(ik.$$.fragment,c),C(dk.$$.fragment,c),C(ck.$$.fragment,c),C(wC.$$.fragment,c),C(fk.$$.fragment,c),C(NC.$$.fragment,c),C(gk.$$.fragment,c),C(hk.$$.fragment,c),C(pk.$$.fragment,c),C(jC.$$.fragment,c),C(_k.$$.fragment,c),C(VC.$$.fragment,c),C(vk.$$.fragment,c),C(Fk.$$.fragment,c),C(Mk.$$.fragment,c),C(zC.$$.fragment,c),C(Ek.$$.fragment,c),C(KC.$$.fragment,c),C(Ck.$$.fragment,c),C(wk.$$.fragment,c),C(Lk.$$.fragment,c),C(e3.$$.fragment,c),C(yk.$$.fragment,c),C(s3.$$.fragment,c),C(xk.$$.fragment,c),C($k.$$.fragment,c),C(Sk.$$.fragment,c),C(i3.$$.fragment,c),C(Rk.$$.fragment,c),C(h3.$$.fragment,c),C(Pk.$$.fragment,c),C(Bk.$$.fragment,c),C(Nk.$$.fragment,c),C(p3.$$.fragment,c),C(qk.$$.fragment,c),C(v3.$$.fragment,c),C(jk.$$.fragment,c),C(Dk.$$.fragment,c),C(Ok.$$.fragment,c),C(T3.$$.fragment,c),C(Vk.$$.fragment,c),C(y3.$$.fragment,c),C(Xk.$$.fragment,c),C(zk.$$.fragment,c),C(Wk.$$.fragment,c),C($3.$$.fragment,c),C(Uk.$$.fragment,c),C(R3.$$.fragment,c),C(Hk.$$.fragment,c),C(Jk.$$.fragment,c),C(Kk.$$.fragment,c),C(B3.$$.fragment,c),C(Zk.$$.fragment,c),C(I5.$$.fragment,c),C(eS.$$.fragment,c),C(oS.$$.fragment,c),C(tS.$$.fragment,c),C(q5.$$.fragment,c),C(aS.$$.fragment,c),C(i0.$$.fragment,c),C(nS.$$.fragment,c),C(sS.$$.fragment,c),C(iS.$$.fragment,c),C(m0.$$.fragment,c),C(dS.$$.fragment,c),C(w0.$$.fragment,c),C(mS.$$.fragment,c),C(cS.$$.fragment,c),C(gS.$$.fragment,c),C(L0.$$.fragment,c),C(hS.$$.fragment,c),C(I0.$$.fragment,c),C(uS.$$.fragment,c),C(pS.$$.fragment,c),C(bS.$$.fragment,c),C(q0.$$.fragment,c),C(vS.$$.fragment,c),C(O0.$$.fragment,c),C(FS.$$.fragment,c),C(TS.$$.fragment,c),C(ES.$$.fragment,c),C(X0.$$.fragment,c),C(CS.$$.fragment,c),C(cw.$$.fragment,c),C(wS.$$.fragment,c),C(AS.$$.fragment,c),C(yS.$$.fragment,c),C(gw.$$.fragment,c),C(xS.$$.fragment,c),C(Cw.$$.fragment,c),C($S.$$.fragment,c),C(kS.$$.fragment,c),C(RS.$$.fragment,c),C(Aw.$$.fragment,c),C(PS.$$.fragment,c),C(eA.$$.fragment,c),C(BS.$$.fragment,c),C(IS.$$.fragment,c),C(qS.$$.fragment,c),C(rA.$$.fragment,c),C(jS.$$.fragment,c),C(FA.$$.fragment,c),C(DS.$$.fragment,c),C(GS.$$.fragment,c),C(VS.$$.fragment,c),C(MA.$$.fragment,c),C(XS.$$.fragment,c),C(wA.$$.fragment,c),C(QS.$$.fragment,c),C(WS.$$.fragment,c),C(HS.$$.fragment,c),C(LA.$$.fragment,c),C(JS.$$.fragment,c),C(xA.$$.fragment,c),C(YS.$$.fragment,c),C(KS.$$.fragment,c),C(eR.$$.fragment,c),C(kA.$$.fragment,c),C(oR.$$.fragment,c),C(RA.$$.fragment,c),C(rR.$$.fragment,c),C(tR.$$.fragment,c),C(nR.$$.fragment,c),C(BA.$$.fragment,c),C(sR.$$.fragment,c),C(t6.$$.fragment,c),C(lR.$$.fragment,c),C(iR.$$.fragment,c),C(mR.$$.fragment,c),C(n6.$$.fragment,c),C(cR.$$.fragment,c),C(L6.$$.fragment,c),C(fR.$$.fragment,c),C(gR.$$.fragment,c),C(uR.$$.fragment,c),C(x6.$$.fragment,c),C(pR.$$.fragment,c),C(k6.$$.fragment,c),C(_R.$$.fragment,c),C(bR.$$.fragment,c),C(FR.$$.fragment,c),C(R6.$$.fragment,c),C(TR.$$.fragment,c),C(B6.$$.fragment,c),C(MR.$$.fragment,c),C(ER.$$.fragment,c),C(wR.$$.fragment,c),C(N6.$$.fragment,c),C(AR.$$.fragment,c),C(c7.$$.fragment,c),C(LR.$$.fragment,c),C(yR.$$.fragment,c),C($R.$$.fragment,c),C(g7.$$.fragment,c),C(kR.$$.fragment,c),C(C7.$$.fragment,c),C(SR.$$.fragment,c),C(RR.$$.fragment,c),C(BR.$$.fragment,c),C(A7.$$.fragment,c),C(IR.$$.fragment,c),C(D7.$$.fragment,c),C(NR.$$.fragment,c),C(qR.$$.fragment,c),C(DR.$$.fragment,c),C(O7.$$.fragment,c),C(GR.$$.fragment,c),C(Z7.$$.fragment,c),C(OR.$$.fragment,c),C(VR.$$.fragment,c),C(zR.$$.fragment,c),C(oL.$$.fragment,c),C(QR.$$.fragment,c),C(fL.$$.fragment,c),C(WR.$$.fragment,c),C(UR.$$.fragment,c),C(JR.$$.fragment,c),C(hL.$$.fragment,c),C(YR.$$.fragment,c),C(wL.$$.fragment,c),C(KR.$$.fragment,c),C(ZR.$$.fragment,c),C(oP.$$.fragment,c),C(LL.$$.fragment,c),C(rP.$$.fragment,c),C(qL.$$.fragment,c),C(tP.$$.fragment,c),C(aP.$$.fragment,c),C(sP.$$.fragment,c),C(DL.$$.fragment,c),C(lP.$$.fragment,c),C(HL.$$.fragment,c),C(iP.$$.fragment,c),C(dP.$$.fragment,c),C(cP.$$.fragment,c),C(YL.$$.fragment,c),C(fP.$$.fragment,c),C(sy.$$.fragment,c),C(gP.$$.fragment,c),C(hP.$$.fragment,c),C(pP.$$.fragment,c),C(iy.$$.fragment,c),C(_P.$$.fragment,c),C(my.$$.fragment,c),C(bP.$$.fragment,c),C(vP.$$.fragment,c),C(TP.$$.fragment,c),C(fy.$$.fragment,c),C(MP.$$.fragment,c),C(uy.$$.fragment,c),C(CP.$$.fragment,c),C(wP.$$.fragment,c),C(LP.$$.fragment,c),C(_y.$$.fragment,c),C(yP.$$.fragment,c),C(vy.$$.fragment,c),Zoo=!1},d(c){t(g),c&&t(v),c&&t(u),w(d),c&&t(Ef),c&&t(pt),c&&t(Ve),c&&t(He),c&&t(wf),w(Qa,c),c&&t(Je),c&&t(Ae),c&&t(xo),c&&t(Wa),c&&t(DZe),c&&t(md),w(ex),c&&t(GZe),c&&t(as),c&&t(OZe),w(ox,c),c&&t(VZe),c&&t(nI),c&&t(XZe),w(yf,c),c&&t(zZe),c&&t(cd),w(rx),c&&t(QZe),c&&t($o),w(tx),w(sx),w(eu),w(lx),c&&t(WZe),c&&t(gd),w(ix),c&&t(UZe),c&&t(ko),w(dx),w(fx),w(Nu),w(gx),c&&t(HZe),c&&t(hd),w(hx),c&&t(JZe),c&&t(So),w(ux),w(bx),w(yp),w(xp),w(vx),c&&t(YZe),c&&t(ud),w(Fx),c&&t(KZe),c&&t(Ro),w(Tx),w(Cx),w(e_),w(o_),w(wx),c&&t(ZZe),c&&t(_d),w(Ax),c&&t(eeo),c&&t(Po),w(Lx),w(xx),w(a_),w($x),w(E1),c&&t(oeo),c&&t(Fd),w(kx),c&&t(reo),c&&t(Bo),w(Sx),w(Px),w(w1),w(Bx),w(Tb),c&&t(teo),c&&t(Ed),w(Ix),c&&t(aeo),c&&t(Io),w(Nx),w(jx),w(Eb),w(Dx),w(gv),c&&t(neo),c&&t(Ad),w(Gx),c&&t(seo),c&&t(No),w(Ox),w(Xx),w(uv),w(zx),w(rF),c&&t(leo),c&&t(xd),w(Qx),c&&t(ieo),c&&t(qo),w(Wx),w(Hx),w(aF),w(Jx),w(AF),c&&t(deo),c&&t(Sd),w(Yx),c&&t(meo),c&&t(jo),w(Kx),w(e$),w(yF),w(o$),w(kT),c&&t(ceo),c&&t(Bd),w(r$),c&&t(feo),c&&t(Do),w(t$),w(n$),w(RT),w(s$),w(gM),c&&t(geo),c&&t(qd),w(l$),c&&t(heo),c&&t(Go),w(i$),w(m$),w(uM),w(c$),w(CM),c&&t(ueo),c&&t(Gd),w(f$),c&&t(peo),c&&t(Oo),w(g$),w(u$),w(AM),w(p$),w(hE),c&&t(_eo),c&&t(Xd),w(_$),c&&t(beo),c&&t(Vo),w(b$),w(F$),w(pE),w(T$),w(d4),c&&t(veo),c&&t(Wd),w(M$),c&&t(Feo),c&&t(Xo),w(E$),w(w$),w(c4),w(A$),w(h4),c&&t(Teo),c&&t(Jd),w(L$),c&&t(Meo),c&&t(zo),w(y$),w($$),w(p4),w(k$),w(T4),c&&t(Eeo),c&&t(em),w(S$),c&&t(Ceo),c&&t(Qo),w(R$),w(B$),w(E4),w(I$),w(D4),c&&t(weo),c&&t(tm),w(N$),c&&t(Aeo),c&&t(Wo),w(q$),w(D$),w(O4),w(G$),w(z4),c&&t(Leo),c&&t(sm),w(O$),c&&t(yeo),c&&t(Uo),w(V$),w(z$),w(W4),w(Q$),w(J4),c&&t(xeo),c&&t(dm),w(W$),c&&t($eo),c&&t(Ho),w(U$),w(J$),w(K4),w(Y$),w(oC),c&&t(keo),c&&t(fm),w(K$),c&&t(Seo),c&&t(Jo),w(Z$),w(ok),w(tC),w(rk),w(hC),c&&t(Reo),c&&t(um),w(tk),c&&t(Peo),c&&t(Yo),w(ak),w(sk),w(pC),w(lk),w(EC),c&&t(Beo),c&&t(bm),w(ik),c&&t(Ieo),c&&t(Ko),w(dk),w(ck),w(wC),w(fk),w(NC),c&&t(Neo),c&&t(Tm),w(gk),c&&t(qeo),c&&t(Zo),w(hk),w(pk),w(jC),w(_k),w(VC),c&&t(jeo),c&&t(Cm),w(vk),c&&t(Deo),c&&t(er),w(Fk),w(Mk),w(zC),w(Ek),w(KC),c&&t(Geo),c&&t(Lm),w(Ck),c&&t(Oeo),c&&t(or),w(wk),w(Lk),w(e3),w(yk),w(s3),c&&t(Veo),c&&t($m),w(xk),c&&t(Xeo),c&&t(rr),w($k),w(Sk),w(i3),w(Rk),w(h3),c&&t(zeo),c&&t(Rm),w(Pk),c&&t(Qeo),c&&t(tr),w(Bk),w(Nk),w(p3),w(qk),w(v3),c&&t(Weo),c&&t(Im),w(jk),c&&t(Ueo),c&&t(ar),w(Dk),w(Ok),w(T3),w(Vk),w(y3),c&&t(Heo),c&&t(jm),w(Xk),c&&t(Jeo),c&&t(nr),w(zk),w(Wk),w($3),w(Uk),w(R3),c&&t(Yeo),c&&t(Om),w(Hk),c&&t(Keo),c&&t(sr),w(Jk),w(Kk),w(B3),w(Zk),w(I5),c&&t(Zeo),c&&t(zm),w(eS),c&&t(eoo),c&&t(lr),w(oS),w(tS),w(q5),w(aS),w(i0),c&&t(ooo),c&&t(Um),w(nS),c&&t(roo),c&&t(ir),w(sS),w(iS),w(m0),w(dS),w(w0),c&&t(too),c&&t(Ym),w(mS),c&&t(aoo),c&&t(dr),w(cS),w(gS),w(L0),w(hS),w(I0),c&&t(noo),c&&t(ec),w(uS),c&&t(soo),c&&t(mr),w(pS),w(bS),w(q0),w(vS),w(O0),c&&t(loo),c&&t(ac),w(FS),c&&t(ioo),c&&t(cr),w(TS),w(ES),w(X0),w(CS),w(cw),c&&t(doo),c&&t(lc),w(wS),c&&t(moo),c&&t(fr),w(AS),w(yS),w(gw),w(xS),w(Cw),c&&t(coo),c&&t(mc),w($S),c&&t(foo),c&&t(gr),w(kS),w(RS),w(Aw),w(PS),w(eA),c&&t(goo),c&&t(gc),w(BS),c&&t(hoo),c&&t(hr),w(IS),w(qS),w(rA),w(jS),w(FA),c&&t(uoo),c&&t(pc),w(DS),c&&t(poo),c&&t(ur),w(GS),w(VS),w(MA),w(XS),w(wA),c&&t(_oo),c&&t(vc),w(QS),c&&t(boo),c&&t(pr),w(WS),w(HS),w(LA),w(JS),w(xA),c&&t(voo),c&&t(Mc),w(YS),c&&t(Foo),c&&t(_r),w(KS),w(eR),w(kA),w(oR),w(RA),c&&t(Too),c&&t(wc),w(rR),c&&t(Moo),c&&t(br),w(tR),w(nR),w(BA),w(sR),w(t6),c&&t(Eoo),c&&t(yc),w(lR),c&&t(Coo),c&&t(vr),w(iR),w(mR),w(n6),w(cR),w(L6),c&&t(woo),c&&t(kc),w(fR),c&&t(Aoo),c&&t(Fr),w(gR),w(uR),w(x6),w(pR),w(k6),c&&t(Loo),c&&t(Pc),w(_R),c&&t(yoo),c&&t(Tr),w(bR),w(FR),w(R6),w(TR),w(B6),c&&t(xoo),c&&t(Nc),w(MR),c&&t($oo),c&&t(Mr),w(ER),w(wR),w(N6),w(AR),w(c7),c&&t(koo),c&&t(Dc),w(LR),c&&t(Soo),c&&t(Er),w(yR),w($R),w(g7),w(kR),w(C7),c&&t(Roo),c&&t(Vc),w(SR),c&&t(Poo),c&&t(Cr),w(RR),w(BR),w(A7),w(IR),w(D7),c&&t(Boo),c&&t(Qc),w(NR),c&&t(Ioo),c&&t(wr),w(qR),w(DR),w(O7),w(GR),w(Z7),c&&t(Noo),c&&t(Hc),w(OR),c&&t(qoo),c&&t(Ar),w(VR),w(zR),w(oL),w(QR),w(fL),c&&t(joo),c&&t(Kc),w(WR),c&&t(Doo),c&&t(Lr),w(UR),w(JR),w(hL),w(YR),w(wL),c&&t(Goo),c&&t(of),w(KR),c&&t(Ooo),c&&t(yr),w(ZR),w(oP),w(LL),w(rP),w(qL),c&&t(Voo),c&&t(af),w(tP),c&&t(Xoo),c&&t(xr),w(aP),w(sP),w(DL),w(lP),w(HL),c&&t(zoo),c&&t(lf),w(iP),c&&t(Qoo),c&&t($r),w(dP),w(cP),w(YL),w(fP),w(sy),c&&t(Woo),c&&t(cf),w(gP),c&&t(Uoo),c&&t(kr),w(hP),w(pP),w(iy),w(_P),w(my),c&&t(Hoo),c&&t(hf),w(bP),c&&t(Joo),c&&t(Sr),w(vP),w(TP),w(fy),w(MP),w(uy),c&&t(Yoo),c&&t(_f),w(CP),c&&t(Koo),c&&t(Rr),w(wP),w(LP),w(_y),w(yP),w(vy)}}}const Xba={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function zba($){return B2a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Kba extends k2a{constructor(g){super();S2a(this,g,zba,Vba,R2a,{})}}export{Kba as default,Xba as metadata};
